{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to run the following noteboooks, if you haven't done yet, you need to deploy a model that uses `text-embedding-ada-002` as base model and set the deployment name inside .env file as `AZURE_OPENAI_EMBEDDINGS_ENDPOINT`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
<<<<<<< HEAD
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
=======
    "  api_key = \"\",  \n",
    "  api_version = \"2023-05-15\",\n",
    "  azure_endpoint = \"https://nsf-openai-dev.openai.azure.com/\"\n",
    "  )\n",
    "\n",
    "model = \"nsfadda\"\n",
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to load the Embedding Index into a Pandas Dataframe. The Embedding Index is stored in a JSON file called `embedding_index_3m.json`. The Embedding Index contains the Embeddings for each of the YouTube transcripts up until late Oct 2023."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
<<<<<<< HEAD
   "outputs": [],
=======
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker</th>\n",
       "      <th>title</th>\n",
       "      <th>videoId</th>\n",
       "      <th>start</th>\n",
       "      <th>seconds</th>\n",
       "      <th>summary</th>\n",
       "      <th>ada_v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:00:00</td>\n",
       "      <td>0</td>\n",
       "      <td>Join Seth Juarez as he discusses ethical conce...</td>\n",
       "      <td>[0.004357332363724, -0.028409153223037, 0.0111...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:03:07</td>\n",
       "      <td>187</td>\n",
       "      <td>In this video, the speaker discusses the chall...</td>\n",
       "      <td>[-0.0038613036740570003, -0.004626247566193000...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:06:13</td>\n",
       "      <td>373</td>\n",
       "      <td>The video discusses the limitations of general...</td>\n",
       "      <td>[0.00287682027556, -0.012365541420876001, 0.02...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:09:21</td>\n",
       "      <td>561</td>\n",
       "      <td>The video discusses the importance of consider...</td>\n",
       "      <td>[0.015913352370262, 0.000721095071639, 0.02349...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Seth Juarez, Josh Lovejoy, Sarah Bird</td>\n",
       "      <td>You're Not Solving the Problem You Think You'r...</td>\n",
       "      <td>-tJQm4mSh1s</td>\n",
       "      <td>00:12:24</td>\n",
       "      <td>744</td>\n",
       "      <td>The video discusses the importance of understa...</td>\n",
       "      <td>[5.447878720588051e-06, -0.011837740428745, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1404</th>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>zdDseNfbvIw</td>\n",
       "      <td>00:06:06</td>\n",
       "      <td>366</td>\n",
       "      <td>The video demonstrates how to use OpenVINO Exe...</td>\n",
       "      <td>[-0.007744120433926, 0.017017424106597002, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1405</th>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>zdDseNfbvIw</td>\n",
       "      <td>00:09:08</td>\n",
       "      <td>548</td>\n",
       "      <td>The video discusses performance optimization t...</td>\n",
       "      <td>[-0.010141291655600002, -0.009897269308567, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1406</th>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>zdDseNfbvIw</td>\n",
       "      <td>00:12:11</td>\n",
       "      <td>731</td>\n",
       "      <td>The video discusses the process of quantizatio...</td>\n",
       "      <td>[-0.016591534018516003, -0.004845560993999001,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1407</th>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>zdDseNfbvIw</td>\n",
       "      <td>00:15:13</td>\n",
       "      <td>913</td>\n",
       "      <td>The video demonstrates how to train and deploy...</td>\n",
       "      <td>[-0.005989842116832, -0.012303071096539001, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1408</th>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>Combining the power of Optimum, OpenVINO™, ONN...</td>\n",
       "      <td>zdDseNfbvIw</td>\n",
       "      <td>00:18:17</td>\n",
       "      <td>1097</td>\n",
       "      <td>The video demonstrates the process of installi...</td>\n",
       "      <td>[-0.010202650912106, 0.0037896572612220003, 0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1409 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                speaker  \\\n",
       "0                 Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "1                 Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "2                 Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "3                 Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "4                 Seth Juarez, Josh Lovejoy, Sarah Bird   \n",
       "...                                                 ...   \n",
       "1404  Combining the power of Optimum, OpenVINO™, ONN...   \n",
       "1405  Combining the power of Optimum, OpenVINO™, ONN...   \n",
       "1406  Combining the power of Optimum, OpenVINO™, ONN...   \n",
       "1407  Combining the power of Optimum, OpenVINO™, ONN...   \n",
       "1408  Combining the power of Optimum, OpenVINO™, ONN...   \n",
       "\n",
       "                                                  title      videoId  \\\n",
       "0     You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s   \n",
       "1     You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s   \n",
       "2     You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s   \n",
       "3     You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s   \n",
       "4     You're Not Solving the Problem You Think You'r...  -tJQm4mSh1s   \n",
       "...                                                 ...          ...   \n",
       "1404  Combining the power of Optimum, OpenVINO™, ONN...  zdDseNfbvIw   \n",
       "1405  Combining the power of Optimum, OpenVINO™, ONN...  zdDseNfbvIw   \n",
       "1406  Combining the power of Optimum, OpenVINO™, ONN...  zdDseNfbvIw   \n",
       "1407  Combining the power of Optimum, OpenVINO™, ONN...  zdDseNfbvIw   \n",
       "1408  Combining the power of Optimum, OpenVINO™, ONN...  zdDseNfbvIw   \n",
       "\n",
       "         start  seconds                                            summary  \\\n",
       "0     00:00:00        0  Join Seth Juarez as he discusses ethical conce...   \n",
       "1     00:03:07      187  In this video, the speaker discusses the chall...   \n",
       "2     00:06:13      373  The video discusses the limitations of general...   \n",
       "3     00:09:21      561  The video discusses the importance of consider...   \n",
       "4     00:12:24      744  The video discusses the importance of understa...   \n",
       "...        ...      ...                                                ...   \n",
       "1404  00:06:06      366  The video demonstrates how to use OpenVINO Exe...   \n",
       "1405  00:09:08      548  The video discusses performance optimization t...   \n",
       "1406  00:12:11      731  The video discusses the process of quantizatio...   \n",
       "1407  00:15:13      913  The video demonstrates how to train and deploy...   \n",
       "1408  00:18:17     1097  The video demonstrates the process of installi...   \n",
       "\n",
       "                                                 ada_v2  \n",
       "0     [0.004357332363724, -0.028409153223037, 0.0111...  \n",
       "1     [-0.0038613036740570003, -0.004626247566193000...  \n",
       "2     [0.00287682027556, -0.012365541420876001, 0.02...  \n",
       "3     [0.015913352370262, 0.000721095071639, 0.02349...  \n",
       "4     [5.447878720588051e-06, -0.011837740428745, 0....  \n",
       "...                                                 ...  \n",
       "1404  [-0.007744120433926, 0.017017424106597002, -0....  \n",
       "1405  [-0.010141291655600002, -0.009897269308567, 0....  \n",
       "1406  [-0.016591534018516003, -0.004845560993999001,...  \n",
       "1407  [-0.005989842116832, -0.012303071096539001, -0...  \n",
       "1408  [-0.010202650912106, 0.0037896572612220003, 0....  \n",
       "\n",
       "[1409 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
<<<<<<< HEAD
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
=======
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")\n",
    "\n"
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to create a function called `get_videos` that will search the Embedding Index for the query. The function will return the top 5 videos that are most similar to the query. The function works as follows:\n",
    "\n",
    "1. First, a copy of the Embedding Index is created.\n",
    "2. Next, the Embedding for the query is calculated using the OpenAI Embedding API.\n",
    "3. Then a new column is created in the Embedding Index called `similarity`. The `similarity` column contains the cosine similarity between the query Embedding and the Embedding for each video segment.\n",
    "4. Next, the Embedding Index is filtered by the `similarity` column. The Embedding Index is filtered to only include videos that have a cosine similarity greater than or equal to 0.75.\n",
    "5. Finally, the Embedding Index is sorted by the `similarity` column and the top 5 videos are returned."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 10,
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is very simple, it just prints out the results of the search query."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
=======
   "execution_count": 11,
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, the Embedding Index is loaded into a Pandas Dataframe.\n",
    "2. Next, the user is prompted to enter a query.\n",
    "3. Then the `get_videos` function is called to search the Embedding Index for the query.\n",
    "4. Finally, the `display_results` function is called to display the results to the user.\n",
    "5. The user is then prompted to enter another query. This process continues until the user enters `exit`.\n",
    "\n",
    "![](../images/notebook-search.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "You will be prompted to enter a query. Enter a query and press enter. The application will return a list of videos that are relevant to the query. The application will also return a link to the place in the video where the answer to the question is located.\n",
    "\n",
    "Here are some queries to try out:\n",
    "\n",
    "- What is Azure Machine Learning?\n",
    "- How do convolutional neural networks work?\n",
    "- What is a neural network?\n",
    "- Can I use Jupyter Notebooks with Azure Machine Learning?\n",
    "- What is ONNX?"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
=======
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Videos similar to 'How do convolutional neural networks work?':\n",
      " - Data Science, Convolutional Neural Networks, and Machine Learning in the Cloud (Part 3 of 4)\n",
      "   Summary: In this video, Seth Juarez continues his talk on data science, convolutional neural networks, and...\n",
      "   YouTube: https://youtu.be/0TwbqkQ9pxk?t=0\n",
      "   Similarity: 0.858103087151287\n",
      "   Speakers: Seth Juarez\n",
      " - Demystifying AI\n",
      "   Summary: In this video, the concept of Convolutional Neural Networks (CNNs) in deep learning for computer...\n",
      "   YouTube: https://youtu.be/k-K3g4FKS_c?t=183\n",
      "   Similarity: 0.8495954828121212\n",
      "   Speakers: Micheleen Harris\n",
      " - An Intuitive Approach to Machine Learning Models (Part 1 of 4)\n",
      "   Summary: In this video, the speaker explains the concept of building convolutional neural networks (CNNs) from...\n",
      "   YouTube: https://youtu.be/lPyK38sRWLI?t=549\n",
      "   Similarity: 0.839157436861602\n",
      "   Speakers: Seth, Seth Juarez\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"../scripts/embedding_index_3m.json\")\n",
    "query = input(\"Enter Query\")\n",
    "vector_heads = get_videos(query,dataset=dataset,rows=3)\n",
    "display_results(vector_heads, query)\n"
   ]
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
  }
 ],
 "metadata": {
  "kernelspec": {
<<<<<<< HEAD
   "display_name": "venv",
=======
   "display_name": "Python 3",
>>>>>>> 584a21c5 (Please enter the commit message for your changes. Lines starting)
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
