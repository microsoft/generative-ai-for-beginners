[![Dostrajanie LLM](../../img/18-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Dostrajanie Twojego LLM

U偶ywanie du偶ych modeli jzykowych do tworzenia aplikacji generatywnej AI wi偶e si z nowymi wyzwaniami. Kluczow kwesti jest zapewnienie jakoci odpowiedzi (dokadnoci i trafnoci) w treci generowanej przez model dla danego 偶dania u偶ytkownika. W poprzednich lekcjach omawialimy techniki takie jak in偶ynieria prompt贸w i retrieval-augmented generation, kt贸re pr贸buj rozwiza problem poprzez _modyfikacj danych wejciowych promptu_ do istniejcego modelu.

W dzisiejszej lekcji omawiamy trzeci technik, **dostrajanie (fine-tuning)**, kt贸ra pr贸buje sprosta wyzwaniu poprzez _ponowne trenowanie samego modelu_ z dodatkowymi danymi. Zagbmy si w szczeg贸y.

## Cele Nauki

Ta lekcja wprowadza pojcie dostrajania dla wstpnie wytrenowanych modeli jzykowych, bada korzyci i wyzwania tego podejcia oraz dostarcza wskaz贸wek, kiedy i jak u偶ywa dostrajania do poprawy wydajnoci Twoich modeli generatywnej AI.

Po ukoczeniu tej lekcji powiniene by w stanie odpowiedzie na nastpujce pytania:

- Czym jest dostrajanie dla modeli jzykowych?
- Kiedy i dlaczego dostrajanie jest przydatne?
- Jak mog dostroi wstpnie wytrenowany model?
- Jakie s ograniczenia dostrajania?

Gotowy? Zaczynajmy.

## Ilustrowany Przewodnik

Chcesz zobaczy og贸lny obraz tego, co om贸wimy, zanim zagbimy si w temat? Sprawd藕 ten ilustrowany przewodnik, kt贸ry opisuje podr贸偶 edukacyjn tej lekcji - od nauki podstawowych koncepcji i motywacji do dostrajania, po zrozumienie procesu i najlepszych praktyk wykonywania zadania dostrajania. To fascynujcy temat do eksploracji, wic nie zapomnij sprawdzi strony [Zasoby](./RESOURCES.md?WT.mc_id=academic-105485-koreyst), aby znale藕 dodatkowe linki wspierajce Twoj samodzieln podr贸偶 edukacyjn!

![Ilustrowany Przewodnik po Dostrajaniu Modeli Jzykowych](../../img/18-fine-tuning-sketchnote.png?WT.mc_id=academic-105485-koreyst)

## Czym jest dostrajanie dla modeli jzykowych?

Z definicji, du偶e modele jzykowe s _wstpnie trenowane_ na du偶ych ilociach tekstu pochodzcego z r贸偶norodnych 藕r贸de, w tym z internetu. Jak nauczylimy si w poprzednich lekcjach, potrzebujemy technik takich jak _in偶ynieria prompt贸w_ i _retrieval-augmented generation_, aby poprawi jako odpowiedzi modelu na pytania u偶ytkownika ("prompty").

Popularna technika in偶ynierii prompt贸w polega na dawaniu modelowi wicej wskaz贸wek na temat tego, czego oczekuje si w odpowiedzi, albo poprzez dostarczanie _instrukcji_ (jawne wskaz贸wki), albo _podawanie mu kilku przykad贸w_ (niejawne wskaz贸wki). Nazywa si to _uczeniem few-shot_, ale ma ono dwa ograniczenia:

- Limity token贸w modelu mog ogranicza liczb przykad贸w, kt贸re mo偶esz poda, i ogranicza skuteczno.
- Koszty token贸w modelu mog sprawi, 偶e dodawanie przykad贸w do ka偶dego promptu bdzie drogie i ograniczy elastyczno.

Dostrajanie jest powszechn praktyk w systemach uczenia maszynowego, gdzie bierzemy wstpnie wytrenowany model i ponownie go trenujemy z nowymi danymi, aby poprawi jego wydajno w konkretnym zadaniu. W kontekcie modeli jzykowych mo偶emy dostroi wstpnie wytrenowany model _za pomoc wyselekcjonowanego zestawu przykad贸w dla danego zadania lub domeny aplikacji_, aby stworzy **model niestandardowy**, kt贸ry mo偶e by bardziej dokadny i trafny dla tego konkretnego zadania lub domeny. Dodatkow korzyci z dostrajania jest to, 偶e mo偶e ono r贸wnie偶 zmniejszy liczb przykad贸w potrzebnych do uczenia few-shot - redukujc zu偶ycie token贸w i zwizane z tym koszty.

## Kiedy i dlaczego powinnimy dostraja modele?

W _tym_ kontekcie, gdy m贸wimy o dostrajaniu, mamy na myli **nadzorowane** dostrajanie, gdzie ponowne trenowanie odbywa si poprzez **dodanie nowych danych**, kt贸re nie byy czci oryginalnego zbioru danych treningowych. R贸偶ni si to od podejcia nienadzorowanego dostrajania, gdzie model jest ponownie trenowany na oryginalnych danych, ale z innymi hiperparametrami.

Kluczow rzecz do zapamitania jest to, 偶e dostrajanie jest zaawansowan technik, kt贸ra wymaga pewnego poziomu wiedzy, aby uzyska po偶dane rezultaty. Jeli zostanie wykonane nieprawidowo, mo偶e nie przynie oczekiwanych ulepsze, a nawet mo偶e pogorszy wydajno modelu dla Twojej docelowej domeny.

Wic zanim dowiesz si, "jak" dostraja modele jzykowe, musisz wiedzie, "dlaczego" powiniene wybra t drog i "kiedy" rozpocz proces dostrajania. Zacznij od zadania sobie tych pyta:

- **Przypadek u偶ycia**: Jaki jest Tw贸j _przypadek u偶ycia_ dla dostrajania? Jaki aspekt obecnego wstpnie wytrenowanego modelu chcesz poprawi?
- **Alternatywy**: Czy pr贸bowae _innych technik_, aby osign po偶dane wyniki? U偶yj ich do stworzenia punktu odniesienia do por贸wnania.
  - In偶ynieria prompt贸w: Wypr贸buj techniki takie jak prompting few-shot z przykadami trafnych odpowiedzi na prompty. Oce jako odpowiedzi.
  - Retrieval Augmented Generation: Spr贸buj wzbogaca prompty wynikami zapyta uzyskanymi poprzez przeszukiwanie Twoich danych. Oce jako odpowiedzi.
- **Koszty**: Czy zidentyfikowae koszty dostrajania?
  - Mo偶liwo dostrojenia - czy wstpnie wytrenowany model jest dostpny do dostrajania?
  - Wysiek - przygotowanie danych treningowych, ocena i udoskonalanie modelu.
  - Obliczenia - uruchamianie zada dostrajania i wdra偶anie dostrojonego modelu
  - Dane - dostp do wystarczajcej jakoci przykad贸w, aby dostrajanie miao wpyw
- **Korzyci**: Czy potwierdzie korzyci pynce z dostrajania?
  - Jako - czy dostrojony model przewy偶szy punkt odniesienia?
  - Koszt - czy redukuje zu偶ycie token贸w poprzez uproszczenie prompt贸w?
  - Rozszerzalno - czy mo偶esz ponownie wykorzysta model podstawowy dla nowych domen?

Odpowiadajc na te pytania, powiniene by w stanie zdecydowa, czy dostrajanie jest waciwym podejciem dla Twojego przypadku u偶ycia. Idealnie, podejcie jest zasadne tylko wtedy, gdy korzyci przewy偶szaj koszty. Gdy zdecydujesz si kontynuowa, nadszed czas, aby pomyle o tym, _jak_ mo偶esz dostroi wstpnie wytrenowany model.

Chcesz uzyska wicej informacji na temat procesu podejmowania decyzji? Obejrzyj [Dostraja czy nie dostraja](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Jak mo偶emy dostroi wstpnie wytrenowany model?

Aby dostroi wstpnie wytrenowany model, potrzebujesz:

- wstpnie wytrenowanego modelu do dostrojenia
- zbioru danych do u偶ycia do dostrajania
- rodowiska treningowego do uruchomienia zadania dostrajania
- rodowiska hostingowego do wdro偶enia dostrojonego modelu

## Dostrajanie w Akcji

Poni偶sze zasoby zawieraj samouczki krok po kroku, kt贸re przeprowadz Ci przez rzeczywisty przykad przy u偶yciu wybranego modelu z wyselekcjonowanym zbiorem danych. Aby przej przez te samouczki, potrzebujesz konta u okrelonego dostawcy, wraz z dostpem do odpowiedniego modelu i zbior贸w danych.

| Dostawca     | Samouczek                                                                                                                                                                       | Opis                                                                                                                                                                                                                                                                                                                                                                                                                                                                      |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Jak dostraja modele czatu](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                   | Naucz si dostraja `gpt-35-turbo` dla konkretnej domeny ("asystent przepis贸w") poprzez przygotowanie danych treningowych, uruchomienie zadania dostrajania i u偶ycie dostrojonego modelu do wnioskowania.                                                                                                                                                                                                                                                                 |
| Azure OpenAI | [Samouczek dostrajania GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Naucz si dostraja model `gpt-35-turbo-0613` **na Azure**, wykonujc kroki tworzenia i przesyania danych treningowych, uruchamiania zadania dostrajania. Wdr贸偶 i u偶ywaj nowego modelu.                                                                                                                                                                                                                                                                                  |
| Hugging Face | [Dostrajanie LLM za pomoc Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                            | Ten wpis na blogu przeprowadzi Ci przez proces dostrajania _otwartego LLM_ (np. `CodeLlama 7B`) przy u偶yciu biblioteki [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) i [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) z otwartymi [zbiorami danych](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |
|  AutoTrain | [Dostrajanie LLM za pomoc AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                      | AutoTrain (lub AutoTrain Advanced) to biblioteka Pythona opracowana przez Hugging Face, kt贸ra umo偶liwia dostrajanie dla wielu r贸偶nych zada, w tym dostrajanie LLM. AutoTrain to rozwizanie bez kodu, a dostrajanie mo偶na wykona we wasnej chmurze, na Hugging Face Spaces lub lokalnie. Obsuguje zar贸wno graficzny interfejs u偶ytkownika oparty na sieci Web, CLI, jak i trenowanie za pomoc plik贸w konfiguracyjnych yaml.                                          |
|              |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                                                           |

## Zadanie

Wybierz jeden z powy偶szych samouczk贸w i przejd藕 przez niego. _Mo偶emy zreplikowa wersj tych samouczk贸w w Jupyter Notebooks w tym repozytorium tylko w celach informacyjnych. Prosimy o bezporednie korzystanie z oryginalnych 藕r贸de, aby uzyska najnowsze wersje_.

## wietna Robota! Kontynuuj Nauk.

Po ukoczeniu tej lekcji sprawd藕 nasz [Kolekcj Nauki o Generatywnej AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby dalej podnosi swoj wiedz o Generatywnej AI!

Gratulacje!! Ukoczye ostatni lekcj z serii v2 tego kursu! Nie przestawaj si uczy i budowa. \*\*Sprawd藕 stron [ZASOBY](RESOURCES.md?WT.mc_id=academic-105485-koreyst), aby znale藕 list dodatkowych sugestii dotyczcych tego tematu.

Nasza seria lekcji v1 r贸wnie偶 zostaa zaktualizowana o wicej zada i koncepcji. Powi wic chwil na odwie偶enie wiedzy - i prosz [podziel si swoimi pytaniami i opiniami](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), aby pom贸c nam ulepszy te lekcje dla spoecznoci.
