# Explorando e comparando diferentes LLMs

[![Exploring and comparing different LLMs](../../images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreystt)

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

Na li√ß√£o anterior, vimos como a IA generativa est√° mudando o cen√°rio tecnol√≥gico, como os Grandes Modelos de Linguagens (LLMs) funcionam e como uma empresa - como nossa startup - pode aplic√°-los aos seus casos de uso e crescer! Neste cap√≠tulo, estamos procurando comparar e contrastar diferentes tipos de modelos de linguagem grandes, LLMs para entender seus pr√≥s e contras.

O pr√≥ximo passo na jornada de nossa startup √© explorar o cen√°rio atual dos Grandes Modelos de Linguagem (LLMs) e entender quais s√£o adequados para nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Diferentes tipos de LLMs no cen√°rio atual.
- Testar, iterar e comparar diferentes modelos para seu caso de uso no Azure.
- Como implantar um LLM.

## Objetivos de aprendizagem

Ap√≥s a conclus√£o desta li√ß√£o, voc√™ ser√° capaz de:

- Selecionar o modelo certo para seu caso de uso.
- Entender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implantam modelos.

## Entenda diferentes tipos de LLMs

Os Grandes Modelos de Linguagem (LLMs) podem ter v√°rias categoriza√ß√µes com base em sua arquitetura, dados de treinamento e caso de uso. Entender essas diferen√ßas ajudar√° nossa startup a selecionar o modelo certo para o cen√°rio e entender como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM, sua escolha de modelo depende do que voc√™ pretende us√°-los, seus dados, quanto voc√™ est√° pronto para pagar e muito mais.

Dependendo se voc√™ pretende usar os modelos para gera√ß√£o de texto, √°udio, v√≠deo ou imagem voc√™ pode optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e fala**: para esse fim, os modelos do tipo Whisper s√£o uma √≥tima escolha. Pois s√£o de prop√≥sito geral e destinados ao reconhecimento de fala. Ele √© treinado em √°udio diversificado e pode realizar reconhecimento de fala multil√≠ngue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de Imagem**: para gera√ß√£o de imagem, DALL-E e Midjourney s√£o duas escolhas muito conhecidas. DALL-E √© oferecido pelo Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**: a maioria dos modelos √© treinada na gera√ß√£o de texto e voc√™ tem uma grande variedade de escolhas, desde GPT-3.5 at√© GPT-4. Eles v√™m a custos diferentes, sendo o GPT-4 o mais caro. Vale a pena dar uma olhada no [Azure Open AI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais modelos se adequam melhor √†s suas necessidades em termos de capacidade e custo.

Escolher um modelo significa que voc√™ obt√©m algumas capacidades b√°sicas, que podem n√£o ser suficientes. Muitas vezes, voc√™ tem dados espec√≠ficos da empresa que precisa informar ao LLM. Existem algumas op√ß√µes diferentes sobre como abordar isso, abordaremos mais sobre isso nas pr√≥ximas se√ß√µes.

### Modelos de base versus LLMs

O termo Modelo de Funda√ß√£o foi [criado por pesquisadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que segue alguns crit√©rios, como:

- **Eles s√£o treinandos usando aprendizado n√£o supervisionado ou aprendizado auto-supervisionado**, o que significa que s√£o treinados em dados multimodais n√£o rotulados e n√£o requerem anota√ß√£o humana ou rotulagem de dados para seu processo de treinamento.

- **Eles s√£o modelos muito grandes**, baseados em redes neurais muito profundas treinadas em bilh√µes de par√¢metros.

- **Normalmente, eles s√£o destinados a servir como uma ‚Äòbase‚Äô para outros modelos**, o que significa que podem ser usados como ponto de partida para outros modelos serem constru√≠dos em cima, o que pode ser feito por ajuste fino.

![Foundation Models versus LLMs](../../images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)

Fonte da imagem: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404?WT.mc_id=academic-105485-koreyst)

Para esclarecer ainda mais essa distin√ß√£o, vamos usar o ChatGPT como exemplo. Para criar a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como modelo fundamental. Isso significa que a OpenAI utilizou alguns dados espec√≠ficos de conversa√ß√£o para criar uma vers√£o ajustada do GPT-3.5 que foi especializada em se sair bem em cen√°rios de conversa√ß√£o, como chatbots.

![Foundation Model](../../images/Multimodal.png?WT.mc_id=academic-105485-koreyst)

Fonte da imagem: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos de C√≥digo Aberto versus Modelos Propriet√°rios

Outra maneira de categorizar os Modelos de Linguagem de Grande Escala (LLMs) √© se eles s√£o de c√≥digo aberto ou propriet√°rios.

Os modelos de c√≥digo aberto s√£o modelos que s√£o disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. Eles s√£o frequentemente disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para diversos casos de uso em LLMs. No entanto, nem sempre s√£o otimizados para uso em produ√ß√£o e podem n√£o ser t√£o eficientes quanto os modelos propriet√°rios. Al√©m disso, o financiamento para modelos de c√≥digo aberto pode ser limitado, e eles podem n√£o ser mantidos a longo prazo ou n√£o ser atualizados com as pesquisas mais recentes. Exemplos de modelos de c√≥digo aberto populares incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://sapling.ai/llm/bloom?WT.mc_id=academic-105485-koreyst) e [LLaMA](https://sapling.ai/llm/llama?WT.mc_id=academic-105485-koreyst).

Os modelos propriet√°rios s√£o modelos de propriedade de uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Esses modelos s√£o frequentemente otimizados para uso em produ√ß√£o. No entanto, n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para uso. Al√©m disso, os usu√°rios n√£o t√™m controle sobre os dados usados para treinar o modelo, o que significa que devem confiar ao propriet√°rio do modelo o compromisso com a privacidade dos dados e o uso respons√°vel da IA. Exemplos de modelos propriet√°rios populares incluem [modelos da OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embeddings versus Gera√ß√£o de Imagem versus Gera√ß√£o de Texto e C√≥digo

Os LLMs tamb√©m podem ser categorizados com base na sa√≠da que geram.

Os `embeddings` s√£o um conjunto de modelos que podem converter texto em uma forma num√©rica, chamada `embedding`, que √© uma representa√ß√£o num√©rica do texto de entrada. Os `embeddings` facilitam a compreens√£o das rela√ß√µes entre palavras ou frases por m√°quinas e podem ser usadas como entradas por outros modelos, como modelos de classifica√ß√£o ou modelos de agrupamento que t√™m um melhor desempenho com dados num√©ricos. Modelos de incorpora√ß√£o s√£o frequentemente usados para aprendizado por transfer√™ncia, onde um modelo √© constru√≠do para uma tarefa substituta para a qual h√° uma abund√¢ncia de dados, e em seguida, os pesos do modelo (`embeddings`) s√£o reutilizados para outras tarefas subsequentes. Um exemplo desta categoria √© [Embeddings no OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../images/Embedding.png?WT.mc_id=academic-105485-koreyst)

Modelos de gera√ß√£o de imagem s√£o modelos que geram imagens. Esses modelos s√£o frequentemente usados para edi√ß√£o de imagens, s√≠ntese de imagens e tradu√ß√£o de imagens. Modelos de gera√ß√£o de imagem s√£o frequentemente treinados em grandes conjuntos de dados de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novas imagens ou editar imagens existentes com t√©cnicas de inpainting, super-resolu√ß√£o e coloriza√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [modelos do Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Image Generation](../../images/Image.png?WT.mc_id=academic-105485-koreyst)

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que geram texto ou c√≥digo. Esses modelos s√£o frequentemente usados para resumir texto, traduzir e responder a perguntas. Modelos de gera√ß√£o de texto s√£o frequentemente treinados em grandes conjuntos de dados de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novo texto ou responder a perguntas. Modelos de gera√ß√£o de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o frequentemente treinados em grandes conjuntos de dados de c√≥digo, como o GitHub, e podem ser usados para gerar novo c√≥digo ou corrigir bugs em c√≥digo existente.

![Text and code generation](../../images/Text.png?WT.mc_id=academic-105485-koreyst)

### Encoder-Decoder versus Decoder-only

Para falar sobre os diferentes tipos de arquiteturas de Grandes Modelos de Linguagem (LLMs), vamos usar uma analogia.

Imagine que seu gerente te deu uma tarefa de escrever um question√°rio para os alunos. Voc√™ tem dois colegas; um supervisiona a cria√ß√£o do conte√∫do e o outro supervisiona a revis√£o.

O criador de conte√∫do √© como um modelo somente `Decoder`, ele pode olhar para o t√≥pico e ver o que voc√™ j√° escreveu e ent√£o ele pode escrever um curso com base nisso. Eles s√£o muito bons em escrever conte√∫do envolvente e informativo, mas n√£o s√£o muito bons em entender o t√≥pico e os objetivos de aprendizado. Alguns exemplos de modelos Decodificadores s√£o os modelos da fam√≠lia GPT, como o GPT-3.

O revisor √© como um modelo somente `Encoder`, eles olham para o curso escrito e as respostas, percebendo a rela√ß√£o entre eles e entendendo o contexto, mas n√£o s√£o bons em gerar conte√∫do. Um exemplo de modelo somente Codificador seria o BERT.

Imagine que tamb√©m podemos ter algu√©m que possa criar e revisar o question√°rio, este √© um modelo `Encoder-Decoder`. Alguns exemplos seriam `BART` e `T5`.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre um servi√ßo e um modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos em Nuvem e √© frequentemente uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo e √© frequentemente um modelo fundamental, como um LLM.

Os servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e muitas vezes s√£o mais f√°ceis de usar do que os modelos, por meio de uma interface gr√°fica de usu√°rio. No entanto, os servi√ßos nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para uso, em troca de aproveitar os recursos e equipamentos do propriet√°rio do servi√ßo, otimizando despesas e escalando facilmente. Um exemplo de servi√ßo √© o [Servi√ßo do Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano de tarifas pay-as-you-go, o que significa que os usu√°rios s√£o cobrados de acordo com o quanto usam o servi√ßo. Al√©m disso, o servi√ßo do Azure OpenAI oferece seguran√ßa de n√≠vel empresarial e um framework de IA respons√°vel sobre as capacidades dos modelos.

Os modelos s√£o apenas as Redes Neurais, com par√¢metros, pesos e outros. Isso permite que as empresas os executem localmente. No entanto, elas precisariam comprar equipamentos, criar uma estrutura para escalar e adquirir uma licen√ßa ou usar um modelo de c√≥digo aberto. Um modelo como o `LLaMA` est√° dispon√≠vel para uso, exigindo poder computacional para executar o modelo.

## Como testar e iterar com diferentes modelos para entender o desempenho no Azure

Depois que nossa equipe explorou o cen√°rio atual dos LLMs e identificou alguns bons candidatos para seus cen√°rios, o pr√≥ximo passo √© test√°-los em seus dados e carga de trabalho. Isso √© um processo iterativo, feito por meio de experimentos e medi√ß√µes.
A maioria dos modelos mencionados nos par√°grafos anteriores (modelos da OpenAI, modelos de c√≥digo aberto como `Llama2` e `Hugging Face transformers`) est√° dispon√≠vel no [Foundation Models](https://learn.microsoft.com/azure/machine-learning/concept-foundation-models?WT.mc_id=academic-105485-koreyst) no [Azure Machine Learning studio](https://ml.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure Machine Learning](https://azure.microsoft.com/products/machine-learning/?WT.mc_id=academic-105485-koreyst) √© um servi√ßo em nuvem projetado para Cientistas de Dados e Engenheiros de Machine Learning que gerenciam o ciclo completo de Aprendizado de M√°quina (treinamento, teste, implanta√ß√£o e gerenciamento de MLOps) em uma √∫nica plataforma. O Machine Learning Studio oferece uma interface gr√°fica de usu√°rio para este servi√ßo e permite ao usu√°rio:

- Encontrar o Foundation Model de interesse no cat√°logo, filtrando por tarefa, licen√ßa ou nome. Tamb√©m √© poss√≠vel importar novos modelos que ainda n√£o estejam inclu√≠dos no cat√°logo.
- Analisar o cart√£o do modelo, incluindo uma descri√ß√£o detalhada e exemplos de c√≥digo, e test√°-lo com o widget de Infer√™ncia de Amostra, fornecendo um prompt de amostra para testar o resultado.

![Cart√£o do Modelo](../../images/Llama1.png?WT.mc_id=academic-105485-koreyst)

- Avaliar o desempenho do modelo com m√©tricas de avalia√ß√£o objetivas em uma carga de trabalho espec√≠fica e um conjunto de dados espec√≠fico fornecido como entrada.

![Avalia√ß√£o do Modelo](../../images/Llama2.png?WT.mc_id=academic-105485-koreyst)

- Ajustar o modelo com dados de treinamento personalizados para melhorar o desempenho do modelo em uma carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e rastreamento do Aprendizado de M√°quina do Azure.

![Ajuste do Modelo](../../images/Llama3.png?WT.mc_id=academic-105485-koreyst)

- Implante o modelo pr√©-treinado original ou a vers√£o ajustada a um ponto de extremidade remoto em tempo real ou por lote, para permitir que aplicativos o consumam.

![Implanta√ß√£o do Modelo](../../images/Llama4.png?WT.mc_id=academic-105485-koreyst)

## Melhorando os Resultados dos LLMs

Exploramos com nossa equipe de startup diferentes tipos de Modelos de Linguagem de Grande Escala (LLMs) e uma Plataforma em Nuvem (Azure Machine Learning) que nos permite comparar diferentes modelos, avali√°-los em dados de teste, melhorar o desempenho e implant√°-los em pontos de extremidade de infer√™ncia.

Mas quando eles devem considerar o ajuste fino de um modelo em vez de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias abordagens que uma empresa pode usar para obter os resultados desejados de um LLM, voc√™ pode selecionar diferentes tipos de modelos com diferentes graus de treinamento.

Implantar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens diferentes:

- **Engenharia de prompts com contexto**: a ideia √© fornecer contexto suficiente ao formular o prompt para garantir que voc√™ obtenha as respostas de que precisa.

- **Gera√ß√£o Aprimorada com Recupera√ß√£o, RAG**: seus dados podem existir em um banco de dados ou ponto de extremidade da web, por exemplo. Para garantir que esses dados, ou um subconjunto deles, estejam inclu√≠dos no momento do prompt, voc√™ pode buscar os dados relevantes e torn√°-los parte do prompt do usu√°rio.

- **Modelo ajustado fino**: nesse caso, voc√™ treinou o modelo ainda mais com seus pr√≥prios dados, o que torna o modelo mais preciso e responsivo √†s suas necessidades, mas pode ser custoso.

![Implanta√ß√£o de LLMs](../../images/Deploy.png?WT.mc_id=academic-105485-koreyst)

Fonte da imagem: [Quatro Maneiras de Empresas Implatarem LLMs | Blog Fiddler AI](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Engenharia de Prompts com Contexto

Os LLMs pr√©-treinados funcionam muito bem em tarefas de linguagem natural generalizadas, mesmo quando chamados com um prompt curto, como uma frase a ser completada ou uma pergunta - o chamado "aprendizado de zero-shot".

No entanto, quanto mais o usu√°rio puder estruturar sua consulta, com uma solicita√ß√£o detalhada e exemplos (o Contexto) mais precisa e pr√≥xima das expectativas do usu√°rio ser√° a resposta. Nesse caso, falamos de "aprendizado de um √∫nico exemplo" se o prompt incluir apenas um exemplo e "aprendizado de alguns exemplos" se incluir v√°rios exemplos.
A Engenharia de Prompts com contexto √© a abordagem mais econ√¥mica para come√ßar.

### Recupera√ß√£o de Gera√ß√£o Aumentada (RAG)

Os LLMs t√™m a limita√ß√£o de que s√≥ podem usar os dados que foram usados durante seu treinamento para gerar uma resposta. Isso significa que eles n√£o sabem nada sobre os fatos que ocorreram ap√≥s seu processo de treinamento e n√£o podem acessar informa√ß√µes n√£o p√∫blicas (como dados de uma empresa).
Isso pode ser superado por meio do `RAG`, uma t√©cnica que amplia o prompt com dados externos na forma de trechos de documentos, considerando limites de comprimento do prompt. Isso √© suportado por ferramentas de banco de dados vetoriais (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam trechos √∫teis de v√°rias fontes de dados predefinidas e os adicionam ao Contexto do prompt.

Essa t√©cnica √© muito √∫til quando uma empresa n√£o possui dados suficientes, tempo suficiente ou recursos para ajustar finamente um LLM, mas ainda deseja melhorar o desempenho em uma carga de trabalho espec√≠fica e reduzir os riscos de alucina√ß√µes. Ou seja, mistifica√ß√£o da realidade ou conte√∫do prejudicial.

### Modelo Ajustado Fino

O ajuste fino √© um processo que alavanca a aprendizagem por transfer√™ncia para 'adaptar' o modelo a uma tarefa subsequente ou para resolver um problema espec√≠fico. Diferentemente do aprendizado de alguns exemplos e do RAG, ele resulta na gera√ß√£o de um novo modelo, com pesos e vieses atualizados. Isso requer um conjunto de exemplos de treinamento consistindo de uma √∫nica entrada (o prompt) e sua sa√≠da associada (a conclus√£o).
Essa seria a abordagem preferida se:

- **Usando modelos ajustados finamente**: Uma empresa deseja usar modelos menos capazes ajustados finamente (como modelos de incorpora√ß√£o) em vez de modelos de alto desempenho, resultando em uma solu√ß√£o mais econ√¥mica e r√°pida.

- **Considerando a lat√™ncia**: A lat√™ncia √© importante para um caso de uso espec√≠fico, portanto, n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que devem ser aprendidos a partir do modelo n√£o se encaixa no limite de comprimento do prompt.

- **Mantendo-se atualizado**: Uma empresa possui muitos dados de alta qualidade e r√≥tulos de verdade fundamentais e os recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo Treinado

Treinar um LLM a partir do zero √©, sem d√∫vida, a abordagem mais dif√≠cil e complexa de adotar, exigindo enormes quantidades de dados, recursos qualificados e poder computacional adequado. Essa op√ß√£o deve ser considerada apenas em um cen√°rio em que uma empresa possui um caso de uso espec√≠fico de dom√≠nio e uma grande quantidade de dados centrados no dom√≠nio.

## Verifica√ß√£o de Conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de completude do LLM?

1. Engenharia de prompts com contexto
1. RAG
1. Modelo ajustado fino

R: 3 Pois, se voc√™ tem o tempo, os recursos e dados de alta qualidade, o ajuste fino √© a melhor op√ß√£o para se manter atualizado. No entanto, se voc√™ est√° procurando melhorar as coisas e est√° com pouco tempo, vale a pena considerar o RAG primeiro.

## üöÄ Desafio

Saiba mais sobre como voc√™ pode [usar o RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para o seu neg√≥cio.

## √ìtimo Trabalho, Continue com Seu Aprendizado

Deseja aprender mais sobre diferentes conceitos de IA Generativa? Acesse a [p√°gina de aprendizado cont√≠nuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar outros √≥timos recursos sobre este t√≥pico.

Vamos para a Li√ß√£o 3, onde veremos como podemos [Criar IA Generativa de forma Respons√°vel](../../../03-using-generative-ai-responsibly/translations/pt-br/README.md?WT.mc_id=academic-105485-koreyst)!
