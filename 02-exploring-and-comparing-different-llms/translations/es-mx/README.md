# Explorando y comparando diferentes LLM (Grandes modelos de lenguaje)

[![Explorando y comparando diferentes LLMs](../../images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://youtu.be/J1mWzw0P74c?WT.mc_id=academic-105485-koreyst)

> *Haz clic en la imagen de arriba para ver el video de esta lecci칩n*

Con la lecci칩n anterior, hemos visto c칩mo la Inteligencia Artificial Generativa est치 cambiando el panorama tecnol칩gico, c칩mo funcionan los Grandes Modelos del Lenguaje (LLMs) y c칩mo una empresa, como nuestra startup, puede aplicarlos a sus casos de uso y crecer. En este cap칤tulo, estamos buscando comparar y contrastar diferentes tipos de modelos de lenguaje grandes, LLMs, para entender sus ventajas y desventajas.

El siguiente paso en la trayectoria de nuestra startup es explorar el panorama actual de los Grandes Modelos del Lenguaje (LLMs) y comprender cu치les son adecuados para nuestro caso de uso.

## Introducci칩n

Esta lecci칩n abordar치:

-Diferentes tipos de Modelos de Lenguaje Grandes (LLMs) en el panorama actual.
-Pruebas, iteraciones y comparaciones de diferentes modelos para tu caso de uso en Azure.
-C칩mo implementar un LLM.

## Objetivos de aprendizaje

Despu칠s de completar esta lecci칩n, podr치s:

-Seleccionar el modelo adecuado para tu caso de uso.
-Comprender c칩mo probar, iterar y mejorar el rendimiento de tu modelo.
-Conocer c칩mo las empresas implementan modelos.

## Comprender diferentes tipos LLMs.

Los Grandes Modelos del Lenguaje (LLMs) pueden tener m칰ltiples categorizaciones basadas en su arquitectura, datos de entrenamiento y caso de uso. Comprender estas diferencias ayudar치 a nuestra startup a seleccionar el modelo adecuado para el escenario y entender c칩mo probar, iterar y mejorar el rendimiento.

Existen muchos tipos diferentes de modelos de LLM, la elecci칩n del modelo depende de para qu칠 planeas utilizarlos, tus datos, cu치nto est치s dispuesto a pagar y otros factores m치s.

Dependiendo de si planeas utilizar los modelos para generaci칩n de texto, audio, video, im치genes, entre otros, es posible que optes por un tipo de modelo diferente.

- **Reconocimiento de audio y voz**. Para este prop칩sito, los modelos tipo Whisper son una excelente elecci칩n, ya que son de prop칩sito general y est치n dise침ados para el reconocimiento de voz. Est치n entrenados en audio diverso y pueden realizar reconocimiento de voz multiling칲e. Obt칠n m치s informaci칩n sobre ellos en: [Modelos tipo Whisper aqu칤](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generaci칩n de im치genes**. Para la generaci칩n de im치genes, DALL-E y Midjourney son dos opciones muy conocidas. DALL-E es ofrecido por Azure OpenAI. [Lee m치s sobre DALL-E aqu칤](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) y tambi칠n en el Cap칤tulo 9 de este curso.

- **Generaci칩n de texto**. La mayor칤a de los modelos est치n entrenados en generaci칩n de texto y tienes una amplia variedad de opciones, desde GPT-3.5 hasta GPT-4. Tienen diferentes costos, siendo GPT-4 el m치s caro. Vale la pena investigar m치s al respecto. [Azure Open AI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para evaluar cu치les modelos se ajustan mejor a tus necesidades en t칠rminos de capacidad y costo.

Seleccionar un modelo te brinda algunas capacidades b치sicas, que podr칤an no ser suficientes. A menudo, tienes datos espec칤ficos de la empresa que necesitas de alguna manera transmitir al LLM. Hay algunas opciones diferentes sobre c칩mo abordar eso, m치s detalles en las secciones pr칩ximas.

### Modelos Fundacionales versus grandes modelos del Lenguaje (LLMs).

El t칠rmino "Modelo Fundacional" [fue acu침ado por investigadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) y se define como un modelo de inteligencia artificial que sigue ciertos criterios, tales como:

- **Son entrenados utilizando aprendizaje no supervisado o aprendizaje auto-supervisado**, Lo que significa que se entrenan con datos multimodales no etiquetados y no requieren anotaci칩n humana o etiquetado de datos para su proceso de entrenamiento.
- **Son modelos muy grandes**, Basados en redes neuronales muy profundas entrenadas con miles de millones de par치metros.
- **Normalmente est치n destinados a servir como una "base" para otros modelos**, Lo que significa que pueden usarse como punto de partida para que otros modelos se construyan sobre ellos, lo cual se puede hacer mediante el ajuste fino (fine-tuning).

![Modelos fundqacionales vs Grandes Modelos del Lenguaje](../../images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)

Fuente de la imagen: [Gu칤a Esencial sobre Modelos Fundacionales y Grandes Modelos del Lenguaje | por Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para aclarar a칰n m치s esta distinci칩n, tomemos ChatGPT como ejemplo. Para construir la primera versi칩n de ChatGPT, se utiliz칩 un modelo llamado GPT-3.5 como modelo base. Esto significa que OpenAI utiliz칩 datos espec칤ficos de conversaci칩n para crear una versi칩n ajustada de GPT-3.5 especializada en rendir bien en escenarios conversacionales, como chatbots.

![Modelo Fundacional](../images/Multimodal.png?WT.mc_id=academic-105485-koreyst)

Fuente de la imagen: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos de C칩digo Abierto versus Modelos Propios

Otra forma de categorizar los LLMs es si son de c칩digo abierto o propietarios.

Los modelos de c칩digo abierto son modelos que se ponen a disposici칩n del p칰blico y pueden ser utilizados por cualquier persona. A menudo son proporcionados por la empresa que los cre칩 o por la comunidad de investigaci칩n. Estos modelos pueden ser inspeccionados, modificados y personalizados para diversos casos de uso en los LLMs. Sin embargo, no siempre est치n optimizados para su uso en producci칩n y pueden no ser tan eficientes como los modelos propietarios. Adem치s, la financiaci칩n para modelos de c칩digo abierto puede ser limitada y es posible que no se mantengan a largo plazo o no se actualicen con las 칰ltimas investigaciones. Ejemplos de modelos de c칩digo abierto populares incluyen [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://sapling.ai/llm/bloom?WT.mc_id=academic-105485-koreyst) y [LLaMA](https://sapling.ai/llm/llama?WT.mc_id=academic-105485-koreyst).

Los modelos propios son modelos que pertenecen a una empresa y no se ponen a disposici칩n del p칰blico. Estos modelos suelen estar optimizados para su uso en producci칩n. Sin embargo, no se permite inspeccionar, modificar o personalizar estos modelos para diferentes casos de uso. Adem치s, no siempre est치n disponibles de forma gratuita y pueden requerir una suscripci칩n o pago para su uso. Tambi칠n, los usuarios no tienen control sobre los datos utilizados para entrenar el modelo, lo que significa que deben confiar en el propietario del modelo para garantizar el compromiso con la privacidad de los datos y el uso responsable de la inteligencia artificial. Ejemplos de modelos propietarios populares incluyen [Modelos de OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) or [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Incrustaci칩n (Embedding) versus Generaci칩n de Im치genes versus Generaci칩n de Texto y C칩digo.

Los LLMs tambi칠n pueden categorizarse seg칰n la salida que generan.

Las incrustaciones (Embeddings) son un conjunto de modelos que pueden convertir el texto en una forma num칠rica, llamada incrustaci칩n, que es una representaci칩n num칠rica del texto de entrada. Las incrustaciones facilitan que las m치quinas comprendan las relaciones entre palabras o oraciones y pueden ser consumidas como entradas por otros modelos, como modelos de clasificaci칩n o modelos de agrupamiento que tienen un mejor rendimiento en datos num칠ricos. Los modelos de incrustaci칩n a menudo se utilizan para el aprendizaje por transferencia, donde se construye un modelo para una tarea sustituta para la cual hay abundancia de datos, y luego los pesos del modelo (incrustaciones) se reutilizan para otras tareas posteriores. Un ejemplo de esta categor칤a es [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../images/Embedding.png?WT.mc_id=academic-105485-koreyst)

Los modelos de generaci칩n de im치genes son modelos que generan im치genes. Estos modelos se utilizan a menudo para la edici칩n de im치genes, s칤ntesis de im치genes y traducci칩n de im치genes. Los modelos de generaci칩n de im치genes a menudo se entrenan en grandes conjuntos de datos de im치genes, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), y se pueden utilizar para generar nuevas im치genes o editar im치genes existentes con t칠cnicas de rellenado, s칰per resoluci칩n y colorizaci칩n. Ejemplos incluyen [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) y [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generaci칩n de im치genes](../../images/Image.png?WT.mc_id=academic-105485-koreyst)

Los modelos de generaci칩n de texto y c칩digo son modelos que generan texto o c칩digo. Estos modelos se utilizan a menudo para la sumarizaci칩n de texto, la traducci칩n y la respuesta a preguntas. Los modelos de generaci칩n de texto a menudo se entrenan en grandes conjuntos de datos de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), y pueden ser utilizados para generar nuevo texto o responder preguntas. Los modelos de generaci칩n de c칩digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), a menudo se entrenan en grandes conjuntos de datos de c칩digo, como GitHub, y se pueden utilizar para generar nuevo c칩digo o corregir errores en el c칩digo existente.

 ![Generaci칩n de texto y c칩digo](../../images/Text.png?WT.mc_id=academic-105485-koreyst)

### Codificador-Decodificador versus Solo Decodificador

Para hablar sobre los diferentes tipos de arquitecturas de LLMs, usemos una analog칤a.

Imagina que tu jefe te asign칩 la tarea de escribir un cuestionario para los estudiantes. Tienes dos colegas; uno se encarga de crear el contenido y el otro se encarga de revisarlo.

El creador de contenido es como un modelo solo de decodificaci칩n, pueden mirar el tema y ver lo que ya escribiste y luego pueden escribir un curso basado en eso. Son muy buenos escribiendo contenido atractivo e informativo, pero no son muy buenos entendiendo el tema y los objetivos de aprendizaje. Algunos ejemplos de modelos de decodificaci칩n son los modelos de la familia GPT, como GPT-3.

El revisor es como un modelo solo de codificaci칩n, ellos miran el curso escrito y las respuestas, notando la relaci칩n entre ellos y entendiendo el contexto, pero no son buenos generando contenido. Un ejemplo de modelo solo de codificaci칩n ser칤a BERT.

Imagina que tambi칠n podemos tener a alguien que pueda crear y revisar el cuestionario, este es un modelo codificador-decodificador. Algunos ejemplos ser칤an BART y T5.

### Servicio versus modelo

Ahora, hablemos sobre la diferencia entre un servicio y un modelo. Un servicio es un producto que ofrece un proveedor de servicios en la nube y a menudo es una combinaci칩n de modelos, datos y otros componentes. Un modelo es el componente central de un servicio y a menudo es un modelo base, como un LLM.

Los servicios a menudo est치n optimizados para su uso en producci칩n y suelen ser m치s f치ciles de usar que los modelos, a trav칠s de una interfaz gr치fica de usuario. Sin embargo, los servicios no siempre est치n disponibles de forma gratuita y pueden requerir una suscripci칩n o pago para su uso, a cambio de aprovechar el equipo y los recursos del propietario del servicio, optimizando gastos y escalando f치cilmente. Un ejemplo de servicio es un servicio de almacenamiento en la nube como Dropbox o Google Drive.[Servicio de Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), el cual ofrece un plan de tarifas de pago por uso, lo que significa que los usuarios son cobrados de manera proporcional a la cantidad que utilicen el servicio. Adem치s, el servicio proporciona seguridad de nivel empresarial y un marco de inteligencia artificial responsable que se suma a las capacidades de los modelos.

Los modelos son simplemente la red neuronal, con sus par치metros, pesos y otros atributos. Permiten a las empresas ejecutarlos localmente; sin embargo, esto requerir칤a la compra de equipos, la construcci칩n de una estructura escalable y la adquisici칩n de una licencia o el uso de un modelo de c칩digo abierto. Un modelo como LLaMA est치 disponible para su uso, pero requiere potencia computacional para ejecutar el modelo.

## C칩mo probar e iterar con diferentes modelos para entender el rendimiento en Azure

Una vez que nuestro equipo ha explorado el panorama actual de los Modelos de Lenguaje de Gran Escala (LLMs, por sus siglas en ingl칠s) e identificado algunos buenos candidatos para sus escenarios, el siguiente paso es probarlos con sus datos y su carga de trabajo. Este es un proceso iterativo, realizado mediante experimentos y medidas. La mayor칤a de los modelos que mencionamos en los p치rrafos anteriores (modelos de OpenAI, modelos de c칩digo abierto como Llama2 y transformadores de Hugging Face) est치n disponibles en los [Modelos Base](https://learn.microsoft.com/azure/machine-learning/concept-foundation-models?WT.mc_id=academic-105485-koreyst) catalogo en [Azure Machine Learning studio](https://ml.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure Machine Learning](https://azure.microsoft.com/products/machine-learning/?WT.mc_id=academic-105485-koreyst)es un servicio en la nube dise침ado para cient칤ficos de datos e ingenieros de aprendizaje autom치tico para gestionar todo el ciclo de vida del aprendizaje autom치tico (entrenamiento, prueba, implementaci칩n y manejo de MLOps) en una sola plataforma. El estudio de aprendizaje autom치tico ofrece una interfaz gr치fica de usuario para este servicio y permite al usuario:

- Encontrar el Modelo Base de inter칠s en el cat치logo, filtrando por tarea, licencia o nombre. Tambi칠n es posible importar nuevos modelos que a칰n no est칠n incluidos en el cat치logo.
- Revisar la ficha del modelo, que incluye una descripci칩n detallada y ejemplos de c칩digo, y probarlo con el widget de Inferencia de Muestra, proporcionando un ejemplo de indicaci칩n para probar el resultado.
![Model card](../../images/Llama1.png?WT.mc_id=academic-105485-koreyst)

- Evaluar el rendimiento del modelo con m칠tricas de evaluaci칩n objetiva en una carga de trabajo espec칤fica y un conjunto de datos espec칤fico proporcionado como entrada.

![Modelo Evaluation](../../images/Llama2.png?WT.mc_id=academic-105485-koreyst)

- Ajustar el modelo con datos de entrenamiento personalizados para mejorar el rendimiento del modelo en una carga de trabajo espec칤fica, aprovechando las capacidades de experimentaci칩n y seguimiento de Azure Machine Learning.

![Modelo Fine-tuning](../../images/Llama3.png?WT.mc_id=academic-105485-koreyst)

- Despliega el modelo pre-entrenado original o la versi칩n ajustada a un punto final remoto de inferencia en tiempo real o por lotes, para permitir que las aplicaciones lo consuman.

![Modelo Deployment](../../images/Llama4.png?WT.mc_id=academic-105485-koreyst)

## Mejorando los resultados de LLM

Hemos explorado con nuestro equipo de inicio diferentes tipos de LLMs y una plataforma en la nube (Azure Machine Learning) que nos permite comparar diferentes modelos, evaluarlos con datos de prueba, mejorar el rendimiento y desplegarlos en puntos finales de inferencia.

Pero 쮺u치ndo deber칤an considerar ajustar finamente un modelo en lugar de usar uno preentrenado? 쮼xisten otros enfoques para mejorar el rendimiento del modelo en cargas de trabajo espec칤ficas?

Hay varios enfoques que una empresa puede usar para obtener los resultados que necesita de un LLM; puede seleccionar diferentes tipos de modelos con diferentes grados de entrenamiento.

desplegar un LLM en producci칩n, con diferentes niveles de complejidad, coste y calidad. Aqu칤 hay algunos enfoques diferentes:

- **Prompt engineering con texto**. La idea es proporcionar suficiente contexto al momento de formular la indicaci칩n para garantizar que obtengas las respuestas que necesitas.
  
- **Generaci칩n Aumentada por Recuperaci칩n (RAG)**. Sus datos podr칤an existir en una base de datos o en un punto final web, por ejemplo. Para asegurarse de que estos datos, o un subconjunto de los mismos, est칠n incluidos al momento de la indicaci칩n, puede recuperar los datos relevantes y hacer que formen parte de la indicaci칩n del usuario.

- **Modelo Fine-tuned**. Aqu칤, entrenaste el modelo a칰n m치s con tus propios datos, lo que hace que el modelo sea m치s preciso y receptivo a tus necesidades, pero podr칤a resultar costoso.

![Despliegue de LLMs](../../images/Deploy.png?WT.mc_id=academic-105485-koreyst)

Img source: [Cuatro formas en que las empresas despliegan LLMs | Blog de Fiddler AI](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ingenier칤a de Indicaciones con Contexto (Prompt Engineering)

Los LLM preentrenados funcionan muy bien en tareas generales del lenguaje natural, incluso al llamarlos con una indicaci칩n corta, como una oraci칩n por completar o una pregunta, lo que se conoce como aprendizaje "zero-shot"

Sin embargo, cuanto m치s el usuario pueda enmarcar su consulta con una solicitud detallada y ejemplos, es decir, el contexto, m치s precisa y cercana a las expectativas del usuario ser치 la respuesta. En este caso, hablamos de "aprendizaje de un disparo" si la indicaci칩n incluye solo un ejemplo y "aprendizaje de unos pocos disparos" si incluye varios ejemplos. La ingenier칤a de indicaciones con contexto es el enfoque m치s rentable para comenzar.

### Generaci칩n Aumentada por Recuperaci칩n (RAG)

Los LLM tienen la limitaci칩n de que solo pueden utilizar los datos que se han utilizado durante su entrenamiento para generar una respuesta. Esto significa que no saben nada sobre los hechos que ocurrieron despu칠s de su proceso de entrenamiento y no pueden acceder a informaci칩n no p칰blica (como datos de la empresa).

Esto se puede superar a trav칠s de RAG, una t칠cnica que aumenta la indicaci칩n con datos externos en forma de fragmentos de documentos, considerando los l칤mites de longitud de la indicaci칩n. Esto es compatible con las herramientas de base de datos vectoriales. (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperan los fragmentos 칰tiles de diversas fuentes de datos predefinidas y los agregan al contexto de la indicaci칩n.

Esta t칠cnica es muy 칰til cuando una empresa no tiene suficientes datos, tiempo o recursos para ajustar finamente un LLM, pero a칰n desea mejorar el rendimiento en una carga de trabajo espec칤fica y reducir los riesgos de fabricaciones, es decir, la mistificaci칩n de la realidad o contenido perjudicial.

### Modelo de ajuste fino (Fine-tuned)

El ajuste fino es un proceso que aprovecha el aprendizaje por transferencia para "adaptar" el modelo a una tarea descendente o para resolver un problema espec칤fico. A diferencia del aprendizaje de unos pocos disparos y de RAG, resulta en la generaci칩n de un nuevo modelo con pesos y sesgos actualizados. Requiere un conjunto de ejemplos de entrenamiento que consisten en una entrada 칰nica (la indicaci칩n) y su salida asociada (la completaci칩n). Este ser칤a el enfoque preferido si:

- **Usando modelos ajustados finamente**. Una empresa preferir칤a utilizar modelos ajustados finamente menos capaces (como modelos de incrustaci칩n) en lugar de modelos de alto rendimiento, lo que resulta en una soluci칩n m치s econ칩mica y r치pida.
  
- **Considerando la latencia**. La latencia es importante para un caso de uso espec칤fico, por lo que no es posible utilizar indicaciones muy largas o el n칰mero de ejemplos que deben ser aprendidos por el modelo no se ajusta al l칤mite de longitud de la indicaci칩n.

- **Mantenerse actualizado**. Una empresa cuenta con una gran cantidad de datos de alta calidad y etiquetas de verdad b치sica, as칤 como los recursos necesarios para mantener estos datos actualizados a lo largo del tiempo.
  
### Modelo entrenado

Entrenar un LLM desde cero es, sin duda, el enfoque m치s dif칤cil y complejo de adoptar, requiriendo cantidades masivas de datos, recursos capacitados y la potencia inform치tica adecuada. Esta opci칩n solo deber칤a considerarse en un escenario donde una empresa tenga un caso de uso espec칤fico del dominio y una gran cantidad de datos centrados en ese dominio.

## Verificaci칩n de conocimientos

쮺u치l podr칤a ser un buen enfoque para mejorar los resultados de finalizaci칩n del LLM?

1. Ingenier칤a de indicaciones con contexto.
1. RAG (Generaci칩n Aumentada por Recuperaci칩n).
1. Modelo ajustado finamente.

R:3, si tiene el tiempo, los recursos y los datos de alta calidad, realizar ajustes es la mejor opci칩n para mantenerse actualizado. Sin embargo, si buscas mejorar las cosas y te falta tiempo, vale la pena considerar RAG primero.

## 游 Desaf칤o

Lea m치s sobre c칩mo puede [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para su negocio.

## Gran trabajo, contin칰a aprendiendo

Despu칠s de completar esta lecci칩n, consulte nuestra [colecci칩n de aprendizaje de IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tus conocimientos de IA generativa!

Dir칤gete a la Lecci칩n 3, donde veremos c칩mo [construir con IA generativa de manera responsable](../../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!
