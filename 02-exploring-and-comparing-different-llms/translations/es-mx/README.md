# Explorando y comparando diferentes LLM

[![Explorando y comparando diferentes LLM](../../images/02-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Haga click en la imagen de arriba para ver el video de esta lecci贸n_

En la lecci贸n anterior, vimos c贸mo la IA Generativa est谩 cambiando el panorama tecnol贸gico, c贸mo funcionan los Modelos de Lenguaje Largo (LLM) y c贸mo una empresa, como nuestra startup, puede aplicarlos a sus casos de uso y crecer. En este cap铆tulo, buscamos comparar y contrastar diferentes tipos de Modelos de Lenguaje Largo (LLM) para comprender sus ventajas y desventajas.

El siguiente paso en la trayectoria de nuestra startup es explorar el panorama actual de los LLM y comprender cu谩les son adecuados para nuestro caso de uso.

## Introducci贸n

Esta lecci贸n cubrir谩:

- Diferentes tipos de LLM en el panorama actual.
- Pruebas, iteraciones y comparaci贸n de diferentes modelos para su caso de uso en Azure.
- C贸mo implementar un LLM.

## Objetivos de aprendizaje

Despu茅s de completar esta lecci贸n, podr谩:

- Seleccionar el modelo adecuado para su caso de uso.
- Comprender c贸mo probar, iterar y mejorar el rendimiento de su modelo.
- Conocer c贸mo las empresas implementan los modelos.

## Comprender los diferentes tipos de LLM

Los LLM pueden tener m煤ltiples categorizaciones seg煤n su arquitectura, datos de entrenamiento y caso de uso. Comprender estas diferencias ayudar谩 a nuestra startup a seleccionar el modelo adecuado para cada escenario y a comprender c贸mo probar, iterar y mejorar el rendimiento.

Existen muchos tipos diferentes de modelos LLM; la elecci贸n del modelo depende de su uso previsto, sus datos, su presupuesto y otros factores.

Dependiendo de si desea utilizar los modelos para texto, audio, v铆deo, generaci贸n de im谩genes, etc., podr铆a optar por un tipo de modelo diferente.

- **Reconocimiento de audio y voz**. Para este prop贸sito, los modelos de tipo Whisper son una excelente opci贸n, ya que son de prop贸sito general y est谩n orientados al reconocimiento de voz. Est谩 entrenado con audio diverso y puede realizar reconocimiento de voz multiling眉e. Obtenga m谩s informaci贸n sobre [modelos de typo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generaci贸n de im谩genes**. Para la generaci贸n de im谩genes, DALL-E y Midjourney son dos opciones muy conocidas. Azure OpenAI ofrece DALL-E. [M谩s informaci贸n sobre DALL-E aqu铆](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) y tambi茅n en el Cap铆tulo 9 de este programa.

- **Generaci贸n de texto**. La mayor铆a de los modelos se entrenan en generaci贸n de texto y existen diversas opciones, desde GPT-3.5 hasta GPT-4. Tienen diferentes precios, siendo GPT-4 el m谩s caro. Vale la pena consultar la [zona de juegos de Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para evaluar qu茅 modelos se adaptan mejor a sus necesidades en t茅rminos de capacidad y costo.

- **Multimodalidad**. Si busca gestionar m煤ltiples tipos de datos de entrada y salida, le recomendamos considerar modelos como [gpt-4 turbo con visi贸n o gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst), las 煤ltimas versiones de los modelos de OpenAI, que combinan el procesamiento del lenguaje natural con la comprensi贸n visual, lo que permite interacciones a trav茅s de interfaces multimodales.

Seleccionar un modelo implica obtener algunas capacidades b谩sicas, pero esto podr铆a no ser suficiente. A menudo, se tienen datos espec铆ficos de la empresa que, de alguna manera, es necesario comunicar al LLM. Existen diferentes opciones para abordar este tema; m谩s informaci贸n al respecto en las pr贸ximas secciones.

### Modelos Fundamentales versus LLMs

El t茅rmino Modelo Fundamental fue [acu帽ado por investigadores de Stanford] (https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) y definido como un modelo de IA que sigue ciertos criterios, como:

- **Se entrenan mediante aprendizaje no supervisado o autosupervisado**, lo que significa que se entrenan con datos multimodales sin etiquetar y no requieren anotaci贸n ni etiquetado humano de los datos para su proceso de entrenamiento.
- **Son modelos muy grandes**, basados en redes neuronales muy profundas entrenadas con miles de millones de par谩metros.
- **Normalmente est谩n pensados para servir de base para otros modelos**, lo que significa que pueden utilizarse como punto de partida para la construcci贸n de otros modelos, lo cual puede lograrse mediante ajustes finos.

![Modelos Fundamentales versus LLMs](../../images/FoundationModel.png?WT.mc_id=academic-105485-koreyst)

Fuente de la imagen: [Gu铆a Esencial de Modelos Fundamentales y Modelos de Lenguaje Grandes | por Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para aclarar mejor esta distinci贸n, tomemos ChatGPT como ejemplo. Para crear la primera versi贸n de ChatGPT, se utiliz贸 un modelo llamado GPT-3.5 como modelo fundamental. Esto significa que OpenAI utiliz贸 datos espec铆ficos del chat para crear una versi贸n optimizada de GPT-3.5, especializada en un buen rendimiento en escenarios conversacionales, como los chatbots.

![Modelo Fundamental](../../images/Multimodal.png?WT.mc_id=academic-105485-koreyst)

Fuente de la imagen: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos de c贸digo abierto versus modelos propietarios

Otra forma de clasificar los LLM es si son de c贸digo abierto o propietarios.

Los modelos de c贸digo abierto son modelos disponibles para el p煤blico general y pueden ser utilizados por cualquier persona. Suelen ser puestos a disposici贸n por la empresa que los cre贸 o por la comunidad investigadora. Estos modelos pueden ser inspeccionados, modificados y personalizados para los diversos casos de uso de los LLM. Sin embargo, no siempre est谩n optimizados para su uso en producci贸n y pueden no ser tan eficientes como los modelos propietarios. Adem谩s, la financiaci贸n para los modelos de c贸digo abierto puede ser limitada y es posible que no se mantengan a largo plazo o que no se actualicen con las 煤ltimas investigaciones. Algunos ejemplos de modelos de c贸digo abierto populares son [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) y [LLaMA](https://llama.meta.com).

Los modelos propietarios son modelos propiedad de una empresa y no est谩n disponibles p煤blicamente. Estos modelos suelen estar optimizados para su uso en producci贸n. Sin embargo, no se permite su inspecci贸n, modificaci贸n ni personalizaci贸n para diferentes casos de uso. Adem谩s, no siempre son gratuitos y pueden requerir una suscripci贸n o pago para su uso. Asimismo, los usuarios no tienen control sobre los datos utilizados para entrenar el modelo, por lo que deben confiar al propietario del modelo la responsabilidad de garantizar el compromiso con la privacidad de los datos y el uso responsable de la IA. Algunos ejemplos de modelos propietarios populares incluyen [modelos OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) o [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Incrustaciones versus Generaci贸n de im谩genes versus Generaci贸n de texto y c贸digo

Los LLM tambi茅n se pueden clasificar por el resultado que generan.

Las incrustaciones son un conjunto de modelos que pueden convertir texto a una forma num茅rica, denominada incrustaci贸n, que es una representaci贸n num茅rica del texto de entrada. Las incrustaciones facilitan a las m谩quinas la comprensi贸n de las relaciones entre palabras u oraciones y pueden ser utilizadas como entrada por otros modelos, como modelos de clasificaci贸n o modelos de agrupamiento, que ofrecen un mejor rendimiento con datos num茅ricos. Los modelos de incrustaci贸n se utilizan a menudo para el aprendizaje por transferencia, donde se construye un modelo para una tarea sustituta para la que existe una gran cantidad de datos, y luego las ponderaciones del modelo (incrustaciones) se reutilizan para otras tareas posteriores. Un ejemplo de esta categor铆a son las incrustaciones de OpenAI (https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Incrustaci贸n](../../images/Embedding.png?WT.mc_id=academic-105485-koreyst)

Los modelos de generaci贸n de im谩genes son modelos que generan im谩genes. Estos modelos se utilizan a menudo para la edici贸n, s铆ntesis y traducci贸n de im谩genes. Suelen entrenarse con grandes conjuntos de datos, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), y pueden utilizarse para generar nuevas im谩genes o editar im谩genes existentes con t茅cnicas de relleno de imagen, superresoluci贸n y colorizaci贸n. Algunos ejemplos son [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) y [modelos de difusi贸n estable](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generaci贸n de im谩genes](../../images/Image.png?WT.mc_id=academic-105485-koreyst)

Los modelos de generaci贸n de texto y c贸digo generan texto o c贸digo. Estos modelos se utilizan a menudo para resumir textos, traducirlos y responder preguntas. Los modelos de generaci贸n de texto suelen entrenarse con grandes conjuntos de datos de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), y pueden utilizarse para generar texto nuevo o responder preguntas. Los modelos de generaci贸n de c贸digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), suelen entrenarse con grandes conjuntos de datos de c贸digo, como GitHub, y pueden usarse para generar c贸digo nuevo o corregir errores en el c贸digo existente.

![Generaci贸n de texto y c贸digo](../../images/Text.png?WT.mc_id=academic-105485-koreyst)

### Codificador-Decodificador versus Solo Decodificador

Para hablar sobre los diferentes tipos de arquitecturas de los LLM, usemos una analog铆a.

Imagina que tu gerente te asigna la tarea de escribir un cuestionario para los estudiantes. Tienes dos colegas: uno supervisa la creaci贸n del contenido y el otro la revisi贸n.

El creador de contenido es como un modelo solo decodificador: puede analizar el tema y ver lo que ya escribiste, y luego puede crear un curso basado en eso. Son muy buenos escribiendo contenido atractivo e informativo, pero no comprenden bien el tema ni los objetivos de aprendizaje. Algunos ejemplos de modelos decodificadores son los modelos de la familia GPT, como GPT-3.

El revisor es como un modelo solo de codificador: revisa el curso escrito y las respuestas, observa la relaci贸n entre ellos y comprende el contexto, pero no es bueno generando contenido. Un ejemplo de modelo solo de codificador ser铆a BERT.

Imaginemos que tambi茅n podemos contar con alguien que cree y revise el cuestionario. Este es un modelo de codificador-decodificador. Algunos ejemplos ser铆an BART y T5.

### Servicio versus Modelo

Ahora, hablemos de la diferencia entre un servicio y un modelo. Un servicio es un producto ofrecido por un proveedor de servicios en la nube y suele ser una combinaci贸n de modelos, datos y otros componentes. Un modelo es el componente central de un servicio y suele ser un modelo base, como un LLM.

Los servicios suelen estar optimizados para producci贸n y son m谩s f谩ciles de usar que los modelos, gracias a una interfaz gr谩fica de usuario. Sin embargo, los servicios no siempre son gratuitos y pueden requerir una suscripci贸n o pago para su uso, a cambio de aprovechar los equipos y recursos del propietario del servicio, optimizar los gastos y escalar f谩cilmente. Un ejemplo de servicio es [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que ofrece un plan de pago por uso, lo que significa que los usuarios pagan proporcionalmente al uso del servicio. Adem谩s, Azure OpenAI Service ofrece seguridad de nivel empresarial y un marco de IA responsable, adem谩s de las capacidades de los modelos.

Los modelos son simplemente la red neuronal, con sus par谩metros, ponderaciones y dem谩s. Sin embargo, para que las empresas puedan operar localmente, se necesitar铆a comprar equipos, construir una estructura para escalar y adquirir una licencia o usar un modelo de c贸digo abierto. Un modelo como LLaMA est谩 disponible, pero requiere potencia computacional para ejecutarlo.

## C贸mo probar e iterar con diferentes modelos para comprender el rendimiento en Azure

Una vez que nuestro equipo haya explorado el panorama actual de los LLM e identificado algunos candidatos id贸neos para sus escenarios, el siguiente paso es probarlos con sus datos y su carga de trabajo. Este es un proceso iterativo, realizado mediante experimentos y mediciones.
La mayor铆a de los modelos mencionados en p谩rrafos anteriores (modelos de OpenAI, modelos de c贸digo abierto como Llama2 y transformadores Hugging Face) est谩n disponibles en el [Cat谩logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) de [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) es una plataforma en la nube dise帽ada para que los desarrolladores creen aplicaciones de IA generativa y gestionen todo el ciclo de vida del desarrollo, desde la experimentaci贸n hasta la evaluaci贸n, combinando todos los servicios de IA de Azure en un 煤nico centro con una pr谩ctica interfaz gr谩fica de usuario. El Cat谩logo de Modelos de Azure AI Studio permite al usuario:

- Encontrar el Modelo Fundacional de inter茅s en el cat谩logo, ya sea propietario o de c贸digo abierto, filtrando por tarea, licencia o nombre. Para facilitar la b煤squeda, los modelos se organizan en colecciones, como la colecci贸n Azure OpenAI, la colecci贸n Hugging Face y muchas m谩s.

![Cat谩logo de modelos](../../images/AzureAIStudioModelCatalog.png?WT.mc_id=academic-105485-koreyst)

- Revise la tarjeta del modelo, que incluye una descripci贸n detallada del uso previsto, los datos de entrenamiento, ejemplos de c贸digo y los resultados de la evaluaci贸n en la biblioteca de evaluaciones internas.

隆[Tarjeta del modelo](../../images/ModelCard.png?WT.mc_id=academic-105485-koreyst)

Compare los puntos de referencia de los modelos y conjuntos de datos disponibles en el sector para evaluar cu谩l se adapta mejor al escenario empresarial mediante el panel [Puntos de referencia del modelo](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Puntos de referencia del modelo](../../images/ModelBenchmarks.png?WT.mc_id=academic-105485-koreyst)

- Ajuste el modelo con datos de entrenamiento personalizados para mejorar su rendimiento en una carga de trabajo espec铆fica, aprovechando las capacidades de experimentaci贸n y seguimiento de Azure AI Studio.

Ajuste del modelo

Implemente el modelo original preentrenado o la versi贸n optimizada en un punto de conexi贸n remoto de inferencia en tiempo real (computaci贸n administrada) o API sin servidor (pago por uso) para que las aplicaciones puedan utilizarlo.

![Implementaci贸n del modelo](../../images/ModelDeploy.png?WT.mc_id=academic-105485-koreyst)

> [!NOTA]
> No todos los modelos del cat谩logo est谩n disponibles actualmente para ajustes o implementaci贸n con pago por uso. Consulte la ficha del modelo para obtener m谩s informaci贸n sobre sus capacidades y limitaciones.

## Mejorando los resultados del LLM

Con nuestro equipo de startups, hemos explorado diferentes tipos de LLM y una plataforma en la nube (Azure Machine Learning) que nos permite comparar diferentes modelos, evaluarlos con datos de prueba, mejorar el rendimiento e implementarlos en puntos finales de inferencia.

Pero cu谩ndo deber铆an considerar ajustar un modelo en lugar de usar uno preentrenado? Existen otros enfoques para mejorar el rendimiento del modelo en cargas de trabajo espec铆ficas?

Existen varios enfoques que una empresa puede utilizar para obtener los resultados que necesita de un LLM. Se pueden seleccionar diferentes tipos de modelos con distintos grados de entrenamiento al implementar un LLM en producci贸n, con distintos niveles de complejidad, coste y calidad. A continuaci贸n, se presentan algunos enfoques:

- **Ingenier铆a de indicaciones con contexto**. La idea es proporcionar suficiente contexto al solicitar para garantizar que se obtengan las respuestas necesarias.

- **Generaci贸n Aumentada de Recuperaci贸n (RAG)**. Sus datos podr铆an estar en una base de datos o un punto final web, por ejemplo. Para garantizar que estos datos, o un subconjunto de ellos, se incluyan al momento de la solicitud, puede obtener los datos relevantes e integrarlos en la solicitud del usuario.

- **Modelo optimizado**. En este caso, entren贸 el modelo con sus propios datos, lo que lo hizo m谩s preciso y adaptable a sus necesidades, aunque podr铆a resultar costoso.

隆Implementaci贸n de LLM!

Fuente de la imagen: [Cuatro maneras en que las empresas implementan LLM | Blog de Fiddler AI](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ingenier铆a de Propuestas con Contexto

Los LLM preentrenados funcionan muy bien en tareas de lenguaje natural generalizadas, incluso al solicitarles una proposici贸n breve, como una oraci贸n para completar o una pregunta: el llamado aprendizaje "de disparo cero".

Sin embargo, cuanto m谩s pueda el usuario estructurar su consulta con una solicitud detallada y ejemplos (el contexto), m谩s precisa y cercana a sus expectativas ser谩 la respuesta. En este caso, hablamos de aprendizaje "de disparo 煤nico" si la proposici贸n incluye solo un ejemplo y de "aprendizaje de disparos m煤ltiples" si incluye varios. La ingenier铆a de propuestas con contexto es el enfoque m谩s rentable para comenzar.

### Generaci贸n Aumentada de Recuperaci贸n (RAG)

Los LLM tienen la limitaci贸n de que solo pueden usar los datos utilizados durante su entrenamiento para generar una respuesta. Esto significa que desconocen los hechos ocurridos despu茅s del proceso de entrenamiento y no pueden acceder a informaci贸n no p煤blica (como datos de la empresa).
Esto se puede solucionar mediante RAG, una t茅cnica que complementa la solicitud con datos externos en forma de fragmentos de documentos, teniendo en cuenta los l铆mites de longitud de la solicitud. Esto es posible gracias a herramientas de bases de datos vectoriales (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), que recuperan los fragmentos 煤tiles de diversas fuentes de datos predefinidas y los a帽aden al contexto de la solicitud.

Esta t茅cnica es muy 煤til cuando una empresa no dispone de suficientes datos, tiempo ni recursos para perfeccionar un LLM, pero aun as铆 desea mejorar el rendimiento en una carga de trabajo espec铆fica y reducir el riesgo de falsificaciones, es decir, la tergiversaci贸n de la realidad o el contenido da帽ino.

### Modelo perfeccionado

El ajuste fino es un proceso que aprovecha el aprendizaje por transferencia para adaptar el modelo a una tarea posterior o para resolver un problema espec铆fico. A diferencia del aprendizaje de pocos disparos y el RAG, genera un nuevo modelo con ponderaciones y sesgos actualizados. Requiere un conjunto de ejemplos de entrenamiento que consta de una 煤nica entrada (la indicaci贸n) y su salida asociada (la finalizaci贸n).
Este ser铆a el enfoque preferido si:

- **Uso de modelos ajustados**. Una empresa prefiere utilizar modelos ajustados con menor capacidad (como modelos de incrustaci贸n) en lugar de modelos de alto rendimiento, lo que resulta en una soluci贸n m谩s rentable y r谩pida.

- **Consideraci贸n de la latencia**. La latencia es importante para un caso de uso espec铆fico, por lo que no es posible utilizar indicaciones muy largas o si el n煤mero de ejemplos que se deben aprender del modelo no se ajusta al l铆mite de longitud de la indicaci贸n.

- **Mantenerse actualizado**. Una empresa cuenta con una gran cantidad de datos de alta calidad y etiquetas de datos reales, as铆 como con los recursos necesarios para mantener estos datos actualizados a lo largo del tiempo.

### Modelo entrenado

Formar un LLM desde cero es, sin duda, el enfoque m谩s dif铆cil y complejo de adoptar, ya que requiere cantidades masivas de datos, recursos especializados y la capacidad computacional adecuada. Esta opci贸n solo debe considerarse en un escenario donde una empresa tenga un caso de uso espec铆fico del dominio y una gran cantidad de datos centrados en el mismo.

## Comprobaci贸n de conocimientos

Cu谩l podr铆a ser un buen enfoque para mejorar los resultados de la finalizaci贸n del LLM?

1. Ingenier铆a r谩pida con contexto
1. RAG
1. Modelo optimizado

R:3, Si dispone del tiempo, los recursos y datos de alta calidad, optimizar es la mejor opci贸n para mantenerse al d铆a. Sin embargo, si busca mejorar y no dispone de tiempo, vale la pena considerar primero RAG.

##  Desaf铆o

Lea m谩s sobre c贸mo puede [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para su negocio.

## 隆Buen trabajo! 隆Contin煤a aprendiendo!

Despu茅s de completar esta lecci贸n, consulta nuestra [colecci贸n de aprendizaje de IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tus conocimientos sobre IA generativa.

Dir铆gete a la Lecci贸n 3, donde veremos c贸mo [construir con IA generativa de forma responsable](../../../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst).