{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) and Vector Databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (1.86.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (0.26.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (0.10.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (2.11.5)\n",
      "Requirement already satisfied: sniffio in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from openai) (4.14.0)\n",
      "Requirement already satisfied: idna>=2.8 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
      "Requirement already satisfied: httpcore==1.* in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.4.1)\n",
      "Requirement already satisfied: colorama in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import openai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating our Knowledge base\n",
    "\n",
    "Creating a Azure Cosmos DB database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cosmos in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (4.9.0)\n",
      "Requirement already satisfied: azure-core>=1.30.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from azure-cosmos) (1.34.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from azure-cosmos) (4.14.0)\n",
      "Requirement already satisfied: requests>=2.21.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from azure-core>=1.30.0->azure-cosmos) (2.32.3)\n",
      "Requirement already satisfied: six>=1.11.0 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from azure-core>=1.30.0->azure-cosmos) (1.17.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-cosmos) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-cosmos) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-cosmos) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\generative-ai-for-beginners\\.conda\\lib\\site-packages (from requests>=2.21.0->azure-core>=1.30.0->azure-cosmos) (2025.4.26)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## create your cosmoss db on Azure CLI using the following commands\n",
    "## az login\n",
    "## az group create -n <resource-group-name> -l <location>\n",
    "## az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>\n",
    "## az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>\n",
    "\n",
    "## Once done navigate to data explorer and create a new database and a new container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cosmos import CosmosClient\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "# Initialize Cosmos Client\n",
    "url = os.environ['COSMOS_DB_ENDPOINT']\n",
    "key = os.environ['COSMOS_DB_KEY']\n",
    "client = CosmosClient(url, credential=key)\n",
    "\n",
    "# Select database\n",
    "database_name = 'rag-cosmos-db'\n",
    "database = client.get_database_client(database_name)\n",
    "\n",
    "# Select container\n",
    "container_name = 'data'\n",
    "container = database.get_container_client(container_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    path                                               text\n",
      "0     data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...\n",
      "1  data/own_framework.md  # Introduction to Neural Networks. Multi-Layer...\n",
      "2     data/perceptron.md  # Introduction to Neural Networks: Perceptron\\...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List to store data before creating DataFrame\n",
    "data = []\n",
    "\n",
    "# Your file paths\n",
    "data_paths = [\n",
    "    \"data/frameworks.md\",# ?WT.mc_id=academic-105485-koreyst\n",
    "    \"data/own_framework.md\",#?WT.mc_id=academic-105485-koreyst\n",
    "    \"data/perceptron.md\"#?WT.mc_id=academic-105485-koreyst\n",
    "]\n",
    "\n",
    "# Read each file and collect content\n",
    "for path in data_paths:\n",
    "    with open(path, 'r', encoding='utf-8') as file:\n",
    "        file_content = file.read()\n",
    "        data.append({'path': path, 'text': file_content})\n",
    "\n",
    "# Create DataFrame from the list\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Display first few rows\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>[# Neural Network Frameworks As we have learne...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>data/own_framework.md</td>\n",
       "      <td># Introduction to Neural Networks. Multi-Layer...</td>\n",
       "      <td>[# Introduction to Neural Networks. Multi-Laye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>data/perceptron.md</td>\n",
       "      <td># Introduction to Neural Networks: Perceptron\\...</td>\n",
       "      <td>[# Introduction to Neural Networks: Perceptron...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    path                                               text  \\\n",
       "0     data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "1  data/own_framework.md  # Introduction to Neural Networks. Multi-Layer...   \n",
       "2     data/perceptron.md  # Introduction to Neural Networks: Perceptron\\...   \n",
       "\n",
       "                                              chunks  \n",
       "0  [# Neural Network Frameworks As we have learne...  \n",
       "1  [# Introduction to Neural Networks. Multi-Laye...  \n",
       "2  [# Introduction to Neural Networks: Perceptron...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def split_text(text, max_length, min_length):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "\n",
    "    for word in words:\n",
    "        current_chunk.append(word)\n",
    "        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:\n",
    "            chunks.append(' '.join(current_chunk))\n",
    "            current_chunk = []\n",
    "\n",
    "    # If the last chunk didn't reach the minimum length, add it anyway\n",
    "    if current_chunk:\n",
    "        chunks.append(' '.join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Assuming analyzed_df is a pandas DataFrame and 'output_content' is a column in that DataFrame\n",
    "splitted_df = df.copy()\n",
    "splitted_df['chunks'] = splitted_df['text'].apply(lambda x: split_text(x, 400, 300))\n",
    "\n",
    "splitted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \n",
       "0  # Neural Network Frameworks As we have learned...  \n",
       "0  descent optimization While the `numpy` library...  \n",
       "0  should give us the opportunity to compute grad...  \n",
       "0  those computations on GPUs is very important. ...  \n",
       "0  API, there is also higher-level API, called Ke...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming 'chunks' is a column of lists in the DataFrame splitted_df, we will split the chunks into different rows\n",
    "flattened_df = splitted_df.explode('chunks')\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting our text to embeddings\n",
    "\n",
    "Converting out text  to embeddings, and storing them in our database in chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key = os.getenv(\"AZURE_OPENAI_API_KEY\"),  \n",
    "  api_version = os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "  azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.01710554026067257,\n",
       " 0.002864499343559146,\n",
       " 0.025373218581080437,\n",
       " -0.03888116404414177,\n",
       " 0.006913489196449518,\n",
       " 0.003886080114170909,\n",
       " -0.006200758274644613,\n",
       " -0.003273471025750041,\n",
       " -0.0029238935094326735,\n",
       " -0.02932378463447094,\n",
       " 0.03480841591954231,\n",
       " 0.02043161727488041,\n",
       " 0.0014475224306806922,\n",
       " 0.0029680149164050817,\n",
       " -0.01467546820640564,\n",
       " -0.010982843115925789,\n",
       " 0.022182898595929146,\n",
       " 0.009109378792345524,\n",
       " -0.02935093641281128,\n",
       " -0.020594527944922447,\n",
       " -0.035487208515405655,\n",
       " -0.0037978373002260923,\n",
       " 0.013039580546319485,\n",
       " -0.034428294748067856,\n",
       " -0.030491305515170097,\n",
       " -0.001521341037005186,\n",
       " 0.015435714274644852,\n",
       " -0.0435512475669384,\n",
       " -0.0076092504896223545,\n",
       " -0.014268193393945694,\n",
       " 0.019752826541662216,\n",
       " 0.012564427219331264,\n",
       " -0.012625518254935741,\n",
       " -0.01565292663872242,\n",
       " -0.0047888727858662605,\n",
       " 0.011138965375721455,\n",
       " 0.0013134611072018743,\n",
       " 0.008247314020991325,\n",
       " -0.0002793650492094457,\n",
       " -0.0018072818638756871,\n",
       " 0.040374506264925,\n",
       " 0.011315451003611088,\n",
       " -0.00984247401356697,\n",
       " -0.007656765636056662,\n",
       " -0.005026449449360371,\n",
       " 0.01065023522824049,\n",
       " -0.025291763246059418,\n",
       " -0.03331507742404938,\n",
       " -0.00633991090580821,\n",
       " 0.003960747271776199,\n",
       " 0.013005641289055347,\n",
       " 0.02393418177962303,\n",
       " -0.044121433049440384,\n",
       " -0.03290780261158943,\n",
       " -0.02119186334311962,\n",
       " 0.012163939885795116,\n",
       " -0.026269223541021347,\n",
       " 0.012808791361749172,\n",
       " 0.02459939569234848,\n",
       " -0.02591625228524208,\n",
       " 0.002404618076980114,\n",
       " 0.01992931216955185,\n",
       " -0.02132762223482132,\n",
       " 0.00299856043420732,\n",
       " -0.007371673360466957,\n",
       " -0.019671371206641197,\n",
       " -0.0014627951895818114,\n",
       " 0.025821220129728317,\n",
       " 0.0034889872185885906,\n",
       " -0.016508204862475395,\n",
       " 0.0036417152732610703,\n",
       " 0.013243217952549458,\n",
       " -0.02560400776565075,\n",
       " 0.0001604705030331388,\n",
       " 0.015286379493772984,\n",
       " 0.004249233286827803,\n",
       " -0.013623340986669064,\n",
       " 0.0017580694984644651,\n",
       " -0.016345294192433357,\n",
       " 0.0025980735663324594,\n",
       " 0.002906923647969961,\n",
       " -0.030518457293510437,\n",
       " -0.013650492765009403,\n",
       " 0.0013737038243561983,\n",
       " 0.0003663351817522198,\n",
       " -0.004269597120583057,\n",
       " 0.012218243442475796,\n",
       " 0.010005383752286434,\n",
       " 0.008545982651412487,\n",
       " -0.005124874413013458,\n",
       " 0.044094283133745193,\n",
       " -0.0015807352028787136,\n",
       " 0.02515600621700287,\n",
       " 0.008756407536566257,\n",
       " 0.007113732863217592,\n",
       " 0.010752053931355476,\n",
       " -0.012713761068880558,\n",
       " 0.006258455570787191,\n",
       " -0.004381597973406315,\n",
       " -0.010012171231210232,\n",
       " -0.012503335252404213,\n",
       " 0.018110152333974838,\n",
       " -0.014851953834295273,\n",
       " -0.018748216331005096,\n",
       " -0.02222362719476223,\n",
       " 0.0005981848225928843,\n",
       " 0.003991292789578438,\n",
       " 0.0006919428706169128,\n",
       " 0.01041265856474638,\n",
       " -0.0010623083217069507,\n",
       " 0.019114762544631958,\n",
       " 0.02261732518672943,\n",
       " -0.009937504306435585,\n",
       " -0.024504365399479866,\n",
       " -0.012489759363234043,\n",
       " -0.009944292716681957,\n",
       " 0.041270509362220764,\n",
       " -0.008491679094731808,\n",
       " -0.007962222211062908,\n",
       " -0.016223112121224403,\n",
       " 0.012428668327629566,\n",
       " 0.02420569770038128,\n",
       " 0.03706200420856476,\n",
       " -0.006438335403800011,\n",
       " 0.01758069358766079,\n",
       " -0.0013244914589449763,\n",
       " 0.027138076722621918,\n",
       " 0.0015951595269143581,\n",
       " -0.018110152333974838,\n",
       " -0.02496594376862049,\n",
       " -0.01186527218669653,\n",
       " 0.00874962005764246,\n",
       " 0.0029103176202625036,\n",
       " 0.02132762223482132,\n",
       " -0.015462866052985191,\n",
       " 0.0041372328996658325,\n",
       " 0.015340683050453663,\n",
       " 0.010507688857614994,\n",
       " -0.03108864091336727,\n",
       " 0.0053556631319224834,\n",
       " 0.011498724110424519,\n",
       " 0.007412401027977467,\n",
       " -0.027178803458809853,\n",
       " -0.013202490285038948,\n",
       " -0.014974135905504227,\n",
       " 0.03700770065188408,\n",
       " 0.030491305515170097,\n",
       " 0.027246681973338127,\n",
       " 0.013799826614558697,\n",
       " -0.009917140938341618,\n",
       " -0.008450951427221298,\n",
       " -0.010840296745300293,\n",
       " -0.013833766803145409,\n",
       " -0.0201872531324625,\n",
       " 0.006740397773683071,\n",
       " 0.0003024863835889846,\n",
       " -0.004296748898923397,\n",
       " 0.03385810926556587,\n",
       " -0.011661634780466557,\n",
       " 0.014919832348823547,\n",
       " 0.01749924011528492,\n",
       " 0.012856307439506054,\n",
       " -0.017119117081165314,\n",
       " -0.002645589178428054,\n",
       " 0.01599232293665409,\n",
       " 0.01231327373534441,\n",
       " 0.04550616815686226,\n",
       " -0.0017937059747055173,\n",
       " 0.024382183328270912,\n",
       " -0.0015332198236137629,\n",
       " 0.013888069428503513,\n",
       " -0.001742796623148024,\n",
       " -0.0055491188541054726,\n",
       " 0.013786250725388527,\n",
       " 0.0207167100161314,\n",
       " 0.007432764861732721,\n",
       " 0.027463896200060844,\n",
       " 0.005654331296682358,\n",
       " -0.034455444663763046,\n",
       " -0.014716194942593575,\n",
       " 0.01800154522061348,\n",
       " 0.01853100210428238,\n",
       " 0.03038269840180874,\n",
       " 0.011661634780466557,\n",
       " -0.0006966095534153283,\n",
       " -0.012985276989638805,\n",
       " 0.023852726444602013,\n",
       " -0.009808533824980259,\n",
       " 0.004595417063683271,\n",
       " -0.032772041857242584,\n",
       " -0.01126793585717678,\n",
       " 0.005016267765313387,\n",
       " -0.00273552886210382,\n",
       " 0.006058212369680405,\n",
       " -0.6260085105895996,\n",
       " -0.0018581912154331803,\n",
       " 0.03703485429286957,\n",
       " -0.03399386629462242,\n",
       " -0.005942817777395248,\n",
       " -0.01348758302628994,\n",
       " -0.013229642063379288,\n",
       " 0.005749362055212259,\n",
       " -0.008905741386115551,\n",
       " 0.03513423725962639,\n",
       " -0.00267274072393775,\n",
       " 0.01234042551368475,\n",
       " 0.0006660639774054289,\n",
       " -0.016956206411123276,\n",
       " 0.009917140938341618,\n",
       " -0.022658053785562515,\n",
       " 0.009272289462387562,\n",
       " -0.03399386629462242,\n",
       " -0.015598624013364315,\n",
       " 0.000878186256159097,\n",
       " -0.008654588833451271,\n",
       " 0.0236219372600317,\n",
       " -0.021015377715229988,\n",
       " 0.020648831501603127,\n",
       " 0.002404618076980114,\n",
       " 0.01343327946960926,\n",
       " -0.003034197026863694,\n",
       " 0.003858928568661213,\n",
       " 0.02373054437339306,\n",
       " 0.02935093641281128,\n",
       " -0.01428176835179329,\n",
       " 0.005776513833552599,\n",
       " 0.014376799575984478,\n",
       " 5.0140402890974656e-05,\n",
       " 0.04056456685066223,\n",
       " -0.008851438760757446,\n",
       " -0.01906045898795128,\n",
       " 0.0377407968044281,\n",
       " 0.009604896418750286,\n",
       " 0.03502563014626503,\n",
       " -0.03011118248105049,\n",
       " -0.013942372985184193,\n",
       " 0.025454673916101456,\n",
       " 0.011362966150045395,\n",
       " -0.009788170456886292,\n",
       " 0.030029727146029472,\n",
       " 0.011885635554790497,\n",
       " 0.004877115599811077,\n",
       " 0.004710811655968428,\n",
       " -0.012998852878808975,\n",
       " 0.00904150027781725,\n",
       " 0.0002401224191999063,\n",
       " 0.012598366476595402,\n",
       " 0.023445451632142067,\n",
       " 0.004432507324963808,\n",
       " -0.0023316480219364166,\n",
       " 0.006852398160845041,\n",
       " -0.022454416379332542,\n",
       " 0.006825246382504702,\n",
       " 0.005976757500320673,\n",
       " 0.010690962895751,\n",
       " -0.008688528090715408,\n",
       " -0.04938885569572449,\n",
       " -0.01341970358043909,\n",
       " -0.01887039840221405,\n",
       " 0.007025490049272776,\n",
       " -0.021965686231851578,\n",
       " 0.02926948107779026,\n",
       " -0.02278023585677147,\n",
       " -0.010948903858661652,\n",
       " 0.019589915871620178,\n",
       " 0.024857336655259132,\n",
       " 0.019549189135432243,\n",
       " 0.006475668866187334,\n",
       " 0.0072834305465221405,\n",
       " 0.022047141566872597,\n",
       " 0.01652177982032299,\n",
       " -0.0031835311092436314,\n",
       " 0.0022603750694543123,\n",
       " 0.011145752854645252,\n",
       " 0.002581103937700391,\n",
       " 0.003936989698559046,\n",
       " -0.018856821581721306,\n",
       " -0.014200313948094845,\n",
       " 0.005969969555735588,\n",
       " 0.00848489161580801,\n",
       " -0.01644032448530197,\n",
       " -0.007962222211062908,\n",
       " 0.007636402267962694,\n",
       " -3.078424560953863e-05,\n",
       " 0.007480280008167028,\n",
       " 0.022712357342243195,\n",
       " -0.017268450930714607,\n",
       " -0.06977974623441696,\n",
       " -0.0003994262660853565,\n",
       " 0.010738478042185307,\n",
       " 0.007717857137322426,\n",
       " 0.013256793841719627,\n",
       " 0.017906514927744865,\n",
       " -0.012937761843204498,\n",
       " -0.008824286982417107,\n",
       " -0.006044636480510235,\n",
       " 0.021381925791502,\n",
       " -0.004093111492693424,\n",
       " -0.01063665933907032,\n",
       " 0.016820447519421577,\n",
       " -0.014403951354324818,\n",
       " 0.04713526740670204,\n",
       " 0.0322018601000309,\n",
       " -0.025685463100671768,\n",
       " -0.031604520976543427,\n",
       " -0.027830442413687706,\n",
       " -0.01066381111741066,\n",
       " 0.02261732518672943,\n",
       " 0.00015633412112947553,\n",
       " -0.030980033800005913,\n",
       " -0.008172647096216679,\n",
       " 0.008206586353480816,\n",
       " -0.008240526542067528,\n",
       " -0.019182641059160233,\n",
       " 0.00902792438864708,\n",
       " 0.013494370505213737,\n",
       " -0.006787912920117378,\n",
       " -0.0006066696951165795,\n",
       " 0.018150879070162773,\n",
       " 0.006227910052984953,\n",
       " -0.030925732105970383,\n",
       " -0.018191605806350708,\n",
       " -0.02702946960926056,\n",
       " -0.012252182699739933,\n",
       " -0.003811413189396262,\n",
       " -0.022739509120583534,\n",
       " 0.0007080641807988286,\n",
       " -0.018069423735141754,\n",
       " 0.026201343163847923,\n",
       " 0.010589144192636013,\n",
       " 0.017485663294792175,\n",
       " -0.021476956084370613,\n",
       " 0.0011301875347271562,\n",
       " -0.03372235223650932,\n",
       " -0.0016095838509500027,\n",
       " -0.02116471342742443,\n",
       " 0.024558668956160545,\n",
       " -0.021517684683203697,\n",
       " -0.014933408237993717,\n",
       " 0.005589846521615982,\n",
       " -0.018042271956801414,\n",
       " -0.005613604094833136,\n",
       " 0.008803922683000565,\n",
       " 0.003953959327191114,\n",
       " 0.001269339700229466,\n",
       " 0.010324415750801563,\n",
       " 1.7533232039568247e-06,\n",
       " 0.003865716513246298,\n",
       " 0.016481053084135056,\n",
       " -0.01984785683453083,\n",
       " -0.017675725743174553,\n",
       " -0.03440114110708237,\n",
       " -0.004530931822955608,\n",
       " -0.033505138009786606,\n",
       " -0.027518199756741524,\n",
       " 0.028617840260267258,\n",
       " -0.028943661600351334,\n",
       " 0.017987968400120735,\n",
       " -0.025590430945158005,\n",
       " -0.02823771722614765,\n",
       " -0.019589915871620178,\n",
       " 0.00461238669231534,\n",
       " 0.004785478580743074,\n",
       " -0.024192120879888535,\n",
       " -0.01323643047362566,\n",
       " -0.03909837827086449,\n",
       " -0.0010343082249164581,\n",
       " 0.014770498499274254,\n",
       " 0.01014793012291193,\n",
       " 0.006485851015895605,\n",
       " -0.011111813597381115,\n",
       " -0.016290990635752678,\n",
       " 0.016983358189463615,\n",
       " -0.0184766985476017,\n",
       " 0.007378461305052042,\n",
       " -0.015897292643785477,\n",
       " -0.025644734501838684,\n",
       " -0.009991807863116264,\n",
       " 0.03657327592372894,\n",
       " -0.006509608589112759,\n",
       " 0.009978231973946095,\n",
       " 0.0013355219271034002,\n",
       " -0.04640217125415802,\n",
       " -0.0134604312479496,\n",
       " -0.0056203920394182205,\n",
       " 0.02470800280570984,\n",
       " -0.028699295595288277,\n",
       " 0.010188656859099865,\n",
       " -0.012197879143059254,\n",
       " 0.00032072889734990895,\n",
       " -0.0026286193169653416,\n",
       " 0.019617067649960518,\n",
       " -0.021979261189699173,\n",
       " 0.006679306272417307,\n",
       " 0.0026981953997164965,\n",
       " -0.01519134920090437,\n",
       " 0.012503335252404213,\n",
       " -0.019861433655023575,\n",
       " 0.012774852104485035,\n",
       " 0.0026931045576930046,\n",
       " 0.019603492692112923,\n",
       " -0.026323527097702026,\n",
       " -0.016277415677905083,\n",
       " 0.00279831700026989,\n",
       " 0.006292395293712616,\n",
       " -0.016331719234585762,\n",
       " -0.009889989160001278,\n",
       " -0.013650492765009403,\n",
       " -0.017621422186493874,\n",
       " 0.03198464587330818,\n",
       " 0.020974650979042053,\n",
       " 0.007011914160102606,\n",
       " -0.00788076687604189,\n",
       " -0.006709851790219545,\n",
       " -0.012537275440990925,\n",
       " -0.004934812895953655,\n",
       " 0.02496594376862049,\n",
       " -0.004734569229185581,\n",
       " -0.002927287481725216,\n",
       " 0.021096833050251007,\n",
       " -0.015910867601633072,\n",
       " 0.009245137684047222,\n",
       " -0.011580179445445538,\n",
       " -0.048601455986499786,\n",
       " -0.0015900685684755445,\n",
       " 0.018232334405183792,\n",
       " -0.002185707911849022,\n",
       " 0.014336071908473969,\n",
       " 0.02845493145287037,\n",
       " 0.0028407415375113487,\n",
       " 0.003405835246667266,\n",
       " 0.0016791599337011576,\n",
       " 0.06424080580472946,\n",
       " -0.003584017977118492,\n",
       " -0.0003553048300091177,\n",
       " 0.009394471533596516,\n",
       " 0.010066474787890911,\n",
       " -0.013636916875839233,\n",
       " 0.018435971811413765,\n",
       " 0.013569038361310959,\n",
       " 0.047651149332523346,\n",
       " 0.014716194942593575,\n",
       " -0.018164455890655518,\n",
       " -0.012265758588910103,\n",
       " -0.009733866900205612,\n",
       " 0.0026574679650366306,\n",
       " -0.004096505232155323,\n",
       " 0.013453643769025803,\n",
       " 0.007242702879011631,\n",
       " -0.015218500979244709,\n",
       " 0.009061863645911217,\n",
       " 0.017716452479362488,\n",
       " 0.015910867601633072,\n",
       " 0.02515600621700287,\n",
       " 0.017458511516451836,\n",
       " 0.006305971182882786,\n",
       " 0.001954918960109353,\n",
       " -0.024368606507778168,\n",
       " -0.0035874119494110346,\n",
       " -0.006438335403800011,\n",
       " 0.013718372210860252,\n",
       " -0.014336071908473969,\n",
       " -0.016033049672842026,\n",
       " -0.0034720173571258783,\n",
       " -0.013345036655664444,\n",
       " -0.020282283425331116,\n",
       " 0.012747700326144695,\n",
       " -0.01802869699895382,\n",
       " -0.00026366798556409776,\n",
       " 0.014322496019303799,\n",
       " -0.003550078487023711,\n",
       " 0.007887555286288261,\n",
       " -0.004697235766798258,\n",
       " 0.015924444422125816,\n",
       " -0.01120684389024973,\n",
       " -0.009496290236711502,\n",
       " 0.013256793841719627,\n",
       " 0.018123727291822433,\n",
       " 0.004955176264047623,\n",
       " -0.014213889837265015,\n",
       " -0.008152283728122711,\n",
       " 0.004490204621106386,\n",
       " 0.004181354306638241,\n",
       " -0.00685579190030694,\n",
       " 0.006733609829097986,\n",
       " -0.006044636480510235,\n",
       " -0.011396905407309532,\n",
       " -0.008247314020991325,\n",
       " 0.0027474076487123966,\n",
       " -0.00039772927993908525,\n",
       " 0.029676755890250206,\n",
       " -0.01012077834457159,\n",
       " 0.008641012944281101,\n",
       " -0.027572501450777054,\n",
       " 0.0340481698513031,\n",
       " 0.010745266452431679,\n",
       " -0.011138965375721455,\n",
       " -0.015001287683844566,\n",
       " 0.03684478998184204,\n",
       " 0.011342602781951427,\n",
       " -0.023554058745503426,\n",
       " -0.010046111419796944,\n",
       " 0.022576598450541496,\n",
       " -0.027015892788767815,\n",
       " 0.008810711093246937,\n",
       " -0.007921494543552399,\n",
       " 0.012421880848705769,\n",
       " 0.00508075300604105,\n",
       " 0.018069423735141754,\n",
       " -0.011050722561776638,\n",
       " 0.009815322235226631,\n",
       " 0.005437118466943502,\n",
       " 0.008478103205561638,\n",
       " 0.014566861093044281,\n",
       " 0.011980666778981686,\n",
       " -0.013881281949579716,\n",
       " -0.01644032448530197,\n",
       " 0.01931839995086193,\n",
       " 0.0322018601000309,\n",
       " 0.025142429396510124,\n",
       " -0.020173676311969757,\n",
       " 0.016223112121224403,\n",
       " -0.0219113826751709,\n",
       " -0.011899211443960667,\n",
       " -0.017716452479362488,\n",
       " -0.02512885443866253,\n",
       " 0.01831378974020481,\n",
       " -0.009672775864601135,\n",
       " 0.009699927642941475,\n",
       " 0.009625260718166828,\n",
       " 0.01510989386588335,\n",
       " -0.0258619487285614,\n",
       " 0.017404207959771156,\n",
       " 0.029079418629407883,\n",
       " -0.0076703415252268314,\n",
       " -0.0016706751193851233,\n",
       " 0.004558083601295948,\n",
       " -0.0024487394839525223,\n",
       " 0.01937270350754261,\n",
       " 0.009469138458371162,\n",
       " 0.014308920130133629,\n",
       " -0.0020143131259828806,\n",
       " 0.004863539710640907,\n",
       " 0.014403951354324818,\n",
       " 0.00028297113021835685,\n",
       " 0.025251036509871483,\n",
       " -0.009163682349026203,\n",
       " -0.023486178368330002,\n",
       " -0.02742316760122776,\n",
       " 0.015842989087104797,\n",
       " 0.010086838155984879,\n",
       " 0.018653184175491333,\n",
       " -0.029540996998548508,\n",
       " 0.048655759543180466,\n",
       " 0.01889755018055439,\n",
       " 0.03706200420856476,\n",
       " 0.006248273886740208,\n",
       " -0.007256278768181801,\n",
       " 0.014200313948094845,\n",
       " 0.008715679869055748,\n",
       " -0.0017130995402112603,\n",
       " -0.002397830132395029,\n",
       " -0.01992931216955185,\n",
       " 0.00817943550646305,\n",
       " 0.008389860391616821,\n",
       " 0.009007560089230537,\n",
       " -0.002779650269076228,\n",
       " -0.0058104535564780235,\n",
       " 0.01343327946960926,\n",
       " -0.006346698384732008,\n",
       " -0.05465627461671829,\n",
       " -0.0033549258951097727,\n",
       " 0.0007678826223127544,\n",
       " 0.006944034714251757,\n",
       " 0.017825059592723846,\n",
       " -0.003590805921703577,\n",
       " 0.01513704564422369,\n",
       " -0.04428434371948242,\n",
       " -0.01926409639418125,\n",
       " 0.0010377021972090006,\n",
       " 0.017716452479362488,\n",
       " 0.004792266525328159,\n",
       " 0.028835054486989975,\n",
       " 0.0054303305223584175,\n",
       " -0.0023112844210118055,\n",
       " 0.012197879143059254,\n",
       " -0.013358612544834614,\n",
       " -0.003295531729236245,\n",
       " -0.030029727146029472,\n",
       " -0.0175535436719656,\n",
       " -0.037279218435287476,\n",
       " 0.00873604416847229,\n",
       " 0.032554831355810165,\n",
       " 0.027830442413687706,\n",
       " 0.011200056411325932,\n",
       " 0.0012973399134352803,\n",
       " -0.016806872561573982,\n",
       " 0.007154460065066814,\n",
       " -0.0005875786882825196,\n",
       " -0.031767431646585464,\n",
       " -0.01710554026067257,\n",
       " -0.029025115072727203,\n",
       " 0.009068652056157589,\n",
       " -0.017730029299855232,\n",
       " 0.003217470832169056,\n",
       " -0.02412424236536026,\n",
       " 0.00519275339320302,\n",
       " 0.006692882161587477,\n",
       " 0.01467546820640564,\n",
       " -0.026214919984340668,\n",
       " -0.0038148071616888046,\n",
       " 0.00505360122770071,\n",
       " 0.0163588710129261,\n",
       " 0.03975001722574234,\n",
       " 0.015001287683844566,\n",
       " -0.0001044171949615702,\n",
       " 0.02029586024582386,\n",
       " -0.01596517115831375,\n",
       " -0.004608992952853441,\n",
       " 0.00547105772420764,\n",
       " 1.1686612197081558e-05,\n",
       " -0.03410247340798378,\n",
       " 0.013745523989200592,\n",
       " -0.014756922610104084,\n",
       " 0.01646747626364231,\n",
       " 0.013731948100030422,\n",
       " 0.002538679400458932,\n",
       " -0.016087353229522705,\n",
       " 0.03708915784955025,\n",
       " 0.015014863573014736,\n",
       " 0.029785361140966415,\n",
       " 0.007935070432722569,\n",
       " 0.03779510036110878,\n",
       " 0.004340870305895805,\n",
       " 0.006350092589855194,\n",
       " 0.017146268859505653,\n",
       " -0.0009375804802402854,\n",
       " 0.007738220971077681,\n",
       " 0.010500901378691196,\n",
       " 0.0007275794050656259,\n",
       " 0.042763851583004,\n",
       " 0.0033566229976713657,\n",
       " 0.0056916652247309685,\n",
       " -0.0003423653542995453,\n",
       " -0.0016375839477404952,\n",
       " -0.029921120032668114,\n",
       " -0.014308920130133629,\n",
       " 0.019997190684080124,\n",
       " 0.010290475562214851,\n",
       " 0.04452870786190033,\n",
       " -0.011288299225270748,\n",
       " -0.022182898595929146,\n",
       " -0.027667533606290817,\n",
       " -0.0011904302518814802,\n",
       " -0.032744891941547394,\n",
       " 0.013955948874354362,\n",
       " -0.0010495809838175774,\n",
       " -0.022264353930950165,\n",
       " 0.023554058745503426,\n",
       " 0.007249490823596716,\n",
       " 0.012157152406871319,\n",
       " -0.022861691191792488,\n",
       " 0.009387683123350143,\n",
       " -0.037224914878606796,\n",
       " -0.0021144349593669176,\n",
       " -0.002480982104316354,\n",
       " 0.007914706133306026,\n",
       " 0.04184069484472275,\n",
       " -0.026214919984340668,\n",
       " 0.012808791361749172,\n",
       " -0.043062519282102585,\n",
       " -0.007174823898822069,\n",
       " -0.015639351680874825,\n",
       " -0.0042085060849785805,\n",
       " 0.000909580325242132,\n",
       " -0.021083258092403412,\n",
       " 0.026147041469812393,\n",
       " 0.05104510486125946,\n",
       " 0.03706200420856476,\n",
       " -0.002788135316222906,\n",
       " 0.003146197646856308,\n",
       " 0.02169417031109333,\n",
       " -0.003309107618406415,\n",
       " 0.002906923647969961,\n",
       " 0.019997190684080124,\n",
       " -0.0016613416373729706,\n",
       " 0.008552770130336285,\n",
       " -0.004391779657453299,\n",
       " 0.0010487325489521027,\n",
       " -0.017512815073132515,\n",
       " 0.01699693314731121,\n",
       " 0.00785361509770155,\n",
       " 0.026690073311328888,\n",
       " -0.0008790347492322326,\n",
       " -0.0007814584532752633,\n",
       " -0.009061863645911217,\n",
       " -0.005389602854847908,\n",
       " -0.03385810926556587,\n",
       " -0.0024572245310992002,\n",
       " 0.03996723145246506,\n",
       " -0.005647543352097273,\n",
       " 0.034564051777124405,\n",
       " -0.02261732518672943,\n",
       " 0.0049857222475111485,\n",
       " 0.010310839861631393,\n",
       " 0.021069681271910667,\n",
       " 0.009414834901690483,\n",
       " -0.002207768615335226,\n",
       " 0.0203230120241642,\n",
       " 0.01178381685167551,\n",
       " -0.007751796394586563,\n",
       " 0.028101960197091103,\n",
       " 0.004422325175255537,\n",
       " -0.02396133355796337,\n",
       " -0.02840062789618969,\n",
       " -0.03472696244716644,\n",
       " -0.026296375319361687,\n",
       " 0.01836809329688549,\n",
       " 0.006764155346900225,\n",
       " 0.011152541264891624,\n",
       " 0.02356763370335102,\n",
       " 0.017268450930714607,\n",
       " -0.022875266149640083,\n",
       " -0.004754933062940836,\n",
       " -0.023716967552900314,\n",
       " -0.014879105612635612,\n",
       " -0.014376799575984478,\n",
       " -0.020227979868650436,\n",
       " -0.030545609071850777,\n",
       " -0.03111579269170761,\n",
       " -0.010270112194120884,\n",
       " 0.0018921307055279613,\n",
       " 0.004225475713610649,\n",
       " 0.004147414583712816,\n",
       " -0.021042529493570328,\n",
       " 0.0055457246489822865,\n",
       " -0.02918802574276924,\n",
       " -0.009231561794877052,\n",
       " 0.01747208833694458,\n",
       " -0.015069167129695415,\n",
       " 0.040075838565826416,\n",
       " -0.01971209980547428,\n",
       " 0.02328254096210003,\n",
       " 0.014919832348823547,\n",
       " 0.005396390799432993,\n",
       " -0.010874236933887005,\n",
       " -0.008634225465357304,\n",
       " 0.008715679869055748,\n",
       " -0.0016630386235192418,\n",
       " 0.029676755890250206,\n",
       " 0.008240526542067528,\n",
       " -0.02333684451878071,\n",
       " -0.01686117611825466,\n",
       " 0.002572618890553713,\n",
       " -0.00016142505046445876,\n",
       " 0.012564427219331264,\n",
       " -0.020390890538692474,\n",
       " 0.026147041469812393,\n",
       " 0.005128268152475357,\n",
       " 0.0030630456749349833,\n",
       " 0.002248496050015092,\n",
       " -0.010534840635955334,\n",
       " -0.02074386179447174,\n",
       " 0.0380123108625412,\n",
       " -0.02227793075144291,\n",
       " -0.008016524836421013,\n",
       " -0.020662406459450722,\n",
       " -0.03478126600384712,\n",
       " -0.018598880618810654,\n",
       " 0.01119326800107956,\n",
       " -0.013467219658195972,\n",
       " 0.031631674617528915,\n",
       " 0.014363223686814308,\n",
       " 0.003903049975633621,\n",
       " -0.0015629169065505266,\n",
       " -0.0024080120492726564,\n",
       " -0.0034329870250076056,\n",
       " 0.004415537230670452,\n",
       " 0.00044121433165855706,\n",
       " 0.032772041857242584,\n",
       " -0.0019362521125003695,\n",
       " 0.021069681271910667,\n",
       " 0.022182898595929146,\n",
       " -0.00954380538314581,\n",
       " -0.013338249176740646,\n",
       " 0.0006821852293796837,\n",
       " 0.008220162242650986,\n",
       " 0.03725206479430199,\n",
       " -0.03372235223650932,\n",
       " -0.010894600301980972,\n",
       " 0.011166117154061794,\n",
       " -0.01038550678640604,\n",
       " 0.01267982181161642,\n",
       " -0.008396647870540619,\n",
       " -0.0030732275918126106,\n",
       " -0.01620953530073166,\n",
       " -0.013127823360264301,\n",
       " -0.008023313246667385,\n",
       " 0.024422910064458847,\n",
       " 0.011790604330599308,\n",
       " -0.01646747626364231,\n",
       " 0.006346698384732008,\n",
       " 0.00843058805912733,\n",
       " -0.009591320529580116,\n",
       " -0.013996676541864872,\n",
       " -0.012041757814586163,\n",
       " 0.004999297671020031,\n",
       " -0.024137819185853004,\n",
       " -0.029948271811008453,\n",
       " 0.018856821581721306,\n",
       " -0.0053658452816307545,\n",
       " 0.0017852210439741611,\n",
       " -0.006991550326347351,\n",
       " -0.017254874110221863,\n",
       " 0.008193010464310646,\n",
       " 0.03475411236286163,\n",
       " -0.01516419742256403,\n",
       " 0.017825059592723846,\n",
       " 0.014811226166784763,\n",
       " 0.008790346793830395,\n",
       " -0.016834024339914322,\n",
       " 0.02169417031109333,\n",
       " -0.020893195644021034,\n",
       " -0.02750462293624878,\n",
       " 0.011288299225270748,\n",
       " -0.03717061132192612,\n",
       " -0.01202139351516962,\n",
       " -0.007073005195707083,\n",
       " 0.0024894671514630318,\n",
       " -0.000603275781031698,\n",
       " 0.006295789033174515,\n",
       " -0.015327107161283493,\n",
       " -0.012754488736391068,\n",
       " 0.018015120178461075,\n",
       " 0.019196217879652977,\n",
       " -0.006614821031689644,\n",
       " 0.014960560016334057,\n",
       " 0.005498209502547979,\n",
       " 0.008450951427221298,\n",
       " -0.011817756108939648,\n",
       " 0.01876179128885269,\n",
       " -0.03521569073200226,\n",
       " -0.0005023055709898472,\n",
       " 0.0029934695921838284,\n",
       " -0.013969524763524532,\n",
       " 7.95988817117177e-05,\n",
       " -0.016711842268705368,\n",
       " 0.012252182699739933,\n",
       " -0.019970040768384933,\n",
       " 0.008240526542067528,\n",
       " -0.00520632928237319,\n",
       " 0.012374365702271461,\n",
       " 0.005735786631703377,\n",
       " 0.0043374765664339066,\n",
       " -0.002833953592926264,\n",
       " 0.009774594567716122,\n",
       " 0.00925192516297102,\n",
       " -0.0015697048511356115,\n",
       " -0.006482456810772419,\n",
       " 0.0016486142994835973,\n",
       " 0.01467546820640564,\n",
       " 0.005213117226958275,\n",
       " -0.030056878924369812,\n",
       " -0.028889358043670654,\n",
       " -0.005012873560190201,\n",
       " -0.01593801937997341,\n",
       " -0.032554831355810165,\n",
       " 0.0034889872185885906,\n",
       " -0.013202490285038948,\n",
       " 0.04805842414498329,\n",
       " 0.03032839484512806,\n",
       " 0.0007997009670361876,\n",
       " -0.004123657010495663,\n",
       " -0.011227208189666271,\n",
       " -0.029948271811008453,\n",
       " -0.008654588833451271,\n",
       " 0.0003720624663401395,\n",
       " 0.021205440163612366,\n",
       " -0.0010945509420707822,\n",
       " 0.030980033800005913,\n",
       " -0.004520750138908625,\n",
       " 0.015775110572576523,\n",
       " -0.008613861165940762,\n",
       " 0.017119117081165314,\n",
       " 0.009699927642941475,\n",
       " 0.00674379151314497,\n",
       " -0.017797907814383507,\n",
       " 0.0065062143839895725,\n",
       " -0.014702619053423405,\n",
       " -0.01510989386588335,\n",
       " -0.0201872531324625,\n",
       " -0.01519134920090437,\n",
       " 0.03372235223650932,\n",
       " -0.024137819185853004,\n",
       " -0.017186995595693588,\n",
       " 0.022902417927980423,\n",
       " 0.003152985591441393,\n",
       " -0.0071476721204817295,\n",
       " -0.0038894740864634514,\n",
       " 0.011179693043231964,\n",
       " 0.0027728623244911432,\n",
       " -0.004160990472882986,\n",
       " 0.020024342462420464,\n",
       " -0.01744493655860424,\n",
       " -0.015367834828794003,\n",
       " 0.001372006954625249,\n",
       " -0.011383330449461937,\n",
       " -0.009937504306435585,\n",
       " -0.00037694128695875406,\n",
       " 0.0023248600773513317,\n",
       " 0.0010673992801457644,\n",
       " 0.010297263972461224,\n",
       " -0.007100156974047422,\n",
       " 0.0010657022939994931,\n",
       " -0.0032191677019000053,\n",
       " -0.015435714274644852,\n",
       " 0.02130047045648098,\n",
       " 0.011512299999594688,\n",
       " 0.018490275368094444,\n",
       " 0.027803290635347366,\n",
       " 0.012428668327629566,\n",
       " 0.01513704564422369,\n",
       " -0.01657608337700367,\n",
       " -0.021069681271910667,\n",
       " -0.017648573964834213,\n",
       " 0.019114762544631958,\n",
       " 0.026785103604197502,\n",
       " -0.026201343163847923,\n",
       " -0.02317393384873867,\n",
       " 0.0027728623244911432,\n",
       " 0.022630902007222176,\n",
       " -0.031061489135026932,\n",
       " -0.03198464587330818,\n",
       " 0.006804882548749447,\n",
       " 0.009815322235226631,\n",
       " -0.01696978323161602,\n",
       " -0.007765372283756733,\n",
       " -0.008661377243697643,\n",
       " -0.022359386086463928,\n",
       " 0.011403693817555904,\n",
       " -0.011939939111471176,\n",
       " 0.013745523989200592,\n",
       " -0.015693655237555504,\n",
       " -0.02040446549654007,\n",
       " 0.027653956785798073,\n",
       " -0.00225698109716177,\n",
       " -0.009889989160001278,\n",
       " 0.0012608547694981098,\n",
       " 0.0036994125694036484,\n",
       " -0.017716452479362488,\n",
       " -0.014838377945125103,\n",
       " 0.031821735203266144,\n",
       " -0.02306532859802246,\n",
       " -0.006360274273902178,\n",
       " 0.1992931216955185,\n",
       " -0.023486178368330002,\n",
       " 0.008824286982417107,\n",
       " -0.006828640587627888,\n",
       " 0.010263324715197086,\n",
       " -0.007168035954236984,\n",
       " 0.01320927869528532,\n",
       " -0.0067302156239748,\n",
       " -0.00040960812475532293,\n",
       " 0.005101116374135017,\n",
       " -0.005274208262562752,\n",
       " 0.010032535530626774,\n",
       " -0.03584017977118492,\n",
       " -0.003414320293813944,\n",
       " 0.005671301390975714,\n",
       " -0.021531259641051292,\n",
       " -0.0366818830370903,\n",
       " -0.010419446043670177,\n",
       " 0.0003678200300782919,\n",
       " 0.011064298450946808,\n",
       " 0.027097348123788834,\n",
       " 0.010589144192636013,\n",
       " -0.004592023324221373,\n",
       " -0.03874540701508522,\n",
       " 0.02918802574276924,\n",
       " -0.001043641590513289,\n",
       " -0.010758842341601849,\n",
       " 0.01937270350754261,\n",
       " 0.02370339259505272,\n",
       " 0.003556866431608796,\n",
       " -0.01984785683453083,\n",
       " 0.011919574812054634,\n",
       " -0.007907918654382229,\n",
       " 0.009163682349026203,\n",
       " -0.031631674617528915,\n",
       " -0.004839782137423754,\n",
       " 0.04518034681677818,\n",
       " -0.007188399787992239,\n",
       " -0.010758842341601849,\n",
       " -0.009190834127366543,\n",
       " 0.012055333703756332,\n",
       " 0.004150808788836002,\n",
       " -0.020309435203671455,\n",
       " 0.00029442572849802673,\n",
       " 0.0017750392435118556,\n",
       " 0.009421623311936855,\n",
       " ...]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_embeddings(text, model=\"text-embedding-ada-002\"):\n",
    "    # Create embeddings for each document chunk\n",
    "    embeddings = client.embeddings.create(input = text, model=model).data[0].embedding\n",
    "    return embeddings\n",
    "\n",
    "#embeddings for the first chunk\n",
    "create_embeddings(flattened_df['chunks'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.0070539116859436035,\n",
       " -0.01734057068824768,\n",
       " -0.009698242880403996,\n",
       " -0.03073945827782154,\n",
       " -0.012484360486268997,\n",
       " 0.0030714645981788635,\n",
       " -0.005111427512019873,\n",
       " -0.041118279099464417,\n",
       " -0.014561542309820652,\n",
       " -0.021268075332045555,\n",
       " 0.019240519031882286,\n",
       " 0.05075980722904205,\n",
       " -0.0012246867408975959,\n",
       " 0.00255216914229095,\n",
       " -0.03845268115401268,\n",
       " -0.006057857070118189,\n",
       " 0.035475149750709534,\n",
       " -0.004622261971235275,\n",
       " 0.002374935196712613,\n",
       " -0.013455602340400219,\n",
       " -0.01894276589155197,\n",
       " 0.00905311107635498,\n",
       " 0.015894342213869095,\n",
       " -0.00870573241263628,\n",
       " -0.014731687493622303,\n",
       " 0.0071425288915634155,\n",
       " 0.013150759972631931,\n",
       " -0.013228743337094784,\n",
       " 0.0028676455840468407,\n",
       " 0.0048987469635903835,\n",
       " 0.004033844918012619,\n",
       " -0.016801780089735985,\n",
       " -0.015752553939819336,\n",
       " -0.04304658621549606,\n",
       " -0.027123885229229927,\n",
       " -0.004278427921235561,\n",
       " 0.008074779063463211,\n",
       " -0.009939280338585377,\n",
       " 0.022076262161135674,\n",
       " -0.009124004282057285,\n",
       " 0.004920014645904303,\n",
       " 0.00036133575486019254,\n",
       " -0.012073177844285965,\n",
       " 0.013200385496020317,\n",
       " -0.00380698568187654,\n",
       " 0.006990107707679272,\n",
       " -0.02209044061601162,\n",
       " -0.004480474628508091,\n",
       " 0.0013567260466516018,\n",
       " 0.013831338845193386,\n",
       " 0.002562803216278553,\n",
       " 0.008138583973050117,\n",
       " -0.011335884220898151,\n",
       " 0.010371731594204903,\n",
       " -0.005093703977763653,\n",
       " 0.0028144754469394684,\n",
       " 0.007996796630322933,\n",
       " -0.01271830964833498,\n",
       " 0.013136581517755985,\n",
       " 0.0022756841499358416,\n",
       " 0.01595105603337288,\n",
       " 0.004136640578508377,\n",
       " -0.0018467778572812676,\n",
       " 0.02275684103369713,\n",
       " 0.01121536549180746,\n",
       " -0.003401119727641344,\n",
       " -0.00725950300693512,\n",
       " 0.0004089673748239875,\n",
       " -0.004104738589376211,\n",
       " 0.005079525522887707,\n",
       " 0.03238419070839882,\n",
       " 0.028045503422617912,\n",
       " 0.02362174354493618,\n",
       " -0.005728201940655708,\n",
       " -0.009584812447428703,\n",
       " -0.0071496181190013885,\n",
       " -0.008663196116685867,\n",
       " 0.011357152834534645,\n",
       " -0.0006473470712080598,\n",
       " -0.005345376208424568,\n",
       " 0.035957228392362595,\n",
       " -0.032611049711704254,\n",
       " -0.016319703310728073,\n",
       " 0.005632495507597923,\n",
       " 0.019765131175518036,\n",
       " 0.006391056813299656,\n",
       " -0.009343774989247322,\n",
       " 0.00945720449090004,\n",
       " -0.010244122706353664,\n",
       " 0.010577322915196419,\n",
       " 0.02104121632874012,\n",
       " 0.026400770992040634,\n",
       " -0.01233548391610384,\n",
       " 0.037601958960294724,\n",
       " -0.01032919529825449,\n",
       " 0.019524093717336655,\n",
       " -0.016915209591388702,\n",
       " 0.02498289942741394,\n",
       " -0.006866043899208307,\n",
       " -0.05983418598771095,\n",
       " 0.005852265749126673,\n",
       " 0.005207133945077658,\n",
       " -0.04298986867070198,\n",
       " -0.007621060591191053,\n",
       " -0.0037467260845005512,\n",
       " -0.009138183668255806,\n",
       " 0.018474869430065155,\n",
       " 0.00099871342536062,\n",
       " 0.01755325123667717,\n",
       " -0.0026177456602454185,\n",
       " -0.0075005413964390755,\n",
       " 0.05750887840986252,\n",
       " 0.011860497295856476,\n",
       " -0.018205473199486732,\n",
       " 0.005958606023341417,\n",
       " -0.0052567594684660435,\n",
       " -0.004927104339003563,\n",
       " -0.024259785190224648,\n",
       " -0.006008231546729803,\n",
       " -0.015922699123620987,\n",
       " 0.010953059419989586,\n",
       " 0.009372131898999214,\n",
       " 0.038849685341119766,\n",
       " 0.007294950075447559,\n",
       " 0.018886052072048187,\n",
       " 0.01901366002857685,\n",
       " -0.007812472991645336,\n",
       " 0.013654104433953762,\n",
       " -0.013384709134697914,\n",
       " 0.017156247049570084,\n",
       " 0.02906637080013752,\n",
       " 0.0006349406903609633,\n",
       " 0.013909321278333664,\n",
       " 0.009747868403792381,\n",
       " 0.0009225027752108872,\n",
       " 0.027591783553361893,\n",
       " -0.0415152832865715,\n",
       " -0.0027701668441295624,\n",
       " -0.004778227768838406,\n",
       " -0.06278336048126221,\n",
       " -0.0023518947418779135,\n",
       " 0.01936812698841095,\n",
       " -0.0195382721722126,\n",
       " 0.015610767528414726,\n",
       " -0.010648217052221298,\n",
       " 0.023706814274191856,\n",
       " 0.024713503196835518,\n",
       " 0.003711279248818755,\n",
       " 0.012066088616847992,\n",
       " 0.0022898628376424313,\n",
       " 0.005210678558796644,\n",
       " -0.008996396325528622,\n",
       " 0.02715224400162697,\n",
       " -0.017609966918826103,\n",
       " -0.0073729329742491245,\n",
       " 0.030314097180962563,\n",
       " 0.0034578347112983465,\n",
       " 0.014916010200977325,\n",
       " -0.002132124500349164,\n",
       " -0.020091243088245392,\n",
       " -0.0002487921738065779,\n",
       " -0.004824308678507805,\n",
       " 0.016943566501140594,\n",
       " -0.014242521487176418,\n",
       " 0.005625405814498663,\n",
       " 0.02708134986460209,\n",
       " 0.02082853578031063,\n",
       " 0.004430849105119705,\n",
       " -0.013838428072631359,\n",
       " 0.00488456804305315,\n",
       " -0.019566629081964493,\n",
       " 0.022969521582126617,\n",
       " -0.006780971307307482,\n",
       " 0.007188609801232815,\n",
       " -0.003899147268384695,\n",
       " 0.00920907687395811,\n",
       " -0.0009100963943637908,\n",
       " -0.005196499638259411,\n",
       " -0.013257100246846676,\n",
       " -0.026925383135676384,\n",
       " -0.013476870954036713,\n",
       " 0.011130292899906635,\n",
       " 0.015624945983290672,\n",
       " 0.03266776353120804,\n",
       " 0.0009402261930517852,\n",
       " 0.005008631851524115,\n",
       " 0.023962032049894333,\n",
       " -0.00816694088280201,\n",
       " -0.009187809191644192,\n",
       " -0.004515921231359243,\n",
       " 0.005614771973341703,\n",
       " 0.026811953634023666,\n",
       " 0.020630033686757088,\n",
       " -0.02338070422410965,\n",
       " -0.6569850444793701,\n",
       " -0.024089640006422997,\n",
       " -0.0094217574223876,\n",
       " -0.012959347106516361,\n",
       " 0.012548164464533329,\n",
       " 0.024061283096671104,\n",
       " 0.002135669346898794,\n",
       " 0.00254330737516284,\n",
       " 0.006398146040737629,\n",
       " -0.01453318540006876,\n",
       " -0.016801780089735985,\n",
       " 0.00901766400784254,\n",
       " 0.0034117538016289473,\n",
       " -0.010371731594204903,\n",
       " -0.01102395262569189,\n",
       " -0.0032841453794389963,\n",
       " -0.004310329910367727,\n",
       " -0.0188435148447752,\n",
       " -0.018092043697834015,\n",
       " 0.023267274722456932,\n",
       " -0.0021728884894400835,\n",
       " 0.005217767786234617,\n",
       " 0.001953118247911334,\n",
       " -0.013037330470979214,\n",
       " 0.004668342415243387,\n",
       " -0.009868387132883072,\n",
       " 0.006869588512927294,\n",
       " -0.03300805389881134,\n",
       " 0.025096328929066658,\n",
       " 0.01528465747833252,\n",
       " -0.012307126075029373,\n",
       " 0.03056931495666504,\n",
       " -0.005402091424912214,\n",
       " -0.013526496477425098,\n",
       " 0.04667633771896362,\n",
       " 0.022870270535349846,\n",
       " 6.834584928583354e-05,\n",
       " 0.027123885229229927,\n",
       " 0.01521376334130764,\n",
       " 0.040636204183101654,\n",
       " -0.018361438065767288,\n",
       " -0.020105421543121338,\n",
       " 0.01674506440758705,\n",
       " 0.002493681851774454,\n",
       " -0.0252948310226202,\n",
       " -0.012044820003211498,\n",
       " -0.000859141640830785,\n",
       " -0.0005104338051751256,\n",
       " 0.010938880033791065,\n",
       " -0.005565146449953318,\n",
       " 0.01636224053800106,\n",
       " -0.007351664826273918,\n",
       " 0.001995654543861747,\n",
       " -0.0073658437468111515,\n",
       " 0.00835835374891758,\n",
       " 0.004540733993053436,\n",
       " 0.024756040424108505,\n",
       " -0.023706814274191856,\n",
       " 0.0030218390747904778,\n",
       " 0.013079866766929626,\n",
       " -0.0035198666155338287,\n",
       " 0.005267393309623003,\n",
       " -0.008223655633628368,\n",
       " -0.02023302949965,\n",
       " -0.016206273809075356,\n",
       " 0.007185064721852541,\n",
       " -0.015242121182382107,\n",
       " -0.003853066358715296,\n",
       " 0.023791886866092682,\n",
       " 0.010960148647427559,\n",
       " 0.0056785764172673225,\n",
       " 0.0058061848394572735,\n",
       " -0.03465278446674347,\n",
       " 0.003881423734128475,\n",
       " 0.003760904772207141,\n",
       " 0.0221613347530365,\n",
       " 0.008783714845776558,\n",
       " -0.01271830964833498,\n",
       " -0.0011156877735629678,\n",
       " -0.011881764978170395,\n",
       " -0.007564345840364695,\n",
       " 0.004203989636152983,\n",
       " -0.0261739119887352,\n",
       " -0.008152762427926064,\n",
       " 0.01576673425734043,\n",
       " -0.011761246249079704,\n",
       " -0.02125389687716961,\n",
       " -0.0013425472425296903,\n",
       " 0.01430632546544075,\n",
       " 0.01130752731114626,\n",
       " 0.007213422562927008,\n",
       " 0.024401571601629257,\n",
       " -0.017326392233371735,\n",
       " 0.014363040216267109,\n",
       " -0.009131093509495258,\n",
       " 0.00938631035387516,\n",
       " -0.006302439607679844,\n",
       " 0.0036173451226204634,\n",
       " 0.01052060816437006,\n",
       " -0.03816910833120346,\n",
       " -0.00795426033437252,\n",
       " -0.004873934201896191,\n",
       " 0.006493852473795414,\n",
       " -0.0068908566609025,\n",
       " 0.022203871980309486,\n",
       " 0.02376352995634079,\n",
       " -0.014816759154200554,\n",
       " 0.018715906888246536,\n",
       " 0.036581091582775116,\n",
       " -0.021452398970723152,\n",
       " 0.005299295764416456,\n",
       " -0.004767593462020159,\n",
       " -0.010003085248172283,\n",
       " 0.00026762328343465924,\n",
       " 0.013866784982383251,\n",
       " -0.031391680240631104,\n",
       " 0.01217951811850071,\n",
       " 0.004781772382557392,\n",
       " 0.01867336966097355,\n",
       " -0.022983700037002563,\n",
       " -0.010237033478915691,\n",
       " 0.020715106278657913,\n",
       " 0.013136581517755985,\n",
       " -0.008556855842471123,\n",
       " 0.0038920578081160784,\n",
       " 0.0029846199322491884,\n",
       " -0.016759242862462997,\n",
       " 0.0012494995025917888,\n",
       " -0.005997597239911556,\n",
       " -0.0021817500237375498,\n",
       " 0.008308728225529194,\n",
       " -0.020261386409401894,\n",
       " 0.014511916786432266,\n",
       " -0.016149558126926422,\n",
       " 0.003238064469769597,\n",
       " 0.0020771820563822985,\n",
       " 0.025082150474190712,\n",
       " 0.016149558126926422,\n",
       " 0.01838979683816433,\n",
       " -0.004430849105119705,\n",
       " -0.025592584162950516,\n",
       " -0.0004264692252036184,\n",
       " 0.010761646553874016,\n",
       " 0.006461950484663248,\n",
       " 0.018276367336511612,\n",
       " 0.002844605129212141,\n",
       " -0.006660452578216791,\n",
       " -0.0244299303740263,\n",
       " 0.0024688690900802612,\n",
       " 0.009584812447428703,\n",
       " -0.014859295450150967,\n",
       " -0.010782914236187935,\n",
       " 0.027676856145262718,\n",
       " 0.01654656231403351,\n",
       " 0.03465278446674347,\n",
       " -0.022317301481962204,\n",
       " -0.010102336294949055,\n",
       " -0.015468980185687542,\n",
       " -0.019183805212378502,\n",
       " -0.008032243698835373,\n",
       " 0.005696299485862255,\n",
       " 0.034142352640628815,\n",
       " -0.0042465259321033955,\n",
       " -0.013689551502466202,\n",
       " -0.01702863909304142,\n",
       " -0.023267274722456932,\n",
       " 0.00949265155941248,\n",
       " 0.03309312462806702,\n",
       " -0.02536572515964508,\n",
       " -0.03331998363137245,\n",
       " -0.00452655553817749,\n",
       " -0.021551650017499924,\n",
       " -0.005753014702349901,\n",
       " 0.02204790525138378,\n",
       " 0.007961349561810493,\n",
       " 0.004331598058342934,\n",
       " 0.008691553957760334,\n",
       " -0.02784700132906437,\n",
       " 0.00832290668040514,\n",
       " 0.0034915090072900057,\n",
       " 0.029321586713194847,\n",
       " -0.004753415007144213,\n",
       " -0.01154856476932764,\n",
       " -0.0063556102104485035,\n",
       " 0.001027956954203546,\n",
       " 0.01650402694940567,\n",
       " 0.03425578027963638,\n",
       " 0.01841815374791622,\n",
       " -0.018574118614196777,\n",
       " 0.01629134640097618,\n",
       " -0.017326392233371735,\n",
       " 0.006061401683837175,\n",
       " -0.0008999054552987218,\n",
       " 0.011087756603956223,\n",
       " 0.000985420891083777,\n",
       " -0.010981416329741478,\n",
       " 0.00544462725520134,\n",
       " 0.022416552528738976,\n",
       " 0.017737574875354767,\n",
       " 0.021792687475681305,\n",
       " -0.0006907694041728973,\n",
       " 0.013143670745193958,\n",
       " 0.010456804186105728,\n",
       " -0.002518494613468647,\n",
       " 0.01970841735601425,\n",
       " -0.03601394221186638,\n",
       " -0.01393767911940813,\n",
       " -0.008096047677099705,\n",
       " 0.03748852759599686,\n",
       " 0.026046304032206535,\n",
       " -0.00012971310934517533,\n",
       " -0.00833708606660366,\n",
       " -0.016206273809075356,\n",
       " -0.012661594897508621,\n",
       " 0.007344575598835945,\n",
       " 0.02839997038245201,\n",
       " -0.010449714958667755,\n",
       " -0.002330626593902707,\n",
       " -0.009152362123131752,\n",
       " 0.0002461336553096771,\n",
       " -0.0075076306238770485,\n",
       " -0.0032433816231787205,\n",
       " -0.005919614341109991,\n",
       " 0.02013377845287323,\n",
       " 0.006238635629415512,\n",
       " 0.011569833382964134,\n",
       " 0.020885249599814415,\n",
       " 0.03598558530211449,\n",
       " 0.004026755690574646,\n",
       " -0.026684345677495003,\n",
       " -0.024699324741959572,\n",
       " 0.00033342139795422554,\n",
       " 0.00957772321999073,\n",
       " 0.010931790806353092,\n",
       " 0.0044698407873511314,\n",
       " -0.0013824249617755413,\n",
       " 0.02760596200823784,\n",
       " -0.020147956907749176,\n",
       " 0.03357520326972008,\n",
       " 0.01306568831205368,\n",
       " 0.00022364710457623005,\n",
       " 0.025096328929066658,\n",
       " 0.0142212538048625,\n",
       " -0.02452918142080307,\n",
       " 0.011832139454782009,\n",
       " -0.003390485653653741,\n",
       " 0.023579206317663193,\n",
       " 0.015383908525109291,\n",
       " -0.0036368409637361765,\n",
       " 0.01521376334130764,\n",
       " -0.013342172838747501,\n",
       " 0.004955461714416742,\n",
       " -0.018233830109238625,\n",
       " 0.01874426379799843,\n",
       " 0.004494653549045324,\n",
       " -0.01595105603337288,\n",
       " 0.01685849390923977,\n",
       " 0.006451316177845001,\n",
       " 0.027138065546751022,\n",
       " 0.031420037150382996,\n",
       " 0.02278519794344902,\n",
       " -0.0006460177828557789,\n",
       " 0.004172087647020817,\n",
       " 0.00048384873662143946,\n",
       " 0.010442624799907207,\n",
       " 0.018347259610891342,\n",
       " 0.019722595810890198,\n",
       " -0.01626298949122429,\n",
       " 0.015653302893042564,\n",
       " 0.005969239864498377,\n",
       " -0.012711220420897007,\n",
       " -0.009372131898999214,\n",
       " 0.010811272077262402,\n",
       " -0.017666680738329887,\n",
       " 0.013292547315359116,\n",
       " 0.012243322096765041,\n",
       " -0.0008684464264661074,\n",
       " -0.005632495507597923,\n",
       " 0.023153845220804214,\n",
       " -0.003546451684087515,\n",
       " -0.017978614196181297,\n",
       " -0.051241882145404816,\n",
       " 0.027648499235510826,\n",
       " -0.004753415007144213,\n",
       " -0.008755357936024666,\n",
       " -0.001816648175008595,\n",
       " -0.04128842428326607,\n",
       " -0.017071176320314407,\n",
       " -0.0021374416537582874,\n",
       " 0.011704531498253345,\n",
       " 0.00029598071705549955,\n",
       " 0.013420156203210354,\n",
       " 0.02226058579981327,\n",
       " 0.019141267985105515,\n",
       " 0.013689551502466202,\n",
       " -0.0022898628376424313,\n",
       " 0.030229024589061737,\n",
       " -0.013143670745193958,\n",
       " 0.00886169821023941,\n",
       " 0.010995594784617424,\n",
       " 0.0016146014677360654,\n",
       " -0.027166422456502914,\n",
       " -0.00945720449090004,\n",
       " -0.02658509463071823,\n",
       " 0.009655706584453583,\n",
       " -0.016064487397670746,\n",
       " -0.016078665852546692,\n",
       " -0.0239053163677454,\n",
       " -0.004565546754747629,\n",
       " 0.0033709900453686714,\n",
       " -0.01996363326907158,\n",
       " 0.017326392233371735,\n",
       " -0.023040415719151497,\n",
       " -0.0102086765691638,\n",
       " -0.014065287075936794,\n",
       " -0.008081869222223759,\n",
       " -0.033972207456827164,\n",
       " -0.002004516078159213,\n",
       " 0.049115076661109924,\n",
       " -0.0012025324394926429,\n",
       " -0.011803781613707542,\n",
       " -0.012378020212054253,\n",
       " -0.034737858921289444,\n",
       " -0.017468180507421494,\n",
       " 0.0704965814948082,\n",
       " 0.008209477178752422,\n",
       " -0.009024753235280514,\n",
       " 0.010690752416849136,\n",
       " 0.001944256597198546,\n",
       " -0.019098732620477676,\n",
       " -0.029491731896996498,\n",
       " 0.0007541305385529995,\n",
       " 0.026982098817825317,\n",
       " 0.01245600264519453,\n",
       " -0.009705332107841969,\n",
       " 0.006033044308423996,\n",
       " 0.009365042671561241,\n",
       " -0.0034082091879099607,\n",
       " -0.002109084278345108,\n",
       " 0.01748235896229744,\n",
       " -0.019424842670559883,\n",
       " 0.0015889025526121259,\n",
       " 0.010534786619246006,\n",
       " -0.013448513112962246,\n",
       " 0.0023767075035721064,\n",
       " 0.0018715906189754605,\n",
       " 0.017156247049570084,\n",
       " 0.0030714645981788635,\n",
       " -0.004406036343425512,\n",
       " -0.005955061409622431,\n",
       " 0.005253214854747057,\n",
       " 0.03371698781847954,\n",
       " 0.018276367336511612,\n",
       " -0.02937830239534378,\n",
       " 0.005253214854747057,\n",
       " 0.018092043697834015,\n",
       " -0.015681661665439606,\n",
       " -0.003521638922393322,\n",
       " 0.011938479728996754,\n",
       " 0.008975127711892128,\n",
       " -0.004785316996276379,\n",
       " 0.008485962636768818,\n",
       " 0.024571716785430908,\n",
       " -0.018162935972213745,\n",
       " 0.020885249599814415,\n",
       " 0.023253096267580986,\n",
       " -0.016107022762298584,\n",
       " -0.019212162122130394,\n",
       " 0.009932191111147404,\n",
       " -0.007160251960158348,\n",
       " 0.0011148016201332211,\n",
       " 0.021438220515847206,\n",
       " 0.011725799180567265,\n",
       " -0.004668342415243387,\n",
       " 0.03833924978971481,\n",
       " 0.029406659305095673,\n",
       " -0.00783374160528183,\n",
       " 0.005079525522887707,\n",
       " -0.016376418992877007,\n",
       " -0.010024352930486202,\n",
       " 0.014107823371887207,\n",
       " -0.00938631035387516,\n",
       " -0.0021480757277458906,\n",
       " -0.016107022762298584,\n",
       " -0.00818112026900053,\n",
       " -0.012434734962880611,\n",
       " 0.012037730775773525,\n",
       " 0.002319992519915104,\n",
       " -0.013717909343540668,\n",
       " -0.022884448990225792,\n",
       " 0.001340774935670197,\n",
       " -0.022005369886755943,\n",
       " -0.03116482123732567,\n",
       " -0.013441423885524273,\n",
       " -0.013852606527507305,\n",
       " -0.016532383859157562,\n",
       " -0.018503226339817047,\n",
       " 0.007720311637967825,\n",
       " 0.006663997191935778,\n",
       " 0.023366525769233704,\n",
       " 0.021977011114358902,\n",
       " -0.02338070422410965,\n",
       " -0.0006894401158206165,\n",
       " 0.02156582847237587,\n",
       " -0.015327192842960358,\n",
       " -0.02620226889848709,\n",
       " 0.004498198162764311,\n",
       " -0.04222422093153,\n",
       " -0.021764330565929413,\n",
       " 0.006649818271398544,\n",
       " -0.006795150227844715,\n",
       " -0.014405576512217522,\n",
       " -0.00488456804305315,\n",
       " -0.00028601131634786725,\n",
       " 0.01965170167386532,\n",
       " 0.0008551538921892643,\n",
       " 0.034737858921289444,\n",
       " -0.01758161000907421,\n",
       " -0.0037644493859261274,\n",
       " 0.01362574752420187,\n",
       " 0.01453318540006876,\n",
       " -0.009294149465858936,\n",
       " 0.003487964393571019,\n",
       " -0.033660273998975754,\n",
       " 0.01415035966783762,\n",
       " -0.024231428280472755,\n",
       " -0.013335083611309528,\n",
       " 0.0020116055384278297,\n",
       " 0.010527697391808033,\n",
       " 0.0001422302593709901,\n",
       " 0.020006170496344566,\n",
       " 0.034596070647239685,\n",
       " 0.0021019948180764914,\n",
       " -0.01772339642047882,\n",
       " 0.009627348743379116,\n",
       " -0.022657589986920357,\n",
       " -0.00957772321999073,\n",
       " -0.010357553139328957,\n",
       " 0.015993593260645866,\n",
       " 0.015071975998580456,\n",
       " -0.022529982030391693,\n",
       " 0.024869469925761223,\n",
       " 0.024401571601629257,\n",
       " -0.0073800222016870975,\n",
       " -0.026982098817825317,\n",
       " -0.019864382222294807,\n",
       " 0.018999481573700905,\n",
       " 0.0308812465518713,\n",
       " -0.011612369678914547,\n",
       " 0.002594705205410719,\n",
       " 0.0013895143056288362,\n",
       " 0.008067689836025238,\n",
       " -0.006291805766522884,\n",
       " 0.007521809544414282,\n",
       " 0.004395402502268553,\n",
       " 0.011959748342633247,\n",
       " -0.012051909230649471,\n",
       " -0.04596740007400513,\n",
       " -0.022898627445101738,\n",
       " -0.013200385496020317,\n",
       " -0.013101134449243546,\n",
       " 0.010357553139328957,\n",
       " -0.006780971307307482,\n",
       " -0.019765131175518036,\n",
       " -0.04520174860954285,\n",
       " 0.0059160697273910046,\n",
       " 0.0013753356179222465,\n",
       " -0.02044571004807949,\n",
       " -0.01870172843337059,\n",
       " -0.042309291660785675,\n",
       " -0.03283790871500969,\n",
       " -0.004519466310739517,\n",
       " 0.004696700256317854,\n",
       " 0.029123084619641304,\n",
       " -0.009563544765114784,\n",
       " 0.010655306279659271,\n",
       " -0.009116915054619312,\n",
       " -0.01681595854461193,\n",
       " -0.015780912712216377,\n",
       " -0.023196380585432053,\n",
       " -0.016631634905934334,\n",
       " -0.0016589099541306496,\n",
       " 0.0338587760925293,\n",
       " 0.02065839059650898,\n",
       " -0.0020151501521468163,\n",
       " 0.008904234506189823,\n",
       " 0.011498939245939255,\n",
       " -0.007486362475901842,\n",
       " -0.008521408773958683,\n",
       " 0.00910982582718134,\n",
       " 0.012151160277426243,\n",
       " 0.011335884220898151,\n",
       " -0.02732238732278347,\n",
       " 0.011576922610402107,\n",
       " 0.01724131964147091,\n",
       " -0.0038247089833021164,\n",
       " -0.0010102336527779698,\n",
       " -0.0016633407212793827,\n",
       " -0.022104620933532715,\n",
       " 0.02013377845287323,\n",
       " 0.0036900111008435488,\n",
       " -0.023040415719151497,\n",
       " 0.0029598071705549955,\n",
       " -0.007578524295240641,\n",
       " 0.014292147010564804,\n",
       " -0.003213251708075404,\n",
       " 0.015724197030067444,\n",
       " 0.015015261247754097,\n",
       " 0.0008790804422460496,\n",
       " -0.0022827733773738146,\n",
       " 0.016631634905934334,\n",
       " 0.00291372649371624,\n",
       " -0.008422157727181911,\n",
       " 0.0047144233249127865,\n",
       " 0.01449773833155632,\n",
       " -0.010003085248172283,\n",
       " 0.01040008943527937,\n",
       " -0.02596123144030571,\n",
       " 0.014334683306515217,\n",
       " -0.03056931495666504,\n",
       " -0.016277167946100235,\n",
       " -0.0025397627614438534,\n",
       " 0.0015437077963724732,\n",
       " -0.01346978172659874,\n",
       " 0.011888854205608368,\n",
       " 0.039728764444589615,\n",
       " 0.0037750834599137306,\n",
       " 0.008932591415941715,\n",
       " 0.00013602706894744188,\n",
       " -0.0071496181190013885,\n",
       " -0.0001742431486491114,\n",
       " -0.016418954357504845,\n",
       " 0.003486192086711526,\n",
       " -0.016305524855852127,\n",
       " -0.00949265155941248,\n",
       " -0.008429246954619884,\n",
       " -0.058359600603580475,\n",
       " -0.02624480612576008,\n",
       " -0.006756158545613289,\n",
       " 0.0015924471663311124,\n",
       " -0.001572951441630721,\n",
       " 0.007741579785943031,\n",
       " -0.010995594784617424,\n",
       " -0.008117315359413624,\n",
       " -0.012044820003211498,\n",
       " 0.0025167223066091537,\n",
       " 0.026358235627412796,\n",
       " -0.02613137662410736,\n",
       " 0.02923651412129402,\n",
       " 0.02631569840013981,\n",
       " -0.01846068911254406,\n",
       " -0.005267393309623003,\n",
       " 0.007206332869827747,\n",
       " -0.015171227045357227,\n",
       " -0.048831503838300705,\n",
       " 0.008174030110239983,\n",
       " 0.003119317814707756,\n",
       " -0.012909721583127975,\n",
       " 0.015568231232464314,\n",
       " -0.006834141910076141,\n",
       " 0.0050405338406562805,\n",
       " -0.014859295450150967,\n",
       " -0.024486644193530083,\n",
       " 0.020856892690062523,\n",
       " 0.032157331705093384,\n",
       " -0.009478472173213959,\n",
       " -0.02899547666311264,\n",
       " 0.010619859211146832,\n",
       " -0.01083253975957632,\n",
       " 0.01803532801568508,\n",
       " -0.00867028534412384,\n",
       " -0.0023625288158655167,\n",
       " -0.03147675096988678,\n",
       " -0.00673489086329937,\n",
       " -0.018730085343122482,\n",
       " 0.016801780089735985,\n",
       " -0.018786801025271416,\n",
       " 0.015851804986596107,\n",
       " 0.007234690245240927,\n",
       " -0.003376306965947151,\n",
       " 0.022203871980309486,\n",
       " 0.013951857574284077,\n",
       " -0.013810070231556892,\n",
       " -0.012626147828996181,\n",
       " -0.031221535056829453,\n",
       " 0.020077062770724297,\n",
       " -0.019382307305932045,\n",
       " 0.032327476888895035,\n",
       " 0.018588298931717873,\n",
       " 0.004278427921235561,\n",
       " -0.019665880128741264,\n",
       " 0.0011148016201332211,\n",
       " -0.01783682592213154,\n",
       " 0.03204390034079552,\n",
       " -0.007330396678298712,\n",
       " -0.010272480547428131,\n",
       " 0.01289554312825203,\n",
       " -0.022487444803118706,\n",
       " 0.015894342213869095,\n",
       " -0.01996363326907158,\n",
       " -0.02030392363667488,\n",
       " 0.002826881827786565,\n",
       " -0.018900230526924133,\n",
       " -0.04026755690574646,\n",
       " 0.01633388176560402,\n",
       " 0.00760688167065382,\n",
       " -0.01215825043618679,\n",
       " 0.003505687927827239,\n",
       " -0.006639184430241585,\n",
       " -0.022104620933532715,\n",
       " -0.004044479224830866,\n",
       " -0.007564345840364695,\n",
       " -0.021764330565929413,\n",
       " -0.005189410410821438,\n",
       " -0.013157849200069904,\n",
       " -0.0038778791204094887,\n",
       " 0.010244122706353664,\n",
       " 0.001640300382860005,\n",
       " 0.017524894326925278,\n",
       " -0.0005042306147515774,\n",
       " -0.001738665159791708,\n",
       " 0.03556022420525551,\n",
       " -0.01231421623378992,\n",
       " 0.02467096783220768,\n",
       " -0.032951340079307556,\n",
       " 0.014561542309820652,\n",
       " -0.021083751693367958,\n",
       " -0.004771138541400433,\n",
       " -0.003743181237950921,\n",
       " 0.009634437970817089,\n",
       " 0.006674631033092737,\n",
       " -0.018715906888246536,\n",
       " -0.008329995907843113,\n",
       " -0.0008374304743483663,\n",
       " -0.006621460895985365,\n",
       " 0.002268594689667225,\n",
       " -0.0020523692946881056,\n",
       " 0.003317819908261299,\n",
       " 0.0058203632943332195,\n",
       " 0.009641528129577637,\n",
       " 0.006330797448754311,\n",
       " -0.008982216939330101,\n",
       " -0.016036128625273705,\n",
       " 0.013873875141143799,\n",
       " -0.010279569774866104,\n",
       " 0.011151561513543129,\n",
       " 0.0061500184237957,\n",
       " -0.0018485502805560827,\n",
       " 0.00910982582718134,\n",
       " -0.019935276359319687,\n",
       " 0.026500022038817406,\n",
       " 0.012739577330648899,\n",
       " -0.015539874322712421,\n",
       " -0.013505227863788605,\n",
       " -0.01946737803518772,\n",
       " 0.009336684830486774,\n",
       " -0.003399347420781851,\n",
       " -0.03499307483434677,\n",
       " -0.014887653291225433,\n",
       " -0.03439756855368614,\n",
       " -0.021268075332045555,\n",
       " 0.022388193756341934,\n",
       " -0.013150759972631931,\n",
       " -0.010648217052221298,\n",
       " 0.011867586523294449,\n",
       " 0.0059408824890851974,\n",
       " -0.011498939245939255,\n",
       " 0.0033603559713810682,\n",
       " -0.022600874304771423,\n",
       " -0.02484111301600933,\n",
       " -0.0109034338966012,\n",
       " 0.008790805004537106,\n",
       " -0.025620941072702408,\n",
       " -0.0060436781495809555,\n",
       " -0.021310612559318542,\n",
       " 0.017851004377007484,\n",
       " 0.008975127711892128,\n",
       " -0.040182486176490784,\n",
       " -0.018687549978494644,\n",
       " 0.00889714527875185,\n",
       " -0.025550048798322678,\n",
       " -0.0045868149027228355,\n",
       " -0.0012920355657115579,\n",
       " 0.00949265155941248,\n",
       " 0.010478071868419647,\n",
       " -0.018347259610891342,\n",
       " 0.01359030045568943,\n",
       " 0.0002767065307125449,\n",
       " -0.003126407042145729,\n",
       " 0.019935276359319687,\n",
       " -0.014816759154200554,\n",
       " -0.013618658296763897,\n",
       " 0.01894276589155197,\n",
       " 0.003743181237950921,\n",
       " 0.024685146287083626,\n",
       " -0.016390597447752953,\n",
       " -0.019722595810890198,\n",
       " -0.024826934561133385,\n",
       " 0.014051108621060848,\n",
       " 0.01602195017039776,\n",
       " 0.0005667055957019329,\n",
       " 0.02631569840013981,\n",
       " 0.0007820448954589665,\n",
       " -0.014426845125854015,\n",
       " 0.0008808528073132038,\n",
       " 0.008563945069909096,\n",
       " 0.024018747732043266,\n",
       " -0.0047959513030946255,\n",
       " 0.012044820003211498,\n",
       " 0.0056785764172673225,\n",
       " -0.01287427544593811,\n",
       " 0.012541075237095356,\n",
       " -0.007932992652058601,\n",
       " 0.0033036412205547094,\n",
       " -0.007847920060157776,\n",
       " -0.011144471354782581,\n",
       " -0.012803381308913231,\n",
       " -0.002415698952972889,\n",
       " -0.012966437265276909,\n",
       " -0.0015694067114964128,\n",
       " -0.0031423582695424557,\n",
       " -0.05498506501317024,\n",
       " -0.018290545791387558,\n",
       " 0.019765131175518036,\n",
       " 0.00016504913219250739,\n",
       " 0.023295631632208824,\n",
       " -0.01127208024263382,\n",
       " -0.013647015206515789,\n",
       " -0.01566748321056366,\n",
       " 0.019212162122130394,\n",
       " -0.016518205404281616,\n",
       " -0.022742662578821182,\n",
       " 0.0261739119887352,\n",
       " 0.015624945983290672,\n",
       " 0.01965170167386532,\n",
       " -0.00870573241263628,\n",
       " -0.012356751598417759,\n",
       " -0.030172310769557953,\n",
       " -0.00901766400784254,\n",
       " 0.00025566000840626657,\n",
       " -0.0063556102104485035,\n",
       " 0.008223655633628368,\n",
       " 0.003760904772207141,\n",
       " 0.009131093509495258,\n",
       " -0.029151443392038345,\n",
       " 0.0020718651358038187,\n",
       " -0.0016261215787380934,\n",
       " -0.024940364062786102,\n",
       " 0.006897945888340473,\n",
       " -0.012484360486268997,\n",
       " 0.0016216908115893602,\n",
       " -0.003317819908261299,\n",
       " -0.006302439607679844,\n",
       " 0.019424842670559883,\n",
       " 0.002853466896340251,\n",
       " -0.00038127455627545714,\n",
       " -0.00253444560803473,\n",
       " -0.0005671486724168062,\n",
       " 0.01576673425734043,\n",
       " 0.0042607043869793415,\n",
       " 0.18341588973999023,\n",
       " -0.0032416093163192272,\n",
       " 0.002545079682022333,\n",
       " 0.03224240243434906,\n",
       " 0.007741579785943031,\n",
       " -0.023494133725762367,\n",
       " 0.03161853924393654,\n",
       " 0.019977811723947525,\n",
       " 0.008131494745612144,\n",
       " 0.018517404794692993,\n",
       " -0.005122061353176832,\n",
       " 0.00216757133603096,\n",
       " -0.0026248351205140352,\n",
       " 0.00795426033437252,\n",
       " 0.0032504708506166935,\n",
       " 0.008641928434371948,\n",
       " -0.027903715148568153,\n",
       " -0.012094445526599884,\n",
       " -0.03190211206674576,\n",
       " -0.015851804986596107,\n",
       " 0.023153845220804214,\n",
       " 0.013193296268582344,\n",
       " -0.025592584162950516,\n",
       " 3.979456232627854e-05,\n",
       " 0.0394168347120285,\n",
       " 0.020162135362625122,\n",
       " -0.02557840570807457,\n",
       " -0.009606081061065197,\n",
       " 0.012413467280566692,\n",
       " 0.0035872154403477907,\n",
       " -0.019169624894857407,\n",
       " -0.009776225313544273,\n",
       " -0.008266191929578781,\n",
       " -0.010031442157924175,\n",
       " -0.004225257784128189,\n",
       " -0.011640726588666439,\n",
       " -0.015511516481637955,\n",
       " 0.022870270535349846,\n",
       " 0.0014293919084593654,\n",
       " 0.018134579062461853,\n",
       " -0.035645294934511185,\n",
       " 0.005664397496730089,\n",
       " -0.009294149465858936,\n",
       " -0.00979040376842022,\n",
       " -0.017142068594694138,\n",
       " 0.03360356017947197,\n",
       " ...]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat = create_embeddings(\"cat\")\n",
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "      <td>[-0.01710554026067257, 0.002864499343559146, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "      <td>[-0.01482970081269741, 0.0016899447655305266, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "      <td>[-0.03680434077978134, -0.02070910856127739, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "      <td>[-0.03173335641622543, -0.011053191497921944, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "      <td>[-0.008027797564864159, -0.0333440825343132, 0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  # Neural Network Frameworks As we have learned...   \n",
       "0  descent optimization While the `numpy` library...   \n",
       "0  should give us the opportunity to compute grad...   \n",
       "0  those computations on GPUs is very important. ...   \n",
       "0  API, there is also higher-level API, called Ke...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [-0.01710554026067257, 0.002864499343559146, 0...  \n",
       "0  [-0.01482970081269741, 0.0016899447655305266, ...  \n",
       "0  [-0.03680434077978134, -0.02070910856127739, 0...  \n",
       "0  [-0.03173335641622543, -0.011053191497921944, ...  \n",
       "0  [-0.008027797564864159, -0.0333440825343132, 0...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create embeddings for the whole data chunks and store them in a list\n",
    "\n",
    "embeddings = []\n",
    "for chunk in flattened_df['chunks']:\n",
    "    embeddings.append(create_embeddings(chunk))\n",
    "\n",
    "# store the embeddings in the dataframe\n",
    "flattened_df['embeddings'] = embeddings\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval\n",
    "\n",
    "Vector search and similiarity between our prompt and the database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating an search index and reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>text</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>indices</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td># Neural Network Frameworks As we have learned...</td>\n",
       "      <td>[-0.01710554026067257, 0.002864499343559146, 0...</td>\n",
       "      <td>[0, 2, 11, 3, 1]</td>\n",
       "      <td>[0.0, 0.5231289234277616, 0.5281664756122898, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>descent optimization While the `numpy` library...</td>\n",
       "      <td>[-0.01482970081269741, 0.0016899447655305266, ...</td>\n",
       "      <td>[1, 0, 32, 2, 50]</td>\n",
       "      <td>[0.0, 0.5700021940324681, 0.5924127753624866, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>should give us the opportunity to compute grad...</td>\n",
       "      <td>[-0.03680434077978134, -0.02070910856127739, 0...</td>\n",
       "      <td>[2, 3, 0, 5, 1]</td>\n",
       "      <td>[0.0, 0.5056656786084963, 0.5231289234277616, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>those computations on GPUs is very important. ...</td>\n",
       "      <td>[-0.03173335641622543, -0.011053191497921944, ...</td>\n",
       "      <td>[3, 2, 0, 10, 11]</td>\n",
       "      <td>[0.0, 0.5056656786084963, 0.5459749903916924, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>data/frameworks.md</td>\n",
       "      <td># Neural Network Frameworks\\n\\nAs we have lear...</td>\n",
       "      <td>API, there is also higher-level API, called Ke...</td>\n",
       "      <td>[-0.008027797564864159, -0.0333440825343132, 0...</td>\n",
       "      <td>[4, 12, 10, 8, 9]</td>\n",
       "      <td>[0.0, 0.5191959112618413, 0.5522311510705009, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 path                                               text  \\\n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "0  data/frameworks.md  # Neural Network Frameworks\\n\\nAs we have lear...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  # Neural Network Frameworks As we have learned...   \n",
       "0  descent optimization While the `numpy` library...   \n",
       "0  should give us the opportunity to compute grad...   \n",
       "0  those computations on GPUs is very important. ...   \n",
       "0  API, there is also higher-level API, called Ke...   \n",
       "\n",
       "                                          embeddings            indices  \\\n",
       "0  [-0.01710554026067257, 0.002864499343559146, 0...   [0, 2, 11, 3, 1]   \n",
       "0  [-0.01482970081269741, 0.0016899447655305266, ...  [1, 0, 32, 2, 50]   \n",
       "0  [-0.03680434077978134, -0.02070910856127739, 0...    [2, 3, 0, 5, 1]   \n",
       "0  [-0.03173335641622543, -0.011053191497921944, ...  [3, 2, 0, 10, 11]   \n",
       "0  [-0.008027797564864159, -0.0333440825343132, 0...  [4, 12, 10, 8, 9]   \n",
       "\n",
       "                                           distances  \n",
       "0  [0.0, 0.5231289234277616, 0.5281664756122898, ...  \n",
       "0  [0.0, 0.5700021940324681, 0.5924127753624866, ...  \n",
       "0  [0.0, 0.5056656786084963, 0.5231289234277616, ...  \n",
       "0  [0.0, 0.5056656786084963, 0.5459749903916924, ...  \n",
       "0  [0.0, 0.5191959112618413, 0.5522311510705009, ...  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "embeddings = flattened_df['embeddings'].to_list()\n",
    "\n",
    "# Create the search index\n",
    "nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)\n",
    "\n",
    "# To query the index, you can use the kneighbors method\n",
    "distances, indices = nbrs.kneighbors(embeddings)\n",
    "\n",
    "# Store the indices and distances in the DataFrame\n",
    "flattened_df['indices'] = indices.tolist()\n",
    "flattened_df['distances'] = distances.tolist()\n",
    "\n",
    "flattened_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5277758037255733, 0.5363335862390093, 0.5444526711829064, 0.5541456450579713]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45856142626262997, 0.5236047423369777, 0.5627386585479264, 0.5634420757319366]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5236047423369777, 0.5444526711829064, 0.5608855365327595, 0.5758940461358417]\n",
      "and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\n",
      "data/perceptron.md\n",
      "[0.0, 0.5046776850042851, 0.5085579879017892, 0.522822193833606, 0.5277758037255733]\n",
      "# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform\n",
      "data/own_framework.md\n",
      "[0.0, 0.45856142626262997, 0.5057877212929998, 0.5085579879017892, 0.5179285575931876]\n",
      "Index 25 not found in DataFrame\n",
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5277758037255733, 0.5363335862390093, 0.5444526711829064, 0.5541456450579713]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45856142626262997, 0.5236047423369777, 0.5627386585479264, 0.5634420757319366]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5236047423369777, 0.5444526711829064, 0.5608855365327595, 0.5758940461358417]\n",
      "and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\n",
      "data/perceptron.md\n",
      "[0.0, 0.5046776850042851, 0.5085579879017892, 0.522822193833606, 0.5277758037255733]\n",
      "# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform\n",
      "data/own_framework.md\n",
      "[0.0, 0.45856142626262997, 0.5057877212929998, 0.5085579879017892, 0.5179285575931876]\n",
      "Index 25 not found in DataFrame\n",
      "in our model, in which case the input vector would be a vector of size N. A perceptron is a **binary classification** model, i.e. it can distinguish between two classes of input data. We will assume that for each input vector x the output of our perceptron would be either +1 or -1, depending on the class.\n",
      "data/perceptron.md\n",
      "[0.0, 0.5277758037255733, 0.5363335862390093, 0.5444526711829064, 0.5541456450579713]\n",
      "# Introduction to Neural Networks: Perceptron One of the first attempts to implement something similar to a modern neural network was done by Frank Rosenblatt from Cornell Aeronautical Laboratory in 1957. It was a hardware implementation called \"Mark-1\", designed to recognize primitive geometric figures,\n",
      "data/perceptron.md\n",
      "[0.0, 0.45856142626262997, 0.5236047423369777, 0.5627386585479264, 0.5634420757319366]\n",
      "user to adjust the resistance of a circuit. > The New York Times wrote about perceptron at that time: *the embryo of an electronic computer that [the Navy] expects will be able to walk, talk, see, write, reproduce itself and be conscious of its existence.* ## Perceptron Model Suppose we have N features\n",
      "data/perceptron.md\n",
      "[0.0, 0.5236047423369777, 0.5444526711829064, 0.5608855365327595, 0.5758940461358417]\n",
      "and to continue learning - go to Perceptron notebook. Here's an interesting article about perceptrons as well. ## Assignment In this lesson, we have implemented a perceptron for binary classification task, and we have used it to classify between two handwritten digits. In this lab, you are asked to solve\n",
      "data/perceptron.md\n",
      "[0.0, 0.5046776850042851, 0.5085579879017892, 0.522822193833606, 0.5277758037255733]\n",
      "# Introduction to Neural Networks. Multi-Layered Perceptron In the previous section, you learned about the simplest neural network model - one-layered perceptron, a linear two-class classification model. In this section we will extend this model into a more flexible framework, allowing us to: * perform\n",
      "data/own_framework.md\n",
      "[0.0, 0.45856142626262997, 0.5057877212929998, 0.5085579879017892, 0.5179285575931876]\n",
      "Index 25 not found in DataFrame\n"
     ]
    }
   ],
   "source": [
    "# Your text question\n",
    "question = \"what is a perceptron?\"\n",
    "\n",
    "# Convert the question to a query vector\n",
    "query_vector = create_embeddings(question)  # You need to define this function\n",
    "\n",
    "# Find the most similar documents\n",
    "distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "index = []\n",
    "# Print the most similar documents\n",
    "for i in range(3):\n",
    "    index = indices[0][i]\n",
    "    for index in indices[0]:\n",
    "        print(flattened_df['chunks'].iloc[index])\n",
    "        print(flattened_df['path'].iloc[index])\n",
    "        print(flattened_df['distances'].iloc[index])\n",
    "    else:\n",
    "        print(f\"Index {index} not found in DataFrame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together to answer a question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "openai.api_type = \"azure\"\n",
    "openai.api_base = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "openai.api_version = \"2023-07-01-preview\"\n",
    "openai.api_key = os.getenv(\"AZURE_OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='A **perceptron** is a fundamental building block of artificial neural networks, especially in the context of machine learning and deep learning.\\n\\n### Definition\\nA perceptron is a simple mathematical model that simulates a single neuron. It takes several input values, applies weights to them, sums them up, and passes the result through an activation function (usually a step or sigmoid function) to produce an output.\\n\\n### How it works\\n\\n1. **Inputs**: \\\\( x_1, x_2, ..., x_n \\\\)\\n2. **Weights**: \\\\( w_1, w_2, ..., w_n \\\\)\\n3. **Bias**: \\\\( b \\\\)\\n4. **Summation**: \\\\( z = w_1x_1 + w_2x_2 + ... + w_nx_n + b \\\\)\\n5. **Activation**: Output \\\\( y = f(z) \\\\), where \\\\( f \\\\) is typically a step function:  \\n   - If \\\\( z > 0 \\\\), output 1  \\n   - Else, output 0\\n\\n### Perceptron as a Linear Classifier\\nA perceptron is a **linear binary classifier**: it can decide whether an input, represented by a vector of numbers, belongs to one class or another.\\n\\n### Limitations\\n- **Only handles linearly separable data** (can’t solve problems like XOR).\\n- Modern neural networks use more complex architectures and activation functions.\\n\\n### Why is it important?\\n- The perceptron is the simplest form of a neural network and a foundational concept in understanding more complex networks.\\n\\n---\\n\\n**In summary:**  \\nA perceptron is a basic artificial neuron that classifies input data by computing a weighted sum and passing it through an activation function. It’s the cornerstone of neural network theory.', refusal=None, role='assistant', annotations=[], audio=None, function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_input = \"what is a perceptron?\"\n",
    "\n",
    "def chatbot(user_input):\n",
    "    # Convert the question to a query vector\n",
    "    query_vector = create_embeddings(user_input)\n",
    "\n",
    "    # Find the most similar documents\n",
    "    distances, indices = nbrs.kneighbors([query_vector])\n",
    "\n",
    "    # add documents to query  to provide context\n",
    "    history = []\n",
    "    for index in indices[0]:\n",
    "        history.append(flattened_df['chunks'].iloc[index])\n",
    "\n",
    "    # combine the history and the user input\n",
    "    history.append(user_input)\n",
    "\n",
    "    # create a message object\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI assiatant that helps with AI questions.\"},\n",
    "        {\"role\": \"user\", \"content\": history[-1]}\n",
    "    ]\n",
    "\n",
    "    # use chat completion to generate a response\n",
    "    response = client.chat.completions.create(\n",
    "        model=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"),\n",
    "        temperature=0.7,\n",
    "        max_tokens=800,\n",
    "        messages=messages\n",
    "    )\n",
    "\n",
    "    return response.choices[0].message\n",
    "\n",
    "chatbot(user_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing and evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A basic example of how you can use Mean Average Precision (MAP) to evaluate the responses of your model based on their relevance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# Define your test cases\n",
    "test_cases = [\n",
    "    {\n",
    "        \"query\": \"What is a perceptron?\",\n",
    "        \"relevant_responses\": [\"A perceptron is a type of artificial neuron.\", \"It's a binary classifier used in machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A perceptron is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is machine learning?\",\n",
    "        \"relevant_responses\": [\"Machine learning is a method of data analysis that automates analytical model building.\", \"It's a branch of artificial intelligence based on the idea that systems can learn from data, identify patterns and make decisions with minimal human intervention.\"],\n",
    "        \"irrelevant_responses\": [\"Machine learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is deep learning?\",\n",
    "        \"relevant_responses\": [\"Deep learning is a subset of machine learning in artificial intelligence (AI) that has networks capable of learning unsupervised from data that is unstructured or unlabeled.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"Deep learning is a type of fruit.\", \"It's a type of car.\"]\n",
    "    },\n",
    "    {\n",
    "        \"query\": \"What is a neural network?\",\n",
    "        \"relevant_responses\": [\"A neural network is a series of algorithms that endeavors to recognize underlying relationships in a set of data through a process that mimics the way the human brain operates.\", \"It's a type of machine learning.\"],\n",
    "        \"irrelevant_responses\": [\"A neural network is a type of fruit.\", \"It's a type of car.\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "# Initialize the total average precision\n",
    "total_average_precision = 0\n",
    "\n",
    "# Test the RAG application\n",
    "for test_case in test_cases:\n",
    "    query = test_case[\"query\"]\n",
    "    relevant_responses = test_case[\"relevant_responses\"]\n",
    "    irrelevant_responses = test_case[\"irrelevant_responses\"]\n",
    "\n",
    "    # Generate a response using your RAG application\n",
    "    response = chatbot(query) \n",
    "\n",
    "    # Create a list of all responses and a list of true binary labels\n",
    "    all_responses = relevant_responses + irrelevant_responses\n",
    "    true_labels = [1] * len(relevant_responses) + [0] * len(irrelevant_responses)\n",
    "\n",
    "    # Create a list of predicted scores based on whether the response is the generated response\n",
    "    predicted_scores = [1 if resp == response else 0 for resp in all_responses]\n",
    "\n",
    "    # Calculate the average precision for this query\n",
    "    average_precision = average_precision_score(true_labels, predicted_scores)\n",
    "\n",
    "    # Add the average precision to the total average precision\n",
    "    total_average_precision += average_precision\n",
    "\n",
    "# Calculate the mean average precision\n",
    "mean_average_precision = total_average_precision / len(test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
