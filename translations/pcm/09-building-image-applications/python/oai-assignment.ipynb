{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to Build App Wey Dey Generate Image\n",
    "\n",
    "LLMs no be only for text generation. Dem fit also use am generate image from text description. To get image as one modality fit dey very useful for plenty areas like MedTech, architecture, tourism, game development and more. For dis chapter, we go look two popular image generation models, DALL-E and Midjourney.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "For dis lesson, we go talk about:\n",
    "\n",
    "- How image generation dey useful.\n",
    "- DALL-E and Midjourney, wetin dem be, and how dem dey work.\n",
    "- How you fit take build app wey dey generate image.\n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "After you finish dis lesson, you go sabi:\n",
    "\n",
    "- Build app wey dey generate image.\n",
    "- Set boundary for your app with meta prompts.\n",
    "- Work with DALL-E and Midjourney.\n",
    "\n",
    "## Why you go wan build app wey dey generate image?\n",
    "\n",
    "App wey dey generate image na better way to test wetin Generative AI fit do. You fit use am for example:\n",
    "\n",
    "- **Image editing and synthesis**. You fit generate image for different use cases like editing or creating new image.\n",
    "\n",
    "- **Fit work for different industries**. You fit use am generate image for industries like MedTech, Tourism, Game development and plenty others.\n",
    "\n",
    "## Scenario: Edu4All\n",
    "\n",
    "For dis lesson, we go still dey work with our startup, Edu4All. The students go create images for their assessment. Wetin dem go create na their choice, e fit be illustration for their own fairytale, new character for their story, or help dem visualize their ideas and concepts.\n",
    "\n",
    "Example, if Edu4All students dey work for class on monuments, dem fit generate dis:\n",
    "\n",
    "![Edu4All startup, class on monuments, Eifel Tower](../../../../translated_images/startup.94d6b79cc4bb3f5a.pcm.png)\n",
    "\n",
    "with prompt like:\n",
    "\n",
    "> \"Dog next to Eiffel Tower in early morning sunlight\"\n",
    "\n",
    "## Wetin be DALL-E and Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) and [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) na two popular image generation models wey dey allow you use prompt generate image.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Make we start with DALL-E, e be Generative AI model wey dey generate image from text description.\n",
    "\n",
    "> [DALL-E na combination of two models, CLIP and diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP**, na model wey dey generate embeddings, wey be numerical representation of data, from image and text.\n",
    "\n",
    "- **Diffused attention**, na model wey dey generate image from embeddings. DALL-E dey trained with dataset of image and text, e fit generate image from text description. For example, DALL-E fit generate image of cat wey wear hat, or dog wey get mohawk.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney dey work like DALL-E, e dey generate image from text prompt. Midjourney fit also generate image with prompt like “cat wey wear hat”, or “dog wey get mohawk”.\n",
    "\n",
    "![Image generated by Midjourney, mechanical pigeon](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Image cred Wikipedia, image generated by Midjourney*\n",
    "\n",
    "## How DALL-E and Midjourney dey Work\n",
    "\n",
    "First, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E na Generative AI model wey dey use transformer architecture with *autoregressive transformer*.\n",
    "\n",
    "*Autoregressive transformer* dey define how model dey generate image from text description. E dey generate one pixel at a time, then e go use the pixel wey e don generate to generate the next one. E go pass through plenty layers for neural network until the image complete.\n",
    "\n",
    "With dis process, DALL-E fit control attributes, objects, characteristics, and more for the image wey e dey generate. But DALL-E 2 and 3 get more control over the image wey dem dey generate.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to build your first image generation app\n",
    "\n",
    "Wetin e go take to build image generation app? You go need dis libraries:\n",
    "\n",
    "- **python-dotenv**, e good make you use dis library to keep your secrets for *.env* file wey no dey inside code.\n",
    "- **openai**, na dis library you go use take connect with OpenAI API.\n",
    "- **pillow**, to work with images for Python.\n",
    "- **requests**, e go help you make HTTP requests.\n",
    "\n",
    "1. Create one file *.env* wey get dis content:\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Put all di libraries wey dey up for one file wey dem go call *requirements.txt* like dis:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. After dat, make virtual environment and install di libraries:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> For Windows, use dis commands to create and activate your virtual environment:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ````\n",
    "\n",
    "1. Add dis code for file wey dem call *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Make we explain dis code:\n",
    "\n",
    "- First, we dey import di libraries wey we need, like di OpenAI library, di dotenv library, di requests library, and di Pillow library.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- After dat, we go create di object wey go collect di API key from your ``.env``.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- Next, we go generate di image:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Di code wey dey up go respond wit JSON object wey get di URL of di image wey dem generate. We fit use di URL download di image and save am for file.\n",
    "\n",
    "- Last last, we go open di image and use di standard image viewer take show am:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### More details on how to generate di image\n",
    "\n",
    "Make we look di code wey dey generate di image well well:\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**, na di text wey dem dey use generate di image. For dis example, we dey use di prompt \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".\n",
    "- **size**, na di size of di image wey dem generate. For dis example, we dey generate image wey be 1024x1024 pixels.\n",
    "- **n**, na di number of images wey dem dey generate. For dis example, we dey generate two images.\n",
    "\n",
    "Plenty tins dey wey you fit do wit images, we go talk about dem for di next section.\n",
    "\n",
    "## Additional capabilities of image generation\n",
    "\n",
    "You don see how we fit generate image wit small Python code. But e get plenty tins wey you fit still do wit images.\n",
    "\n",
    "You fit do dis ones too:\n",
    "\n",
    "- **Perform edits**. If you provide one image wey don dey already, mask, and prompt, you fit change di image. For example, you fit add something for one part of di image. Imagine di bunny image, you fit add hat for di bunny head. How you go do am na to provide di image, mask (wey go show di part wey you wan change) and text prompt wey go talk wetin you wan make e happen.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    Di base image go only get di rabbit but di final image go get di hat for di rabbit head.\n",
    "    \n",
    "- **Create variations**. Di idea be say you go carry one image wey don dey already and ask make dem create different versions. To create variation, you go provide di image and text prompt and code like dis:\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:  \nDis dokyument don translate wit AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator). Even as we dey try make am accurate, abeg sabi say automated translations fit get mistake or no correct well. Di original dokyument for im native language na di main source wey you go trust. For important information, e good make professional human translation dey use. We no go fit take blame for any misunderstanding or wrong interpretation wey fit happen because you use dis translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-11-12T09:19:49+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "pcm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}