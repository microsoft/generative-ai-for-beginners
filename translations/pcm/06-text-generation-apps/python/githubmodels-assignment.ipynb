{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build text generation apps\n",
    "\n",
    "You don see say for dis curriculum, we get core concepts like prompts and even one whole discipline wey dem dey call \"prompt engineering\". Plenty tools wey you fit use like ChatGPT, Office 365, Microsoft Power Platform and others, dey support you to use prompts do something.\n",
    "\n",
    "For you to add dis kain experience for app, you go need understand concepts like prompts, completions and choose one library wey you go use. Na wetin you go learn for dis chapter be dat.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "For dis chapter, you go:\n",
    "\n",
    "- Learn about the openai library and the main concepts wey dey inside.\n",
    "- Build one text generation app wey dey use openai.\n",
    "- Understand how you fit use concepts like prompt, temperature, and tokens to build text generation app.\n",
    "\n",
    "## Learning goals\n",
    "\n",
    "By the end of dis lesson, you go fit:\n",
    "\n",
    "- Explain wetin text generation app be.\n",
    "- Build one text generation app wey dey use openai.\n",
    "- Configure your app to use more or less tokens and also change the temperature, so the output go dey different.\n",
    "\n",
    "## Wetin be text generation app?\n",
    "\n",
    "Normally, when you dey build app, e go get some kain interface like dis ones:\n",
    "\n",
    "- Command-based. Console apps na apps wey you go type command and e go do wetin you want. For example, `git` na command-based app.\n",
    "- User interface (UI). Some apps get graphical user interfaces (GUIs) wey you go fit click buttons, type text, select options and more.\n",
    "\n",
    "### Console and UI apps get limit\n",
    "\n",
    "Compare am to command-based app wey you dey type command:\n",
    "\n",
    "- **E get limit**. You no fit just type any command, na only the ones wey the app support you fit type.\n",
    "- **Language specific**. Some apps dey support many languages, but normally the app dey built for one specific language, even if you fit add more language support.\n",
    "\n",
    "### Benefits of text generation apps\n",
    "\n",
    "So, how text generation app dey different?\n",
    "\n",
    "For text generation app, you get more freedom, you no dey limited to set of commands or one specific input language. Instead, you fit use natural language interact with the app. Another benefit be say, because you dey interact with data source wey dem don train with plenty information, traditional app fit dey limited to wetin dey inside database.\n",
    "\n",
    "### Wetin I fit build with text generation app?\n",
    "\n",
    "Plenty things dey wey you fit build. For example:\n",
    "\n",
    "- **Chatbot**. Chatbot wey dey answer questions about topics, like your company and the products fit make sense.\n",
    "- **Helper**. LLMs dey good for things like summarizing text, getting insights from text, producing text like resumes and more.\n",
    "- **Code assistant**. Depending on the language model wey you dey use, you fit build code assistant wey go help you write code. For example, you fit use product like GitHub Copilot or ChatGPT to help you write code.\n",
    "\n",
    "## How I fit start?\n",
    "\n",
    "You go need find way to connect with LLM wey usually involve dis two approaches:\n",
    "\n",
    "- Use API. For here, you go dey construct web requests with your prompt and get generated text back.\n",
    "- Use library. Libraries dey help make API calls easy to use.\n",
    "\n",
    "## Libraries/SDKs\n",
    "\n",
    "Some popular libraries dey for working with LLMs like:\n",
    "\n",
    "- **openai**, dis library dey make am easy to connect to your model and send prompts.\n",
    "\n",
    "Then we get libraries wey dey operate for higher level like:\n",
    "\n",
    "- **Langchain**. Langchain dey popular and e dey support Python.\n",
    "- **Semantic Kernel**. Semantic Kernel na library wey Microsoft create wey dey support languages like C#, Python, and Java.\n",
    "\n",
    "## First app using GitHub Models Playground and Azure AI Inference SDK\n",
    "\n",
    "Make we see how we fit build our first app, wetin we need, how much work e go take and so on.\n",
    "\n",
    "### Wetin be GitHub Models?\n",
    "\n",
    "Welcome to [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Everything don ready for you to explore different AI Models wey dey hosted on Azure AI, all dey accessible through playground for GitHub or directly for your favorite code IDE, free to try.\n",
    "\n",
    "### Wetin I need?\n",
    "\n",
    "* GitHub Account: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Sign Up for GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Make we start!\n",
    "\n",
    "### Find model and test am\n",
    "\n",
    "Go [GitHub Models for Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![GitHub Models main screen showing a list of model cards such as Cohere, Meta llama, Mistral and GPT models](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.pcm.png)\n",
    "\n",
    "Choose one model - for example [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "For here you go see the model card. You fit:\n",
    "* Interact with the model for there by typing message for the text box\n",
    "* You fit read details about the model for the readme, Evaluation, Transparency and License tabs\n",
    "* Also check the 'About' section for the model access for the right side\n",
    "\n",
    "![GitHub Models GPT-4o Model Card](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.pcm.png)\n",
    "\n",
    "But we go go straight to the playground by clicking the ['Playground' button, top right](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). You fit interact with the model here, add system prompts and change parameter details - but also get all the code wey you need to run am from anywhere. Available as of September 2024: Python, Javascript, C# and REST.\n",
    "\n",
    "![GitHub Models Playground experience with code and languages shown](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.pcm.png)  \n",
    "\n",
    "### Make we use the model for our own IDE\n",
    "\n",
    "Two options dey here:\n",
    "1. **GitHub Codespaces** - e dey integrate well with Codespaces and you no need token to start\n",
    "2. **VS Code (or any favorite IDE)** - you go need [Personal Access Token from GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Anyhow, instructions dey provided through the 'Get started' green button for the top right.\n",
    "\n",
    "![Get Started screen showing you how to access Codespaces or use a personal access token to setup in your own IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.pcm.png)\n",
    "\n",
    "### 1.Codespaces \n",
    "\n",
    "* From the 'Get started' window choose \"Run codespace\"\n",
    "* Create new codespace (or use the one wey you don already get)\n",
    "* VS Code go open for your browser with set of sample notebooks for different languages wey you fit try\n",
    "* Run the sample ```./githubmodels-app.py```. \n",
    "\n",
    "> Note: For codespaces, you no need to set the Github Token variable, skip dis step\n",
    "\n",
    "**Now move to 'Generate Text' section below to continue dis assignment**\n",
    "\n",
    "### 2. VS Code (or any favorite IDE)\n",
    "\n",
    "From the 'Get started' green button you go get all the information wey you need to run for your favorite IDE. Dis example go show VS Code.\n",
    "\n",
    "* Select the language and SDK - for dis example we choose Python and Azure AI Inference SDK\n",
    "* Create personal access token for GitHub. E dey for Developer Settings section. You no need give any permissions to the token. Note say the token go dey sent to Microsoft service.\n",
    "* Create environment variable to store your Github personal access token - samples dey available for bash, powershell and windows command prompt\n",
    "* Install dependencies: ```pip install azure-ai-inference```\n",
    "* Copy basic sample code into one .py file\n",
    "* Navigate to where your code dey saved and run the file: ```python filename.py```\n",
    "\n",
    "No forget say by using Azure AI Inference SDK, you fit experiment with different models by changing the value of `model_name` for the code.\n",
    "\n",
    "Dis models dey available for GitHub Models service as of September 2024:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Now move to 'Generate Text' section below to continue dis assignment**\n",
    "\n",
    "## Generate text with ChatCompletions\n",
    "\n",
    "The way to generate text na to use `ChatCompletionsClient` class. \n",
    "For `samples/python/azure_ai_inference/basic.py`, for the response section of code, update the code the user role by changing the content parameter to below:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Run the updated file to see the output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different kain prompts, for different things\n",
    "\n",
    "Now you don see how to use prompt take generate text. You even get program wey dey run wey you fit modify and change to generate different kain text.\n",
    "\n",
    "Prompts fit dey use for plenty tasks. Example:\n",
    "\n",
    "- **Generate one kain text**. Like, you fit generate poem, questions for quiz, etc.\n",
    "- **Find information**. You fit use prompt find information like this example 'Wetin CORS mean for web development?'\n",
    "- **Generate code**. You fit use prompt generate code, like to create regular expression wey dey validate emails or even generate full program, like web app.\n",
    "\n",
    "## Exercise: Recipe generator\n",
    "\n",
    "Imagine say you get ingredients for house and you wan cook something. For that, you go need recipe. One way to find recipe na to use search engine or you fit use LLM do am.\n",
    "\n",
    "You fit write prompt like this:\n",
    "\n",
    "> \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "Based on the prompt wey dey above, you fit get response wey be like this:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "This result dey good, I don sabi wetin to cook. For this point, wetin fit make sense na:\n",
    "\n",
    "- Remove ingredients wey I no like or wey I dey allergic to.\n",
    "- Create shopping list, in case I no get all the ingredients for house.\n",
    "\n",
    "For the cases wey dey above, make we add another prompt:\n",
    "\n",
    "> \"Please remove recipes with garlic as I'm allergic and replace it with something else. Also, please produce a shopping list for the recipes, considering I already have chicken, potatoes and carrots at home.\"\n",
    "\n",
    "Now you go get new result, wey be:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Na your five recipes be that, garlic no dey inside and you get shopping list wey consider wetin you already get for house.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise - build recipe generator\n",
    "\n",
    "Now wey we don play one scenario, make we write code wey go match wetin we show for the scenario. To do am, follow dis steps:\n",
    "\n",
    "1. Use the file wey dey already as starting point\n",
    "1. Create one `prompt` variable and change the sample code like dis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you run di code now, you go see output wey be like:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, your LLM no dey do di same thing everytime, so you fit get different result anytime you run di program.\n",
    "\n",
    "Okay, make we see how we fit make am better. To make am better, we wan make sure say di code dey flexible, so say ingredients and number of recipes fit dey change and improve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Make we change di code like dis:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test di code, e fit look like dis:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Make am beta by add filter and shopping list\n",
    "\n",
    "Di app wey we don build dey work well, e fit produce recipe and e dey flexible because e dey depend on wetin di user put, both di number of recipe and di ingredient wey dem wan use.\n",
    "\n",
    "To make am beta, we wan add dis things:\n",
    "\n",
    "- **Remove ingredient wey we no want**. We wan fit remove ingredient wey we no like or wey we dey allergic to. To do dis change, we fit edit di prompt wey we don already get and add condition for di end like dis:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    For di example above, we add `{filter}` for di end of di prompt and we go also collect di filter value from di user.\n",
    "\n",
    "    Example of how di program go run now fit look like dis:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Make shopping list**. We wan make shopping list, we go consider wetin we don already get for house.\n",
    "\n",
    "    For dis functionality, we fit try solve everything for one prompt or we fit divide am into two prompts. Make we try di second way. For here, we dey suggest say make we add another prompt, but for dat one to work, we need to add di result of di first prompt as context for di second prompt.\n",
    "\n",
    "    Find di part for di code wey dey print di result from di first prompt and add dis code below:\n",
    "\n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "\n",
    "    Make you note dis things:\n",
    "\n",
    "    - We dey build new prompt by adding di result from di first prompt to di new prompt: \n",
    "    \n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - We dey make new request, but we go also consider di number of tokens we ask for di first prompt, so dis time we go talk say `max_tokens` na 1200. **About token length**. We suppose think about how many tokens we need to generate di text wey we want. Tokens dey cost money, so where e possible, we suppose try dey manage di number of tokens we dey use. For example, we fit arrange di prompt so we go use less tokens?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        As we dey test dis code, di output wey we go get go look like dis:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Try temperature**. Temperature na something we never talk about before but e dey important for how our program go perform. Di higher di temperature value, di more random di output go be. But if di temperature value dey low, di output go dey more predictable. Make you think whether you want variation for di output or not.\n",
    "\n",
    "   To change di temperature, you fit use di `temperature` parameter. For example, if you wan use temperature of 0.5, you go do am like dis:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Note, di closer e dey to 1.0, di more di output go dey different.\n",
    "\n",
    "\n",
    "## Assignment\n",
    "\n",
    "For dis assignment, you fit choose wetin you wan build.\n",
    "\n",
    "Here na some ideas:\n",
    "\n",
    "- Adjust di recipe generator app to make am beta. Play with di temperature values and di prompts to see wetin you fit come up with.\n",
    "- Build \"study buddy\". Dis app suppose fit answer question about one topic like Python, you fit get prompts like \"Wetin be one topic for Python?\", or you fit get prompt wey talk say, show me code for one topic etc.\n",
    "- History bot, make history dey alive, tell di bot to act like one historical person and ask am question about di person life and time.\n",
    "\n",
    "## Solution\n",
    "\n",
    "### Study buddy\n",
    "\n",
    "- \"You sabi Python language well well\n",
    "\n",
    "    Suggest beginner lesson for Python for dis format:\n",
    "    \n",
    "    Format:\n",
    "    - concepts:\n",
    "    - small explanation of di lesson:\n",
    "    - exercise for code with solution\"\n",
    "\n",
    "Di prompt above na starter, see how you fit use am and adjust am to how you like.\n",
    "\n",
    "### History bot\n",
    "\n",
    "Here na some prompts wey you fit use:\n",
    "\n",
    "- \"You be Abe Lincoln, tell me about yourself for 3 sentences, and answer like how Abe go talk\"\n",
    "- \"You be Abe Lincoln, answer like how Abe go talk:\n",
    "\n",
    "   Tell me about your biggest achievement, for 300 words:\"\n",
    "\n",
    "## Knowledge check\n",
    "\n",
    "Wetin di concept temperature dey do?\n",
    "\n",
    "1. E dey control how random di output go be.\n",
    "1. E dey control how big di response go be.\n",
    "1. E dey control how many tokens dem go use.\n",
    "\n",
    "A: 1\n",
    "\n",
    "Wetin be di best way to keep secrets like API keys?\n",
    "\n",
    "1. For code.\n",
    "1. For file.\n",
    "1. For environment variables.\n",
    "\n",
    "A: 3, because environment variables no dey inside code and di code fit load am.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:  \nDis dokyument don use AI transleshion service [Co-op Translator](https://github.com/Azure/co-op-translator) do di transleshion. Even as we dey try make am accurate, abeg make you sabi say automatik transleshion fit get mistake or no dey correct well. Di original dokyument wey dey for im native language na di one wey you go take as di correct source. For important mata, e good make you use professional human transleshion. We no go fit take blame for any misunderstanding or wrong interpretation wey go happen because you use dis transleshion.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-11-12T09:15:23+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "pcm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}