{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit run di following notebooks, if you never do am yet, you gats set di openai key inside .env file as `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we go load di Embedding Index inside one Pandas Dataframe. Di Embedding Index dey for one JSON file wey dem call `embedding_index_3m.json`. Di Embedding Index get di Embeddings for each YouTube transcripts wey reach late Oct 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we go create one function wey dem go call `get_videos` wey go search the Embedding Index for the query. The function go return the top 5 videos wey dey most similar to the query. The function dey work like this:\n",
    "\n",
    "1. First, dem go create one copy of the Embedding Index.\n",
    "2. Next, dem go calculate the Embedding for the query using the OpenAI Embedding API.\n",
    "3. Then dem go create one new column for the Embedding Index wey dem go call `similarity`. The `similarity` column get the cosine similarity between the query Embedding and the Embedding for each video segment.\n",
    "4. Next, dem go filter the Embedding Index by the `similarity` column. The Embedding Index go only get videos wey get cosine similarity wey big pass or equal to 0.75.\n",
    "5. Finally, dem go sort the Embedding Index by the `similarity` column and return the top 5 videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dis function na very simple one, e just dey print out di results of di search query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fes, di Embedding Index go load inside Pandas Dataframe.\n",
    "2. Next, di user go get prompt to enter query.\n",
    "3. Den di `get_videos` function go call to search di Embedding Index for di query.\n",
    "4. Last last, di `display_results` function go call to show di results to di user.\n",
    "5. Di user go den get prompt to enter anoda query. Dis process go continue until di user enter `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc.pcm.png)\n",
    "\n",
    "You go get prompt to enter query. Enter query and press enter. Di application go return list of videos wey relate to di query. Di application go also return link to di place for di video wey di answer to di question dey.\n",
    "\n",
    "Here na some queries to try out:\n",
    "\n",
    "- Wetin be Azure Machine Learning?\n",
    "- How convolutional neural networks dey work?\n",
    "- Wetin be neural network?\n",
    "- I fit use Jupyter Notebooks with Azure Machine Learning?\n",
    "- Wetin be ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:\nDis document na AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator) wey dem use translate am. Even though we dey try make am correct, abeg sabi say automated translation fit get some mistakes or no too correct. Di original document wey e dey for im own language na di correct one wey you suppose trust. If na serious matter, e better make person wey sabi translate am well do am. We no go responsible for any wahala or wrong understanding wey fit happen because of dis translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T12:20:15+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "pcm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}