{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit run di notebooks wey dey here, if you neva do am before, you go need put di openai key inside .env file as `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we go load di Embedding Index inside Pandas Dataframe. Di Embedding Index dey store for one JSON file wey dem call `embedding_index_3m.json`. Di Embedding Index get di Embeddings for each of di YouTube transcripts reach late Oct 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we go create one function wey we go call `get_videos` wey go search the Embedding Index for the query. The function go return the top 5 videos wey dey most similar to the query. The function dey work like dis:\n",
    "\n",
    "1. First, dem go create one copy of the Embedding Index.\n",
    "2. Next, dem go calculate the Embedding for the query using the OpenAI Embedding API.\n",
    "3. Then dem go create one new column for the Embedding Index wey dem go call `similarity`. The `similarity` column go get the cosine similarity between the query Embedding and the Embedding for each video segment.\n",
    "4. Next, dem go filter the Embedding Index by the `similarity` column. Dem go filter the Embedding Index to only include videos wey get cosine similarity wey big pass or equal to 0.75.\n",
    "5. Finally, dem go arrange the Embedding Index by the `similarity` column and return the top 5 videos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dis function dey very simple, e just dey show di result of di search query.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. First, dem go load di Embedding Index inside Pandas Dataframe.\n",
    "2. Next, di user go dey ask to type query.\n",
    "3. Then, dem go call di `get_videos` function to search di Embedding Index for di query.\n",
    "4. Finally, dem go call di `display_results` function to show di results to di user.\n",
    "5. Di user go dey ask again to type another query. Dis process go continue until di user type `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.pcm.png)\n",
    "\n",
    "Dem go ask you to type query. Type di query and press enter. Di app go show you list of videos wey relate to di query. Di app go also show link to di part for di video wey get di answer to di question.\n",
    "\n",
    "Try dis queries:\n",
    "\n",
    "- Wetin be Azure Machine Learning?\n",
    "- How convolutional neural networks dey work?\n",
    "- Wetin be neural network?\n",
    "- I fit use Jupyter Notebooks with Azure Machine Learning?\n",
    "- Wetin be ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Disclaimer**:  \nDis dokyument don use AI translation service [Co-op Translator](https://github.com/Azure/co-op-translator) do di translation. Even though we dey try make am correct, abeg make you sabi say machine translation fit get mistake or no dey accurate well. Di original dokyument wey dey for di native language na di main source wey you go trust. For important information, e better make professional human translator check am. We no go fit take blame for any misunderstanding or wrong interpretation wey fit happen because you use dis translation.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "2c0494ceb4f5fc618a6abda0b5c09c73",
   "translation_date": "2025-11-12T09:12:38+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "pcm"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}