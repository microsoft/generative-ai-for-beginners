{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# บทที่ 7: สร้างแอปพลิเคชันแชท\n",
    "## เริ่มต้นใช้งาน OpenAI API\n",
    "\n",
    "สมุดบันทึกนี้ดัดแปลงมาจาก [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) ซึ่งมีสมุดบันทึกสำหรับเข้าถึงบริการ [Azure OpenAI](notebook-azure-openai.ipynb)\n",
    "\n",
    "OpenAI API สำหรับภาษา Python สามารถใช้งานร่วมกับโมเดลของ Azure OpenAI ได้เช่นกัน โดยมีการปรับแต่งเล็กน้อย ดูรายละเอียดเกี่ยวกับความแตกต่างเพิ่มเติมได้ที่นี่: [วิธีสลับใช้งานระหว่าง OpenAI และ Azure OpenAI endpoints ด้วย Python](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# ภาพรวม  \n",
    "\"โมเดลภาษาใหญ่คือฟังก์ชันที่แปลงข้อความหนึ่งไปเป็นข้อความอีกข้อความหนึ่ง เมื่อได้รับข้อความอินพุต โมเดลภาษาใหญ่จะพยายามทำนายข้อความถัดไปที่จะตามมา\" (1) โน้ตบุ๊ก \"เริ่มต้นอย่างรวดเร็ว\" นี้จะพาผู้ใช้ไปรู้จักกับแนวคิดหลักของ LLM ข้อกำหนดแพ็กเกจสำคัญสำหรับการเริ่มต้นใช้งาน AML แนะนำเบื้องต้นเกี่ยวกับการออกแบบพรอมต์ และตัวอย่างสั้น ๆ ของการใช้งานในรูปแบบต่าง ๆ\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## สารบัญ  \n",
    "\n",
    "[ภาพรวม](../../../../07-building-chat-applications/python)  \n",
    "[วิธีใช้งาน OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[1. การสร้าง OpenAI Service ของคุณ](../../../../07-building-chat-applications/python)  \n",
    "[2. การติดตั้ง](../../../../07-building-chat-applications/python)    \n",
    "[3. ข้อมูลรับรอง](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[กรณีการใช้งาน](../../../../07-building-chat-applications/python)    \n",
    "[1. สรุปข้อความ](../../../../07-building-chat-applications/python)  \n",
    "[2. จัดประเภทข้อความ](../../../../07-building-chat-applications/python)  \n",
    "[3. สร้างชื่อสินค้าขึ้นมาใหม่](../../../../07-building-chat-applications/python)  \n",
    "[4. ปรับแต่งตัวจัดประเภท](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[แหล่งอ้างอิง](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### สร้างพรอมต์แรกของคุณ  \n",
    "แบบฝึกหัดสั้น ๆ นี้จะเป็นการแนะนำพื้นฐานสำหรับการส่งพรอมต์ไปยังโมเดลของ OpenAI เพื่อทำงานง่าย ๆ อย่าง \"สรุปเนื้อหา\"\n",
    "\n",
    "**ขั้นตอน**:  \n",
    "1. ติดตั้งไลบรารี OpenAI ในสภาพแวดล้อม python ของคุณ  \n",
    "2. โหลดไลบรารีช่วยเหลือมาตรฐานและตั้งค่าข้อมูลรับรองความปลอดภัยของ OpenAI สำหรับบริการ OpenAI ที่คุณสร้างไว้  \n",
    "3. เลือกโมเดลสำหรับงานของคุณ  \n",
    "4. สร้างพรอมต์ง่าย ๆ สำหรับโมเดล  \n",
    "5. ส่งคำขอของคุณไปยัง API ของโมเดล!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. การเลือกโมเดลที่เหมาะสม  \n",
    "โมเดล GPT-3.5-turbo หรือ GPT-4 สามารถเข้าใจและสร้างข้อความภาษาธรรมชาติได้\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. การออกแบบพรอมต์  \n",
    "\n",
    "\"ความมหัศจรรย์ของโมเดลภาษาใหญ่คือ เมื่อถูกฝึกให้ลดข้อผิดพลาดในการทำนายจากข้อความจำนวนมหาศาล โมเดลจะได้เรียนรู้แนวคิดที่เป็นประโยชน์ต่อการทำนายเหล่านี้ ตัวอย่างเช่น โมเดลจะได้เรียนรู้แนวคิดอย่างเช่น\"(1):\n",
    "\n",
    "* การสะกดคำ\n",
    "* หลักไวยากรณ์\n",
    "* การเขียนใหม่ให้ความหมายเหมือนเดิม\n",
    "* การตอบคำถาม\n",
    "* การสนทนา\n",
    "* การเขียนได้หลายภาษา\n",
    "* การเขียนโค้ด\n",
    "* ฯลฯ\n",
    "\n",
    "#### วิธีควบคุมโมเดลภาษาใหญ่  \n",
    "\"ในบรรดาข้อมูลนำเข้าทั้งหมดของโมเดลภาษาใหญ่ ข้อความพรอมต์มีอิทธิพลมากที่สุด\"(1)\n",
    "\n",
    "โมเดลภาษาใหญ่สามารถถูกกระตุ้นให้สร้างผลลัพธ์ได้หลายวิธี เช่น:\n",
    "\n",
    "Instruction: บอกโมเดลว่าคุณต้องการอะไร\n",
    "Completion: กระตุ้นให้โมเดลเขียนต่อจากจุดเริ่มต้นที่คุณต้องการ\n",
    "Demonstration: แสดงให้โมเดลเห็นว่าคุณต้องการอะไร โดยใช้:\n",
    "ตัวอย่างไม่กี่ตัวในพรอมต์\n",
    "ตัวอย่างจำนวนมากในชุดข้อมูลฝึกแบบ fine-tuning\n",
    "\n",
    "\n",
    "\n",
    "#### มีแนวทางพื้นฐาน 3 ข้อในการสร้างพรอมต์:\n",
    "\n",
    "**แสดงและบอก**. ทำให้ชัดเจนว่าคุณต้องการอะไร ไม่ว่าจะผ่านคำสั่ง ตัวอย่าง หรือทั้งสองอย่างผสมกัน ถ้าคุณต้องการให้โมเดลจัดอันดับรายการตามตัวอักษร หรือจัดหมวดหมู่ย่อหน้าตามอารมณ์ ให้แสดงให้เห็นว่านี่คือสิ่งที่คุณต้องการ\n",
    "\n",
    "**ให้ข้อมูลที่มีคุณภาพ**. ถ้าคุณพยายามสร้างตัวจำแนกประเภท หรืออยากให้โมเดลทำตามรูปแบบที่ต้องการ ต้องแน่ใจว่ามีตัวอย่างเพียงพอ อย่าลืมตรวจทานตัวอย่างของคุณด้วย — โมเดลมักจะฉลาดพอที่จะมองข้ามข้อผิดพลาดการสะกดคำพื้นฐานและตอบกลับได้ แต่บางครั้งอาจคิดว่าคุณตั้งใจและอาจส่งผลต่อคำตอบ\n",
    "\n",
    "**ตรวจสอบการตั้งค่า**. การตั้งค่า temperature และ top_p จะควบคุมว่าโมเดลจะตอบแบบแน่นอนแค่ไหน ถ้าคุณต้องการคำตอบที่มีเพียงคำตอบเดียวที่ถูกต้อง ควรตั้งค่าให้น้อยลง แต่ถ้าต้องการคำตอบที่หลากหลายมากขึ้น อาจตั้งค่าสูงขึ้น ข้อผิดพลาดที่พบบ่อยที่สุดคือคิดว่าการตั้งค่านี้เป็นตัวควบคุม \"ความฉลาด\" หรือ \"ความคิดสร้างสรรค์\"\n",
    "\n",
    "\n",
    "ที่มา: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## สรุปข้อความ  \n",
    "#### ความท้าทาย  \n",
    "สรุปข้อความโดยการเพิ่ม 'tl;dr:' ต่อท้ายข้อความ ดูว่าระบบสามารถเข้าใจและทำงานหลายอย่างได้โดยไม่ต้องมีคำสั่งเพิ่มเติม คุณสามารถลองใช้ prompt ที่อธิบายละเอียดกว่านี้แทน tl;dr เพื่อปรับพฤติกรรมของโมเดลและปรับแต่งการสรุปที่คุณต้องการได้(3)  \n",
    "\n",
    "งานวิจัยล่าสุดแสดงให้เห็นว่าการฝึกโมเดลด้วยข้อมูลข้อความขนาดใหญ่ก่อน แล้วจึงปรับแต่งกับงานเฉพาะ ช่วยให้ได้ผลลัพธ์ที่ดีขึ้นในหลายงานและเกณฑ์วัดของ NLP แม้สถาปัตยกรรมจะไม่ได้ผูกกับงานใดงานหนึ่ง แต่ก็ยังต้องใช้ชุดข้อมูลสำหรับปรับแต่งที่มีตัวอย่างนับพันหรือนับหมื่น ในทางตรงข้าม มนุษย์มักจะทำงานภาษาใหม่ ๆ ได้จากตัวอย่างเพียงไม่กี่ตัวอย่างหรือแค่คำอธิบายง่าย ๆ ซึ่งระบบ NLP ปัจจุบันยังทำได้ไม่ดีนัก ที่นี่เราจะแสดงให้เห็นว่าการขยายขนาดโมเดลภาษา ช่วยเพิ่มประสิทธิภาพแบบไม่ผูกกับงานและแบบ few-shot ได้มากขึ้น บางครั้งก็สามารถแข่งขันกับวิธีการปรับแต่งที่ดีที่สุดในอดีตได้เลย\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# แบบฝึกหัดสำหรับหลายกรณีการใช้งาน  \n",
    "1. สรุปข้อความ  \n",
    "2. จัดประเภทข้อความ  \n",
    "3. สร้างชื่อสินค้ารูปแบบใหม่\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## จัดหมวดหมู่ข้อความ  \n",
    "#### ความท้าทาย  \n",
    "จัดหมวดหมู่รายการต่าง ๆ ให้อยู่ในหมวดหมู่ที่กำหนดไว้ในขณะที่ทำการประมวลผล ในตัวอย่างต่อไปนี้ เราจะระบุทั้งหมวดหมู่และข้อความที่ต้องการจัดหมวดหมู่ไว้ในพรอมต์ (*playground_reference)\n",
    "\n",
    "คำถามจากลูกค้า: สวัสดีค่ะ ปุ่มบนคีย์บอร์ดแล็ปท็อปของฉันหักไปหนึ่งปุ่มเมื่อไม่นานมานี้ และฉันต้องการเปลี่ยนใหม่:\n",
    "\n",
    "หมวดหมู่ที่จัดไว้:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## สร้างชื่อสินค้ารูปแบบใหม่\n",
    "#### โจทย์\n",
    "สร้างชื่อสินค้าจากคำตัวอย่างที่ให้มา ในคำสั่งนี้จะมีข้อมูลเกี่ยวกับสินค้าที่เราต้องการตั้งชื่อให้ พร้อมตัวอย่างที่คล้ายกันเพื่อแสดงรูปแบบที่ต้องการ นอกจากนี้ยังตั้งค่า temperature สูงเพื่อให้ได้คำตอบที่หลากหลายและสร้างสรรค์มากขึ้น\n",
    "\n",
    "รายละเอียดสินค้า: เครื่องทำมิลค์เชคสำหรับใช้ในบ้าน\n",
    "คำตัวอย่าง: รวดเร็ว, สุขภาพดี, กะทัดรัด\n",
    "ชื่อสินค้า: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "รายละเอียดสินค้า: รองเท้าที่สามารถปรับขนาดให้พอดีกับเท้าได้ทุกขนาด\n",
    "คำตัวอย่าง: ปรับเปลี่ยนได้, พอดี, omni-fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# แหล่งข้อมูลอ้างอิง  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [ตัวอย่างจาก OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [แนวทางปฏิบัติที่ดีที่สุดสำหรับการปรับแต่ง GPT-3 เพื่อจัดประเภทข้อความ](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# สำหรับความช่วยเหลือเพิ่มเติม  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# ผู้ร่วมเขียน\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ข้อจำกัดความรับผิดชอบ**:  \nเอกสารฉบับนี้ได้รับการแปลโดยใช้บริการแปลภาษา AI [Co-op Translator](https://github.com/Azure/co-op-translator) แม้ว่าเราจะพยายามอย่างเต็มที่เพื่อความถูกต้อง แต่โปรดทราบว่าการแปลโดยอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นทางควรถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่มีความสำคัญ แนะนำให้ใช้บริการแปลโดยนักแปลมืออาชีพ ทางเราจะไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความที่คลาดเคลื่อนซึ่งเกิดจากการใช้การแปลนี้\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:17:47+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "th"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}