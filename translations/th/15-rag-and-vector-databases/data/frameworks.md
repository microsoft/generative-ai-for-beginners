<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:32:19+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "th"
}
-->
# Neural Network Frameworks

อย่างที่เราได้เรียนรู้ไปแล้ว เพื่อให้สามารถฝึกสอน neural networks ได้อย่างมีประสิทธิภาพ เราจำเป็นต้องทำสองอย่างนี้:

* การทำงานกับ tensors เช่น การคูณ การบวก และการคำนวณฟังก์ชันบางอย่าง เช่น sigmoid หรือ softmax
* การคำนวณ gradients ของนิพจน์ทั้งหมด เพื่อใช้ในการทำ gradient descent optimization

แม้ว่าไลบรารี `numpy` จะทำงานส่วนแรกได้ แต่เราต้องการกลไกบางอย่างในการคำนวณ gradients ในเฟรมเวิร์กที่เราพัฒนาขึ้นในส่วนก่อนหน้านี้ เราต้องเขียนฟังก์ชันอนุพันธ์ทั้งหมดด้วยตนเองภายในเมธอด `backward` ซึ่งทำหน้าที่ backpropagation โดยในอุดมคติ เฟรมเวิร์กควรเปิดโอกาสให้เราคำนวณ gradients ของ *นิพจน์ใดๆ* ที่เรากำหนดได้

อีกสิ่งสำคัญคือความสามารถในการประมวลผลบน GPU หรือหน่วยประมวลผลเฉพาะทางอื่นๆ เช่น TPU การฝึกสอน deep neural networks ต้องการการคำนวณจำนวนมาก และการกระจายการคำนวณเหล่านั้นบน GPUs จึงมีความสำคัญอย่างยิ่ง

> ✅ คำว่า 'parallelize' หมายถึงการกระจายการคำนวณไปยังอุปกรณ์หลายตัวพร้อมกัน

ปัจจุบัน เฟรมเวิร์ก neural network ที่ได้รับความนิยมสูงสุดสองตัวคือ TensorFlow และ PyTorch ทั้งสองมี API ระดับต่ำสำหรับการทำงานกับ tensors บน CPU และ GPU นอกจากนี้ยังมี API ระดับสูงที่เรียกว่า Keras และ PyTorch Lightning ตามลำดับ

Low-Level API | TensorFlow| PyTorch
--------------|-------------------------------------|--------------------------------
High-level API| Keras| Pytorch

**Low-level APIs** ในทั้งสองเฟรมเวิร์กช่วยให้คุณสร้างที่เรียกว่า **computational graphs** กราฟนี้กำหนดวิธีการคำนวณผลลัพธ์ (โดยปกติคือฟังก์ชัน loss) จากพารามิเตอร์อินพุต และสามารถส่งไปประมวลผลบน GPU ได้หากมี ฟังก์ชันเหล่านี้สามารถทำการอนุพันธ์กราฟและคำนวณ gradients ซึ่งนำไปใช้ในการปรับแต่งพารามิเตอร์ของโมเดลได้

**High-level APIs** มอง neural networks เป็น **ลำดับของเลเยอร์** และช่วยให้การสร้าง neural networks ส่วนใหญ่ทำได้ง่ายขึ้นมาก การฝึกสอนโมเดลมักจะต้องเตรียมข้อมูลก่อน แล้วเรียกใช้ฟังก์ชัน `fit` เพื่อทำงาน

API ระดับสูงช่วยให้คุณสร้าง neural networks ทั่วไปได้อย่างรวดเร็วโดยไม่ต้องกังวลกับรายละเอียดมากมาย ในขณะที่ API ระดับต่ำให้การควบคุมกระบวนการฝึกสอนได้มากกว่า จึงมักถูกใช้ในงานวิจัยเมื่อคุณต้องจัดการกับสถาปัตยกรรม neural network ใหม่ๆ

นอกจากนี้ยังสำคัญที่ต้องเข้าใจว่าคุณสามารถใช้ทั้งสอง API ร่วมกันได้ เช่น คุณสามารถพัฒนาเลเยอร์ของเครือข่ายด้วย API ระดับต่ำ แล้วนำไปใช้ในเครือข่ายขนาดใหญ่ที่สร้างและฝึกด้วย API ระดับสูง หรือคุณอาจกำหนดเครือข่ายด้วย API ระดับสูงเป็นลำดับของเลเยอร์ แล้วใช้ลูปฝึกสอนระดับต่ำของคุณเองในการปรับแต่ง ทั้งสอง API ใช้แนวคิดพื้นฐานเดียวกันและออกแบบมาให้ทำงานร่วมกันได้ดี

## Learning

ในคอร์สนี้ เรามีเนื้อหาสำหรับทั้ง PyTorch และ TensorFlow คุณสามารถเลือกเฟรมเวิร์กที่ชอบและเรียนรู้จากโน้ตบุ๊กที่เกี่ยวข้องเท่านั้น หากไม่แน่ใจว่าจะเลือกเฟรมเวิร์กไหน ลองอ่านบทสนทนาในอินเทอร์เน็ตเกี่ยวกับ **PyTorch vs. TensorFlow** หรือดูทั้งสองเฟรมเวิร์กเพื่อเข้าใจมากขึ้น

เมื่อเป็นไปได้ เราจะใช้ High-Level APIs เพื่อความง่าย แต่เราเชื่อว่าการเข้าใจการทำงานของ neural networks ตั้งแต่พื้นฐานเป็นสิ่งสำคัญ ดังนั้นในช่วงแรกเราจะเริ่มจากการทำงานกับ low-level API และ tensors แต่ถ้าคุณต้องการเริ่มต้นอย่างรวดเร็วและไม่อยากเสียเวลามากกับรายละเอียดเหล่านี้ คุณสามารถข้ามไปที่โน้ตบุ๊กของ high-level API ได้เลย

## ✍️ Exercises: Frameworks

เรียนรู้ต่อในโน้ตบุ๊กต่อไปนี้:

Low-Level API | TensorFlow+Keras Notebook | PyTorch
--------------|-------------------------------------|--------------------------------
High-level API| Keras | *PyTorch Lightning*

หลังจากที่เชี่ยวชาญเฟรมเวิร์กแล้ว เรามาทบทวนแนวคิดเรื่อง overfitting กัน

# Overfitting

Overfitting เป็นแนวคิดที่สำคัญมากใน machine learning และต้องเข้าใจให้ถูกต้อง!

ลองพิจารณาปัญหาการประมาณค่า 5 จุด (แทนด้วย `x` บนกราฟด้านล่าง):

!linear | overfit
-------------------------|--------------------------
**Linear model, 2 parameters** | **Non-linear model, 7 parameters**
Training error = 5.3 | Training error = 0
Validation error = 5.1 | Validation error = 20

* ด้านซ้าย เราเห็นการประมาณเส้นตรงที่ดี เพราะจำนวนพารามิเตอร์เหมาะสม โมเดลจึงจับแนวทางการกระจายจุดได้ถูกต้อง
* ด้านขวา โมเดลมีความซับซ้อนเกินไป เนื่องจากมีแค่ 5 จุดแต่โมเดลมี 7 พารามิเตอร์ จึงสามารถปรับให้ผ่านทุกจุดได้ ทำให้ training error เป็น 0 แต่โมเดลไม่เข้าใจรูปแบบที่แท้จริงของข้อมูล จึงทำให้ validation error สูงมาก

จึงสำคัญมากที่จะต้องหาสมดุลที่เหมาะสมระหว่างความซับซ้อนของโมเดล (จำนวนพารามิเตอร์) กับจำนวนตัวอย่างฝึกสอน

## Why overfitting occurs

  * ข้อมูลฝึกสอนไม่เพียงพอ
  * โมเดลมีความซับซ้อนเกินไป
  * มีสัญญาณรบกวนในข้อมูลอินพุตมากเกินไป

## How to detect overfitting

จากกราฟข้างต้น เราจะตรวจจับ overfitting ได้จาก training error ที่ต่ำมาก แต่ validation error สูง ปกติระหว่างการฝึกสอน training และ validation error จะลดลงพร้อมกัน แต่บางจุด validation error อาจหยุดลดและเริ่มเพิ่มขึ้น นี่คือสัญญาณของ overfitting และบ่งชี้ว่าเราควรหยุดการฝึกสอน ณ จุดนี้ (หรืออย่างน้อยก็เก็บ snapshot ของโมเดลไว้)

overfitting

## How to prevent overfitting

ถ้าคุณเห็นว่าเกิด overfitting ขึ้น คุณสามารถทำอย่างใดอย่างหนึ่งต่อไปนี้:

 * เพิ่มจำนวนข้อมูลฝึกสอน
 * ลดความซับซ้อนของโมเดล
 * ใช้เทคนิค regularization เช่น Dropout ซึ่งเราจะพูดถึงในภายหลัง

## Overfitting and Bias-Variance Tradeoff

Overfitting เป็นกรณีหนึ่งของปัญหาทั่วไปในสถิติที่เรียกว่า Bias-Variance Tradeoff ถ้าเราพิจารณาแหล่งที่มาของข้อผิดพลาดในโมเดล เราจะเห็นข้อผิดพลาดสองประเภท:

* **Bias errors** เกิดจากอัลกอริทึมของเราไม่สามารถจับความสัมพันธ์ในข้อมูลฝึกสอนได้อย่างถูกต้อง อาจเกิดจากโมเดลไม่ซับซ้อนพอ (**underfitting**)
* **Variance errors** เกิดจากโมเดลประมาณสัญญาณรบกวนในข้อมูลอินพุตแทนที่จะเป็นความสัมพันธ์ที่มีความหมาย (**overfitting**)

ระหว่างการฝึกสอน bias error จะลดลง (เมื่อโมเดลเรียนรู้ที่จะประมาณข้อมูล) ในขณะที่ variance error จะเพิ่มขึ้น จึงสำคัญที่จะหยุดการฝึกสอน - ไม่ว่าจะด้วยตนเอง (เมื่อพบ overfitting) หรืออัตโนมัติ (โดยใช้ regularization) - เพื่อป้องกัน overfitting

## Conclusion

ในบทเรียนนี้ คุณได้เรียนรู้ความแตกต่างระหว่าง API ต่างๆ ของสองเฟรมเวิร์ก AI ที่ได้รับความนิยมสูงสุด คือ TensorFlow และ PyTorch นอกจากนี้ยังได้เรียนรู้เรื่องสำคัญอย่าง overfitting

## 🚀 Challenge

ในโน้ตบุ๊กประกอบ คุณจะพบ 'tasks' ที่ส่วนล่างของแต่ละโน้ตบุ๊ก ให้ทำตามและทำงานให้ครบถ้วน

## Review & Self Study

ค้นคว้าเพิ่มเติมในหัวข้อต่อไปนี้:

- TensorFlow
- PyTorch
- Overfitting

ถามตัวเองด้วยคำถามเหล่านี้:

- ความแตกต่างระหว่าง TensorFlow กับ PyTorch คืออะไร?
- ความแตกต่างระหว่าง overfitting กับ underfitting คืออะไร?

## Assignment

ในแลปนี้ คุณจะได้รับโจทย์ให้แก้ปัญหาการจำแนกประเภทสองปัญหาโดยใช้เครือข่าย fully-connected แบบชั้นเดียวและหลายชั้น โดยใช้ PyTorch หรือ TensorFlow

**ข้อจำกัดความรับผิดชอบ**:  
เอกสารนี้ได้รับการแปลโดยใช้บริการแปลภาษาอัตโนมัติ [Co-op Translator](https://github.com/Azure/co-op-translator) แม้เราจะพยายามให้ความถูกต้องสูงสุด แต่โปรดทราบว่าการแปลอัตโนมัติอาจมีข้อผิดพลาดหรือความไม่ถูกต้อง เอกสารต้นฉบับในภาษาต้นทางถือเป็นแหล่งข้อมูลที่เชื่อถือได้ สำหรับข้อมูลที่สำคัญ ขอแนะนำให้ใช้บริการแปลโดยผู้เชี่ยวชาญมนุษย์ เราไม่รับผิดชอบต่อความเข้าใจผิดหรือการตีความผิดใด ๆ ที่เกิดจากการใช้การแปลนี้