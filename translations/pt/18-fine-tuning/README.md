<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T17:45:46+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "pt"
}
-->
[![Open Source Models](../../../../../translated_images/pt-PT/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Ajuste Fino do Seu LLM

Usar grandes modelos de linguagem para construir aplica√ß√µes de IA generativa traz novos desafios. Uma quest√£o chave √© garantir a qualidade da resposta (exatid√£o e relev√¢ncia) no conte√∫do gerado pelo modelo para um dado pedido do utilizador. Nas li√ß√µes anteriores, discutimos t√©cnicas como engenharia de prompts e gera√ß√£o aumentada por recupera√ß√£o que tentam resolver o problema ao _modificar a entrada do prompt_ para o modelo existente.

Na li√ß√£o de hoje, discutimos uma terceira t√©cnica, o **ajuste fino**, que tenta abordar o desafio _re-treinando o pr√≥prio modelo_ com dados adicionais. Vamos entrar em detalhes.

## Objetivos de Aprendizagem

Esta li√ß√£o introduz o conceito de ajuste fino para modelos de linguagem pr√©-treinados, explora os benef√≠cios e desafios desta abordagem, e fornece orienta√ß√µes sobre quando e como usar o ajuste fino para melhorar o desempenho dos seus modelos de IA generativa.

No final desta li√ß√£o, dever√° ser capaz de responder √†s seguintes perguntas:

- O que √© ajuste fino para modelos de linguagem?
- Quando, e porqu√™, o ajuste fino √© √∫til?
- Como posso ajustar um modelo pr√©-treinado?
- Quais s√£o as limita√ß√µes do ajuste fino?

Pronto? Vamos come√ßar.

## Guia Ilustrado

Quer ter uma vis√£o geral do que vamos cobrir antes de come√ßarmos? Veja este guia ilustrado que descreve a jornada de aprendizagem para esta li√ß√£o - desde aprender os conceitos essenciais e a motiva√ß√£o para o ajuste fino, at√© entender o processo e as melhores pr√°ticas para executar a tarefa de ajuste fino. Este √© um t√≥pico fascinante para explora√ß√£o, por isso n√£o se esque√ßa de consultar a p√°gina de [Recursos](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) para links adicionais que apoiem a sua aprendizagem aut√≥noma!

![Illustrated Guide to Fine Tuning Language Models](../../../../../translated_images/pt-PT/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## O que √© ajuste fino para modelos de linguagem?

Por defini√ß√£o, grandes modelos de linguagem s√£o _pr√©-treinados_ com grandes quantidades de texto provenientes de fontes diversas, incluindo a internet. Como aprendemos nas li√ß√µes anteriores, precisamos de t√©cnicas como _engenharia de prompts_ e _gera√ß√£o aumentada por recupera√ß√£o_ para melhorar a qualidade das respostas do modelo √†s perguntas do utilizador ("prompts").

Uma t√©cnica popular de engenharia de prompts envolve dar ao modelo mais orienta√ß√£o sobre o que √© esperado na resposta, seja fornecendo _instru√ß√µes_ (orienta√ß√£o expl√≠cita) ou _dando-lhe alguns exemplos_ (orienta√ß√£o impl√≠cita). Isto √© referido como _few-shot learning_ mas tem duas limita√ß√µes:

- Os limites de tokens do modelo podem restringir o n√∫mero de exemplos que pode dar, limitando a efic√°cia.
- Os custos de tokens do modelo podem tornar caro adicionar exemplos a cada prompt, limitando a flexibilidade.

O ajuste fino √© uma pr√°tica comum em sistemas de aprendizagem autom√°tica onde pegamos num modelo pr√©-treinado e re-treinamo-lo com novos dados para melhorar o seu desempenho numa tarefa espec√≠fica. No contexto dos modelos de linguagem, podemos ajustar o modelo pr√©-treinado _com um conjunto selecionado de exemplos para uma dada tarefa ou dom√≠nio de aplica√ß√£o_ para criar um **modelo personalizado** que pode ser mais preciso e relevante para essa tarefa ou dom√≠nio espec√≠fico. Um benef√≠cio adicional do ajuste fino √© que pode tamb√©m reduzir o n√∫mero de exemplos necess√°rios para few-shot learning - reduzindo o uso de tokens e custos relacionados.

## Quando e porqu√™ devemos ajustar os modelos?

Neste _contexto_, quando falamos de ajuste fino, referimo-nos ao ajuste fino **supervisionado** onde o re-treinamento √© feito por **adicionar novos dados** que n√£o faziam parte do conjunto de dados original de treino. Isto √© diferente de uma abordagem n√£o supervisionada de ajuste fino, onde o modelo √© re-treinado nos dados originais, mas com hiperpar√¢metros diferentes.

A coisa importante a lembrar √© que o ajuste fino √© uma t√©cnica avan√ßada que requer um certo n√≠vel de especializa√ß√£o para obter os resultados desejados. Se feito incorretamente, pode n√£o fornecer as melhorias esperadas, e at√© deteriorar o desempenho do modelo para o seu dom√≠nio alvo.

Por isso, antes de aprender "como" ajustar modelos de linguagem, precisa de saber "porqu√™" deve tomar este caminho, e "quando" iniciar o processo de ajuste fino. Comece por fazer a si mesmo estas perguntas:

- **Caso de Uso**: Qual √© o seu _caso de uso_ para o ajuste fino? Que aspeto do modelo pr√©-treinado atual quer melhorar?
- **Alternativas**: J√° experimentou _outras t√©cnicas_ para alcan√ßar os resultados desejados? Use-as para criar uma linha base de compara√ß√£o.
  - Engenharia de prompts: Experimente t√©cnicas como few-shot prompting com exemplos de respostas relevantes. Avalie a qualidade das respostas.
  - Gera√ß√£o Aumentada por Recupera√ß√£o: Experimente aumentar os prompts com resultados de pesquisa do seu dado. Avalie a qualidade das respostas.
- **Custos**: Identificou os custos do ajuste fino?
  - Possibilidade de ajuste - o modelo pr√©-treinado est√° dispon√≠vel para ajuste fino?
  - Esfor√ßo - para preparar dados de treino, avaliar e refinar o modelo.
  - Computa√ß√£o - para executar trabalhos de ajuste fino e implementar o modelo ajustado.
  - Dados - acesso a exemplos de qualidade suficiente para impacto do ajuste fino.
- **Benef√≠cios**: Confirmou os benef√≠cios do ajuste fino?
  - Qualidade - o modelo ajustado teve um desempenho superior √† linha base?
  - Custo - reduz o uso de tokens simplificando os prompts?
  - Extensibilidade - pode reutilizar o modelo base para novos dom√≠nios?

Respondendo a estas perguntas, dever√° ser capaz de decidir se o ajuste fino √© a abordagem certa para o seu caso de uso. Idealmente, a abordagem √© v√°lida apenas se os benef√≠cios superarem os custos. Depois de decidir avan√ßar, √© tempo de pensar _como_ pode ajustar o modelo pr√©-treinado.

Quer obter mais insights no processo de decis√£o? Veja [Ajustar ou n√£o ajustar](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Como podemos ajustar um modelo pr√©-treinado?

Para ajustar um modelo pr√©-treinado, precisa de ter:

- um modelo pr√©-treinado para ajustar
- um conjunto de dados para usar no ajuste fino
- um ambiente de treino para executar a tarefa de ajuste fino
- um ambiente de implementa√ß√£o para alojar o modelo ajustado

## Ajuste Fino em A√ß√£o

Os recursos seguintes fornecem tutoriais passo a passo para o guiar por um exemplo real usando um modelo selecionado com um conjunto de dados selecionado. Para trabalhar estes tutoriais, precisa de uma conta no fornecedor espec√≠fico, juntamente com acesso ao modelo e conjuntos de dados relevantes.

| Fornecedor   | Tutorial                                                                                                                                                                       | Descri√ß√£o                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Como ajustar modelos de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Aprenda a ajustar um `gpt-35-turbo` para um dom√≠nio espec√≠fico ("assistente de receitas") preparando os dados de treino, executando o trabalho de ajuste fino, e usando o modelo ajustado para infer√™ncia.                                                                                                                                                                                                                          |
| Azure OpenAI | [Tutorial de ajuste fino GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Aprenda a ajustar um modelo `gpt-35-turbo-0613` **na Azure** seguindo os passos para criar e carregar os dados de treino, executar o trabalho de ajuste fino. Implementar e usar o novo modelo.                                                                                                                                                                                                                                      |
| Hugging Face | [Ajuste fino de LLMs com Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Este artigo guia o ajuste fino de um _LLM aberto_ (ex: `CodeLlama 7B`) usando a biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) & o [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) com [conjuntos de dados](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) abertos no Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Ajuste fino de LLMs com AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (ou AutoTrain Advanced) √© uma biblioteca python desenvolvida pela Hugging Face que permite ajuste fino para muitas tarefas diferentes incluindo ajuste fino de LLMs. AutoTrain √© uma solu√ß√£o sem c√≥digo e o ajuste fino pode ser feito na sua pr√≥pria cloud, no Hugging Face Spaces ou localmente. Suporta GUI web, CLI e treino via ficheiros de configura√ß√£o yaml.                                                                |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü¶• Unsloth | [Ajuste fino de LLMs com Unsloth](https://github.com/unslothai/unsloth)                                                         | Unsloth √© um framework open-source que suporta ajuste fino de LLM e aprendizagem por refor√ßo (RL). Unsloth simplifica treino local, avalia√ß√£o, e implementa√ß√£o com [notebooks](https://github.com/unslothai/notebooks) prontos a usar. Suporta tamb√©m text-to-speech (TTS), modelos BERT e multimodais. Para come√ßar, leia o seu guia passo a passo [Fine-tuning LLMs Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                                              |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
## Tarefa

Selecione um dos tutoriais acima e siga-o passo a passo. _Podemos replicar uma vers√£o destes tutoriais em Jupyter Notebooks neste reposit√≥rio apenas para refer√™ncia. Por favor, use as fontes originais diretamente para obter as vers√µes mais recentes_.

## Excelente Trabalho! Continue a Sua Aprendizagem.

Depois de completar esta li√ß√£o, confira a nossa [cole√ß√£o de Aprendizagem de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar a evoluir o seu conhecimento em IA Generativa!

Parab√©ns!! Concluiu a √∫ltima li√ß√£o da s√©rie v2 deste curso! N√£o pare de aprender e construir. \*\*Consulte a p√°gina [RECURSOS](RESOURCES.md?WT.mc_id=academic-105485-koreyst) para uma lista de sugest√µes adicionais sobre este tema.

A nossa s√©rie v1 de li√ß√µes tamb√©m foi atualizada com mais tarefas e conceitos. Reserve um minuto para refrescar o seu conhecimento - e por favor [partilhe as suas quest√µes e feedback](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) para nos ajudar a melhorar estas li√ß√µes para a comunidade.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Apesar dos nossos esfor√ßos para garantir a precis√£o, por favor, tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->