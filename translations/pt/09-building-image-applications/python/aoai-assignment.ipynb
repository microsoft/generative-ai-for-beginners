{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construir uma Aplicação de Geração de Imagens\n",
    "\n",
    "Os LLMs não servem apenas para gerar texto. Também é possível criar imagens a partir de descrições em texto. Ter imagens como uma modalidade pode ser extremamente útil em várias áreas, desde MedTech, arquitetura, turismo, desenvolvimento de jogos e muito mais. Neste capítulo, vamos explorar os dois modelos de geração de imagens mais populares, DALL-E e Midjourney.\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Nesta lição, vamos abordar:\n",
    "\n",
    "- Geração de imagens e a sua utilidade.\n",
    "- DALL-E e Midjourney, o que são e como funcionam.\n",
    "- Como construir uma aplicação de geração de imagens.\n",
    "\n",
    "## Objetivos de Aprendizagem\n",
    "\n",
    "Depois de concluir esta lição, vais conseguir:\n",
    "\n",
    "- Construir uma aplicação de geração de imagens.\n",
    "- Definir limites para a tua aplicação com meta prompts.\n",
    "- Trabalhar com DALL-E e Midjourney.\n",
    "\n",
    "## Porquê construir uma aplicação de geração de imagens?\n",
    "\n",
    "Aplicações de geração de imagens são uma excelente forma de explorar as capacidades da IA Generativa. Podem ser usadas, por exemplo, para:\n",
    "\n",
    "- **Edição e síntese de imagens**. Podes criar imagens para vários casos de uso, como edição ou síntese de imagens.\n",
    "\n",
    "- **Aplicação em várias indústrias**. Também podem ser usadas para gerar imagens para diferentes setores como MedTech, Turismo, Desenvolvimento de Jogos, entre outros.\n",
    "\n",
    "## Cenário: Edu4All\n",
    "\n",
    "Como parte desta lição, vamos continuar a trabalhar com a nossa startup, Edu4All. Os alunos vão criar imagens para os seus trabalhos, sendo que o tipo de imagem depende deles: podem ser ilustrações para um conto de fadas, criar uma nova personagem para a sua história ou ajudar a visualizar ideias e conceitos.\n",
    "\n",
    "Por exemplo, se os alunos estiverem a trabalhar numa aula sobre monumentos, podem gerar algo como:\n",
    "\n",
    "![Startup Edu4All, aula sobre monumentos, Torre Eiffel](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.pt.png)\n",
    "\n",
    "usando um prompt como\n",
    "\n",
    "> \"Cão ao lado da Torre Eiffel ao nascer do sol\"\n",
    "\n",
    "## O que são DALL-E e Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) e [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) são dois dos modelos de geração de imagens mais conhecidos, permitindo criar imagens a partir de prompts.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Comecemos pelo DALL-E, que é um modelo de IA Generativa capaz de criar imagens a partir de descrições em texto.\n",
    "\n",
    "> [O DALL-E é uma combinação de dois modelos, CLIP e atenção difusa](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** é um modelo que gera embeddings, ou seja, representações numéricas de dados, a partir de imagens e texto.\n",
    "\n",
    "- **Atenção difusa** é um modelo que gera imagens a partir desses embeddings. O DALL-E é treinado com um conjunto de dados de imagens e texto, podendo criar imagens a partir de descrições. Por exemplo, o DALL-E pode gerar imagens de um gato com um chapéu, ou de um cão com um moicano.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "O Midjourney funciona de forma semelhante ao DALL-E, gerando imagens a partir de prompts em texto. Também pode ser usado para criar imagens com prompts como “um gato com um chapéu” ou “um cão com um moicano”.\n",
    "\n",
    "![Imagem gerada pelo Midjourney, pombo mecânico](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Crédito da imagem: Wikipedia, imagem gerada pelo Midjourney*\n",
    "\n",
    "## Como funcionam o DALL-E e o Midjourney\n",
    "\n",
    "Primeiro, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). O DALL-E é um modelo de IA Generativa baseado na arquitetura transformer com um *transformer autoregressivo*.\n",
    "\n",
    "Um *transformer autoregressivo* define como o modelo gera imagens a partir de descrições em texto: cria um pixel de cada vez e usa os pixels já gerados para criar o próximo. O processo passa por várias camadas de uma rede neural até a imagem estar completa.\n",
    "\n",
    "Com este método, o DALL-E controla atributos, objetos, características e outros detalhes na imagem gerada. No entanto, o DALL-E 2 e 3 oferecem ainda mais controlo sobre a imagem criada,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criar a sua primeira aplicação de geração de imagens\n",
    "\n",
    "Então, o que é preciso para criar uma aplicação de geração de imagens? Vai precisar das seguintes bibliotecas:\n",
    "\n",
    "- **python-dotenv**, é altamente recomendado usar esta biblioteca para guardar os seus segredos num ficheiro *.env* separado do código.\n",
    "- **openai**, esta é a biblioteca que vai usar para interagir com a API da OpenAI.\n",
    "- **pillow**, para trabalhar com imagens em Python.\n",
    "- **requests**, para ajudar a fazer pedidos HTTP.\n",
    "\n",
    "\n",
    "1. Crie um ficheiro *.env* com o seguinte conteúdo:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Encontre esta informação no Portal do Azure, na secção \"Chaves e Endpoint\" do seu recurso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Junta as bibliotecas acima num ficheiro chamado *requirements.txt* da seguinte forma:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. De seguida, cria um ambiente virtual e instala as bibliotecas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Para Windows, utilize os seguintes comandos para criar e ativar o seu ambiente virtual:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Adicione o seguinte código num ficheiro chamado *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Vamos explicar este código:\n",
    "\n",
    "- Primeiro, importamos as bibliotecas necessárias, incluindo a biblioteca OpenAI, a dotenv, a requests e a Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- De seguida, carregamos as variáveis de ambiente a partir do ficheiro *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Depois, definimos o endpoint, a chave da API da OpenAI, a versão e o tipo.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- A seguir, geramos a imagem:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    O código acima devolve um objeto JSON que contém o URL da imagem gerada. Podemos usar esse URL para descarregar a imagem e guardá-la num ficheiro.\n",
    "\n",
    "- Por fim, abrimos a imagem e usamos o visualizador de imagens padrão para a mostrar:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Mais detalhes sobre a geração da imagem\n",
    "\n",
    "Vamos analisar o código que gera a imagem com mais detalhe:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** é o texto que serve de base para gerar a imagem. Neste caso, estamos a usar o prompt \"Coelho em cima de um cavalo, a segurar um chupa-chupa, num prado com nevoeiro onde crescem narcisos\".\n",
    "- **size** é o tamanho da imagem gerada. Neste exemplo, estamos a criar uma imagem de 1024x1024 píxeis.\n",
    "- **n** é o número de imagens geradas. Aqui, estamos a gerar duas imagens.\n",
    "- **temperature** é um parâmetro que controla o grau de aleatoriedade do resultado de um modelo de IA generativa. O valor da temperatura varia entre 0 e 1, onde 0 significa que o resultado é determinístico e 1 significa que é aleatório. O valor por defeito é 0.7.\n",
    "\n",
    "Há mais funcionalidades que podes explorar com imagens, que vamos abordar na próxima secção.\n",
    "\n",
    "## Funcionalidades adicionais na geração de imagens\n",
    "\n",
    "Até agora, viste como conseguimos gerar uma imagem com apenas algumas linhas de Python. No entanto, há mais possibilidades quando se trata de imagens.\n",
    "\n",
    "Também podes fazer o seguinte:\n",
    "\n",
    "- **Fazer edições**. Ao fornecer uma imagem existente, uma máscara e um prompt, podes alterar uma imagem. Por exemplo, podes adicionar algo a uma parte da imagem. Imagina a nossa imagem do coelho: podes adicionar um chapéu ao coelho. Para isso, forneces a imagem, uma máscara (que identifica a área a alterar) e um prompt de texto a indicar o que deve ser feito.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    A imagem base teria apenas o coelho, mas a imagem final mostraria o chapéu no coelho.\n",
    "    \n",
    "- **Criar variações**.\n",
    "    Consulta o nosso [notebook OpenAI para mais informações](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precisão, tenha em atenção que traduções automáticas podem conter erros ou imprecisões. O documento original, na sua língua nativa, deve ser considerado a fonte autorizada. Para informações críticas, recomenda-se a tradução profissional humana. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas resultantes da utilização desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:14:41+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}