{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Criar aplicações de geração de texto\n",
    "\n",
    "Ao longo deste currículo, já viste que existem conceitos fundamentais como prompts e até uma disciplina inteira chamada \"engenharia de prompts\". Muitas ferramentas com as quais podes interagir, como o ChatGPT, Office 365, Microsoft Power Platform e outras, permitem-te usar prompts para realizar tarefas.\n",
    "\n",
    "Para adicionares esta experiência a uma aplicação, precisas de perceber conceitos como prompts, completions e escolher uma biblioteca para trabalhar. É precisamente isso que vais aprender neste capítulo.\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Neste capítulo, vais:\n",
    "\n",
    "- Aprender sobre a biblioteca openai e os seus conceitos principais.\n",
    "- Construir uma aplicação de geração de texto usando openai.\n",
    "- Perceber como usar conceitos como prompt, temperature e tokens para criar uma aplicação de geração de texto.\n",
    "\n",
    "## Objetivos de aprendizagem\n",
    "\n",
    "No final desta lição, serás capaz de:\n",
    "\n",
    "- Explicar o que é uma aplicação de geração de texto.\n",
    "- Construir uma aplicação de geração de texto usando openai.\n",
    "- Configurar a tua aplicação para usar mais ou menos tokens e também alterar a temperature, para obter resultados variados.\n",
    "\n",
    "## O que é uma aplicação de geração de texto?\n",
    "\n",
    "Normalmente, quando crias uma aplicação, ela tem algum tipo de interface como as seguintes:\n",
    "\n",
    "- Baseada em comandos. Aplicações de consola são típicas onde escreves um comando e ela executa uma tarefa. Por exemplo, o `git` é uma aplicação baseada em comandos.\n",
    "- Interface de utilizador (UI). Algumas aplicações têm interfaces gráficas (GUIs) onde clicas em botões, inseres texto, escolhes opções, entre outros.\n",
    "\n",
    "### Aplicações de consola e UI são limitadas\n",
    "\n",
    "Compara com uma aplicação baseada em comandos onde escreves um comando:\n",
    "\n",
    "- **É limitada**. Não podes escrever qualquer comando, apenas os que a aplicação suporta.\n",
    "- **Específica de linguagem**. Algumas aplicações suportam várias línguas, mas por defeito a aplicação é feita para uma língua específica, mesmo que possas adicionar suporte para mais línguas.\n",
    "\n",
    "### Vantagens das aplicações de geração de texto\n",
    "\n",
    "Então, em que é que uma aplicação de geração de texto é diferente?\n",
    "\n",
    "Numa aplicação de geração de texto, tens mais flexibilidade, não estás limitado a um conjunto de comandos ou a uma língua de entrada específica. Em vez disso, podes usar linguagem natural para interagir com a aplicação. Outra vantagem é que, como já estás a interagir com uma fonte de dados treinada num vasto conjunto de informação, enquanto uma aplicação tradicional pode estar limitada ao que está numa base de dados.\n",
    "\n",
    "### O que posso construir com uma aplicação de geração de texto?\n",
    "\n",
    "Há muitas coisas que podes criar. Por exemplo:\n",
    "\n",
    "- **Um chatbot**. Um chatbot que responde a perguntas sobre temas, como a tua empresa e os seus produtos, pode ser uma boa opção.\n",
    "- **Assistente**. Os LLMs são ótimos para resumir texto, obter insights de texto, produzir textos como currículos e muito mais.\n",
    "- **Assistente de código**. Dependendo do modelo de linguagem que usares, podes criar um assistente de código que te ajuda a programar. Por exemplo, podes usar um produto como o GitHub Copilot ou o ChatGPT para te ajudar a escrever código.\n",
    "\n",
    "## Como posso começar?\n",
    "\n",
    "Bem, precisas de encontrar uma forma de integrar com um LLM, o que normalmente implica uma destas duas abordagens:\n",
    "\n",
    "- Usar uma API. Aqui constróis pedidos web com o teu prompt e recebes texto gerado de volta.\n",
    "- Usar uma biblioteca. As bibliotecas ajudam a encapsular as chamadas à API e tornam o processo mais simples.\n",
    "\n",
    "## Bibliotecas/SDKs\n",
    "\n",
    "Existem algumas bibliotecas bem conhecidas para trabalhar com LLMs, como:\n",
    "\n",
    "- **openai**, esta biblioteca facilita a ligação ao teu modelo e o envio de prompts.\n",
    "\n",
    "Depois há bibliotecas que operam a um nível mais alto, como:\n",
    "\n",
    "- **Langchain**. O Langchain é bastante conhecido e suporta Python.\n",
    "- **Semantic Kernel**. O Semantic Kernel é uma biblioteca da Microsoft que suporta C#, Python e Java.\n",
    "\n",
    "## Primeira aplicação com GitHub Models Playground e Azure AI Inference SDK\n",
    "\n",
    "Vamos ver como podemos construir a nossa primeira aplicação, que bibliotecas são necessárias, o que é preciso, e assim por diante.\n",
    "\n",
    "### O que é o GitHub Models?\n",
    "\n",
    "Bem-vindo ao [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Está tudo pronto para explorares diferentes Modelos de IA alojados no Azure AI, todos acessíveis através de um playground no GitHub ou diretamente no teu IDE favorito, gratuitamente para experimentar.\n",
    "\n",
    "### O que preciso?\n",
    "\n",
    "* Uma conta GitHub: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Inscrever-te no GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Vamos começar!\n",
    "\n",
    "### Encontrar um modelo e testá-lo\n",
    "\n",
    "Vai até [GitHub Models no Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Ecrã principal do GitHub Models a mostrar uma lista de cartões de modelos como Cohere, Meta llama, Mistral e modelos GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.pt.png)\n",
    "\n",
    "Escolhe um modelo – por exemplo [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Aqui vais ver o cartão do modelo. Podes:\n",
    "* Interagir com o modelo diretamente, escrevendo uma mensagem na caixa de texto\n",
    "* Ler detalhes sobre o modelo nas abas readme, Evaluation, Transparency e License\n",
    "* E ainda consultar a secção 'About' para informações de acesso ao modelo à direita\n",
    "\n",
    "![Cartão do modelo GPT-4o no GitHub Models](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.pt.png)\n",
    "\n",
    "Mas vamos avançar diretamente para o playground clicando no ['Playground' no canto superior direito](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Aqui podes interagir com o modelo, adicionar prompts de sistema e alterar parâmetros – e ainda obter todo o código necessário para correr isto em qualquer lado. Disponível a partir de setembro de 2024: Python, Javascript, C# e REST.\n",
    "\n",
    "![Experiência do Playground do GitHub Models com código e linguagens visíveis](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.pt.png)  \n",
    "\n",
    "### Vamos usar o modelo no nosso próprio IDE\n",
    "\n",
    "Tens duas opções:\n",
    "1. **GitHub Codespaces** – integração direta com Codespaces e não precisas de token para começar\n",
    "2. **VS Code (ou outro IDE à tua escolha)** – precisas de obter um [Personal Access Token do GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Em qualquer dos casos, as instruções estão disponíveis através do botão verde 'Get started' no canto superior direito.\n",
    "\n",
    "![Ecrã Get Started a mostrar como aceder ao Codespaces ou usar um personal access token para configurar no teu IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.pt.png)\n",
    "\n",
    "### 1. Codespaces\n",
    "\n",
    "* Na janela 'Get started', escolhe \"Run codespace\"\n",
    "* Cria um novo codespace (ou usa um já existente)\n",
    "* O VS Code vai abrir no teu browser com um conjunto de notebooks de exemplo em várias linguagens que podes experimentar\n",
    "* Executa o exemplo ```./githubmodels-app.py```.\n",
    "\n",
    "> Nota: No codespaces não é necessário definir a variável Github Token, podes saltar este passo\n",
    "\n",
    "**Agora avança para a secção 'Gerar Texto' abaixo para continuares este exercício**\n",
    "\n",
    "### 2. VS Code (ou outro IDE à tua escolha)\n",
    "\n",
    "A partir do botão verde 'Get started' tens toda a informação necessária para correr no teu IDE favorito. Este exemplo mostra o VS Code\n",
    "\n",
    "* Seleciona a linguagem e SDK – neste exemplo escolhemos Python e Azure AI Inference SDK\n",
    "* Cria um personal access token no GitHub. Isto está na secção Developer Settings. Não precisas de dar permissões ao token. Nota que o token será enviado para um serviço da Microsoft.\n",
    "* Cria uma variável de ambiente para guardar o teu personal access token do Github – há exemplos para bash, powershell e prompt de comandos do Windows\n",
    "* Instala as dependências: ```pip install azure-ai-inference```\n",
    "* Copia o código de exemplo básico para um ficheiro .py\n",
    "* Vai até à pasta onde guardaste o código e executa o ficheiro: ```python filename.py```\n",
    "\n",
    "Não te esqueças que, ao usar o Azure AI Inference SDK, podes facilmente experimentar diferentes modelos alterando o valor de `model_name` no código.\n",
    "\n",
    "Os seguintes modelos estão disponíveis no serviço GitHub Models a partir de setembro de 2024:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Agora avança para a secção 'Gerar Texto' abaixo para continuares este exercício**\n",
    "\n",
    "## Gerar texto com ChatCompletions\n",
    "\n",
    "A forma de gerar texto é usar a classe `ChatCompletionsClient`.\n",
    "Em `samples/python/azure_ai_inference/basic.py`, na secção de resposta do código, atualiza o código do papel do utilizador alterando o parâmetro content para o seguinte:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Executa o ficheiro atualizado para veres o resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes tipos de prompts, para diferentes situações\n",
    "\n",
    "Já viste como gerar texto usando um prompt. Até já tens um programa a funcionar que podes modificar e alterar para gerar diferentes tipos de texto.\n",
    "\n",
    "Os prompts podem ser usados para todo o tipo de tarefas. Por exemplo:\n",
    "\n",
    "- **Gerar um tipo de texto**. Por exemplo, podes criar um poema, perguntas para um quiz, etc.\n",
    "- **Procurar informação**. Podes usar prompts para procurar informações como, por exemplo, 'O que significa CORS no desenvolvimento web?'.\n",
    "- **Gerar código**. Podes usar prompts para gerar código, por exemplo, criar uma expressão regular para validar emails ou até gerar um programa completo, como uma aplicação web.\n",
    "\n",
    "## Exercício: um gerador de receitas\n",
    "\n",
    "Imagina que tens ingredientes em casa e queres cozinhar algo. Para isso, precisas de uma receita. Uma forma de encontrar receitas é usar um motor de busca ou podes usar um LLM para o fazer.\n",
    "\n",
    "Podes escrever um prompt assim:\n",
    "\n",
    "> \"Mostra-me 5 receitas para um prato com os seguintes ingredientes: frango, batatas e cenouras. Para cada receita, indica todos os ingredientes usados\"\n",
    "\n",
    "Dado o prompt acima, podes obter uma resposta semelhante a:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Este resultado é ótimo, já sei o que cozinhar. Neste ponto, algumas melhorias úteis poderiam ser:\n",
    "\n",
    "- Excluir ingredientes de que não gosto ou aos quais sou alérgico.\n",
    "- Criar uma lista de compras, caso não tenha todos os ingredientes em casa.\n",
    "\n",
    "Para os casos acima, vamos acrescentar um prompt adicional:\n",
    "\n",
    "> \"Por favor, remove receitas com alho porque sou alérgico e substitui por outro ingrediente. Além disso, faz uma lista de compras para as receitas, tendo em conta que já tenho frango, batatas e cenouras em casa.\"\n",
    "\n",
    "Agora tens um novo resultado, nomeadamente:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Aqui tens as tuas cinco receitas, sem alho mencionado, e também uma lista de compras tendo em conta o que já tens em casa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício - criar um gerador de receitas\n",
    "\n",
    "Agora que já explorámos um cenário, vamos escrever código para corresponder ao cenário demonstrado. Para isso, siga estes passos:\n",
    "\n",
    "1. Use o ficheiro existente como ponto de partida\n",
    "1. Crie uma variável `prompt` e altere o código de exemplo como abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agora executares o código, deves ver um resultado semelhante a:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, o teu LLM é não determinístico, por isso podes obter resultados diferentes cada vez que executares o programa.\n",
    "\n",
    "Ótimo, vamos ver como podemos melhorar isto. Para melhorar, queremos garantir que o código seja flexível, para que os ingredientes e o número de receitas possam ser ajustados e alterados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executar o código para um teste pode ser assim:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Melhorar adicionando filtro e lista de compras\n",
    "\n",
    "Agora temos uma aplicação funcional capaz de gerar receitas e é flexível, pois depende das entradas do utilizador, tanto no número de receitas como nos ingredientes usados.\n",
    "\n",
    "Para melhorar ainda mais, queremos adicionar o seguinte:\n",
    "\n",
    "- **Filtrar ingredientes**. Queremos poder excluir ingredientes que não gostamos ou aos quais somos alérgicos. Para fazer esta alteração, podemos editar o nosso prompt existente e adicionar uma condição de filtro no final, assim:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Acima, adicionamos `{filter}` ao final do prompt e também capturamos o valor do filtro do utilizador.\n",
    "\n",
    "    Um exemplo de entrada ao executar o programa pode ser assim:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Gerar uma lista de compras**. Queremos criar uma lista de compras, tendo em conta o que já temos em casa.\n",
    "\n",
    "    Para esta funcionalidade, podemos tentar resolver tudo num só prompt ou dividir em dois prompts. Vamos experimentar a segunda abordagem. Aqui sugerimos adicionar um prompt adicional, mas para funcionar, precisamos de adicionar o resultado do primeiro prompt como contexto ao segundo prompt.\n",
    "\n",
    "    Localiza a parte do código que imprime o resultado do primeiro prompt e adiciona o seguinte código abaixo:\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Nota o seguinte:\n",
    "\n",
    "    - Estamos a construir um novo prompt ao adicionar o resultado do primeiro prompt ao novo prompt:\n",
    "\n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Fazemos um novo pedido, mas também considerando o número de tokens que pedimos no primeiro prompt, por isso desta vez dizemos que `max_tokens` é 1200. **Uma nota sobre o comprimento dos tokens**. Devemos considerar quantos tokens precisamos para gerar o texto desejado. Os tokens têm custo, por isso, sempre que possível, devemos tentar ser económicos no número de tokens usados. Por exemplo, será que podemos formular o prompt de forma a usar menos tokens?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Ao testar este código, obtemos o seguinte resultado:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Experimentar com a temperatura**. A temperatura é algo que ainda não mencionámos, mas é importante para o funcionamento do programa. Quanto maior o valor da temperatura, mais aleatório será o resultado. Por outro lado, quanto menor o valor, mais previsível será a resposta. Pensa se queres ou não variação nas respostas.\n",
    "\n",
    "   Para alterar a temperatura, podes usar o parâmetro `temperature`. Por exemplo, se quiseres usar uma temperatura de 0.5, faz assim:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Nota, quanto mais próximo de 1.0, mais variado será o resultado.\n",
    "\n",
    "\n",
    "## Exercício\n",
    "\n",
    "Neste exercício, podes escolher o que construir.\n",
    "\n",
    "Aqui ficam algumas sugestões:\n",
    "\n",
    "- Ajusta a aplicação de geração de receitas para a melhorar ainda mais. Experimenta diferentes valores de temperatura e modifica os prompts para ver o que consegues criar.\n",
    "- Constrói um \"companheiro de estudo\". Esta aplicação deve conseguir responder a perguntas sobre um tema, por exemplo Python. Podes ter prompts como \"O que é determinado tema em Python?\", ou um prompt que peça para mostrar código sobre um tema específico, etc.\n",
    "- Bot de história, faz a história ganhar vida, instrui o bot para interpretar uma personagem histórica e faz-lhe perguntas sobre a sua vida e época.\n",
    "\n",
    "## Solução\n",
    "\n",
    "### Companheiro de estudo\n",
    "\n",
    "- \"És um especialista na linguagem Python\n",
    "\n",
    "    Sugere uma lição para principiantes em Python no seguinte formato:\n",
    "    \n",
    "    Formato:\n",
    "    - conceitos:\n",
    "    - breve explicação da lição:\n",
    "    - exercício em código com soluções\"\n",
    "\n",
    "Acima está um prompt inicial, vê como podes usá-lo e adaptá-lo ao teu gosto.\n",
    "\n",
    "### Bot de história\n",
    "\n",
    "Aqui estão alguns prompts que podes usar:\n",
    "\n",
    "- \"És Abe Lincoln, fala-me sobre ti em 3 frases e responde usando a gramática e palavras que o Abe usaria\"\n",
    "- \"És Abe Lincoln, responde usando a gramática e palavras que o Abe usaria:\n",
    "\n",
    "   Fala-me sobre os teus maiores feitos, em 300 palavras:\"\n",
    "\n",
    "## Verificação de conhecimentos\n",
    "\n",
    "O que faz o conceito de temperatura?\n",
    "\n",
    "1. Controla o quão aleatório é o resultado.\n",
    "1. Controla o tamanho da resposta.\n",
    "1. Controla quantos tokens são usados.\n",
    "\n",
    "R: 1\n",
    "\n",
    "Qual é uma boa forma de guardar segredos como chaves de API?\n",
    "\n",
    "1. No código.\n",
    "1. Num ficheiro.\n",
    "1. Em variáveis de ambiente.\n",
    "\n",
    "R: 3, porque as variáveis de ambiente não ficam guardadas no código e podem ser carregadas a partir do código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precisão, tenha em atenção que traduções automáticas podem conter erros ou imprecisões. O documento original, na sua língua nativa, deve ser considerado a fonte autorizada. Para informações críticas, recomenda-se a tradução profissional por um humano. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas resultantes da utilização desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T15:05:39+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "pt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}