<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:30:25+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "pt"
}
-->
# Frameworks de Redes Neuronais

Como j√° aprendemos, para conseguir treinar redes neuronais de forma eficiente precisamos de fazer duas coisas:

* Operar sobre tensores, por exemplo multiplicar, somar e calcular algumas fun√ß√µes como sigmoid ou softmax
* Calcular gradientes de todas as express√µes, para realizar a otimiza√ß√£o por descida do gradiente

Embora a biblioteca `numpy` consiga fazer a primeira parte, precisamos de algum mecanismo para calcular gradientes. No nosso framework que desenvolvemos na sec√ß√£o anterior, tivemos de programar manualmente todas as fun√ß√µes derivadas dentro do m√©todo `backward`, que faz a retropropaga√ß√£o. Idealmente, um framework deveria dar-nos a possibilidade de calcular gradientes de *qualquer express√£o* que possamos definir.

Outra coisa importante √© conseguir realizar c√°lculos em GPU, ou em qualquer outra unidade de c√°lculo especializada, como TPU. O treino de redes neuronais profundas requer *muitos* c√°lculos, e conseguir paralelizar esses c√°lculos em GPUs √© muito importante.

> ‚úÖ O termo 'paralelizar' significa distribuir os c√°lculos por v√°rios dispositivos.

Atualmente, os dois frameworks de redes neuronais mais populares s√£o: TensorFlow e PyTorch. Ambos fornecem uma API de baixo n√≠vel para operar com tensores tanto em CPU como em GPU. Por cima da API de baixo n√≠vel, existe tamb√©m uma API de alto n√≠vel, chamada Keras e PyTorch Lightning, respetivamente.

API de Baixo N√≠vel | TensorFlow | PyTorch
-------------------|------------|---------
API de Alto N√≠vel  | Keras      | PyTorch

As **APIs de baixo n√≠vel** em ambos os frameworks permitem construir os chamados **grafos computacionais**. Este grafo define como calcular a sa√≠da (normalmente a fun√ß√£o de perda) com os par√¢metros de entrada dados, e pode ser enviado para c√°lculo em GPU, se estiver dispon√≠vel. Existem fun√ß√µes para diferenciar este grafo computacional e calcular gradientes, que depois podem ser usados para otimizar os par√¢metros do modelo.

As **APIs de alto n√≠vel** consideram as redes neuronais como uma **sequ√™ncia de camadas**, facilitando muito a constru√ß√£o da maioria das redes neuronais. O treino do modelo normalmente requer preparar os dados e depois chamar uma fun√ß√£o `fit` para fazer o trabalho.

A API de alto n√≠vel permite construir redes neuronais t√≠picas muito rapidamente sem se preocupar com muitos detalhes. Ao mesmo tempo, a API de baixo n√≠vel oferece muito mais controlo sobre o processo de treino, sendo por isso muito usada em investiga√ß√£o, quando se trabalha com novas arquiteturas de redes neuronais.

√â tamb√©m importante perceber que se podem usar ambas as APIs em conjunto, por exemplo, pode desenvolver a sua pr√≥pria arquitetura de camada de rede usando a API de baixo n√≠vel, e depois us√°-la dentro de uma rede maior constru√≠da e treinada com a API de alto n√≠vel. Ou pode definir uma rede usando a API de alto n√≠vel como uma sequ√™ncia de camadas, e depois usar o seu pr√≥prio ciclo de treino de baixo n√≠vel para realizar a otimiza√ß√£o. Ambas as APIs usam os mesmos conceitos b√°sicos subjacentes e foram desenhadas para funcionar bem em conjunto.

## Aprendizagem

Neste curso, oferecemos a maior parte do conte√∫do tanto para PyTorch como para TensorFlow. Pode escolher o framework que preferir e seguir apenas os notebooks correspondentes. Se n√£o tiver a certeza de qual escolher, leia algumas discuss√µes na internet sobre **PyTorch vs. TensorFlow**. Pode tamb√©m explorar ambos os frameworks para obter uma melhor compreens√£o.

Sempre que poss√≠vel, usaremos APIs de alto n√≠vel pela simplicidade. No entanto, acreditamos que √© importante entender como as redes neuronais funcionam desde a base, por isso no in√≠cio come√ßamos a trabalhar com a API de baixo n√≠vel e tensores. Contudo, se quiser avan√ßar rapidamente e n√£o quiser perder muito tempo a aprender estes detalhes, pode saltar diretamente para os notebooks da API de alto n√≠vel.

## ‚úçÔ∏è Exerc√≠cios: Frameworks

Continue a sua aprendizagem nos seguintes notebooks:

API de Baixo N√≠vel | Notebook TensorFlow+Keras | PyTorch
-------------------|----------------------------|---------
API de Alto N√≠vel  | Keras                      | *PyTorch Lightning*

Depois de dominar os frameworks, vamos recapitular o conceito de overfitting.

# Overfitting

Overfitting √© um conceito extremamente importante em machine learning, e √© fundamental compreend√™-lo bem!

Considere o seguinte problema de aproximar 5 pontos (representados por `x` nos gr√°ficos abaixo):

!linear | overfit
-------------------------|--------------------------
**Modelo linear, 2 par√¢metros** | **Modelo n√£o linear, 7 par√¢metros**
Erro de treino = 5.3 | Erro de treino = 0
Erro de valida√ß√£o = 5.1 | Erro de valida√ß√£o = 20

* √Ä esquerda, vemos uma boa aproxima√ß√£o por uma linha reta. Como o n√∫mero de par√¢metros √© adequado, o modelo percebe corretamente a distribui√ß√£o dos pontos.
* √Ä direita, o modelo √© demasiado poderoso. Como s√≥ temos 5 pontos e o modelo tem 7 par√¢metros, ele consegue ajustar-se de forma a passar por todos os pontos, fazendo o erro de treino ser 0. No entanto, isto impede o modelo de compreender o padr√£o correto por tr√°s dos dados, pelo que o erro de valida√ß√£o √© muito elevado.

√â muito importante encontrar um equil√≠brio correto entre a complexidade do modelo (n√∫mero de par√¢metros) e o n√∫mero de amostras de treino.

## Por que ocorre overfitting

  * Dados de treino insuficientes
  * Modelo demasiado complexo
  * Muito ru√≠do nos dados de entrada

## Como detetar overfitting

Como pode ver no gr√°fico acima, o overfitting pode ser detetado por um erro de treino muito baixo e um erro de valida√ß√£o elevado. Normalmente, durante o treino, veremos tanto o erro de treino como o de valida√ß√£o a diminuir, e depois, em algum ponto, o erro de valida√ß√£o pode deixar de diminuir e come√ßar a aumentar. Este ser√° um sinal de overfitting, e um indicador de que provavelmente devemos parar o treino nesse momento (ou pelo menos guardar uma c√≥pia do modelo).

overfitting

## Como prevenir overfitting

Se perceber que est√° a ocorrer overfitting, pode fazer uma das seguintes coisas:

 * Aumentar a quantidade de dados de treino
 * Diminuir a complexidade do modelo
 * Usar alguma t√©cnica de regulariza√ß√£o, como Dropout, que iremos considerar mais tarde.

## Overfitting e o compromisso Bias-Vari√¢ncia

Overfitting √© na verdade um caso de um problema mais gen√©rico em estat√≠stica chamado compromisso Bias-Vari√¢ncia. Se considerarmos as poss√≠veis fontes de erro no nosso modelo, podemos ver dois tipos de erros:

* **Erros de bias** s√£o causados pelo nosso algoritmo n√£o conseguir captar corretamente a rela√ß√£o entre os dados de treino. Pode resultar do facto de o nosso modelo n√£o ser suficientemente poderoso (**underfitting**).
* **Erros de vari√¢ncia**, que s√£o causados pelo modelo a aproximar o ru√≠do nos dados de entrada em vez de uma rela√ß√£o significativa (**overfitting**).

Durante o treino, o erro de bias diminui (√† medida que o modelo aprende a aproximar os dados), e o erro de vari√¢ncia aumenta. √â importante parar o treino ‚Äì manualmente (quando detetamos overfitting) ou automaticamente (introduzindo regulariza√ß√£o) ‚Äì para evitar overfitting.

## Conclus√£o

Nesta li√ß√£o, aprendeu sobre as diferen√ßas entre as v√°rias APIs dos dois frameworks de IA mais populares, TensorFlow e PyTorch. Al√©m disso, aprendeu sobre um tema muito importante, o overfitting.

## üöÄ Desafio

Nos notebooks que acompanham esta li√ß√£o, encontrar√° 'tarefas' no final; trabalhe nos notebooks e complete as tarefas.

## Revis√£o & Estudo Aut√≥nomo

Fa√ßa alguma pesquisa sobre os seguintes t√≥picos:

- TensorFlow
- PyTorch
- Overfitting

Pergunte a si mesmo as seguintes quest√µes:

- Qual √© a diferen√ßa entre TensorFlow e PyTorch?
- Qual √© a diferen√ßa entre overfitting e underfitting?

## Trabalho Pr√°tico

Neste laborat√≥rio, √© pedido que resolva dois problemas de classifica√ß√£o usando redes totalmente conectadas de camada √∫nica e m√∫ltiplas camadas, utilizando PyTorch ou TensorFlow.

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, por favor tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes da utiliza√ß√£o desta tradu√ß√£o.