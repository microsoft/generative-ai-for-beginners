<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:22:28+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "pt"
}
-->
# Explorar e comparar diferentes LLMs

[![Explorar e comparar diferentes LLMs](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.pt.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

Na li√ß√£o anterior, vimos como a IA Generativa est√° a transformar o panorama tecnol√≥gico, como funcionam os Large Language Models (LLMs) e como uma empresa ‚Äì como a nossa startup ‚Äì pode aplic√°-los nos seus casos de uso e crescer! Neste cap√≠tulo, vamos comparar e contrastar diferentes tipos de grandes modelos de linguagem (LLMs) para compreender as suas vantagens e desvantagens.

O pr√≥ximo passo na jornada da nossa startup √© explorar o panorama atual dos LLMs e perceber quais s√£o adequados para o nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o ir√° abordar:

- Diferentes tipos de LLMs no panorama atual.
- Testar, iterar e comparar diferentes modelos para o seu caso de uso no Azure.
- Como implementar um LLM.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, ser√° capaz de:

- Selecionar o modelo certo para o seu caso de uso.
- Compreender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implementam modelos.

## Compreender os diferentes tipos de LLMs

Os LLMs podem ser categorizados de v√°rias formas, consoante a sua arquitetura, dados de treino e caso de uso. Compreender estas diferen√ßas ajudar√° a nossa startup a escolher o modelo certo para o cen√°rio e a perceber como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM; a sua escolha depende do que pretende fazer com eles, dos seus dados, do or√ßamento dispon√≠vel e outros fatores.

Consoante pretenda usar os modelos para texto, √°udio, v√≠deo, gera√ß√£o de imagens, entre outros, poder√° optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e voz**. Para este prop√≥sito, os modelos do tipo Whisper s√£o uma excelente escolha, pois s√£o de uso geral e focados no reconhecimento de voz. S√£o treinados com √°udio diversificado e conseguem realizar reconhecimento de voz multilingue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de imagens**. Para gera√ß√£o de imagens, DALL-E e Midjourney s√£o duas escolhas muito conhecidas. O DALL-E √© disponibilizado pelo Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**. A maioria dos modelos √© treinada para gera√ß√£o de texto e tem uma grande variedade de op√ß√µes, desde GPT-3.5 at√© GPT-4. Estes modelos t√™m custos diferentes, sendo o GPT-4 o mais caro. Vale a pena explorar o [playground do Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais os modelos que melhor se adequam √†s suas necessidades em termos de capacidade e custo.

- **Multi-modalidade**. Se pretende lidar com v√°rios tipos de dados na entrada e sa√≠da, poder√° querer explorar modelos como [gpt-4 turbo com vis√£o ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ‚Äì as √∫ltimas vers√µes dos modelos OpenAI ‚Äì que combinam processamento de linguagem natural com compreens√£o visual, permitindo intera√ß√µes atrav√©s de interfaces multimodais.

Selecionar um modelo significa obter algumas capacidades b√°sicas, que por vezes podem n√£o ser suficientes. Muitas vezes, tem dados espec√≠ficos da empresa que precisa de comunicar ao LLM. Existem algumas op√ß√µes para abordar isso, que ser√£o explicadas nas pr√≥ximas sec√ß√µes.

### Foundation Models versus LLMs

O termo Foundation Model foi [criado por investigadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que cumpre certos crit√©rios, tais como:

- **S√£o treinados usando aprendizagem n√£o supervisionada ou auto-supervisionada**, ou seja, s√£o treinados com dados multimodais n√£o rotulados, sem necessidade de anota√ß√£o humana para o processo de treino.
- **S√£o modelos muito grandes**, baseados em redes neurais profundas treinadas com milhares de milh√µes de par√¢metros.
- **Destinam-se normalmente a servir como ‚Äòfunda√ß√£o‚Äô para outros modelos**, podendo ser usados como ponto de partida para construir outros modelos, atrav√©s de fine-tuning.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.pt.png)

Fonte da imagem: [Essential Guide to Foundation Models and Large Language Models | por Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para clarificar esta distin√ß√£o, tomemos o ChatGPT como exemplo. Para construir a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como foundation model. Isto significa que a OpenAI usou dados espec√≠ficos de conversa√ß√£o para criar uma vers√£o ajustada do GPT-3.5, especializada em ter bom desempenho em cen√°rios de conversa√ß√£o, como chatbots.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.pt.png)

Fonte da imagem: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos Open Source versus Propriet√°rios

Outra forma de categorizar os LLMs √© se s√£o open source ou propriet√°rios.

Modelos open source s√£o disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. S√£o frequentemente disponibilizados pela empresa que os criou ou pela comunidade de investiga√ß√£o. Estes modelos podem ser inspecionados, modificados e personalizados para diferentes casos de uso. No entanto, nem sempre est√£o otimizados para uso em produ√ß√£o, podendo n√£o ter o mesmo desempenho que modelos propriet√°rios. Al√©m disso, o financiamento para modelos open source pode ser limitado, podendo n√£o ser mantidos a longo prazo ou atualizados com as √∫ltimas pesquisas. Exemplos populares de modelos open source incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) e [LLaMA](https://llama.meta.com).

Modelos propriet√°rios s√£o propriedade de uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Estes modelos s√£o frequentemente otimizados para uso em produ√ß√£o. No entanto, n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, nem sempre est√£o dispon√≠veis gratuitamente, podendo exigir subscri√ß√£o ou pagamento para uso. Os utilizadores tamb√©m n√£o t√™m controlo sobre os dados usados para treinar o modelo, pelo que devem confiar no propriet√°rio do modelo para garantir o compromisso com a privacidade dos dados e o uso respons√°vel da IA. Exemplos populares de modelos propriet√°rios incluem [modelos OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Gera√ß√£o de Imagens versus Gera√ß√£o de Texto e C√≥digo

Os LLMs tamb√©m podem ser categorizados pelo tipo de sa√≠da que geram.

Embeddings s√£o um conjunto de modelos que convertem texto numa forma num√©rica, chamada embedding, que √© uma representa√ß√£o num√©rica do texto de entrada. Os embeddings facilitam a compreens√£o das rela√ß√µes entre palavras ou frases pelas m√°quinas e podem ser usados como entrada para outros modelos, como modelos de classifica√ß√£o ou de clustering, que t√™m melhor desempenho com dados num√©ricos. Os modelos de embedding s√£o frequentemente usados para transfer learning, onde um modelo √© constru√≠do para uma tarefa substituta com abund√¢ncia de dados, e depois os pesos do modelo (embeddings) s√£o reutilizados para outras tarefas. Um exemplo desta categoria s√£o os [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.pt.png)

Modelos de gera√ß√£o de imagens s√£o modelos que criam imagens. S√£o frequentemente usados para edi√ß√£o, s√≠ntese e tradu√ß√£o de imagens. Estes modelos s√£o treinados em grandes conjuntos de dados de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novas imagens ou editar imagens existentes com t√©cnicas de inpainting, super-resolu√ß√£o e colora√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [modelos Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Gera√ß√£o de imagens](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.pt.png)

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que geram texto ou c√≥digo. S√£o usados para sumariza√ß√£o, tradu√ß√£o e resposta a perguntas. Os modelos de gera√ß√£o de texto s√£o treinados em grandes conjuntos de dados de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem gerar texto novo ou responder a perguntas. Modelos de gera√ß√£o de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o treinados em grandes conjuntos de dados de c√≥digo, como GitHub, e podem gerar c√≥digo novo ou corrigir bugs em c√≥digo existente.

![Gera√ß√£o de texto e c√≥digo](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.pt.png)

### Encoder-Decoder versus Decoder-only

Para falar sobre os diferentes tipos de arquiteturas dos LLMs, vamos usar uma analogia.

Imagine que o seu gestor lhe deu a tarefa de criar um quiz para os alunos. Tem dois colegas; um √© respons√°vel por criar o conte√∫do e o outro por o rever.

O criador de conte√∫do √© como um modelo Decoder only, que pode olhar para o tema e ver o que j√° escreveu, e depois escrever um curso com base nisso. S√£o muito bons a escrever conte√∫dos envolventes e informativos, mas n√£o s√£o muito bons a compreender o tema e os objetivos de aprendizagem. Alguns exemplos de modelos Decoder s√£o os da fam√≠lia GPT, como o GPT-3.

O revisor √© como um modelo Encoder only, que olha para o curso escrito e as respostas, notando a rela√ß√£o entre eles e compreendendo o contexto, mas n√£o √© bom a gerar conte√∫do. Um exemplo de modelo Encoder only seria o BERT.

Imagine que pud√©ssemos ter algu√©m que criasse e revisasse o quiz, este seria um modelo Encoder-Decoder. Alguns exemplos seriam BART e T5.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre um servi√ßo e um modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos Cloud, e √© frequentemente uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo, e √© frequentemente um foundation model, como um LLM.

Os servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e s√£o geralmente mais f√°ceis de usar do que os modelos, atrav√©s de uma interface gr√°fica. No entanto, os servi√ßos nem sempre s√£o gratuitos, podendo exigir subscri√ß√£o ou pagamento, em troca de aproveitar o equipamento e recursos do propriet√°rio do servi√ßo, otimizando custos e facilitando a escalabilidade. Um exemplo de servi√ßo √© o [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano pay-as-you-go, ou seja, os utilizadores s√£o cobrados proporcionalmente ao uso do servi√ßo. Al√©m disso, o Azure OpenAI Service oferece seguran√ßa ao n√≠vel empresarial e um framework de IA respons√°vel, para al√©m das capacidades dos modelos.

Os modelos s√£o apenas a Rede Neural, com os par√¢metros, pesos e outros. Permitem que as empresas os executem localmente, mas para isso precisam de comprar equipamento, construir uma infraestrutura para escalar e adquirir uma licen√ßa ou usar um modelo open source. Um modelo como o LLaMA est√° dispon√≠vel para uso, exigindo poder computacional para executar o modelo.

## Como testar e iterar com diferentes modelos para compreender o desempenho no Azure

Depois de a nossa equipa explorar o panorama atual dos LLMs e identificar alguns bons candidatos para os seus cen√°rios, o pr√≥ximo passo √© test√°-los com os seus dados e carga de trabalho. Este √© um processo iterativo, feito atrav√©s de experi√™ncias e medi√ß√µes.
A maioria dos modelos que mencion√°mos nos par√°grafos anteriores (modelos OpenAI, modelos open source como o Llama2 e transformers da Hugging Face) est√£o dispon√≠veis no [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) no [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √© uma plataforma na Cloud concebida para desenvolvedores criarem aplica√ß√µes de IA generativa e gerirem todo o ciclo de vida do desenvolvimento ‚Äì desde a experimenta√ß√£o at√© √† avalia√ß√£o ‚Äì combinando todos os servi√ßos Azure AI num √∫nico hub com uma interface gr√°fica pr√°tica. O Cat√°logo de Modelos no Azure AI Studio permite ao utilizador:

- Encontrar o Foundation Model de interesse no cat√°logo ‚Äì seja propriet√°rio ou open source, filtrando por tarefa, licen√ßa ou nome. Para melhorar a pesquisa, os modelos est√£o organizados em cole√ß√µes, como a cole√ß√£o Azure OpenAI, cole√ß√£o Hugging Face, entre outras.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.pt.png)

- Consultar a ficha do modelo, incluindo uma descri√ß√£o detalhada do uso pretendido e dos dados de treino, exemplos de c√≥digo e resultados de avalia√ß√£o na biblioteca interna de avalia√ß√µes.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.pt.png)

- Comparar benchmarks entre modelos e conjuntos de dados dispon√≠veis na ind√∫stria para avaliar qual deles se adequa ao cen√°rio de neg√≥cio, atrav√©s do painel [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.pt.png)

- Ajustar o modelo com dados de treino personalizados para melhorar o desempenho do modelo numa carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e monitoriza√ß√£o do Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.pt.png)

- Implementar o modelo pr√©-treinado original ou a vers√£o ajustada num endpoint remoto de infer√™ncia em tempo real ‚Äì computa√ß√£o gerida ‚Äì ou num endpoint API serverless ‚Äì [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) ‚Äì para permitir que as aplica√ß√µes o consumam.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.pt.png)


> [!NOTE]
> Nem todos os modelos no cat√°logo est√£o atualmente dispon√≠veis para fine-tuning e/ou implementa√ß√£o pay-as-you-go. Consulte a ficha do modelo para detalhes sobre as capacidades e limita√ß√µes do modelo.

## Melhorar os resultados dos LLM

Explor√°mos com a nossa equipa startup diferentes tipos de LLMs e uma plataforma Cloud (Azure Machine Learning) que nos permite comparar diferentes modelos, avali√°-los com dados de teste, melhorar o desempenho e implement√°-los em endpoints de infer√™ncia.

Mas quando devem considerar ajustar um modelo em vez de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias abordagens que uma empresa pode usar para obter os resultados desejados de um LLM. Pode escolher diferentes tipos de modelos com diferentes graus de treino ao implementar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens diferentes:

- **Prompt engineering com contexto**. A ideia √© fornecer contexto suficiente quando se faz o prompt para garantir que se obt√™m as respostas necess√°rias.

- **Retrieval Augmented Generation, RAG**. Os seus dados podem existir numa base de dados ou endpoint web, por exemplo, para garantir que esses dados, ou um subconjunto deles, s√£o inclu√≠dos no momento do prompt, pode buscar os dados relevantes e torn√°-los parte do prompt do utilizador.

- **Modelo ajustado (fine-tuned)**. Aqui, treinou-se o modelo adicionalmente com os seus pr√≥prios dados, o que torna o modelo mais exato e responsivo √†s suas necessidades, mas pode ser dispendioso.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.pt.png)

Fonte da imagem: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering com Contexto

LLMs pr√©-treinados funcionam muito bem em tarefas generalizadas de linguagem natural, mesmo quando chamados com um prompt curto, como uma frase a completar ou uma pergunta ‚Äì o chamado ‚Äúzero-shot‚Äù learning.

No entanto, quanto mais o utilizador conseguir enquadrar a sua consulta, com um pedido detalhado e exemplos ‚Äì o Contexto ‚Äì mais precisa e pr√≥xima das expectativas do utilizador ser√° a resposta. Neste caso, falamos em ‚Äúone-shot‚Äù learning se o prompt incluir apenas um exemplo e ‚Äúfew-shot learning‚Äù se incluir v√°rios exemplos.  
Prompt engineering com contexto √© a abordagem mais econ√≥mica para come√ßar.

### Retrieval Augmented Generation (RAG)

Os LLMs t√™m a limita√ß√£o de s√≥ poderem usar os dados que foram utilizados durante o seu treino para gerar uma resposta. Isto significa que n√£o sabem nada sobre factos que aconteceram ap√≥s o seu processo de treino, e n√£o podem aceder a informa√ß√£o n√£o p√∫blica (como dados da empresa).  
Isto pode ser ultrapassado atrav√©s do RAG, uma t√©cnica que aumenta o prompt com dados externos na forma de fragmentos de documentos, considerando os limites de comprimento do prompt. Isto √© suportado por ferramentas de bases de dados vetoriais (como o [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam os fragmentos √∫teis de v√°rias fontes de dados pr√©-definidas e adicionam-nos ao Contexto do prompt.

Esta t√©cnica √© muito √∫til quando uma empresa n√£o tem dados suficientes, tempo suficiente ou recursos para ajustar um LLM, mas ainda assim deseja melhorar o desempenho numa carga de trabalho espec√≠fica e reduzir riscos de inven√ß√µes, ou seja, distor√ß√£o da realidade ou conte√∫do prejudicial.

### Modelo ajustado (fine-tuned)

O fine-tuning √© um processo que aproveita o transfer learning para ‚Äòadaptar‚Äô o modelo a uma tarefa espec√≠fica ou para resolver um problema concreto. Diferentemente do few-shot learning e do RAG, resulta na gera√ß√£o de um novo modelo, com pesos e biases atualizados. Requer um conjunto de exemplos de treino consistindo num √∫nico input (o prompt) e o output associado (a conclus√£o).  
Esta seria a abordagem preferida se:

- **Usar modelos ajustados**. Uma empresa gostaria de usar modelos ajustados menos potentes (como modelos de embedding) em vez de modelos de alto desempenho, resultando numa solu√ß√£o mais econ√≥mica e r√°pida.

- **Considerar a lat√™ncia**. A lat√™ncia √© importante para um caso de uso espec√≠fico, pelo que n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que o modelo deve aprender n√£o se enquadra no limite de comprimento do prompt.

- **Manter-se atualizado**. Uma empresa tem muitos dados de alta qualidade e etiquetas de ground truth e os recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo treinado

Treinar um LLM do zero √©, sem d√∫vida, a abordagem mais dif√≠cil e complexa de adotar, exigindo enormes quantidades de dados, recursos especializados e poder computacional adequado. Esta op√ß√£o deve ser considerada apenas num cen√°rio em que uma empresa tenha um caso de uso espec√≠fico de dom√≠nio e uma grande quantidade de dados centrados nesse dom√≠nio.

## Verifica√ß√£o de conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de conclus√£o de um LLM?

1. Prompt engineering com contexto  
1. RAG  
1. Modelo ajustado

R:3, se tiver tempo, recursos e dados de alta qualidade, o fine-tuning √© a melhor op√ß√£o para se manter atualizado. No entanto, se pretende melhorar as coisas e n√£o tem tempo, vale a pena considerar primeiro o RAG.

## üöÄ Desafio

Leia mais sobre como pode [usar o RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para o seu neg√≥cio.

## Excelente trabalho, continue a aprender

Depois de concluir esta li√ß√£o, consulte a nossa [cole√ß√£o de Aprendizagem de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar a aprimorar os seus conhecimentos em IA Generativa!

Siga para a Li√ß√£o 3 onde veremos como [construir com IA Generativa de forma respons√°vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, por favor tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes erradas decorrentes da utiliza√ß√£o desta tradu√ß√£o.