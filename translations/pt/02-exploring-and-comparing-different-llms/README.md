<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T13:56:58+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "pt"
}
-->
# Explorando e comparando diferentes LLMs

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

Na li√ß√£o anterior, vimos como a IA Generativa est√° mudando o cen√°rio tecnol√≥gico, como os Modelos de Linguagem de Grande Porte (LLMs) funcionam e como um neg√≥cio - como nossa startup - pode aplic√°-los aos seus casos de uso e crescer! Neste cap√≠tulo, vamos comparar e contrastar diferentes tipos de modelos de linguagem de grande porte (LLMs) para entender seus pr√≥s e contras.

O pr√≥ximo passo na jornada da nossa startup √© explorar o cen√°rio atual dos LLMs e entender quais s√£o adequados para nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o ir√° abordar:

- Diferentes tipos de LLMs no cen√°rio atual.
- Testar, iterar e comparar diferentes modelos para seu caso de uso no Azure.
- Como implantar um LLM.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, voc√™ ser√° capaz de:

- Selecionar o modelo certo para seu caso de uso.
- Entender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implantam modelos.

## Entender diferentes tipos de LLMs

LLMs podem ter m√∫ltiplas categoriza√ß√µes baseadas em sua arquitetura, dados de treinamento e caso de uso. Entender essas diferen√ßas ajudar√° nossa startup a selecionar o modelo certo para o cen√°rio e entender como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM, sua escolha de modelo depende do que voc√™ pretende usar, seus dados, quanto est√° disposto a pagar e mais.

Dependendo se voc√™ pretende usar os modelos para texto, √°udio, v√≠deo, gera√ß√£o de imagens e assim por diante, voc√™ pode optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e fala**. Para este prop√≥sito, modelos do tipo Whisper s√£o uma √≥tima escolha, pois s√£o de uso geral e voltados para reconhecimento de fala. S√£o treinados em √°udio diversificado e podem realizar reconhecimento de fala multil√≠ngue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de imagens**. Para gera√ß√£o de imagens, DALL-E e Midjourney s√£o duas escolhas bem conhecidas. DALL-E √© oferecido pelo Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**. A maioria dos modelos s√£o treinados para gera√ß√£o de texto e voc√™ tem uma grande variedade de escolhas, desde GPT-3.5 at√© GPT-4. Eles v√™m com diferentes custos, sendo o GPT-4 o mais caro. Vale a pena conferir o [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais modelos melhor atendem suas necessidades em termos de capacidade e custo.

- **Multi-modalidade**. Se voc√™ est√° procurando lidar com m√∫ltiplos tipos de dados na entrada e sa√≠da, pode querer explorar modelos como [gpt-4 turbo com vis√£o ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - os lan√ßamentos mais recentes de modelos da OpenAI - que s√£o capazes de combinar processamento de linguagem natural com entendimento visual, permitindo intera√ß√µes atrav√©s de interfaces multimodais.

Selecionar um modelo significa que voc√™ obt√©m algumas capacidades b√°sicas, que podem n√£o ser suficientes, no entanto. Muitas vezes voc√™ tem dados espec√≠ficos da empresa que precisa de alguma forma informar ao LLM. Existem algumas escolhas diferentes sobre como abordar isso, mais sobre isso nas pr√≥ximas se√ß√µes.

### Modelos de Funda√ß√£o versus LLMs

O termo Modelo de Funda√ß√£o foi [cunhado por pesquisadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que segue alguns crit√©rios, como:

- **Eles s√£o treinados usando aprendizado n√£o supervisionado ou auto-supervisionado**, o que significa que s√£o treinados em dados multimodais n√£o rotulados e n√£o requerem anota√ß√£o ou rotulagem humana dos dados para seu processo de treinamento.
- **Eles s√£o modelos muito grandes**, baseados em redes neurais muito profundas treinadas em bilh√µes de par√¢metros.
- **Eles s√£o normalmente destinados a servir como uma 'funda√ß√£o' para outros modelos**, o que significa que podem ser usados como ponto de partida para outros modelos a serem constru√≠dos sobre eles, o que pode ser feito por ajuste fino.

Para esclarecer ainda mais essa distin√ß√£o, vamos pegar o ChatGPT como exemplo. Para construir a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como modelo de funda√ß√£o. Isso significa que a OpenAI usou alguns dados espec√≠ficos de chat para criar uma vers√£o ajustada do GPT-3.5 que foi especializada em desempenhar bem em cen√°rios de conversa√ß√£o, como chatbots.

### Modelos de C√≥digo Aberto versus Propriet√°rios

Outra maneira de categorizar LLMs √© se eles s√£o de c√≥digo aberto ou propriet√°rios.

Modelos de c√≥digo aberto s√£o modelos que s√£o disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. Eles s√£o frequentemente disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para os diversos casos de uso em LLMs. No entanto, eles nem sempre s√£o otimizados para uso em produ√ß√£o e podem n√£o ser t√£o performantes quanto modelos propriet√°rios. Al√©m disso, o financiamento para modelos de c√≥digo aberto pode ser limitado e eles podem n√£o ser mantidos a longo prazo ou podem n√£o ser atualizados com as pesquisas mais recentes. Exemplos de modelos de c√≥digo aberto populares incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) e [LLaMA](https://llama.meta.com).

Modelos propriet√°rios s√£o modelos que s√£o propriedade de uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Esses modelos s√£o frequentemente otimizados para uso em produ√ß√£o. No entanto, eles n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, eles nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para uso. Al√©m disso, os usu√°rios n√£o t√™m controle sobre os dados usados para treinar o modelo, o que significa que devem confiar no propriet√°rio do modelo para garantir o compromisso com a privacidade dos dados e o uso respons√°vel da IA. Exemplos de modelos propriet√°rios populares incluem [modelos da OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Gera√ß√£o de Imagem versus Gera√ß√£o de Texto e C√≥digo

LLMs tamb√©m podem ser categorizados pelo tipo de sa√≠da que geram.

Embeddings s√£o um conjunto de modelos que podem converter texto em uma forma num√©rica, chamada embedding, que √© uma representa√ß√£o num√©rica do texto de entrada. Embeddings facilitam para m√°quinas entenderem as rela√ß√µes entre palavras ou frases e podem ser consumidos como entradas por outros modelos, como modelos de classifica√ß√£o ou modelos de agrupamento que t√™m melhor desempenho em dados num√©ricos. Modelos de embedding s√£o frequentemente usados para aprendizado por transfer√™ncia, onde um modelo √© constru√≠do para uma tarefa substituta para a qual h√° uma abund√¢ncia de dados, e ent√£o os pesos do modelo (embeddings) s√£o reutilizados para outras tarefas subsequentes. Um exemplo desta categoria √© [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

Modelos de gera√ß√£o de imagens s√£o modelos que geram imagens. Esses modelos s√£o frequentemente usados para edi√ß√£o de imagens, s√≠ntese de imagens e tradu√ß√£o de imagens. Modelos de gera√ß√£o de imagens s√£o frequentemente treinados em grandes conjuntos de dados de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novas imagens ou editar imagens existentes com t√©cnicas de inpainting, super-resolu√ß√£o e coloriza√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [modelos Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que geram texto ou c√≥digo. Esses modelos s√£o frequentemente usados para sumariza√ß√£o de texto, tradu√ß√£o e resposta a perguntas. Modelos de gera√ß√£o de texto s√£o frequentemente treinados em grandes conjuntos de dados de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novo texto ou responder a perguntas. Modelos de gera√ß√£o de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o frequentemente treinados em grandes conjuntos de dados de c√≥digo, como GitHub, e podem ser usados para gerar novo c√≥digo ou corrigir bugs em c√≥digo existente.

### Encoder-Decoder versus Apenas Decoder

Para falar sobre os diferentes tipos de arquiteturas de LLMs, vamos usar uma analogia.

Imagine que seu gerente lhe deu uma tarefa para escrever um quiz para os alunos. Voc√™ tem dois colegas; um √© respons√°vel por criar o conte√∫do e o outro por revis√°-lo.

O criador de conte√∫do √© como um modelo Apenas Decoder, ele pode olhar para o t√≥pico e ver o que voc√™ j√° escreveu e ent√£o ele pode escrever um curso com base nisso. Eles s√£o muito bons em escrever conte√∫do envolvente e informativo, mas n√£o s√£o muito bons em entender o t√≥pico e os objetivos de aprendizado. Alguns exemplos de modelos Decoder s√£o modelos da fam√≠lia GPT, como GPT-3.

O revisor √© como um modelo Apenas Encoder, ele olha para o curso escrito e as respostas, percebendo a rela√ß√£o entre eles e entendendo o contexto, mas n√£o √© bom em gerar conte√∫do. Um exemplo de modelo Apenas Encoder seria o BERT.

Imagine que podemos ter algu√©m tamb√©m que poderia criar e revisar o quiz, este √© um modelo Encoder-Decoder. Alguns exemplos seriam BART e T5.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre um servi√ßo e um modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos em Nuvem e √© frequentemente uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo e √© frequentemente um modelo de funda√ß√£o, como um LLM.

Servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e s√£o frequentemente mais f√°ceis de usar do que modelos, via uma interface gr√°fica. No entanto, servi√ßos nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para uso, em troca de aproveitar os equipamentos e recursos do propriet√°rio do servi√ßo, otimizando despesas e escalando facilmente. Um exemplo de servi√ßo √© [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano de taxa conforme o uso, significando que os usu√°rios s√£o cobrados proporcionalmente ao quanto usam o servi√ßo. Al√©m disso, o Azure OpenAI Service oferece seguran√ßa de n√≠vel empresarial e um framework de IA respons√°vel em cima das capacidades dos modelos.

Modelos s√£o apenas a Rede Neural, com os par√¢metros, pesos e outros. Permitindo que empresas executem localmente, no entanto, precisariam comprar equipamentos, construir uma estrutura para escalar e comprar uma licen√ßa ou usar um modelo de c√≥digo aberto. Um modelo como o LLaMA est√° dispon√≠vel para ser usado, exigindo poder computacional para executar o modelo.

## Como testar e iterar com diferentes modelos para entender o desempenho no Azure

Uma vez que nossa equipe explorou o cen√°rio atual de LLMs e identificou alguns bons candidatos para seus cen√°rios, o pr√≥ximo passo √© test√°-los em seus dados e em sua carga de trabalho. Este √© um processo iterativo, feito por experimentos e medidas. A maioria dos modelos que mencionamos nos par√°grafos anteriores (modelos da OpenAI, modelos de c√≥digo aberto como Llama2 e transformadores do Hugging Face) est√£o dispon√≠veis no [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) no [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √© uma Plataforma em Nuvem projetada para desenvolvedores constru√≠rem aplica√ß√µes de IA generativa e gerenciarem todo o ciclo de desenvolvimento - desde experimenta√ß√£o at√© avalia√ß√£o - combinando todos os servi√ßos de IA do Azure em um √∫nico hub com uma interface gr√°fica pr√°tica. O Cat√°logo de Modelos no Azure AI Studio permite ao usu√°rio:

- Encontrar o Modelo de Funda√ß√£o de interesse no cat√°logo - seja propriet√°rio ou de c√≥digo aberto, filtrando por tarefa, licen√ßa ou nome. Para melhorar a pesquisa, os modelos s√£o organizados em cole√ß√µes, como cole√ß√£o Azure OpenAI, cole√ß√£o Hugging Face e mais.

- Revisar o cart√£o do modelo, incluindo uma descri√ß√£o detalhada do uso pretendido e dados de treinamento, exemplos de c√≥digo e resultados de avalia√ß√£o na biblioteca de avalia√ß√µes internas.
- Compare benchmarks entre modelos e conjuntos de dados dispon√≠veis no mercado para avaliar qual atende ao cen√°rio de neg√≥cios, atrav√©s do painel [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.pt.png)

- Ajuste fino do modelo em dados de treinamento personalizados para melhorar o desempenho do modelo em uma carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e rastreamento do Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.pt.png)

- Implante o modelo pr√©-treinado original ou a vers√£o ajustada para uma infer√™ncia em tempo real remota - computa√ß√£o gerenciada - ou endpoint de API sem servidor - [pague conforme o uso](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - para permitir que aplicativos o consumam.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.pt.png)

> [!NOTE]
> Nem todos os modelos no cat√°logo est√£o atualmente dispon√≠veis para ajuste fino e/ou implanta√ß√£o no modo pague conforme o uso. Verifique o cart√£o do modelo para detalhes sobre as capacidades e limita√ß√µes do modelo.

## Melhorando os resultados de LLM

Exploramos com nossa equipe de startup diferentes tipos de LLMs e uma plataforma em nuvem (Azure Machine Learning) que nos permite comparar diferentes modelos, avali√°-los em dados de teste, melhorar o desempenho e implant√°-los em endpoints de infer√™ncia.

Mas quando devem considerar ajustar um modelo em vez de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias abordagens que uma empresa pode usar para obter os resultados que precisa de um LLM. Voc√™ pode selecionar diferentes tipos de modelos com diferentes graus de treinamento ao implantar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens diferentes:

- **Engenharia de prompt com contexto**. A ideia √© fornecer contexto suficiente ao fazer o prompt para garantir que voc√™ obtenha as respostas de que precisa.

- **Gera√ß√£o Aumentada por Recupera√ß√£o, RAG**. Seus dados podem existir em um banco de dados ou endpoint web, por exemplo, para garantir que esses dados, ou um subconjunto deles, sejam inclu√≠dos no momento do prompt, voc√™ pode buscar os dados relevantes e torn√°-los parte do prompt do usu√°rio.

- **Modelo ajustado**. Aqui, voc√™ treinou o modelo mais a fundo com seus pr√≥prios dados, o que levou o modelo a ser mais exato e responsivo √†s suas necessidades, mas pode ser caro.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.pt.png)

Fonte da imagem: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Engenharia de Prompt com Contexto

LLMs pr√©-treinados funcionam muito bem em tarefas de linguagem natural generalizadas, mesmo chamando-os com um prompt curto, como uma frase para completar ou uma pergunta ‚Äì o chamado aprendizado ‚Äúzero-shot‚Äù.

No entanto, quanto mais o usu√°rio puder estruturar sua consulta, com um pedido detalhado e exemplos ‚Äì o Contexto ‚Äì mais precisa e pr√≥xima das expectativas do usu√°rio ser√° a resposta. Neste caso, falamos de aprendizado ‚Äúone-shot‚Äù se o prompt incluir apenas um exemplo e ‚Äúfew-shot learning‚Äù se incluir v√°rios exemplos. A engenharia de prompt com contexto √© a abordagem mais econ√¥mica para come√ßar.

### Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)

LLMs t√™m a limita√ß√£o de que s√≥ podem usar os dados que foram usados durante seu treinamento para gerar uma resposta. Isso significa que eles n√£o sabem nada sobre os fatos que aconteceram ap√≥s o processo de treinamento, e n√£o podem acessar informa√ß√µes n√£o p√∫blicas (como dados da empresa). Isso pode ser superado atrav√©s do RAG, uma t√©cnica que aumenta o prompt com dados externos na forma de peda√ßos de documentos, considerando os limites de comprimento do prompt. Isso √© suportado por ferramentas de banco de dados de vetor (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam os peda√ßos √∫teis de v√°rias fontes de dados pr√©-definidas e os adicionam ao Contexto do prompt.

Esta t√©cnica √© muito √∫til quando uma empresa n√£o tem dados suficientes, tempo suficiente ou recursos para ajustar um LLM, mas ainda deseja melhorar o desempenho em uma carga de trabalho espec√≠fica e reduzir os riscos de falsifica√ß√µes, ou seja, mistifica√ß√£o da realidade ou conte√∫do prejudicial.

### Modelo ajustado

O ajuste fino √© um processo que aproveita o aprendizado de transfer√™ncia para ‚Äòadaptar‚Äô o modelo a uma tarefa a jusante ou para resolver um problema espec√≠fico. Diferentemente do few-shot learning e do RAG, resulta em um novo modelo sendo gerado, com pesos e vi√©s atualizados. Requer um conjunto de exemplos de treinamento consistindo de uma √∫nica entrada (o prompt) e sua sa√≠da associada (a conclus√£o). Esta seria a abordagem preferida se:

- **Usando modelos ajustados**. Uma empresa gostaria de usar modelos ajustados menos capazes (como modelos de incorpora√ß√£o) em vez de modelos de alto desempenho, resultando em uma solu√ß√£o mais econ√¥mica e r√°pida.

- **Considerando a lat√™ncia**. A lat√™ncia √© importante para um caso de uso espec√≠fico, portanto, n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que devem ser aprendidos pelo modelo n√£o cabe no limite de comprimento do prompt.

- **Mantendo-se atualizado**. Uma empresa possui muitos dados de alta qualidade e r√≥tulos de verdade fundamental e os recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo treinado

Treinar um LLM do zero √© sem d√∫vida a abordagem mais dif√≠cil e complexa de adotar, exigindo quantidades massivas de dados, recursos qualificados e poder computacional adequado. Esta op√ß√£o deve ser considerada apenas em um cen√°rio onde uma empresa possui um caso de uso espec√≠fico de dom√≠nio e uma grande quantidade de dados centrados no dom√≠nio.

## Verifica√ß√£o de conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de conclus√£o do LLM?

1. Engenharia de prompt com contexto
1. RAG
1. Modelo ajustado

A:3, se voc√™ tiver tempo e recursos e dados de alta qualidade, o ajuste fino √© a melhor op√ß√£o para se manter atualizado. No entanto, se voc√™ estiver procurando melhorar as coisas e estiver com pouco tempo, vale a pena considerar o RAG primeiro.

## üöÄ Desafio

Leia mais sobre como voc√™ pode [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para o seu neg√≥cio.

## √ìtimo Trabalho, Continue Aprendendo

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de aprendizado de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

V√° para a Li√ß√£o 3, onde veremos como [construir com IA Generativa de forma respons√°vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o humana profissional. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.