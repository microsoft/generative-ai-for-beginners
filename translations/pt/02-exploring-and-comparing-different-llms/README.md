<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-18T00:40:10+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "pt"
}
-->
# Explorando e comparando diferentes LLMs

[![Explorando e comparando diferentes LLMs](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.pt.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Clique na imagem acima para assistir ao v√≠deo desta li√ß√£o_

Na li√ß√£o anterior, vimos como a IA Generativa est√° mudando o cen√°rio tecnol√≥gico, como os Modelos de Linguagem de Grande Escala (LLMs) funcionam e como uma empresa - como a nossa startup - pode aplic√°-los aos seus casos de uso e crescer! Neste cap√≠tulo, vamos comparar e contrastar diferentes tipos de modelos de linguagem de grande escala (LLMs) para entender seus pr√≥s e contras.

O pr√≥ximo passo na jornada da nossa startup √© explorar o cen√°rio atual dos LLMs e entender quais s√£o adequados para o nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Diferentes tipos de LLMs no cen√°rio atual.
- Testar, iterar e comparar diferentes modelos para o seu caso de uso no Azure.
- Como implementar um LLM.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, voc√™ ser√° capaz de:

- Selecionar o modelo certo para o seu caso de uso.
- Entender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implementam modelos.

## Entender os diferentes tipos de LLMs

Os LLMs podem ser classificados de v√°rias maneiras com base na sua arquitetura, dados de treinamento e caso de uso. Compreender essas diferen√ßas ajudar√° nossa startup a selecionar o modelo certo para o cen√°rio e entender como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM, e sua escolha depende do objetivo de uso, dos seus dados, do or√ßamento dispon√≠vel e outros fatores.

Dependendo se voc√™ pretende usar os modelos para gera√ß√£o de texto, √°udio, v√≠deo, imagens e assim por diante, pode optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e fala**. Para este prop√≥sito, os modelos do tipo Whisper s√£o uma √≥tima escolha, pois s√£o de uso geral e voltados para reconhecimento de fala. Eles s√£o treinados em √°udio diversificado e podem realizar reconhecimento de fala multil√≠ngue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de imagens**. Para gera√ß√£o de imagens, DALL-E e Midjourney s√£o duas escolhas bem conhecidas. DALL-E √© oferecido pelo Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**. A maioria dos modelos √© treinada para gera√ß√£o de texto e h√° uma grande variedade de op√ß√µes, desde GPT-3.5 at√© GPT-4. Eles t√™m custos diferentes, sendo o GPT-4 o mais caro. Vale a pena explorar o [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais modelos melhor atendem √†s suas necessidades em termos de capacidade e custo.

- **Multimodalidade**. Se voc√™ deseja lidar com v√°rios tipos de dados na entrada e sa√≠da, pode querer explorar modelos como [gpt-4 turbo com vis√£o ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - os lan√ßamentos mais recentes dos modelos da OpenAI - que s√£o capazes de combinar processamento de linguagem natural com compreens√£o visual, permitindo intera√ß√µes por meio de interfaces multimodais.

Selecionar um modelo significa obter algumas capacidades b√°sicas, que podem n√£o ser suficientes. Muitas vezes, voc√™ tem dados espec√≠ficos da empresa que precisa informar ao LLM de alguma forma. Existem algumas abordagens diferentes para isso, mais sobre isso nas pr√≥ximas se√ß√µes.

### Modelos Fundamentais versus LLMs

O termo Modelo Fundamental foi [cunhado por pesquisadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que segue alguns crit√©rios, como:

- **S√£o treinados usando aprendizado n√£o supervisionado ou aprendizado auto-supervisionado**, ou seja, s√£o treinados com dados multimodais n√£o rotulados e n√£o requerem anota√ß√£o ou rotulagem humana de dados para seu processo de treinamento.
- **S√£o modelos muito grandes**, baseados em redes neurais profundas treinadas com bilh√µes de par√¢metros.
- **Normalmente s√£o destinados a servir como uma 'base' para outros modelos**, ou seja, podem ser usados como ponto de partida para outros modelos serem constru√≠dos sobre eles, o que pode ser feito por meio de ajuste fino.

![Modelos Fundamentais versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.pt.png)

Fonte da imagem: [Essential Guide to Foundation Models and Large Language Models | por Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para esclarecer ainda mais essa distin√ß√£o, vamos usar o ChatGPT como exemplo. Para construir a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como modelo fundamental. Isso significa que a OpenAI usou alguns dados espec√≠ficos de chat para criar uma vers√£o ajustada do GPT-3.5 que foi especializada em ter um bom desempenho em cen√°rios de conversa√ß√£o, como chatbots.

![Modelo Fundamental](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.pt.png)

Fonte da imagem: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos Open Source versus Propriet√°rios

Outra forma de categorizar os LLMs √© se eles s√£o de c√≥digo aberto ou propriet√°rios.

Modelos de c√≥digo aberto s√£o modelos disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. Eles geralmente s√£o disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para os diversos casos de uso em LLMs. No entanto, nem sempre s√£o otimizados para uso em produ√ß√£o e podem n√£o ser t√£o eficientes quanto os modelos propriet√°rios. Al√©m disso, o financiamento para modelos de c√≥digo aberto pode ser limitado, e eles podem n√£o ser mantidos a longo prazo ou atualizados com as pesquisas mais recentes. Exemplos de modelos populares de c√≥digo aberto incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) e [LLaMA](https://llama.meta.com).

Modelos propriet√°rios s√£o modelos que pertencem a uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Esses modelos geralmente s√£o otimizados para uso em produ√ß√£o. No entanto, n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para serem usados. Os usu√°rios tamb√©m n√£o t√™m controle sobre os dados usados para treinar o modelo, o que significa que devem confiar no propriet√°rio do modelo para garantir o compromisso com a privacidade dos dados e o uso respons√°vel da IA. Exemplos de modelos propriet√°rios populares incluem [Modelos OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Gera√ß√£o de Imagens versus Gera√ß√£o de Texto e C√≥digo

Os LLMs tamb√©m podem ser categorizados pelo tipo de sa√≠da que geram.

Embeddings s√£o um conjunto de modelos que podem converter texto em uma forma num√©rica, chamada embedding, que √© uma representa√ß√£o num√©rica do texto de entrada. Os embeddings facilitam a compreens√£o das rela√ß√µes entre palavras ou frases pelas m√°quinas e podem ser usados como entradas por outros modelos, como modelos de classifica√ß√£o ou de agrupamento que t√™m melhor desempenho com dados num√©ricos. Modelos de embedding s√£o frequentemente usados para aprendizado de transfer√™ncia, onde um modelo √© constru√≠do para uma tarefa substituta para a qual h√° uma abund√¢ncia de dados, e ent√£o os pesos do modelo (embeddings) s√£o reutilizados para outras tarefas subsequentes. Um exemplo dessa categoria √© [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.pt.png)

Modelos de gera√ß√£o de imagens s√£o modelos que geram imagens. Esses modelos s√£o frequentemente usados para edi√ß√£o de imagens, s√≠ntese de imagens e tradu√ß√£o de imagens. Modelos de gera√ß√£o de imagens s√£o frequentemente treinados em grandes conjuntos de dados de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novas imagens ou editar imagens existentes com t√©cnicas de inpainting, super-resolu√ß√£o e coloriza√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [Modelos Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Gera√ß√£o de imagens](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.pt.png)

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que geram texto ou c√≥digo. Esses modelos s√£o frequentemente usados para sumariza√ß√£o de texto, tradu√ß√£o e resposta a perguntas. Modelos de gera√ß√£o de texto s√£o frequentemente treinados em grandes conjuntos de dados de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novo texto ou responder perguntas. Modelos de gera√ß√£o de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o frequentemente treinados em grandes conjuntos de dados de c√≥digo, como GitHub, e podem ser usados para gerar novo c√≥digo ou corrigir bugs em c√≥digo existente.

![Gera√ß√£o de texto e c√≥digo](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.pt.png)

### Encoder-Decoder versus Apenas Decoder

Para falar sobre os diferentes tipos de arquiteturas de LLMs, vamos usar uma analogia.

Imagine que seu gerente lhe deu a tarefa de criar um quiz para os alunos. Voc√™ tem dois colegas; um √© respons√°vel por criar o conte√∫do e o outro por revis√°-lo.

O criador de conte√∫do √© como um modelo apenas Decoder, ele pode olhar para o t√≥pico e ver o que voc√™ j√° escreveu e, ent√£o, escrever um curso com base nisso. Ele √© muito bom em escrever conte√∫do envolvente e informativo, mas n√£o √© muito bom em entender o t√≥pico e os objetivos de aprendizado. Alguns exemplos de modelos Decoder s√£o os modelos da fam√≠lia GPT, como GPT-3.

O revisor √© como um modelo apenas Encoder, ele olha para o curso escrito e as respostas, percebendo a rela√ß√£o entre eles e entendendo o contexto, mas n√£o √© bom em gerar conte√∫do. Um exemplo de modelo apenas Encoder seria o BERT.

Imagine que tamb√©m podemos ter algu√©m que possa criar e revisar o quiz, este √© um modelo Encoder-Decoder. Alguns exemplos seriam BART e T5.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre um servi√ßo e um modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos em Nuvem e geralmente √© uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo e geralmente √© um modelo fundamental, como um LLM.

Os servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e geralmente s√£o mais f√°ceis de usar do que os modelos, por meio de uma interface gr√°fica. No entanto, os servi√ßos nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para serem usados, em troca de aproveitar os equipamentos e recursos do propriet√°rio do servi√ßo, otimizando despesas e escalando facilmente. Um exemplo de servi√ßo √© o [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano de tarifas pay-as-you-go, ou seja, os usu√°rios s√£o cobrados proporcionalmente ao uso do servi√ßo. Al√©m disso, o Azure OpenAI Service oferece seguran√ßa de n√≠vel empresarial e um framework de IA respons√°vel sobre as capacidades dos modelos.

Os modelos s√£o apenas a Rede Neural, com os par√¢metros, pesos e outros. Permitem que as empresas os executem localmente, mas exigem a compra de equipamentos, a constru√ß√£o de uma estrutura para escalonamento e a aquisi√ß√£o de uma licen√ßa ou o uso de um modelo de c√≥digo aberto. Um modelo como o LLaMA est√° dispon√≠vel para uso, exigindo poder computacional para executar o modelo.

## Como testar e iterar com diferentes modelos para entender o desempenho no Azure

Depois que nossa equipe explorou o cen√°rio atual de LLMs e identificou alguns bons candidatos para seus cen√°rios, o pr√≥ximo passo √© test√°-los com seus dados e cargas de trabalho. Este √© um processo iterativo, realizado por meio de experimentos e medi√ß√µes.
A maioria dos modelos que mencion√°mos nos par√°grafos anteriores (modelos da OpenAI, modelos de c√≥digo aberto como Llama2 e transformers da Hugging Face) est√£o dispon√≠veis no [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) no [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √© uma plataforma na nuvem projetada para desenvolvedores criarem aplica√ß√µes de IA generativa e gerirem todo o ciclo de desenvolvimento - desde a experimenta√ß√£o at√© √† avalia√ß√£o - combinando todos os servi√ßos de IA do Azure num √∫nico hub com uma interface gr√°fica pr√°tica. O Cat√°logo de Modelos no Azure AI Studio permite ao utilizador:

- Encontrar o Modelo Base de interesse no cat√°logo - seja propriet√°rio ou de c√≥digo aberto, filtrando por tarefa, licen√ßa ou nome. Para melhorar a pesquisa, os modelos est√£o organizados em cole√ß√µes, como a cole√ß√£o Azure OpenAI, cole√ß√£o Hugging Face, entre outras.

![Cat√°logo de modelos](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.pt.png)

- Rever o cart√£o do modelo, incluindo uma descri√ß√£o detalhada do uso pretendido e dos dados de treino, exemplos de c√≥digo e resultados de avalia√ß√£o na biblioteca interna de avalia√ß√µes.

![Cart√£o do modelo](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.pt.png)

- Comparar benchmarks entre modelos e conjuntos de dados dispon√≠veis na ind√∫stria para avaliar qual deles atende ao cen√°rio de neg√≥cio, atrav√©s do painel [Benchmarks de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarks de modelos](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.pt.png)

- Ajustar o modelo com dados de treino personalizados para melhorar o desempenho do modelo numa carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e rastreamento do Azure AI Studio.

![Ajuste de modelo](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.pt.png)

- Implementar o modelo pr√©-treinado original ou a vers√£o ajustada para uma infer√™ncia remota em tempo real - computa√ß√£o gerida - ou endpoint de API sem servidor - [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - para permitir que as aplica√ß√µes o consumam.

![Implementa√ß√£o de modelo](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.pt.png)

> [!NOTE]
> Nem todos os modelos no cat√°logo est√£o atualmente dispon√≠veis para ajuste e/ou implementa√ß√£o pay-as-you-go. Verifique o cart√£o do modelo para detalhes sobre as capacidades e limita√ß√µes do modelo.

## Melhorando os resultados de LLM

Explor√°mos com a nossa equipa de startup diferentes tipos de LLMs e uma plataforma na nuvem (Azure Machine Learning) que nos permite comparar diferentes modelos, avali√°-los com dados de teste, melhorar o desempenho e implement√°-los em endpoints de infer√™ncia.

Mas quando √© que devem considerar ajustar um modelo em vez de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias abordagens que uma empresa pode usar para obter os resultados necess√°rios de um LLM. Pode-se selecionar diferentes tipos de modelos com diferentes graus de treino ao implementar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens diferentes:

- **Engenharia de prompts com contexto**. A ideia √© fornecer contexto suficiente ao criar o prompt para garantir que obtenha as respostas necess√°rias.

- **Gera√ß√£o Aumentada por Recupera√ß√£o, RAG**. Os seus dados podem estar numa base de dados ou endpoint web, por exemplo. Para garantir que esses dados, ou um subconjunto deles, sejam inclu√≠dos no momento de criar o prompt, pode-se buscar os dados relevantes e torn√°-los parte do prompt do utilizador.

- **Modelo ajustado**. Aqui, o modelo √© treinado adicionalmente com os seus pr√≥prios dados, o que o torna mais preciso e responsivo √†s suas necessidades, mas pode ser dispendioso.

![Implementa√ß√£o de LLMs](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.pt.png)

Fonte da imagem: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Engenharia de Prompts com Contexto

Os LLMs pr√©-treinados funcionam muito bem em tarefas gerais de linguagem natural, mesmo quando chamados com um prompt curto, como uma frase para completar ou uma pergunta ‚Äì o chamado aprendizado ‚Äúzero-shot‚Äù.

No entanto, quanto mais o utilizador conseguir enquadrar a sua consulta, com um pedido detalhado e exemplos ‚Äì o Contexto ‚Äì mais precisa e pr√≥xima das expectativas do utilizador ser√° a resposta. Neste caso, falamos de aprendizado ‚Äúone-shot‚Äù se o prompt incluir apenas um exemplo e de aprendizado ‚Äúfew-shot‚Äù se incluir v√°rios exemplos. A engenharia de prompts com contexto √© a abordagem mais econ√≥mica para come√ßar.

### Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)

Os LLMs t√™m a limita√ß√£o de que s√≥ podem usar os dados que foram utilizados durante o seu treino para gerar uma resposta. Isso significa que n√£o sabem nada sobre os factos que ocorreram ap√≥s o processo de treino e n√£o podem aceder a informa√ß√µes n√£o p√∫blicas (como dados da empresa). 

Isso pode ser superado atrav√©s do RAG, uma t√©cnica que aumenta o prompt com dados externos na forma de fragmentos de documentos, considerando os limites de comprimento do prompt. Isso √© suportado por ferramentas de base de dados de vetores (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam os fragmentos √∫teis de v√°rias fontes de dados predefinidas e os adicionam ao Contexto do prompt.

Esta t√©cnica √© muito √∫til quando uma empresa n√£o tem dados suficientes, tempo suficiente ou recursos para ajustar um LLM, mas ainda assim deseja melhorar o desempenho numa carga de trabalho espec√≠fica e reduzir os riscos de fabrica√ß√µes, ou seja, distor√ß√µes da realidade ou conte√∫do prejudicial.

### Modelo ajustado

O ajuste √© um processo que utiliza aprendizado por transfer√™ncia para ‚Äòadaptar‚Äô o modelo a uma tarefa espec√≠fica ou para resolver um problema espec√≠fico. Diferentemente do aprendizado few-shot e do RAG, resulta na gera√ß√£o de um novo modelo, com pesos e vieses atualizados. Requer um conjunto de exemplos de treino consistindo num √∫nico input (o prompt) e o seu output associado (a conclus√£o). 

Esta seria a abordagem preferida se:

- **Usar modelos ajustados**. Uma empresa gostaria de usar modelos ajustados menos capazes (como modelos de embedding) em vez de modelos de alto desempenho, resultando numa solu√ß√£o mais econ√≥mica e r√°pida.

- **Considerar lat√™ncia**. A lat√™ncia √© importante para um caso de uso espec√≠fico, ent√£o n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que devem ser aprendidos pelo modelo n√£o cabe no limite de comprimento do prompt.

- **Manter-se atualizado**. Uma empresa tem muitos dados de alta qualidade e etiquetas de verdade base e os recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo treinado

Treinar um LLM do zero √©, sem d√∫vida, a abordagem mais dif√≠cil e complexa de adotar, exigindo quantidades massivas de dados, recursos qualificados e poder computacional adequado. Esta op√ß√£o deve ser considerada apenas num cen√°rio em que uma empresa tenha um caso de uso espec√≠fico para o seu dom√≠nio e uma grande quantidade de dados centrados nesse dom√≠nio.

## Verifica√ß√£o de conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de conclus√£o de um LLM?

1. Engenharia de prompts com contexto  
1. RAG  
1. Modelo ajustado  

A:3, se tiver tempo, recursos e dados de alta qualidade, o ajuste √© a melhor op√ß√£o para se manter atualizado. No entanto, se estiver a tentar melhorar as coisas e n√£o tiver tempo, vale a pena considerar primeiro o RAG.

## üöÄ Desafio

Leia mais sobre como pode [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para o seu neg√≥cio.

## Excelente trabalho, continue a aprender

Depois de concluir esta li√ß√£o, consulte a nossa [cole√ß√£o de aprendizagem sobre IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar a aprofundar os seus conhecimentos sobre IA generativa!

Avance para a Li√ß√£o 3, onde exploraremos como [construir com IA generativa de forma respons√°vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.