<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-18T00:39:11+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "pt"
}
-->
# Usar IA Generativa de Forma Respons√°vel

[![Usar IA Generativa de Forma Respons√°vel](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.pt.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _Clique na imagem acima para assistir ao v√≠deo desta li√ß√£o_

√â f√°cil ficar fascinado com a IA, especialmente a IA generativa, mas √© importante considerar como utiliz√°-la de forma respons√°vel. √â necess√°rio pensar em como garantir que os resultados sejam justos, n√£o prejudiciais e mais. Este cap√≠tulo tem como objetivo fornecer o contexto mencionado, o que considerar e como tomar medidas ativas para melhorar o uso da IA.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Por que deve-se priorizar a IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Princ√≠pios fundamentais da IA Respons√°vel e como eles se relacionam com a IA Generativa.
- Como colocar esses princ√≠pios de IA Respons√°vel em pr√°tica atrav√©s de estrat√©gias e ferramentas.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, voc√™ saber√°:

- A import√¢ncia da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quando pensar e aplicar os princ√≠pios fundamentais da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quais ferramentas e estrat√©gias est√£o dispon√≠veis para colocar o conceito de IA Respons√°vel em pr√°tica.

## Princ√≠pios da IA Respons√°vel

O entusiasmo pela IA Generativa nunca foi t√£o grande. Esse entusiasmo trouxe muitos novos desenvolvedores, aten√ß√£o e financiamento para este campo. Embora isso seja muito positivo para quem deseja construir produtos e empresas usando IA Generativa, tamb√©m √© importante avan√ßar de forma respons√°vel.

Ao longo deste curso, estamos focados em construir nossa startup e nosso produto educacional de IA. Usaremos os princ√≠pios da IA Respons√°vel: Justi√ßa, Inclus√£o, Confiabilidade/Seguran√ßa, Seguran√ßa e Privacidade, Transpar√™ncia e Responsabilidade. Com esses princ√≠pios, exploraremos como eles se relacionam com o uso da IA Generativa em nossos produtos.

## Por que Priorizar a IA Respons√°vel

Ao construir um produto, adotar uma abordagem centrada no ser humano, mantendo os melhores interesses do usu√°rio em mente, leva aos melhores resultados.

A singularidade da IA Generativa est√° em sua capacidade de criar respostas √∫teis, informa√ß√µes, orienta√ß√µes e conte√∫dos para os usu√°rios. Isso pode ser feito sem muitos passos manuais, o que pode levar a resultados muito impressionantes. Sem planejamento e estrat√©gias adequados, isso tamb√©m pode, infelizmente, levar a resultados prejudiciais para seus usu√°rios, seu produto e a sociedade como um todo.

Vamos analisar alguns (mas n√£o todos) desses resultados potencialmente prejudiciais:

### Alucina√ß√µes

Alucina√ß√µes s√£o um termo usado para descrever quando um LLM produz conte√∫do que √© completamente sem sentido ou algo que sabemos ser factualmente incorreto com base em outras fontes de informa√ß√£o.

Por exemplo, suponha que criemos um recurso para nossa startup que permita aos estudantes fazer perguntas hist√≥ricas a um modelo. Um estudante pergunta: `Quem foi o √∫nico sobrevivente do Titanic?`

O modelo produz uma resposta como a seguinte:

![Prompt dizendo "Quem foi o √∫nico sobrevivente do Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fonte: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Esta √© uma resposta muito confiante e detalhada. Infelizmente, est√° incorreta. Mesmo com uma pesquisa m√≠nima, descobrir√≠amos que houve mais de um sobrevivente do desastre do Titanic. Para um estudante que est√° come√ßando a pesquisar este t√≥pico, esta resposta pode ser persuasiva o suficiente para n√£o ser questionada e tratada como fato. As consequ√™ncias disso podem levar o sistema de IA a ser pouco confi√°vel e impactar negativamente a reputa√ß√£o da nossa startup.

Com cada itera√ß√£o de um determinado LLM, temos visto melhorias de desempenho na minimiza√ß√£o de alucina√ß√µes. Mesmo com essa melhoria, n√≥s, como criadores e usu√°rios de aplica√ß√µes, ainda precisamos estar cientes dessas limita√ß√µes.

### Conte√∫do Prejudicial

J√° abordamos na se√ß√£o anterior o caso em que um LLM produz respostas incorretas ou sem sentido. Outro risco que precisamos estar atentos √© quando um modelo responde com conte√∫do prejudicial.

Conte√∫do prejudicial pode ser definido como:

- Fornecer instru√ß√µes ou encorajar autoles√£o ou danos a determinados grupos.
- Conte√∫do odioso ou depreciativo.
- Orientar o planejamento de qualquer tipo de ataque ou atos violentos.
- Fornecer instru√ß√µes sobre como encontrar conte√∫do ilegal ou cometer atos ilegais.
- Exibir conte√∫do sexualmente expl√≠cito.

Para nossa startup, queremos garantir que temos as ferramentas e estrat√©gias certas para evitar que esse tipo de conte√∫do seja visto pelos estudantes.

### Falta de Justi√ßa

Justi√ßa √© definida como ‚Äúgarantir que um sistema de IA esteja livre de preconceitos e discrimina√ß√£o e que trate todos de forma justa e igualit√°ria.‚Äù No mundo da IA Generativa, queremos garantir que vis√µes de mundo excludentes de grupos marginalizados n√£o sejam refor√ßadas pelos resultados do modelo.

Esses tipos de resultados n√£o apenas prejudicam a constru√ß√£o de experi√™ncias positivas de produto para nossos usu√°rios, mas tamb√©m causam danos sociais adicionais. Como criadores de aplica√ß√µes, devemos sempre ter em mente uma base de usu√°rios ampla e diversificada ao construir solu√ß√µes com IA Generativa.

## Como Usar IA Generativa de Forma Respons√°vel

Agora que identificamos a import√¢ncia da IA Generativa Respons√°vel, vamos analisar 4 etapas que podemos seguir para construir nossas solu√ß√µes de IA de forma respons√°vel:

![Ciclo de Mitiga√ß√£o](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.pt.png)

### Medir Danos Potenciais

Nos testes de software, testamos as a√ß√µes esperadas de um usu√°rio em uma aplica√ß√£o. Da mesma forma, testar um conjunto diversificado de prompts que os usu√°rios provavelmente usar√£o √© uma boa maneira de medir danos potenciais.

Como nossa startup est√° construindo um produto educacional, seria bom preparar uma lista de prompts relacionados √† educa√ß√£o. Isso poderia abranger um determinado assunto, fatos hist√≥ricos e prompts sobre a vida estudantil.

### Mitigar Danos Potenciais

Agora √© hora de encontrar maneiras de prevenir ou limitar os danos potenciais causados pelo modelo e suas respostas. Podemos analisar isso em 4 camadas diferentes:

![Camadas de Mitiga√ß√£o](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.pt.png)

- **Modelo**. Escolher o modelo certo para o caso de uso certo. Modelos maiores e mais complexos, como o GPT-4, podem causar mais risco de conte√∫do prejudicial quando aplicados a casos de uso menores e mais espec√≠ficos. Usar seus dados de treinamento para ajuste fino tamb√©m reduz o risco de conte√∫do prejudicial.

- **Sistema de Seguran√ßa**. Um sistema de seguran√ßa √© um conjunto de ferramentas e configura√ß√µes na plataforma que serve o modelo e ajuda a mitigar danos. Um exemplo disso √© o sistema de filtragem de conte√∫do no servi√ßo Azure OpenAI. Os sistemas tamb√©m devem detectar ataques de jailbreak e atividades indesejadas, como solicita√ß√µes de bots.

- **Metaprompt**. Metaprompts e grounding s√£o maneiras de direcionar ou limitar o modelo com base em certos comportamentos e informa√ß√µes. Isso pode incluir usar entradas do sistema para definir certos limites do modelo. Al√©m disso, fornecer resultados mais relevantes para o escopo ou dom√≠nio do sistema.

Tamb√©m pode incluir o uso de t√©cnicas como Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) para que o modelo obtenha informa√ß√µes apenas de uma sele√ß√£o de fontes confi√°veis. H√° uma li√ß√£o mais adiante neste curso sobre [constru√ß√£o de aplica√ß√µes de busca](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Experi√™ncia do Usu√°rio**. A camada final √© onde o usu√°rio interage diretamente com o modelo atrav√©s da interface da nossa aplica√ß√£o de alguma forma. Dessa forma, podemos projetar o UI/UX para limitar o usu√°rio nos tipos de entradas que ele pode enviar ao modelo, bem como no texto ou imagens exibidos ao usu√°rio. Ao implementar a aplica√ß√£o de IA, tamb√©m devemos ser transparentes sobre o que nossa aplica√ß√£o de IA Generativa pode e n√£o pode fazer.

Temos uma li√ß√£o inteira dedicada a [Projetar UX para Aplica√ß√µes de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Avaliar o modelo**. Trabalhar com LLMs pode ser desafiador porque nem sempre temos controle sobre os dados nos quais o modelo foi treinado. Mesmo assim, devemos sempre avaliar o desempenho e os resultados do modelo. Ainda √© importante medir a precis√£o, similaridade, fundamenta√ß√£o e relev√¢ncia dos resultados do modelo. Isso ajuda a fornecer transpar√™ncia e confian√ßa para as partes interessadas e usu√°rios.

### Operar uma solu√ß√£o de IA Generativa Respons√°vel

Construir uma pr√°tica operacional em torno de suas aplica√ß√µes de IA √© a etapa final. Isso inclui fazer parcerias com outras partes da nossa startup, como Jur√≠dico e Seguran√ßa, para garantir que estamos em conformidade com todas as pol√≠ticas regulat√≥rias. Antes de lan√ßar, tamb√©m queremos construir planos em torno da entrega, gerenciamento de incidentes e revers√£o para evitar qualquer dano aos nossos usu√°rios.

## Ferramentas

Embora o trabalho de desenvolver solu√ß√µes de IA Respons√°vel possa parecer muito, √© um esfor√ßo que vale a pena. √Ä medida que a √°rea de IA Generativa cresce, mais ferramentas para ajudar os desenvolvedores a integrar responsabilidade de forma eficiente em seus fluxos de trabalho ir√£o amadurecer. Por exemplo, o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) pode ajudar a detectar conte√∫do e imagens prejudiciais por meio de uma solicita√ß√£o de API.

## Verifica√ß√£o de Conhecimento

Quais s√£o algumas coisas que voc√™ precisa considerar para garantir o uso respons√°vel da IA?

1. Que a resposta esteja correta.
1. Uso prejudicial, que a IA n√£o seja usada para fins criminosos.
1. Garantir que a IA esteja livre de preconceitos e discrimina√ß√£o.

R: 2 e 3 est√£o corretas. A IA Respons√°vel ajuda voc√™ a considerar como mitigar efeitos prejudiciais, preconceitos e mais.

## üöÄ Desafio

Leia sobre o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) e veja o que pode adotar para o seu uso.

## Excelente Trabalho, Continue Aprendendo

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de aprendizado sobre IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento sobre IA Generativa!

Avance para a Li√ß√£o 4, onde exploraremos [Fundamentos de Engenharia de Prompts](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o profissional realizada por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.