<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:54:09+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "pt"
}
-->
# Usar a IA Generativa de Forma Respons√°vel

[![Using Generative AI Responsibly](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.pt.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

√â f√°cil ficar fascinado com a IA e, em particular, com a IA generativa, mas √© importante pensar em como a usar de forma respons√°vel. Deve considerar aspetos como garantir que o resultado √© justo, n√£o prejudicial e muito mais. Este cap√≠tulo pretende fornecer o contexto mencionado, o que deve ter em conta e como tomar medidas ativas para melhorar a sua utiliza√ß√£o da IA.

## Introdu√ß√£o

Esta li√ß√£o ir√° abordar:

- Por que deve priorizar a IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Princ√≠pios fundamentais da IA Respons√°vel e como se relacionam com a IA Generativa.
- Como colocar estes princ√≠pios de IA Respons√°vel em pr√°tica atrav√©s de estrat√©gias e ferramentas.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, saber√°:

- A import√¢ncia da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quando pensar e aplicar os princ√≠pios fundamentais da IA Respons√°vel ao desenvolver aplica√ß√µes de IA Generativa.
- Que ferramentas e estrat√©gias tem dispon√≠veis para colocar o conceito de IA Respons√°vel em pr√°tica.

## Princ√≠pios da IA Respons√°vel

O entusiasmo em torno da IA Generativa nunca foi t√£o grande. Este entusiasmo trouxe muitos novos desenvolvedores, aten√ß√£o e financiamento para esta √°rea. Embora isto seja muito positivo para quem quer criar produtos e empresas usando IA Generativa, √© igualmente importante avan√ßar de forma respons√°vel.

Ao longo deste curso, estamos focados em construir a nossa startup e o nosso produto educativo de IA. Vamos usar os princ√≠pios da IA Respons√°vel: Justi√ßa, Inclusividade, Fiabilidade/Seguran√ßa, Seguran√ßa & Privacidade, Transpar√™ncia e Responsabiliza√ß√£o. Com estes princ√≠pios, exploraremos como eles se relacionam com o uso da IA Generativa nos nossos produtos.

## Por Que Deve Priorizar a IA Respons√°vel

Ao construir um produto, adotar uma abordagem centrada no ser humano, tendo em mente o melhor interesse do utilizador, leva aos melhores resultados.

A singularidade da IA Generativa est√° no seu poder de criar respostas √∫teis, informa√ß√£o, orienta√ß√£o e conte√∫do para os utilizadores. Isto pode ser feito sem muitos passos manuais, o que pode levar a resultados muito impressionantes. Sem um planeamento e estrat√©gias adequadas, infelizmente, tamb√©m pode resultar em consequ√™ncias prejudiciais para os seus utilizadores, para o seu produto e para a sociedade em geral.

Vamos ver alguns (mas n√£o todos) destes poss√≠veis resultados prejudiciais:

### Alucina√ß√µes

Alucina√ß√µes √© um termo usado para descrever quando um LLM produz conte√∫do que √© completamente sem sentido ou algo que sabemos ser factualmente incorreto com base noutras fontes de informa√ß√£o.

Por exemplo, imaginemos que criamos uma funcionalidade para a nossa startup que permite aos estudantes fazer perguntas hist√≥ricas a um modelo. Um estudante pergunta: `Quem foi o √∫nico sobrevivente do Titanic?`

O modelo produz uma resposta como a seguinte:

![Prompt dizendo "Quem foi o √∫nico sobrevivente do Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fonte: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Esta √© uma resposta muito confiante e detalhada. Infelizmente, est√° incorreta. Mesmo com uma pesquisa m√≠nima, descobrir-se-ia que houve mais do que um sobrevivente do desastre do Titanic. Para um estudante que est√° a come√ßar a investigar este tema, esta resposta pode ser suficientemente persuasiva para n√£o ser questionada e ser tratada como um facto. As consequ√™ncias disto podem tornar o sistema de IA pouco fi√°vel e afetar negativamente a reputa√ß√£o da nossa startup.

Com cada itera√ß√£o de qualquer LLM, temos visto melhorias no desempenho para minimizar as alucina√ß√µes. Mesmo com esta melhoria, n√≥s, enquanto construtores de aplica√ß√µes e utilizadores, devemos continuar conscientes destas limita√ß√µes.

### Conte√∫do Prejudicial

Na sec√ß√£o anterior, fal√°mos sobre quando um LLM produz respostas incorretas ou sem sentido. Outro risco que devemos ter em conta √© quando um modelo responde com conte√∫do prejudicial.

Conte√∫do prejudicial pode ser definido como:

- Fornecer instru√ß√µes ou incentivar o auto-preju√≠zo ou o preju√≠zo a determinados grupos.
- Conte√∫do odioso ou depreciativo.
- Orientar o planeamento de qualquer tipo de ataque ou atos violentos.
- Fornecer instru√ß√µes sobre como encontrar conte√∫do ilegal ou cometer atos ilegais.
- Exibir conte√∫do sexualmente expl√≠cito.

Para a nossa startup, queremos garantir que temos as ferramentas e estrat√©gias certas para evitar que este tipo de conte√∫do seja visto pelos estudantes.

### Falta de Justi√ßa

Justi√ßa √© definida como ‚Äúgarantir que um sistema de IA est√° livre de preconceitos e discrimina√ß√£o e que trata todos de forma justa e igualit√°ria.‚Äù No mundo da IA Generativa, queremos assegurar que vis√µes de mundo exclusivas e marginalizadoras n√£o sejam refor√ßadas pela sa√≠da do modelo.

Este tipo de resultados n√£o s√≥ prejudica a cria√ß√£o de experi√™ncias positivas para os nossos utilizadores, como tamb√©m causa danos sociais adicionais. Como construtores de aplica√ß√µes, devemos sempre ter em mente uma base de utilizadores ampla e diversa ao criar solu√ß√µes com IA Generativa.

## Como Usar a IA Generativa de Forma Respons√°vel

Agora que identific√°mos a import√¢ncia da IA Generativa Respons√°vel, vejamos 4 passos que podemos seguir para construir as nossas solu√ß√µes de IA de forma respons√°vel:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.pt.png)

### Medir os Potenciais Danos

No teste de software, testamos as a√ß√µes esperadas de um utilizador numa aplica√ß√£o. De forma semelhante, testar um conjunto diversificado de prompts que os utilizadores provavelmente ir√£o usar √© uma boa forma de medir potenciais danos.

Como a nossa startup est√° a construir um produto educativo, seria √∫til preparar uma lista de prompts relacionados com a educa√ß√£o. Isto pode cobrir uma determinada disciplina, factos hist√≥ricos e prompts sobre a vida estudantil.

### Mitigar os Potenciais Danos

√â agora altura de encontrar formas de prevenir ou limitar os potenciais danos causados pelo modelo e pelas suas respostas. Podemos olhar para isto em 4 camadas diferentes:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.pt.png)

- **Modelo**. Escolher o modelo certo para o caso de uso adequado. Modelos maiores e mais complexos como o GPT-4 podem representar um maior risco de conte√∫do prejudicial quando aplicados a casos de uso mais pequenos e espec√≠ficos. Usar os seus dados de treino para ajustar o modelo tamb√©m reduz o risco de conte√∫do prejudicial.

- **Sistema de Seguran√ßa**. Um sistema de seguran√ßa √© um conjunto de ferramentas e configura√ß√µes na plataforma que serve o modelo e que ajudam a mitigar danos. Um exemplo disto √© o sistema de filtragem de conte√∫do no servi√ßo Azure OpenAI. Os sistemas tamb√©m devem detetar ataques de jailbreak e atividades indesejadas, como pedidos de bots.

- **Metaprompt**. Metaprompts e grounding s√£o formas de direcionar ou limitar o modelo com base em certos comportamentos e informa√ß√µes. Isto pode ser feito usando inputs do sistema para definir certos limites do modelo. Al√©m disso, fornecer sa√≠das que sejam mais relevantes para o √¢mbito ou dom√≠nio do sistema.

Tamb√©m pode incluir t√©cnicas como Retrieval Augmented Generation (RAG) para que o modelo apenas retire informa√ß√£o de uma sele√ß√£o de fontes confi√°veis. H√° uma li√ß√£o mais √† frente neste curso sobre [constru√ß√£o de aplica√ß√µes de pesquisa](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Experi√™ncia do Utilizador**. A camada final √© onde o utilizador interage diretamente com o modelo atrav√©s da interface da nossa aplica√ß√£o. Desta forma, podemos desenhar o UI/UX para limitar o tipo de inputs que o utilizador pode enviar ao modelo, bem como o texto ou imagens exibidas ao utilizador. Ao lan√ßar a aplica√ß√£o de IA, tamb√©m devemos ser transparentes sobre o que a nossa aplica√ß√£o de IA Generativa pode e n√£o pode fazer.

Temos uma li√ß√£o inteira dedicada a [Desenhar UX para Aplica√ß√µes de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Avaliar o modelo**. Trabalhar com LLMs pode ser desafiante porque nem sempre temos controlo sobre os dados com que o modelo foi treinado. Independentemente disso, devemos sempre avaliar o desempenho e as sa√≠das do modelo. √â importante medir a precis√£o, similaridade, fundamenta√ß√£o e relev√¢ncia da sa√≠da do modelo. Isto ajuda a proporcionar transpar√™ncia e confian√ßa aos stakeholders e utilizadores.

### Operar uma Solu√ß√£o de IA Generativa Respons√°vel

Construir uma pr√°tica operacional em torno das suas aplica√ß√µes de IA √© a etapa final. Isto inclui colaborar com outras √°reas da nossa startup, como Jur√≠dico e Seguran√ßa, para garantir que estamos em conformidade com todas as pol√≠ticas regulat√≥rias. Antes do lan√ßamento, tamb√©m queremos criar planos para a entrega, gest√£o de incidentes e rollback para evitar que qualquer dano aos nossos utilizadores aumente.

## Ferramentas

Embora o trabalho de desenvolver solu√ß√µes de IA Respons√°vel possa parecer muito, √© um esfor√ßo que vale a pena. √Ä medida que a √°rea da IA Generativa cresce, mais ferramentas para ajudar os desenvolvedores a integrar a responsabilidade de forma eficiente nos seus fluxos de trabalho ir√£o amadurecer. Por exemplo, o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) pode ajudar a detetar conte√∫do e imagens prejudiciais atrav√©s de um pedido API.

## Verifica√ß√£o de Conhecimento

Quais s√£o algumas das coisas de que precisa de se preocupar para garantir o uso respons√°vel da IA?

1. Que a resposta esteja correta.  
1. Uso prejudicial, que a IA n√£o seja usada para fins criminosos.  
1. Garantir que a IA est√° livre de preconceitos e discrimina√ß√£o.

R: 2 e 3 est√£o corretos. A IA Respons√°vel ajuda a considerar como mitigar efeitos prejudiciais, preconceitos e muito mais.

## üöÄ Desafio

Leia sobre o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) e veja o que pode adotar para o seu uso.

## Excelente Trabalho, Continue a Aprender

Ap√≥s completar esta li√ß√£o, consulte a nossa [cole√ß√£o de Aprendizagem de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar a aprofundar os seus conhecimentos em IA Generativa!

Siga para a Li√ß√£o 4, onde iremos abordar os [Fundamentos da Engenharia de Prompts](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, por favor tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes da utiliza√ß√£o desta tradu√ß√£o.