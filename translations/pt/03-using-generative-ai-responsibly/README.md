<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:37:52+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "pt"
}
-->
# Usando IA Generativa de Forma Respons√°vel

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

√â f√°cil se fascinar com IA e, em particular, com IA generativa, mas √© preciso considerar como us√°-la de forma respons√°vel. √â necess√°rio pensar em como garantir que o resultado seja justo, n√£o prejudicial e mais. Este cap√≠tulo visa fornecer o contexto mencionado, o que considerar e como tomar medidas ativas para melhorar o uso da IA.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Por que voc√™ deve priorizar a IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Princ√≠pios fundamentais da IA Respons√°vel e como eles se relacionam com a IA Generativa.
- Como colocar esses princ√≠pios de IA Respons√°vel em pr√°tica por meio de estrat√©gia e ferramentas.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, voc√™ saber√°:

- A import√¢ncia da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quando pensar e aplicar os princ√≠pios fundamentais da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quais ferramentas e estrat√©gias est√£o dispon√≠veis para voc√™ colocar o conceito de IA Respons√°vel em pr√°tica.

## Princ√≠pios da IA Respons√°vel

O entusiasmo pela IA Generativa nunca foi t√£o grande. Esse entusiasmo trouxe muitos novos desenvolvedores, aten√ß√£o e financiamento para este espa√ßo. Embora isso seja muito positivo para quem deseja construir produtos e empresas usando IA Generativa, tamb√©m √© importante proceder de forma respons√°vel.

Ao longo deste curso, estamos focando na constru√ß√£o de nossa startup e nosso produto de educa√ß√£o em IA. Usaremos os princ√≠pios da IA Respons√°vel: Justi√ßa, Inclus√£o, Confiabilidade/Seguran√ßa, Seguran√ßa & Privacidade, Transpar√™ncia e Responsabilidade. Com esses princ√≠pios, exploraremos como eles se relacionam com nosso uso de IA Generativa em nossos produtos.

## Por que Voc√™ Deve Priorizar a IA Respons√°vel

Ao construir um produto, adotar uma abordagem centrada no ser humano, mantendo em mente o melhor interesse do usu√°rio, leva aos melhores resultados.

A singularidade da IA Generativa √© seu poder de criar respostas √∫teis, informa√ß√µes, orienta√ß√µes e conte√∫do para os usu√°rios. Isso pode ser feito sem muitos passos manuais, o que pode levar a resultados muito impressionantes. Sem o planejamento e as estrat√©gias adequadas, isso tamb√©m pode, infelizmente, levar a alguns resultados prejudiciais para seus usu√°rios, seu produto e a sociedade como um todo.

Vamos examinar alguns (mas n√£o todos) desses resultados potencialmente prejudiciais:

### Alucina√ß√µes

Alucina√ß√µes s√£o um termo usado para descrever quando um LLM produz conte√∫do que √© completamente sem sentido ou algo que sabemos estar factualmente errado com base em outras fontes de informa√ß√£o.

Vamos supor que constru√≠mos um recurso para nossa startup que permite que os alunos fa√ßam perguntas hist√≥ricas a um modelo. Um aluno faz a pergunta `Who was the sole survivor of Titanic?`

O modelo produz uma resposta como a abaixo:

Esta √© uma resposta muito confiante e completa. Infelizmente, est√° incorreta. Mesmo com uma quantidade m√≠nima de pesquisa, descobrir√≠amos que houve mais de um sobrevivente do desastre do Titanic. Para um aluno que est√° apenas come√ßando a pesquisar este t√≥pico, essa resposta pode ser persuasiva o suficiente para n√£o ser questionada e tratada como fato. As consequ√™ncias disso podem levar o sistema de IA a ser pouco confi√°vel e impactar negativamente a reputa√ß√£o de nossa startup.

Com cada itera√ß√£o de um determinado LLM, vimos melhorias de desempenho em torno da minimiza√ß√£o de alucina√ß√µes. Mesmo com essa melhoria, n√≥s, como construtores de aplica√ß√µes e usu√°rios, ainda precisamos estar cientes dessas limita√ß√µes.

### Conte√∫do Prejudicial

Cobrimos na se√ß√£o anterior quando um LLM produz respostas incorretas ou sem sentido. Outro risco do qual precisamos estar cientes √© quando um modelo responde com conte√∫do prejudicial.

Conte√∫do prejudicial pode ser definido como:

- Fornecer instru√ß√µes ou encorajar autoles√£o ou dano a certos grupos.
- Conte√∫do odioso ou depreciativo.
- Orientar o planejamento de qualquer tipo de ataque ou atos violentos.
- Fornecer instru√ß√µes sobre como encontrar conte√∫do ilegal ou cometer atos ilegais.
- Exibir conte√∫do sexualmente expl√≠cito.

Para nossa startup, queremos garantir que temos as ferramentas e estrat√©gias certas em vigor para impedir que esse tipo de conte√∫do seja visto pelos alunos.

### Falta de Justi√ßa

Justi√ßa √© definida como "garantir que um sistema de IA esteja livre de preconceitos e discrimina√ß√£o e que trate todos de forma justa e igualit√°ria." No mundo da IA Generativa, queremos garantir que vis√µes de mundo excludentes de grupos marginalizados n√£o sejam refor√ßadas pela sa√≠da do modelo.

Esses tipos de sa√≠das n√£o s√£o apenas destrutivos para construir experi√™ncias de produto positivas para nossos usu√°rios, mas tamb√©m causam mais danos sociais. Como construtores de aplica√ß√µes, devemos sempre ter em mente uma base de usu√°rios ampla e diversa ao construir solu√ß√µes com IA Generativa.

## Como Usar a IA Generativa de Forma Respons√°vel

Agora que identificamos a import√¢ncia da IA Generativa Respons√°vel, vamos examinar 4 etapas que podemos seguir para construir nossas solu√ß√µes de IA de forma respons√°vel:

### Medir Potenciais Danos

Nos testes de software, testamos as a√ß√µes esperadas de um usu√°rio em uma aplica√ß√£o. Da mesma forma, testar um conjunto diversificado de prompts que os usu√°rios provavelmente usar√£o √© uma boa maneira de medir danos potenciais.

Como nossa startup est√° construindo um produto educacional, seria bom preparar uma lista de prompts relacionados √† educa√ß√£o. Isso poderia cobrir um determinado assunto, fatos hist√≥ricos e prompts sobre a vida estudantil.

### Mitigar Potenciais Danos

Agora √© hora de encontrar maneiras de prevenir ou limitar o potencial dano causado pelo modelo e suas respostas. Podemos olhar para isso em 4 camadas diferentes:

- **Modelo**. Escolher o modelo certo para o caso de uso certo. Modelos maiores e mais complexos, como o GPT-4, podem causar mais risco de conte√∫do prejudicial quando aplicados a casos de uso menores e mais espec√≠ficos. Usar seus dados de treinamento para ajuste fino tamb√©m reduz o risco de conte√∫do prejudicial.

- **Sistema de Seguran√ßa**. Um sistema de seguran√ßa √© um conjunto de ferramentas e configura√ß√µes na plataforma que serve o modelo e ajuda a mitigar danos. Um exemplo disso √© o sistema de filtragem de conte√∫do no servi√ßo Azure OpenAI. Os sistemas tamb√©m devem detectar ataques de jailbreak e atividades indesejadas, como solicita√ß√µes de bots.

- **Metaprompt**. Metaprompts e grounding s√£o maneiras de direcionar ou limitar o modelo com base em certos comportamentos e informa√ß√µes. Isso pode ser usando entradas do sistema para definir certos limites do modelo. Al√©m disso, fornecer sa√≠das mais relevantes para o escopo ou dom√≠nio do sistema.

Tamb√©m pode ser usando t√©cnicas como Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) para que o modelo apenas busque informa√ß√µes de uma sele√ß√£o de fontes confi√°veis. H√° uma li√ß√£o mais adiante neste curso para [construir aplica√ß√µes de busca](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Experi√™ncia do Usu√°rio**. A camada final √© onde o usu√°rio interage diretamente com o modelo atrav√©s da interface de nossa aplica√ß√£o de alguma forma. Dessa forma, podemos projetar a UI/UX para limitar o usu√°rio nos tipos de entradas que podem ser enviadas ao modelo, bem como textos ou imagens exibidos ao usu√°rio. Ao implantar a aplica√ß√£o de IA, tamb√©m devemos ser transparentes sobre o que nossa aplica√ß√£o de IA Generativa pode e n√£o pode fazer.

Temos uma li√ß√£o inteira dedicada a [Projetar UX para Aplica√ß√µes de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Avaliar modelo**. Trabalhar com LLMs pode ser desafiador porque nem sempre temos controle sobre os dados nos quais o modelo foi treinado. Independentemente disso, devemos sempre avaliar o desempenho e as sa√≠das do modelo. Ainda √© importante medir a precis√£o, similaridade, fundamenta√ß√£o e relev√¢ncia da sa√≠da do modelo. Isso ajuda a fornecer transpar√™ncia e confian√ßa para as partes interessadas e usu√°rios.

### Operar uma Solu√ß√£o de IA Generativa Respons√°vel

Construir uma pr√°tica operacional em torno de suas aplica√ß√µes de IA √© a etapa final. Isso inclui parcerias com outras partes de nossa startup, como Jur√≠dico e Seguran√ßa, para garantir que estamos em conformidade com todas as pol√≠ticas regulat√≥rias. Antes do lan√ßamento, tamb√©m queremos construir planos em torno da entrega, gerenciamento de incidentes e rollback para evitar qualquer dano aos nossos usu√°rios √† medida que crescemos.

## Ferramentas

Embora o trabalho de desenvolver solu√ß√µes de IA Respons√°vel possa parecer muito, √© um trabalho que vale a pena o esfor√ßo. √Ä medida que a √°rea de IA Generativa cresce, mais ferramentas para ajudar os desenvolvedores a integrar a responsabilidade em seus fluxos de trabalho de forma eficiente amadurecer√£o. Por exemplo, o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) pode ajudar a detectar conte√∫do e imagens prejudiciais por meio de uma solicita√ß√£o de API.

## Verifica√ß√£o de Conhecimento

Quais s√£o algumas coisas que voc√™ precisa se preocupar para garantir o uso respons√°vel da IA?

1. Que a resposta esteja correta.
1. Uso prejudicial, que a IA n√£o seja usada para fins criminosos.
1. Garantir que a IA esteja livre de preconceitos e discrimina√ß√£o.

A: 2 e 3 est√£o corretas. A IA Respons√°vel ajuda voc√™ a considerar como mitigar efeitos prejudiciais e preconceitos e mais.

## üöÄ Desafio

Leia sobre [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) e veja o que voc√™ pode adotar para seu uso.

## √ìtimo Trabalho, Continue Seu Aprendizado

Ap√≥s completar esta li√ß√£o, confira nossa [cole√ß√£o de aprendizado de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento sobre IA Generativa!

V√° para a Li√ß√£o 4, onde analisaremos [Fundamentos de Engenharia de Prompt](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se uma tradu√ß√£o humana profissional. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.