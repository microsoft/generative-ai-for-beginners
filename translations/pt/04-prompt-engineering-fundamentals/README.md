<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dcbaaae026cb50fee071e690685b5843",
  "translation_date": "2025-08-26T16:18:12+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "pt"
}
-->
# Fundamentos da Engenharia de Prompts

[![Fundamentos da Engenharia de Prompts](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.pt.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introdu√ß√£o
Este m√≥dulo aborda conceitos e t√©cnicas essenciais para criar prompts eficazes em modelos de IA generativa. A forma como escreves o teu prompt para um LLM tamb√©m faz diferen√ßa. Um prompt bem elaborado pode garantir uma resposta de melhor qualidade. Mas afinal, o que significam termos como _prompt_ e _engenharia de prompts_? E como posso melhorar o _input_ do prompt que envio para o LLM? S√£o estas as perguntas que vamos tentar responder neste cap√≠tulo e no seguinte.

A _IA generativa_ consegue criar novos conte√∫dos (por exemplo, texto, imagens, √°udio, c√≥digo, etc.) em resposta a pedidos dos utilizadores. Isto √© poss√≠vel gra√ßas a _Modelos de Linguagem de Grande Escala_ como a s√©rie GPT ("Generative Pre-trained Transformer") da OpenAI, treinados para trabalhar com linguagem natural e c√≥digo.

Os utilizadores podem agora interagir com estes modelos atrav√©s de interfaces familiares como o chat, sem precisarem de conhecimentos t√©cnicos ou forma√ß√£o espec√≠fica. Os modelos s√£o _baseados em prompts_ ‚Äì o utilizador envia um texto (prompt) e recebe uma resposta da IA (completion). Pode depois "conversar com a IA" de forma iterativa, em v√°rias voltas, ajustando o prompt at√© que a resposta corresponda ao que pretende.

Os "prompts" tornam-se assim a principal _interface de programa√ß√£o_ para aplica√ß√µes de IA generativa, indicando aos modelos o que fazer e influenciando a qualidade das respostas. A "Engenharia de Prompts" √© uma √°rea de estudo em r√°pido crescimento, focada no _design e otimiza√ß√£o_ de prompts para garantir respostas consistentes e de qualidade em larga escala.

## Objetivos de Aprendizagem

Nesta li√ß√£o, vamos aprender o que √© Engenharia de Prompts, porque √© importante e como podemos criar prompts mais eficazes para um determinado modelo e objetivo de aplica√ß√£o. Vamos perceber os conceitos fundamentais e as melhores pr√°ticas para engenharia de prompts ‚Äì e conhecer um ambiente interativo em Jupyter Notebooks onde podemos ver estes conceitos aplicados a exemplos reais.

No final desta li√ß√£o seremos capazes de:

1. Explicar o que √© engenharia de prompts e porque √© relevante.
2. Descrever os componentes de um prompt e como s√£o utilizados.
3. Aprender boas pr√°ticas e t√©cnicas para engenharia de prompts.
4. Aplicar as t√©cnicas aprendidas a exemplos reais, usando um endpoint da OpenAI.

## Termos-Chave

Engenharia de Prompts: Pr√°tica de desenhar e aperfei√ßoar inputs para orientar modelos de IA a produzir os resultados desejados.
Tokeniza√ß√£o: Processo de converter texto em unidades mais pequenas, chamadas tokens, que o modelo consegue compreender e processar.
LLMs Ajustados por Instru√ß√µes: Modelos de Linguagem de Grande Escala (LLMs) que foram ajustados com instru√ß√µes espec√≠ficas para melhorar a precis√£o e relev√¢ncia das respostas.

## Sandbox de Aprendizagem

A engenharia de prompts √©, para j√°, mais uma arte do que uma ci√™ncia. A melhor forma de desenvolver intui√ß√£o para esta √°rea √© _praticar bastante_ e adotar uma abordagem de tentativa e erro, combinando conhecimento do dom√≠nio de aplica√ß√£o com t√©cnicas recomendadas e otimiza√ß√µes espec√≠ficas do modelo.

O Jupyter Notebook que acompanha esta li√ß√£o oferece um ambiente _sandbox_ onde podes experimentar o que aprendes ‚Äì √† medida que avan√ßas ou como parte do desafio de c√≥digo no final. Para executar os exerc√≠cios, vais precisar de:

1. **Uma chave de API do Azure OpenAI** ‚Äì o endpoint do servi√ßo para um LLM implementado.
2. **Um ambiente de execu√ß√£o Python** ‚Äì onde o Notebook pode ser executado.
3. **Vari√°veis de ambiente locais** ‚Äì _conclui agora os passos de [CONFIGURA√á√ÉO](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) para te preparares_.

O notebook inclui exerc√≠cios _iniciais_ ‚Äì mas √©s incentivado a acrescentar as tuas pr√≥prias sec√ß√µes de _Markdown_ (descri√ß√£o) e _C√≥digo_ (pedidos de prompt) para experimentar mais exemplos ou ideias ‚Äì e desenvolver a tua intui√ß√£o para o design de prompts.

## Guia Ilustrado

Queres ter uma vis√£o geral do que esta li√ß√£o cobre antes de come√ßares? Consulta este guia ilustrado, que te d√° uma ideia dos principais t√≥picos abordados e dos pontos-chave para refletires em cada um. O roteiro da li√ß√£o leva-te desde a compreens√£o dos conceitos e desafios fundamentais at√© √† sua resolu√ß√£o com t√©cnicas e boas pr√°ticas relevantes de engenharia de prompts. Repara que a sec√ß√£o "T√©cnicas Avan√ßadas" neste guia refere-se a conte√∫dos que ser√£o abordados no _pr√≥ximo_ cap√≠tulo deste curso.

![Guia Ilustrado para Engenharia de Prompts](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.pt.png)

## A Nossa Startup

Agora, vamos falar sobre como _este tema_ se relaciona com a nossa miss√£o de startup de [trazer inova√ß√£o em IA para a educa√ß√£o](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos criar aplica√ß√µes de _aprendizagem personalizada_ com IA ‚Äì por isso, vamos pensar em como diferentes utilizadores da nossa aplica√ß√£o podem "desenhar" prompts:

- **Administradores** podem pedir √† IA para _analisar dados curriculares e identificar lacunas de cobertura_. A IA pode resumir os resultados ou visualiz√°-los com c√≥digo.
- **Educadores** podem pedir √† IA para _gerar um plano de aula para um p√∫blico-alvo e tema espec√≠fico_. A IA pode construir o plano personalizado num formato definido.
- **Alunos** podem pedir √† IA para _os ajudar numa disciplina dif√≠cil_. A IA pode orientar os alunos com li√ß√µes, dicas e exemplos adaptados ao seu n√≠vel.

Isto √© apenas o in√≠cio. V√™ [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì uma biblioteca open-source de prompts, curada por especialistas em educa√ß√£o ‚Äì para teres uma ideia mais ampla das possibilidades! _Experimenta alguns desses prompts no sandbox ou no OpenAI Playground para ver o que acontece!_

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve cobrir o conceito fundamental #1.
Refor√ßa o conceito com exemplos e refer√™ncias.

CONCEITO #1:
Engenharia de Prompts.
Define e explica porque √© necess√°ria.
-->

## O que √© Engenharia de Prompts?

Come√ß√°mos esta li√ß√£o por definir **Engenharia de Prompts** como o processo de _desenhar e otimizar_ inputs de texto (prompts) para garantir respostas consistentes e de qualidade (completions) para um determinado objetivo de aplica√ß√£o e modelo. Podemos pensar nisto como um processo em 2 etapas:

- _desenhar_ o prompt inicial para um modelo e objetivo espec√≠ficos
- _refinar_ o prompt de forma iterativa para melhorar a qualidade da resposta

Este √© inevitavelmente um processo de tentativa e erro que exige intui√ß√£o e esfor√ßo do utilizador para obter os melhores resultados. Mas porque √© importante? Para responder, precisamos primeiro de perceber tr√™s conceitos:

- _Tokeniza√ß√£o_ = como o modelo "v√™" o prompt
- _LLMs Base_ = como o modelo de base "processa" um prompt
- _LLMs Ajustados por Instru√ß√µes_ = como o modelo consegue agora ver "tarefas"

### Tokeniza√ß√£o

Um LLM v√™ os prompts como uma _sequ√™ncia de tokens_, e diferentes modelos (ou vers√µes de um modelo) podem tokenizar o mesmo prompt de formas distintas. Como os LLMs s√£o treinados com tokens (e n√£o com texto bruto), a forma como os prompts s√£o tokenizados tem impacto direto na qualidade da resposta gerada.

Para perceberes como funciona a tokeniza√ß√£o, experimenta ferramentas como o [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) mostrado abaixo. Cola o teu prompt ‚Äì e v√™ como √© convertido em tokens, prestando aten√ß√£o ao tratamento de espa√ßos e pontua√ß√£o. Nota que este exemplo mostra um LLM mais antigo (GPT-3) ‚Äì se experimentares com um modelo mais recente, podes obter resultados diferentes.

![Tokeniza√ß√£o](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.pt.png)

### Conceito: Modelos de Base

Depois de tokenizado o prompt, a principal fun√ß√£o do ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou modelo de base) √© prever o pr√≥ximo token nessa sequ√™ncia. Como os LLMs s√£o treinados com enormes conjuntos de dados de texto, t√™m uma boa no√ß√£o das rela√ß√µes estat√≠sticas entre tokens e conseguem fazer essa previs√£o com alguma confian√ßa. Repara que n√£o compreendem o _significado_ das palavras ou tokens do prompt; apenas identificam padr√µes que podem "completar" com a pr√≥xima previs√£o. Podem continuar a prever a sequ√™ncia at√© serem interrompidos pelo utilizador ou por alguma condi√ß√£o pr√©-definida.

Queres ver como funciona a conclus√£o baseada em prompts? Introduz o prompt acima no [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) do Azure OpenAI Studio com as defini√ß√µes padr√£o. O sistema est√° configurado para tratar prompts como pedidos de informa√ß√£o ‚Äì por isso deves ver uma resposta que se enquadra nesse contexto.

Mas e se o utilizador quiser ver algo espec√≠fico que cumpra certos crit√©rios ou objetivos de tarefa? √â aqui que entram os LLMs _ajustados por instru√ß√µes_.

![Conclus√£o de Chat com LLM Base](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.pt.png)

### Conceito: LLMs Ajustados por Instru√ß√µes

Um [LLM Ajustado por Instru√ß√µes](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) parte do modelo de base e √© ajustado com exemplos ou pares de input/output (por exemplo, "mensagens" em v√°rias voltas) que podem conter instru√ß√µes claras ‚Äì e a resposta da IA tenta seguir essa instru√ß√£o.

Isto recorre a t√©cnicas como Aprendizagem por Refor√ßo com Feedback Humano (RLHF), que treinam o modelo para _seguir instru√ß√µes_ e _aprender com o feedback_, produzindo respostas mais adequadas a aplica√ß√µes pr√°ticas e mais relevantes para os objetivos do utilizador.

Vamos experimentar ‚Äì volta ao prompt acima, mas agora altera a _mensagem do sistema_ para fornecer a seguinte instru√ß√£o como contexto:

> _Resume o conte√∫do que te for fornecido para um aluno do segundo ano. Mant√©m o resultado num par√°grafo com 3-5 pontos-chave._

V√™ como o resultado agora est√° ajustado para refletir o objetivo e formato pretendidos? Um educador pode usar diretamente esta resposta nos seus slides para essa aula.

![Conclus√£o de Chat com LLM Ajustado por Instru√ß√µes](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.pt.png)

## Porque precisamos de Engenharia de Prompts?

Agora que sabemos como os prompts s√£o processados pelos LLMs, vamos falar sobre _porque_ precisamos de engenharia de prompts. A resposta est√° no facto de que os LLMs atuais apresentam v√°rios desafios que tornam _completions fi√°veis e consistentes_ mais dif√≠ceis de obter sem investir no design e otimiza√ß√£o dos prompts. Por exemplo:

1. **As respostas dos modelos s√£o estoc√°sticas.** O _mesmo prompt_ provavelmente vai gerar respostas diferentes em modelos ou vers√µes de modelos distintos. E pode at√© produzir resultados diferentes com o _mesmo modelo_ em momentos diferentes. _As t√©cnicas de engenharia de prompts ajudam a minimizar estas varia√ß√µes, fornecendo melhores limites e orienta√ß√µes_.

1. **Os modelos podem inventar respostas.** Os modelos s√£o pr√©-treinados com _conjuntos de dados grandes mas finitos_, o que significa que n√£o t√™m conhecimento sobre conceitos fora desse √¢mbito. Como resultado, podem gerar respostas que s√£o imprecisas, inventadas ou at√© contradit√≥rias com factos conhecidos. _A engenharia de prompts ajuda os utilizadores a identificar e mitigar estas inven√ß√µes, por exemplo, pedindo √† IA cita√ß√µes ou justifica√ß√µes_.

1. **As capacidades dos modelos variam.** Modelos mais recentes ou gera√ß√µes diferentes t√™m capacidades mais avan√ßadas, mas tamb√©m trazem particularidades e compromissos em termos de custo e complexidade. _A engenharia de prompts permite desenvolver boas pr√°ticas e fluxos de trabalho que abstraem diferen√ßas e se adaptam a requisitos espec√≠ficos de cada modelo de forma escal√°vel e fluida_.

Vamos ver isto em a√ß√£o no OpenAI ou Azure OpenAI Playground:

- Usa o mesmo prompt com diferentes implementa√ß√µes de LLM (por exemplo, OpenAI, Azure OpenAI, Hugging Face) ‚Äì reparaste nas varia√ß√µes?
- Usa o mesmo prompt v√°rias vezes com a _mesma_ implementa√ß√£o de LLM (por exemplo, Azure OpenAI playground) ‚Äì como diferiram essas varia√ß√µes?

### Exemplo de Fabrica√ß√µes

Neste curso, usamos o termo **"fabrica√ß√£o"** para referir o fen√≥meno em que os LLMs por vezes geram informa√ß√£o factualmente incorreta devido a limita√ß√µes no seu treino ou outros fatores. Tamb√©m podes ter ouvido este fen√≥meno chamado de _"alucina√ß√µes"_ em artigos ou estudos. No entanto, recomendamos fortemente o uso do termo _"fabrica√ß√£o"_ para evitar atribuir caracter√≠sticas humanas a um resultado gerado por m√°quina. Isto tamb√©m refor√ßa as [diretrizes de IA Respons√°vel](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) do ponto de vista da terminologia, eliminando termos que podem ser considerados ofensivos ou n√£o inclusivos em certos contextos.

Queres perceber como funcionam as fabrica√ß√µes? Pensa num prompt que instrua a IA a gerar conte√∫do sobre um tema inexistente (para garantir que n√£o est√° no conjunto de treino). Por exemplo ‚Äì experimentei este prompt:
# Plano de Aula: A Guerra Marciana de 2076

## Objetivos de Aprendizagem

- Compreender as causas e consequ√™ncias da Guerra Marciana de 2076.
- Analisar o impacto do conflito na sociedade marciana e terrestre.
- Discutir as estrat√©gias militares e diplom√°ticas utilizadas durante a guerra.
- Refletir sobre as li√ß√µes aprendidas e poss√≠veis implica√ß√µes para o futuro.

## Introdu√ß√£o

A Guerra Marciana de 2076 foi um dos eventos mais marcantes do s√©culo XXI, alterando profundamente as rela√ß√µes entre Marte e a Terra. Neste plano de aula, vamos explorar os principais acontecimentos, os protagonistas e as consequ√™ncias deste conflito hist√≥rico.

## Conte√∫do

### 1. Contexto Hist√≥rico

- Coloniza√ß√£o de Marte e tens√µes iniciais com a Terra.
- Disputas por recursos naturais e autonomia marciana.
- Eventos que levaram ao in√≠cio da guerra em 2076.

### 2. Principais Fases do Conflito

- In√≠cio das hostilidades e ataques estrat√©gicos.
- Interven√ß√£o de alian√ßas internacionais.
- Uso de tecnologia avan√ßada e armas inovadoras.

### 3. Protagonistas

- L√≠deres marcianos e terrestres.
- Papel das organiza√ß√µes civis e militares.
- Influ√™ncia de empresas privadas e cientistas.

### 4. Consequ√™ncias

- Mudan√ßas pol√≠ticas e sociais em Marte e na Terra.
- Tratados de paz e reconstru√ß√£o p√≥s-guerra.
- Impacto na explora√ß√£o espacial e nas futuras col√≥nias.

## Atividades

- Debate em grupo sobre as causas da guerra.
- An√°lise de fontes hist√≥ricas e testemunhos de sobreviventes.
- Simula√ß√£o de negocia√ß√µes de paz entre Marte e Terra.

## Avalia√ß√£o

- Participa√ß√£o nas discuss√µes e atividades.
- Elabora√ß√£o de um relat√≥rio sobre as consequ√™ncias da guerra.
- Apresenta√ß√£o de propostas para evitar futuros conflitos interplanet√°rios.

## Recursos

- Documentos hist√≥ricos e artigos cient√≠ficos.
- Mapas das batalhas e movimenta√ß√µes militares.
- Entrevistas com especialistas em hist√≥ria marciana.

## Conclus√£o

A Guerra Marciana de 2076 serve como um exemplo importante dos desafios e oportunidades que surgem com a expans√£o humana para outros planetas. Ao estudar este conflito, podemos aprender a promover a coopera√ß√£o e evitar os erros do passado.
Uma pesquisa na web mostrou-me que existem relatos fict√≠cios (por exemplo, s√©ries de televis√£o ou livros) sobre guerras em Marte ‚Äì mas nenhum em 2076. O senso comum tamb√©m nos diz que 2076 √© _no futuro_ e, por isso, n√£o pode estar associado a um evento real.

Ent√£o, o que acontece quando executamos este prompt com diferentes fornecedores de LLM?

> **Resposta 1**: OpenAI Playground (GPT-35)

![Resposta 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.pt.png)

> **Resposta 2**: Azure OpenAI Playground (GPT-35)

![Resposta 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.pt.png)

> **Resposta 3**: : Hugging Face Chat Playground (LLama-2)

![Resposta 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.pt.png)

Como era de esperar, cada modelo (ou vers√£o do modelo) produz respostas ligeiramente diferentes devido ao comportamento estoc√°stico e √†s varia√ß√µes de capacidade dos modelos. Por exemplo, um modelo dirige-se a um p√∫blico do 8.¬∫ ano, enquanto outro assume um estudante do ensino secund√°rio. Mas todos os tr√™s modelos geraram respostas que poderiam convencer um utilizador desinformado de que o evento era real.

T√©cnicas de engenharia de prompts como _metaprompting_ e _configura√ß√£o de temperatura_ podem reduzir as fabrica√ß√µes dos modelos at√© certo ponto. Novas _arquiteturas_ de engenharia de prompts tamb√©m incorporam novas ferramentas e t√©cnicas de forma integrada no fluxo do prompt, para mitigar ou reduzir alguns destes efeitos.

## Caso de Estudo: GitHub Copilot

Vamos terminar esta sec√ß√£o percebendo como a engenharia de prompts √© usada em solu√ß√µes reais, analisando um Caso de Estudo: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

O GitHub Copilot √© o teu "Programador Parceiro de IA" ‚Äì converte prompts de texto em sugest√µes de c√≥digo e est√° integrado no teu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experi√™ncia de utiliza√ß√£o fluida. Como documentado na s√©rie de blogs abaixo, a vers√£o inicial baseava-se no modelo OpenAI Codex ‚Äì com os engenheiros a perceberem rapidamente a necessidade de afinar o modelo e desenvolver melhores t√©cnicas de engenharia de prompts para melhorar a qualidade do c√≥digo. Em julho, [lan√ßaram um modelo de IA melhorado que vai al√©m do Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugest√µes ainda mais r√°pidas.

L√™ os artigos por ordem para acompanhar a evolu√ß√£o do seu conhecimento.

- **Maio 2023** | [O GitHub Copilot est√° a ficar melhor a compreender o teu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maio 2023** | [Por dentro do GitHub: Trabalhar com os LLMs por tr√°s do GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jun 2023** | [Como escrever melhores prompts para o GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jul 2023** | [.. O GitHub Copilot vai al√©m do Codex com um modelo de IA melhorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [Guia do Programador para Engenharia de Prompts e LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Set 2023** | [Como construir uma app empresarial com LLM: Li√ß√µes do GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Tamb√©m podes explorar o [blog de Engenharia](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para mais artigos como [este](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que mostra como estes modelos e t√©cnicas s√£o _aplicados_ para impulsionar aplica√ß√µes reais.

---

## Constru√ß√£o de Prompts

J√° vimos porque √© que a engenharia de prompts √© importante ‚Äì agora vamos perceber como os prompts s√£o _constru√≠dos_ para podermos avaliar diferentes t√©cnicas para um design de prompts mais eficaz.

### Prompt B√°sico

Comecemos pelo prompt b√°sico: um texto enviado ao modelo sem qualquer outro contexto. Eis um exemplo ‚Äì quando enviamos as primeiras palavras do hino nacional dos EUA √† [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) da OpenAI, esta _completa_ imediatamente a resposta com as linhas seguintes, ilustrando o comportamento b√°sico de previs√£o.

| Prompt (Entrada)     | Completamento (Sa√≠da)                                                                                                                        |
| :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see   | Parece que est√°s a come√ßar a letra de "The Star-Spangled Banner", o hino nacional dos Estados Unidos. A letra completa √© ...                |

### Prompt Complexo

Agora vamos adicionar contexto e instru√ß√µes a esse prompt b√°sico. A [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) permite-nos construir um prompt complexo como um conjunto de _mensagens_ com:

- Pares de entrada/sa√≠da que refletem a entrada do _utilizador_ e a resposta do _assistente_.
- Mensagem de sistema que define o contexto para o comportamento ou personalidade do assistente.

O pedido tem agora o formato abaixo, onde a _tokeniza√ß√£o_ capta eficazmente a informa√ß√£o relevante do contexto e da conversa. Agora, alterar o contexto do sistema pode ter tanto impacto na qualidade das respostas como as entradas do utilizador fornecidas.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt de Instru√ß√£o

Nos exemplos acima, o prompt do utilizador era uma simples consulta de texto que pode ser interpretada como um pedido de informa√ß√£o. Com prompts de _instru√ß√£o_, podemos usar esse texto para especificar uma tarefa com mais detalhe, dando uma orienta√ß√£o mais clara √† IA. Eis um exemplo:

| Prompt (Entrada)                                                                                                                                                                                                                         | Completamento (Sa√≠da)                                                                                                        | Tipo de Instru√ß√£o   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Escreve uma descri√ß√£o da Guerra Civil                                                                                                                                                                                                   | _devolveu um par√°grafo simples_                                                                                              | Simples             |
| Escreve uma descri√ß√£o da Guerra Civil. Indica datas e eventos importantes e descreve a sua relev√¢ncia                                                                                             | _devolveu um par√°grafo seguido de uma lista de datas de eventos importantes com descri√ß√µes_                                  | Complexa            |
| Escreve uma descri√ß√£o da Guerra Civil num par√°grafo. Indica 3 pontos-chave com datas e a sua relev√¢ncia. Indica mais 3 pontos-chave com figuras hist√≥ricas e as suas contribui√ß√µes. Devolve o resultado em formato JSON                   | _devolve detalhes mais extensos numa caixa de texto, formatados em JSON que podes copiar para um ficheiro e validar se necess√°rio_ | Complexa. Formatada. |

## Conte√∫do Principal

Nos exemplos acima, o prompt ainda era bastante aberto, permitindo ao LLM decidir que parte do seu conjunto de dados pr√©-treinado era relevante. Com o padr√£o de design de _conte√∫do principal_, o texto de entrada √© dividido em duas partes:

- uma instru√ß√£o (a√ß√£o)
- conte√∫do relevante (que influencia a a√ß√£o)

Eis um exemplo em que a instru√ß√£o √© "resume isto em 2 frases".

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completamento (Sa√≠da)                                                                                                                                                                                                                                                                             |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter √© o quinto planeta a contar do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa mil vezes menor que a do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registada. O seu nome vem do deus romano J√∫piter.[19] Visto da Terra, J√∫piter pode ser suficientemente brilhante para a sua luz refletida projetar sombras vis√≠veis,[20] e √©, em m√©dia, o terceiro objeto natural mais brilhante no c√©u noturno, depois da Lua e de V√©nus. <br/> **Resume isto em 2 frases curtas** | J√∫piter, o quinto planeta a contar do Sol, √© o maior do Sistema Solar e √© conhecido por ser um dos objetos mais brilhantes no c√©u noturno. Com o nome do deus romano J√∫piter, √© um gigante gasoso cuja massa √© duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. |

O segmento de conte√∫do principal pode ser usado de v√°rias formas para tornar as instru√ß√µes mais eficazes:

- **Exemplos** ‚Äì em vez de dizer ao modelo o que fazer com uma instru√ß√£o expl√≠cita, d√°-lhe exemplos do que fazer e deixa-o inferir o padr√£o.
- **Cues (Ind√≠cios)** ‚Äì segue a instru√ß√£o com um "ind√≠cio" que prepara a resposta, guiando o modelo para respostas mais relevantes.
- **Templates (Modelos)** ‚Äì s√£o 'receitas' repet√≠veis para prompts com espa√ßos reservados (vari√°veis) que podem ser personalizados com dados para casos de uso espec√≠ficos.

Vamos ver estes casos em a√ß√£o.

### Usar Exemplos

Esta √© uma abordagem em que usas o conte√∫do principal para "alimentar o modelo" com exemplos do resultado desejado para uma determinada instru√ß√£o, deixando-o inferir o padr√£o para a sa√≠da pretendida. Dependendo do n√∫mero de exemplos fornecidos, podemos ter zero-shot prompting, one-shot prompting, few-shot prompting, etc.

O prompt passa a ter tr√™s componentes:

- Uma descri√ß√£o da tarefa
- Alguns exemplos do resultado desejado
- O in√≠cio de um novo exemplo (que se torna uma descri√ß√£o impl√≠cita da tarefa)

| Tipo de Aprendizagem | Prompt (Entrada)                                                                                                                                        | Completamento (Sa√≠da)         |
| :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :---------------------------- |
| Zero-shot            | "The Sun is Shining". Translate to Spanish                                                                                                              | "El Sol est√° brillando".      |
| One-shot             | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                   | "Es un d√≠a fr√≠o y ventoso".   |
| Few-shot             | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>   | Basketball                    |
|                      |                                                                                                                                                         |                               |

Repara como tivemos de dar uma instru√ß√£o expl√≠cita ("Translate to Spanish") no zero-shot prompting, mas ela √© inferida no exemplo one-shot. O exemplo few-shot mostra como, ao adicionar mais exemplos, os modelos conseguem fazer infer√™ncias mais precisas sem instru√ß√µes adicionais.

### Ind√≠cios no Prompt (Prompt Cues)

Outra t√©cnica para usar o conte√∫do principal √© fornecer _ind√≠cios_ em vez de exemplos. Neste caso, estamos a dar ao modelo um empurr√£o na dire√ß√£o certa, _come√ßando_ com um excerto que reflete o formato de resposta desejado. O modelo depois "segue o ind√≠cio" e continua nesse registo.

| N√∫mero de Ind√≠cios | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completamento (Sa√≠da)                                                                                                                                                                                                                                                                                       |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                  | J√∫piter √© o quinto planeta a contar do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa mil vezes menor que a do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registada.

**Resumir Isto**                                       | J√∫piter √© o maior planeta do nosso Sistema Solar e o quinto a contar do Sol. √â um gigante gasoso com uma massa equivalente a 1/1000 da do Sol, mas √© mais pesado do que todos os outros planetas juntos. As civiliza√ß√µes antigas j√° conheciam J√∫piter h√° muito tempo, e √© facilmente vis√≠vel no c√©u noturno. |
| 1              | J√∫piter √© o quinto planeta a contar do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registada. <br/>**Resumir Isto** <br/> O que aprendemos √© que J√∫piter | √© o quinto planeta a contar do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas juntos. √â facilmente vis√≠vel a olho nu e √© conhecido desde a Antiguidade.                        |
| 2              | J√∫piter √© o quinto planeta a contar do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registada. <br/>**Resumir Isto** <br/> Top 3 Factos Aprendidos:         | 1. J√∫piter √© o quinto planeta a contar do Sol e o maior do Sistema Solar. <br/> 2. √â um gigante gasoso com uma massa equivalente a um mil√©simo da do Sol...<br/> 3. J√∫piter √© vis√≠vel a olho nu desde a Antiguidade ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Modelos de Prompt

Um modelo de prompt √© uma _receita pr√©-definida para um prompt_ que pode ser guardada e reutilizada conforme necess√°rio, para garantir experi√™ncias de utilizador mais consistentes em larga escala. Na sua forma mais simples, √© apenas uma cole√ß√£o de exemplos de prompts como [este da OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que fornece tanto os componentes interativos do prompt (mensagens do utilizador e do sistema) como o formato de pedido orientado por API - para facilitar a reutiliza√ß√£o.

Numa forma mais complexa, como [este exemplo do LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), cont√©m _espa√ßos reservados_ que podem ser substitu√≠dos por dados de v√°rias fontes (entrada do utilizador, contexto do sistema, fontes de dados externas, etc.) para gerar um prompt de forma din√¢mica. Isto permite criar uma biblioteca de prompts reutiliz√°veis que podem ser usados para garantir experi√™ncias de utilizador consistentes **programaticamente** em escala.

Por fim, o verdadeiro valor dos modelos est√° na capacidade de criar e publicar _bibliotecas de prompts_ para dom√≠nios de aplica√ß√£o verticalizados - onde o modelo de prompt √© agora _optimizado_ para refletir o contexto ou exemplos espec√≠ficos da aplica√ß√£o, tornando as respostas mais relevantes e precisas para o p√∫blico-alvo. O reposit√≥rio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √© um excelente exemplo desta abordagem, ao reunir uma biblioteca de prompts para o dom√≠nio da educa√ß√£o com √™nfase em objetivos-chave como planeamento de aulas, desenho curricular, tutoria de alunos, etc.

## Conte√∫do de Apoio

Se pensarmos na constru√ß√£o de prompts como tendo uma instru√ß√£o (tarefa) e um alvo (conte√∫do principal), ent√£o o _conte√∫do secund√°rio_ √© como contexto adicional que fornecemos para **influenciar a resposta de alguma forma**. Pode ser par√¢metros de afina√ß√£o, instru√ß√µes de formata√ß√£o, taxonomias de t√≥picos, etc., que ajudam o modelo a _ajustar_ a sua resposta para se adequar aos objetivos ou expectativas do utilizador.

Por exemplo: Dado um cat√°logo de cursos com metadados extensos (nome, descri√ß√£o, n√≠vel, etiquetas, instrutor, etc.) sobre todos os cursos dispon√≠veis no curr√≠culo:

- podemos definir uma instru√ß√£o para "resumir o cat√°logo de cursos para o Outono de 2023"
- podemos usar o conte√∫do principal para fornecer alguns exemplos do resultado desejado
- podemos usar o conte√∫do secund√°rio para identificar as 5 principais "etiquetas" de interesse.

Agora, o modelo pode fornecer um resumo no formato mostrado pelos exemplos - mas se um resultado tiver v√°rias etiquetas, pode dar prioridade √†s 5 identificadas no conte√∫do secund√°rio.

---

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve cobrir o conceito central #1.
Refor√ßar o conceito com exemplos e refer√™ncias.

CONCEITO #3:
T√©cnicas de Engenharia de Prompts.
Quais s√£o algumas t√©cnicas b√°sicas de engenharia de prompts?
Ilustre com alguns exerc√≠cios.
-->

## Boas Pr√°ticas de Prompting

Agora que j√° sabemos como os prompts podem ser _constru√≠dos_, podemos come√ßar a pensar em como _desenh√°-los_ para refletir as melhores pr√°ticas. Podemos pensar nisto em duas partes - ter a _mentalidade_ certa e aplicar as _t√©cnicas_ certas.

### Mentalidade de Engenharia de Prompts

A Engenharia de Prompts √© um processo de tentativa e erro, por isso mantenha tr√™s grandes fatores orientadores em mente:

1. **Compreens√£o do Dom√≠nio √© Importante.** A precis√£o e relev√¢ncia das respostas depende do _dom√≠nio_ em que a aplica√ß√£o ou utilizador opera. Use a sua intui√ß√£o e experi√™ncia no dom√≠nio para **personalizar t√©cnicas** ainda mais. Por exemplo, defina _personalidades espec√≠ficas do dom√≠nio_ nos seus prompts de sistema, ou use _modelos espec√≠ficos do dom√≠nio_ nos seus prompts de utilizador. Forne√ßa conte√∫do secund√°rio que reflita contextos do dom√≠nio, ou use _pistas e exemplos do dom√≠nio_ para guiar o modelo para padr√µes de uso familiares.

2. **Compreens√£o do Modelo √© Importante.** Sabemos que os modelos s√£o estoc√°sticos por natureza. Mas as implementa√ß√µes dos modelos tamb√©m podem variar em termos do conjunto de dados de treino que usam (conhecimento pr√©-treinado), das capacidades que oferecem (por exemplo, via API ou SDK) e do tipo de conte√∫do para o qual est√£o otimizados (por exemplo, c√≥digo vs. imagens vs. texto). Compreenda os pontos fortes e limita√ß√µes do modelo que est√° a usar, e use esse conhecimento para _priorizar tarefas_ ou construir _modelos personalizados_ otimizados para as capacidades do modelo.

3. **Itera√ß√£o & Valida√ß√£o s√£o Importantes.** Os modelos est√£o a evoluir rapidamente, tal como as t√©cnicas de engenharia de prompts. Como especialista no dom√≠nio, pode ter outro contexto ou crit√©rios para _a sua_ aplica√ß√£o espec√≠fica, que podem n√£o se aplicar √† comunidade em geral. Use ferramentas e t√©cnicas de engenharia de prompts para "dar o pontap√© de sa√≠da" na constru√ß√£o de prompts, depois itere e valide os resultados usando a sua pr√≥pria intui√ß√£o e experi√™ncia. Registe os seus insights e crie uma **base de conhecimento** (por exemplo, bibliotecas de prompts) que possa ser usada como novo ponto de partida por outros, para itera√ß√µes mais r√°pidas no futuro.

## Boas Pr√°ticas

Vejamos agora algumas boas pr√°ticas recomendadas por profissionais da [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) e da [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| O qu√™                              | Porqu√™                                                                                                                                                                                                                                               |
| :--------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Avalie os modelos mais recentes.   | Novas gera√ß√µes de modelos tendem a ter melhores funcionalidades e qualidade - mas tamb√©m podem ter custos mais elevados. Avalie o impacto e s√≥ depois decida migrar.                                                                                |
| Separe instru√ß√µes e contexto       | Verifique se o seu modelo/fornecedor define _delimitadores_ para distinguir instru√ß√µes, conte√∫do principal e secund√°rio de forma mais clara. Isto pode ajudar os modelos a atribuir pesos mais precisos aos tokens.                                 |
| Seja espec√≠fico e claro            | D√™ mais detalhes sobre o contexto desejado, resultado, comprimento, formato, estilo, etc. Isto melhora a qualidade e consist√™ncia das respostas. Guarde receitas em modelos reutiliz√°veis.                                                          |
| Seja descritivo, use exemplos      | Os modelos podem responder melhor a uma abordagem de "mostrar e explicar". Comece com uma abordagem `zero-shot` onde d√° apenas uma instru√ß√£o (sem exemplos) e depois tente `few-shot` como refinamento, fornecendo alguns exemplos do resultado. Use analogias. |
| Use pistas para iniciar respostas  | D√™ um empurr√£o na dire√ß√£o do resultado desejado, fornecendo algumas palavras ou frases iniciais que o modelo possa usar como ponto de partida para a resposta.                                                                                       |
| Reforce a instru√ß√£o                | Por vezes pode ser necess√°rio repetir a instru√ß√£o ao modelo. D√™ instru√ß√µes antes e depois do conte√∫do principal, use uma instru√ß√£o e uma pista, etc. Itere e valide para ver o que resulta melhor.                                                  |
| A ordem importa                    | A ordem em que apresenta a informa√ß√£o ao modelo pode influenciar o resultado, mesmo nos exemplos de aprendizagem, devido ao vi√©s de rec√™ncia. Experimente diferentes op√ß√µes para ver o que funciona melhor.                                         |
| D√™ ao modelo uma ‚Äúescapat√≥ria‚Äù     | D√™ ao modelo uma resposta de _reserva_ que possa fornecer caso n√£o consiga completar a tarefa por algum motivo. Isto pode reduzir a probabilidade de respostas falsas ou inventadas.                                                               |
|                                   |                                                                                                                                                                                                                                                     |

Como em qualquer boa pr√°tica, lembre-se que _os resultados podem variar_ consoante o modelo, a tarefa e o dom√≠nio. Use estas recomenda√ß√µes como ponto de partida e itere para encontrar o que funciona melhor para si. Reavalie constantemente o seu processo de engenharia de prompts √† medida que surgem novos modelos e ferramentas, com foco na escalabilidade do processo e na qualidade das respostas.

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve fornecer um desafio de c√≥digo, se aplic√°vel

DESAFIO:
Ligue para um Jupyter Notebook apenas com os coment√°rios de c√≥digo nas instru√ß√µes (as sec√ß√µes de c√≥digo est√£o vazias).

SOLU√á√ÉO:
Ligue para uma c√≥pia desse Notebook com os prompts preenchidos e executados, mostrando um exemplo poss√≠vel.
-->

## Exerc√≠cio

Parab√©ns! Chegou ao fim da li√ß√£o! Est√° na altura de p√¥r alguns destes conceitos e t√©cnicas √† prova com exemplos reais!

Para o nosso exerc√≠cio, vamos usar um Jupyter Notebook com exerc√≠cios que pode completar de forma interativa. Tamb√©m pode estender o Notebook com as suas pr√≥prias c√©lulas Markdown e de C√≥digo para explorar ideias e t√©cnicas por si.

### Para come√ßar, fa√ßa fork do reposit√≥rio, depois

- (Recomendado) Inicie o GitHub Codespaces
- (Em alternativa) Clone o reposit√≥rio para o seu dispositivo local e use-o com o Docker Desktop
- (Em alternativa) Abra o Notebook no seu ambiente de execu√ß√£o de Notebooks preferido.

### De seguida, configure as vari√°veis de ambiente

- Copie o ficheiro `.env.copy` na raiz do reposit√≥rio para `.env` e preencha os valores `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` e `AZURE_OPENAI_DEPLOYMENT`. Volte √† [sec√ß√£o Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) para saber como.

### Depois, abra o Jupyter Notebook

- Selecione o kernel de execu√ß√£o. Se usar as op√ß√µes 1 ou 2, basta selecionar o kernel Python 3.10.x por defeito fornecido pelo dev container.

Est√° tudo pronto para executar os exerc√≠cios. Note que aqui n√£o h√° respostas _certas ou erradas_ - trata-se apenas de explorar op√ß√µes por tentativa e erro e construir intui√ß√£o sobre o que funciona para um determinado modelo e dom√≠nio de aplica√ß√£o.

_Por este motivo, n√£o h√° segmentos de Solu√ß√£o de C√≥digo nesta li√ß√£o. Em vez disso, o Notebook ter√° c√©lulas Markdown intituladas "A Minha Solu√ß√£o:" que mostram um exemplo de sa√≠da para refer√™ncia._

 <!--
MODELO DE LI√á√ÉO:
Envolva a sec√ß√£o com um resumo e recursos para autoaprendizagem.
-->

## Verifica√ß√£o de Conhecimentos

Qual dos seguintes √© um bom prompt seguindo algumas boas pr√°ticas razo√°veis?

1. Mostra-me uma imagem de um carro vermelho
2. Mostra-me uma imagem de um carro vermelho da marca Volvo e modelo XC90 estacionado junto a uma fal√©sia com o sol a p√¥r-se
3. Mostra-me uma imagem de um carro vermelho da marca Volvo e modelo XC90

R: 2, √© o melhor prompt pois fornece detalhes sobre o "qu√™" e vai ao pormenor (n√£o √© apenas um carro qualquer, mas uma marca e modelo espec√≠ficos) e tamb√©m descreve o cen√°rio geral. O 3 √© o seguinte melhor, pois tamb√©m cont√©m bastante descri√ß√£o.

## üöÄ Desafio

V√™ se consegues usar a t√©cnica da "pista" com o prompt: Completa a frase "Mostra-me uma imagem de um carro vermelho da marca Volvo e ". O que responde o modelo, e como o melhorarias?

## Excelente Trabalho! Continua a Aprender

Queres aprender mais sobre diferentes conceitos de Engenharia de Prompts? Vai √† [p√°gina de aprendizagem cont√≠nua](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrares outros √≥timos recursos sobre este tema.

Segue para a Li√ß√£o 5 onde vamos explorar [t√©cnicas avan√ßadas de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas resultantes do uso desta tradu√ß√£o.