{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norint paleisti toliau pateiktus užrašų knygelius, jei dar to nepadarėte, turite nustatyti openai raktą .env faile kaip `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toliau įkelsime įterpimų indeksą į Pandas duomenų rėmelį. Įterpimų indeksas saugomas JSON faile, pavadintame `embedding_index_3m.json`. Įterpimų indeksas talpina įterpimus kiekvienam YouTube transkriptui iki 2023 m. spalio pabaigos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toliau sukursime funkciją pavadinimu `get_videos`, kuri ieškos užklausos Embedding indekse. Funkcija grąžins 5 geriausiai užklausai panašius vaizdo įrašus. Funkcija veikia taip:\n",
    "\n",
    "1. Pirmiausia sukuriama Embedding indekso kopija.\n",
    "2. Tada apskaičiuojamas užklausos Embeddingas naudojant OpenAI Embedding API.\n",
    "3. Tuomet Embedding indekse sukuriamas naujas stulpelis pavadinimu `similarity`. Stulpelyje `similarity` yra kosininio panašumo tarp užklausos Embeddingo ir kiekvieno vaizdo segmento Embeddingo reikšmės.\n",
    "4. Toliau Embedding indeksas filtruojamas pagal stulpelį `similarity`. Filtruojami tik tie vaizdo įrašai, kurių kosininis panašumas yra didesnis arba lygus 0.75.\n",
    "5. Galiausiai Embedding indeksas rūšiuojamas pagal stulpelį `similarity` ir grąžinami 5 geriausi vaizdo įrašai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ši funkcija yra labai paprasta, ji tiesiog išveda paieškos užklausos rezultatus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pirmiausia, įterpimo indeksas įkeliamas į Pandas duomenų rėmelį.\n",
    "2. Tada vartotojui pateikiama užklausa įvesti užklausą.\n",
    "3. Po to kviečiama funkcija `get_videos`, kuri ieško įterpimo indekse pagal užklausą.\n",
    "4. Galiausiai kviečiama funkcija `display_results`, kuri rodo rezultatus vartotojui.\n",
    "5. Vartotojui vėl pateikiama užklausa įvesti kitą užklausą. Šis procesas tęsiasi tol, kol vartotojas įveda `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc.lt.png)\n",
    "\n",
    "Jums bus pasiūlyta įvesti užklausą. Įveskite užklausą ir paspauskite enter. Programa pateiks sąrašą vaizdo įrašų, kurie yra susiję su užklausa. Programa taip pat pateiks nuorodą į vietą vaizdo įraše, kur randamas atsakymas į klausimą.\n",
    "\n",
    "Štai keletas užklausų, kurias galite išbandyti:\n",
    "\n",
    "- Kas yra Azure Machine Learning?\n",
    "- Kaip veikia konvoliuciniai neuroniniai tinklai?\n",
    "- Kas yra neuroninis tinklas?\n",
    "- Ar galiu naudoti Jupyter užrašų knygutes su Azure Machine Learning?\n",
    "- Kas yra ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Atsakomybės apribojimas**:  \nŠis dokumentas buvo išverstas naudojant dirbtinio intelekto vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors stengiamės užtikrinti tikslumą, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Svarbiai informacijai rekomenduojamas profesionalus žmogaus vertimas. Mes neatsakome už bet kokius nesusipratimus ar neteisingus aiškinimus, kilusius dėl šio vertimo naudojimo.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T12:06:19+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "lt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}