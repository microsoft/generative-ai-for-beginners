{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norėdami paleisti šiuos užrašus, jei to dar nepadarėte, turite nustatyti openai raktą .env faile kaip `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toliau įkelsime įterpinių indeksą į Pandas duomenų rėmelį. Įterpinių indeksas saugomas JSON faile, pavadintame `embedding_index_3m.json`. Įterpinių indeksas apima kiekvienos „YouTube“ transkripcijos įterpinius iki 2023 m. spalio pabaigos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toliau sukursime funkciją, pavadintą `get_videos`, kuri ieškos užklausos Embedding Index'e. Ši funkcija grąžins 5 labiausiai su užklausa susijusius vaizdo įrašus. Funkcija veikia taip:\n",
    "\n",
    "1. Pirmiausia sukuriama Embedding Index kopija.\n",
    "2. Tada užklausos Embedding apskaičiuojamas naudojant OpenAI Embedding API.\n",
    "3. Toliau Embedding Index'e sukuriamas naujas stulpelis, pavadintas `similarity`. Šiame `similarity` stulpelyje saugomas kosinusinis panašumas tarp užklausos Embedding ir kiekvieno vaizdo įrašo segmento Embedding.\n",
    "4. Toliau Embedding Index filtruojamas pagal `similarity` stulpelį. Embedding Index paliekami tik tie vaizdo įrašai, kurių kosinusinis panašumas yra didesnis arba lygus 0,75.\n",
    "5. Galiausiai Embedding Index surūšiuojamas pagal `similarity` stulpelį ir grąžinami 5 geriausi vaizdo įrašai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ši funkcija yra labai paprasta, ji tiesiog išveda paieškos užklausos rezultatus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Pirmiausia, į Pandas Dataframe įkeliamas Embedding Index.\n",
    "2. Toliau vartotojui pateikiamas prašymas įvesti užklausą.\n",
    "3. Tada iškviečiama funkcija `get_videos`, kuri ieško užklausos Embedding Index.\n",
    "4. Galiausiai iškviečiama funkcija `display_results`, kuri parodo rezultatus vartotojui.\n",
    "5. Vartotojui vėl pateikiamas prašymas įvesti kitą užklausą. Šis procesas kartojamas tol, kol vartotojas įveda `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.lt.png)\n",
    "\n",
    "Jums bus pateiktas prašymas įvesti užklausą. Įveskite užklausą ir paspauskite Enter. Programa pateiks vaizdo įrašų sąrašą, kurie yra susiję su jūsų užklausa. Taip pat bus pateikta nuoroda į tą vietą vaizdo įraše, kurioje yra atsakymas į jūsų klausimą.\n",
    "\n",
    "Štai keletas užklausų, kurias galite išbandyti:\n",
    "\n",
    "- Kas yra Azure Machine Learning?\n",
    "- Kaip veikia konvoliuciniai neuroniniai tinklai?\n",
    "- Kas yra neuroninis tinklas?\n",
    "- Ar galiu naudoti Jupyter Notebooks su Azure Machine Learning?\n",
    "- Kas yra ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Atsakomybės atsisakymas**:  \nŠis dokumentas buvo išverstas naudojant dirbtinio intelekto vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Svarbiai informacijai rekomenduojame profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už bet kokius nesusipratimus ar neteisingą interpretavimą, kilusį naudojantis šiuo vertimu.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "2c0494ceb4f5fc618a6abda0b5c09c73",
   "translation_date": "2025-08-25T19:05:05+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "lt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}