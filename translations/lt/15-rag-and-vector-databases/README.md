# PaieÅ¡kos plÄ—tinio generavimas (RAG) ir vektorinÄ—s duomenÅ³ bazÄ—s

[![PaieÅ¡kos plÄ—tinio generavimas (RAG) ir vektorinÄ—s duomenÅ³ bazÄ—s](../../../translated_images/lt/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

PaieÅ¡kos taikomÅ³jÅ³ programÅ³ pamokoje trumpai suÅ¾inojome, kaip integruoti savo duomenis Ä¯ didelius kalbos modelius (LLM). Å ioje pamokoje gilinsimÄ—s Ä¯ jÅ«sÅ³ duomenÅ³ pagrindimÄ… jÅ«sÅ³ LLM programoje, proceso mechanikÄ… ir duomenÅ³ saugojimo metodus, Ä¯skaitant tiek vektorius, tiek tekstÄ….

> **Vaizdo Ä¯raÅ¡as netrukus**

## Ä®vadas

Å ioje pamokoje aptarsime:

- Ä®vadÄ… Ä¯ RAG, kas tai yra ir kodÄ—l jis naudojamas dirbtiniame intelekte (AI).

- SupratimÄ…, kas yra vektorinÄ—s duomenÅ³ bazÄ—s, ir vienos jÅ³ sukÅ«rimÄ… mÅ«sÅ³ programai.

- PraktinÄ¯ pavyzdÄ¯, kaip integruoti RAG Ä¯ programÄ….

## Mokymosi tikslai

Baigus Å¡iÄ… pamokÄ…, galÄ—site:

- PaaiÅ¡kinti RAG reikÅ¡mÄ™ duomenÅ³ gavimui ir apdorojimui.

- Nustatyti RAG programÄ… ir pagrÄ¯sti savo duomenis LLM.

- Efektyviai integruoti RAG ir vektorines duomenÅ³ bazes LLM programose.

## MÅ«sÅ³ scenarijus: LLM patobulinimas su mÅ«sÅ³ paÄiÅ³ duomenimis

Å iai pamokai norime pridÄ—ti savo uÅ¾raÅ¡us Ä¯ Å¡vietimo startuolÄ¯, kuris leidÅ¾ia pokalbiÅ³ robotui gauti daugiau informacijos apie Ä¯vairias temas. Naudodamiesi turimais uÅ¾raÅ¡ais, mokiniai galÄ—s geriau mokytis ir suprasti skirtingas temas, palengvindami pasiruoÅ¡imÄ… egzaminams. Scenarijui kurti naudosime:

- `Azure OpenAI:` LLM, kurÄ¯ naudosime pokalbiÅ³ robotui kurti

- `AI pradedantiesiems: neuroniniÅ³ tinklÅ³ pamoka`: tai bus duomenys, ant kuriÅ³ pagrÄ¯sime mÅ«sÅ³ LLM

- `Azure AI Search` ir `Azure Cosmos DB:` vektoriniÅ³ duomenÅ³ bazÄ— mÅ«sÅ³ duomenims saugoti ir paieÅ¡kos indeksui kurti

Vartotojai galÄ—s kurti praktinius klausimynus iÅ¡ savo uÅ¾raÅ¡Å³, pakartojimo korteles ir apibendrinti juos glaustais apraÅ¡ymais. PradÄ—kime nuo to, kas yra RAG ir kaip jis veikia:

## PaieÅ¡kos plÄ—tinio generavimas (RAG)

LLM pagrÄ¯stas pokalbiÅ³ robotas apdoroja vartotojo uÅ¾klausas, kad sukurtÅ³ atsakymus. Jis sukurtas bÅ«ti interaktyvus ir bendrauti su vartotojais Ä¯vairiomis temomis. TaÄiau jo atsakymai yra ribojami pateiktos konteksto ir pagrindiniÅ³ mokymo duomenÅ³. PavyzdÅ¾iui, GPT-4 Å¾iniÅ³ ribojimas yra 2021 m. rugsÄ—jis, reiÅ¡kiantis, kad jis neturi Å¾iniÅ³ apie Ä¯vykius po Å¡io laikotarpio. Be to, LLM mokymams naudojami duomenys neapima konfidencialios informacijos, kaip asmeniniai uÅ¾raÅ¡ai ar Ä¯monÄ—s produktÅ³ vadovai.

### Kaip veikia RAG (paieÅ¡kos plÄ—tinio generavimas)

![braiÅ¾inys, rodantis kaip veikia RAG](../../../translated_images/lt/how-rag-works.f5d0ff63942bd3a6.webp)

Tarkime, norite Ä¯diegti pokalbiÅ³ robotÄ…, kuris kuria klausimynus iÅ¡ jÅ«sÅ³ uÅ¾raÅ¡Å³, jums reikÄ—s jungties prie Å¾iniÅ³ bazÄ—s. Å tai kur RAG padeda. RAG veikia taip:

- **Å½iniÅ³ bazÄ—:** PrieÅ¡ ieÅ¡kant, Å¡ie dokumentai turi bÅ«ti Ä¯kelti ir iÅ¡ankstinai apdoroti, daÅ¾niausiai suskaidant didelius dokumentus Ä¯ maÅ¾esnius segmentus, transformuojant juos Ä¯ tekstinius Ä¯terpimus ir saugant duomenÅ³ bazÄ—je.

- **Vartotojo uÅ¾klausa:** vartotojas uÅ¾duoda klausimÄ…

- **PaieÅ¡ka:** Kai vartotojas uÅ¾duoda klausimÄ…, Ä¯terpimo modelis suranda susijusiÄ… informacijÄ… mÅ«sÅ³ Å¾iniÅ³ bazÄ—je, kad pateiktÅ³ daugiau konteksto, kuris bus Ä¯trauktas Ä¯ uÅ¾klausÄ….

- **PlÄ—stinis generavimas:** LLM pagerina savo atsakymÄ… remdamasis gautais duomenimis. Tai leidÅ¾ia atsakymui bÅ«ti pagrÄ¯stam ne tik iÅ¡ anksto apmokytais duomenimis, bet ir papildoma informacija iÅ¡ pridÄ—to konteksto. Gauti duomenys naudojami LLM atsakymams papildyti. LLM tada pateikia atsakymÄ… vartotojo klausimui.

![braiÅ¾inys, rodantis kaip veikia RAG architektÅ«ra](../../../translated_images/lt/encoder-decode.f2658c25d0eadee2.webp)

RAG architektÅ«ra Ä¯gyvendinama naudojant transformerius, sudarytus iÅ¡ dviejÅ³ daliÅ³: kodavimo ir dekodavimo. PavyzdÅ¾iui, kai vartotojas uÅ¾duoda klausimÄ…, Ä¯vestas tekstas yra â€uÅ¾koduojamasâ€œ Ä¯ vektorius, kurie fiksuoja Å¾odÅ¾iÅ³ reikÅ¡mÄ™, o vektoriai yra â€iÅ¡koduojamiâ€œ Ä¯ mÅ«sÅ³ dokumentÅ³ indeksÄ… ir generuoja naujÄ… tekstÄ…, remiantis vartotojo uÅ¾klausa. LLM naudoja abu â€“ kodavimo-dekodavimo modelÄ¯, kad sugeneruotÅ³ rezultatÄ….

Yra du RAG Ä¯gyvendinimo metodai pagal siÅ«lomÄ… straipsnÄ¯: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst):

- **_RAG-Sequence_** naudoja surinktus dokumentus, kad prognozuotÅ³ geriausiÄ… atsakymÄ… vartotojo uÅ¾klausai

- **RAG-Token** generuoja kitÄ… Å¾odÅ¾io vienetÄ…, naudodama dokumentus, tada juos surenka, kad atsakytÅ³ Ä¯ vartotojo klausimÄ…

### KodÄ—l verta naudoti RAG?Â 

- **Informacijos turtingumas:** uÅ¾tikrina, kad tekstiniai atsakymai bÅ«tÅ³ atnaujinti ir aktualÅ«s. TodÄ—l pagerina naÅ¡umÄ… srityse, reikalaujanÄiose specifiniÅ³ Å¾iniÅ³, pasiekiant vidinÄ™ Å¾iniÅ³ bazÄ™.

- MaÅ¾ina klaidingÄ… informacijÄ… naudodamas **patikimus duomenis** Å¾iniÅ³ bazÄ—je, kad pateiktÅ³ kontekstÄ… vartotojÅ³ uÅ¾klausoms.

- Tai **ekonomiÅ¡ka**, nes yra pigesnÄ— alternatyva nei LLM perkvalifikavimas (fine-tuning)

## Å½iniÅ³ bazÄ—s kÅ«rimas

MÅ«sÅ³ programa remiasi mÅ«sÅ³ asmeniniais duomenimis, t.y. neuroniniÅ³ tinklÅ³ pamoka AI pradedantiesiems mokyme.

### VektorinÄ—s duomenÅ³ bazÄ—s

VektorinÄ— duomenÅ³ bazÄ—, skirtingai nei tradicinÄ—s duomenÅ³ bazÄ—s, yra specializuota duomenÅ³ bazÄ—, sukurta saugoti, valdyti ir ieÅ¡koti Ä¯terptus vektorius. Joje saugomos dokumentÅ³ skaitmeninÄ—s reprezentacijos. DuomenÅ³ skaidymas Ä¯ skaitmeninius Ä¯terpimus leidÅ¾ia mÅ«sÅ³ DI sistemai lengviau suprasti ir apdoroti duomenis.

Mes saugome savo Ä¯terpimus vektorinÄ—se duomenÅ³ bazÄ—se, nes LLM turi apribojimÄ…, kiek Å¾odÅ¾iÅ³ (tokenâ€™Å³) gali priimti kaip Ä¯vestÄ¯. Kadangi negalite perduoti visÅ³ Ä¯terpimÅ³ vienu metu LLM, turÄ—sime juos suskaidyti Ä¯ segmentus ir kai vartotojas uÅ¾duoda klausimÄ…, grÄ…Å¾inami segmentai, kurie geriausiai atitinka uÅ¾klausÄ… kartu su uÅ¾klausa. Segmentavimas taip pat maÅ¾ina sÄ…naudas dÄ—l perduodamÅ³ Å¾odÅ¾iÅ³ skaiÄiaus LLM.

Populiarios vektorinÄ—s duomenÅ³ bazÄ—s yra Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ir DeepLake. Galite sukurti Azure Cosmos DB modelÄ¯ naudodami Azure CLI Å¡ia komanda:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### IÅ¡ teksto Ä¯ Ä¯terpimus

PrieÅ¡ saugodami duomenis, turime juos konvertuoti Ä¯ vektoriÅ³ Ä¯terpimus prieÅ¡ saugojant duomenÅ³ bazÄ—je. Dirbdami su dideliais dokumentais ar ilgu tekstu, galite juos suskaidyti pagal numatomas uÅ¾klausas. Skirstyti galima pagal sakinius arba pastraipas. Kadangi segmentavimas gilinasi Ä¯ Å¾odÅ¾iÅ³ aplinkÄ…, galite pridÄ—ti papildomÄ… kontekstÄ…, pvz., dokumento pavadinimÄ… arba prieÅ¡ ar po segmento esantÄ¯ tekstÄ…. Duomenis galite suskaidyti taip:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # Jei paskutinÄ— dalis nepasiekÄ— minimalaus ilgio, vis tiek jÄ… pridÄ—kite
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

SuskaidÅ¾ius, galime naudoti Ä¯vairius Ä¯terpimo modelius tekstui Ä¯terpti. Kai kurie modeliai yra: word2vec, ada-002 iÅ¡ OpenAI, Azure Computer Vision ir daugelis kitÅ³. Modelio pasirinkimas priklauso nuo kalbÅ³, kurias naudojate, koduojamo turinio tipo (tekstai/vaizdai/garsas), Ä¯vesties dydÅ¾io ir Ä¯terpimo iÅ¡vesties ilgio.

Pavyzdys, kaip atrodo tekstas su OpenAI `text-embedding-ada-002` modeliu:
![Å¾odÅ¾io katÄ— Ä¯terpimas](../../../translated_images/lt/cat.74cbd7946bc9ca38.webp)

## PaieÅ¡ka ir vektorinÄ— paieÅ¡ka

Kai vartotojas uÅ¾duoda klausimÄ…, paieÅ¡kos modulis paverÄia jÄ¯ vektoriumi naudodamas uÅ¾klausÅ³ kodavimo modelÄ¯, tada ieÅ¡ko dokumentÅ³ paieÅ¡kos indekse vektoriÅ³, susijusiÅ³ su Ä¯vestimi. Pabaigoje abi Ä¯vesties ir dokumentÅ³ vektorius konvertuoja Ä¯ tekstÄ… ir perduoda Ä¯ LLM.

### PaieÅ¡ka

PaieÅ¡ka vyksta, kai sistema bando greitai rasti dokumentus indekse, kurie atitinka paieÅ¡kos kriterijus. PaieÅ¡kos modulio tikslas yra gauti dokumentus, kurie bus naudojami kontekstui pateikti ir pagrÄ¯sti LLM jÅ«sÅ³ duomenimis.

DuomenÅ³ bazÄ—je paieÅ¡kÄ… atlikti galima Ä¯vairiais bÅ«dais, pavyzdÅ¾iui:

- **RaktiniÅ³ Å¾odÅ¾iÅ³ paieÅ¡ka** - skirta tekstinÄ—ms paieÅ¡koms

- **VektorinÄ— paieÅ¡ka** - konvertuoja dokumentus iÅ¡ teksto Ä¯ vektorius naudodama Ä¯terpimo modelius, leidÅ¾ianÄius atlikti **semantinÄ™ paieÅ¡kÄ…** pagal Å¾odÅ¾iÅ³ prasmÄ™. PaieÅ¡ka vykdoma ieÅ¡kant dokumentÅ³, kuriÅ³ vektorinÄ—s reprezentacijos yra arÄiausiai vartotojo uÅ¾klausos.

- **Hibridinis** - derinys tarp raktiniÅ³ Å¾odÅ¾iÅ³ ir vektoriniÅ³ paieÅ¡kÅ³.

Problema, kylanti su paieÅ¡ka, yra tada, kai duomenÅ³ bazÄ—je nÄ—ra panaÅ¡aus atsakymo Ä¯ uÅ¾klausÄ…, sistema grÄ…Å¾ins geriausiÄ… turimÄ… informacijÄ…, taÄiau galite naudoti taktikÄ…, pavyzdÅ¾iui, nustatyti maksimalÅ³ aktualumo atstumÄ… arba naudoti hibridinÄ™ paieÅ¡kÄ…, kuri jungia raktinius Å¾odÅ¾ius ir vektorinÄ™ paieÅ¡kÄ…. Å ioje pamokoje naudosime hibridinÄ™ paieÅ¡kÄ…, derinÄ¯ tarp vektorinÄ—s ir raktiniÅ³ Å¾odÅ¾iÅ³ paieÅ¡kos. Duomenis saugosime duomenÅ³ lentelÄ—je su stulpeliais, kuriuose bus segmentai ir Ä¯terpimai.

### VektorinÄ— panaÅ¡umas

PaieÅ¡kos modulis ieÅ¡kos Å¾iniÅ³ bazÄ—je Ä¯terpimÅ³, kurie yra arti vienas kito, artimiausiÅ³ kaimynÅ³ principu, nes jie yra panaÅ¡Å«s tekstai. Kai vartotojas uÅ¾duoda uÅ¾klausÄ…, ji pirmiausia paverÄiama Ä¯terpimu, tada lyginama su panaÅ¡iais Ä¯terpimais. DaÅ¾niausiai naudojamas panaÅ¡umo matas yra kosinusinÄ— panaÅ¡umo reikÅ¡mÄ—, kuri remiasi kampu tarp dviejÅ³ vektoriÅ³.

PanaÅ¡umui matuoti galima naudoti kitas alternatyvas, pvz., Euklido atstumÄ…, kuris yra trumpiausia linija tarp vektoriÅ³ galiniÅ³ taÅ¡kÅ³, arba skaliarinÄ™ sandaugÄ…, kuri matuoja atitinkamÅ³ dviejÅ³ vektoriÅ³ elementÅ³ sandaugÅ³ sumÄ….

### PaieÅ¡kos indeksas

Atlikdami paieÅ¡kÄ…, turime sukurti paieÅ¡kos indeksÄ… mÅ«sÅ³ Å¾iniÅ³ bazei prieÅ¡ pradÄ—dami paieÅ¡kÄ…. Indeksas saugos mÅ«sÅ³ Ä¯terpimus ir gali greitai rasti artimiausius segmentus net didelÄ—je duomenÅ³ bazÄ—je. IndeksÄ… galime sukurti lokaliai naudojant:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Sukurkite paieÅ¡kos indeksÄ…
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# NorÄ—dami klausti indekso, galite naudoti metodÄ… kneighbors
distances, indices = nbrs.kneighbors(embeddings)
```

### Pakartotinis rÅ«Å¡iavimas

Pateikus uÅ¾klausÄ… Ä¯ duomenÅ³ bazÄ™, galbÅ«t reikÄ—s iÅ¡rÅ«Å¡iuoti rezultatus pagal aktualumÄ…. PakartotinÄ¯ rÅ«Å¡iavimÄ… atlieka LLM, kuris naudoja maÅ¡ininÄ¯ mokymÄ…si, kad pagerintÅ³ paieÅ¡kos rezultatÅ³ aktualumÄ…, rÅ«Å¡iuodamas juos nuo svarbiausiÅ³. Naudojant Azure AI Search, pakartotinis rÅ«Å¡iavimas atliekamas automatiÅ¡kai naudojant semantinÄ¯ perrÅ«Å¡iavimÄ…. Pavyzdys, kaip veikia perrÅ«Å¡iavimas, naudojant artimiausius kaimynus:

```python
# Raskite labiausiai panaÅ¡ius dokumentus
distances, indices = nbrs.kneighbors([query_vector])

index = []
# IÅ¡spausdinkite labiausiai panaÅ¡ius dokumentus
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Viskas kartu

Paskutinis Å¾ingsnis â€“ Ä¯traukti mÅ«sÅ³ LLM, kad galÄ—tume gauti atsakymus, pagrÄ¯stus mÅ«sÅ³ duomenimis. Galime Ä¯gyvendinti taip:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Paversti klausimÄ… Ä¯ uÅ¾klausos vektoriÅ³
    query_vector = create_embeddings(user_input)

    # Rasti labiausiai panaÅ¡ius dokumentus
    distances, indices = nbrs.kneighbors([query_vector])

    # pridÄ—ti dokumentus prie uÅ¾klausos, kad suteiktÅ³ kontekstÄ…
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # sujungti istorijÄ… ir vartotojo Ä¯vestÄ¯
    history.append(user_input)

    # sukurti Å¾inutÄ—s objektÄ…
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # naudoti pokalbio uÅ¾baigimÄ… atsakymui generuoti
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Programos vertinimas

### Vertinimo metrika

- AtsakymÅ³ kokybÄ—: uÅ¾tikrinant, kad jie skambÄ—tÅ³ natÅ«raliai, sklandÅ¾iai ir Å¾mogiÅ¡kai

- DuomenÅ³ pagrindimas: vertinant, ar atsakymas pateiktas remiantis papildytais dokumentais

- Aktualumas: vertinant, ar atsakymas atitinka ir susijÄ™s su uÅ¾duotu klausimu

- Sklandumas â€“ ar atsakymas yra prasmingas gramatiniu poÅ¾iÅ«riu

## RAG (paieÅ¡kos plÄ—tinio generavimas) ir vektoriniÅ³ duomenÅ³ baziÅ³ naudojimo scenarijai

Yra daugybÄ— Ä¯vairiÅ³ atvejÅ³, kur funkcijÅ³ iÅ¡kvietimai gali pagerinti jÅ«sÅ³ programÄ…, pavyzdÅ¾iui:

- KlausimÅ³ ir atsakymÅ³ sistema: pagrindÅ¾iant jÅ«sÅ³ Ä¯monÄ—s duomenis pokalbiÅ³ robotui, kurÄ¯ darbuotojai gali naudoti klausimams uÅ¾duoti.

- RekomendacijÅ³ sistemos: kur galima sukurti sistemÄ…, kuri parenka panaÅ¡iausias reikÅ¡mes, pvz., filmus, restoranus ir kt.

- PokalbiÅ³ robotÅ³ paslaugos: galite saugoti pokalbiÅ³ istorijÄ… ir pritaikyti pokalbÄ¯ pagal vartotojo duomenis.

- VaizdÅ³ paieÅ¡ka, pagrÄ¯sta vektoriniais Ä¯terpimais, naudinga atliekant vaizdÅ³ atpaÅ¾inimÄ… ir anomalijÅ³ aptikimÄ….

## Santrauka

Mes apÅ¾velgÄ—me pagrindines RAG sritis nuo mÅ«sÅ³ duomenÅ³ pridÄ—jimo Ä¯ programÄ…, vartotojo uÅ¾klausos iki atsakymo. NorÄ—dami palengvinti RAG kÅ«rimÄ…, galite naudoti tokias sistemas kaip Semantic Kernel, Langchain ar Autogen.

## UÅ¾duotis

NorÄ—dami toliau gilinti Å¾inias apie paieÅ¡kos plÄ—tinio generavimÄ… (RAG), sukurkite:

- Programos sÄ…sajos priekinÄ™ dalÄ¯ naudodami jums patinkanÄiÄ… sistemÄ…

- Naudokite sistemÄ…, pvz., LangChain arba Semantic Kernel, ir atkurkite savo programÄ…

Sveikiname baigus pamokÄ… ğŸ‘.

## Mokymasis Äia nesibaigia, tÄ™skite kelionÄ™

BaigÄ™ Å¡iÄ… pamokÄ…, perÅ¾iÅ«rÄ—kite mÅ«sÅ³ [Generatyviojo DI mokymosi kolekcijÄ…](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), kad toliau keltumÄ—te savo generatyviojo DI Å¾inias!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**AtsakomybÄ—s apribojimas**:
Å is dokumentas buvo iÅ¡verstas naudojant dirbtinio intelekto vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors stengiamÄ—s uÅ¾tikrinti tikslumÄ…, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Svarbiai informacijai rekomenduojamas profesionalus Å¾mogaus vertimas. Mes neatsakome uÅ¾ bet kokius nesusipratimus ar klaidingus vertimus, kilusius naudojant Å¡Ä¯ vertimÄ….
<!-- CO-OP TRANSLATOR DISCLAIMER END -->