<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "59021c5f419d3feda19075910a74280a",
  "translation_date": "2025-08-25T12:47:50+00:00",
  "source_file": "15-rag-and-vector-databases/data/perceptron.md",
  "language_code": "lt"
}
-->
# Ä®vadas Ä¯ neuroninius tinklus: perceptronas

Vienas pirmÅ³jÅ³ bandymÅ³ sukurti kaÅ¾kÄ… panaÅ¡aus Ä¯ Å¡iuolaikinÄ¯ neuroninÄ¯ tinklÄ… buvo atliktas Franko Rosenblatto iÅ¡ Kornelio aeronautikos laboratorijos 1957 metais. Tai buvo aparatinis Ä¯gyvendinimas, pavadintas â€Mark-1â€œ, sukurtas atpaÅ¾inti paprastas geometrines figÅ«ras, tokias kaip trikampiai, kvadratai ir apskritimai.

|      |      |
|--------------|-----------|
|<img src='images/Rosenblatt-wikipedia.jpg' alt='Frank Rosenblatt'/> | <img src='images/Mark_I_perceptron_wikipedia.jpg' alt='The Mark 1 Perceptron' />|

> PaveikslÄ—liai iÅ¡ Vikipedijos

Ä®vesties vaizdas buvo vaizduojamas 20x20 fotolÄ…steliÅ³ matrica, taigi neuroninis tinklas turÄ—jo 400 Ä¯Ä—jimÅ³ ir vienÄ… dvejetainÄ¯ iÅ¡Ä—jimÄ…. Paprastas tinklas turÄ—jo vienÄ… neuronÄ…, dar vadinamÄ… **slenksÄio logikos vienetu**. Neuroninio tinklo svoriai veikÄ— kaip potenciometrai, kuriuos reikÄ—jo rankiniu bÅ«du reguliuoti mokymo metu.

> âœ… Potenciometras â€“ tai prietaisas, leidÅ¾iantis vartotojui reguliuoti grandinÄ—s varÅ¾Ä….

> Tuo metu â€The New York Timesâ€œ raÅ¡Ä— apie perceptronÄ…: *elektroninio kompiuterio embrionas, iÅ¡ kurio [JAV karinis jÅ«rÅ³ laivynas] tikisi, kad jis galÄ—s vaikÅ¡Äioti, kalbÄ—ti, matyti, raÅ¡yti, daugintis ir suvokti savo egzistavimÄ….*

## Perceptrono modelis

Tarkime, kad mÅ«sÅ³ modelyje yra N poÅ¾ymiÅ³, tuomet Ä¯vesties vektorius bus N dydÅ¾io vektorius. Perceptronas yra **dvejetainÄ—s klasifikacijos** modelis, t.y. jis gali atskirti dvi Ä¯vesties duomenÅ³ klases. Tarkime, kad kiekvienam Ä¯vesties vektoriui x perceptrono iÅ¡Ä—jimas bus +1 arba -1, priklausomai nuo klasÄ—s. IÅ¡Ä—jimas skaiÄiuojamas pagal formulÄ™:

y(x) = f(w<sup>T</sup>x)

kur f yra slenksÄio aktyvacijos funkcija

## Perceptrono mokymas

Norint apmokyti perceptronÄ…, reikia rasti svoriÅ³ vektoriÅ³ w, kuris teisingai klasifikuotÅ³ kuo daugiau reikÅ¡miÅ³, t.y. duotÅ³ maÅ¾iausiÄ… **klaidÄ…**. Å i klaida apibrÄ—Å¾iama pagal **perceptrono kriterijÅ³** taip:

E(w) = -âˆ‘w<sup>T</sup>x<sub>i</sub>t<sub>i</sub>

kur:

* suma skaiÄiuojama tik tiems mokymo duomenÅ³ taÅ¡kams i, kurie buvo neteisingai klasifikuoti
* x<sub>i</sub> â€“ Ä¯vesties duomenys, o t<sub>i</sub> â€“ -1 arba +1, atitinkamai neigiamiems ir teigiamiems pavyzdÅ¾iams.

Å is kriterijus laikomas svoriÅ³ w funkcija, ir jÄ¯ reikia minimizuoti. DaÅ¾nai naudojamas metodas, vadinamas **gradientiniu nusileidimu**, kai pradedama nuo pradinio svoriÅ³ vektoriaus w<sup>(0)</sup>, o kiekviename Å¾ingsnyje svoriai atnaujinami pagal formulÄ™:

w<sup>(t+1)</sup> = w<sup>(t)</sup> - Î·âˆ‡E(w)

ÄŒia Î· â€“ vadinamas **mokymosi greitis**, o âˆ‡E(w) Å¾ymi E **gradientÄ…**. ApskaiÄiavus gradientÄ…, gauname

w<sup>(t+1)</sup> = w<sup>(t)</sup> + âˆ‘Î·x<sub>i</sub>t<sub>i</sub>

Algoritmas Python kalba atrodo taip:

```python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)
        
    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```

## IÅ¡vada

Å ioje pamokoje suÅ¾inojote apie perceptronÄ… â€“ dvejetainÄ—s klasifikacijos modelÄ¯, ir kaip jÄ¯ apmokyti naudojant svoriÅ³ vektoriÅ³.

## ğŸš€ IÅ¡Å¡Å«kis

Jei norite patys sukurti perceptronÄ…, iÅ¡bandykite Å¡iÄ… laboratorijÄ… Microsoft Learn, kurioje naudojamas Azure ML dizaineris


## ApÅ¾valga ir savarankiÅ¡kas mokymasis

NorÄ—dami pamatyti, kaip perceptronÄ… galima naudoti sprendÅ¾iant Å¾aislinius ir realius uÅ¾davinius, ir tÄ™sti mokymÄ…si â€“ eikite Ä¯ Perceptron uÅ¾raÅ¡Å³ knygÄ….

Taip pat Å¡tai Ä¯domus straipsnis apie perceptronus.

## UÅ¾duotis

Å ioje pamokoje Ä¯gyvendinome perceptronÄ… dvejetainÄ—s klasifikacijos uÅ¾duoÄiai ir panaudojome jÄ¯ dviem ranka raÅ¡ytiems skaitmenims klasifikuoti. Å ioje laboratorijoje jÅ«sÅ³ praÅ¡oma visiÅ¡kai iÅ¡sprÄ™sti skaitmenÅ³ klasifikavimo uÅ¾davinÄ¯, t.y. nustatyti, kuris skaitmuo greiÄiausiai atitinka pateiktÄ… vaizdÄ….

* Instrukcijos
* UÅ¾raÅ¡Å³ knyga

---

**AtsakomybÄ—s atsisakymas**:  
Å is dokumentas buvo iÅ¡verstas naudojant dirbtinio intelekto vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Svarbios informacijos atveju rekomenduojame profesionalÅ³ Å¾mogaus vertimÄ…. Mes neatsakome uÅ¾ nesusipratimus ar neteisingÄ… interpretavimÄ…, kilusÄ¯ dÄ—l Å¡io vertimo naudojimo.