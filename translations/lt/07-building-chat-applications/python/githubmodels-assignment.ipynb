{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 7 skyrius: Pokalbių programėlių kūrimas\n",
    "## Github Models API greitoji pradžia\n",
    "\n",
    "Šis užrašų knygelės pavyzdys pritaikytas iš [Azure OpenAI pavyzdžių saugyklos](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), kurioje rasite užrašų knygeles, leidžiančias naudotis [Azure OpenAI](notebook-azure-openai.ipynb) paslaugomis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Apžvalga  \n",
    "„Dideli kalbos modeliai yra funkcijos, kurios tekstą paverčia tekstu. Gavęs įvesties tekstą, didelis kalbos modelis bando nuspėti, koks tekstas bus toliau“(1). Ši „greito starto“ užrašų knygelė supažindins vartotojus su pagrindinėmis LLM sąvokomis, pagrindiniais paketais, reikalingais darbui su AML, lengvu įvadu į užklausų kūrimą ir keliomis trumpomis skirtingų panaudojimo atvejų iliustracijomis.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Turinys  \n",
    "\n",
    "[Apžvalga](../../../../07-building-chat-applications/python)  \n",
    "[Kaip naudotis OpenAI paslauga](../../../../07-building-chat-applications/python)  \n",
    "[1. Sukurkite savo OpenAI paslaugą](../../../../07-building-chat-applications/python)  \n",
    "[2. Diegimas](../../../../07-building-chat-applications/python)    \n",
    "[3. Prisijungimo duomenys](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Panaudojimo atvejai](../../../../07-building-chat-applications/python)    \n",
    "[1. Teksto santrauka](../../../../07-building-chat-applications/python)  \n",
    "[2. Teksto klasifikavimas](../../../../07-building-chat-applications/python)  \n",
    "[3. Nauji produktų pavadinimai](../../../../07-building-chat-applications/python)  \n",
    "[4. Klasifikatoriaus tobulinimas](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Nuorodos](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Sukurkite savo pirmąjį užklausimą  \n",
    "Ši trumpa užduotis suteiks pagrindinę įžangą, kaip pateikti užklausas modeliui Github Models, atliekant paprastą užduotį – „sutrumpinimą“.\n",
    "\n",
    "\n",
    "**Veiksmai**:  \n",
    "1. Įdiekite `azure-ai-inference` biblioteką savo python aplinkoje, jei dar to nepadarėte.  \n",
    "2. Įkelkite standartines pagalbines bibliotekas ir pasiruoškite Github Models prisijungimo duomenis.  \n",
    "3. Pasirinkite modelį savo užduočiai  \n",
    "4. Sukurkite paprastą užklausą modeliui  \n",
    "5. Pateikite savo užklausą modelio API!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Įdiekite `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Tinkamo modelio pasirinkimas  \n",
    "GPT-3.5-turbo arba GPT-4 modeliai gali suprasti ir generuoti natūralią kalbą.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Užklausų kūrimas\n",
    "\n",
    "„Didžiausias kalbos modelių stebuklas yra tas, kad mokydamiesi sumažinti prognozavimo klaidą analizuodami milžiniškus tekstų kiekius, modeliai išmoksta sąvokų, kurios padeda jiems prognozuoti. Pavyzdžiui, jie išmoksta tokių dalykų kaip“(1):\n",
    "\n",
    "* kaip rašyti be klaidų\n",
    "* kaip veikia gramatika\n",
    "* kaip perfrazuoti mintis\n",
    "* kaip atsakyti į klausimus\n",
    "* kaip palaikyti pokalbį\n",
    "* kaip rašyti įvairiomis kalbomis\n",
    "* kaip programuoti\n",
    "* ir t. t.\n",
    "\n",
    "#### Kaip valdyti didelį kalbos modelį\n",
    "„Iš visų didelio kalbos modelio įvesties duomenų, pats svarbiausias yra tekstinė užklausa“(1).\n",
    "\n",
    "Dideli kalbos modeliai gali būti paskatinti generuoti atsakymus keliais būdais:\n",
    "\n",
    "Instrukcija: Pasakykite modeliui, ko norite\n",
    "Užbaigimas: Paskatinkite modelį užbaigti tai, ką pradėjote\n",
    "Demonstracija: Parodykite modeliui, ko norite, naudodami:\n",
    "Keletą pavyzdžių užklausoje\n",
    "Šimtus ar tūkstančius pavyzdžių specialiai paruoštame mokymo duomenų rinkinyje\n",
    "\n",
    "#### Yra trys pagrindinės užklausų kūrimo taisyklės:\n",
    "\n",
    "**Parodykite ir paaiškinkite.** Aiškiai nurodykite, ko norite – per instrukcijas, pavyzdžius arba jų derinį. Jei norite, kad modelis surikiuotų sąrašą abėcėlės tvarka ar priskirtų pastraipai emociją, parodykite, kad būtent to tikitės.\n",
    "\n",
    "**Naudokite kokybiškus duomenis.** Jei kuriate klasifikatorių ar norite, kad modelis laikytųsi tam tikro šablono, pasirūpinkite, kad pavyzdžių būtų pakankamai. Būtinai peržiūrėkite savo pavyzdžius – modelis dažnai pakankamai išmanus, kad suprastų elementarias rašybos klaidas ir vis tiek pateiktų atsakymą, tačiau gali manyti, kad tai padaryta specialiai, ir tai gali paveikti rezultatą.\n",
    "\n",
    "**Patikrinkite nustatymus.** Temperatūros ir top_p parametrai lemia, kiek modelis bus nuspėjamas generuodamas atsakymą. Jei prašote atsakymo, kur yra tik vienas teisingas variantas, šiuos parametrus reikėtų nustatyti žemiau. Jei norite įvairesnių atsakymų, galite juos padidinti. Dažniausia klaida – manyti, kad šie nustatymai lemia „išradingumą“ ar „kūrybiškumą“.\n",
    "\n",
    "Šaltinis: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Apibendrinti tekstą  \n",
    "#### Užduotis  \n",
    "Apibendrinkite tekstą, pridėdami „tl;dr:“ pabaigoje. Atkreipkite dėmesį, kaip modelis geba atlikti įvairias užduotis be papildomų nurodymų. Galite eksperimentuoti su išsamesniais raginimais nei tl;dr, kad pakeistumėte modelio elgesį ir pritaikytumėte gautą santrauką(3).  \n",
    "\n",
    "Naujausi tyrimai parodė reikšmingą pažangą daugelyje NLP užduočių ir etalonų, kai pirmiausia modeliai apmokomi su dideliu tekstų korpusu, o vėliau pritaikomi konkrečiai užduočiai. Nors tokia architektūra dažniausiai yra nepriklausoma nuo užduoties, vis tiek reikia tūkstančių ar dešimčių tūkstančių pavyzdžių specializuotam pritaikymui. Priešingai, žmonės dažnai gali atlikti naują kalbinę užduotį vos iš kelių pavyzdžių ar paprastų nurodymų – tai, su kuo dabartinės NLP sistemos vis dar sunkiai susidoroja. Čia parodome, kad didinant kalbos modelių mastą, žymiai pagerėja užduočiai nepriklausomas, kelių pavyzdžių veikimas, kartais net pasiekiamas konkurencingumas su ankstesniais pažangiausiais pritaikymo metodais.  \n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Pratimai keliems naudojimo atvejams  \n",
    "1. Apibendrinti tekstą  \n",
    "2. Klasifikuoti tekstą  \n",
    "3. Generuoti naujus produktų pavadinimus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klasifikuokite tekstą  \n",
    "#### Užduotis  \n",
    "Klasifikuokite elementus į kategorijas, kurios pateikiamos užklausos metu. Šiame pavyzdyje tiek kategorijos, tiek tekstas klasifikavimui yra pateikiami užklausoje (*playground_reference).\n",
    "\n",
    "Kliento užklausa: Sveiki, vienas iš mano nešiojamojo kompiuterio klaviatūros klavišų neseniai sulūžo ir man reikės pakeitimo:\n",
    "\n",
    "Priskirta kategorija:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sukurkite naujus produktų pavadinimus\n",
    "#### Užduotis\n",
    "Sukurkite produktų pavadinimus pagal pateiktus pavyzdinius žodžius. Čia į užklausą įtraukiame informaciją apie produktą, kuriam generuosime pavadinimus. Taip pat pateikiame panašų pavyzdį, kad parodytume, kokio tipo pavadinimų tikimės. Be to, nustatėme aukštą temperatūros reikšmę, kad atsakymai būtų įvairesni ir kūrybiškesni.\n",
    "\n",
    "Produkto aprašymas: Namų kokteilių plaktuvas\n",
    "Raktiniai žodžiai: greitas, sveikas, kompaktiškas.\n",
    "Produktų pavadinimai: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Produkto aprašymas: Batų pora, kuri tinka bet kokio dydžio pėdai.\n",
    "Raktiniai žodžiai: prisitaikantis, tinkamas, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Nuorodos  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Pavyzdžiai](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Geriausia praktika GPT-3 pritaikymui teksto klasifikavimui](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Daugiau pagalbos  \n",
    "[OpenAI komercializacijos komanda](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Prisidėję asmenys\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Atsakomybės atsisakymas**:  \nŠis dokumentas buvo išverstas naudojant dirbtinio intelekto vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, atkreipkite dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Svarbiai informacijai rekomenduojame profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už bet kokius nesusipratimus ar neteisingą interpretavimą, kilusį naudojantis šiuo vertimu.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:55:26+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "lt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}