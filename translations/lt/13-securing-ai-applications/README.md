<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f3cac698e9eea47dd563633bd82daf8c",
  "translation_date": "2025-08-25T12:39:39+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "lt"
}
-->
# Kaip uÅ¾tikrinti generatyviosios AI programÅ³ saugumÄ…

[![Kaip uÅ¾tikrinti generatyviosios AI programÅ³ saugumÄ…](../../../translated_images/13-lesson-banner.14103e36b4bbf17398b64ed2b0531f6f2c6549e7f7342f797c40bcae5a11862e.lt.png)](https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst)

## Ä®vadas

Å ioje pamokoje aptarsime:

- SaugumÄ… AI sistemÅ³ kontekste.
- DaÅ¾niausias rizikas ir grÄ—smes AI sistemoms.
- AI sistemÅ³ apsaugos bÅ«dus ir svarbiausius aspektus.

## Mokymosi tikslai

BaigÄ™ Å¡iÄ… pamokÄ…, suprasite:

- Kokios grÄ—smÄ—s ir rizikos kyla AI sistemoms.
- DaÅ¾niausius AI sistemÅ³ apsaugos metodus ir praktikÄ….
- Kaip saugumo testavimas gali padÄ—ti iÅ¡vengti netikÄ—tÅ³ rezultatÅ³ ir vartotojÅ³ pasitikÄ—jimo praradimo.

## KÄ… reiÅ¡kia saugumas generatyviosios AI kontekste?

Dirbtinis intelektas (AI) ir maÅ¡ininis mokymasis (ML) vis labiau keiÄia mÅ«sÅ³ gyvenimÄ…, todÄ—l svarbu apsaugoti ne tik klientÅ³ duomenis, bet ir paÄias AI sistemas. AI/ML vis daÅ¾niau naudojamas priimant svarbius sprendimus srityse, kur neteisingas sprendimas gali turÄ—ti rimtÅ³ pasekmiÅ³.

SvarbÅ«s aspektai, Ä¯ kuriuos reikia atkreipti dÄ—mesÄ¯:

- **AI/ML poveikis**: AI/ML daro didelÄ™ Ä¯takÄ… kasdieniam gyvenimui, todÄ—l jÅ³ apsauga tampa bÅ«tina.
- **Saugumo iÅ¡Å¡Å«kiai**: DÄ—l Å¡io poveikio bÅ«tina tinkamai pasirÅ«pinti AI pagrÄ¯stÅ³ produktÅ³ apsauga nuo sudÄ—tingÅ³ atakÅ³ â€“ tiek iÅ¡ piktavaliÅ³, tiek iÅ¡ organizuotÅ³ grupiÅ³.
- **StrateginÄ—s problemos**: TechnologijÅ³ sektorius turi iÅ¡ anksto sprÄ™sti strateginius iÅ¡Å¡Å«kius, kad uÅ¾tikrintÅ³ ilgalaikÄ¯ klientÅ³ saugumÄ… ir duomenÅ³ apsaugÄ….

Be to, maÅ¡ininio mokymosi modeliai daÅ¾nai nesugeba atskirti piktavaliÅ¡kÅ³ Ä¯vesÄiÅ³ nuo nekaltÅ³ anomalijÅ³. DidelÄ— dalis mokymosi duomenÅ³ gaunama iÅ¡ nepriÅ¾iÅ«rimÅ³, nefiltruotÅ³ vieÅ¡Å³ duomenÅ³ rinkiniÅ³, prie kuriÅ³ gali prisidÄ—ti bet kas. UÅ¾puolikams nereikia Ä¯silauÅ¾ti Ä¯ duomenÅ³ rinkinius, jei jie gali laisvai juos papildyti. Ilgainiui Å¾emos kokybÄ—s piktavaliÅ¡ki duomenys tampa patikimais, jei jÅ³ struktÅ«ra ir formatas atitinka reikalavimus.

TodÄ—l labai svarbu uÅ¾tikrinti, kad jÅ«sÅ³ modeliÅ³ naudojami duomenÅ³ Å¡altiniai bÅ«tÅ³ patikimi ir apsaugoti.

## AI grÄ—smiÅ³ ir rizikÅ³ supratimas

AI ir susijusiÅ³ sistemÅ³ kontekste duomenÅ³ uÅ¾nuodijimas Å¡iuo metu yra viena didÅ¾iausiÅ³ saugumo grÄ—smiÅ³. DuomenÅ³ uÅ¾nuodijimas â€“ tai tyÄinis mokymo duomenÅ³ pakeitimas, dÄ—l kurio AI pradeda daryti klaidas. Taip nutinka dÄ—l to, kad nÄ—ra standartizuotÅ³ aptikimo ir prevencijos metodÅ³, o mokymui daÅ¾nai naudojami nepatikimi ar nepriÅ¾iÅ«rimi vieÅ¡i duomenÅ³ rinkiniai. Norint iÅ¡laikyti duomenÅ³ vientisumÄ… ir iÅ¡vengti klaidingo mokymo proceso, bÅ«tina sekti duomenÅ³ kilmÄ™ ir istorijÄ…. PrieÅ¡ingu atveju galioja sena taisyklÄ—: â€Å¡iukÅ¡lÄ—s Ä¯eina â€“ Å¡iukÅ¡lÄ—s iÅ¡einaâ€œ, o modelio veikimas nukenÄia.

Å tai keletas pavyzdÅ¾iÅ³, kaip duomenÅ³ uÅ¾nuodijimas gali paveikti jÅ«sÅ³ modelius:

1. **Å½ymÅ³ apkeitimas**: DvejetainÄ—s klasifikacijos uÅ¾duotyje uÅ¾puolikas tyÄia pakeiÄia dalies mokymo duomenÅ³ Å¾ymas. PavyzdÅ¾iui, nekalti pavyzdÅ¾iai paÅ¾ymimi kaip piktavaliÅ¡ki, todÄ—l modelis iÅ¡moksta neteisingas asociacijas.\
   **Pavyzdys**: Å lamÅ¡to filtras, dÄ—l pakeistÅ³ Å¾ymÅ³, teisÄ—tus laiÅ¡kus priskiria Å¡lamÅ¡tui.
2. **PoÅ¾ymiÅ³ uÅ¾nuodijimas**: UÅ¾puolikas subtiliai pakeiÄia mokymo duomenÅ³ poÅ¾ymius, kad sukeltÅ³ Å¡aliÅ¡kumÄ… ar suklaidintÅ³ modelÄ¯.\
   **Pavyzdys**: Pridedami nereikalingi raktiniai Å¾odÅ¾iai prie produktÅ³ apraÅ¡ymÅ³, kad bÅ«tÅ³ paveiktos rekomendacijÅ³ sistemos.
3. **DuomenÅ³ Ä¯terpimas**: Ä® mokymo rinkinÄ¯ Ä¯terpiami piktavaliÅ¡ki duomenys, siekiant paveikti modelio elgesÄ¯.\
   **Pavyzdys**: Sukuriamos netikros vartotojÅ³ apÅ¾valgos, kad bÅ«tÅ³ iÅ¡kreipti nuotaikÅ³ analizÄ—s rezultatai.
4. **â€Backdoorâ€œ atakos**: UÅ¾puolikas Ä¯terpia paslÄ—ptÄ… Å¡ablonÄ… (backdoor) Ä¯ mokymo duomenis. Modelis iÅ¡moksta atpaÅ¾inti Å¡Ä¯ Å¡ablonÄ… ir, jam pasireiÅ¡kus, elgiasi piktavaliÅ¡kai.\
   **Pavyzdys**: VeidÅ³ atpaÅ¾inimo sistema, apmokyta su â€uÅ¾nuodytaisâ€œ vaizdais, neteisingai atpaÅ¾Ä¯sta konkretÅ³ asmenÄ¯.

MITRE korporacija sukÅ«rÄ— [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst) â€“ Å¾iniÅ³ bazÄ™ apie taktikas ir technikas, kurias naudoja uÅ¾puolikai realiose AI sistemÅ³ atakose.

> AI pagrÄ¯stose sistemose daugÄ—ja paÅ¾eidÅ¾iamumÅ³, nes AI integravimas padidina atakos pavirÅ¡iÅ³, palyginti su tradicinÄ—mis kibernetinÄ—mis atakomis. SukÅ«rÄ—me ATLAS, kad atkreiptume dÄ—mesÄ¯ Ä¯ Å¡iuos unikalius ir besikeiÄianÄius paÅ¾eidÅ¾iamumus, nes vis daugiau pasaulio bendruomenÄ—s AI integruoja Ä¯ Ä¯vairias sistemas. ATLAS modeliuojamas pagal MITRE ATT&CKÂ® sistemÄ…, o jo taktikos, technikos ir procedÅ«ros (TTP) papildo ATT&CK.

Kaip ir MITRE ATT&CKÂ® sistema, plaÄiai naudojama tradicinÄ—je kibernetinÄ—je saugoje planuojant paÅ¾angias atakÅ³ imitacijas, ATLAS pateikia lengvai ieÅ¡komÄ… TTP rinkinÄ¯, kuris padeda geriau suprasti ir pasiruoÅ¡ti naujoms grÄ—smÄ—ms.

Taip pat Open Web Application Security Project (OWASP) sukÅ«rÄ— "[Top 10 sÄ…raÅ¡Ä…](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" â€“ svarbiausiÅ³ paÅ¾eidÅ¾iamumÅ³, aptinkamÅ³ LLM naudojanÄiose programose. Å iame sÄ…raÅ¡e pabrÄ—Å¾iamos tokios grÄ—smÄ—s kaip minÄ—tas duomenÅ³ uÅ¾nuodijimas ir kitos, pavyzdÅ¾iui:

- **Prompt Injection**: technika, kai uÅ¾puolikai specialiai suformuluotomis Ä¯vestimis priverÄia didelÄ¯ kalbos modelÄ¯ (LLM) elgtis ne taip, kaip numatyta.
- **Tiekimo grandinÄ—s paÅ¾eidÅ¾iamumai**: LLM naudojamÅ³ programÅ³ komponentai ir programinÄ— Ä¯ranga, tokie kaip Python moduliai ar iÅ¡oriniai duomenÅ³ rinkiniai, taip pat gali bÅ«ti paÅ¾eisti, dÄ—l ko atsiranda netikÄ—tÅ³ rezultatÅ³, Å¡aliÅ¡kumo ar net paÅ¾eidÅ¾iamumÅ³ infrastruktÅ«roje.
- **Per didelis pasitikÄ—jimas**: LLM nÄ—ra neklystantys ir gali â€fantazuotiâ€œ, pateikdami netikslius ar nesaugius rezultatus. Yra uÅ¾fiksuota atvejÅ³, kai Å¾monÄ—s aklai pasitikÄ—jo LLM atsakymais, dÄ—l ko kilo neigiamÅ³ pasekmiÅ³ realiame pasaulyje.

Microsoft Cloud Advocate Rod Trent paraÅ¡Ä— nemokamÄ… elektroninÄ™ knygÄ… [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst), kurioje iÅ¡samiai nagrinÄ—jamos Å¡ios ir kitos naujos AI grÄ—smÄ—s bei pateikiamos rekomendacijos, kaip su jomis kovoti.

## AI sistemÅ³ ir LLM saugumo testavimas

Dirbtinis intelektas (AI) keiÄia Ä¯vairias sritis ir pramonÄ—s Å¡akas, atverdamas naujas galimybes ir naudÄ… visuomenei. TaÄiau AI taip pat kelia rimtÅ³ iÅ¡Å¡Å«kiÅ³ ir rizikÅ³, tokiÅ³ kaip duomenÅ³ privatumas, Å¡aliÅ¡kumas, paaiÅ¡kinamumo stoka ir galimas piktnaudÅ¾iavimas. TodÄ—l labai svarbu uÅ¾tikrinti, kad AI sistemos bÅ«tÅ³ saugios ir atsakingos â€“ laikytÅ³si etikos ir teisÄ—s normÅ³, o vartotojai ir suinteresuotosios Å¡alys galÄ—tÅ³ jomis pasitikÄ—ti.

Saugumo testavimas â€“ tai AI sistemos ar LLM saugumo Ä¯vertinimo procesas, nustatant ir iÅ¡naudojant jÅ³ paÅ¾eidÅ¾iamumus. Tai gali atlikti kÅ«rÄ—jai, vartotojai ar nepriklausomi auditoriai, priklausomai nuo testavimo tikslo ir apimties. DaÅ¾niausi AI sistemÅ³ ir LLM saugumo testavimo metodai:

- **DuomenÅ³ iÅ¡valymas**: Tai procesas, kai iÅ¡ mokymo duomenÅ³ ar AI sistemos/LLM Ä¯vesties paÅ¡alinama arba anonimizuojama jautri ar privati informacija. DuomenÅ³ iÅ¡valymas padeda iÅ¡vengti duomenÅ³ nutekÄ—jimo ir piktavaliÅ¡ko manipuliavimo, sumaÅ¾inant konfidencialiÅ³ ar asmeniniÅ³ duomenÅ³ atskleidimÄ….
- **Adversarial testavimas**: Tai procesas, kai AI sistemos ar LLM Ä¯vestims ar iÅ¡vestims taikomi specialiai sukurti pavyzdÅ¾iai, siekiant Ä¯vertinti jÅ³ atsparumÄ… piktavaliÅ¡koms atakoms. Adversarial testavimas padeda nustatyti ir sumaÅ¾inti AI sistemos ar LLM paÅ¾eidÅ¾iamumus, kuriuos gali iÅ¡naudoti uÅ¾puolikai.
- **Modelio verifikavimas**: Tai procesas, kai tikrinamas AI sistemos ar LLM modelio parametrÅ³ ar architektÅ«ros teisingumas ir pilnumas. Modelio verifikavimas padeda aptikti ir uÅ¾kirsti keliÄ… modelio vagystei, uÅ¾tikrinant, kad modelis bÅ«tÅ³ apsaugotas ir autentiÅ¡kas.
- **IÅ¡vesties tikrinimas**: Tai procesas, kai tikrinama AI sistemos ar LLM iÅ¡vesties kokybÄ— ir patikimumas. IÅ¡vesties tikrinimas padeda aptikti ir iÅ¡taisyti piktavaliÅ¡kÄ… manipuliavimÄ…, uÅ¾tikrinant, kad iÅ¡vestis bÅ«tÅ³ nuosekli ir tiksli.

OpenAI, viena iÅ¡ AI lyderiÅ³, Ä¯diegÄ— _saugumo vertinimus_ kaip savo â€red teamingâ€œ tinklo iniciatyvos dalÄ¯, siekdama testuoti AI sistemÅ³ iÅ¡vestÄ¯ ir prisidÄ—ti prie AI saugumo.

> Vertinimai gali bÅ«ti nuo paprastÅ³ klausimÅ³-atsakymÅ³ testÅ³ iki sudÄ—tingesniÅ³ simuliacijÅ³. Å tai keletas OpenAI sukurtÅ³ vertinimÅ³, skirtÅ³ AI elgsenai Ä¯vertinti iÅ¡ Ä¯vairiÅ³ pusiÅ³:

#### Ä®tikinÄ—jimas

- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai AI sistema gali priversti kitÄ… AI sistemÄ… pasakyti slaptÄ… Å¾odÄ¯?
- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai AI sistema gali Ä¯tikinti kitÄ… AI sistemÄ… paaukoti pinigÅ³?
- [Ballot Proposal](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai AI sistema gali paveikti kitos AI sistemos palaikymÄ… politiniam pasiÅ«lymui?

#### Steganografija (slapta Å¾inutÄ—)

- [Steganography](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai AI sistema gali perduoti slaptas Å¾inutes, kad kitos AI sistemos jÅ³ nepastebÄ—tÅ³?
- [Text Compression](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai AI sistema gali suspausti ir iÅ¡skleisti Å¾inutes, kad bÅ«tÅ³ galima paslÄ—pti slaptas Å¾inutes?
- [Schelling Point](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): Kaip gerai AI sistema gali koordinuotis su kita AI sistema be tiesioginio bendravimo?

### AI saugumas

Labai svarbu siekti apsaugoti AI sistemas nuo piktavaliÅ¡kÅ³ atakÅ³, piktnaudÅ¾iavimo ar netyÄiniÅ³ pasekmiÅ³. Tai apima veiksmus, uÅ¾tikrinanÄius AI sistemÅ³ saugumÄ…, patikimumÄ… ir pasitikÄ—jimÄ…, pavyzdÅ¾iui:

- Saugoti duomenis ir algoritmus, naudojamus AI modeliÅ³ mokymui ir veikimui
- UÅ¾kirsti keliÄ… neleistinam AI sistemÅ³ pasiekimui, manipuliavimui ar sabotaÅ¾ui
- Aptikti ir maÅ¾inti Å¡aliÅ¡kumÄ…, diskriminacijÄ… ar etines problemas AI sistemose
- UÅ¾tikrinti AI sprendimÅ³ ir veiksmÅ³ atskaitomybÄ™, skaidrumÄ… ir paaiÅ¡kinamumÄ…
- Suderinti AI sistemÅ³ tikslus ir vertybes su Å¾moniÅ³ ir visuomenÄ—s interesais

AI saugumas svarbus siekiant uÅ¾tikrinti AI sistemÅ³ ir duomenÅ³ vientisumÄ…, prieinamumÄ… ir konfidencialumÄ…. Pagrindiniai AI saugumo iÅ¡Å¡Å«kiai ir galimybÄ—s:

- GalimybÄ—: AI integravimas Ä¯ kibernetinio saugumo strategijas, nes AI gali padÄ—ti greiÄiau aptikti grÄ—smes ir reaguoti Ä¯ jas. AI gali automatizuoti ir pagerinti kibernetiniÅ³ atakÅ³, tokiÅ³ kaip phishing, kenkÄ—jiÅ¡ka programinÄ— Ä¯ranga ar ransomware, aptikimÄ… ir prevencijÄ….
- IÅ¡Å¡Å«kis: AI taip pat gali bÅ«ti naudojamas uÅ¾puolikÅ³ sudÄ—tingoms atakoms, pavyzdÅ¾iui, kuriant netikrÄ… ar klaidinanÄiÄ… informacijÄ…, apsimetant vartotojais ar iÅ¡naudojant AI sistemÅ³ paÅ¾eidÅ¾iamumus. TodÄ—l AI kÅ«rÄ—jai turi ypatingÄ… atsakomybÄ™ kurti sistemas, atsparias piktnaudÅ¾iavimui.

### DuomenÅ³ apsauga

LLM gali kelti grÄ—smÄ™ jÅ³ naudojamÅ³ duomenÅ³ privatumui ir saugumui. PavyzdÅ¾iui, LLM gali Ä¯siminti ir nutekinti jautriÄ… informacijÄ… iÅ¡ mokymo duomenÅ³, tokiÄ… kaip asmenvardÅ¾iai, adresai, slaptaÅ¾odÅ¾iai ar kreditiniÅ³ korteliÅ³ numeriai. Taip pat LLM gali bÅ«ti manipuliuojami ar atakuojami piktavaliÅ³, siekianÄiÅ³ iÅ¡naudoti jÅ³ paÅ¾eidÅ¾iamumus ar Å¡aliÅ¡kumÄ…. TodÄ—l svarbu Å¾inoti Å¡ias rizikas ir imtis tinkamÅ³ priemoniÅ³ apsaugoti su LLM naudojamus duomenis. Yra keli Å¾ingsniai, kuriÅ³ galite imtis norÄ—dami apsaugoti LLM naudojamus duomenis:

- **Riboti su LLM dalijamÅ³ duomenÅ³ kiekÄ¯ ir tipÄ…**: DalinkitÄ—s tik tais duomenimis, kurie bÅ«tini ir aktualÅ«s numatytiems tikslams, ir venkite dalintis jautriais, konfidencialiais ar asmeniniais duomenimis. Vartotojai taip pat turÄ—tÅ³ anonimizuoti ar uÅ¾Å¡ifruoti su LLM dalijamus duomenis, pavyzdÅ¾iui, paÅ¡alindami ar uÅ¾maskuodami identifikuojanÄiÄ… informacijÄ… arba naudodami saugius komunikacijos kanalus.
- **Tikrinkite LLM sugeneruotus duomenis**: Visada patikrinkite LLM sugeneruotos iÅ¡vesties tikslumÄ… ir kokybÄ™, kad Ä¯sitikintumÄ—te, jog joje nÄ—ra nepageidaujamos ar netinkamos informacijos.
- **PraneÅ¡kite apie duomenÅ³ paÅ¾eidimus ar incidentus**: BÅ«kite budrÅ«s dÄ—l bet kokios Ä¯tartinos ar neÄ¯prastos LLM veiklos, pavyzdÅ¾iui, jei generuojami tekstai yra nesusijÄ™, netikslÅ«s, Ä¯Å¾eidÅ¾iantys ar Å¾aling
AI red teaming praktika iÅ¡siplÄ—tÄ— ir dabar apima ne tik saugumo spragÅ³ paieÅ¡kÄ…, bet ir kitÅ³ sistemos gedimÅ³, pavyzdÅ¾iui, galimai Å¾alingo turinio generavimo, tikrinimÄ…. AI sistemos kelia naujÅ³ rizikÅ³, o red teaming yra esminis siekiant suprasti Å¡ias naujas grÄ—smes, tokias kaip prompt injection ar nepagrÄ¯sto turinio kÅ«rimas. - [Microsoft AI Red Team building future of safer AI](https://www.microsoft.com/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-105485-koreyst)
Å½emiau pateikiamos pagrindinÄ—s Ä¯Å¾valgos, kurios formavo Microsoft AI Red Team programÄ….

1. **Plati AI Red Teaming apimtis:**
   AI red teaming dabar apima tiek saugumo, tiek Atsakingo dirbtinio intelekto (RAI) rezultatus. TradiciÅ¡kai red teaming buvo orientuotas Ä¯ saugumÄ…, modelÄ¯ laikant vektoriumi (pvz., modelio vagystÄ—). TaÄiau AI sistemos sukuria naujÅ³ saugumo spragÅ³ (pvz., prompt injection, nuodijimas), kurioms reikia skirti ypatingÄ… dÄ—mesÄ¯. Be saugumo, AI red teaming taip pat nagrinÄ—ja teisingumo klausimus (pvz., stereotipus) ir Å¾alingÄ… turinÄ¯ (pvz., smurto Å¡lovinimÄ…). Ankstyvas Å¡iÅ³ problemÅ³ nustatymas leidÅ¾ia tinkamai paskirstyti gynybos iÅ¡teklius.
2. **Kenksmingos ir nekaltos nesÄ—kmÄ—s:**
   AI red teaming vertina nesÄ—kmes tiek iÅ¡ kenksmingos, tiek iÅ¡ nekaltos pusÄ—s. PavyzdÅ¾iui, testuojant naujÄ… Bing, analizuojame ne tik kaip piktavaliai gali apeiti sistemÄ…, bet ir kaip paprasti vartotojai gali susidurti su probleminiu ar Å¾alingu turiniu. Skirtingai nei tradicinis saugumo red teaming, kuris daugiausia dÄ—mesio skiria piktavaliams, AI red teaming apima platesnÄ¯ asmenÅ³ ir galimÅ³ nesÄ—kmiÅ³ spektrÄ….
3. **DinamiÅ¡kas AI sistemÅ³ pobÅ«dis:**
   AI programos nuolat keiÄiasi. DideliÅ³ kalbos modeliÅ³ aplikacijose kÅ«rÄ—jai prisitaiko prie besikeiÄianÄiÅ³ reikalavimÅ³. Nuolatinis red teaming uÅ¾tikrina budrumÄ… ir prisitaikymÄ… prie kintanÄiÅ³ rizikÅ³.

AI red teaming nÄ—ra visapusiÅ¡kas ir turÄ—tÅ³ bÅ«ti laikomas papildoma priemone kartu su kitomis kontrolÄ—s priemonÄ—mis, tokiomis kaip [role-based access control (RBAC)](https://learn.microsoft.com/azure/ai-services/openai/how-to/role-based-access-control?WT.mc_id=academic-105485-koreyst) ir iÅ¡samÅ«s duomenÅ³ valdymo sprendimai. Tai skirta papildyti saugumo strategijÄ…, kuri remiasi saugiÅ³ ir atsakingÅ³ AI sprendimÅ³ naudojimu, atsiÅ¾velgiant Ä¯ privatumÄ… ir saugumÄ…, kartu siekiant sumaÅ¾inti Å¡aliÅ¡kumÄ…, Å¾alingÄ… turinÄ¯ ir dezinformacijÄ…, galinÄiÄ… sumaÅ¾inti vartotojÅ³ pasitikÄ—jimÄ….

Å tai papildomos literatÅ«ros sÄ…raÅ¡as, kuris padÄ—s geriau suprasti, kaip red teaming gali padÄ—ti identifikuoti ir sumaÅ¾inti rizikas jÅ«sÅ³ AI sistemose:

- [Red teaming planavimas dideliems kalbos modeliams (LLMs) ir jÅ³ aplikacijoms](https://learn.microsoft.com/azure/ai-services/openai/concepts/red-teaming?WT.mc_id=academic-105485-koreyst)
- [Kas yra OpenAI Red Teaming Network?](https://openai.com/blog/red-teaming-network?WT.mc_id=academic-105485-koreyst)
- [AI Red Teaming â€“ svarbi praktika kuriant saugesnius ir atsakingesnius AI sprendimus](https://rodtrent.substack.com/p/ai-red-teaming?WT.mc_id=academic-105485-koreyst)
- MITRE [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), Å¾iniÅ³ bazÄ— apie taktikas ir technikas, kurias naudoja piktavaliai atakuodami AI sistemas realiame pasaulyje.

## Å½iniÅ³ patikrinimas

Koks galÄ—tÅ³ bÅ«ti geras bÅ«das uÅ¾tikrinti duomenÅ³ vientisumÄ… ir uÅ¾kirsti keliÄ… netinkamam naudojimui?

1. Naudoti grieÅ¾tÄ… prieigos kontrolÄ™ pagal roles duomenÅ³ prieigai ir valdymui
1. Ä®diegti ir audituoti duomenÅ³ Å¾ymÄ—jimÄ…, kad bÅ«tÅ³ iÅ¡vengta duomenÅ³ iÅ¡kraipymo ar netinkamo naudojimo
1. UÅ¾tikrinti, kad jÅ«sÅ³ AI infrastruktÅ«ra palaiko turinio filtravimÄ…

A:1, Nors visi trys yra puikios rekomendacijos, svarbiausia â€“ tinkamai paskirstyti duomenÅ³ prieigos teises vartotojams, nes tai padÄ—s iÅ¡vengti duomenÅ³ manipuliavimo ir iÅ¡kraipymo, naudojamÅ³ LLM.

## ğŸš€ IÅ¡Å¡Å«kis

PasidomÄ—kite daugiau, kaip galite [valdyti ir apsaugoti jautriÄ… informacijÄ…](https://learn.microsoft.com/training/paths/purview-protect-govern-ai/?WT.mc_id=academic-105485-koreyst) AI amÅ¾iuje.

## Puikus darbas, tÄ™skite mokymÄ…si

BaigÄ™ Å¡iÄ… pamokÄ…, perÅ¾iÅ«rÄ—kite mÅ«sÅ³ [Generatyvaus AI mokymosi kolekcijÄ…](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), kad dar labiau pagilintumÄ—te Å¾inias apie generatyvÅ³ AI!

Eikite Ä¯ 14 pamokÄ…, kurioje nagrinÄ—sime [Generatyvaus AI aplikacijos gyvavimo ciklÄ…](../14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst)!

---

**AtsakomybÄ—s atsisakymas**:  
Å is dokumentas buvo iÅ¡verstas naudojant dirbtinio intelekto vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. Svarbios informacijos atveju rekomenduojame profesionalÅ³ Å¾mogaus vertimÄ…. Mes neatsakome uÅ¾ nesusipratimus ar neteisingÄ… interpretavimÄ…, kilusÄ¯ dÄ—l Å¡io vertimo naudojimo.