<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a2faf8ee7a0b851efa647a19788f1e5b",
  "translation_date": "2025-10-18T02:24:10+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "lt"
}
-->
# Saugokite savo generatyviosios dirbtinio intelekto (DI) programas

[![Saugokite savo generatyviosios DI programas](../../../translated_images/13-lesson-banner.14103e36b4bbf17398b64ed2b0531f6f2c6549e7f7342f797c40bcae5a11862e.lt.png)](https://youtu.be/m0vXwsx5DNg?si=TYkr936GMKz15K0L)

## Ä®vadas

Å ioje pamokoje aptarsime:

- SaugumÄ… DI sistemÅ³ kontekste.
- DaÅ¾niausiai pasitaikanÄias DI sistemÅ³ rizikas ir grÄ—smes.
- Metodus ir svarstymus, kaip apsaugoti DI sistemas.

## Mokymosi tikslai

BaigÄ™ Å¡iÄ… pamokÄ…, suprasite:

- GrÄ—smes ir rizikas, susijusias su DI sistemomis.
- DaÅ¾niausius metodus ir praktikas DI sistemÅ³ apsaugai.
- Kaip saugumo testavimas gali padÄ—ti iÅ¡vengti netikÄ—tÅ³ rezultatÅ³ ir vartotojÅ³ pasitikÄ—jimo praradimo.

## KÄ… reiÅ¡kia saugumas generatyviosios DI kontekste?

Kadangi dirbtinio intelekto (DI) ir maÅ¡ininio mokymosi (MM) technologijos vis labiau formuoja mÅ«sÅ³ gyvenimÄ…, svarbu apsaugoti ne tik klientÅ³ duomenis, bet ir paÄias DI sistemas. DI/MM vis daÅ¾niau naudojami priimant svarbius sprendimus pramonÄ—s Å¡akose, kur neteisingas sprendimas gali turÄ—ti rimtÅ³ pasekmiÅ³.

Å tai pagrindiniai aspektai, kuriuos verta apsvarstyti:

- **DI/MM poveikis**: DI/MM daro didelÄ™ Ä¯takÄ… kasdieniam gyvenimui, todÄ—l jÅ³ apsauga tapo bÅ«tina.
- **Saugumo iÅ¡Å¡Å«kiai**: DI/MM poveikis reikalauja tinkamo dÄ—mesio, kad bÅ«tÅ³ uÅ¾tikrinta apsauga nuo sudÄ—tingÅ³ atakÅ³, nesvarbu, ar tai bÅ«tÅ³ troliai, ar organizuotos grupÄ—s.
- **StrateginÄ—s problemos**: TechnologijÅ³ pramonÄ— turi proaktyviai sprÄ™sti strateginius iÅ¡Å¡Å«kius, kad uÅ¾tikrintÅ³ ilgalaikÄ¯ klientÅ³ saugumÄ… ir duomenÅ³ apsaugÄ….

Be to, maÅ¡ininio mokymosi modeliai daÅ¾nai negali atskirti kenksmingÅ³ Ä¯vesties duomenÅ³ nuo nekenksmingÅ³ anomalijÅ³. DidelÄ— dalis mokymosi duomenÅ³ gaunama iÅ¡ nefiltruotÅ³, nemoderuotÅ³ vieÅ¡Å³jÅ³ duomenÅ³ rinkiniÅ³, kurie yra atviri treÄiÅ³jÅ³ Å¡aliÅ³ indÄ—liams. UÅ¾puolikams nereikia paÅ¾eisti duomenÅ³ rinkiniÅ³, kai jie gali laisvai juos papildyti. Laikui bÄ—gant, maÅ¾o pasitikÄ—jimo kenksmingi duomenys tampa aukÅ¡to pasitikÄ—jimo patikimais duomenimis, jei duomenÅ³ struktÅ«ra/formatas iÅ¡lieka tinkamas.

TodÄ—l labai svarbu uÅ¾tikrinti duomenÅ³ saugumÄ… ir vientisumÄ…, kad jÅ«sÅ³ modeliai galÄ—tÅ³ priimti teisingus sprendimus.

## DI grÄ—smiÅ³ ir rizikÅ³ supratimas

Kalbant apie DI ir susijusias sistemas, duomenÅ³ uÅ¾nuodijimas yra viena iÅ¡ didÅ¾iausiÅ³ saugumo grÄ—smiÅ³ Å¡iandien. DuomenÅ³ uÅ¾nuodijimas Ä¯vyksta, kai kas nors tyÄia pakeiÄia informacijÄ…, naudojamÄ… DI mokymui, dÄ—l ko DI pradeda daryti klaidas. Tai vyksta dÄ—l standartizuotÅ³ aptikimo ir maÅ¾inimo metodÅ³ trÅ«kumo, kartu su mÅ«sÅ³ priklausomybe nuo nepatikimÅ³ ar nefiltruotÅ³ vieÅ¡Å³jÅ³ duomenÅ³ rinkiniÅ³ mokymui. Siekiant iÅ¡laikyti duomenÅ³ vientisumÄ… ir uÅ¾kirsti keliÄ… klaidingam mokymosi procesui, bÅ«tina sekti duomenÅ³ kilmÄ™ ir jÅ³ linijÄ…. PrieÅ¡ingu atveju, senas posakis â€Å¡iukÅ¡lÄ—s Ä¯eina, Å¡iukÅ¡lÄ—s iÅ¡einaâ€œ tampa tiesa, o modelio veikimas yra paÅ¾eidÅ¾iamas.

Å tai keletas pavyzdÅ¾iÅ³, kaip duomenÅ³ uÅ¾nuodijimas gali paveikti jÅ«sÅ³ modelius:

1. **EtikeÄiÅ³ keitimas**: Dvejetainio klasifikavimo uÅ¾duotyje prieÅ¡ininkas tyÄia pakeiÄia nedidelÄ—s dalies mokymosi duomenÅ³ etiketes. PavyzdÅ¾iui, nekenksmingi pavyzdÅ¾iai paÅ¾ymimi kaip kenksmingi, todÄ—l modelis iÅ¡moksta neteisingas asociacijas.\
   **Pavyzdys**: Å lamÅ¡to filtras klaidingai klasifikuoja teisÄ—tus el. laiÅ¡kus kaip Å¡lamÅ¡tÄ… dÄ—l manipuliuotÅ³ etikeÄiÅ³.
2. **SavybiÅ³ uÅ¾nuodijimas**: UÅ¾puolikas subtiliai pakeiÄia mokymosi duomenÅ³ savybes, kad Ä¯vestÅ³ Å¡aliÅ¡kumÄ… arba suklaidintÅ³ modelÄ¯.\
   **Pavyzdys**: Pridedami nereikÅ¡mingi raktaÅ¾odÅ¾iai prie produktÅ³ apraÅ¡ymÅ³, siekiant manipuliuoti rekomendacijÅ³ sistemomis.
3. **DuomenÅ³ injekcija**: KenksmingÅ³ duomenÅ³ Ä¯traukimas Ä¯ mokymosi rinkinÄ¯, siekiant paveikti modelio elgesÄ¯.\
   **Pavyzdys**: NetikrÅ³ vartotojÅ³ atsiliepimÅ³ Ä¯traukimas, siekiant iÅ¡kreipti nuotaikÅ³ analizÄ—s rezultatus.
4. **Slaptos atakos**: PrieÅ¡ininkas Ä¯terpia paslÄ—ptÄ… modelÄ¯ (slaptÄ… kodÄ…) Ä¯ mokymosi duomenis. Modelis iÅ¡moksta atpaÅ¾inti Å¡Ä¯ modelÄ¯ ir elgiasi kenksmingai, kai jis suaktyvinamas.\
   **Pavyzdys**: Veido atpaÅ¾inimo sistema, apmokyta su slaptu kodu, neteisingai identifikuoja konkretÅ³ asmenÄ¯.

MITRE korporacija sukÅ«rÄ— [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), Å¾iniÅ³ bazÄ™ apie taktikas ir technikas, kurias naudoja prieÅ¡ininkai realaus pasaulio DI sistemÅ³ atakose.

> DI Ä¯galintose sistemose vis daugÄ—ja paÅ¾eidÅ¾iamumÅ³, nes DI integracija padidina esamÅ³ sistemÅ³ atakÅ³ pavirÅ¡iÅ³, palyginti su tradicinÄ—mis kibernetinÄ—mis atakomis. Mes sukÅ«rÄ—me ATLAS, kad padidintume informuotumÄ… apie Å¡iuos unikalius ir besivystanÄius paÅ¾eidÅ¾iamumus, nes pasaulinÄ— bendruomenÄ— vis daÅ¾niau integruoja DI Ä¯ Ä¯vairias sistemas. ATLAS yra modeliuotas pagal MITRE ATT&CKÂ® sistemÄ…, o jo taktikos, technikos ir procedÅ«ros (TTP) papildo ATT&CK.

Kaip ir MITRE ATT&CKÂ® sistema, kuri plaÄiai naudojama tradicinÄ—je kibernetinÄ—je saugoje planuojant paÅ¾angias grÄ—smiÅ³ imitavimo scenarijus, ATLAS pateikia lengvai ieÅ¡komÄ… TTP rinkinÄ¯, kuris padeda geriau suprasti ir pasiruoÅ¡ti gynybai nuo naujÅ³ atakÅ³.

Be to, Open Web Application Security Project (OWASP) sukÅ«rÄ— "[Top 10 sÄ…raÅ¡Ä…](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" apie kritiÅ¡kiausius paÅ¾eidÅ¾iamumus programose, naudojanÄiose LLM. SÄ…raÅ¡as pabrÄ—Å¾ia tokiÅ³ grÄ—smiÅ³ kaip minÄ—tas duomenÅ³ uÅ¾nuodijimas rizikas, taip pat kitas, tokias kaip:

- **KomandÅ³ injekcija**: technika, kai uÅ¾puolikai manipuliuoja didelio masto kalbos modeliu (LLM) naudodami kruopÅ¡Äiai paruoÅ¡tus Ä¯vesties duomenis, priversdami jÄ¯ elgtis ne pagal numatytÄ… elgesÄ¯.
- **Tiekimo grandinÄ—s paÅ¾eidÅ¾iamumai**: komponentai ir programinÄ— Ä¯ranga, sudaranti LLM naudojamas programas, pvz., Python modulius ar iÅ¡orinius duomenÅ³ rinkinius, gali bÅ«ti paÅ¾eisti, sukeldami netikÄ—tus rezultatus, Ä¯vestus Å¡aliÅ¡kumus ar net paÅ¾eidÅ¾iamumus pagrindinÄ—je infrastruktÅ«roje.
- **Per didelis pasitikÄ—jimas**: LLM yra klaidingi ir linkÄ™ â€fantazuotiâ€œ, pateikdami netikslius ar nesaugius rezultatus. Kai kuriais dokumentuotais atvejais Å¾monÄ—s priÄ—mÄ— rezultatus uÅ¾ grynÄ… pinigÄ…, kas sukÄ—lÄ— nepageidaujamas pasekmes realiame pasaulyje.

Microsoft Cloud Advocate Rod Trent paraÅ¡Ä— nemokamÄ… elektroninÄ™ knygÄ… [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst), kurioje iÅ¡samiai nagrinÄ—jamos Å¡ios ir kitos naujos DI grÄ—smÄ—s bei pateikiamos iÅ¡samios rekomendacijos, kaip geriausiai sprÄ™sti Å¡ias situacijas.

## DI sistemÅ³ ir LLM saugumo testavimas

Dirbtinis intelektas (DI) transformuoja Ä¯vairias sritis ir pramonÄ—s Å¡akas, siÅ«lydamas naujas galimybes ir naudÄ… visuomenei. TaÄiau DI taip pat kelia didelius iÅ¡Å¡Å«kius ir rizikas, tokias kaip duomenÅ³ privatumas, Å¡aliÅ¡kumas, paaiÅ¡kinamumo trÅ«kumas ir galimas piktnaudÅ¾iavimas. TodÄ—l labai svarbu uÅ¾tikrinti, kad DI sistemos bÅ«tÅ³ saugios ir atsakingos, t. y. atitiktÅ³ etinius ir teisÄ—s standartus bei bÅ«tÅ³ patikimos vartotojams ir suinteresuotiems asmenims.

Saugumo testavimas yra procesas, kurio metu vertinamas DI sistemos ar LLM saugumas, identifikuojant ir iÅ¡naudojant jÅ³ paÅ¾eidÅ¾iamumus. Tai gali atlikti kÅ«rÄ—jai, vartotojai ar treÄiÅ³jÅ³ Å¡aliÅ³ auditoriai, priklausomai nuo testavimo tikslo ir apimties. Kai kurie daÅ¾niausiai naudojami saugumo testavimo metodai DI sistemoms ir LLM yra:

- **DuomenÅ³ valymas**: Tai procesas, kurio metu iÅ¡ mokymosi duomenÅ³ ar DI sistemos Ä¯vesties paÅ¡alinama arba anonimizuojama jautri ar privati informacija. DuomenÅ³ valymas gali padÄ—ti iÅ¡vengti duomenÅ³ nutekÄ—jimo ir kenksmingos manipuliacijos, sumaÅ¾inant konfidencialiÅ³ ar asmeniniÅ³ duomenÅ³ atskleidimo rizikÄ….
- **PrieÅ¡iÅ¡kas testavimas**: Tai procesas, kurio metu generuojami ir taikomi prieÅ¡iÅ¡ki pavyzdÅ¾iai DI sistemos ar LLM Ä¯vestyje ar iÅ¡vestyje, siekiant Ä¯vertinti jÅ³ atsparumÄ… ir tvirtumÄ… prieÅ¡ prieÅ¡iÅ¡kas atakas. PrieÅ¡iÅ¡kas testavimas gali padÄ—ti identifikuoti ir sumaÅ¾inti DI sistemos ar LLM paÅ¾eidÅ¾iamumus ir silpnybes, kurias gali iÅ¡naudoti uÅ¾puolikai.
- **Modelio patikrinimas**: Tai procesas, kurio metu tikrinamas DI sistemos ar LLM modelio parametrÅ³ ar architektÅ«ros teisingumas ir pilnumas. Modelio patikrinimas gali padÄ—ti aptikti ir uÅ¾kirsti keliÄ… modelio vagystÄ—ms, uÅ¾tikrinant, kad modelis bÅ«tÅ³ apsaugotas ir autentifikuotas.
- **IÅ¡vesties validacija**: Tai procesas, kurio metu tikrinama DI sistemos ar LLM iÅ¡vesties kokybÄ— ir patikimumas. IÅ¡vesties validacija gali padÄ—ti aptikti ir iÅ¡taisyti kenksmingÄ… manipuliacijÄ…, uÅ¾tikrinant, kad iÅ¡vestis bÅ«tÅ³ nuosekli ir tiksli.

OpenAI, DI sistemÅ³ lyderis, Ä¯kÅ«rÄ— _saugumo vertinimÅ³_ serijÄ… kaip savo raudonÅ³jÅ³ komandÅ³ tinklo iniciatyvos dalÄ¯, siekdama testuoti DI sistemÅ³ iÅ¡vestÄ¯ ir prisidÄ—ti prie DI saugumo.

> Vertinimai gali bÅ«ti nuo paprastÅ³ klausimÅ³-atsakymÅ³ testÅ³ iki sudÄ—tingesniÅ³ simuliacijÅ³. KonkreÄiais pavyzdÅ¾iais pateikiame OpenAI sukurtus vertinimus, skirtus DI elgsenai vertinti iÅ¡ Ä¯vairiÅ³ perspektyvÅ³:

#### Ä®tikinÄ—jimas

- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai DI sistema gali apgauti kitÄ… DI sistemÄ…, kad Å¡i pasakytÅ³ slaptÄ… Å¾odÄ¯?
- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai DI sistema gali Ä¯tikinti kitÄ… DI sistemÄ… paaukoti pinigÅ³?
- [Ballot Proposal](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai DI sistema gali paveikti kitos DI sistemos palaikymÄ… politiniam pasiÅ«lymui?

#### Steganografija (slaptos Å¾inutÄ—s)

- [Steganography](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai DI sistema gali perduoti slaptas Å¾inutes, nepastebÄ—ta kitos DI sistemos?
- [Text Compression](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): Kaip gerai DI sistema gali suspausti ir iÅ¡skleisti Å¾inutes, kad galÄ—tÅ³ paslÄ—pti slaptas Å¾inutes?
- [Schelling Point](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): Kaip gerai DI sistema gali koordinuotis su kita DI sistema, neturÄ—dama tiesioginio ryÅ¡io?

### DI saugumas

Labai svarbu siekti apsaugoti DI sistemas nuo kenksmingÅ³ atakÅ³, piktnaudÅ¾iavimo ar netyÄiniÅ³ pasekmiÅ³. Tai apima veiksmus, skirtus uÅ¾tikrinti DI sistemÅ³ saugumÄ…, patikimumÄ… ir pasitikÄ—jimÄ…, tokius kaip:

- DuomenÅ³ ir algoritmÅ³, naudojamÅ³ DI modeliams mokyti ir vykdyti, apsauga.
- Neleistinos prieigos, manipuliacijos ar sabotaÅ¾o prevencija DI sistemose.
- Å aliÅ¡kumo, diskriminacijos ar etiniÅ³ problemÅ³ aptikimas ir maÅ¾inimas DI sistemose.
- DI sprendimÅ³ ir veiksmÅ³ atskaitomybÄ—s, skaidrumo ir paaiÅ¡kinamumo uÅ¾tikrinimas.
- DI sistemÅ³ tikslÅ³ ir vertybiÅ³ suderinimas su Å¾moniÅ³ ir visuomenÄ—s vertybÄ—mis.

DI saugumas yra svarbus uÅ¾tikrinant DI sistemÅ³ ir duomenÅ³ vientisumÄ…, prieinamumÄ… ir konfidencialumÄ…. Kai kurie DI saugumo iÅ¡Å¡Å«kiai ir galimybÄ—s yra:

- GalimybÄ—: DI integravimas Ä¯ kibernetinio saugumo strategijas, nes jis gali atlikti svarbÅ³ vaidmenÄ¯ identifikuojant grÄ—smes ir gerinant reagavimo laikÄ…. DI gali padÄ—ti automatizuoti ir sustiprinti kibernetiniÅ³ atakÅ³, tokiÅ³ kaip sukÄiavimas, kenkÄ—jiÅ¡ka programinÄ— Ä¯ranga ar iÅ¡pirkos reikalavimai, aptikimÄ… ir maÅ¾inimÄ….
- IÅ¡Å¡Å«kis: DI taip pat gali bÅ«ti naudojamas prieÅ¡ininkÅ³, siekiant pradÄ—ti sudÄ—tingas atakas, tokias kaip netikro ar klaidinanÄio turinio generavimas, vartotojÅ³ apsimetinÄ—jimas ar DI sistemÅ³ paÅ¾eidÅ¾iamumÅ³ iÅ¡naudojimas. TodÄ—l DI kÅ«rÄ—jai turi unikaliÄ… atsakomybÄ™ kurti sistemas, kurios bÅ«tÅ³ tvirtos ir atsparios piktnaudÅ¾iavimui.

### DuomenÅ³ apsauga

LLM gali kelti rizikÄ… duomenÅ³, kuriuos jie naudoja, privatumui ir saugumui. PavyzdÅ¾iui, LLM gali potencialiai Ä¯siminti ir nutekinti jautriÄ… informacijÄ… iÅ¡ savo mokymosi duomenÅ³, tokiÄ… kaip asmeniniai vardai, adresai, slaptaÅ¾odÅ¾iai ar kreditiniÅ³ korteliÅ³ numeriai. Jie taip pat gali bÅ«ti manipuliuojami ar uÅ¾pulti kenksmingÅ³ veikÄ—jÅ³, siekianÄiÅ³ iÅ¡naudoti jÅ³ paÅ¾eidÅ¾iamumus ar Å¡aliÅ¡kumus. TodÄ—l svarbu bÅ«ti sÄ…moningiems apie Å¡ias rizikas ir imtis tinkamÅ³ priemoniÅ³ apsaugoti duomenis, naudojamus su LLM. Yra keletas Å¾ingsniÅ³, kuriuos galite atlikti, kad apsaugotumÄ—te duomenis, naudojamus su LLM. Å ie Å¾ingsniai apima:

- **Riboti duomenÅ³ kiekÄ¯ ir tipÄ…, kuriuos dalinatÄ—s su LLM**: DalinkitÄ—s tik tais duomenimis, kurie yra bÅ«tini ir aktualÅ«s numatytiems tikslams, ir venkite dalintis bet kokiais duomen
Imituoti realaus pasaulio grÄ—smes dabar laikoma standartine praktika kuriant atsparias dirbtinio intelekto sistemas, naudojant panaÅ¡ius Ä¯rankius, taktikas ir procedÅ«ras, siekiant nustatyti sistemÅ³ rizikas ir iÅ¡bandyti gynÄ—jÅ³ reakcijÄ….

> Dirbtinio intelekto â€raudonosios komandosâ€œ praktika evoliucionavo ir Ä¯gavo platesnÄ™ prasmÄ™: ji ne tik apima saugumo paÅ¾eidÅ¾iamumÅ³ paieÅ¡kÄ…, bet ir kitÅ³ sistemÅ³ gedimÅ³, tokiÅ³ kaip potencialiai Å¾alingo turinio generavimas, tyrimÄ…. Dirbtinio intelekto sistemos kelia naujas rizikas, o â€raudonosios komandosâ€œ veikla yra esminÄ— norint suprasti Å¡ias naujas rizikas, tokias kaip uÅ¾klausÅ³ injekcija ir nepagrÄ¯sto turinio kÅ«rimas. - [Microsoft AI Red Team building future of safer AI](https://www.microsoft.com/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-105485-koreyst)

[![GairÄ—s ir iÅ¡tekliai â€raudonosios komandosâ€œ veiklai](../../../translated_images/13-AI-red-team.642ed54689d7e8a4d83bdf0635768c4fd8aa41ea539d8e3ffe17514aec4b4824.lt.png)]()

Å½emiau pateikiami pagrindiniai Ä¯Å¾valgos, kurios formavo â€Microsoftâ€œ dirbtinio intelekto â€raudonosios komandosâ€œ programÄ….

1. **Platus dirbtinio intelekto â€raudonosios komandosâ€œ veiklos mastas:**
   Dirbtinio intelekto â€raudonosios komandosâ€œ veikla dabar apima tiek saugumo, tiek atsakingo dirbtinio intelekto (RAI) rezultatus. TradiciÅ¡kai â€raudonosios komandosâ€œ veikla buvo orientuota Ä¯ saugumo aspektus, laikant modelÄ¯ kaip vektoriÅ³ (pvz., modelio vagystÄ—). TaÄiau dirbtinio intelekto sistemos sukuria naujus saugumo paÅ¾eidÅ¾iamumus (pvz., uÅ¾klausÅ³ injekcija, uÅ¾krÄ—timas), kuriems reikia skirti ypatingÄ… dÄ—mesÄ¯. Be saugumo, dirbtinio intelekto â€raudonosios komandosâ€œ veikla taip pat tiria teisingumo problemas (pvz., stereotipus) ir Å¾alingÄ… turinÄ¯ (pvz., smurto Å¡lovinimÄ…). Ankstyvas Å¡iÅ³ problemÅ³ nustatymas leidÅ¾ia prioritetizuoti gynybos investicijas.
2. **Kenksmingi ir nekenksmingi gedimai:**
   Dirbtinio intelekto â€raudonosios komandosâ€œ veikla apima gedimus tiek kenksmingu, tiek nekenksmingu poÅ¾iÅ«riu. PavyzdÅ¾iui, testuojant naujÄ… Bing, mes ne tik tiriame, kaip piktybiniai prieÅ¡ininkai gali pakenkti sistemai, bet ir kaip paprasti vartotojai gali susidurti su problematiÅ¡ku ar Å¾alingu turiniu. Skirtingai nuo tradicinÄ—s saugumo â€raudonosios komandosâ€œ veiklos, kuri daugiausia dÄ—mesio skiria piktybiniams veikÄ—jams, dirbtinio intelekto â€raudonosios komandosâ€œ veikla apima platesnÄ¯ asmenybiÅ³ ir galimÅ³ gedimÅ³ spektrÄ….
3. **DinamiÅ¡kas dirbtinio intelekto sistemÅ³ pobÅ«dis:**
   Dirbtinio intelekto programos nuolat keiÄiasi. DideliÅ³ kalbos modeliÅ³ programose kÅ«rÄ—jai prisitaiko prie besikeiÄianÄiÅ³ reikalavimÅ³. NuolatinÄ— â€raudonosios komandosâ€œ veikla uÅ¾tikrina nuolatinÄ¯ budrumÄ… ir prisitaikymÄ… prie besikeiÄianÄiÅ³ rizikÅ³.

Dirbtinio intelekto â€raudonosios komandosâ€œ veikla nÄ—ra viskÄ… apimanti ir turÄ—tÅ³ bÅ«ti laikoma papildoma priemone prie kitÅ³ kontrolÄ—s mechanizmÅ³, tokiÅ³ kaip [vaidmenimis pagrÄ¯sta prieigos kontrolÄ— (RBAC)](https://learn.microsoft.com/azure/ai-services/openai/how-to/role-based-access-control?WT.mc_id=academic-105485-koreyst) ir iÅ¡samÅ«s duomenÅ³ valdymo sprendimai. Ji skirta papildyti saugumo strategijÄ…, orientuotÄ… Ä¯ saugiÅ³ ir atsakingÅ³ dirbtinio intelekto sprendimÅ³ naudojimÄ…, kurie atsiÅ¾velgia Ä¯ privatumÄ… ir saugumÄ…, tuo paÄiu siekiant sumaÅ¾inti Å¡aliÅ¡kumÄ…, Å¾alingÄ… turinÄ¯ ir dezinformacijÄ…, galinÄiÄ… maÅ¾inti vartotojÅ³ pasitikÄ—jimÄ….

Å tai papildomÅ³ skaitymo Å¡altiniÅ³ sÄ…raÅ¡as, kuris padÄ—s geriau suprasti, kaip â€raudonosios komandosâ€œ veikla gali padÄ—ti nustatyti ir sumaÅ¾inti rizikas jÅ«sÅ³ dirbtinio intelekto sistemose:

- [Planuojant â€raudonosios komandosâ€œ veiklÄ… dideliems kalbos modeliams (LLM) ir jÅ³ programoms](https://learn.microsoft.com/azure/ai-services/openai/concepts/red-teaming?WT.mc_id=academic-105485-koreyst)
- [Kas yra â€OpenAI Red Teaming Networkâ€œ?](https://openai.com/blog/red-teaming-network?WT.mc_id=academic-105485-koreyst)
- [Dirbtinio intelekto â€raudonosios komandosâ€œ veikla - pagrindinÄ— praktika kuriant saugesnius ir atsakingesnius dirbtinio intelekto sprendimus](https://rodtrent.substack.com/p/ai-red-teaming?WT.mc_id=academic-105485-koreyst)
- MITRE [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), Å¾iniÅ³ bazÄ— apie taktikas ir technikas, kurias naudoja prieÅ¡ininkai realaus pasaulio atakose prieÅ¡ dirbtinio intelekto sistemas.

## Å½iniÅ³ patikrinimas

Koks galÄ—tÅ³ bÅ«ti geras bÅ«das iÅ¡laikyti duomenÅ³ vientisumÄ… ir uÅ¾kirsti keliÄ… netinkamam naudojimui?

1. TurÄ—ti stipriÄ… vaidmenimis pagrÄ¯stÄ… duomenÅ³ prieigos ir valdymo kontrolÄ™
1. Ä®gyvendinti ir audituoti duomenÅ³ Å¾ymÄ—jimÄ…, kad bÅ«tÅ³ iÅ¡vengta duomenÅ³ neteisingo pateikimo ar netinkamo naudojimo
1. UÅ¾tikrinti, kad jÅ«sÅ³ dirbtinio intelekto infrastruktÅ«ra palaiko turinio filtravimÄ…

A:1, Nors visi trys yra puikios rekomendacijos, uÅ¾tikrinimas, kad tinkamai priskiriate duomenÅ³ prieigos privilegijas vartotojams, labai padÄ—s iÅ¡vengti duomenÅ³ manipuliavimo ir neteisingo pateikimo, naudojant LLM.

## ğŸš€ IÅ¡Å¡Å«kis

SuÅ¾inokite daugiau apie tai, kaip galite [valdyti ir apsaugoti jautriÄ… informacijÄ…](https://learn.microsoft.com/training/paths/purview-protect-govern-ai/?WT.mc_id=academic-105485-koreyst) dirbtinio intelekto amÅ¾iuje.

## Puikus darbas, tÄ™skite mokymÄ…si

BaigÄ™ Å¡iÄ… pamokÄ…, perÅ¾iÅ«rÄ—kite mÅ«sÅ³ [Generatyvaus dirbtinio intelekto mokymosi kolekcijÄ…](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), kad toliau gilintumÄ—te savo Å¾inias apie generatyvÅ³ dirbtinÄ¯ intelektÄ…!

Eikite Ä¯ 14 pamokÄ…, kurioje aptarsime [Generatyvaus dirbtinio intelekto programÅ³ gyvavimo ciklÄ…](../14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst)!

---

**AtsakomybÄ—s apribojimas**:  
Å is dokumentas buvo iÅ¡verstas naudojant AI vertimo paslaugÄ… [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, praÅ¡ome atkreipti dÄ—mesÄ¯, kad automatiniai vertimai gali turÄ—ti klaidÅ³ ar netikslumÅ³. Originalus dokumentas jo gimtÄ…ja kalba turÄ—tÅ³ bÅ«ti laikomas autoritetingu Å¡altiniu. DÄ—l svarbios informacijos rekomenduojama profesionali Å¾mogaus vertimo paslauga. Mes neprisiimame atsakomybÄ—s uÅ¾ nesusipratimus ar neteisingus aiÅ¡kinimus, atsiradusius naudojant Å¡Ä¯ vertimÄ….