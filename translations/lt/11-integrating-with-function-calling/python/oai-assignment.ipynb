{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Įvadas \n",
    "\n",
    "Ši pamoka apims: \n",
    "- Kas yra funkcijos kvietimas ir jo panaudojimo atvejai \n",
    "- Kaip sukurti funkcijos kvietimą naudojant OpenAI \n",
    "- Kaip integruoti funkcijos kvietimą į programą \n",
    "\n",
    "## Mokymosi tikslai \n",
    "\n",
    "Baigę šią pamoką žinosite ir suprasite: \n",
    "\n",
    "- Funkcijos kvietimo naudojimo paskirtį \n",
    "- Kaip nustatyti funkcijos kvietimą naudojant OpenAI paslaugą \n",
    "- Kaip sukurti efektyvius funkcijos kvietimus jūsų programos naudojimo atvejui \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcijų kvietimų supratimas\n",
    "\n",
    "Šiam pamokai norime sukurti funkciją mūsų švietimo startuoliui, leidžiančią vartotojams naudoti pokalbių robotą techninių kursų paieškai. Rekomenduosime kursus, atitinkančius jų įgūdžių lygį, dabartinę pareigybę ir dominančią technologiją.\n",
    "\n",
    "Norėdami tai įgyvendinti, naudosime šių derinį:\n",
    " - `OpenAI`, kad sukurtume vartotojui pokalbių patirtį\n",
    " - `Microsoft Learn Catalog API`, kad padėtume vartotojams rasti kursus pagal jų užklausą\n",
    " - `Function Calling`, kad vartotojo užklausą perduotume funkcijai, kuri atliks API užklausą.\n",
    "\n",
    "Pradėkime nuo to, kodėl iš viso norėtume naudoti funkcijų kvietimą:\n",
    "\n",
    "print(\"Žinutės kitoje užklausoje:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # gauti naują atsakymą iš GPT, kuriame matomas funkcijos atsakymas\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodėl funkcijų kvietimas\n",
    "\n",
    "Jei jau baigėte bet kurį kitą šio kurso pamoką, tikriausiai suprantate didelių kalbos modelių (LLM) naudojimo galią. Tikimės, kad taip pat matote kai kurias jų ribotumas.\n",
    "\n",
    "Funkcijų kvietimas yra OpenAI paslaugos funkcija, skirta spręsti šias problemas:\n",
    "\n",
    "Nenuosekli atsakymų formatavimo:\n",
    "- Prieš funkcijų kvietimą, didelio kalbos modelio atsakymai buvo nestruktūruoti ir nenuoseklūs. Kūrėjams reikėjo rašyti sudėtingą validacijos kodą, kad apdorotų kiekvieną išvesties variaciją.\n",
    "\n",
    "Ribota integracija su išoriniais duomenimis:\n",
    "- Prieš šią funkciją buvo sunku įtraukti duomenis iš kitų programos dalių į pokalbio kontekstą.\n",
    "\n",
    "Standartizuodama atsakymų formatus ir leidžiant sklandžią integraciją su išoriniais duomenimis, funkcijų kvietimas supaprastina kūrimą ir sumažina papildomos validacijos logikos poreikį.\n",
    "\n",
    "Vartotojai negalėjo gauti atsakymų, tokių kaip „Koks yra dabartinis oras Stokholme?“. Tai todėl, kad modeliai buvo apriboti duomenų mokymo laiku.\n",
    "\n",
    "Pažiūrėkime žemiau pateiktą pavyzdį, kuris iliustruoja šią problemą:\n",
    "\n",
    "Tarkime, norime sukurti studentų duomenų bazę, kad galėtume jiems pasiūlyti tinkamą kursą. Žemiau turime du studentų aprašymus, kurie yra labai panašūs pagal turimus duomenis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mes norime tai siųsti LLM, kad jis išanalizuotų duomenis. Tai vėliau gali būti naudojama mūsų programoje, norint siųsti tai į API arba saugoti duomenų bazėje.\n",
    "\n",
    "Sukurkime du identiškus užklausimus, kuriuose nurodome LLM, kokia informacija mus domina:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mes norime tai siųsti LLM, kad jis išskirtų mūsų produktui svarbias dalis. Taigi galime sukurti du identiškus užklausimus, kad nurodytume LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sukūrę šiuos du užklausimus, mes juos išsiųsime LLM naudodami `openai.ChatCompletion`. Užklausimą saugome kintamajame `messages` ir priskiriame vaidmenį `user`. Tai imituoja vartotojo žinutės rašymą pokalbių robotui.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar galime išsiųsti abu užklausimus LLM ir išnagrinėti gautą atsakymą.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nors užklausos yra tos pačios ir aprašymai panašūs, mes galime gauti skirtingus `Grades` savybės formatus.\n",
    "\n",
    "Jei aukščiau pateiktą langelį paleisite kelis kartus, formatas gali būti `3.7` arba `3.7 GPA`.\n",
    "\n",
    "Taip yra todėl, kad LLM priima nestruktūruotus duomenis rašytinės užklausos pavidalu ir taip pat grąžina nestruktūruotus duomenis. Mums reikia turėti struktūruotą formatą, kad žinotume, ko tikėtis saugant ar naudojant šiuos duomenis.\n",
    "\n",
    "Naudodami funkcijų kvietimą galime užtikrinti, kad gausime struktūruotus duomenis atgal. Naudojant funkcijų kvietimą, LLM iš tikrųjų nekviečia ar nevykdo jokių funkcijų. Vietoj to, mes sukuriame struktūrą, kurios LLM turi laikytis savo atsakymuose. Tada naudojame tuos struktūruotus atsakymus, kad žinotume, kurią funkciją vykdyti mūsų programose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funkcijų kvietimo srauto diagrama](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.lt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tada galime paimti tai, kas grąžinama iš funkcijos, ir siųsti tai atgal į LLM. LLM tuomet atsakys natūralia kalba, kad atsakytų į vartotojo užklausą.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naudojimo atvejai funkcijų kvietimams\n",
    "\n",
    "**Išorinių įrankių kvietimas**  \n",
    "Pokalbių robotai puikiai atsako į vartotojų klausimus. Naudodami funkcijų kvietimus, pokalbių robotai gali naudoti vartotojų žinutes tam tikroms užduotims atlikti. Pavyzdžiui, studentas gali paprašyti pokalbių roboto „Išsiųsk el. laišką mano dėstytojui, sakydamas, kad man reikia daugiau pagalbos su šia tema“. Tai gali sukelti funkcijos kvietimą `send_email(to: string, body: string)`.\n",
    "\n",
    "**API arba duomenų bazės užklausų kūrimas**  \n",
    "Vartotojai gali rasti informaciją naudodami natūralią kalbą, kuri paverčiama į suformatuotą užklausą arba API užklausą. Pavyzdys galėtų būti mokytojas, kuris prašo „Kas yra studentai, kurie atliko paskutinį užduotį“, ir tai gali iškviesti funkciją pavadinimu `get_completed(student_name: string, assignment: int, current_status: string)`.\n",
    "\n",
    "**Struktūruotų duomenų kūrimas**  \n",
    "Vartotojai gali paimti teksto bloką arba CSV ir naudoti LLM, kad ištrauktų svarbią informaciją. Pavyzdžiui, studentas gali konvertuoti Vikipedijos straipsnį apie taikos susitarimus, kad sukurtų AI atmintines. Tai galima padaryti naudojant funkciją `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pirmojo funkcijos kvietimo kūrimas\n",
    "\n",
    "Funkcijos kvietimo kūrimo procesas apima 3 pagrindinius žingsnius:\n",
    "1. Iškvietimas Chat Completions API su jūsų funkcijų sąrašu ir vartotojo žinute\n",
    "2. Modelio atsakymo skaitymas, kad būtų atliktas veiksmas, t.y. įvykdyta funkcija arba API kvietimas\n",
    "3. Kitas kvietimas Chat Completions API su jūsų funkcijos atsakymu, kad būtų panaudota ši informacija atsakymui vartotojui sukurti.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funkcijos kvietimo srautas](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.lt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijos kvietimo elementai\n",
    "\n",
    "#### Vartotojo įvestis\n",
    "\n",
    "Pirmasis žingsnis yra sukurti vartotojo žinutę. Tai gali būti dinamiškai priskirta paimant teksto įvesties reikšmę arba galite priskirti reikšmę čia. Jei tai pirmas kartas, kai dirbate su Chat Completions API, turime apibrėžti žinutės `role` ir `content`.\n",
    "\n",
    "`role` gali būti `system` (taisyklių kūrimas), `assistant` (modelis) arba `user` (galutinis vartotojas). Funkcijų kvietimui mes priskirsime `user` ir pateiksime pavyzdinį klausimą.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijų kūrimas.\n",
    "\n",
    "Toliau apibrėšime funkciją ir tos funkcijos parametrus. Čia naudosime tik vieną funkciją, vadinamą `search_courses`, tačiau galite sukurti kelias funkcijas.\n",
    "\n",
    "**Svarbu**: Funkcijos įtraukiamos į sistemos pranešimą LLM ir bus įskaičiuotos į turimų žetonų kiekį.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apibrėžimai** \n",
    "\n",
    "Funkcijos apibrėžimo struktūra turi kelis lygius, kiekvienas su savo savybėmis. Štai išskaidymas įdėtoje struktūroje:\n",
    "\n",
    "**Pagrindinės funkcijos savybės:**\n",
    "\n",
    "`name` - Funkcijos pavadinimas, kurią norime iškviesti. \n",
    "\n",
    "`description` - Tai aprašymas, kaip funkcija veikia. Čia svarbu būti konkrečiam ir aiškiam. \n",
    "\n",
    "`parameters` - Reikšmių ir formato sąrašas, kurį norite, kad modelis pateiktų savo atsakyme. \n",
    "\n",
    "**Parametrų objekto savybės:**\n",
    "\n",
    "`type` - Parametrų objekto duomenų tipas (dažniausiai \"object\")\n",
    "\n",
    "`properties` - Konkretūs reikšmių sąrašai, kuriuos modelis naudos savo atsakyme. \n",
    "\n",
    "**Individualių parametrų savybės:**\n",
    "\n",
    "`name` - Implicitškai apibrėžtas pagal savybės raktą (pvz., \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Šio konkretaus parametro duomenų tipas (pvz., \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Konkretus parametro aprašymas. \n",
    "\n",
    "**Pasirenkamos savybės:**\n",
    "\n",
    "`required` - Masyvas, nurodantis, kurie parametrai yra privalomi, kad funkcijos kvietimas būtų įvykdytas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijos kvietimo atlikimas  \n",
    "Apibrėžus funkciją, dabar turime ją įtraukti į kvietimą Chat Completion API. Tai darome pridėdami `functions` prie užklausos. Šiuo atveju `functions=functions`.  \n",
    "\n",
    "Taip pat yra galimybė nustatyti `function_call` į `auto`. Tai reiškia, kad leisime LLM nuspręsti, kuri funkcija turėtų būti kviečiama pagal vartotojo žinutę, o ne priskirsime ją patys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar pažvelkime į atsakymą ir pamatykime, kaip jis yra suformatuotas:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Matote, kad yra iškviestas funkcijos pavadinimas, o iš vartotojo žinutės LLM sugebėjo rasti duomenis, atitinkančius funkcijos argumentus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Funkcijų kvietimų integravimas į programą. \n",
    "\n",
    "\n",
    "Kai išbandėme suformatuotą atsakymą iš LLM, dabar galime tai integruoti į programą. \n",
    "\n",
    "### Srauto valdymas \n",
    "\n",
    "Norėdami tai integruoti į mūsų programą, atlikime šiuos veiksmus: \n",
    "\n",
    "Pirmiausia atlikime kvietimą OpenAI paslaugoms ir išsaugokime žinutę kintamajame, pavadintame `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar apibrėšime funkciją, kuri kvies Microsoft Learn API, kad gautų kursų sąrašą:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaip geriausia praktika, mes tada patikrinsime, ar modelis nori iškviesti funkciją. Po to sukursime vieną iš galimų funkcijų ir suderinsime ją su kviečiama funkcija.  \n",
    "Tada paimsime funkcijos argumentus ir susiesime juos su argumentais iš LLM.\n",
    "\n",
    "Galiausiai pridėsime funkcijos kvietimo žinutę ir reikšmes, kurias grąžino `search_courses` žinutė. Tai suteikia LLM visą reikalingą informaciją, kad jis galėtų natūralia kalba atsakyti vartotojui.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar mes išsiųsime atnaujintą žinutę į LLM, kad galėtume gauti natūralios kalbos atsakymą, o ne API JSON formato atsakymą.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodo iššūkis \n",
    "\n",
    "Puikus darbas! Norėdami tęsti mokymąsi apie OpenAI funkcijų kvietimą, galite sukurti: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Daugiau funkcijos parametrų, kurie gali padėti besimokantiesiems rasti daugiau kursų. Galimus API parametrus galite rasti čia:  \n",
    " - Sukurkite kitą funkcijos kvietimą, kuris priimtų daugiau informacijos iš besimokančiojo, pavyzdžiui, jų gimtąją kalbą  \n",
    " - Sukurkite klaidų tvarkymą, kai funkcijos kvietimas ir/arba API kvietimas negrąžina tinkamų kursų  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Atsakomybės apribojimas**:  \nŠis dokumentas buvo išverstas naudojant dirbtinio intelekto vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors stengiamės užtikrinti tikslumą, prašome atkreipti dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Svarbiai informacijai rekomenduojamas profesionalus žmogaus vertimas. Mes neatsakome už bet kokius nesusipratimus ar neteisingus aiškinimus, kilusius dėl šio vertimo naudojimo.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T12:08:39+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "lt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}