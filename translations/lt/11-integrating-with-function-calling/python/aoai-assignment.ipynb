{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Įvadas\n",
    "\n",
    "Šioje pamokoje aptarsime:\n",
    "- Kas yra funkcijų kvietimas ir kur jis naudojamas\n",
    "- Kaip sukurti funkcijų kvietimą naudojant Azure OpenAI\n",
    "- Kaip integruoti funkcijų kvietimą į programą\n",
    "\n",
    "## Mokymosi tikslai\n",
    "\n",
    "Baigę šią pamoką, mokėsite ir suprasite:\n",
    "\n",
    "- Kodėl verta naudoti funkcijų kvietimą\n",
    "- Kaip nustatyti funkcijų kvietimą naudojant Azure Open AI paslaugą\n",
    "- Kaip sukurti efektyvius funkcijų kvietimus pagal savo programos poreikius\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suprasti funkcijų iškvietimus\n",
    "\n",
    "Šioje pamokoje kursime funkciją mūsų švietimo startuoliui, kuri leis naudotojams per pokalbių robotą rasti techninius kursus. Rekomenduosime kursus, atitinkančius jų įgūdžių lygį, dabartinį vaidmenį ir dominančias technologijas.\n",
    "\n",
    "Tam įgyvendinti naudosime šiuos komponentus:\n",
    " - `Azure Open AI`, kad sukurtume pokalbio patirtį naudotojui\n",
    " - `Microsoft Learn Catalog API`, kad padėtume naudotojams rasti kursus pagal jų užklausą\n",
    " - `Function Calling`, kad naudotojo užklausą perduotume funkcijai, kuri atliks API užklausą\n",
    "\n",
    "Pradėkime nuo to, kodėl apskritai verta naudoti funkcijų iškvietimą:\n",
    "\n",
    "print(\"Žinutės kitoje užklausoje:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # gauti naują GPT atsakymą, kuriame jis mato funkcijos atsakymą\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kodėl verta naudoti funkcijų iškvietimą\n",
    "\n",
    "Jei jau baigėte bent vieną kitą šio kurso pamoką, tikriausiai suprantate, kokią galią turi dideli kalbos modeliai (LLM). Tikimės, kad pastebėjote ir jų tam tikrus apribojimus.\n",
    "\n",
    "Funkcijų iškvietimas – tai Azure Open AI Service funkcija, padedanti įveikti šiuos apribojimus:\n",
    "1) Nuoseklus atsakymų formatas\n",
    "2) Galimybė naudoti duomenis iš kitų programos šaltinių pokalbio kontekste\n",
    "\n",
    "Prieš atsirandant funkcijų iškvietimui, LLM atsakymai būdavo neapibrėžti ir nenuoseklūs. Kūrėjams tekdavo rašyti sudėtingą validavimo kodą, kad galėtų apdoroti kiekvieną atsakymo variantą.\n",
    "\n",
    "Vartotojai negalėdavo gauti atsakymų, tokių kaip „Koks dabar oras Stokholme?“. Taip yra todėl, kad modeliai buvo apriboti duomenų, kuriais buvo apmokyti, laikotarpiu.\n",
    "\n",
    "Pažvelkime į žemiau pateiktą pavyzdį, kuris iliustruoja šią problemą:\n",
    "\n",
    "Tarkime, norime sukurti studentų duomenų bazę, kad galėtume jiems pasiūlyti tinkamą kursą. Žemiau pateikti du studentų aprašymai, kurie yra labai panašūs pagal juose esančią informaciją.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Norime tai išsiųsti LLM, kad jis apdorotų duomenis. Vėliau tai galėsime panaudoti savo programėlėje, siųsti į API arba saugoti duomenų bazėje.\n",
    "\n",
    "Sukurkime du identiškus užklausos tekstus, kuriais nurodome LLM, kokia informacija mums yra aktuali:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mes norime tai nusiųsti LLM, kad išanalizuotų mūsų produktui svarbias dalis. Taigi galime sukurti du identiškus raginimus, kad nurodytume LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sukūrę šiuos du raginimus, juos išsiųsime LLM naudodami `openai.ChatCompletion`. Raginimą saugome kintamajame `messages` ir priskiriame vaidmenį `user`. Tai daroma tam, kad būtų imituojama vartotojo žinutė, rašoma pokalbių robotui.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nors užklausos yra tokios pačios ir aprašymai panašūs, galime gauti skirtingus `Grades` savybės formatus.\n",
    "\n",
    "Jei aukščiau esantį langelį paleisite kelis kartus, formatas gali būti `3.7` arba `3.7 GPA`.\n",
    "\n",
    "Taip yra todėl, kad LLM priima nestruktūruotus duomenis rašytinės užklausos pavidalu ir taip pat grąžina nestruktūruotus duomenis. Mums reikia turėti struktūruotą formatą, kad žinotume, ko tikėtis saugant ar naudojant šiuos duomenis.\n",
    "\n",
    "Naudodami funkcijų iškvietimą, galime užtikrinti, kad gausime atgal struktūruotus duomenis. Naudojant funkcijų iškvietimą, LLM iš tikrųjų neiškviečia ir nevykdo jokių funkcijų. Vietoj to, mes sukuriame struktūrą, kurios LLM turi laikytis savo atsakymuose. Tuomet tuos struktūruotus atsakymus naudojame tam, kad žinotume, kokią funkciją paleisti savo programose.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funkcijų iškvietimo srauto diagrama](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.lt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijų iškvietimo naudojimo atvejai\n",
    "\n",
    "**Išorinių įrankių kvietimas**\n",
    "Pokalbių robotai puikiai atsako į vartotojų klausimus. Naudojant funkcijų iškvietimą, pokalbių robotai gali panaudoti vartotojo žinutes tam tikroms užduotims atlikti. Pavyzdžiui, studentas gali paprašyti roboto: „Išsiųsk el. laišką mano dėstytojui, kad man reikia daugiau pagalbos su šia tema“. Tokiu atveju gali būti iškviečiama funkcija `send_email(to: string, body: string)`\n",
    "\n",
    "**API ar duomenų bazės užklausų kūrimas**\n",
    "Vartotojai gali ieškoti informacijos natūralia kalba, kuri paverčiama į suformatuotą užklausą ar API prašymą. Pavyzdžiui, mokytojas gali paklausti: „Kas iš studentų atliko paskutinę užduotį?“, ir tai gali iškviesti funkciją `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Struktūruotų duomenų kūrimas**\n",
    "Vartotojai gali paimti teksto bloką ar CSV ir pasitelkti LLM, kad išgautų svarbią informaciją. Pavyzdžiui, studentas gali konvertuoti Vikipedijos straipsnį apie taikos susitarimus ir sukurti AI atminties korteles. Tam galima naudoti funkciją `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Pirmosios funkcijos iškvietimo kūrimas\n",
    "\n",
    "Funkcijos iškvietimo kūrimo procesą sudaro 3 pagrindiniai žingsniai:\n",
    "1. Iškvieskite Chat Completions API su savo funkcijų sąrašu ir vartotojo žinute\n",
    "2. Perskaitykite modelio atsakymą, kad atliktumėte veiksmą, pvz., įvykdytumėte funkciją ar API užklausą\n",
    "3. Dar kartą iškvieskite Chat Completions API su jūsų funkcijos atsakymu, kad galėtumėte panaudoti tą informaciją atsakymui vartotojui sukurti\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funkcijos iškvietimo eiga](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.lt.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijos iškvietimo elementai\n",
    "\n",
    "#### Vartotojo įvestis\n",
    "\n",
    "Pirmas žingsnis – sukurti vartotojo žinutę. Tai galima padaryti dinamiškai, paimant reikšmę iš teksto įvesties lauko, arba galite reikšmę priskirti čia. Jei pirmą kartą dirbate su Chat Completions API, turime apibrėžti žinutės `role` ir `content`.\n",
    "\n",
    "`role` gali būti `system` (taisyklių kūrimas), `assistant` (modelis) arba `user` (galutinis vartotojas). Funkcijų iškvietimui priskirsime `user` ir pateiksime pavyzdinį klausimą.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijų kūrimas.\n",
    "\n",
    "Toliau apibrėšime funkciją ir jos parametrus. Čia naudosime tik vieną funkciją, pavadintą `search_courses`, tačiau galite sukurti ir daugiau funkcijų.\n",
    "\n",
    "**Svarbu**: Funkcijos yra įtraukiamos į sistemos žinutę LLM ir jos bus skaičiuojamos į jūsų turimų žetonų kiekį.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Apibrėžimai**\n",
    "\n",
    "`name` - Funkcijos, kurią norime iškviesti, pavadinimas.\n",
    "\n",
    "`description` - Tai aprašymas, kaip veikia funkcija. Čia svarbu būti konkrečiam ir aiškiam.\n",
    "\n",
    "`parameters` - Vertybių ir formato sąrašas, kurį norite, kad modelis pateiktų savo atsakyme.\n",
    "\n",
    "`type` - Duomenų tipas, kuriame bus saugomos savybės.\n",
    "\n",
    "`properties` - Konkretūs reikšmių sąrašai, kuriuos modelis naudos savo atsakyme.\n",
    "\n",
    "`name` - Savybės pavadinimas, kurį modelis naudos suformatuotame atsakyme.\n",
    "\n",
    "`type` - Šios savybės duomenų tipas.\n",
    "\n",
    "`description` - Konkrečios savybės aprašymas.\n",
    "\n",
    "**Nebūtina**\n",
    "\n",
    "`required` - Būtina savybė, kad funkcijos iškvietimas būtų įvykdytas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcijos iškvietimas\n",
    "Apibrėžus funkciją, dabar turime ją įtraukti į Chat Completion API užklausą. Tai darome pridėdami `functions` prie užklausos. Šiuo atveju `functions=functions`.\n",
    "\n",
    "Taip pat yra galimybė nustatyti `function_call` reikšmę į `auto`. Tai reiškia, kad leisime LLM pačiam nuspręsti, kuri funkcija turėtų būti iškviesta pagal vartotojo žinutę, užuot priskyrę ją patys.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar pažiūrėkime į atsakymą ir jo formatavimą:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Matote, kad funkcijos pavadinimas yra iškviestas, o iš naudotojo žinutės LLM sugebėjo rasti duomenis, tinkamus funkcijos argumentams.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funkcijų iškvietimų integravimas į programą.\n",
    "\n",
    "Ištestavus suformatuotą LLM atsakymą, dabar galime jį integruoti į programą.\n",
    "\n",
    "### Srauto valdymas\n",
    "\n",
    "Norėdami tai integruoti į savo programą, atlikime šiuos veiksmus:\n",
    "\n",
    "Pirmiausia, iškvieskime Open AI paslaugas ir išsaugokime žinutę kintamajame `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dabar apibrėšime funkciją, kuri iškvies Microsoft Learn API, kad gautų kursų sąrašą:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kaip geriausia praktika, mes pirmiausia patikrinsime, ar modelis nori iškviesti funkciją. Po to sukursime vieną iš galimų funkcijų ir pritaikysime ją prie kviečiamos funkcijos.\n",
    "\n",
    "Tada paimsime funkcijos argumentus ir susiesime juos su argumentais iš LLM.\n",
    "\n",
    "Galiausiai, pridėsime funkcijos iškvietimo žinutę ir reikšmes, kurias grąžino `search_courses` žinutė. Tai suteikia LLM visą reikiamą informaciją, kad galėtų atsakyti vartotojui natūralia kalba.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodo iššūkis\n",
    "\n",
    "Puikus darbas! Norėdami toliau gilinti žinias apie Azure Open AI funkcijų iškvietimą, galite sukurti: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Daugiau funkcijos parametrų, kurie galėtų padėti besimokantiesiems rasti daugiau kursų. Galimus API parametrus rasite čia:\n",
    " - Sukurkite dar vieną funkcijos iškvietimą, kuris gautų daugiau informacijos iš besimokančiojo, pavyzdžiui, jo gimtąją kalbą\n",
    " - Sukurkite klaidų valdymą, kai funkcijos ir/arba API iškvietimas negrąžina tinkamų kursų\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Atsakomybės atsisakymas**:  \nŠis dokumentas buvo išverstas naudojant dirbtinio intelekto vertimo paslaugą [Co-op Translator](https://github.com/Azure/co-op-translator). Nors siekiame tikslumo, atkreipkite dėmesį, kad automatiniai vertimai gali turėti klaidų ar netikslumų. Originalus dokumentas jo gimtąja kalba turėtų būti laikomas autoritetingu šaltiniu. Svarbiai informacijai rekomenduojame profesionalų žmogaus vertimą. Mes neprisiimame atsakomybės už bet kokius nesusipratimus ar neteisingą interpretavimą, kilusį naudojantis šiuo vertimu.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:38:26+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "lt"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}