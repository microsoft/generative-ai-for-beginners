{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning Open AI Models\n",
    "\n",
    "Ang notebook na ito ay batay sa kasalukuyang gabay na ibinigay sa [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) dokumentasyon mula sa Open AI.\n",
    "\n",
    "Pinapabuti ng fine-tuning ang pagganap ng mga foundation model para sa iyong aplikasyon sa pamamagitan ng muling pagsasanay nito gamit ang karagdagang data at konteksto na may kaugnayan sa partikular na paggamit o senaryo. Tandaan na ang mga teknik sa prompt engineering tulad ng _few shot learning_ at _retrieval augmented generation_ ay nagpapahintulot sa iyo na pagandahin ang default na prompt gamit ang kaugnay na data upang mapabuti ang kalidad. Gayunpaman, ang mga pamamaraang ito ay limitado ng max token window size ng target na foundation model.\n",
    "\n",
    "Sa fine-tuning, epektibo nating muling sinasanay ang mismong modelo gamit ang kinakailangang data (na nagpapahintulot sa atin na gumamit ng mas maraming halimbawa kaysa sa kasya sa max token window) - at nagde-deploy ng _custom_ na bersyon ng modelo na hindi na kailangan ng mga halimbawa sa oras ng inference. Hindi lamang nito pinapabuti ang bisa ng disenyo ng ating prompt (mayroon tayong mas maraming kalayaan sa paggamit ng token window para sa iba pang bagay) kundi posibleng pinapabuti rin ang ating mga gastos (sa pamamagitan ng pagbabawas ng bilang ng mga token na kailangang ipadala sa modelo sa oras ng inference).\n",
    "\n",
    "Ang fine tuning ay may 4 na hakbang:\n",
    "1. Ihanda ang training data at i-upload ito.\n",
    "1. Patakbuhin ang training job upang makakuha ng fine-tuned na modelo.\n",
    "1. Suriin ang fine-tuned na modelo at ulitin para sa kalidad.\n",
    "1. I-deploy ang fine-tuned na modelo para sa inference kapag nasiyahan na.\n",
    "\n",
    "Tandaan na hindi lahat ng foundation model ay sumusuporta sa fine-tuning - [tingnan ang OpenAI dokumentasyon](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) para sa pinakabagong impormasyon. Maaari ka ring mag-fine-tune ng isang dating fine-tuned na modelo. Sa tutorial na ito, gagamitin natin ang `gpt-35-turbo` bilang target na foundation model para sa fine-tuning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 1.1: Ihanda ang Iyong Dataset\n",
    "\n",
    "Gumawa tayo ng chatbot na tutulong sa iyo na maunawaan ang periodic table ng mga elemento sa pamamagitan ng pagsagot sa mga tanong tungkol sa isang elemento gamit ang isang limerick. Sa _tutorial_ na ito, gagawa lang tayo ng dataset para sanayin ang modelo gamit ang ilang mga halimbawa ng mga tugon na nagpapakita ng inaasahang format ng data. Sa totoong paggamit, kakailanganin mong gumawa ng dataset na may mas maraming mga halimbawa. Maaari ka ring gumamit ng open dataset (para sa iyong domain ng aplikasyon) kung mayroon, at i-reformat ito para magamit sa fine-tuning.\n",
    "\n",
    "Dahil nakatuon tayo sa `gpt-35-turbo` at naghahanap ng isang single-turn na tugon (chat completion), maaari tayong gumawa ng mga halimbawa gamit ang [inirerekomendang format na ito](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) na sumusunod sa mga kinakailangan ng OpenAI chat completion. Kung inaasahan mo ang multi-turn na pag-uusap, gagamitin mo ang [multi-turn example format](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) na may kasamang `weight` parameter upang ipahiwatig kung aling mga mensahe ang dapat gamitin (o hindi) sa proseso ng fine-tuning.\n",
    "\n",
    "Gagamitin natin ang mas simpleng single-turn format para sa tutorial na ito. Ang data ay nasa [jsonl format](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) na may 1 tala bawat linya, bawat isa ay kinakatawan bilang isang JSON-formatted na object. Ipinapakita ng snippet sa ibaba ang 2 tala bilang halimbawa - tingnan ang [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) para sa buong set ng halimbawa (10 halimbawa) na gagamitin natin para sa tutorial ng fine-tuning. **Tandaan:** Bawat tala _dapat_ ay nakasaad sa isang linya lamang (hindi hinati sa maraming linya tulad ng karaniwan sa isang formatted JSON file)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Sa totoong paggamit, kakailanganin mo ng mas malaking set ng mga halimbawa para sa magagandang resulta - ang palitan ay nasa pagitan ng kalidad ng mga tugon at ng oras/gastos para sa fine-tuning. Gumagamit tayo ng maliit na set upang mabilis nating matapos ang fine-tuning at maipakita ang proseso. Tingnan ang [halimbawa mula sa OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) para sa mas kumplikadong tutorial ng fine-tuning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hakbang 1.2 I-upload ang Iyong Dataset\n",
    "\n",
    "I-upload ang data gamit ang Files API [ayon sa paglalarawan dito](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Tandaan na upang mapatakbo ang code na ito, dapat mo munang nagawa ang mga sumusunod na hakbang:\n",
    " - Nai-install ang `openai` Python package (siguraduhing gumagamit ka ng bersyon >=0.28.0 para sa mga pinakabagong tampok)\n",
    " - Na-set ang `OPENAI_API_KEY` environment variable sa iyong OpenAI API key\n",
    "Para matuto pa, tingnan ang [Setup guide](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) na ibinigay para sa kurso.\n",
    "\n",
    "Ngayon, patakbuhin ang code upang gumawa ng file para i-upload mula sa iyong lokal na JSONL file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hakbang 2.1: Lumikha ng Fine-tuning na trabaho gamit ang SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hakbang 2.2: Suriin ang Katayuan ng trabaho\n",
    "\n",
    "Narito ang ilang bagay na maaari mong gawin gamit ang `client.fine_tuning.jobs` API:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Ilista ang huling n fine-tuning na mga trabaho\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Kunin ang mga detalye ng isang partikular na fine-tuning na trabaho\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Kanselahin ang isang fine-tuning na trabaho\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Ilista hanggang n mga kaganapan mula sa trabaho\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Ang unang hakbang ng proseso ay _pag-validate ng training file_ upang matiyak na ang data ay nasa tamang format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hakbang 2.3: Subaybayan ang mga kaganapan upang bantayan ang progreso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 2.4: Tingnan ang status sa OpenAI Dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maaari mo ring tingnan ang status sa pamamagitan ng pagbisita sa website ng OpenAI at pag-explore sa seksyon ng _Fine-tuning_ ng platform. Ipapakita nito sa iyo ang status ng kasalukuyang trabaho, at papayagan ka ring subaybayan ang kasaysayan ng mga naunang pagpapatakbo ng trabaho. Sa screenshot na ito, makikita mo na nabigo ang naunang pagpapatakbo, at nagtagumpay ang pangalawang pagpapatakbo. Bilang konteksto, nangyari ito nang ginamit ng unang pagpapatakbo ang isang JSON file na may maling format ng mga tala - nang maitama ito, matagumpay na natapos ang pangalawang pagpapatakbo at naging available ang modelo para magamit.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/tl/fine-tuned-model-status.563271727bf7bfba.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maaari mo ring tingnan ang mga mensahe ng status at mga sukatan sa pamamagitan ng pag-scroll pababa pa sa visual dashboard tulad ng ipinapakita:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/tl/fine-tuned-messages-panel.4ed0c2da5ea1313b.webp) |  ![Metrics](../../../../../translated_images/tl/fine-tuned-metrics-panel.700d7e4995a65229.webp)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hakbang 3.1: Kunin ang ID at Subukan ang Fine-Tuned na Modelo sa Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Hakbang 3.2: I-load at Subukan ang Fine-Tuned na Modelo sa Playground\n",
    "\n",
    "Maaari mo nang subukan ang fine-tuned na modelo sa dalawang paraan. Una, maaari kang bumisita sa Playground at gamitin ang Models drop-down upang piliin ang iyong bagong fine-tuned na modelo mula sa mga nakalistang opsyon. Ang isa pang opsyon ay gamitin ang \"Playground\" na opsyon na ipinapakita sa Fine-tuning panel (tingnan ang screenshot sa itaas) na naglulunsad ng sumusunod na _comparative_ na view na nagpapakita ng foundation at fine-tuned na mga bersyon ng modelo nang magkatabi para sa mabilisang pagsusuri.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/tl/fine-tuned-playground-compare.56e06f0ad8922016.webp)\n",
    "\n",
    "Punan lamang ang system context na ginamit sa iyong training data at ibigay ang iyong test na tanong. Mapapansin mo na parehong na-update ang magkabilang panig ng magkaparehong context at tanong. Patakbuhin ang paghahambing at makikita mo ang pagkakaiba sa mga output sa pagitan nila. _Pansinin kung paano inilalahad ng fine-tuned na modelo ang tugon sa format na ibinigay mo sa iyong mga halimbawa habang ang foundation na modelo ay sumusunod lamang sa system prompt_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/tl/fine-tuned-playground-launch.5a26495c983c6350.webp)\n",
    "\n",
    "Mapapansin mo rin na ang paghahambing ay nagbibigay din ng bilang ng mga token para sa bawat modelo, at ang oras na ginugol para sa inference. **Ang partikular na halimbawang ito ay isang payak na halimbawa na nilalayong ipakita ang proseso ngunit hindi talaga sumasalamin sa totoong dataset o senaryo**. Maaaring mapansin mo na parehong nagpapakita ang dalawang sample ng parehong bilang ng mga token (magkapareho ang system context at user prompt) kung saan ang fine-tuned na modelo ay mas matagal sa inference (custom na modelo).\n",
    "\n",
    "Sa mga totoong senaryo, hindi ka gagamit ng ganitong simpleng halimbawa, kundi mag-fi-fine-tune laban sa totoong data (hal., katalogo ng produkto para sa customer service) kung saan mas magiging halata ang kalidad ng tugon. Sa _ganitong_ konteksto, ang pagkuha ng katumbas na kalidad ng tugon gamit ang foundation na modelo ay mangangailangan ng mas maraming custom prompt engineering na magpapataas ng paggamit ng token at posibleng ang kaugnay na oras ng pagproseso para sa inference. _Para subukan ito, tingnan ang mga halimbawa ng fine-tuning sa OpenAI Cookbook upang makapagsimula._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Paunawa**:\nAng dokumentong ito ay isinalin gamit ang serbisyong AI na pagsasalin na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamat nagsusumikap kami para sa katumpakan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o di-tumpak na impormasyon. Ang orihinal na dokumento sa orihinal nitong wika ang dapat ituring na pangunahing sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring magmula sa paggamit ng pagsasaling ito.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:10:15+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "tl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}