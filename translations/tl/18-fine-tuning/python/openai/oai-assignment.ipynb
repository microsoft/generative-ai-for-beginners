{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine Tuning ng Open AI Models\n",
    "\n",
    "Ang notebook na ito ay batay sa kasalukuyang gabay na makikita sa [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) na dokumentasyon mula sa Open AI.\n",
    "\n",
    "Pinapahusay ng fine-tuning ang performance ng foundation models para sa iyong aplikasyon sa pamamagitan ng muling pagsasanay gamit ang karagdagang datos at konteksto na may kaugnayan sa partikular na use case o sitwasyon. Tandaan na ang mga teknik tulad ng _few shot learning_ at _retrieval augmented generation_ ay nagbibigay-daan para mapabuti ang default na prompt gamit ang mga kaugnay na datos upang mapataas ang kalidad. Gayunpaman, limitado ang mga pamamaraang ito ng maximum token window size ng napiling foundation model.\n",
    "\n",
    "Sa fine-tuning, muling sinasanay mismo ang model gamit ang kinakailangang datos (na nagbibigay-daan para magamit ang mas maraming halimbawa kaysa sa kasya sa max token window) - at nagde-deploy ng isang _custom_ na bersyon ng model na hindi na kailangang bigyan ng mga halimbawa tuwing inference. Hindi lang nito pinapabuti ang bisa ng ating prompt design (mas malaya tayong magamit ang token window para sa ibang bagay) kundi maaari ring makatipid sa gastos (dahil nababawasan ang bilang ng tokens na kailangang ipadala sa model tuwing inference).\n",
    "\n",
    "Ang fine tuning ay may 4 na hakbang:\n",
    "1. Ihanda ang training data at i-upload ito.\n",
    "1. Patakbuhin ang training job para makakuha ng fine-tuned na model.\n",
    "1. Suriin ang fine-tuned na model at ulitin ang proseso para sa kalidad.\n",
    "1. I-deploy ang fine-tuned na model para sa inference kapag kontento na.\n",
    "\n",
    "Tandaan na hindi lahat ng foundation models ay sumusuporta sa fine-tuning - [tingnan ang dokumentasyon ng OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) para sa pinakabagong impormasyon. Maaari ka ring mag-fine-tune ng model na dati nang na-fine-tune. Sa tutorial na ito, gagamitin natin ang `gpt-35-turbo` bilang target foundation model para sa fine-tuning.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 1.1: Ihanda ang Iyong Dataset\n",
    "\n",
    "Gagawa tayo ng chatbot na tutulong sa iyo na maintindihan ang periodic table ng mga elemento sa pamamagitan ng pagsagot ng mga tanong tungkol sa isang elemento gamit ang isang limerick. Sa _tutorial_ na ito, gagawa lang tayo ng dataset para sanayin ang modelo gamit ang ilang halimbawa ng mga sagot na nagpapakita ng inaasahang format ng data. Sa totoong paggamit, kailangan mong gumawa ng dataset na may mas maraming halimbawa. Maaari ka ring gumamit ng open dataset (para sa iyong application domain) kung meron, at i-reformat ito para magamit sa fine-tuning.\n",
    "\n",
    "Dahil nakatuon tayo sa `gpt-35-turbo` at naghahanap ng isang beses na sagot (chat completion), maaari tayong gumawa ng mga halimbawa gamit ang [inirerekomendang format na ito](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) na sumusunod sa mga kinakailangan ng OpenAI chat completion. Kung inaasahan mong magkakaroon ng usapan na may maraming palitan ng mensahe, gagamitin mo ang [multi-turn example format](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) na may kasamang `weight` parameter para tukuyin kung aling mga mensahe ang dapat (o hindi dapat) gamitin sa fine-tuning process.\n",
    "\n",
    "Gagamitin natin ang mas simpleng single-turn format para sa tutorial na ito. Ang data ay nasa [jsonl format](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) na may 1 record bawat linya, bawat isa ay isang JSON-formatted object. Ang snippet sa ibaba ay nagpapakita ng 2 record bilang halimbawa - tingnan ang [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) para sa buong sample set (10 halimbawa) na gagamitin natin para sa fine-training tutorial. **Tandaan:** Ang bawat record _ay dapat_ nakasulat sa isang linya lang (hindi hinati-hati sa maraming linya gaya ng karaniwan sa formatted JSON file)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Sa totoong paggamit, kailangan mo ng mas malaking set ng mga halimbawa para sa mas magagandang resulta - ang magiging kapalit ay ang kalidad ng mga sagot at ang oras/gastos ng fine-tuning. Maliit lang ang set na ginagamit natin dito para mabilis nating matapos ang fine-tuning at maipakita ang proseso. Tingnan ang [OpenAI Cookbook na halimbawa na ito](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) para sa mas kumplikadong fine-tuning tutorial.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 1.2 I-upload ang Iyong Dataset\n",
    "\n",
    "I-upload ang data gamit ang Files API [gaya ng ipinaliwanag dito](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Tandaan na bago mo mapatakbo ang code na ito, kailangan mo munang gawin ang mga sumusunod na hakbang:\n",
    " - Na-install ang `openai` Python package (siguraduhing ang bersyon ay >=0.28.0 para sa mga pinakabagong features)\n",
    " - Na-set ang `OPENAI_API_KEY` environment variable gamit ang iyong OpenAI API key\n",
    "Para sa karagdagang impormasyon, tingnan ang [Setup guide](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) na ibinigay para sa kursong ito.\n",
    "\n",
    "Ngayon, patakbuhin ang code para gumawa ng file na ia-upload mula sa iyong lokal na JSONL file.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 2.1: Gumawa ng Fine-tuning na trabaho gamit ang SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 2.2: Suriin ang Status ng job\n",
    "\n",
    "Narito ang ilang bagay na maaari mong gawin gamit ang `client.fine_tuning.jobs` API:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Ilista ang huling n fine-tuning jobs\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Kunin ang detalye ng isang partikular na fine-tuning job\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Kanselahin ang isang fine-tuning job\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Ilista hanggang n events mula sa job\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Ang unang hakbang sa proseso ay _beripikahin ang training file_ para matiyak na tama ang format ng data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 2.3: Subaybayan ang mga kaganapan para makita ang progreso\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 2.4: Tingnan ang status sa OpenAI Dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maaari mo ring tingnan ang status sa pamamagitan ng pagbisita sa website ng OpenAI at pag-explore sa seksyong _Fine-tuning_ ng platform. Ipapakita nito sa iyo ang status ng kasalukuyang trabaho, at maaari mo ring subaybayan ang kasaysayan ng mga naunang pagpapatakbo ng trabaho. Sa screenshot na ito, makikita mo na nabigo ang naunang pagpapatakbo, at nagtagumpay ang pangalawang run. Para sa konteksto, nangyari ito nang gumamit ang unang run ng JSON file na may maling format ng mga record – nang maitama ito, matagumpay na natapos ang pangalawang run at naging available na ang modelong magamit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maaari mo ring makita ang mga mensahe ng status at mga sukatan sa pamamagitan ng pag-scroll paibaba sa visual dashboard gaya ng ipinapakita:\n",
    "\n",
    "| Mga Mensahe | Mga Sukatan |\n",
    "|:---|:---|\n",
    "| ![Mga Mensahe](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.tl.png) |  ![Mga Sukatan](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.tl.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 3.1: Kunin ang ID at Subukan ang Fine-Tuned na Modelo sa Code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hakbang 3.2: I-load at Subukan ang Fine-Tuned na Model sa Playground\n",
    "\n",
    "Pwede mo nang subukan ang fine-tuned na model sa dalawang paraan. Una, maaari mong bisitahin ang Playground at gamitin ang Models drop-down para piliin ang bago mong fine-tuned na model mula sa mga opsyon na nakalista. Ang isa pang paraan ay gamitin ang \"Playground\" na opsyon na makikita sa Fine-tuning panel (tingnan ang screenshot sa itaas) na magbubukas ng _comparative_ na view kung saan makikita mo ang foundation at fine-tuned na model na magkatabi para sa mabilisang pagsusuri.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.tl.png)\n",
    "\n",
    "Ilagay lang ang system context na ginamit mo sa training data at ibigay ang iyong test question. Mapapansin mong parehong na-update ang magkabilang panig gamit ang parehong context at tanong. Patakbuhin ang comparison at makikita mo ang pagkakaiba ng outputs ng dalawa. _Pansinin kung paano sinusunod ng fine-tuned na model ang format ng sagot na ibinigay mo sa mga halimbawa, habang ang foundation model ay sumusunod lang sa system prompt_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.tl.png)\n",
    "\n",
    "Mapapansin mo rin na ipinapakita ng comparison ang bilang ng tokens para sa bawat model, pati na rin ang oras na ginugol para sa inference. **Ang partikular na halimbawa na ito ay simple lang at layuning ipakita ang proseso, ngunit hindi talaga sumasalamin sa totoong dataset o sitwasyon.** Maaaring mapansin mong pareho ang bilang ng tokens ng parehong sample (magkapareho ang system context at user prompt) pero mas matagal ang inference ng fine-tuned na model (custom model).\n",
    "\n",
    "Sa totoong mga sitwasyon, hindi ka gagamit ng ganitong simpleng halimbawa, kundi magfi-fine-tune gamit ang totoong data (halimbawa, product catalog para sa customer service) kung saan mas halata ang kalidad ng sagot. Sa _ganung_ konteksto, para makuha ang kaparehong kalidad ng sagot gamit ang foundation model, kakailanganin ng mas masusing prompt engineering na magdudulot ng mas mataas na token usage at posibleng mas matagal na processing time para sa inference. _Para subukan ito, tingnan ang mga fine-tuning na halimbawa sa OpenAI Cookbook bilang panimula._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Paunawa**:  \nAng dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama’t nagsusumikap kami para sa kawastuhan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi eksaktong pagsasalin. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring lumitaw mula sa paggamit ng pagsasaling ito.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:51:44+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "tl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}