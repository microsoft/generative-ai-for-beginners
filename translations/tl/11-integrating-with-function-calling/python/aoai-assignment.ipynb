{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panimula\n",
    "\n",
    "Tatalakayin sa araling ito ang:\n",
    "- Ano ang function calling at mga gamit nito\n",
    "- Paano gumawa ng function call gamit ang Azure OpenAI\n",
    "- Paano isama ang function call sa isang application\n",
    "\n",
    "## Mga Layunin sa Pagkatuto\n",
    "\n",
    "Pagkatapos ng araling ito, malalaman mo kung paano at maiintindihan mo ang:\n",
    "\n",
    "- Layunin ng paggamit ng function calling\n",
    "- Pagsasaayos ng Function Call gamit ang Azure Open AI Service\n",
    "- Pagdidisenyo ng epektibong function calls para sa iyong application at mga gamit nito\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pag-unawa sa Function Calls\n",
    "\n",
    "Para sa leksyong ito, gusto nating gumawa ng isang feature para sa ating education startup na magpapahintulot sa mga user na gumamit ng chatbot para maghanap ng mga technical na kurso. Magrerekomenda tayo ng mga kurso na akma sa kanilang kasanayan, kasalukuyang tungkulin, at teknolohiyang interesado sila.\n",
    "\n",
    "Para magawa ito, gagamit tayo ng kombinasyon ng:\n",
    " - `Azure Open AI` para gumawa ng chat experience para sa user\n",
    " - `Microsoft Learn Catalog API` para tulungan ang mga user na makahanap ng mga kurso base sa kanilang hinihiling\n",
    " - `Function Calling` para kunin ang query ng user at ipadala ito sa isang function para mag-request sa API.\n",
    "\n",
    "Para makapagsimula, tingnan muna natin kung bakit natin gustong gumamit ng function calling:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # kumuha ng bagong response mula sa GPT kung saan makikita nito ang sagot ng function\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bakit Mahalaga ang Function Calling\n",
    "\n",
    "Kung nakatapos ka na ng ibang aralin sa kursong ito, malamang alam mo na kung gaano ka-powerful ang paggamit ng Large Language Models (LLMs). Sana napansin mo rin ang ilang limitasyon ng mga ito.\n",
    "\n",
    "Ang Function Calling ay isang tampok ng Azure Open AI Service na tumutulong malampasan ang mga sumusunod na limitasyon:\n",
    "1) Pare-parehong format ng sagot\n",
    "2) Kakayahang gumamit ng datos mula sa ibang sources ng isang application sa chat context\n",
    "\n",
    "Bago pa man ang function calling, ang mga sagot mula sa LLM ay kadalasang walang istraktura at hindi pare-pareho. Kailangan pang magsulat ng mga developer ng kumplikadong validation code para masigurong kaya nilang hawakan ang bawat uri ng sagot.\n",
    "\n",
    "Hindi rin makakuha ng sagot ang mga user sa mga tanong tulad ng \"Ano ang kasalukuyang lagay ng panahon sa Stockholm?\". Ito ay dahil limitado ang mga modelo sa panahon kung kailan sila na-train.\n",
    "\n",
    "Tingnan natin ang halimbawa sa ibaba na nagpapakita ng problemang ito:\n",
    "\n",
    "Halimbawa, gusto nating gumawa ng database ng impormasyon ng mga estudyante para makapag-suggest tayo ng tamang kurso para sa kanila. Sa ibaba, may dalawang paglalarawan ng mga estudyante na halos magkapareho ang laman ng datos.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gusto naming ipadala ito sa isang LLM para i-parse ang data. Maaari itong magamit sa aming application para ipadala ito sa isang API o i-store sa isang database.\n",
    "\n",
    "Gumawa tayo ng dalawang magkaparehong prompt na magbibigay ng instruksyon sa LLM kung anong impormasyon ang gusto naming makuha:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gusto naming ipadala ito sa isang LLM upang suriin ang mga bahagi na mahalaga sa aming produkto. Kaya maaari kaming gumawa ng dalawang magkaparehong prompt upang bigyan ng tagubilin ang LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagkatapos gawin ang dalawang prompt na ito, ipapadala natin ang mga ito sa LLM gamit ang `openai.ChatCompletion`. Iniimbak natin ang prompt sa variable na `messages` at itinatakda ang role bilang `user`. Ito ay upang tularan ang isang mensahe mula sa isang user na isinusulat sa isang chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kahit na pareho ang mga prompt at magkahawig ang mga deskripsyon, maaari tayong makakuha ng ibaâ€™t ibang format ng property na `Grades`.\n",
    "\n",
    "Kung paulit-ulit mong patakbuhin ang cell sa itaas, maaaring maging `3.7` o `3.7 GPA` ang format.\n",
    "\n",
    "Ito ay dahil ang LLM ay tumatanggap ng hindi istrakturadong datos mula sa isinulat na prompt at nagbabalik din ng hindi istrakturadong datos. Kailangan nating magkaroon ng istrakturadong format para alam natin kung ano ang aasahan kapag iniimbak o ginagamit ang datos na ito.\n",
    "\n",
    "Sa pamamagitan ng paggamit ng functional calling, masisiguro natin na pabalik ay istrakturadong datos ang matatanggap natin. Kapag gumagamit ng function calling, hindi talaga tumatawag o nagpapatakbo ng anumang function ang LLM. Sa halip, gumagawa tayo ng isang istraktura na susundan ng LLM para sa mga sagot nito. Ginagamit natin ang mga istrakturadong sagot na ito para malaman kung anong function ang dapat patakbuhin sa ating mga application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Function Calling Flow Diagram](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.tl.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mga Halimbawa ng Paggamit ng function calls\n",
    "\n",
    "**Pagtawag ng Panlabas na Mga Tool**  \n",
    "Mahusay ang mga chatbot sa pagbibigay ng sagot sa mga tanong ng mga user. Sa pamamagitan ng function calling, magagamit ng mga chatbot ang mga mensahe ng user para tapusin ang ilang gawain. Halimbawa, maaaring sabihin ng isang estudyante sa chatbot na \"Magpadala ng email sa guro ko na kailangan ko pa ng tulong sa subject na ito.\" Maaari nitong gamitin ang function na `send_email(to: string, body: string)`\n",
    "\n",
    "**Paglikha ng API o Database Queries**  \n",
    "Maaaring maghanap ng impormasyon ang mga user gamit ang natural na wika na iko-convert sa isang formatted na query o API request. Halimbawa nito ay isang guro na nagtatanong, \"Sino-sino ang mga estudyanteng nakatapos ng huling assignment?\" na maaaring gumamit ng function na `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Paglikha ng Structured Data**  \n",
    "Maaaring kumuha ang mga user ng isang block ng text o CSV at gamitin ang LLM para kunin ang mahahalagang impormasyon mula rito. Halimbawa, maaaring gawing AI flash cards ng isang estudyante ang isang Wikipedia article tungkol sa mga kasunduan sa kapayapaan. Magagawa ito gamit ang function na `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Paglikha ng Iyong Unang Function Call\n",
    "\n",
    "Ang proseso ng paggawa ng function call ay binubuo ng 3 pangunahing hakbang:\n",
    "1. Tawagin ang Chat Completions API gamit ang listahan ng iyong mga function at isang mensahe mula sa user\n",
    "2. Basahin ang sagot ng modelo upang magsagawa ng aksyon, halimbawa magpatakbo ng function o API Call\n",
    "3. Gumawa ng panibagong tawag sa Chat Completions API gamit ang sagot mula sa iyong function upang magamit ang impormasyong iyon sa paggawa ng sagot para sa user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mga Elemento ng Pagtawag ng Function\n",
    "\n",
    "#### Input ng User\n",
    "\n",
    "Ang unang hakbang ay gumawa ng mensahe mula sa user. Maaari itong itakda nang dynamic gamit ang halaga mula sa isang text input o maaari kang magtakda ng halaga dito. Kung ito ang unang beses mong gagamitin ang Chat Completions API, kailangan nating tukuyin ang `role` at ang `content` ng mensahe.\n",
    "\n",
    "Ang `role` ay maaaring `system` (gumagawa ng mga patakaran), `assistant` (ang modelo), o `user` (ang end-user). Para sa function calling, itatakda natin ito bilang `user` at maglalagay ng halimbawa ng tanong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paglikha ng mga function.\n",
    "\n",
    "Susunod, magde-define tayo ng isang function at ang mga parameter nito. Gagamit tayo dito ng isang function na tinatawag na `search_courses` pero maaari kang gumawa ng maraming function.\n",
    "\n",
    "**Mahalaga**: Kasama ang mga function sa system message na ipinapadala sa LLM at isasama ito sa kabuuang bilang ng tokens na maaari mong gamitin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mga Kahulugan**\n",
    "\n",
    "`name` - Ang pangalan ng function na gusto nating tawagin.\n",
    "\n",
    "`description` - Ito ang paliwanag kung paano gumagana ang function. Dito mahalagang maging tiyak at malinaw.\n",
    "\n",
    "`parameters` - Isang listahan ng mga halaga at format na gusto mong ilabas ng model sa sagot nito.\n",
    "\n",
    "`type` - Ang uri ng data kung saan itatago ang mga properties.\n",
    "\n",
    "`properties` - Listahan ng mga partikular na halaga na gagamitin ng model para sa sagot nito.\n",
    "\n",
    "`name` - Ang pangalan ng property na gagamitin ng model sa naka-format nitong sagot.\n",
    "\n",
    "`type` - Ang uri ng data ng property na ito.\n",
    "\n",
    "`description` - Paliwanag ng partikular na property.\n",
    "\n",
    "**Opsyonal**\n",
    "\n",
    "`required` - kinakailangang property para makumpleto ang function call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paggawa ng function call\n",
    "Pagkatapos magtakda ng function, kailangan na natin itong isama sa pagtawag sa Chat Completion API. Ginagawa natin ito sa pamamagitan ng pagdagdag ng `functions` sa request. Sa kasong ito, `functions=functions`.\n",
    "\n",
    "Mayroon ding opsyon na itakda ang `function_call` sa `auto`. Ibig sabihin nito, hahayaan natin ang LLM na pumili kung aling function ang tatawagin base sa mensahe ng user, sa halip na tayo mismo ang magtakda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngayon, tingnan natin ang tugon at kung paano ito naka-format:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Makikita mo na tinawag ang pangalan ng function at mula sa mensahe ng user, nakuha ng LLM ang mga datos na kailangan para mapunan ang arguments ng function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pagsasama ng Function Calls sa isang Aplikasyon.\n",
    "\n",
    "Matapos nating masubukan ang na-format na sagot mula sa LLM, maaari na natin itong isama sa isang aplikasyon.\n",
    "\n",
    "### Pamamahala ng Daloy\n",
    "\n",
    "Para maisama ito sa ating aplikasyon, sundin natin ang mga hakbang na ito:\n",
    "\n",
    "Una, gawin natin ang tawag sa Open AI services at itago ang mensahe sa isang variable na tinatawag na `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngayon ay itatala natin ang function na tatawag sa Microsoft Learn API upang makuha ang listahan ng mga kurso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilang isang pinakamainam na gawain, titignan muna natin kung gusto ng modelo na tumawag ng isang function. Pagkatapos nito, gagawa tayo ng isa sa mga available na function at itutugma ito sa function na tinatawag.  \n",
    "Pagkatapos, kukunin natin ang mga argumento ng function at itutugma sa mga argumento mula sa LLM.\n",
    "\n",
    "Sa huli, idadagdag natin ang mensahe ng function call at ang mga halagang ibinalik ng `search_courses` na mensahe. Bibigyan nito ang LLM ng lahat ng impormasyong kailangan nito para\n",
    "tumugon sa user gamit ang natural na wika.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamon sa Pag-code\n",
    "\n",
    "Magaling! Para ipagpatuloy ang iyong pagkatuto tungkol sa Azure Open AI Function Calling, maaari mong subukan ang: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Magdagdag ng mas maraming parameter sa function na makakatulong sa mga mag-aaral na makahanap ng mas maraming kurso. Makikita mo ang mga available na API parameter dito:\n",
    " - Gumawa ng isa pang function call na kumukuha ng karagdagang impormasyon mula sa mag-aaral tulad ng kanilang katutubong wika\n",
    " - Gumawa ng error handling kapag ang function call at/o API call ay hindi nagbalik ng angkop na mga kurso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Paunawa**:  \nAng dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagamaâ€™t nagsusumikap kami para sa kawastuhan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi eksaktong pagsasalin. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring lumitaw mula sa paggamit ng pagsasaling ito.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:25:44+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "tl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}