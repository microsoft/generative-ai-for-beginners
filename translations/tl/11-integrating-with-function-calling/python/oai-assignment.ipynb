{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Panimula\n",
    "\n",
    "Tatalakayin sa araling ito ang:\n",
    "- Ano ang function calling at mga gamit nito\n",
    "- Paano gumawa ng function call gamit ang OpenAI\n",
    "- Paano isama ang function call sa isang application\n",
    "\n",
    "## Mga Layunin sa Pagkatuto\n",
    "\n",
    "Pagkatapos ng araling ito, malalaman mo kung paano at maiintindihan mo ang:\n",
    "\n",
    "- Layunin ng paggamit ng function calling\n",
    "- Pagsasaayos ng Function Call gamit ang OpenAI Service\n",
    "- Pagdidisenyo ng epektibong function calls para sa gamit ng iyong application\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pag-unawa sa Function Calls\n",
    "\n",
    "Para sa araling ito, gusto nating bumuo ng isang tampok para sa ating education startup na nagpapahintulot sa mga user na gumamit ng chatbot upang makahanap ng mga technical na kurso. Magrerekomenda tayo ng mga kurso na akma sa kanilang antas ng kasanayan, kasalukuyang tungkulin, at teknolohiyang interesado sila.\n",
    "\n",
    "Para magawa ito, gagamit tayo ng kumbinasyon ng:\n",
    " - `OpenAI` para lumikha ng chat experience para sa user\n",
    " - `Microsoft Learn Catalog API` para tulungan ang mga user na makahanap ng mga kurso base sa kanilang hinihiling\n",
    " - `Function Calling` para kunin ang query ng user at ipadala ito sa isang function upang gawin ang API request.\n",
    "\n",
    "Para magsimula, tingnan muna natin kung bakit natin gustong gumamit ng function calling:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # kumuha ng bagong response mula sa GPT kung saan makikita nito ang function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bakit Mahalaga ang Function Calling\n",
    "\n",
    "Kung nakatapos ka na ng ibang aralin sa kursong ito, malamang ay naiintindihan mo na ang lakas ng paggamit ng Large Language Models (LLMs). Sana napansin mo rin ang ilang limitasyon ng mga ito.\n",
    "\n",
    "Ang Function Calling ay isang tampok ng OpenAI Service na nilikha para tugunan ang mga sumusunod na hamon:\n",
    "\n",
    "Hindi Pare-parehong Pormat ng Sagot:\n",
    "- Bago ang function calling, ang mga sagot mula sa large language model ay walang istraktura at hindi pare-pareho. Kailangan pang magsulat ng kumplikadong validation code ang mga developer para lang ma-handle ang bawat pagkakaiba sa output.\n",
    "\n",
    "Limitadong Integrasyon sa Panlabas na Data:\n",
    "- Bago lumabas ang tampok na ito, mahirap isama ang data mula sa ibang bahagi ng application papunta sa chat context.\n",
    "\n",
    "Sa pamamagitan ng pag-standardize ng pormat ng sagot at pagpapadali ng integrasyon sa panlabas na data, pinapadali ng function calling ang development at binabawasan ang pangangailangan para sa dagdag na validation logic.\n",
    "\n",
    "Hindi makakuha ng sagot ang mga user tulad ng \"Ano ang kasalukuyang lagay ng panahon sa Stockholm?\". Ito ay dahil limitado ang mga modelo sa panahon kung kailan sila na-train.\n",
    "\n",
    "Tingnan natin ang halimbawa sa ibaba na nagpapakita ng problemang ito:\n",
    "\n",
    "Halimbawa, gusto nating gumawa ng database ng impormasyon ng mga estudyante para makapag-suggest tayo ng tamang kurso para sa kanila. Sa ibaba, may dalawang paglalarawan ng mga estudyante na halos magkapareho ang laman ng data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gusto naming ipadala ito sa isang LLM para i-parse ang data. Maaari itong magamit sa aming application para ipadala ito sa isang API o i-store sa isang database.\n",
    "\n",
    "Gumawa tayo ng dalawang magkaparehong prompt na magbibigay ng instruksyon sa LLM kung anong impormasyon ang gusto naming makuha:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gusto naming ipadala ito sa isang LLM upang suriin ang mga bahagi na mahalaga sa aming produkto. Kaya maaari kaming gumawa ng dalawang magkaparehong prompt upang bigyan ng tagubilin ang LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pagkatapos gawin ang dalawang prompt na ito, ipapadala natin ang mga ito sa LLM gamit ang `openai.ChatCompletion`. Iniimbak natin ang prompt sa variable na `messages` at itinatakda ang role bilang `user`. Ito ay upang tularan ang isang mensahe mula sa isang user na isinusulat sa isang chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kahit na pareho ang mga prompt at magkahawig ang mga deskripsyon, maaari tayong makakuha ng ibaâ€™t ibang format ng property na `Grades`.\n",
    "\n",
    "Kung paulit-ulit mong patakbuhin ang cell sa itaas, maaaring maging `3.7` o `3.7 GPA` ang format.\n",
    "\n",
    "Ito ay dahil ang LLM ay tumatanggap ng hindi istrakturadong datos mula sa isinulat na prompt at nagbabalik din ng hindi istrakturadong datos. Kailangan nating magkaroon ng istrakturadong format para alam natin kung ano ang aasahan kapag iniimbak o ginagamit ang datos na ito.\n",
    "\n",
    "Sa pamamagitan ng paggamit ng functional calling, masisiguro nating pabalik ay istrakturadong datos. Kapag gumagamit ng function calling, hindi talaga tumatawag o nagpapatakbo ng anumang function ang LLM. Sa halip, gumagawa tayo ng isang istraktura na susundan ng LLM para sa mga sagot nito. Ginagamit natin ang mga istrakturadong sagot na ito para malaman kung anong function ang dapat patakbuhin sa ating mga application.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Function Calling Flow Diagram](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.tl.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mga Halimbawa ng Paggamit ng function calls\n",
    "\n",
    "**Pagtawag ng Panlabas na Mga Tool**  \n",
    "Mahusay ang mga chatbot sa pagbibigay ng sagot sa mga tanong ng mga user. Sa pamamagitan ng function calling, maaaring gamitin ng mga chatbot ang mga mensahe ng user para tapusin ang ilang gawain. Halimbawa, maaaring sabihin ng isang estudyante sa chatbot na \"Magpadala ng email sa guro ko na kailangan ko pa ng tulong sa paksang ito.\" Maaari nitong tawagin ang function na `send_email(to: string, body: string)`\n",
    "\n",
    "**Paglikha ng API o Database Queries**  \n",
    "Maaaring makahanap ng impormasyon ang mga user gamit ang natural na wika na iko-convert sa isang formatted na query o API request. Halimbawa nito ay isang guro na nagtatanong, \"Sino-sino ang mga estudyanteng nakatapos ng huling takdang-aralin?\" na maaaring tumawag sa function na `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Paglikha ng Structured Data**  \n",
    "Maaaring kumuha ang mga user ng isang block ng teksto o CSV at gamitin ang LLM para kunin ang mahahalagang impormasyon mula rito. Halimbawa, maaaring gawing AI flash cards ng isang estudyante ang isang Wikipedia article tungkol sa mga kasunduan sa kapayapaan. Magagawa ito gamit ang function na `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Paglikha ng Iyong Unang Function Call\n",
    "\n",
    "Ang proseso ng paggawa ng function call ay binubuo ng 3 pangunahing hakbang:\n",
    "1. Tawagin ang Chat Completions API gamit ang listahan ng iyong mga function at isang mensahe mula sa user\n",
    "2. Basahin ang sagot ng modelo upang magsagawa ng aksyon, halimbawa magpatakbo ng function o API Call\n",
    "3. Gumawa ng panibagong tawag sa Chat Completions API gamit ang sagot mula sa iyong function upang magamit ang impormasyong iyon sa paggawa ng sagot para sa user.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mga Elemento ng Pagtawag ng Function\n",
    "\n",
    "#### Input ng User\n",
    "\n",
    "Ang unang hakbang ay gumawa ng mensahe mula sa user. Maaari itong itakda nang dynamic sa pamamagitan ng pagkuha ng halaga mula sa isang text input o maaari kang magtalaga ng halaga dito. Kung ito ang unang beses mong gagamitin ang Chat Completions API, kailangan nating tukuyin ang `role` at ang `content` ng mensahe.\n",
    "\n",
    "Ang `role` ay maaaring `system` (gumagawa ng mga patakaran), `assistant` (ang modelo), o `user` (ang end-user). Para sa function calling, itatakda natin ito bilang `user` at maglalagay ng halimbawa ng tanong.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paglikha ng mga function.\n",
    "\n",
    "Susunod, magde-define tayo ng function at ang mga parameter nito. Isang function lang ang gagamitin natin dito na tinatawag na `search_courses` pero maaari kang gumawa ng maraming function.\n",
    "\n",
    "**Mahalaga** : Ang mga function ay isinasama sa system message para sa LLM at kasama ito sa bilang ng mga token na maaari mong gamitin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Mga Kahulugan**\n",
    "\n",
    "Ang estruktura ng function definition ay may ilang antas, bawat isa ay may sariling mga katangian. Narito ang paliwanag ng nested na estruktura:\n",
    "\n",
    "**Mga Katangian ng Function sa Pinakamataas na Antas:**\n",
    "\n",
    "`name` -  Pangalan ng function na nais nating tawagin.\n",
    "\n",
    "`description` - Ito ang paliwanag kung paano gumagana ang function. Mahalaga dito na maging tiyak at malinaw.\n",
    "\n",
    "`parameters` - Isang listahan ng mga halaga at format na gusto mong ilabas ng model sa sagot nito.\n",
    "\n",
    "**Mga Katangian ng Parameters Object:**\n",
    "\n",
    "`type` -  Uri ng data ng parameters object (karaniwan ay \"object\")\n",
    "\n",
    "`properties` - Listahan ng mga partikular na halaga na gagamitin ng model para sa sagot nito\n",
    "\n",
    "**Mga Katangian ng Bawat Indibidwal na Parameter:**\n",
    "\n",
    "`name` - Implicit na tinutukoy ng property key (hal., \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Uri ng data ng partikular na parameter na ito (hal., \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Paliwanag ng partikular na parameter\n",
    "\n",
    "**Mga Opsyonal na Katangian:**\n",
    "\n",
    "`required` - Isang array na naglalaman kung aling mga parameter ang kinakailangan para makumpleto ang function call\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paggawa ng function call\n",
    "Pagkatapos magtakda ng function, kailangan na natin itong isama sa pagtawag sa Chat Completion API. Ginagawa natin ito sa pamamagitan ng pagdagdag ng `functions` sa request. Sa kasong ito, `functions=functions`.\n",
    "\n",
    "Mayroon ding opsyon na itakda ang `function_call` sa `auto`. Ibig sabihin nito, hahayaan natin ang LLM na pumili kung aling function ang tatawagin base sa mensahe ng user, sa halip na tayo mismo ang magtakda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngayon, tingnan natin ang tugon at kung paano ito naka-format:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Makikita mo na tinawag ang pangalan ng function at mula sa mensahe ng user, nakuha ng LLM ang mga datos na kailangan para mapunan ang arguments ng function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pagsasama ng Function Calls sa isang Aplikasyon.\n",
    "\n",
    "Matapos nating subukan ang na-format na tugon mula sa LLM, maaari na natin itong isama sa isang aplikasyon.\n",
    "\n",
    "### Pamamahala ng daloy\n",
    "\n",
    "Para maisama ito sa ating aplikasyon, sundin natin ang mga sumusunod na hakbang:\n",
    "\n",
    "Una, gawin natin ang tawag sa OpenAI services at i-save ang mensahe sa isang variable na tinatawag na `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngayon ay itatala natin ang function na tatawag sa Microsoft Learn API upang makuha ang listahan ng mga kurso:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bilang pinakamainam na gawain, titignan muna natin kung gusto ng modelo na tumawag ng isang function. Pagkatapos nito, gagawa tayo ng isa sa mga available na function at itutugma ito sa function na tinatawag.  \n",
    "Pagkatapos, kukunin natin ang mga argumento ng function at itutugma ang mga ito sa mga argumento mula sa LLM.\n",
    "\n",
    "Sa huli, idadagdag natin ang mensahe ng pagtawag ng function at ang mga halagang ibinalik ng `search_courses` na mensahe. Bibigyan nito ang LLM ng lahat ng impormasyong kailangan nito para\n",
    "tumugon sa user gamit ang natural na wika.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hamon sa Pag-cocode\n",
    "\n",
    "Magaling! Para ipagpatuloy ang iyong pagkatuto tungkol sa OpenAI Function Calling, maaari kang gumawa ng: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Mas maraming parameter ng function na makakatulong sa mga nag-aaral na makahanap ng mas maraming kurso. Makikita mo ang mga available na API parameter dito:\n",
    " - Gumawa ng isa pang function call na kumukuha ng karagdagang impormasyon mula sa nag-aaral tulad ng kanilang katutubong wika\n",
    " - Gumawa ng error handling kapag ang function call at/o API call ay hindi nagbalik ng angkop na mga kurso\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Paunawa**:  \nAng dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagaman nagsusumikap kami para sa kawastuhan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi eksaktong pagsasalin. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring lumitaw mula sa paggamit ng pagsasaling ito.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:14:40+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "tl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}