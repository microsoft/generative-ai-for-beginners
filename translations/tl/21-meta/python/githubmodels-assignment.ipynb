{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pagbuo Gamit ang Meta Family Models\n",
    "\n",
    "## Panimula\n",
    "\n",
    "Sasaklawin ng araling ito ang:\n",
    "\n",
    "- Pag-explore sa dalawang pangunahing modelo ng Meta family - Llama 3.1 at Llama 3.2\n",
    "- Pag-unawa sa mga gamit at sitwasyon para sa bawat modelo\n",
    "- Halimbawa ng code para ipakita ang natatanging katangian ng bawat modelo\n",
    "\n",
    "## Ang Meta Family ng mga Modelo\n",
    "\n",
    "Sa araling ito, tatalakayin natin ang 2 modelo mula sa Meta family o \"Llama Herd\" - Llama 3.1 at Llama 3.2\n",
    "\n",
    "Ang mga modelong ito ay may iba’t ibang variant at makukuha sa Github Model marketplace. Narito ang karagdagang detalye tungkol sa paggamit ng Github Models para [mag-prototype gamit ang AI models](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "Mga Variant ng Modelo:\n",
    "- Llama 3.1 - 70B Instruct\n",
    "- Llama 3.1 - 405B Instruct\n",
    "- Llama 3.2 - 11B Vision Instruct\n",
    "- Llama 3.2 - 90B Vision Instruct\n",
    "\n",
    "*Tandaan: Ang Llama 3 ay available din sa Github Models ngunit hindi ito tatalakayin sa araling ito*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "Sa 405 Bilyong Parameter, kabilang ang Llama 3.1 sa kategorya ng open source na LLM.\n",
    "\n",
    "Ang mode na ito ay isang pag-upgrade mula sa naunang release na Llama 3 sa pamamagitan ng pag-aalok ng:\n",
    "\n",
    "- Mas malaking context window - 128k tokens kumpara sa 8k tokens\n",
    "- Mas mataas na Max Output Tokens - 4096 kumpara sa 2048\n",
    "- Mas mahusay na Multilingual Support - dahil sa pagdami ng training tokens\n",
    "\n",
    "Dahil dito, kayang hawakan ng Llama 3.1 ang mas komplikadong mga use case kapag gumagawa ng GenAI applications kabilang ang:\n",
    "- Native Function Calling - kakayahang tumawag ng mga external na tool at function sa labas ng LLM workflow\n",
    "- Mas mahusay na RAG Performance - dahil sa mas mataas na context window\n",
    "- Synthetic Data Generation - kakayahang gumawa ng epektibong data para sa mga gawain tulad ng fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Function Calling\n",
    "\n",
    "Ang Llama 3.1 ay mas pinahusay para maging mas epektibo sa pagtawag ng mga function o tool. Mayroon din itong dalawang built-in na tool na kayang tukuyin ng modelo kung kailan dapat gamitin, depende sa prompt ng user. Ang mga tool na ito ay:\n",
    "\n",
    "- **Brave Search** - Puwedeng gamitin para makakuha ng pinakabagong impormasyon gaya ng lagay ng panahon sa pamamagitan ng web search\n",
    "- **Wolfram Alpha** - Puwedeng gamitin para sa mas komplikadong kalkulasyon sa matematika kaya hindi mo na kailangang gumawa ng sarili mong mga function.\n",
    "\n",
    "Puwede ka ring gumawa ng sarili mong custom na tool na pwedeng tawagin ng LLM.\n",
    "\n",
    "Sa code example sa ibaba:\n",
    "\n",
    "- Ipinapakita kung paano ideklara ang mga available na tool (brave_search, wolfram_alpha) sa system prompt.\n",
    "- Magpapadala ng user prompt na nagtatanong tungkol sa lagay ng panahon sa isang partikular na lungsod.\n",
    "- Sasagot ang LLM gamit ang tool call papunta sa Brave Search tool na ganito ang itsura `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`\n",
    "\n",
    "*Note: Sa example na ito, tool call lang ang ginagawa. Kung gusto mong makuha ang resulta, kailangan mong gumawa ng libreng account sa Brave API page at ideklara mismo ang function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2\n",
    "\n",
    "Kahit isa itong LLM, isa sa mga limitasyon ng Llama 3.1 ay ang kakulangan sa multimodality. Ibig sabihin, hindi ito kayang tumanggap ng iba’t ibang uri ng input gaya ng mga larawan bilang prompt at magbigay ng sagot. Isa ito sa mga pangunahing tampok ng Llama 3.2. Kasama rin sa mga tampok na ito ang:\n",
    "\n",
    "- Multimodality – may kakayahang suriin ang parehong text at image prompts\n",
    "- Maliit hanggang katamtamang laki ng mga variant (11B at 90B) – nagbibigay ito ng flexible na opsyon para sa deployment,\n",
    "- Mga variant na text-only (1B at 3B) – nagbibigay-daan ito para magamit ang model sa edge / mobile devices at maghatid ng mababang latency\n",
    "\n",
    "Ang suporta sa multimodal ay malaking hakbang sa mundo ng open source na mga modelo. Sa halimbawa ng code sa ibaba, parehong larawan at text prompt ang ginagamit para makakuha ng pagsusuri ng larawan mula sa Llama 3.2 90B.\n",
    "\n",
    "### Multimodal na Suporta gamit ang Llama 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindi dito nagtatapos ang pagkatuto, ipagpatuloy ang Paglalakbay\n",
    "\n",
    "Pagkatapos mong matapos ang araling ito, bisitahin ang aming [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para patuloy mong mapalawak ang iyong kaalaman sa Generative AI!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Paunawa**:  \nAng dokumentong ito ay isinalin gamit ang AI translation service na [Co-op Translator](https://github.com/Azure/co-op-translator). Bagama’t nagsusumikap kami para sa kawastuhan, pakatandaan na ang mga awtomatikong pagsasalin ay maaaring maglaman ng mga pagkakamali o hindi eksaktong pagsasalin. Ang orihinal na dokumento sa kanyang katutubong wika ang dapat ituring na opisyal na sanggunian. Para sa mahalagang impormasyon, inirerekomenda ang propesyonal na pagsasalin ng tao. Hindi kami mananagot sa anumang hindi pagkakaunawaan o maling interpretasyon na maaaring idulot ng paggamit ng pagsasaling ito.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:46:56+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "tl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}