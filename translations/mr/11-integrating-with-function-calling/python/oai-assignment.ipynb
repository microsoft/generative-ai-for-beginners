{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिचय\n",
    "\n",
    "या धड्यात आपण शिकणार आहोत:\n",
    "- फंक्शन कॉलिंग म्हणजे काय आणि त्याचे उपयोग\n",
    "- OpenAI वापरून फंक्शन कॉल कसा तयार करायचा\n",
    "- फंक्शन कॉल आपल्या ॲप्लिकेशनमध्ये कसा समाविष्ट करायचा\n",
    "\n",
    "## शिकण्याची उद्दिष्टे\n",
    "\n",
    "हे धडे पूर्ण केल्यानंतर तुम्हाला खालील गोष्टी समजतील आणि करता येतील:\n",
    "\n",
    "- फंक्शन कॉलिंगचा उपयोग का करावा हे समजेल\n",
    "- OpenAI सेवा वापरून फंक्शन कॉल सेटअप करणे\n",
    "- आपल्या ॲप्लिकेशनच्या गरजेनुसार प्रभावी फंक्शन कॉल डिझाइन करणे\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## फंक्शन कॉल्स समजून घेणे\n",
    "\n",
    "या धड्यासाठी, आपल्याला आपल्या एज्युकेशन स्टार्टअपसाठी अशी सुविधा तयार करायची आहे ज्यामुळे वापरकर्ते चॅटबॉट वापरून तांत्रिक कोर्सेस शोधू शकतील. आपण त्यांच्या कौशल्य पातळी, सध्याची भूमिका आणि आवडत्या तंत्रज्ञानानुसार कोर्सेस सुचवणार आहोत.\n",
    "\n",
    "हे पूर्ण करण्यासाठी आपण खालील गोष्टींचा एकत्रित वापर करू:\n",
    " - `OpenAI` वापरून वापरकर्त्यासाठी चॅट अनुभव तयार करणे\n",
    " - `Microsoft Learn Catalog API` वापरून वापरकर्त्याच्या विनंतीनुसार कोर्सेस शोधण्यात मदत करणे\n",
    " - `Function Calling` वापरून वापरकर्त्याची क्वेरी घेऊन ती API विनंतीसाठी फंक्शनला पाठवणे\n",
    "\n",
    "सुरुवात करण्यासाठी, आपण प्रथम फंक्शन कॉलिंग का वापरायचे हे पाहूया:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT कडून नवीन प्रतिसाद मिळवा जिथे त्याला फंक्शनचा प्रतिसाद दिसू शकतो\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलिंग का?\n",
    "\n",
    "जर तुम्ही या कोर्समधील इतर कोणताही धडा पूर्ण केला असेल, तर तुम्हाला मोठ्या भाषा मॉडेल्स (LLMs) वापरण्याची ताकद समजली असेल. आशा आहे की तुम्हाला त्यांची काही मर्यादाही लक्षात आल्या असतील.\n",
    "\n",
    "फंक्शन कॉलिंग ही OpenAI Service ची एक वैशिष्ट्य आहे जी खालील अडचणी सोडवण्यासाठी डिझाइन करण्यात आली आहे:\n",
    "\n",
    "असंगत प्रतिसाद फॉरमॅटिंग:\n",
    "- फंक्शन कॉलिंगच्या आधी, मोठ्या भाषा मॉडेलकडून मिळणारे प्रतिसाद असंघटित आणि असंगत असायचे. प्रत्येक वेळी वेगळ्या स्वरूपात येणारे आउटपुट हाताळण्यासाठी डेव्हलपर्सना क्लिष्ट व्हॅलिडेशन कोड लिहावा लागायचा.\n",
    "\n",
    "बाह्य डेटासोबत मर्यादित एकत्रीकरण:\n",
    "- या वैशिष्ट्यापूर्वी, अ‍ॅप्लिकेशनच्या इतर भागातील डेटा चॅट संदर्भात समाविष्ट करणे कठीण होते.\n",
    "\n",
    "प्रतिसादांचे स्वरूप एकसंध करून आणि बाह्य डेटासोबत सहज एकत्रीकरण शक्य करून, फंक्शन कॉलिंग डेव्हलपमेंट सुलभ करते आणि अतिरिक्त व्हॅलिडेशन लॉजिकची गरज कमी करते.\n",
    "\n",
    "वापरकर्त्यांना \"स्टॉकहोममधील सध्याचे हवामान काय आहे?\" असे प्रश्न विचारता येत नव्हते. कारण मॉडेल्सना केवळ त्यांच्या प्रशिक्षणाच्या वेळेपर्यंतच माहिती मर्यादित होती.\n",
    "\n",
    "चला, खालील उदाहरण पाहूया जे ही समस्या स्पष्ट करते:\n",
    "\n",
    "समजा, आपण विद्यार्थ्यांचा डेटा असलेला डेटाबेस तयार करू इच्छितो, जेणेकरून त्यांना योग्य कोर्स सुचवता येईल. खाली दोन विद्यार्थ्यांची वर्णने दिली आहेत, ज्यामधील माहिती जवळजवळ सारखीच आहे.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आपण हे LLM कडे पाठवू इच्छितो जेणेकरून ते डेटा पार्स करू शकेल. नंतर हे आपल्या अनुप्रयोगात API कडे पाठवण्यासाठी किंवा डेटाबेसमध्ये साठवण्यासाठी वापरता येईल.\n",
    "\n",
    "चला दोन एकसारखे प्रॉम्प्ट तयार करूया, ज्यात आपण LLM ला कोणती माहिती आवश्यक आहे हे सांगू:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आम्ही हे आमच्या उत्पादनासाठी महत्त्वाचे असलेले भाग पार्स करण्यासाठी LLM कडे पाठवू इच्छितो. त्यामुळे आपण LLM ला सूचना देण्यासाठी दोन एकसारखे प्रॉम्प्ट तयार करू शकतो:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ही दोन प्रॉम्प्ट तयार केल्यानंतर, आपण त्या LLM कडे `openai.ChatCompletion` वापरून पाठवू. आपण प्रॉम्प्ट `messages` या व्हेरिएबलमध्ये साठवतो आणि त्याला `user` ही भूमिका देतो. हे वापरकर्त्याने चॅटबॉटला लिहिलेला संदेश असल्याचे अनुकरण करण्यासाठी आहे.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "जरी प्रॉम्प्ट्स सारखे असले आणि वर्णनेही जवळजवळ एकसारखी असली, तरी आपल्याला `Grades` प्रॉपर्टीचे वेगवेगळे फॉरमॅट्स मिळू शकतात.\n",
    "\n",
    "वरील सेल अनेक वेळा चालवला, तर फॉरमॅट `3.7` किंवा `3.7 GPA` असे येऊ शकते.\n",
    "\n",
    "हे असे होते कारण LLM अनस्ट्रक्चर्ड डेटा म्हणजेच लिहिलेल्या प्रॉम्प्टच्या स्वरूपात डेटा घेतो आणि अनस्ट्रक्चर्ड डेटा परत करतो. आपल्याला स्ट्रक्चर्ड फॉरमॅटची गरज आहे, जेणेकरून हा डेटा साठवताना किंवा वापरताना काय अपेक्षित आहे हे आपल्याला कळेल.\n",
    "\n",
    "फंक्शनल कॉलिंग वापरून, आपण खात्री करू शकतो की आपल्याला स्ट्रक्चर्ड डेटा परत मिळेल. फंक्शन कॉलिंग वापरताना, LLM प्रत्यक्षात कोणतेही फंक्शन कॉल करत नाही किंवा चालवत नाही. त्याऐवजी, आपण LLM साठी त्याच्या प्रतिसादांसाठी एक स्ट्रक्चर तयार करतो. नंतर आपण हे स्ट्रक्चर्ड प्रतिसाद वापरून आपल्या अ‍ॅप्लिकेशन्समध्ये कोणते फंक्शन चालवायचे ते ठरवतो.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉल्स वापरण्याची उपयोगिता\n",
    "\n",
    "**बाह्य साधनांना कॉल करणे**  \n",
    "चॅटबॉट्स वापरकर्त्यांच्या प्रश्नांना उत्तरे देण्यात खूप चांगले असतात. फंक्शन कॉलिंग वापरून, चॅटबॉट्स वापरकर्त्यांच्या संदेशांचा वापर विशिष्ट कामे पूर्ण करण्यासाठी करू शकतात. उदाहरणार्थ, एखादा विद्यार्थी चॅटबॉटला विचारू शकतो, \"माझ्या शिक्षकाला ईमेल पाठव की मला या विषयात अधिक मदतीची गरज आहे\". यासाठी `send_email(to: string, body: string)` हे फंक्शन कॉल केले जाऊ शकते.\n",
    "\n",
    "**API किंवा डेटाबेस क्वेरी तयार करणे**  \n",
    "वापरकर्ते नैसर्गिक भाषेत माहिती शोधू शकतात, जी नंतर योग्य फॉरमॅटमधील क्वेरी किंवा API रिक्वेस्टमध्ये रूपांतरित होते. उदाहरणार्थ, एखादा शिक्षक विचारू शकतो, \"शेवटचे असाइनमेंट पूर्ण केलेले विद्यार्थी कोण आहेत?\" यासाठी `get_completed(student_name: string, assignment: int, current_status: string)` नावाचे फंक्शन कॉल केले जाऊ शकते.\n",
    "\n",
    "**संरचित डेटा तयार करणे**  \n",
    "वापरकर्ते मजकूराचा तुकडा किंवा CSV घेऊन LLM चा वापर करून त्यातून महत्त्वाची माहिती काढू शकतात. उदाहरणार्थ, एखादा विद्यार्थी शांतता करारांवरील विकिपीडिया लेख घेऊन त्यावरून AI फ्लॅश कार्ड्स तयार करू शकतो. हे `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` या फंक्शनचा वापर करून करता येते.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## २. आपली पहिली फंक्शन कॉल तयार करणे\n",
    "\n",
    "फंक्शन कॉल तयार करण्याची प्रक्रिया ३ मुख्य टप्प्यांमध्ये विभागलेली आहे:\n",
    "1. आपल्या फंक्शन्सची यादी आणि वापरकर्त्याचा संदेश घेऊन Chat Completions API ला कॉल करणे\n",
    "2. मॉडेलच्या प्रतिसादावरून कोणती कृती करायची ते समजून घेणे, म्हणजे फंक्शन किंवा API कॉल चालवणे\n",
    "3. आपल्या फंक्शनकडून मिळालेल्या प्रतिसादासह पुन्हा एकदा Chat Completions API ला कॉल करणे, जेणेकरून त्या माहितीचा वापर करून वापरकर्त्याला योग्य प्रतिसाद देता येईल.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow of a Function Call](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.mr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलचे घटक\n",
    "\n",
    "#### वापरकर्त्याचा इनपुट\n",
    "\n",
    "सर्वात पहिलं पाऊल म्हणजे वापरकर्त्याचा मेसेज तयार करणं. हे तुम्ही टेक्स्ट इनपुटमधून डायनॅमिकली घेऊ शकता किंवा इथेच एखादी किंमत देऊ शकता. जर तुम्ही पहिल्यांदाच Chat Completions API वापरत असाल, तर आपल्याला मेसेजचं `role` आणि `content` ठरवावं लागतं.\n",
    "\n",
    "`role` हे `system` (नियम तयार करणं), `assistant` (मॉडेल) किंवा `user` (शेवटचा वापरकर्ता) असू शकतं. फंक्शन कॉलसाठी, आपण हे `user` म्हणून सेट करू आणि एक उदाहरण प्रश्न देऊ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन्स तयार करणे.\n",
    "\n",
    "पुढे आपण एक फंक्शन आणि त्या फंक्शनचे पॅरामीटर्स कसे ठरवायचे ते पाहू. इथे आपण `search_courses` नावाचे एकच फंक्शन वापरणार आहोत, पण तुम्ही हवे असल्यास अनेक फंक्शन्स तयार करू शकता.\n",
    "\n",
    "**महत्वाचे** : फंक्शन्स सिस्टीम मेसेजमध्ये LLM ला दिल्या जातात आणि त्यामुळे तुमच्याकडे उपलब्ध असलेल्या टोकन्सच्या मर्यादेत त्यांचा समावेश होतो.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**परिभाषा**\n",
    "\n",
    "फंक्शन डिफिनिशन स्ट्रक्चरमध्ये अनेक स्तर असतात, आणि प्रत्येक स्तराला त्याच्या स्वतःच्या वैशिष्ट्यांचा संच असतो. खाली या नेस्टेड स्ट्रक्चरचे स्पष्टीकरण दिले आहे:\n",
    "\n",
    "**टॉप लेव्हल फंक्शन वैशिष्ट्ये:**\n",
    "\n",
    "`name` - आपण कॉल करावयाचा असलेला फंक्शनचा नाव.\n",
    "\n",
    "`description` - या फंक्शनचे कार्य कसे चालते याचे वर्णन. येथे स्पष्ट आणि नेमकेपणाने सांगणे महत्त्वाचे आहे.\n",
    "\n",
    "`parameters` - आपण मॉडेलकडून प्रतिसादात कोणत्या मूल्ये आणि फॉरमॅटमध्ये माहिती हवी आहे याची यादी.\n",
    "\n",
    "**Parameters ऑब्जेक्टची वैशिष्ट्ये:**\n",
    "\n",
    "`type` - parameters ऑब्जेक्टचा डेटा टाईप (साधारणपणे \"object\")\n",
    "\n",
    "`properties` - मॉडेल आपल्या प्रतिसादासाठी कोणती विशिष्ट मूल्ये वापरणार आहे याची यादी\n",
    "\n",
    "**प्रत्येक पॅरामीटरची वैशिष्ट्ये:**\n",
    "\n",
    "`name` - प्रॉपर्टी कीने अप्रत्यक्षपणे ठरवलेले नाव (उदा., \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - या विशिष्ट पॅरामीटरचा डेटा टाईप (उदा., \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - त्या विशिष्ट पॅरामीटरचे वर्णन\n",
    "\n",
    "**ऐच्छिक वैशिष्ट्ये:**\n",
    "\n",
    "`required` - फंक्शन कॉल पूर्ण करण्यासाठी कोणते पॅरामीटर्स आवश्यक आहेत याची यादी असलेली अ‍ॅरे\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉल करणे\n",
    "फंक्शन परिभाषित केल्यानंतर, आता आपल्याला ते Chat Completion API च्या कॉलमध्ये समाविष्ट करावे लागेल. हे करण्यासाठी आपण विनंतीमध्ये `functions` जोडतो. या प्रकरणात `functions=functions` असेल.\n",
    "\n",
    "याशिवाय, `function_call` हे `auto` वर सेट करण्याचा पर्याय देखील आहे. याचा अर्थ असा की, वापरकर्त्याच्या संदेशावरून कोणते फंक्शन कॉल करायचे हे LLM ठरवेल, आपण ते स्वतः ठरवण्याऐवजी.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण प्रतिसादाकडे पाहू आणि त्याचे स्वरूप कसे आहे ते पाहूया:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "आपण पाहू शकता की फंक्शनचे नाव कॉल केले आहे आणि वापरकर्त्याच्या संदेशातून, LLM ला फंक्शनच्या arguments मध्ये बसवण्यासाठी डेटा मिळाला.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.फंक्शन कॉल्सना ॲप्लिकेशनमध्ये समाविष्ट करणे.\n",
    "\n",
    "आपण LLM कडून मिळालेल्या फॉरमॅटेड प्रतिसादाची चाचणी घेतल्यानंतर, आता आपण हे ॲप्लिकेशनमध्ये समाविष्ट करू शकतो.\n",
    "\n",
    "### फ्लो व्यवस्थापित करणे\n",
    "\n",
    "हे आपल्या ॲप्लिकेशनमध्ये समाविष्ट करण्यासाठी, खालील पावले उचलूया:\n",
    "\n",
    "सर्वप्रथम, आपण OpenAI सेवेला कॉल करू आणि संदेश `response_message` नावाच्या व्हेरिएबलमध्ये साठवू.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण अशी फंक्शन परिभाषित करू जी Microsoft Learn API ला कॉल करून कोर्सेसची यादी मिळवेल:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "एक उत्तम पद्धत म्हणून, आपण पाहू की मॉडेलला एखादी फंक्शन कॉल करायची आहे का. त्यानंतर, आपण उपलब्ध फंक्शन्सपैकी एक तयार करू आणि ती कॉल केलेल्या फंक्शनशी जुळवू.\n",
    "\n",
    "यानंतर, आपण फंक्शनचे arguments घेऊ आणि ते LLM कडून आलेल्या arguments शी जुळवू.\n",
    "\n",
    "शेवटी, आपण function call message आणि `search_courses` मेसेजने परत आलेल्या values जोडू. यामुळे LLM ला वापरकर्त्याला नैसर्गिक भाषेत उत्तर देण्यासाठी आवश्यक सर्व माहिती मिळते.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कोड चॅलेंज\n",
    "\n",
    "छान काम केले! OpenAI Function Calling बद्दल अधिक शिकण्यासाठी तुम्ही हे तयार करू शकता: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - फंक्शनचे अधिक पॅरामीटर्स जोडा, जेणेकरून शिकणाऱ्यांना अधिक कोर्सेस शोधायला मदत होईल. उपलब्ध API पॅरामीटर्स तुम्ही येथे पाहू शकता:\n",
    " - आणखी एक फंक्शन कॉल तयार करा, जे शिकणाऱ्याची मातृभाषा यासारखी अधिक माहिती घेईल\n",
    " - फंक्शन कॉल आणि/किंवा API कॉलमधून योग्य कोर्सेस मिळाले नाहीत, तर एरर हँडलिंग तयार करा\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nहे दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित केले आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानावा. अत्यावश्यक माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थ लावण्यास आम्ही जबाबदार राहणार नाही.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T20:55:35+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}