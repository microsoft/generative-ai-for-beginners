{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिचय\n",
    "\n",
    "हा धडा खालील गोष्टींचा आढावा घेईल:\n",
    "- फंक्शन कॉलिंग म्हणजे काय आणि त्याचे वापराचे प्रकार\n",
    "- OpenAI वापरून फंक्शन कॉल कसे तयार करायचे\n",
    "- फंक्शन कॉल कसे अॅप्लिकेशनमध्ये समाकलित करायचे\n",
    "\n",
    "## शिकण्याचे उद्दिष्टे\n",
    "\n",
    "हा धडा पूर्ण केल्यानंतर तुम्हाला कसे करायचे आणि समजेल:\n",
    "\n",
    "- फंक्शन कॉलिंग वापरण्याचा उद्देश काय आहे\n",
    "- OpenAI सेवा वापरून फंक्शन कॉल सेटअप करणे\n",
    "- तुमच्या अॅप्लिकेशनच्या वापरासाठी प्रभावी फंक्शन कॉल डिझाइन करणे\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## फंक्शन कॉल्स समजून घेणे\n",
    "\n",
    "या धड्यात, आपल्याला आपल्या शिक्षण स्टार्टअपने एक अशी सुविधा तयार करायची आहे ज्यामुळे वापरकर्ते तांत्रिक कोर्सेस शोधण्यासाठी चॅटबॉट वापरू शकतील. आम्ही त्यांच्या कौशल्य पातळी, सध्याच्या भूमिके आणि आवडत्या तंत्रज्ञानानुसार कोर्सेस शिफारस करू.\n",
    "\n",
    "हे पूर्ण करण्यासाठी आपण खालील संयोजन वापरणार आहोत:\n",
    " - वापरकर्त्यासाठी चॅट अनुभव तयार करण्यासाठी `OpenAI`\n",
    " - वापरकर्त्यांच्या विनंतीनुसार कोर्सेस शोधण्यासाठी `Microsoft Learn Catalog API`\n",
    " - वापरकर्त्याच्या क्वेरीला फंक्शनकडे पाठवण्यासाठी आणि API विनंती करण्यासाठी `Function Calling`\n",
    "\n",
    "सुरू करण्यासाठी, आपण प्रथम का फंक्शन कॉलिंग वापरायचे आहे ते पाहूया:\n",
    "\n",
    "print(\"पुढील विनंतीतील संदेश:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT कडून नवीन प्रतिसाद मिळवा जिथे ते फंक्शन प्रतिसाद पाहू शकते\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलिंग का आवश्यक आहे\n",
    "\n",
    "जर तुम्ही या कोर्समधील इतर कोणताही धडा पूर्ण केला असेल, तर तुम्हाला मोठ्या भाषा मॉडेल्स (LLMs) वापरण्याची ताकद कदाचित समजली असेल. आशा आहे की तुम्हाला त्यांच्या काही मर्यादा देखील दिसल्या असतील.\n",
    "\n",
    "फंक्शन कॉलिंग ही OpenAI सेवा एक वैशिष्ट्य आहे जी खालील आव्हानांवर मात करण्यासाठी डिझाइन केली गेली आहे:\n",
    "\n",
    "असंगत प्रतिसाद स्वरूप:\n",
    "- फंक्शन कॉलिंगपूर्वी, मोठ्या भाषा मॉडेलकडून मिळणारे प्रतिसाद असंरचित आणि असंगत होते. विकसकांना आउटपुटमधील प्रत्येक बदलासाठी जटिल प्रमाणीकरण कोड लिहावा लागायचा.\n",
    "\n",
    "बाह्य डेटासह मर्यादित एकत्रीकरण:\n",
    "- या वैशिष्ट्यापूर्वी, चॅट संदर्भात अनुप्रयोगाच्या इतर भागांमधील डेटा समाविष्ट करणे कठीण होते.\n",
    "\n",
    "प्रतिसाद स्वरूपांचे मानकीकरण करून आणि बाह्य डेटासह अखंड एकत्रीकरण सक्षम करून, फंक्शन कॉलिंग विकास सुलभ करते आणि अतिरिक्त प्रमाणीकरण लॉजिकची गरज कमी करते.\n",
    "\n",
    "वापरकर्त्यांना \"स्टॉकहोममधील सध्याचा हवामान काय आहे?\" यासारखे उत्तर मिळू शकले नाही. कारण मॉडेल्सना फक्त प्रशिक्षणासाठी वापरलेल्या डेटाच्या वेळेपुरते मर्यादित केले गेले होते.\n",
    "\n",
    "खालील उदाहरण पाहूया जे या समस्येचे स्पष्टीकरण करते:\n",
    "\n",
    "समजा आपण विद्यार्थ्यांचा डेटा संग्रहित करण्यासाठी एक डेटाबेस तयार करू इच्छितो जेणेकरून त्यांना योग्य कोर्स सुचवता येईल. खाली दोन विद्यार्थ्यांचे वर्णन आहे जे त्यांच्या डेटामध्ये खूपच समान आहेत.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आम्हाला हे डेटा पार्स करण्यासाठी LLM कडे पाठवायचे आहे. नंतर हे आमच्या अनुप्रयोगात API कडे पाठवण्यासाठी किंवा डेटाबेसमध्ये साठवण्यासाठी वापरले जाऊ शकते.\n",
    "\n",
    "चला दोन सारखे प्रॉम्प्ट तयार करू ज्यात आम्ही LLM ला कोणती माहिती आम्हाला हवी आहे हे निर्देशित करू:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आम्हाला हे आमच्या उत्पादनासाठी महत्त्वाच्या भागांचे विश्लेषण करण्यासाठी LLM कडे पाठवायचे आहे. त्यामुळे आम्ही LLM ला सूचित करण्यासाठी दोन एकसारखे प्रॉम्प्ट तयार करू शकतो:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हे दोन प्रॉम्प्ट तयार केल्यानंतर, आम्ही त्यांना `openai.ChatCompletion` वापरून LLM कडे पाठवू. आम्ही प्रॉम्प्ट `messages` व्हेरिएबलमध्ये साठवतो आणि भूमिका `user` म्हणून नियुक्त करतो. हे वापरकर्त्याने चॅटबॉटला लिहिलेल्या संदेशाचे अनुकरण करण्यासाठी आहे.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण दोन्ही विनंत्या LLM कडे पाठवू शकतो आणि आम्हाला मिळालेल्या प्रतिसादाचे परीक्षण करू शकतो.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "जरी प्रॉम्प्ट्स सारखे असले तरी आणि वर्णने समान असली तरी, आपल्याला `Grades` प्रॉपर्टीचे वेगवेगळे स्वरूप मिळू शकते.\n",
    "\n",
    "जर आपण वरील सेल अनेक वेळा चालवले, तर स्वरूप `3.7` किंवा `3.7 GPA` असू शकते.\n",
    "\n",
    "हे कारण LLM लिहिलेल्या प्रॉम्प्टच्या स्वरूपात असंरचित डेटा घेतो आणि असंरचित डेटा परत करतो. आपल्याला एक संरचित स्वरूप असणे आवश्यक आहे जेणेकरून आपण या डेटाचा संग्रह करताना किंवा वापरताना काय अपेक्षित आहे हे समजू शकेल.\n",
    "\n",
    "फंक्शनल कॉलिंग वापरून, आपण सुनिश्चित करू शकतो की आपल्याला संरचित डेटा परत मिळेल. फंक्शन कॉलिंग वापरताना, LLM प्रत्यक्षात कोणतेही फंक्शन्स कॉल किंवा चालवत नाही. त्याऐवजी, आपण LLM साठी त्याच्या प्रतिसादांसाठी एक संरचना तयार करतो. नंतर आपण त्या संरचित प्रतिसादांचा वापर करून आपल्या अनुप्रयोगांमध्ये कोणता फंक्शन चालवायचा हे ठरवतो.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![फंक्शन कॉलिंग फ्लो डायग्राम](../../../../translated_images/Function-Flow.083875364af4f4bb.mr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आम्ही नंतर फंक्शनकडून परत आलेले मूल्य घेऊ शकतो आणि ते LLM कडे परत पाठवू शकतो. नंतर LLM नैसर्गिक भाषेचा वापर करून वापरकर्त्याच्या प्रश्नाचे उत्तर देईल.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉल वापरण्याचे वापर प्रकरणे\n",
    "\n",
    "**बाह्य साधने कॉल करणे**  \n",
    "चॅटबॉट वापरकर्त्यांच्या प्रश्नांची उत्तरे देण्यात उत्कृष्ट असतात. फंक्शन कॉलिंग वापरून, चॅटबॉट वापरकर्त्यांकडून आलेले संदेश वापरून काही कार्ये पूर्ण करू शकतात. उदाहरणार्थ, विद्यार्थी चॅटबॉटला विचारू शकतो, \"माझ्या शिक्षकाला ईमेल पाठवा की मला या विषयावर अधिक मदतीची गरज आहे\". हे `send_email(to: string, body: string)` या फंक्शन कॉल करू शकते.\n",
    "\n",
    "**API किंवा डेटाबेस क्वेरी तयार करणे**  \n",
    "वापरकर्ते नैसर्गिक भाषेचा वापर करून माहिती शोधू शकतात जी नंतर फॉरमॅट केलेल्या क्वेरी किंवा API विनंतीमध्ये रूपांतरित होते. याचे उदाहरण म्हणजे शिक्षक जो विचारतो, \"शेवटच्या असाइनमेंट पूर्ण केलेले विद्यार्थी कोण आहेत?\" ज्यासाठी `get_completed(student_name: string, assignment: int, current_status: string)` नावाचे फंक्शन कॉल केले जाऊ शकते.\n",
    "\n",
    "**संरचित डेटा तयार करणे**  \n",
    "वापरकर्ते मजकूराचा ब्लॉक किंवा CSV घेऊन त्यातून महत्त्वाची माहिती काढण्यासाठी LLM वापरू शकतात. उदाहरणार्थ, विद्यार्थी शांतता करारांबद्दल विकिपीडिया लेख रूपांतरित करून AI फ्लॅश कार्ड तयार करू शकतो. हे `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` नावाच्या फंक्शनचा वापर करून केले जाऊ शकते.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. तुमच्या पहिल्या फंक्शन कॉलची निर्मिती\n",
    "\n",
    "फंक्शन कॉल तयार करण्याची प्रक्रिया 3 मुख्य टप्प्यांमध्ये आहे:  \n",
    "1. तुमच्या फंक्शन्सची यादी आणि वापरकर्त्याचा संदेश वापरून Chat Completions API कॉल करणे  \n",
    "2. कृती करण्यासाठी मॉडेलच्या प्रतिसादाचे वाचन करणे म्हणजे फंक्शन किंवा API कॉल चालवणे  \n",
    "3. वापरकर्त्यास प्रतिसाद तयार करण्यासाठी तुमच्या फंक्शनमधून आलेल्या प्रतिसादासह Chat Completions API ला आणखी एक कॉल करणे.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![फंक्शन कॉलचा प्रवाह](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.mr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलचे घटक\n",
    "\n",
    "#### वापरकर्त्याचा इनपुट\n",
    "\n",
    "पहिला टप्पा म्हणजे वापरकर्त्याचा संदेश तयार करणे. हा संदेश डायनॅमिकली टेक्स्ट इनपुटची किंमत घेऊन असाइन केला जाऊ शकतो किंवा तुम्ही येथे एक किंमत असाइन करू शकता. जर तुम्ही Chat Completions API सह प्रथमच काम करत असाल, तर आपल्याला संदेशाचा `role` आणि `content` परिभाषित करणे आवश्यक आहे.\n",
    "\n",
    "`role` हे `system` (नियम तयार करणे), `assistant` (मॉडेल) किंवा `user` (अंतिम वापरकर्ता) पैकी कोणतेही असू शकते. फंक्शन कॉलिंगसाठी, आपण याला `user` म्हणून असाइन करू आणि एक उदाहरण प्रश्न देऊ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन्स तयार करणे.\n",
    "\n",
    "पुढे आपण एक फंक्शन आणि त्या फंक्शनचे पॅरामीटर्स परिभाषित करू. येथे आपण फक्त एक फंक्शन वापरणार आहोत ज्याला `search_courses` म्हणतात, पण तुम्ही अनेक फंक्शन्स तयार करू शकता.\n",
    "\n",
    "**महत्त्वाचे** : फंक्शन्स LLM साठी सिस्टम मेसेजमध्ये समाविष्ट असतात आणि ते तुमच्याकडे उपलब्ध असलेल्या टोकन्सच्या संख्येत समाविष्ट होतील.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**व्याख्या**\n",
    "\n",
    "फंक्शन व्याख्या संरचनेमध्ये अनेक स्तर असतात, प्रत्येकाची स्वतःची वैशिष्ट्ये असतात. येथे नेस्टेड संरचनेचे विघटन दिले आहे:\n",
    "\n",
    "**टॉप लेव्हल फंक्शन वैशिष्ट्ये:**\n",
    "\n",
    "`name` - कॉल करायच्या फंक्शनचे नाव.\n",
    "\n",
    "`description` - फंक्शन कसे कार्य करते याचे वर्णन. येथे स्पष्ट आणि विशिष्ट असणे महत्त्वाचे आहे.\n",
    "\n",
    "`parameters` - मॉडेलने त्याच्या प्रतिसादात तयार करावयाच्या मूल्यांची आणि स्वरूपाची यादी.\n",
    "\n",
    "**पॅरामीटर्स ऑब्जेक्ट वैशिष्ट्ये:**\n",
    "\n",
    "`type` - पॅरामीटर्स ऑब्जेक्टचा डेटा प्रकार (सामान्यतः \"object\")\n",
    "\n",
    "`properties` - मॉडेल त्याच्या प्रतिसादासाठी वापरणार्‍या विशिष्ट मूल्यांची यादी.\n",
    "\n",
    "**वैयक्तिक पॅरामीटर वैशिष्ट्ये:**\n",
    "\n",
    "`name` - प्रॉपर्टी कीने अप्रत्यक्षपणे परिभाषित (उदा., \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - या विशिष्ट पॅरामीटरचा डेटा प्रकार (उदा., \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - विशिष्ट पॅरामीटरचे वर्णन.\n",
    "\n",
    "**ऐच्छिक वैशिष्ट्ये:**\n",
    "\n",
    "`required` - फंक्शन कॉल पूर्ण होण्यासाठी कोणते पॅरामीटर्स आवश्यक आहेत याची यादी असलेले अ‍ॅरे.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉल करणे  \n",
    "फंक्शन परिभाषित केल्यानंतर, आता आपल्याला ते Chat Completion API कॉलमध्ये समाविष्ट करणे आवश्यक आहे. आपण हे विनंतीमध्ये `functions` जोडून करतो. या प्रकरणात `functions=functions` आहे.  \n",
    "\n",
    "`function_call` ला `auto` सेट करण्याचा पर्याय देखील आहे. याचा अर्थ आपण स्वतः फंक्शन नियुक्त करण्याऐवजी वापरकर्त्याच्या संदेशावर आधारित कोणते फंक्शन कॉल करायचे ते LLM ठरवू देऊ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण प्रतिसादाकडे पाहूया आणि ते कसे स्वरूपित आहे ते पाहूया:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "आपण पाहू शकता की फंक्शनचे नाव कॉल केले गेले आहे आणि वापरकर्त्याच्या संदेशातून, LLM ला फंक्शनच्या आर्ग्युमेंट्ससाठी डेटा सापडला आहे.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.अ‍ॅप्लिकेशनमध्ये फंक्शन कॉल्स एकत्रित करणे. \n",
    "\n",
    "\n",
    "आम्ही LLM कडून फॉर्मॅट केलेला प्रतिसाद तपासल्यानंतर, आता आपण याला अ‍ॅप्लिकेशनमध्ये एकत्रित करू शकतो. \n",
    "\n",
    "### प्रवाह व्यवस्थापन \n",
    "\n",
    "हे आमच्या अ‍ॅप्लिकेशनमध्ये एकत्रित करण्यासाठी, चला खालील पावले उचलूया: \n",
    "\n",
    "प्रथम, OpenAI सेवांना कॉल करूया आणि संदेश `response_message` नावाच्या व्हेरिएबलमध्ये साठवूया. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण तो फंक्शन परिभाषित करू ज्यामुळे Microsoft Learn API कॉल करून कोर्सेसची यादी मिळेल:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "सर्वोत्तम पद्धती म्हणून, आपण नंतर पाहू की मॉडेलला एखादी फंक्शन कॉल करायची आहे का. त्यानंतर, आपण उपलब्ध फंक्शन्सपैकी एक तयार करू आणि त्याला कॉल होणाऱ्या फंक्शनशी जुळवून घेऊ.  \n",
    "नंतर, आपण फंक्शनचे आर्ग्युमेंट्स घेऊन त्यांना LLM मधील आर्ग्युमेंट्सशी मॅप करू.  \n",
    "\n",
    "शेवटी, आपण फंक्शन कॉल मेसेज आणि `search_courses` मेसेजने परत केलेल्या मूल्यांना जोडू. यामुळे LLM ला वापरकर्त्याला नैसर्गिक भाषेत प्रतिसाद देण्यासाठी आवश्यक सर्व माहिती मिळते.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण अद्ययावत संदेश LLM कडे पाठवू जेणेकरून आपल्याला API JSON स्वरूपातील प्रतिसादाऐवजी नैसर्गिक भाषा प्रतिसाद प्राप्त होईल.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कोड आव्हान\n",
    "\n",
    "छान काम! OpenAI फंक्शन कॉलिंगचे तुमचे शिक्षण सुरू ठेवण्यासाठी तुम्ही तयार करू शकता: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - फंक्शनचे अधिक पॅरामीटर्स जे शिकणाऱ्यांना अधिक कोर्सेस शोधण्यात मदत करू शकतात. तुम्हाला उपलब्ध API पॅरामीटर्स येथे सापडतील:  \n",
    " - आणखी एक फंक्शन कॉल तयार करा जे शिकणाऱ्यांकडून त्यांची मातृभाषा यासारखी अधिक माहिती घेतो  \n",
    " - जेव्हा फंक्शन कॉल आणि/किंवा API कॉल कोणतेही योग्य कोर्सेस परत करत नाही तेव्हा त्रुटी हाताळणी तयार करा\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**अस्वीकरण**:\nहा दस्तऐवज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून अनुवादित केला आहे. आम्ही अचूकतेसाठी प्रयत्न करतो, तरी कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये चुका किंवा अचूकतेची कमतरता असू शकते. मूळ दस्तऐवज त्याच्या स्थानिक भाषेत अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी अनुवाद शिफारसीय आहे. या अनुवादाच्या वापरामुळे उद्भवलेल्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थलागी आम्ही जबाबदार नाही.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T09:44:32+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}