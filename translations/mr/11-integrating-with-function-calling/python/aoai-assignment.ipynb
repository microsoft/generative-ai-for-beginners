{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिचय\n",
    "\n",
    "या धड्यात आपण शिकणार आहोत:\n",
    "- फंक्शन कॉलिंग म्हणजे काय आणि त्याचे उपयोग\n",
    "- Azure OpenAI वापरून फंक्शन कॉल कसे तयार करायचे\n",
    "- फंक्शन कॉल आपल्या ॲप्लिकेशनमध्ये कसे एकत्रित करायचे\n",
    "\n",
    "## शिकण्याची उद्दिष्टे\n",
    "\n",
    "हे धडे पूर्ण केल्यानंतर तुम्हाला खालील गोष्टी समजतील आणि करता येतील:\n",
    "\n",
    "- फंक्शन कॉलिंगचा उपयोग का करावा हे समजेल\n",
    "- Azure Open AI Service वापरून फंक्शन कॉल सेटअप करणे\n",
    "- आपल्या ॲप्लिकेशनच्या गरजेनुसार प्रभावी फंक्शन कॉल डिझाइन करणे\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## फंक्शन कॉल्स समजून घेणे\n",
    "\n",
    "या धड्यासाठी, आपल्याला आपल्या एज्युकेशन स्टार्टअपसाठी अशी सुविधा तयार करायची आहे ज्यामुळे वापरकर्ते चॅटबॉट वापरून तांत्रिक कोर्सेस शोधू शकतील. आपण त्यांच्या कौशल्याच्या पातळीला, सध्याच्या भूमिकेला आणि आवडत्या तंत्रज्ञानाला अनुरूप कोर्सेस सुचवणार आहोत.\n",
    "\n",
    "हे पूर्ण करण्यासाठी आपण खालील गोष्टींचा एकत्रित वापर करू:\n",
    " - `Azure Open AI` वापरून वापरकर्त्यासाठी चॅट अनुभव तयार करणे\n",
    " - `Microsoft Learn Catalog API` वापरून वापरकर्त्याच्या विनंतीनुसार कोर्सेस शोधण्यात मदत करणे\n",
    " - `Function Calling` वापरून वापरकर्त्याच्या क्वेरीला फंक्शनमध्ये पाठवून API विनंती करणे\n",
    "\n",
    "सुरुवात करण्यासाठी, आपण प्रथम फंक्शन कॉलिंग का वापरावे हे पाहूया:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT कडून नवीन प्रतिसाद मिळवा जिथे त्याला फंक्शनचा प्रतिसाद दिसू शकतो\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलिंग का?\n",
    "\n",
    "या कोर्समधील इतर कोणताही धडा पूर्ण केला असेल, तर तुम्हाला Large Language Models (LLMs) वापरण्याची ताकद समजली असेल. तसेच, त्यांची काही मर्यादा देखील लक्षात आल्या असतील.\n",
    "\n",
    "Azure Open AI Service मधील Function Calling हे खालील मर्यादा दूर करण्यासाठीचे एक वैशिष्ट्य आहे:\n",
    "1) उत्तरांचा एकसारखा फॉरमॅट मिळवणे\n",
    "2) चॅट संदर्भात अ‍ॅप्लिकेशनमधील इतर स्रोतांमधून डेटा वापरण्याची क्षमता\n",
    "\n",
    "फंक्शन कॉलिंगच्या आधी, LLM कडून मिळणारी उत्तरे असंघटित आणि विसंगत असायची. डेव्हलपर्सना प्रत्येक वेगळ्या उत्तरासाठी क्लिष्ट व्हॅलिडेशन कोड लिहावा लागायचा.\n",
    "\n",
    "वापरकर्त्यांना \"स्टॉकहोममधील सध्याचे हवामान काय आहे?\" असे प्रश्न विचारता येत नव्हते. कारण मॉडेल्सना केवळ त्यांच्या ट्रेनिंगच्या काळातील माहितीच माहित असायची.\n",
    "\n",
    "चला, खालील उदाहरण पाहूया जे ही समस्या स्पष्ट करते:\n",
    "\n",
    "समजा, आपल्याला विद्यार्थ्यांचा डेटा असलेला एक डेटाबेस तयार करायचा आहे, जेणेकरून आपण त्यांना योग्य कोर्स सुचवू शकू. खाली दोन विद्यार्थ्यांची वर्णने दिली आहेत, ज्यामध्ये असलेला डेटा खूपच समान आहे.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आपण हे एका LLM कडे पाठवू इच्छितो जेणेकरून डेटा पार्स करता येईल. हे नंतर आपल्या अनुप्रयोगात API कडे पाठवण्यासाठी किंवा डेटाबेसमध्ये साठवण्यासाठी वापरता येईल.\n",
    "\n",
    "चला दोन एकसारख्या प्रॉम्प्ट्स तयार करूया ज्यामध्ये आपण LLM ला कोणती माहिती आवश्यक आहे हे सांगतो:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आम्ही हे आमच्या उत्पादनासाठी महत्त्वाचे असलेले भाग पार्स करण्यासाठी LLM कडे पाठवू इच्छितो. त्यामुळे आपण LLM ला सूचना देण्यासाठी दोन एकसारखे प्रॉम्प्ट तयार करू शकतो:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ही दोन प्रॉम्प्ट तयार केल्यानंतर, आपण त्या LLM कडे `openai.ChatCompletion` वापरून पाठवू. आपण प्रॉम्प्ट `messages` या व्हेरिएबलमध्ये साठवतो आणि त्याला `user` ही भूमिका देतो. हे वापरकर्त्याने चॅटबॉटला पाठवलेला संदेश असल्याचे अनुकरण करण्यासाठी आहे.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "जरी प्रॉम्प्ट्स सारखे असले आणि वर्णनेही जवळजवळ तशीच असली, तरी आपल्याला `Grades` प्रॉपर्टीचे वेगवेगळे फॉरमॅट्स मिळू शकतात.\n",
    "\n",
    "जर तुम्ही वरील सेल अनेक वेळा चालवला, तर फॉरमॅट `3.7` किंवा `3.7 GPA` असे येऊ शकते.\n",
    "\n",
    "हे असे होते कारण LLM अनस्ट्रक्चर्ड डेटा म्हणजेच लिहिलेल्या प्रॉम्प्टच्या स्वरूपात डेटा घेतो आणि अनस्ट्रक्चर्ड डेटा परत देतो. आपल्याला एक स्ट्रक्चर्ड फॉरमॅट असणे आवश्यक आहे, जेणेकरून हा डेटा साठवताना किंवा वापरताना काय अपेक्षित आहे हे आपल्याला कळेल.\n",
    "\n",
    "फंक्शनल कॉलिंग वापरून, आपण खात्री करू शकतो की आपल्याला स्ट्रक्चर्ड डेटा परत मिळेल. फंक्शन कॉलिंग वापरताना, LLM प्रत्यक्षात कोणतेही फंक्शन्स कॉल करत नाही किंवा चालवत नाही. त्याऐवजी, आपण LLM साठी त्याच्या प्रतिसादांसाठी एक स्ट्रक्चर तयार करतो. नंतर आपण हे स्ट्रक्चर्ड प्रतिसाद वापरून आपल्या अ‍ॅप्लिकेशन्समध्ये कोणता फंक्शन चालवायचा हे ठरवतो.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉल्स वापरण्याची उपयोगिता\n",
    "\n",
    "**बाह्य साधनांना कॉल करणे**  \n",
    "चॅटबॉट्स वापरकर्त्यांच्या प्रश्नांना उत्तरे देण्यात खूप चांगले असतात. फंक्शन कॉलिंग वापरून, चॅटबॉट्स वापरकर्त्यांच्या संदेशांचा वापर विशिष्ट कामे पूर्ण करण्यासाठी करू शकतात. उदाहरणार्थ, एखादा विद्यार्थी चॅटबॉटला विचारू शकतो, \"माझ्या शिक्षकाला ईमेल पाठव की मला या विषयात अधिक मदतीची गरज आहे\". यासाठी `send_email(to: string, body: string)` हे फंक्शन कॉल केले जाऊ शकते.\n",
    "\n",
    "**API किंवा डेटाबेस क्वेरी तयार करणे**  \n",
    "वापरकर्ते नैसर्गिक भाषेत माहिती शोधू शकतात, जी नंतर योग्य फॉरमॅटमधील क्वेरी किंवा API रिक्वेस्टमध्ये रूपांतरित होते. उदाहरणार्थ, एखादा शिक्षक विचारू शकतो, \"शेवटचे असाइनमेंट पूर्ण केलेले विद्यार्थी कोण आहेत?\" यासाठी `get_completed(student_name: string, assignment: int, current_status: string)` नावाचे फंक्शन कॉल केले जाऊ शकते.\n",
    "\n",
    "**संरचित डेटा तयार करणे**  \n",
    "वापरकर्ते मजकूराचा तुकडा किंवा CSV घेऊन LLM चा वापर करून त्यातून महत्त्वाची माहिती काढू शकतात. उदाहरणार्थ, एखादा विद्यार्थी शांतता करारांवरील विकिपीडिया लेख घेऊन AI फ्लॅश कार्ड्स तयार करू शकतो. हे `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` या फंक्शनचा वापर करून करता येते.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## २. आपली पहिली फंक्शन कॉल तयार करणे\n",
    "\n",
    "फंक्शन कॉल तयार करण्याची प्रक्रिया ३ मुख्य टप्प्यांमध्ये विभागली आहे:\n",
    "1. आपल्या फंक्शन्सची यादी आणि वापरकर्त्याचा संदेश घेऊन Chat Completions API ला कॉल करणे\n",
    "2. मॉडेलच्या प्रतिसादावरून कृती करणे म्हणजेच फंक्शन किंवा API कॉल चालवणे\n",
    "3. आपल्या फंक्शनकडून मिळालेल्या प्रतिसादासह पुन्हा एकदा Chat Completions API ला कॉल करणे, जेणेकरून त्या माहितीचा वापर करून वापरकर्त्याला उत्तर तयार करता येईल.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow of a Function Call](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.mr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलचे घटक\n",
    "\n",
    "#### वापरकर्त्याचा इनपुट\n",
    "\n",
    "सर्वात पहिलं पाऊल म्हणजे वापरकर्त्याचा मेसेज तयार करणं. हे तुम्ही टेक्स्ट इनपुटमधून डायनॅमिकली घेऊ शकता किंवा इथेच एखादी किंमत देऊ शकता. जर तुम्ही पहिल्यांदाच Chat Completions API वापरत असाल, तर आपल्याला मेसेजचं `role` आणि `content` ठरवावं लागतं.\n",
    "\n",
    "`role` हे `system` (नियम तयार करणं), `assistant` (मॉडेल) किंवा `user` (शेवटचा वापरकर्ता) असू शकतं. फंक्शन कॉलसाठी, आपण हे `user` म्हणून सेट करू आणि एक उदाहरण प्रश्न देऊ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन्स तयार करणे.\n",
    "\n",
    "पुढे आपण एक फंक्शन आणि त्या फंक्शनचे पॅरामीटर्स कसे ठरवायचे ते पाहू. इथे आपण `search_courses` नावाचे एकच फंक्शन वापरणार आहोत, पण तुम्ही हवे असल्यास अनेक फंक्शन्स तयार करू शकता.\n",
    "\n",
    "**महत्वाचे** : फंक्शन्स सिस्टीम मेसेजमध्ये LLM ला दिल्या जातात आणि त्यामुळे तुमच्याकडे उपलब्ध असलेल्या टोकन्सच्या मर्यादेत त्यांचा समावेश होतो.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**व्याख्या**\n",
    "\n",
    "`name` - आपण कॉल करायची असलेली फंक्शनचे नाव.\n",
    "\n",
    "`description` - फंक्शन कसे कार्य करते याचे वर्णन. येथे स्पष्ट आणि नेमकेपणाने सांगणे महत्त्वाचे आहे.\n",
    "\n",
    "`parameters` - मॉडेलने आपल्या प्रतिसादात तयार करावयाच्या मूल्यांची आणि स्वरूपाची यादी.\n",
    "\n",
    "`type` - प्रॉपर्टीज ज्या डेटाटाइपमध्ये साठविल्या जातील.\n",
    "\n",
    "`properties` - मॉडेल आपल्या प्रतिसादासाठी वापरणार असलेल्या विशिष्ट मूल्यांची यादी.\n",
    "\n",
    "`name` - मॉडेल आपल्या फॉरमॅटेड प्रतिसादात वापरणार असलेल्या प्रॉपर्टीचे नाव.\n",
    "\n",
    "`type` - या प्रॉपर्टीचा डेटाटाइप.\n",
    "\n",
    "`description` - त्या विशिष्ट प्रॉपर्टीचे वर्णन.\n",
    "\n",
    "**ऐच्छिक**\n",
    "\n",
    "`required` - फंक्शन कॉल पूर्ण होण्यासाठी आवश्यक असलेली प्रॉपर्टी.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉल करणे\n",
    "फंक्शन डिफाइन केल्यानंतर, आता आपल्याला ते Chat Completion API च्या कॉलमध्ये समाविष्ट करायचे आहे. हे करण्यासाठी आपण `functions` रिक्वेस्टमध्ये जोडतो. या उदाहरणात `functions=functions` असे आहे.\n",
    "\n",
    "याशिवाय, `function_call` हे `auto` वर सेट करण्याचा पर्याय देखील आहे. याचा अर्थ असा की, वापरकर्त्याच्या मेसेजवरून कोणते फंक्शन कॉल करायचे हे LLM ठरवेल, आपण ते स्वतः ठरवणार नाही.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण प्रतिसादाकडे पाहूया आणि त्याचे स्वरूप कसे आहे ते पाहूया:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "आपण पाहू शकता की फंक्शनचे नाव कॉल केले आहे आणि वापरकर्त्याच्या संदेशातून, LLM ला फंक्शनच्या arguments मध्ये बसवण्यासाठी डेटा मिळाला आहे.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.फंक्शन कॉल्सना ॲप्लिकेशनमध्ये समाविष्ट करणे.\n",
    "\n",
    "आपण LLM कडून मिळालेल्या फॉरमॅटेड प्रतिसादाची चाचणी घेतल्यानंतर, आता आपण हे ॲप्लिकेशनमध्ये समाविष्ट करू शकतो.\n",
    "\n",
    "### फ्लो व्यवस्थापित करणे\n",
    "\n",
    "हे आपल्या ॲप्लिकेशनमध्ये समाविष्ट करण्यासाठी, खालील पावले उचलूया:\n",
    "\n",
    "सर्वप्रथम, आपण Open AI सेवेला कॉल करू आणि संदेश `response_message` नावाच्या व्हेरिएबलमध्ये साठवू.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "आता आपण अशी फंक्शन परिभाषित करू जी Microsoft Learn API ला कॉल करून कोर्सेसची यादी मिळवेल:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "एक उत्तम पद्धत म्हणून, आपण पाहू की मॉडेलला एखादी फंक्शन कॉल करायची आहे का. त्यानंतर, आपण उपलब्ध फंक्शन्सपैकी एक तयार करू आणि ती कॉल केलेल्या फंक्शनशी जुळवू.\n",
    "\n",
    "यानंतर, आपण फंक्शनचे arguments घेऊ आणि ते LLM कडून आलेल्या arguments शी जुळवू.\n",
    "\n",
    "शेवटी, आपण function call message आणि `search_courses` मेसेजने परत आलेल्या मूल्यांना जोडू. यामुळे LLM ला वापरकर्त्याला नैसर्गिक भाषेत उत्तर देण्यासाठी आवश्यक सर्व माहिती मिळते.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कोड चॅलेंज\n",
    "\n",
    "छान काम केले! Azure Open AI Function Calling शिकण्यास पुढे जाण्यासाठी तुम्ही हे तयार करू शकता: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - फंक्शनचे आणखी काही पॅरामीटर्स वापरून शिकणाऱ्यांना अधिक कोर्सेस शोधायला मदत होईल. उपलब्ध API पॅरामीटर्स तुम्ही येथे पाहू शकता:\n",
    " - आणखी एक फंक्शन कॉल तयार करा ज्यामध्ये शिकणाऱ्याची मातृभाषा यासारखी अधिक माहिती घेतली जाईल\n",
    " - फंक्शन कॉल आणि/किंवा API कॉलमधून योग्य कोर्सेस मिळाले नाहीत, तर एरर हँडलिंग तयार करा\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nहे दस्तऐवज AI भाषांतर सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून भाषांतरित केले आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित भाषांतरांमध्ये त्रुटी किंवा अचूकतेचा अभाव असू शकतो. मूळ भाषेतील मूळ दस्तऐवज हा अधिकृत स्रोत मानावा. अत्यावश्यक माहितीसाठी, व्यावसायिक मानवी भाषांतराची शिफारस केली जाते. या भाषांतराचा वापर केल्यामुळे उद्भवणाऱ्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थ लावण्यास आम्ही जबाबदार राहणार नाही.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:06:47+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}