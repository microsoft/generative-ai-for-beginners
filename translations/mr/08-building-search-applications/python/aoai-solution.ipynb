{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "खालील नोटबुक चालवण्यासाठी, जर तुम्ही अद्याप केले नसेल, तर तुम्हाला `text-embedding-ada-002` या बेस मॉडेलचा वापर करणारा एक मॉडेल डिप्लॉय करावा लागेल आणि .env फाईलमध्ये डिप्लॉयमेंटचे नाव `AZURE_OPENAI_EMBEDDINGS_ENDPOINT` म्हणून सेट करावे लागेल.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "पुढे, आपण एम्बेडिंग इंडेक्स पांडस डेटाफ्रेममध्ये लोड करणार आहोत. एम्बेडिंग इंडेक्स `embedding_index_3m.json` नावाच्या JSON फाईलमध्ये संग्रहित आहे. एम्बेडिंग इंडेक्समध्ये ऑक्टोबर 2023 च्या शेवटपर्यंत प्रत्येक यूट्यूब ट्रान्सक्रिप्टसाठी एम्बेडिंग्ज असतात.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "पुढे, आपण `get_videos` नावाची एक फंक्शन तयार करणार आहोत जी क्वेरीसाठी Embedding Index मध्ये शोध करेल. ही फंक्शन क्वेरीशी सर्वात जास्त सादृश्य असलेली टॉप 5 व्हिडिओ परत करेल. फंक्शन खालीलप्रमाणे कार्य करते:\n",
    "\n",
    "1. प्रथम, Embedding Index ची एक कॉपी तयार केली जाते.\n",
    "2. नंतर, OpenAI Embedding API वापरून क्वेरीसाठी Embedding गणना केली जाते.\n",
    "3. त्यानंतर Embedding Index मध्ये `similarity` नावाचा एक नवीन कॉलम तयार केला जातो. `similarity` कॉलममध्ये क्वेरी Embedding आणि प्रत्येक व्हिडिओ सेगमेंटसाठी Embedding यांच्यातील कोसाइन सादृश्यता असते.\n",
    "4. पुढे, `similarity` कॉलमद्वारे Embedding Index फिल्टर केला जातो. Embedding Index मध्ये फक्त असे व्हिडिओ समाविष्ट केले जातात ज्यांची कोसाइन सादृश्यता 0.75 किंवा त्याहून जास्त असते.\n",
    "5. शेवटी, Embedding Index `similarity` कॉलमनुसार क्रमवारी लावला जातो आणि टॉप 5 व्हिडिओ परत केले जातात.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ही फंक्शन खूप सोपी आहे, ती फक्त शोध क्वेरीचे निकाल छापते.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. प्रथम, एम्बेडिंग निर्देशांक पांडस डेटाफ्रेममध्ये लोड केला जातो.\n",
    "2. नंतर, वापरकर्त्याला क्वेरी टाकण्यास सांगितले जाते.\n",
    "3. त्यानंतर `get_videos` फंक्शन कॉल करून क्वेरीसाठी एम्बेडिंग निर्देशांक शोधला जातो.\n",
    "4. शेवटी, `display_results` फंक्शन कॉल करून वापरकर्त्यास निकाल दाखवले जातात.\n",
    "5. नंतर वापरकर्त्याला आणखी एक क्वेरी टाकण्यास सांगितले जाते. हा प्रक्रिया वापरकर्ता `exit` टाकेपर्यंत चालू राहते.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc.mr.png)\n",
    "\n",
    "आपल्याला क्वेरी टाकण्यास सांगितले जाईल. एक क्वेरी टाका आणि एंटर दाबा. अ‍ॅप्लिकेशन क्वेरीशी संबंधित व्हिडिओंची यादी परत करेल. अ‍ॅप्लिकेशन प्रश्नाच्या उत्तराचा व्हिडिओतील स्थानाचा दुवा देखील परत करेल.\n",
    "\n",
    "येथे काही क्वेरी आहेत ज्यांचा प्रयत्न करू शकता:\n",
    "\n",
    "- Azure Machine Learning म्हणजे काय?\n",
    "- कॉन्व्होल्यूशनल न्यूरल नेटवर्क कसे कार्य करतात?\n",
    "- न्यूरल नेटवर्क म्हणजे काय?\n",
    "- मी Azure Machine Learning सह Jupyter Notebooks वापरू शकतो का?\n",
    "- ONNX म्हणजे काय?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**अस्वीकरण**:\nहा दस्तऐवज AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) वापरून अनुवादित केला आहे. आम्ही अचूकतेसाठी प्रयत्नशील असलो तरी, कृपया लक्षात घ्या की स्वयंचलित अनुवादांमध्ये चुका किंवा अचूकतेची कमतरता असू शकते. मूळ दस्तऐवज त्याच्या स्थानिक भाषेत अधिकृत स्रोत मानला जावा. महत्त्वाच्या माहितीसाठी व्यावसायिक मानवी अनुवाद शिफारसीय आहे. या अनुवादाच्या वापरामुळे उद्भवलेल्या कोणत्याही गैरसमजुती किंवा चुकीच्या अर्थलागी आम्ही जबाबदार नाही.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "ff5415e24294df268ec7e7a2b12af509",
   "translation_date": "2025-12-19T09:41:53+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "mr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}