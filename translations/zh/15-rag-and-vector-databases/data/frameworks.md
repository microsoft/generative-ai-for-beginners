# 神经网络框架

正如我们已经学习到的，为了能够高效地训练神经网络，我们需要做到以下两点：

* 操作张量，例如进行乘法、加法，并计算一些函数如sigmoid或softmax
* 计算所有表达式的梯度，以便进行梯度下降优化

虽然`numpy`库可以完成第一部分，但我们需要某种机制来计算梯度。在我们在上一节中开发的框架中，我们必须手动在`backward`方法中编程所有的导数函数，这个方法进行反向传播。理想情况下，一个框架应该让我们能够计算我们可以定义的*任何表达式*的梯度。

另一个重要的事情是能够在GPU或其他专用计算单元（如TPU）上执行计算。深度神经网络训练需要*大量*的计算，能够在GPU上并行化这些计算是非常重要的。

> ✅ 术语“并行化”是指将计算分布在多个设备上。

目前，最流行的两个神经网络框架是：TensorFlow和PyTorch。两者都提供了一个低级API，可以在CPU和GPU上操作张量。在低级API之上，还有更高级的API，分别称为Keras和PyTorch Lightning。

低级API | TensorFlow | PyTorch
--------|------------|---------
高级API | Keras      | PyTorch Lightning

**低级API** 在两个框架中都允许你构建所谓的**计算图**。这个图定义了如何用给定的输入参数计算输出（通常是损失函数），如果可用的话，可以将其推送到GPU上进行计算。这里有一些函数可以对这个计算图进行微分并计算梯度，然后可以用来优化模型参数。

**高级API** 基本上将神经网络视为一个**层的序列**，并且使得构建大多数神经网络变得更容易。训练模型通常需要准备数据，然后调用一个`fit`函数来完成任务。

高级API允许你非常快速地构建典型的神经网络，而不必担心很多细节。同时，低级API提供了对训练过程的更多控制，因此在研究中被大量使用，当你处理新的神经网络架构时。

同样重要的是要理解，你可以同时使用这两种API，例如，你可以使用低级API开发自己的网络层架构，然后在用高级API构建和训练的更大网络中使用它。或者你可以使用高级API定义一个层的序列网络，然后使用自己的低级训练循环进行优化。两种API使用相同的基本概念，并且它们被设计为能够很好地协同工作。

## 学习

在本课程中，我们提供了大部分内容，既有针对PyTorch，也有针对TensorFlow的。你可以选择你喜欢的框架，只学习相应的笔记本。如果你不确定选择哪个框架，可以在网上阅读一些关于**PyTorch vs. TensorFlow**的讨论。你也可以看看这两个框架，以便更好地理解。

在可能的情况下，我们将使用高级API以简化过程。然而，我们认为理解神经网络的基本工作原理是很重要的，因此一开始我们将从低级API和张量开始。然而，如果你想快速入门，不想花太多时间学习这些细节，可以跳过这些内容，直接进入高级API笔记本。

## ✍️ 练习：框架

在以下笔记本中继续学习：

低级API | TensorFlow+Keras笔记本 | PyTorch
--------|-------------------------|---------
高级API | Keras                   | *PyTorch Lightning*

掌握了这些框架之后，让我们回顾一下过拟合的概念。

# 过拟合

过拟合是机器学习中一个极其重要的概念，正确理解它非常重要！

考虑下面这个逼近5个点的问题（在下图中用`x`表示）：

!线性 | 过拟合
----------------|-------------------
**线性模型，2个参数** | **非线性模型，7个参数**
训练误差 = 5.3 | 训练误差 = 0
验证误差 = 5.1 | 验证误差 = 20

* 左图中，我们看到一个很好的直线逼近。由于参数数量合适，模型正确地理解了点分布的背后规律。
* 右图中，模型过于强大。因为我们只有5个点，而模型有7个参数，它可以调整以通过所有点，使训练误差为0。然而，这阻止了模型理解数据背后的正确模式，因此验证误差非常高。

在模型的丰富性（参数数量）和训练样本数量之间找到正确的平衡非常重要。

## 为什么会发生过拟合

  * 训练数据不足
  * 模型过于强大
  * 输入数据中噪声过多

## 如何检测过拟合

从上图可以看出，过拟合可以通过非常低的训练误差和很高的验证误差来检测。通常在训练过程中，我们会看到训练误差和验证误差都开始下降，然后在某个点验证误差可能会停止下降并开始上升。这将是过拟合的一个标志，并且表明我们可能应该在此时停止训练（或者至少保存模型的一个快照）。

## 如何防止过拟合

如果你发现发生了过拟合，你可以采取以下措施之一：

 * 增加训练数据的数量
 * 降低模型的复杂性
 * 使用一些正则化技术，如Dropout，我们将在后面讨论。

## 过拟合和偏差-方差权衡

过拟合实际上是统计学中一个更普遍的问题，称为偏差-方差权衡。如果我们考虑模型中可能的误差来源，我们可以看到两种类型的误差：

* **偏差误差** 是由于我们的算法无法正确捕捉训练数据之间的关系而引起的。它可能是因为我们的模型不够强大（**欠拟合**）。
* **方差误差** 是由于模型逼近输入数据中的噪声而不是有意义的关系而引起的（**过拟合**）。

在训练过程中，偏差误差减少（因为我们的模型学会了逼近数据），而方差误差增加。重要的是要停止训练 - 无论是手动（当我们检测到过拟合时）还是自动（通过引入正则化） - 以防止过拟合。

## 结论

在本节课中，你学习了两种最流行的AI框架TensorFlow和PyTorch的不同API。此外，你还学习了一个非常重要的话题，过拟合。

## 🚀 挑战

在随附的笔记本中，你会在底部找到“任务”；通过笔记本并完成这些任务。

## 回顾与自学

对以下主题进行一些研究：

- TensorFlow
- PyTorch
- 过拟合

问自己以下问题：

- TensorFlow和PyTorch有什么区别？
- 过拟合和欠拟合有什么区别？

## 作业

在这个实验中，你需要使用PyTorch或TensorFlow解决两个分类问题，使用单层和多层全连接网络。

**免责声明**：  
本文档是使用机器翻译服务翻译的。虽然我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。应将原文档的母语版本视为权威来源。对于关键信息，建议使用专业人工翻译。对于因使用本翻译而产生的任何误解或误读，我们不承担责任。