```markdown
# 初学者生成式AI的小型语言模型介绍

生成式AI是人工智能的一个迷人领域，专注于创建能够生成新内容的系统。这些内容可以从文本和图像到音乐，甚至是整个虚拟环境。生成式AI最令人兴奋的应用之一是在语言模型领域。

## 什么是小型语言模型？

小型语言模型（SLM）代表了大型语言模型（LLM）的缩小版，利用了许多LLM的架构原则和技术，同时表现出显著减少的计算占用。SLM是设计用来生成类人文本的语言模型的一个子集。与其更大的对手，如GPT-4不同，SLM更加紧凑和高效，使其在计算资源有限的应用中理想。尽管它们的规模较小，它们仍能执行多种任务。通常，SLM通过压缩或蒸馏LLM构建，旨在保留原始模型功能和语言能力的很大一部分。这种模型规模的减少降低了整体复杂性，使SLM在内存使用和计算要求方面更加高效。尽管进行了这些优化，SLM仍能执行广泛的自然语言处理（NLP）任务：

- 文本生成：创建连贯且上下文相关的句子或段落。
- 文本补全：根据给定的提示预测和补全句子。
- 翻译：将文本从一种语言转换为另一种语言。
- 摘要：将长篇文本压缩为更简洁易懂的摘要。

尽管与其更大的对手相比，在性能或理解深度上有一些权衡。

## 小型语言模型如何工作？

SLM是在大量文本数据上训练的。在训练期间，它们学习语言的模式和结构，使它们能够生成既语法正确又上下文适当的文本。训练过程包括：

- 数据收集：从各种来源收集大量文本数据。
- 预处理：清理和组织数据以适合训练。
- 训练：使用机器学习算法教模型如何理解和生成文本。
- 微调：调整模型以提高其在特定任务上的性能。

SLM的发展符合在资源受限环境中部署模型的日益增长的需求，例如移动设备或边缘计算平台，在这些平台上，由于资源需求较高，全规模的LLM可能不切实际。通过专注于效率，SLM在性能和可访问性之间取得平衡，使其能够在各个领域中更广泛地应用。

![slm](../../../translated_images/slm.png?WT.85221b66c3ce1b5e21e84c783c7ba31848501cd5c9557bb7fdf13173edafd675.zh.mc_id=academic-105485-koreyst)

## 学习目标

在本课中，我们希望介绍SLM的知识，并结合微软Phi-3学习文本内容、视觉和MoE的不同场景。到本课结束时，你应该能够回答以下问题：

- 什么是SLM
- SLM和LLM有什么区别
- 什么是微软Phi-3/3.5系列
- 如何推理微软Phi-3/3.5系列

准备好了吗？让我们开始吧。

## 大型语言模型（LLM）和小型语言模型（SLM）之间的区别

LLM和SLM都建立在概率机器学习的基础原则之上，在其架构设计、训练方法、数据生成过程和模型评估技术上采用类似的方法。然而，有几个关键因素区分了这两种类型的模型。

## 小型语言模型的应用

SLM有广泛的应用，包括：

- 聊天机器人：以对话方式提供客户支持并与用户互动。
- 内容创作：通过生成创意甚至撰写整篇文章来协助作家。
- 教育：帮助学生完成写作作业或学习新语言。
- 可访问性：为残障人士创建工具，如文本转语音系统。

**规模**

LLM和SLM之间的一个主要区别在于模型的规模。LLM，例如ChatGPT（GPT-4），可以包含大约1.76万亿个参数，而开源SLM如Mistral 7B则设计有显著更少的参数——大约70亿个。这种差异主要是由于模型架构和训练过程的不同。例如，ChatGPT在编码器-解码器框架中使用自注意机制，而Mistral 7B使用滑动窗口注意机制，这使得在仅解码器模型中更高效地训练。这种架构差异对这些模型的复杂性和性能有深远影响。

**理解**

SLM通常为特定领域的性能进行了优化，使其高度专业化，但在提供跨多个知识领域的广泛上下文理解方面可能有限。相比之下，LLM旨在模拟更全面的人类智能。LLM在庞大、多样化的数据集上进行训练，设计上可以在各种领域中表现良好，提供更大的多功能性和适应性。因此，LLM更适合于更广泛的下游任务，如自然语言处理和编程。

**计算**

LLM的训练和部署是资源密集型过程，通常需要显著的计算基础设施，包括大规模GPU集群。例如，从头开始训练像ChatGPT这样的模型可能需要数千个GPU和长时间的训练。相比之下，SLM由于参数较少，在计算资源方面更易于访问。像Mistral 7B这样的模型可以在配备适度GPU能力的本地机器上进行训练和运行，尽管训练仍需要在多个GPU上花费数小时。

**偏见**

偏见是LLM的一个已知问题，主要是由于训练数据的性质。这些模型通常依赖于来自互联网的原始、公开可用的数据，这些数据可能会低估或误导某些群体，引入错误的标记，或反映受方言、地理变异和语法规则影响的语言偏见。此外，LLM架构的复杂性可能会无意中加剧偏见，如果没有仔细的微调，这种偏见可能会被忽视。另一方面，SLM由于在更受限、领域特定的数据集上进行训练，本质上对这种偏见不太敏感，尽管它们也不是完全免疫的。

**推理**

SLM的规模较小使其在推理速度方面具有显著优势，允许它们在本地硬件上高效生成输出，而无需广泛的并行处理。相比之下，LLM由于其规模和复杂性，通常需要大量的并行计算资源才能实现可接受的推理时间。当在大规模部署时，多个并发用户的存在进一步减慢了LLM的响应时间。

总之，虽然LLM和SLM在机器学习上有共同的基础，但在模型规模、资源需求、上下文理解、偏见的易感性和推理速度方面有显著差异。这些区别反映了它们在不同用例中的适用性，LLM更具多功能性但资源密集，而SLM在领域特定效率方面提供了更少的计算需求。

***注意：在本章中，我们将以微软Phi-3 / 3.5为例介绍SLM。***

## 介绍Phi-3 / Phi-3.5系列

Phi-3 / 3.5系列主要针对文本、视觉和代理（MoE）应用场景：

### Phi-3 / 3.5 指导

主要用于文本生成、聊天完成和内容信息提取等。

**Phi-3-mini**

3.8B语言模型可在Microsoft Azure AI Studio、Hugging Face和Ollama上使用。Phi-3模型在关键基准测试中显著超越相同和更大规模的语言模型（参见下面的基准测试数据，数字越高越好）。Phi-3-mini在规模上超过了比它大两倍的模型，而Phi-3-small和Phi-3-medium则超过了更大的模型，包括GPT-3.5。

**Phi-3-small & medium**

仅凭70亿个参数，Phi-3-small在各种语言、推理、编码和数学基准测试中击败了GPT-3.5T。具有140亿个参数的Phi-3-medium继续这一趋势，并超过了Gemini 1.0 Pro。

**Phi-3.5-mini**

我们可以将其视为Phi-3-mini的升级版。虽然参数保持不变，但它提高了对多种语言的支持能力（支持20多种语言：阿拉伯语、中文、捷克语、丹麦语、荷兰语、英语、芬兰语、法语、德语、希伯来语、匈牙利语、意大利语、日语、韩语、挪威语、波兰语、葡萄牙语、俄语、西班牙语、瑞典语、泰语、土耳其语、乌克兰语）并增加了对长上下文的更强支持。Phi-3.5-mini以3.8B参数超越了相同规模的语言模型，并与规模两倍的模型相当。

### Phi-3 / 3.5 视觉

我们可以将Phi-3/3.5的指导模型视为Phi的理解能力，而视觉则赋予Phi理解世界的眼睛。

**Phi-3-Vision**

Phi-3-vision仅有4.2B参数，继续这一趋势，在一般视觉推理任务、OCR、表格和图表理解任务中超过了更大的模型，如Claude-3 Haiku和Gemini 1.0 Pro V。

**Phi-3.5-Vision**

Phi-3.5-Vision也是Phi-3-Vision的升级版，增加了对多张图像的支持。你可以将其视为视觉的改进，不仅可以看到图片，还可以看到视频。Phi-3.5-vision在OCR、表格和图表理解任务中超过了更大的模型，如Claude-3.5 Sonnet和Gemini 1.5 Flash，并在一般视觉知识推理任务中表现相当。支持多帧输入，即对多个输入图像进行推理。

### Phi-3.5-MoE

***专家混合（MoE）***使模型可以用更少的计算进行预训练，这意味着可以在与密集模型相同的计算预算下显著扩大模型或数据集的规模。特别是，MoE模型在预训练期间应该比其密集对手更快地达到相同的质量。Phi-3.5-MoE包含16x3.8B专家模块。Phi-3.5-MoE仅用6.6B活跃参数实现了与更大模型相当的推理、语言理解和数学水平。

我们可以根据不同场景使用Phi-3/3.5系列模型。与LLM不同，你可以在边缘设备上部署Phi-3/3.5-mini或Phi-3/3.5-Vision。

## 如何使用Phi-3/3.5系列模型

我们希望在不同场景中使用Phi-3/3.5。接下来，我们将在不同场景中使用Phi-3/3.5。

![phi3](../../../translated_images/phi3.png?WT.0d1077c4470f7b6eef536aba4426fa8df26762844164cc3883d455ab5251bad1.zh.mc_id=academic-105485-koreyst)

### 推理差异

云的API

**GitHub模型**

GitHub模型
```



**免责声明**：  
本文件使用基于机器的人工智能翻译服务进行翻译。尽管我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。应将原始文件的母语版本视为权威来源。对于关键信息，建议进行专业的人类翻译。对于因使用本翻译而引起的任何误解或误读，我们概不负责。