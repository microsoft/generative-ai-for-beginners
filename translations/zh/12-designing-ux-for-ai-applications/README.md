# 为 AI 应用设计用户体验

[![为 AI 应用设计用户体验](../../../translated_images/12-lesson-banner.png?WT.998ee992c9acfb5c1b2802fb3817b9a1a704886f30157b28dff34cd9c2ee598b.zh.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson12-gh?WT.mc_id=academic-105485-koreyst)

> _(点击上面的图片观看本课的视频)_

用户体验是构建应用程序时非常重要的一个方面。用户需要能够高效地使用您的应用来执行任务。高效是一方面，您还需要设计应用以便所有人都能使用，使其具有_可访问性_。本章将重点关注这一领域，希望您最终能够设计出人们能够并愿意使用的应用。

## 介绍

用户体验是用户如何与特定产品或服务（无论是系统、工具还是设计）进行互动和使用。在开发 AI 应用时，开发人员不仅关注确保用户体验的有效性，还关注其道德性。在本课中，我们将介绍如何构建满足用户需求的人工智能 (AI) 应用。

本课将涵盖以下几个方面：

- 用户体验简介及理解用户需求
- 为信任和透明度设计 AI 应用
- 为协作和反馈设计 AI 应用

## 学习目标

完成本课后，您将能够：

- 理解如何构建满足用户需求的 AI 应用。
- 设计促进信任与协作的 AI 应用。

### 前提条件

花些时间阅读更多关于[用户体验和设计思维](https://learn.microsoft.com/training/modules/ux-design?WT.mc_id=academic-105485-koreyst)的内容。

## 用户体验简介及理解用户需求

在我们虚构的教育初创公司中，我们有两个主要用户：教师和学生。每个用户都有独特的需求。以用户为中心的设计优先考虑用户，确保产品对其目标用户是相关且有益的。

应用应当**有用、可靠、可访问且令人愉悦**，以提供良好的用户体验。

### 可用性

有用意味着应用具有与其预期目的相匹配的功能，例如自动化评分过程或生成用于复习的闪卡。自动化评分过程的应用应能够根据预定义标准准确且高效地为学生作业评分。同样，生成复习闪卡的应用应能够基于其数据创建相关且多样的问题。

### 可靠性

可靠意味着应用能够一致且无误地执行其任务。然而，AI 像人类一样并不完美，可能会出现错误。应用可能会遇到需要人工干预或纠正的错误或意外情况。您如何处理错误？在本课的最后一节中，我们将介绍如何为协作和反馈设计 AI 系统和应用。

### 可访问性

可访问性意味着将用户体验扩展到各种能力的用户，包括那些有残疾的用户，确保没有人被遗漏。通过遵循可访问性指南和原则，AI 解决方案变得更加包容、可用且对所有用户有益。

### 令人愉悦

令人愉悦意味着应用使用起来令人愉快。吸引人的用户体验可以对用户产生积极影响，鼓励他们返回应用并增加业务收入。

![展示 AI 中 UX 考虑因素的图像](../../../translated_images/uxinai.png?WT.00d77ed86b53127e3860f8ee713e684370fe08c450c8a1e496beb82e96c59355.zh.mc_id=academic-105485-koreyst)

并非每个挑战都可以用 AI 解决。AI 是来增强您的用户体验的，无论是自动化手动任务，还是个性化用户体验。

## 为信任和透明度设计 AI 应用

在设计 AI 应用时，建立信任至关重要。信任确保用户相信应用能够完成工作、始终如一地交付结果，并且结果是用户所需的。该领域的一个风险是缺乏信任和过度信任。缺乏信任发生在用户对 AI 系统没有信任时，这会导致用户拒绝您的应用。过度信任发生在用户高估 AI 系统的能力时，导致用户对 AI 系统过于信任。例如，在自动评分系统中，过度信任可能导致教师不仔细检查一些论文，以确保评分系统正常工作。这可能导致学生的成绩不公正或不准确，或错失反馈和改进的机会。

确保信任在设计中占据中心位置的两种方法是可解释性和控制。

### 可解释性

当 AI 帮助做出诸如向下一代传授知识的决策时，教师和家长理解 AI 决策的方式至关重要。这就是可解释性——理解 AI 应用如何做出决策。为可解释性而设计包括添加 AI 应用可以做的事情的示例细节。例如，而不是简单地说"开始使用 AI 教师"，系统可以使用："使用 AI 总结您的笔记以便于复习。"

![一个应用的登录页面，清晰展示了 AI 应用中的可解释性](../../../translated_images/explanability-in-ai.png?WT.e66323dd42a976cd7fb15d79304f70a3d625eac6607ec395311a772915a45ffa.zh.mc_id=academic-105485-koreyst)

另一个例子是 AI 如何使用用户和个人数据。例如，具有学生角色的用户可能会基于其角色受到限制。AI 可能无法透露问题的答案，但可以帮助引导用户思考如何解决问题。

![AI 根据角色回答问题](../../../translated_images/solving-questions.png?WT.f7c41f8c20cb98ec5d456d1e14e7fee2b11b7adc77c23421645a82495b51208d.zh.mc_id=academic-105485-koreyst)

可解释性的最后一个关键部分是简化解释。学生和教师可能不是 AI 专家，因此应用可以或不能做什么的解释应简化并易于理解。

![简化的 AI 功能解释](../../../translated_images/simplified-explanations.png?WT.58904786757a91a1365e98cac5f9088bb16c9241e312463921a9a1733a85adc0.zh.mc_id=academic-105485-koreyst)

### 控制

生成式 AI 创造了 AI 和用户之间的协作，例如，用户可以修改提示以获得不同的结果。此外，一旦生成输出，用户应能够修改结果，从而获得一种控制感。例如，在使用 Bing 时，您可以根据格式、语气和长度定制您的提示。此外，您可以对输出进行更改并修改输出，如下所示：

![Bing 搜索结果，具有修改提示和输出的选项](../../../translated_images/bing1.png?WT.ebdf6777a639acf82cbb61a6fae2357561366cbc515efa7cb3029925f54ffee8.zh.mc_id=academic-105485-koreyst "bing 搜索结果，具有修改提示和输出的选项")

Bing 中的另一个功能是允许用户对应用拥有控制权，即选择加入和退出 AI 使用的数据。对于学校应用，学生可能希望使用他们的笔记以及教师的资源作为复习材料。

![Bing 搜索结果，具有修改提示和输出的选项](../../../translated_images/bing2.png?WT.0ec6611c5476823caf1f85f7e7840435bf6f90c51a6fa40652dc718d8528acae.zh.mc_id=academic-105485-koreyst "bing 搜索结果，具有修改提示和输出的选项")

> 在设计 AI 应用时，有意性是确保用户不过度信任、对其能力设置不切实际期望的关键。做到这一点的一种方法是在提示和结果之间制造摩擦。提醒用户，这只是 AI，而不是一个同类的人。

## 为协作和反馈设计 AI 应用

如前所述，生成式 AI 创造了用户和 AI 之间的协作。大多数互动是用户输入提示，AI 生成输出。如果输出不正确怎么办？如果发生错误，应用如何处理？AI 是否指责用户或花时间解释错误？

AI 应用应内置接收和提供反馈的功能。这不仅有助于 AI 系统改进，还建立了与用户的信任。设计中应包含反馈回路，例如可以是输出上的简单点赞或点踩。

另一种处理方法是清楚地传达系统的功能和局限性。当用户请求超出 AI 能力的内容时，也应有一种处理方法，如下所示。

![提供反馈和处理错误](../../../translated_images/feedback-loops.png?WT.ee4d8df7b207adf073487e9a9617e4f901a404fc4b826152a56435fb5bd32705.zh.mc_id=academic-105485-koreyst)

系统错误在应用中很常见，用户可能需要超出 AI 范围的信息帮助，或者应用可能对用户可以生成摘要的问题/主题数量有限制。例如，训练有有限学科数据的 AI 应用，例如历史和数学，可能无法处理地理问题。为缓解这一问题，AI 系统可以给出如下回应："对不起，我们的产品已使用以下学科的数据进行训练.....，我无法回应您提出的问题。"

AI 应用并不完美，因此，它们难免会犯错误。在设计您的应用时，您应确保为用户反馈和错误处理留出空间，并以简单且易于理解的方式进行。

## 作业

在您迄今为止构建的任何 AI 应用中，考虑在您的应用中实施以下步骤：

- **令人愉悦：** 考虑如何使您的应用更令人愉悦。您是否在每个地方添加了解释，您是否鼓励用户探索？您如何措辞错误消息？

- **可用性：** 构建一个 Web 应用。确保您的应用既可以通过鼠标又可以通过键盘导航。

- **信任与透明度：** 不要完全信任 AI 及其输出，考虑如何在过程中添加人工以验证输出。还要考虑并实施其他方法来实现信任与透明度。

- **控制：** 给予用户对他们提供给应用的数据的控制权。实施一种方式，使用户可以选择加入和退出 AI 应用中的数据收集。

## 继续学习！

完成本课后，请查看我们的[生成式 AI 学习合集](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)，继续提升您的生成式 AI 知识！

前往第 13 课，我们将探讨如何[保护 AI 应用](../13-securing-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)！

**免责声明**：
本文档使用机器翻译服务进行了翻译。尽管我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。应将原始语言的文档视为权威来源。对于关键信息，建议使用专业人工翻译。对于因使用本翻译而产生的任何误解或误释，我们不承担责任。