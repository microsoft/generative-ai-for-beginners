[![开源模型](../../../translated_images/18-lesson-banner.png?WT.73626ba24f59a39704c5137a18c9de8b23179ea0e1ace42c97e02f0310adcee0.zh.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# 微调您的大型语言模型

使用大型语言模型来构建生成式AI应用程序带来了新的挑战。一个关键问题是确保模型对用户请求生成的内容的响应质量（准确性和相关性）。在之前的课程中，我们讨论了通过_修改现有模型的提示输入_来解决问题的技术，如提示工程和检索增强生成。

在今天的课程中，我们讨论第三种技术，**微调**，它通过_用额外的数据重新训练模型本身_来解决这个挑战。让我们深入了解细节。

## 学习目标

本课程介绍了预训练语言模型的微调概念，探讨了这种方法的优缺点，并提供了何时以及如何使用微调来提高生成式AI模型性能的指导。

在本课程结束时，您应该能够回答以下问题：

- 什么是语言模型的微调？
- 微调何时以及为何有用？
- 我如何微调一个预训练模型？
- 微调的局限性是什么？

准备好了吗？让我们开始吧。

## 插图指南

想在深入学习之前了解我们将要覆盖的内容吗？查看这个插图指南，它描述了本课程的学习旅程——从学习微调的核心概念和动机，到理解执行微调任务的过程和最佳实践。这是一个值得探索的有趣话题，所以不要忘记查看[资源](./RESOURCES.md?WT.mc_id=academic-105485-koreyst)页面以获取更多支持您自学的链接！

![语言模型微调插图指南](../../../translated_images/18-fine-tuning-sketchnote.png?WT.6cca0798e805b67b1f22beaba7478f40066f3a2879380a0e27dbc70ac1dc7832.zh.mc_id=academic-105485-koreyst)

## 什么是语言模型的微调？

从定义上讲，大型语言模型是从包括互联网在内的多种来源的大量文本中_预训练_的。正如我们在之前的课程中所了解到的，我们需要诸如_提示工程_和_检索增强生成_之类的技术来提高模型对用户问题（“提示”）的响应质量。

一种流行的提示工程技术是通过提供_指令_（明确指导）或_给出几个示例_（隐性指导）来为模型提供更多关于期望响应的指导。这被称为_少样本学习_，但它有两个限制：

- 模型的token限制可能会限制您可以提供的示例数量，并限制其有效性。
- 模型的token成本可能会使每个提示添加示例变得昂贵，并限制灵活性。

微调是机器学习系统中一种常见的做法，我们采用一个预训练模型并用新数据重新训练它，以提高其在特定任务上的性能。在语言模型的背景下，我们可以通过_为给定任务或应用领域准备的一组示例_微调预训练模型，以创建一个可能对该特定任务或领域更准确和相关的**自定义模型**。微调的一个附带好处是它还可以减少少样本学习所需的示例数量，从而减少token使用和相关成本。

## 何时以及为何我们应该微调模型？

在_这个_背景下，当我们谈论微调时，我们指的是**监督**微调，其中通过**添加新数据**（这些数据不属于原始训练数据集）来进行重新训练。这不同于无监督微调方法，后者是在原始数据上重新训练模型，但使用不同的超参数。

需要记住的关键是，微调是一种高级技术，需要一定水平的专业知识才能获得预期的结果。如果操作不当，可能无法提供预期的改进，甚至可能降低目标领域模型的性能。

因此，在您学习“如何”微调语言模型之前，您需要知道“为什么”您应该选择这条路线，以及“何时”开始微调过程。首先问自己这些问题：

- **用例**：您的微调_用例_是什么？您希望改进当前预训练模型的哪个方面？
- **替代方案**：您是否尝试过_其他技术_来实现预期结果？使用它们创建一个比较基线。
  - 提示工程：尝试使用相关提示响应示例的少样本提示技术。评估响应质量。
  - 检索增强生成：尝试通过检索您的数据进行查询结果增强提示。评估响应质量。
- **成本**：您是否确定了微调的成本？
  - 可调性——预训练模型是否可供微调？
  - 努力——准备训练数据、评估和改进模型的努力。
  - 计算——运行微调作业和部署微调模型的计算。
  - 数据——访问足够质量的示例以实现微调影响。
- **好处**：您是否确认了微调的好处？
  - 质量——微调模型是否优于基线？
  - 成本——通过简化提示是否减少了token使用？
  - 可扩展性——您能否将基础模型重新用于新领域？

通过回答这些问题，您应该能够决定微调是否是您用例的正确方法。理想情况下，只有当收益超过成本时，该方法才是有效的。一旦您决定继续，就该考虑_如何_微调预训练模型。

想获得更多关于决策过程的见解吗？观看[是否要微调](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## 我们如何微调一个预训练模型？

要微调一个预训练模型，您需要具备：

- 一个要微调的预训练模型
- 一个用于微调的数据集
- 一个运行微调作业的训练环境
- 一个部署微调模型的托管环境

## 微调实战

以下资源提供了逐步教程，引导您通过使用精选模型和精心准备的数据集的真实示例。要完成这些教程，您需要在特定提供商处拥有一个账户，并访问相关模型和数据集。

| 提供商       | 教程                                                                                                                                                                       | 描述                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [如何微调聊天模型](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                       | 学习如何通过准备训练数据、运行微调作业以及使用微调模型进行推理来微调一个`gpt-35-turbo`以适应特定领域（“食谱助手”）。                                                                                                                                                                                                                                                  |
| Azure OpenAI | [GPT 3.5 Turbo 微调教程](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst)        | 学习如何通过采取步骤创建和上传训练数据、运行微调作业来**在Azure上**微调一个`gpt-35-turbo-0613`模型。部署并使用新模型。                                                                                                                                                                                                                                                                   |
| Hugging Face | [使用Hugging Face微调LLM](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                                     | 这篇博文引导您使用[transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst)库和[Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst])以及开放数据集在Hugging Face上微调一个_开放LLM_（例如：`CodeLlama 7B`）。 |
|              |                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                            |
| 🤗 AutoTrain | [使用AutoTrain微调LLM](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                               | AutoTrain（或AutoTrain Advanced）是由Hugging Face开发的一个python库，允许对许多不同任务进行微调，包括LLM微调。AutoTrain是一种无代码解决方案，微调可以在您自己的云中、Hugging Face Spaces上或本地完成。它支持基于Web的GUI、CLI和通过yaml配置文件进行的训练。                                                                                              |
|              |                                                                                                                                                                          |                                                                                                                                                                                                                                                                                                                                                                                                                            |

## 作业

选择上面的一个教程并完成它们。_我们可能会在这个repo中以Jupyter Notebooks的形式复制这些教程的一个版本，仅供参考。请直接使用原始来源以获取最新版本_。

## 干得好！继续学习。

完成本课程后，请查看我们的[生成式AI学习集合](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)，继续提升您的生成式AI知识！

恭喜！！您已完成本课程v2系列的最后一课！不要停止学习和构建。**查看[资源](RESOURCES.md?WT.mc_id=academic-105485-koreyst)页面，获取仅针对该主题的额外建议列表。

我们的v1系列课程也已更新了更多的作业和概念。因此，花点时间刷新您的知识——并请[分享您的问题和反馈](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst)，以帮助我们为社区改进这些课程。

**免责声明**：  
本文件是使用机器翻译服务翻译的。尽管我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。应将原始文件的母语版本视为权威来源。对于关键信息，建议使用专业人工翻译。对于因使用本翻译而产生的任何误解或误读，我们概不负责。