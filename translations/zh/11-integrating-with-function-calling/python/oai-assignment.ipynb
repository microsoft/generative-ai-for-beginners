{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介绍\n",
    "\n",
    "本课将涵盖：\n",
    "- 什么是函数调用及其使用场景\n",
    "- 如何使用 OpenAI 创建函数调用\n",
    "- 如何将函数调用集成到应用程序中\n",
    "\n",
    "## 学习目标\n",
    "\n",
    "完成本课后，您将了解并掌握：\n",
    "\n",
    "- 使用函数调用的目的\n",
    "- 使用 OpenAI 服务设置函数调用\n",
    "- 为您的应用场景设计有效的函数调用\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理解函数调用\n",
    "\n",
    "在本课中，我们希望为我们的教育初创公司构建一个功能，允许用户使用聊天机器人查找技术课程。我们将推荐适合他们技能水平、当前角色和感兴趣技术的课程。\n",
    "\n",
    "为完成此任务，我们将结合使用：\n",
    " - `OpenAI` 为用户创建聊天体验\n",
    " - `Microsoft Learn Catalog API` 帮助用户根据请求查找课程\n",
    " - `Function Calling` 将用户的查询发送到函数以进行 API 请求。\n",
    "\n",
    "首先，让我们看看为什么我们首先要使用函数调用：\n",
    "\n",
    "print(\"下一次请求中的消息：\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # 从 GPT 获取一个新响应，它可以看到函数响应\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 为什么使用函数调用\n",
    "\n",
    "如果你已经完成了本课程中的其他任何课程，你可能已经理解了使用大型语言模型（LLMs）的强大功能。希望你也能看到它们的一些局限性。\n",
    "\n",
    "函数调用是 OpenAI 服务的一个功能，旨在解决以下挑战：\n",
    "\n",
    "响应格式不一致：\n",
    "- 在函数调用之前，大型语言模型的响应是无结构且不一致的。开发者不得不编写复杂的验证代码来处理输出中的每种变体。\n",
    "\n",
    "与外部数据集成有限：\n",
    "- 在此功能之前，很难将应用程序其他部分的数据整合到聊天上下文中。\n",
    "\n",
    "通过标准化响应格式并实现与外部数据的无缝集成，函数调用简化了开发过程，减少了额外验证逻辑的需求。\n",
    "\n",
    "用户无法获得诸如“斯德哥尔摩当前天气如何？”之类的答案。这是因为模型的知识仅限于训练数据的时间范围。\n",
    "\n",
    "让我们看下面的示例来说明这个问题：\n",
    "\n",
    "假设我们想创建一个学生数据数据库，以便为他们推荐合适的课程。下面我们有两个学生的描述，它们在包含的数据上非常相似。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们想将此发送给大型语言模型（LLM）以解析数据。稍后可以在我们的应用程序中使用这些数据，将其发送到API或存储在数据库中。\n",
    "\n",
    "让我们创建两个相同的提示，指示LLM我们感兴趣的信息：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们想将此发送给大型语言模型（LLM），以解析对我们的产品重要的部分。因此，我们可以创建两个相同的提示来指导LLM：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在创建这两个提示后，我们将使用 `openai.ChatCompletion` 将它们发送给大型语言模型（LLM）。我们将提示存储在 `messages` 变量中，并将角色分配为 `user`。这是为了模拟用户向聊天机器人发送消息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以将这两个请求发送给大型语言模型（LLM），并检查我们收到的响应。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "尽管提示相同且描述类似，我们仍然可能得到不同格式的 `Grades` 属性。\n",
    "\n",
    "如果多次运行上述单元格，格式可能是 `3.7` 或 `3.7 GPA`。\n",
    "\n",
    "这是因为大语言模型接收的是以书面提示形式存在的非结构化数据，并且返回的也是非结构化数据。我们需要一个结构化的格式，以便在存储或使用这些数据时知道预期的内容。\n",
    "\n",
    "通过使用函数调用，我们可以确保收到结构化的数据。使用函数调用时，LLM 实际上并不会调用或运行任何函数。相反，我们为 LLM 创建一个结构，供其响应时遵循。然后，我们使用这些结构化的响应来确定在我们的应用程序中运行哪个函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![函数调用流程图](../../../../translated_images/Function-Flow.083875364af4f4bb.zh.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后我们可以将函数返回的内容发送回大型语言模型（LLM）。LLM随后将使用自然语言来回答用户的查询。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用函数调用的用例\n",
    "\n",
    "**调用外部工具**  \n",
    "聊天机器人非常擅长为用户的问题提供答案。通过使用函数调用，聊天机器人可以利用用户的消息来完成某些任务。例如，学生可以请求聊天机器人“给我的导师发送电子邮件，说我需要更多关于这门课程的帮助”。这可以调用函数 `send_email(to: string, body: string)`\n",
    "\n",
    "**创建 API 或数据库查询**  \n",
    "用户可以使用自然语言查找信息，这些信息会被转换成格式化的查询或 API 请求。一个例子是老师请求“谁完成了上一次作业”，这可以调用名为 `get_completed(student_name: string, assignment: int, current_status: string)` 的函数\n",
    "\n",
    "**创建结构化数据**  \n",
    "用户可以将一段文本或 CSV 文件交给大语言模型，从中提取重要信息。例如，学生可以将一篇关于和平协议的维基百科文章转换成 AI 闪卡。这可以通过调用函数 `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` 来完成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 创建您的第一个函数调用\n",
    "\n",
    "创建函数调用的过程包括三个主要步骤：\n",
    "1. 使用您的函数列表和用户消息调用 Chat Completions API\n",
    "2. 读取模型的响应以执行操作，即执行函数或 API 调用\n",
    "3. 使用函数的响应再次调用 Chat Completions API，利用该信息创建对用户的响应。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![函数调用流程](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.zh.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函数调用的元素\n",
    "\n",
    "#### 用户输入\n",
    "\n",
    "第一步是创建一个用户消息。这可以通过获取文本输入的值动态分配，或者你可以在这里分配一个值。如果这是你第一次使用聊天补全 API，我们需要定义消息的 `role` 和 `content`。\n",
    "\n",
    "`role` 可以是 `system`（创建规则）、`assistant`（模型）或 `user`（最终用户）。对于函数调用，我们将其分配为 `user` 并给出一个示例问题。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 创建函数。\n",
    "\n",
    "接下来我们将定义一个函数及该函数的参数。这里我们只使用一个名为 `search_courses` 的函数，但你可以创建多个函数。\n",
    "\n",
    "**重要**：函数包含在发送给大型语言模型的系统消息中，并且会计入你可用的令牌数量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定义**\n",
    "\n",
    "函数定义结构有多个层级，每个层级都有其自身的属性。以下是嵌套结构的详细说明：\n",
    "\n",
    "**顶层函数属性：**\n",
    "\n",
    "`name` - 我们希望调用的函数名称。\n",
    "\n",
    "`description` - 这是函数的工作描述。在这里，明确和具体非常重要。\n",
    "\n",
    "`parameters` - 你希望模型在响应中生成的值和格式的列表。\n",
    "\n",
    "**参数对象属性：**\n",
    "\n",
    "`type` - 参数对象的数据类型（通常是 \"object\"）\n",
    "\n",
    "`properties` - 模型将在响应中使用的具体值列表。\n",
    "\n",
    "**单个参数属性：**\n",
    "\n",
    "`name` - 由属性键隐式定义（例如 \"role\"、\"product\"、\"level\"）\n",
    "\n",
    "`type` - 该具体参数的数据类型（例如 \"string\"、\"number\"、\"boolean\"）\n",
    "\n",
    "`description` - 该具体参数的描述。\n",
    "\n",
    "**可选属性：**\n",
    "\n",
    "`required` - 列出哪些参数是完成函数调用所必需的数组。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 调用函数  \n",
    "定义函数后，我们现在需要在调用 Chat Completion API 时包含它。我们通过向请求中添加 `functions` 来实现。在本例中为 `functions=functions`。\n",
    "\n",
    "还有一个选项是将 `function_call` 设置为 `auto`。这意味着我们将让 LLM 根据用户消息决定调用哪个函数，而不是自己指定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在让我们来看一下响应以及它是如何格式化的：\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "你可以看到函数的名称被调用了，并且从用户消息中，LLM能够找到数据来匹配函数的参数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.将函数调用集成到应用程序中。\n",
    "\n",
    "在我们测试了来自大型语言模型的格式化响应之后，现在可以将其集成到应用程序中。\n",
    "\n",
    "### 管理流程\n",
    "\n",
    "为了将其集成到我们的应用程序中，让我们采取以下步骤：\n",
    "\n",
    "首先，让我们调用 OpenAI 服务并将消息存储在名为 `response_message` 的变量中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们将定义一个函数，该函数将调用 Microsoft Learn API 以获取课程列表：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作为最佳实践，我们将首先查看模型是否想调用某个函数。之后，我们将创建一个可用的函数，并将其与被调用的函数进行匹配。  \n",
    "然后，我们将获取该函数的参数，并将其映射到来自LLM的参数。  \n",
    "\n",
    "最后，我们将附加函数调用消息以及由`search_courses`消息返回的值。这为LLM提供了所有所需的信息，以便使用自然语言响应用户。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们将发送更新后的消息给大型语言模型，以便我们可以收到自然语言的回复，而不是API的JSON格式回复。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 代码挑战\n",
    "\n",
    "干得好！为了继续学习 OpenAI 函数调用，你可以构建：https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    "- 函数的更多参数，可能帮助学习者找到更多课程。你可以在这里找到可用的 API 参数：  \n",
    "- 创建另一个函数调用，获取学习者的更多信息，比如他们的母语  \n",
    "- 当函数调用和/或 API 调用未返回任何合适的课程时，创建错误处理机制\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免责声明**：  \n本文件由人工智能翻译服务 [Co-op Translator](https://github.com/Azure/co-op-translator) 翻译而成。尽管我们力求准确，但请注意自动翻译可能存在错误或不准确之处。原始语言的文档应被视为权威来源。对于重要信息，建议使用专业人工翻译。因使用本翻译而产生的任何误解或误释，我们概不负责。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T09:08:16+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "zh"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}