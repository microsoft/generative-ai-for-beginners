# 负责任地使用生成式 AI

[![负责任地使用生成式 AI](../../../translated_images/03-lesson-banner.png?WT.b0b917735411b39a55748e827c5c3121004890110b27f306bfe685c450c81ff9.zh.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _点击上面的图片观看本课视频_

对 AI，尤其是生成式 AI 感到着迷是很容易的，但你需要考虑如何负责任地使用它。你需要考虑如何确保输出是公平的、无害的等等。本章旨在为你提供上述背景、需要考虑的因素以及如何采取积极措施来改善你的 AI 使用。

## 介绍

本课将涵盖：

- 为什么在构建生成式 AI 应用程序时应优先考虑负责任的 AI。
- 负责任 AI 的核心原则以及它们如何与生成式 AI 相关。
- 如何通过策略和工具将这些负责任 AI 的原则付诸实践。

## 学习目标

完成本课后，你将了解：

- 在构建生成式 AI 应用程序时，负责任 AI 的重要性。
- 在构建生成式 AI 应用程序时，何时思考和应用负责任 AI 的核心原则。
- 可用的工具和策略，以将负责任 AI 的概念付诸实践。

## 负责任 AI 的原则

生成式 AI 的兴奋程度前所未有。这种兴奋为该领域带来了许多新的开发者、关注和资金。虽然这对任何希望使用生成式 AI 构建产品和公司的人来说都是非常积极的，但我们也需要以负责任的态度前进。

在整个课程中，我们专注于构建我们的初创公司和我们的 AI 教育产品。我们将使用负责任 AI 的原则：公平性、包容性、可靠性/安全性、安全性和隐私、透明性和责任制。通过这些原则，我们将探讨它们如何与我们在产品中使用生成式 AI 相关。

## 为什么要优先考虑负责任的 AI

在构建产品时，采取以人为本的方法，牢记用户的最大利益，会带来最佳结果。

生成式 AI 的独特之处在于其为用户创建有用答案、信息、指导和内容的能力。这可以在没有许多手动步骤的情况下完成，从而带来非常令人印象深刻的结果。但如果没有适当的计划和策略，也可能不幸地导致对用户、产品和整个社会的某些有害结果。

让我们来看一些（但不是全部）这些潜在的有害结果：

### 幻觉

幻觉是一个术语，用来描述当 LLM 生成的内容完全无意义或根据其他信息来源我们知道是事实错误的内容。

例如，我们为初创公司构建了一个功能，允许学生向模型提问历史问题。一名学生提问 `Who was the sole survivor of Titanic?`

模型生成如下响应：

![提示“谁是泰坦尼克号的唯一幸存者”](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(来源：[Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

这是一个非常自信且详尽的答案。不幸的是，它是错误的。即使进行最少量的研究，也会发现泰坦尼克号灾难中不止一名幸存者。对于刚开始研究该主题的学生来说，这个答案可能足够有说服力，不会被质疑并被视为事实。这可能导致 AI 系统不可靠，并对我们初创公司的声誉产生负面影响。

随着任何给定 LLM 的每次迭代，我们已经看到在减少幻觉方面的性能改进。即使有这种改进，作为应用程序构建者和用户，我们仍然需要意识到这些限制。

### 有害内容

我们在前一节中讨论了当 LLM 生成不正确或无意义的响应时。我们还需要注意的另一个风险是当模型响应有害内容时。

有害内容可以定义为：

- 提供自我伤害或伤害特定群体的指示或鼓励。
- 仇恨或贬低的内容。
- 指导计划任何类型的攻击或暴力行为。
- 提供查找非法内容或实施非法行为的指示。
- 显示色情内容。

对于我们的初创公司，我们希望确保我们有适当的工具和策略来防止学生看到此类内容。

### 缺乏公平性

公平性被定义为“确保 AI 系统没有偏见和歧视，并且对每个人都公平和平等。”在生成式 AI 的世界中，我们希望确保被边缘化群体的排他性世界观不会被模型的输出所强化。

这些类型的输出不仅对构建积极的用户产品体验有破坏性，而且还会造成进一步的社会危害。作为应用程序构建者，我们在使用生成式 AI 构建解决方案时应始终考虑广泛和多样化的用户群体。

## 如何负责任地使用生成式 AI

现在我们已经确定了负责任生成式 AI 的重要性，让我们来看一下我们可以采取的 4 个步骤，以负责任地构建我们的 AI 解决方案：

![减轻周期](../../../translated_images/mitigate-cycle.png?WT.ffc987e1880649a302a311432b78f49faa64e46f65df6350c9c409b5ed79549b.zh.mc_id=academic-105485-koreyst)

### 衡量潜在危害

在软件测试中，我们测试用户在应用程序上的预期操作。类似地，测试用户最有可能使用的多样化提示集是衡量潜在危害的好方法。

由于我们的初创公司正在构建一个教育产品，准备一个与教育相关的提示列表是个好主意。这可以涵盖某个学科、历史事实以及关于学生生活的提示。

### 减轻潜在危害

现在是时候找出我们可以在哪里防止或限制模型及其响应所造成的潜在危害。我们可以从 4 个不同层面来看待这一点：

![减轻层](../../../translated_images/mitigation-layers.png?WT.cb109f48e143f1ff4dee760b4b0c9477c7d11c2fe57f3efdd89f68c1109f2de6.zh.mc_id=academic-105485-koreyst)

- **模型**。为正确的用例选择合适的模型。像 GPT-4 这样更大更复杂的模型在应用于较小和更具体的用例时，可能会导致更高的有害内容风险。使用你的训练数据进行微调也可以降低有害内容的风险。

- **安全系统**。安全系统是一个工具和配置集，用于服务模型的平台上，以帮助减轻危害。Azure OpenAI 服务上的内容过滤系统就是一个例子。系统还应该检测越狱攻击和不需要的活动，例如来自机器人的请求。

- **元提示**。元提示和基础是我们可以根据某些行为和信息引导或限制模型的方法。这可以是使用系统输入来定义模型的某些限制。此外，提供与系统范围或领域更相关的输出。

也可以使用检索增强生成（RAG）等技术，让模型仅从一组选定的可信来源中提取信息。本课程稍后会有一个关于[构建搜索应用程序](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)的课程。

- **用户体验**。最后一层是用户通过我们的应用程序界面以某种方式直接与模型交互。在这种方式中，我们可以设计 UI/UX 来限制用户可以发送给模型的输入类型以及显示给用户的文本或图像。在部署 AI 应用程序时，我们还必须透明地说明我们的生成式 AI 应用程序可以和不能做什么。

我们有一个专门的课程来[设计 AI 应用程序的 UX](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)。

- **评估模型**。与 LLMs 合作可能具有挑战性，因为我们并不总是能够控制模型所训练的数据。无论如何，我们应该始终评估模型的性能和输出。衡量模型输出的准确性、相似性、基础性和相关性仍然很重要。这有助于为利益相关者和用户提供透明性和信任。

### 运营负责任的生成式 AI 解决方案

围绕你的 AI 应用程序构建运营实践是最后阶段。这包括与我们初创公司的其他部分（如法律和安全）合作，以确保我们符合所有监管政策。在发布之前，我们还希望围绕交付、处理事件和回滚制定计划，以防止用户受到任何伤害。

## 工具

虽然开发负责任 AI 解决方案的工作看起来很多，但这项工作非常值得。随着生成式 AI 领域的增长，帮助开发人员有效地将责任整合到工作流程中的工具也将逐渐成熟。例如，[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) 可以通过 API 请求帮助检测有害内容和图像。

## 知识检查

为了确保负责任的 AI 使用，你需要关心哪些方面？

1. 答案是否正确。
2. 有害使用，确保 AI 不被用于犯罪目的。
3. 确保 AI 没有偏见和歧视。

A：2 和 3 是正确的。负责任的 AI 帮助你考虑如何减轻有害影响和偏见等问题。

## 🚀 挑战

阅读 [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) 并查看你可以采用哪些内容。

## 出色的工作，继续学习

完成本课后，查看我们的 [生成式 AI 学习集合](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)，继续提升你的生成式 AI 知识！

前往第 4 课，我们将探讨 [提示工程基础](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)！

**免责声明**：

本文件是使用机器翻译服务翻译的。虽然我们努力确保准确性，但请注意，自动翻译可能包含错误或不准确之处。应将原始语言的文件视为权威来源。对于关键信息，建议使用专业人工翻译。对于因使用此翻译而引起的任何误解或误读，我们不承担责任。