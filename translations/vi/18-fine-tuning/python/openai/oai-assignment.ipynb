{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tinh Chỉnh Mô Hình Open AI\n",
    "\n",
    "Sổ tay này dựa trên hướng dẫn hiện tại được cung cấp trong tài liệu [Tinh Chỉnh](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) từ Open AI.\n",
    "\n",
    "Tinh chỉnh cải thiện hiệu suất của các mô hình nền tảng cho ứng dụng của bạn bằng cách huấn luyện lại với dữ liệu bổ sung và ngữ cảnh liên quan đến trường hợp sử dụng hoặc kịch bản cụ thể đó. Lưu ý rằng các kỹ thuật thiết kế prompt như _học ít mẫu_ và _tăng cường tạo bằng truy xuất_ cho phép bạn nâng cao prompt mặc định với dữ liệu liên quan để cải thiện chất lượng. Tuy nhiên, các phương pháp này bị giới hạn bởi kích thước cửa sổ token tối đa của mô hình nền tảng mục tiêu.\n",
    "\n",
    "Với tinh chỉnh, chúng ta thực sự đang huấn luyện lại chính mô hình với dữ liệu cần thiết (cho phép chúng ta sử dụng nhiều ví dụ hơn so với những gì có thể chứa trong cửa sổ token tối đa) - và triển khai một phiên bản _tùy chỉnh_ của mô hình mà không còn cần phải cung cấp ví dụ tại thời điểm suy luận. Điều này không chỉ cải thiện hiệu quả thiết kế prompt của chúng ta (chúng ta có nhiều linh hoạt hơn trong việc sử dụng cửa sổ token cho các mục đích khác) mà còn có thể cải thiện chi phí (bằng cách giảm số lượng token cần gửi đến mô hình khi suy luận).\n",
    "\n",
    "Tinh chỉnh có 4 bước:\n",
    "1. Chuẩn bị dữ liệu huấn luyện và tải lên.\n",
    "1. Chạy công việc huấn luyện để có được mô hình đã được tinh chỉnh.\n",
    "1. Đánh giá mô hình đã tinh chỉnh và lặp lại để nâng cao chất lượng.\n",
    "1. Triển khai mô hình đã tinh chỉnh để suy luận khi hài lòng.\n",
    "\n",
    "Lưu ý rằng không phải tất cả các mô hình nền tảng đều hỗ trợ tinh chỉnh - [kiểm tra tài liệu OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) để biết thông tin mới nhất. Bạn cũng có thể tinh chỉnh một mô hình đã được tinh chỉnh trước đó. Trong hướng dẫn này, chúng ta sẽ sử dụng `gpt-35-turbo` làm mô hình nền tảng mục tiêu để tinh chỉnh.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 1.1: Chuẩn bị Bộ Dữ liệu của Bạn\n",
    "\n",
    "Hãy xây dựng một chatbot giúp bạn hiểu bảng tuần hoàn các nguyên tố bằng cách trả lời các câu hỏi về một nguyên tố dưới dạng một bài thơ limerick. Trong _hướng dẫn_ đơn giản này, chúng ta sẽ chỉ tạo một bộ dữ liệu để huấn luyện mô hình với một vài ví dụ mẫu về các phản hồi thể hiện định dạng dữ liệu mong đợi. Trong trường hợp sử dụng thực tế, bạn sẽ cần tạo một bộ dữ liệu với nhiều ví dụ hơn nhiều. Bạn cũng có thể sử dụng một bộ dữ liệu mở (cho lĩnh vực ứng dụng của bạn) nếu có, và định dạng lại để sử dụng trong việc tinh chỉnh.\n",
    "\n",
    "Vì chúng ta tập trung vào `gpt-35-turbo` và tìm kiếm phản hồi một lượt (hoàn thành chat) nên chúng ta có thể tạo các ví dụ sử dụng [định dạng được đề xuất này](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) phản ánh các yêu cầu hoàn thành chat của OpenAI. Nếu bạn mong đợi nội dung hội thoại nhiều lượt, bạn sẽ sử dụng [định dạng ví dụ nhiều lượt](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) bao gồm tham số `weight` để báo hiệu những tin nhắn nào nên được sử dụng (hoặc không) trong quá trình tinh chỉnh.\n",
    "\n",
    "Chúng ta sẽ sử dụng định dạng một lượt đơn giản hơn cho hướng dẫn ở đây. Dữ liệu ở định dạng [jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) với 1 bản ghi trên mỗi dòng, mỗi bản ghi được biểu diễn dưới dạng một đối tượng JSON. Đoạn mã dưới đây hiển thị 2 bản ghi làm ví dụ - xem [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) để xem bộ mẫu đầy đủ (10 ví dụ) mà chúng ta sẽ sử dụng cho hướng dẫn tinh chỉnh. **Lưu ý:** Mỗi bản ghi _phải_ được định nghĩa trên một dòng duy nhất (không chia nhỏ trên nhiều dòng như trong file JSON định dạng thông thường)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Trong trường hợp sử dụng thực tế, bạn sẽ cần một bộ ví dụ lớn hơn nhiều để có kết quả tốt - sự đánh đổi sẽ là giữa chất lượng phản hồi và thời gian/chi phí cho việc tinh chỉnh. Chúng tôi đang sử dụng một bộ nhỏ để có thể hoàn thành việc tinh chỉnh nhanh chóng nhằm minh họa quy trình. Xem [ví dụ trong OpenAI Cookbook này](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) cho một hướng dẫn tinh chỉnh phức tạp hơn.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bước 1.2 Tải lên Bộ dữ liệu của bạn\n",
    "\n",
    "Tải dữ liệu lên bằng cách sử dụng Files API [như được mô tả ở đây](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Lưu ý rằng để chạy được mã này, bạn phải đã thực hiện các bước sau trước:\n",
    " - Cài đặt gói Python `openai` (đảm bảo bạn sử dụng phiên bản >=0.28.0 để có các tính năng mới nhất)\n",
    " - Đặt biến môi trường `OPENAI_API_KEY` thành khóa API OpenAI của bạn\n",
    "Để tìm hiểu thêm, xem [Hướng dẫn cài đặt](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) được cung cấp cho khóa học.\n",
    "\n",
    "Bây giờ, chạy mã để tạo một tệp để tải lên từ tệp JSONL cục bộ của bạn.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bước 2.1: Tạo công việc Fine-tuning với SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bước 2.2: Kiểm tra trạng thái của công việc\n",
    "\n",
    "Dưới đây là một số việc bạn có thể làm với API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Liệt kê n công việc fine-tuning cuối cùng\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Lấy chi tiết của một công việc fine-tuning cụ thể\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Hủy một công việc fine-tuning\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Liệt kê tối đa n sự kiện từ công việc\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Bước đầu tiên của quy trình là _xác thực file đào tạo_ để đảm bảo dữ liệu đúng định dạng.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bước 2.3: Theo dõi sự kiện để giám sát tiến trình\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bước 2.4: Xem trạng thái trong Bảng điều khiển OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn cũng có thể xem trạng thái bằng cách truy cập trang web OpenAI và khám phá phần _Fine-tuning_ của nền tảng. Điều này sẽ hiển thị cho bạn trạng thái của công việc hiện tại, đồng thời cho phép bạn theo dõi lịch sử các lần thực thi công việc trước đó. Trong ảnh chụp màn hình này, bạn có thể thấy rằng lần thực thi trước đã thất bại, và lần chạy thứ hai đã thành công. Để làm rõ, điều này xảy ra khi lần chạy đầu tiên sử dụng một tệp JSON với các bản ghi định dạng sai - sau khi được sửa, lần chạy thứ hai đã hoàn thành thành công và làm cho mô hình có thể sử dụng được.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/vi/fine-tuned-model-status.563271727bf7bfba.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bạn cũng có thể xem các thông báo trạng thái và số liệu bằng cách cuộn xuống thêm trong bảng điều khiển trực quan như hình dưới đây:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/vi/fine-tuned-messages-panel.4ed0c2da5ea1313b.png) |  ![Metrics](../../../../../translated_images/vi/fine-tuned-metrics-panel.700d7e4995a65229.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bước 3.1: Lấy ID & Kiểm tra Mô hình Tinh chỉnh trong Mã nguồn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Bước 3.2: Tải & Kiểm Tra Mô Hình Đã Tinh Chỉnh Trong Playground\n",
    "\n",
    "Bây giờ bạn có thể kiểm tra mô hình đã tinh chỉnh theo hai cách. Đầu tiên, bạn có thể truy cập Playground và sử dụng menu thả xuống Models để chọn mô hình đã tinh chỉnh mới của bạn từ các tùy chọn được liệt kê. Lựa chọn khác là sử dụng tùy chọn \"Playground\" hiển thị trong bảng Fine-tuning (xem ảnh chụp màn hình phía trên) để khởi chạy chế độ xem _so sánh_ sau đây, hiển thị các phiên bản mô hình nền tảng và mô hình đã tinh chỉnh cạnh nhau để đánh giá nhanh.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/vi/fine-tuned-playground-compare.56e06f0ad8922016.png)\n",
    "\n",
    "Chỉ cần điền vào ngữ cảnh hệ thống được sử dụng trong dữ liệu huấn luyện của bạn và cung cấp câu hỏi kiểm tra. Bạn sẽ nhận thấy rằng cả hai bên đều được cập nhật với cùng một ngữ cảnh và câu hỏi giống hệt nhau. Chạy so sánh và bạn sẽ thấy sự khác biệt trong kết quả đầu ra giữa chúng. _Lưu ý cách mô hình đã tinh chỉnh trả lời theo định dạng bạn đã cung cấp trong các ví dụ của mình trong khi mô hình nền tảng chỉ đơn giản theo lời nhắc hệ thống_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/vi/fine-tuned-playground-launch.5a26495c983c6350.png)\n",
    "\n",
    "Bạn sẽ nhận thấy rằng so sánh cũng cung cấp số lượng token cho mỗi mô hình, và thời gian thực hiện suy luận. **Ví dụ cụ thể này là một ví dụ đơn giản nhằm minh họa quy trình nhưng không phản ánh dữ liệu hoặc kịch bản thực tế**. Bạn có thể nhận thấy rằng cả hai mẫu đều hiển thị cùng số lượng token (ngữ cảnh hệ thống và lời nhắc người dùng giống hệt nhau) với mô hình đã tinh chỉnh mất nhiều thời gian hơn để suy luận (mô hình tùy chỉnh).\n",
    "\n",
    "Trong các kịch bản thực tế, bạn sẽ không sử dụng một ví dụ đơn giản như thế này, mà sẽ tinh chỉnh dựa trên dữ liệu thực (ví dụ: danh mục sản phẩm cho dịch vụ khách hàng) nơi chất lượng phản hồi sẽ rõ ràng hơn nhiều. Trong _ngữ cảnh đó_, để có được chất lượng phản hồi tương đương với mô hình nền tảng sẽ đòi hỏi kỹ thuật tạo lời nhắc tùy chỉnh nhiều hơn, điều này sẽ làm tăng việc sử dụng token và có thể tăng thời gian xử lý suy luận liên quan. _Để thử điều này, hãy xem các ví dụ tinh chỉnh trong OpenAI Cookbook để bắt đầu._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Tuyên bố từ chối trách nhiệm**:  \nTài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ gốc của nó nên được coi là nguồn chính xác và đáng tin cậy. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp do con người thực hiện. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc giải thích sai nào phát sinh từ việc sử dụng bản dịch này.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T10:57:16+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "vi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}