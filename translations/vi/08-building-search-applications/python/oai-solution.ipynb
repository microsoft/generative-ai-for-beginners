{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Để chạy các sổ tay sau, nếu bạn chưa làm, bạn cần đặt khóa openai bên trong tệp .env dưới dạng `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, chúng ta sẽ tải Chỉ mục Nhúng vào một Dataframe của Pandas. Chỉ mục Nhúng được lưu trong một tệp JSON có tên là `embedding_index_3m.json`. Chỉ mục Nhúng chứa các Nhúng cho từng bản ghi phụ đề YouTube cho đến cuối tháng 10 năm 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tiếp theo, chúng ta sẽ tạo một hàm gọi là `get_videos` để tìm kiếm trong Chỉ mục Nhúng cho truy vấn. Hàm sẽ trả về 5 video hàng đầu có độ tương đồng cao nhất với truy vấn. Hàm hoạt động như sau:\n",
    "\n",
    "1. Đầu tiên, một bản sao của Chỉ mục Nhúng được tạo ra.\n",
    "2. Tiếp theo, Nhúng cho truy vấn được tính toán bằng cách sử dụng API Nhúng của OpenAI.\n",
    "3. Sau đó, một cột mới được tạo trong Chỉ mục Nhúng gọi là `similarity`. Cột `similarity` chứa độ tương đồng cosine giữa Nhúng truy vấn và Nhúng cho mỗi đoạn video.\n",
    "4. Tiếp theo, Chỉ mục Nhúng được lọc theo cột `similarity`. Chỉ mục Nhúng được lọc để chỉ bao gồm các video có độ tương đồng cosine lớn hơn hoặc bằng 0.75.\n",
    "5. Cuối cùng, Chỉ mục Nhúng được sắp xếp theo cột `similarity` và 5 video hàng đầu được trả về.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hàm này rất đơn giản, nó chỉ in ra kết quả của truy vấn tìm kiếm.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Đầu tiên, Chỉ mục Nhúng được tải vào một Pandas Dataframe.  \n",
    "2. Tiếp theo, người dùng được yêu cầu nhập một truy vấn.  \n",
    "3. Sau đó, hàm `get_videos` được gọi để tìm kiếm Chỉ mục Nhúng theo truy vấn.  \n",
    "4. Cuối cùng, hàm `display_results` được gọi để hiển thị kết quả cho người dùng.  \n",
    "5. Người dùng sau đó được yêu cầu nhập một truy vấn khác. Quá trình này tiếp tục cho đến khi người dùng nhập `exit`.  \n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc.vi.png)  \n",
    "\n",
    "Bạn sẽ được yêu cầu nhập một truy vấn. Nhập một truy vấn và nhấn enter. Ứng dụng sẽ trả về danh sách các video liên quan đến truy vấn. Ứng dụng cũng sẽ trả về một liên kết đến vị trí trong video nơi câu trả lời cho câu hỏi được đặt.  \n",
    "\n",
    "Dưới đây là một số truy vấn để thử:  \n",
    "\n",
    "- Azure Machine Learning là gì?  \n",
    "- Mạng nơ-ron tích chập hoạt động như thế nào?  \n",
    "- Mạng nơ-ron là gì?  \n",
    "- Tôi có thể sử dụng Jupyter Notebooks với Azure Machine Learning không?  \n",
    "- ONNX là gì?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Tuyên bố từ chối trách nhiệm**:  \nTài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ gốc của nó nên được coi là nguồn chính xác và đáng tin cậy. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp do con người thực hiện. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc giải thích sai nào phát sinh từ việc sử dụng bản dịch này.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T10:54:23+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "vi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}