<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-07-09T16:16:18+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "vi"
}
-->
# Retrieval Augmented Generation (RAG) vÃ  CÆ¡ sá»Ÿ dá»¯ liá»‡u Vector

[![Retrieval Augmented Generation (RAG) vÃ  CÆ¡ sá»Ÿ dá»¯ liá»‡u Vector](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.vi.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

Trong bÃ i há»c vá» á»©ng dá»¥ng tÃ¬m kiáº¿m, chÃºng ta Ä‘Ã£ tÃ¬m hiá»ƒu sÆ¡ lÆ°á»£c cÃ¡ch tÃ­ch há»£p dá»¯ liá»‡u cá»§a riÃªng báº¡n vÃ o cÃ¡c MÃ´ hÃ¬nh NgÃ´n ngá»¯ Lá»›n (LLMs). Trong bÃ i há»c nÃ y, chÃºng ta sáº½ Ä‘i sÃ¢u hÆ¡n vÃ o khÃ¡i niá»‡m gáº¯n dá»¯ liá»‡u cá»§a báº¡n vÃ o á»©ng dá»¥ng LLM, cÆ¡ cháº¿ cá»§a quÃ¡ trÃ¬nh nÃ y vÃ  cÃ¡c phÆ°Æ¡ng phÃ¡p lÆ°u trá»¯ dá»¯ liá»‡u, bao gá»“m cáº£ embeddings vÃ  vÄƒn báº£n.

> **Video sáº½ sá»›m ra máº¯t**

## Giá»›i thiá»‡u

Trong bÃ i há»c nÃ y, chÃºng ta sáº½ Ä‘á» cáº­p Ä‘áº¿n:

- Giá»›i thiá»‡u vá» RAG, nÃ³ lÃ  gÃ¬ vÃ  táº¡i sao nÃ³ Ä‘Æ°á»£c sá»­ dá»¥ng trong AI (trÃ­ tuá»‡ nhÃ¢n táº¡o).

- Hiá»ƒu vá» cÆ¡ sá»Ÿ dá»¯ liá»‡u vector lÃ  gÃ¬ vÃ  cÃ¡ch táº¡o má»™t cÆ¡ sá»Ÿ dá»¯ liá»‡u cho á»©ng dá»¥ng cá»§a chÃºng ta.

- VÃ­ dá»¥ thá»±c táº¿ vá» cÃ¡ch tÃ­ch há»£p RAG vÃ o má»™t á»©ng dá»¥ng.

## Má»¥c tiÃªu há»c táº­p

Sau khi hoÃ n thÃ nh bÃ i há»c nÃ y, báº¡n sáº½ cÃ³ thá»ƒ:

- Giáº£i thÃ­ch táº§m quan trá»ng cá»§a RAG trong viá»‡c truy xuáº¥t vÃ  xá»­ lÃ½ dá»¯ liá»‡u.

- Thiáº¿t láº­p á»©ng dá»¥ng RAG vÃ  gáº¯n dá»¯ liá»‡u cá»§a báº¡n vÃ o LLM.

- TÃ­ch há»£p hiá»‡u quáº£ RAG vÃ  CÆ¡ sá»Ÿ dá»¯ liá»‡u Vector trong cÃ¡c á»©ng dá»¥ng LLM.

## Ká»‹ch báº£n cá»§a chÃºng ta: nÃ¢ng cao LLM vá»›i dá»¯ liá»‡u riÃªng

Trong bÃ i há»c nÃ y, chÃºng ta muá»‘n thÃªm cÃ¡c ghi chÃº cá»§a riÃªng mÃ¬nh vÃ o startup giÃ¡o dá»¥c, giÃºp chatbot cÃ³ thÃªm thÃ´ng tin vá» cÃ¡c mÃ´n há»c khÃ¡c nhau. Sá»­ dá»¥ng cÃ¡c ghi chÃº nÃ y, ngÆ°á»i há»c sáº½ cÃ³ thá»ƒ há»c tá»‘t hÆ¡n vÃ  hiá»ƒu rÃµ cÃ¡c chá»§ Ä‘á», giÃºp viá»‡c Ã´n táº­p cho ká»³ thi trá»Ÿ nÃªn dá»… dÃ ng hÆ¡n. Äá»ƒ táº¡o ká»‹ch báº£n nÃ y, chÃºng ta sáº½ sá»­ dá»¥ng:

- `Azure OpenAI:` LLM mÃ  chÃºng ta sáº½ dÃ¹ng Ä‘á»ƒ táº¡o chatbot

- `BÃ i há»c AI cho ngÆ°á»i má»›i báº¯t Ä‘áº§u vá» Máº¡ng Neural:` Ä‘Ã¢y sáº½ lÃ  dá»¯ liá»‡u Ä‘á»ƒ gáº¯n vÃ o LLM cá»§a chÃºng ta

- `Azure AI Search` vÃ  `Azure Cosmos DB:` cÆ¡ sá»Ÿ dá»¯ liá»‡u vector Ä‘á»ƒ lÆ°u trá»¯ dá»¯ liá»‡u vÃ  táº¡o chá»‰ má»¥c tÃ¬m kiáº¿m

NgÆ°á»i dÃ¹ng sáº½ cÃ³ thá»ƒ táº¡o cÃ¡c bÃ i kiá»ƒm tra thá»±c hÃ nh tá»« ghi chÃº, tháº» Ã´n táº­p vÃ  tÃ³m táº¯t thÃ nh cÃ¡c báº£n tá»•ng quan ngáº¯n gá»n. Äá»ƒ báº¯t Ä‘áº§u, hÃ£y cÃ¹ng tÃ¬m hiá»ƒu RAG lÃ  gÃ¬ vÃ  cÃ¡ch nÃ³ hoáº¡t Ä‘á»™ng:

## Retrieval Augmented Generation (RAG)

Chatbot Ä‘Æ°á»£c há»— trá»£ bá»Ÿi LLM xá»­ lÃ½ cÃ¡c cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng Ä‘á»ƒ táº¡o ra cÃ¢u tráº£ lá»i. NÃ³ Ä‘Æ°á»£c thiáº¿t káº¿ Ä‘á»ƒ tÆ°Æ¡ng tÃ¡c vÃ  trao Ä‘á»•i vá»›i ngÆ°á»i dÃ¹ng vá» nhiá»u chá»§ Ä‘á» khÃ¡c nhau. Tuy nhiÃªn, cÃ¢u tráº£ lá»i cá»§a nÃ³ bá»‹ giá»›i háº¡n trong ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p vÃ  dá»¯ liá»‡u Ä‘Ã o táº¡o ná»n táº£ng. VÃ­ dá»¥, GPT-4 cÃ³ kiáº¿n thá»©c cáº­p nháº­t Ä‘áº¿n thÃ¡ng 9 nÄƒm 2021, nghÄ©a lÃ  nÃ³ khÃ´ng biáº¿t vá» cÃ¡c sá»± kiá»‡n xáº£y ra sau thá»i Ä‘iá»ƒm Ä‘Ã³. ThÃªm vÃ o Ä‘Ã³, dá»¯ liá»‡u dÃ¹ng Ä‘á»ƒ Ä‘Ã o táº¡o LLM khÃ´ng bao gá»“m thÃ´ng tin bÃ­ máº­t nhÆ° ghi chÃº cÃ¡ nhÃ¢n hay hÆ°á»›ng dáº«n sáº£n pháº©m cá»§a cÃ´ng ty.

### CÃ¡ch hoáº¡t Ä‘á»™ng cá»§a RAG (Retrieval Augmented Generation)

![hÃ¬nh minh há»a cÃ¡ch hoáº¡t Ä‘á»™ng cá»§a RAG](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.vi.png)

Giáº£ sá»­ báº¡n muá»‘n triá»ƒn khai má»™t chatbot táº¡o bÃ i kiá»ƒm tra tá»« ghi chÃº cá»§a báº¡n, báº¡n sáº½ cáº§n káº¿t ná»‘i vá»›i cÆ¡ sá»Ÿ tri thá»©c. ÄÃ¢y chÃ­nh lÃ  lÃºc RAG phÃ¡t huy tÃ¡c dá»¥ng. RAG hoáº¡t Ä‘á»™ng nhÆ° sau:

- **CÆ¡ sá»Ÿ tri thá»©c:** TrÆ°á»›c khi truy xuáº¥t, cÃ¡c tÃ i liá»‡u nÃ y cáº§n Ä‘Æ°á»£c nháº­p vÃ  xá»­ lÃ½ trÆ°á»›c, thÆ°á»ng lÃ  chia nhá» cÃ¡c tÃ i liá»‡u lá»›n thÃ nh cÃ¡c pháº§n nhá» hÆ¡n, chuyá»ƒn Ä‘á»•i chÃºng thÃ nh embeddings vÄƒn báº£n vÃ  lÆ°u trá»¯ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u.

- **Truy váº¥n ngÆ°á»i dÃ¹ng:** ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i

- **Truy xuáº¥t:** Khi ngÆ°á»i dÃ¹ng há»i, mÃ´ hÃ¬nh embedding sáº½ truy xuáº¥t thÃ´ng tin liÃªn quan tá»« cÆ¡ sá»Ÿ tri thá»©c Ä‘á»ƒ cung cáº¥p thÃªm ngá»¯ cáº£nh, Ä‘Æ°á»£c tÃ­ch há»£p vÃ o prompt.

- **Táº¡o cÃ¢u tráº£ lá»i nÃ¢ng cao:** LLM cáº£i thiá»‡n cÃ¢u tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u Ä‘Æ°á»£c truy xuáº¥t. Äiá»u nÃ y cho phÃ©p cÃ¢u tráº£ lá»i khÃ´ng chá»‰ dá»±a trÃªn dá»¯ liá»‡u Ä‘Ã£ Ä‘Æ°á»£c Ä‘Ã o táº¡o mÃ  cÃ²n dá»±a trÃªn thÃ´ng tin liÃªn quan tá»« ngá»¯ cáº£nh bá»• sung. Dá»¯ liá»‡u truy xuáº¥t Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ tÄƒng cÆ°á»ng cÃ¢u tráº£ lá»i cá»§a LLM. Sau Ä‘Ã³, LLM tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.

![hÃ¬nh minh há»a kiáº¿n trÃºc RAG](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.vi.png)

Kiáº¿n trÃºc cá»§a RAG Ä‘Æ°á»£c triá»ƒn khai báº±ng transformer gá»“m hai pháº§n: encoder vÃ  decoder. VÃ­ dá»¥, khi ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i, vÄƒn báº£n Ä‘áº§u vÃ o Ä‘Æ°á»£c 'mÃ£ hÃ³a' thÃ nh cÃ¡c vector thá»ƒ hiá»‡n Ã½ nghÄ©a cá»§a tá»«, sau Ä‘Ã³ cÃ¡c vector nÃ y Ä‘Æ°á»£c 'giáº£i mÃ£' vÃ o chá»‰ má»¥c tÃ i liá»‡u vÃ  táº¡o ra vÄƒn báº£n má»›i dá»±a trÃªn truy váº¥n cá»§a ngÆ°á»i dÃ¹ng. LLM sá»­ dá»¥ng mÃ´ hÃ¬nh encoder-decoder Ä‘á»ƒ táº¡o ra káº¿t quáº£.

CÃ³ hai cÃ¡ch tiáº¿p cáº­n khi triá»ƒn khai RAG theo bÃ i bÃ¡o Ä‘á» xuáº¥t: [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst):

- **_RAG-Sequence_** sá»­ dá»¥ng tÃ i liá»‡u truy xuáº¥t Ä‘á»ƒ dá»± Ä‘oÃ¡n cÃ¢u tráº£ lá»i tá»‘t nháº¥t cho truy váº¥n ngÆ°á»i dÃ¹ng

- **RAG-Token** sá»­ dá»¥ng tÃ i liá»‡u Ä‘á»ƒ táº¡o token tiáº¿p theo, sau Ä‘Ã³ truy xuáº¥t chÃºng Ä‘á»ƒ tráº£ lá»i cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng

### Táº¡i sao báº¡n nÃªn dÃ¹ng RAG?

- **Äa dáº¡ng thÃ´ng tin:** Ä‘áº£m báº£o cÃ¢u tráº£ lá»i vÄƒn báº£n luÃ´n cáº­p nháº­t vÃ  chÃ­nh xÃ¡c. Do Ä‘Ã³, nÃ³ nÃ¢ng cao hiá»‡u suáº¥t trong cÃ¡c nhiá»‡m vá»¥ chuyÃªn ngÃ nh báº±ng cÃ¡ch truy cáº­p cÆ¡ sá»Ÿ tri thá»©c ná»™i bá»™.

- Giáº£m thiá»ƒu thÃ´ng tin sai lá»‡ch báº±ng cÃ¡ch sá»­ dá»¥ng **dá»¯ liá»‡u cÃ³ thá»ƒ kiá»ƒm chá»©ng** trong cÆ¡ sá»Ÿ tri thá»©c Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh cho cÃ¢u há»i cá»§a ngÆ°á»i dÃ¹ng.

- **Tiáº¿t kiá»‡m chi phÃ­** vÃ¬ nÃ³ kinh táº¿ hÆ¡n so vá»›i viá»‡c tinh chá»‰nh láº¡i LLM.

## Táº¡o cÆ¡ sá»Ÿ tri thá»©c

á»¨ng dá»¥ng cá»§a chÃºng ta dá»±a trÃªn dá»¯ liá»‡u cÃ¡ nhÃ¢n, cá»¥ thá»ƒ lÃ  bÃ i há»c vá» Máº¡ng Neural trong chÆ°Æ¡ng trÃ¬nh AI cho ngÆ°á»i má»›i báº¯t Ä‘áº§u.

### CÆ¡ sá»Ÿ dá»¯ liá»‡u Vector

CÆ¡ sá»Ÿ dá»¯ liá»‡u vector, khÃ¡c vá»›i cÆ¡ sá»Ÿ dá»¯ liá»‡u truyá»n thá»‘ng, lÃ  má»™t loáº¡i cÆ¡ sá»Ÿ dá»¯ liá»‡u chuyÃªn biá»‡t Ä‘á»ƒ lÆ°u trá»¯, quáº£n lÃ½ vÃ  tÃ¬m kiáº¿m cÃ¡c vector nhÃºng. NÃ³ lÆ°u trá»¯ cÃ¡c biá»ƒu diá»…n sá»‘ cá»§a tÃ i liá»‡u. Viá»‡c chuyá»ƒn dá»¯ liá»‡u thÃ nh embeddings sá»‘ giÃºp há»‡ thá»‘ng AI dá»… dÃ ng hiá»ƒu vÃ  xá»­ lÃ½ dá»¯ liá»‡u hÆ¡n.

ChÃºng ta lÆ°u embeddings trong cÆ¡ sá»Ÿ dá»¯ liá»‡u vector vÃ¬ LLM cÃ³ giá»›i háº¡n sá»‘ token Ä‘áº§u vÃ o. VÃ¬ khÃ´ng thá»ƒ truyá»n toÃ n bá»™ embeddings vÃ o LLM, chÃºng ta cáº§n chia nhá» chÃºng thÃ nh cÃ¡c pháº§n, vÃ  khi ngÆ°á»i dÃ¹ng há»i, cÃ¡c embeddings phÃ¹ há»£p nháº¥t sáº½ Ä‘Æ°á»£c tráº£ vá» cÃ¹ng vá»›i prompt. Viá»‡c chia nhá» cÅ©ng giÃºp giáº£m chi phÃ­ dá»±a trÃªn sá»‘ token truyá»n qua LLM.

Má»™t sá»‘ cÆ¡ sá»Ÿ dá»¯ liá»‡u vector phá»• biáº¿n gá»“m Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant vÃ  DeepLake. Báº¡n cÃ³ thá»ƒ táº¡o mÃ´ hÃ¬nh Azure Cosmos DB báº±ng Azure CLI vá»›i lá»‡nh sau:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tá»« vÄƒn báº£n Ä‘áº¿n embeddings

TrÆ°á»›c khi lÆ°u trá»¯ dá»¯ liá»‡u, chÃºng ta cáº§n chuyá»ƒn Ä‘á»•i nÃ³ thÃ nh embeddings vector. Náº¿u báº¡n lÃ m viá»‡c vá»›i tÃ i liá»‡u lá»›n hoáº·c vÄƒn báº£n dÃ i, báº¡n cÃ³ thá»ƒ chia nhá» dá»±a trÃªn cÃ¡c truy váº¥n dá»± kiáº¿n. Viá»‡c chia nhá» cÃ³ thá»ƒ thá»±c hiá»‡n á»Ÿ cáº¥p cÃ¢u hoáº·c Ä‘oáº¡n vÄƒn. VÃ¬ viá»‡c chia nhá» dá»±a trÃªn Ã½ nghÄ©a cá»§a cÃ¡c tá»« xung quanh, báº¡n cÃ³ thá»ƒ thÃªm má»™t sá»‘ ngá»¯ cáº£nh khÃ¡c vÃ o pháº§n chia nhá», vÃ­ dá»¥ nhÆ° thÃªm tiÃªu Ä‘á» tÃ i liá»‡u hoáº·c má»™t sá»‘ vÄƒn báº£n trÆ°á»›c hoáº·c sau pháº§n Ä‘Ã³. Báº¡n cÃ³ thá»ƒ chia nhá» dá»¯ liá»‡u nhÆ° sau:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Sau khi chia nhá», chÃºng ta cÃ³ thá»ƒ nhÃºng vÄƒn báº£n báº±ng cÃ¡c mÃ´ hÃ¬nh embedding khÃ¡c nhau. Má»™t sá»‘ mÃ´ hÃ¬nh báº¡n cÃ³ thá»ƒ dÃ¹ng gá»“m: word2vec, ada-002 cá»§a OpenAI, Azure Computer Vision vÃ  nhiá»u hÆ¡n ná»¯a. Viá»‡c chá»n mÃ´ hÃ¬nh phá»¥ thuá»™c vÃ o ngÃ´n ngá»¯ báº¡n sá»­ dá»¥ng, loáº¡i ná»™i dung mÃ£ hÃ³a (vÄƒn báº£n/hÃ¬nh áº£nh/Ã¢m thanh), kÃ­ch thÆ°á»›c Ä‘áº§u vÃ o cÃ³ thá»ƒ mÃ£ hÃ³a vÃ  Ä‘á»™ dÃ i Ä‘áº§u ra embedding.

VÃ­ dá»¥ vá» vÄƒn báº£n Ä‘Æ°á»£c nhÃºng báº±ng mÃ´ hÃ¬nh `text-embedding-ada-002` cá»§a OpenAI lÃ :
![embedding cá»§a tá»« cat](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.vi.png)

## Truy xuáº¥t vÃ  TÃ¬m kiáº¿m Vector

Khi ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i, bá»™ truy xuáº¥t sáº½ chuyá»ƒn Ä‘á»•i cÃ¢u há»i thÃ nh vector báº±ng bá»™ mÃ£ hÃ³a truy váº¥n, sau Ä‘Ã³ tÃ¬m kiáº¿m trong chá»‰ má»¥c tÃ i liá»‡u cÃ¡c vector liÃªn quan Ä‘áº¿n Ä‘áº§u vÃ o. Khi hoÃ n thÃ nh, nÃ³ chuyá»ƒn Ä‘á»•i cáº£ vector Ä‘áº§u vÃ o vÃ  vector tÃ i liá»‡u thÃ nh vÄƒn báº£n vÃ  truyá»n qua LLM.

### Truy xuáº¥t

Truy xuáº¥t xáº£y ra khi há»‡ thá»‘ng cá»‘ gáº¯ng nhanh chÃ³ng tÃ¬m cÃ¡c tÃ i liá»‡u trong chá»‰ má»¥c thá»a mÃ£n tiÃªu chÃ­ tÃ¬m kiáº¿m. Má»¥c tiÃªu cá»§a bá»™ truy xuáº¥t lÃ  láº¥y cÃ¡c tÃ i liá»‡u sáº½ Ä‘Æ°á»£c dÃ¹ng Ä‘á»ƒ cung cáº¥p ngá»¯ cáº£nh vÃ  gáº¯n LLM vÃ o dá»¯ liá»‡u cá»§a báº¡n.

CÃ³ nhiá»u cÃ¡ch Ä‘á»ƒ tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ dá»¯ liá»‡u nhÆ°:

- **TÃ¬m kiáº¿m theo tá»« khÃ³a** - dÃ¹ng cho tÃ¬m kiáº¿m vÄƒn báº£n

- **TÃ¬m kiáº¿m ngá»¯ nghÄ©a** - sá»­ dá»¥ng Ã½ nghÄ©a ngá»¯ cáº£nh cá»§a tá»«

- **TÃ¬m kiáº¿m vector** - chuyá»ƒn tÃ i liá»‡u tá»« vÄƒn báº£n sang biá»ƒu diá»…n vector báº±ng mÃ´ hÃ¬nh embedding. Truy xuáº¥t sáº½ dá»±a trÃªn viá»‡c truy váº¥n cÃ¡c tÃ i liá»‡u cÃ³ vector gáº§n nháº¥t vá»›i cÃ¢u há»i ngÆ°á»i dÃ¹ng.

- **Káº¿t há»£p** - káº¿t há»£p cáº£ tÃ¬m kiáº¿m theo tá»« khÃ³a vÃ  vector.

Má»™t thÃ¡ch thá»©c khi truy xuáº¥t lÃ  khi khÃ´ng cÃ³ cÃ¢u tráº£ lá»i tÆ°Æ¡ng tá»± trong cÆ¡ sá»Ÿ dá»¯ liá»‡u, há»‡ thá»‘ng sáº½ tráº£ vá» thÃ´ng tin tá»‘t nháº¥t cÃ³ thá»ƒ, tuy nhiÃªn báº¡n cÃ³ thá»ƒ dÃ¹ng cÃ¡c chiáº¿n thuáº­t nhÆ° thiáº¿t láº­p khoáº£ng cÃ¡ch tá»‘i Ä‘a cho Ä‘á»™ liÃªn quan hoáº·c dÃ¹ng tÃ¬m kiáº¿m káº¿t há»£p cáº£ tá»« khÃ³a vÃ  vector. Trong bÃ i há»c nÃ y, chÃºng ta sáº½ dÃ¹ng tÃ¬m kiáº¿m káº¿t há»£p, káº¿t há»£p cáº£ vector vÃ  tá»« khÃ³a. Dá»¯ liá»‡u sáº½ Ä‘Æ°á»£c lÆ°u trong dataframe vá»›i cÃ¡c cá»™t chá»©a pháº§n chia nhá» cÅ©ng nhÆ° embeddings.

### Äá»™ tÆ°Æ¡ng Ä‘á»“ng vector

Bá»™ truy xuáº¥t sáº½ tÃ¬m kiáº¿m trong cÆ¡ sá»Ÿ tri thá»©c cÃ¡c embeddings gáº§n nhau nháº¥t, gá»i lÃ  lÃ¡ng giá»ng gáº§n nháº¥t, vÃ¬ chÃºng lÃ  cÃ¡c vÄƒn báº£n tÆ°Æ¡ng tá»±. Trong ká»‹ch báº£n, khi ngÆ°á»i dÃ¹ng Ä‘áº·t cÃ¢u há»i, cÃ¢u há»i Ä‘Æ°á»£c nhÃºng rá»“i so khá»›p vá»›i cÃ¡c embeddings tÆ°Æ¡ng tá»±. PhÆ°Æ¡ng phÃ¡p phá»• biáº¿n Ä‘á»ƒ Ä‘o Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giá»¯a cÃ¡c vector lÃ  cosine similarity dá»±a trÃªn gÃ³c giá»¯a hai vector.

ChÃºng ta cÅ©ng cÃ³ thá»ƒ Ä‘o Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng báº±ng cÃ¡c phÆ°Æ¡ng phÃ¡p khÃ¡c nhÆ° khoáº£ng cÃ¡ch Euclidean (Ä‘Æ°á»ng tháº³ng giá»¯a hai Ä‘iá»ƒm vector) vÃ  tÃ­ch vÃ´ hÆ°á»›ng (dot product) Ä‘o tá»•ng tÃ­ch cÃ¡c pháº§n tá»­ tÆ°Æ¡ng á»©ng cá»§a hai vector.

### Chá»‰ má»¥c tÃ¬m kiáº¿m

Khi thá»±c hiá»‡n truy xuáº¥t, chÃºng ta cáº§n xÃ¢y dá»±ng chá»‰ má»¥c tÃ¬m kiáº¿m cho cÆ¡ sá»Ÿ tri thá»©c trÆ°á»›c khi tÃ¬m kiáº¿m. Chá»‰ má»¥c sáº½ lÆ°u embeddings vÃ  cÃ³ thá»ƒ nhanh chÃ³ng truy xuáº¥t cÃ¡c pháº§n chia nhá» tÆ°Æ¡ng tá»± nháº¥t ngay cáº£ trong cÆ¡ sá»Ÿ dá»¯ liá»‡u lá»›n. ChÃºng ta cÃ³ thá»ƒ táº¡o chá»‰ má»¥c cá»¥c bá»™ báº±ng:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Sáº¯p xáº¿p láº¡i káº¿t quáº£

Sau khi truy váº¥n cÆ¡ sá»Ÿ dá»¯ liá»‡u, báº¡n cÃ³ thá»ƒ cáº§n sáº¯p xáº¿p káº¿t quáº£ theo má»©c Ä‘á»™ liÃªn quan. Má»™t LLM sáº¯p xáº¿p láº¡i sá»­ dá»¥ng Machine Learning Ä‘á»ƒ cáº£i thiá»‡n Ä‘á»™ liÃªn quan cá»§a káº¿t quáº£ tÃ¬m kiáº¿m báº±ng cÃ¡ch xáº¿p chÃºng theo thá»© tá»± tá»« liÃªn quan nháº¥t. Sá»­ dá»¥ng Azure AI Search, viá»‡c sáº¯p xáº¿p láº¡i Ä‘Æ°á»£c thá»±c hiá»‡n tá»± Ä‘á»™ng báº±ng bá»™ sáº¯p xáº¿p ngá»¯ nghÄ©a. VÃ­ dá»¥ vá» cÃ¡ch sáº¯p xáº¿p láº¡i sá»­ dá»¥ng lÃ¡ng giá»ng gáº§n nháº¥t:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Káº¿t há»£p táº¥t cáº£ láº¡i

BÆ°á»›c cuá»‘i cÃ¹ng lÃ  thÃªm LLM vÃ o Ä‘á»ƒ cÃ³ thá»ƒ nháº­n Ä‘Æ°á»£c cÃ¢u tráº£ lá»i dá»±a trÃªn dá»¯ liá»‡u cá»§a chÃºng ta. ChÃºng ta cÃ³ thá»ƒ triá»ƒn khai nhÆ° sau:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## ÄÃ¡nh giÃ¡ á»©ng dá»¥ng

### CÃ¡c chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡

- Cháº¥t lÆ°á»£ng cÃ¢u tráº£ lá»i Ä‘áº£m báº£o tá»± nhiÃªn, trÃ´i cháº£y vÃ  giá»‘ng con ngÆ°á»i

- TÃ­nh gáº¯n káº¿t dá»¯ liá»‡u: Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i cÃ³ dá»±a trÃªn tÃ i liá»‡u cung cáº¥p hay khÃ´ng

- TÃ­nh liÃªn quan: Ä‘Ã¡nh giÃ¡ cÃ¢u tráº£ lá»i phÃ¹ há»£p vÃ  liÃªn quan Ä‘áº¿n cÃ¢u há»i

- TÃ­nh trÃ´i cháº£y - cÃ¢u tráº£ lá»i cÃ³ há»£p lÃ½ vá» ngá»¯ phÃ¡p hay khÃ´ng

## CÃ¡c trÆ°á»ng há»£p sá»­ dá»¥ng RAG vÃ  cÆ¡ sá»Ÿ dá»¯ liá»‡u vector

CÃ³ nhiá»u trÆ°á»ng há»£p sá»­ dá»¥ng khÃ¡c nhau mÃ  function calls cÃ³ thá»ƒ cáº£i thiá»‡n á»©ng dá»¥ng cá»§a báº¡n nhÆ°:

- Há»i Ä‘Ã¡p: gáº¯n dá»¯ liá»‡u cÃ´ng ty vÃ o chatbot Ä‘á»ƒ nhÃ¢n viÃªn cÃ³ thá»ƒ Ä‘áº·t cÃ¢u há»i.

- Há»‡ thá»‘ng Ä‘á» xuáº¥t: táº¡o há»‡ thá»‘ng khá»›p cÃ¡c giÃ¡ trá»‹ tÆ°Æ¡ng tá»± nháº¥t vÃ­ dá»¥ nhÆ° phim, nhÃ  hÃ ng vÃ  nhiá»u hÆ¡n ná»¯a.

- Dá»‹ch vá»¥ chatbot: lÆ°u lá»‹ch sá»­ trÃ² chuyá»‡n vÃ  cÃ¡ nhÃ¢n hÃ³a cuá»™c há»™i thoáº¡i dá»±a trÃªn dá»¯ liá»‡u ngÆ°á»i dÃ¹ng.

- TÃ¬m kiáº¿m hÃ¬nh áº£nh dá»±a trÃªn embeddings vector, há»¯u Ã­ch trong nháº­n dáº¡ng hÃ¬nh áº£nh vÃ  phÃ¡t hiá»‡n báº¥t thÆ°á»ng.

## TÃ³m táº¯t

ChÃºng ta Ä‘Ã£ bao quÃ¡t cÃ¡c khÃ­a cáº¡nh cÆ¡ báº£n cá»§a RAG tá»« viá»‡c thÃªm dá»¯ liá»‡u vÃ o á»©ng dá»¥ng, truy váº¥n ngÆ°á»i dÃ¹ng Ä‘áº¿n káº¿t quáº£ Ä‘áº§u ra. Äá»ƒ Ä‘Æ¡n giáº£n hÃ³a viá»‡c táº¡o RAG, báº¡n cÃ³ thá»ƒ sá»­ dá»¥ng cÃ¡c framework nhÆ° Semantic Kernel, Langchain hoáº·c Autogen.

## BÃ i táº­p

Äá»ƒ tiáº¿p tá»¥c há»c vá» Retrieval Augmented Generation (RAG), báº¡n cÃ³ thá»ƒ xÃ¢y dá»±ng:

- Táº¡o giao diá»‡n front-end cho á»©ng dá»¥ng báº±ng framework báº¡n chá»n

- Sá»­ dá»¥ng má»™t framework, LangChain hoáº·c Semantic Kernel, vÃ  tÃ¡i táº¡o á»©ng dá»¥ng cá»§a báº¡n.

ChÃºc má»«ng báº¡n Ä‘Ã£ hoÃ n thÃ nh bÃ i há»c ğŸ‘.

## Há»c táº­p khÃ´ng dá»«ng láº¡i á»Ÿ Ä‘Ã¢y, hÃ£y tiáº¿p tá»¥c hÃ nh trÃ¬nh

Sau khi hoÃ n thÃ nh bÃ i há»c nÃ y, hÃ£y khÃ¡m phÃ¡ bá»™ sÆ°u táº­p [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) Ä‘á»ƒ tiáº¿p tá»¥c nÃ¢ng cao kiáº¿n thá»©c vá» Generative AI!

**TuyÃªn bá»‘ tá»« chá»‘i trÃ¡ch nhiá»‡m**:  
TÃ i liá»‡u nÃ y Ä‘Ã£ Ä‘Æ°á»£c dá»‹ch báº±ng dá»‹ch vá»¥ dá»‹ch thuáº­t AI [Co-op Translator](https://github.com/Azure/co-op-translator). Máº·c dÃ¹ chÃºng tÃ´i cá»‘ gáº¯ng Ä‘áº£m báº£o Ä‘á»™ chÃ­nh xÃ¡c, xin lÆ°u Ã½ ráº±ng cÃ¡c báº£n dá»‹ch tá»± Ä‘á»™ng cÃ³ thá»ƒ chá»©a lá»—i hoáº·c khÃ´ng chÃ­nh xÃ¡c. TÃ i liá»‡u gá»‘c báº±ng ngÃ´n ngá»¯ gá»‘c cá»§a nÃ³ nÃªn Ä‘Æ°á»£c coi lÃ  nguá»“n chÃ­nh xÃ¡c vÃ  Ä‘Ã¡ng tin cáº­y. Äá»‘i vá»›i cÃ¡c thÃ´ng tin quan trá»ng, nÃªn sá»­ dá»¥ng dá»‹ch vá»¥ dá»‹ch thuáº­t chuyÃªn nghiá»‡p do con ngÆ°á»i thá»±c hiá»‡n. ChÃºng tÃ´i khÃ´ng chá»‹u trÃ¡ch nhiá»‡m vá» báº¥t ká»³ sá»± hiá»ƒu láº§m hoáº·c giáº£i thÃ­ch sai nÃ o phÃ¡t sinh tá»« viá»‡c sá»­ dá»¥ng báº£n dá»‹ch nÃ y.