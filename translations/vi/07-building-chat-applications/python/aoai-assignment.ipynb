{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Chương 7: Xây dựng Ứng dụng Trò chuyện\n",
    "## Bắt đầu nhanh với Azure OpenAI API\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Tổng quan\n",
    "Sổ tay này được điều chỉnh từ [Kho mẫu Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) bao gồm các sổ tay cũng truy cập dịch vụ [OpenAI](notebook-openai.ipynb).\n",
    "\n",
    "API Python OpenAI cũng hoạt động với Azure OpenAI, với một vài sửa đổi. Tìm hiểu thêm về sự khác biệt tại đây: [Cách chuyển đổi giữa các điểm cuối OpenAI và Azure OpenAI với Python](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n",
    "\n",
    "Để xem thêm các ví dụ khởi đầu nhanh, vui lòng tham khảo tài liệu chính thức [Hướng dẫn khởi động nhanh Azure OpenAI](https://learn.microsoft.com/azure/cognitive-services/openai/quickstart?pivots=programming-language-studio&WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Mục lục  \n",
    "\n",
    "[Tổng quan](../../../../07-building-chat-applications/python)  \n",
    "[Bắt đầu với Dịch vụ Azure OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[Xây dựng lời nhắc đầu tiên của bạn](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Trường hợp sử dụng](../../../../07-building-chat-applications/python)    \n",
    "[1. Tóm tắt văn bản](../../../../07-building-chat-applications/python)  \n",
    "[2. Phân loại văn bản](../../../../07-building-chat-applications/python)  \n",
    "[3. Tạo tên sản phẩm mới](../../../../07-building-chat-applications/python)  \n",
    "[4. Tinh chỉnh bộ phân loại](../../../../07-building-chat-applications/python)  \n",
    "[5. Nhúng](../../../../07-building-chat-applications/python)\n",
    "\n",
    "[Tham khảo](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Bắt đầu với Dịch vụ Azure OpenAI\n",
    "\n",
    "Khách hàng mới sẽ cần [đăng ký truy cập](https://aka.ms/oai/access?WT.mc_id=academic-105485-koreyst) vào Dịch vụ Azure OpenAI.  \n",
    "Sau khi được phê duyệt, khách hàng có thể đăng nhập vào cổng Azure, tạo một tài nguyên Dịch vụ Azure OpenAI và bắt đầu thử nghiệm với các mô hình qua studio  \n",
    "\n",
    "[Tài nguyên tuyệt vời để bắt đầu nhanh chóng](https://techcommunity.microsoft.com/blog/educatordeveloperblog/azure-openai-service-is-now-generally-available/3719177?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Xây dựng prompt đầu tiên của bạn  \n",
    "Bài tập ngắn này sẽ cung cấp một giới thiệu cơ bản về cách gửi prompt đến một mô hình OpenAI cho một nhiệm vụ đơn giản \"tóm tắt\".\n",
    "\n",
    "\n",
    "**Các bước**:  \n",
    "1. Cài đặt thư viện OpenAI trong môi trường python của bạn  \n",
    "2. Tải các thư viện trợ giúp tiêu chuẩn và thiết lập các thông tin bảo mật OpenAI điển hình cho Dịch vụ OpenAI mà bạn đã tạo  \n",
    "3. Chọn một mô hình cho nhiệm vụ của bạn  \n",
    "4. Tạo một prompt đơn giản cho mô hình  \n",
    "5. Gửi yêu cầu của bạn đến API mô hình!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Cài đặt OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > [!LƯU Ý] Bước này không cần thiết nếu chạy sổ tay này trên Codespaces hoặc trong một Devcontainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Nhập các thư viện hỗ trợ và khởi tạo thông tin xác thực\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import AzureOpenAI\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "#validate data inside .env file\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Tìm mô hình phù hợp  \n",
    "Các mô hình GPT-3.5-turbo hoặc GPT-4 có thể hiểu và tạo ra ngôn ngữ tự nhiên. Dịch vụ cung cấp bốn khả năng mô hình, mỗi khả năng có mức độ sức mạnh và tốc độ khác nhau phù hợp với các nhiệm vụ khác nhau.\n",
    "\n",
    "[Azure OpenAI models](https://learn.microsoft.com/azure/cognitive-services/openai/concepts/models?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Thiết kế Prompt  \n",
    "\n",
    "\"Phép màu của các mô hình ngôn ngữ lớn là bằng cách được huấn luyện để giảm thiểu lỗi dự đoán này trên một lượng lớn văn bản, các mô hình cuối cùng học được các khái niệm hữu ích cho những dự đoán này. Ví dụ, chúng học các khái niệm như\"(1):\n",
    "\n",
    "* cách đánh vần\n",
    "* cách ngữ pháp hoạt động\n",
    "* cách diễn đạt lại\n",
    "* cách trả lời câu hỏi\n",
    "* cách giữ cuộc trò chuyện\n",
    "* cách viết bằng nhiều ngôn ngữ\n",
    "* cách lập trình\n",
    "* v.v.\n",
    "\n",
    "#### Cách kiểm soát một mô hình ngôn ngữ lớn  \n",
    "\"Trong tất cả các đầu vào cho một mô hình ngôn ngữ lớn, rõ ràng đầu vào có ảnh hưởng nhất là prompt văn bản(1).\n",
    "\n",
    "Các mô hình ngôn ngữ lớn có thể được prompt để tạo ra đầu ra theo một vài cách:\n",
    "\n",
    "- Hướng dẫn: Nói cho mô hình biết bạn muốn gì\n",
    "- Hoàn thành: Khiến mô hình hoàn thành phần bắt đầu của những gì bạn muốn\n",
    "- Minh họa: Cho mô hình thấy bạn muốn gì, với:\n",
    "- Một vài ví dụ trong prompt\n",
    "- Hàng trăm hoặc hàng nghìn ví dụ trong bộ dữ liệu huấn luyện tinh chỉnh\n",
    "\n",
    "\n",
    "\n",
    "#### Có ba hướng dẫn cơ bản để tạo prompt:\n",
    "\n",
    "**Hiển thị và nói rõ**. Làm rõ bạn muốn gì thông qua hướng dẫn, ví dụ, hoặc kết hợp cả hai. Nếu bạn muốn mô hình xếp hạng một danh sách các mục theo thứ tự chữ cái hoặc phân loại một đoạn văn theo cảm xúc, hãy cho nó thấy đó là điều bạn muốn.\n",
    "\n",
    "**Cung cấp dữ liệu chất lượng**. Nếu bạn đang cố gắng xây dựng một bộ phân loại hoặc khiến mô hình theo một mẫu, hãy đảm bảo có đủ ví dụ. Hãy chắc chắn kiểm tra kỹ các ví dụ của bạn — mô hình thường đủ thông minh để nhận ra các lỗi chính tả cơ bản và vẫn đưa ra phản hồi, nhưng nó cũng có thể cho rằng điều này là cố ý và điều đó có thể ảnh hưởng đến phản hồi.\n",
    "\n",
    "**Kiểm tra cài đặt của bạn.** Các cài đặt temperature và top_p kiểm soát mức độ quyết đoán của mô hình trong việc tạo phản hồi. Nếu bạn yêu cầu phản hồi mà chỉ có một câu trả lời đúng duy nhất, bạn nên đặt các giá trị này thấp hơn. Nếu bạn muốn có các phản hồi đa dạng hơn, bạn có thể đặt chúng cao hơn. Sai lầm số một mà mọi người hay mắc phải với các cài đặt này là cho rằng chúng là điều khiển \"sự thông minh\" hoặc \"sự sáng tạo\".\n",
    "\n",
    "\n",
    "Nguồn: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "hình ảnh đang tạo lời nhắc văn bản đầu tiên của bạn!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 5. Gửi đi!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Lặp lại cuộc gọi tương tự, kết quả so sánh như thế nào?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Tóm tắt văn bản  \n",
    "#### Thách thức  \n",
    "Tóm tắt văn bản bằng cách thêm 'tl;dr:' vào cuối đoạn văn bản. Hãy chú ý cách mô hình hiểu và thực hiện nhiều nhiệm vụ mà không cần hướng dẫn bổ sung. Bạn có thể thử nghiệm với các lời nhắc mô tả hơn tl;dr để điều chỉnh hành vi của mô hình và tùy chỉnh bản tóm tắt bạn nhận được(3).  \n",
    "\n",
    "Các nghiên cứu gần đây đã chứng minh sự cải thiện đáng kể trên nhiều nhiệm vụ và chuẩn đánh giá NLP bằng cách tiền huấn luyện trên một tập văn bản lớn, sau đó tinh chỉnh trên một nhiệm vụ cụ thể. Mặc dù kiến trúc thường không phụ thuộc vào nhiệm vụ, phương pháp này vẫn yêu cầu các bộ dữ liệu tinh chỉnh riêng cho từng nhiệm vụ với hàng nghìn hoặc hàng chục nghìn ví dụ. Ngược lại, con người thường có thể thực hiện một nhiệm vụ ngôn ngữ mới chỉ với vài ví dụ hoặc hướng dẫn đơn giản - điều mà các hệ thống NLP hiện tại vẫn còn gặp nhiều khó khăn. Ở đây, chúng tôi cho thấy việc mở rộng quy mô mô hình ngôn ngữ cải thiện đáng kể hiệu suất không phụ thuộc nhiệm vụ với vài ví dụ, đôi khi thậm chí đạt được sự cạnh tranh với các phương pháp tinh chỉnh tiên tiến trước đây.  \n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bài tập cho một số trường hợp sử dụng  \n",
    "1. Tóm tắt văn bản  \n",
    "2. Phân loại văn bản  \n",
    "3. Tạo tên sản phẩm mới  \n",
    "4. Nhúng  \n",
    "5. Tinh chỉnh bộ phân loại\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\ntl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Phân loại văn bản  \n",
    "#### Thách thức  \n",
    "Phân loại các mục vào các danh mục được cung cấp tại thời điểm suy luận. Trong ví dụ sau, chúng tôi cung cấp cả danh mục và văn bản cần phân loại trong lời nhắc (*playground_reference).\n",
    "\n",
    "Yêu cầu của khách hàng: Xin chào, một trong những phím trên bàn phím laptop của tôi gần đây bị hỏng và tôi cần thay thế:\n",
    "\n",
    "Danh mục đã phân loại:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Tạo Tên Sản Phẩm Mới\n",
    "#### Thách thức\n",
    "Tạo tên sản phẩm từ các từ ví dụ. Ở đây chúng tôi bao gồm trong lời nhắc thông tin về sản phẩm mà chúng tôi sẽ tạo tên cho nó. Chúng tôi cũng cung cấp một ví dụ tương tự để cho thấy mẫu mà chúng tôi mong muốn nhận được. Chúng tôi cũng đã đặt giá trị nhiệt độ cao để tăng tính ngẫu nhiên và các phản hồi sáng tạo hơn.\n",
    "\n",
    "Mô tả sản phẩm: Máy làm sữa lắc tại nhà  \n",
    "Từ khóa gốc: nhanh, lành mạnh, nhỏ gọn.  \n",
    "Tên sản phẩm: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Mô tả sản phẩm: Một đôi giày có thể vừa với mọi kích cỡ chân.  \n",
    "Từ khóa gốc: thích nghi, vừa vặn, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Embeddings\n",
    "Phần này sẽ hướng dẫn cách lấy embeddings và tìm sự tương đồng giữa các từ, câu và tài liệu. Để chạy các notebook dưới đây, bạn cần triển khai một mô hình sử dụng `text-embedding-ada-002` làm mô hình cơ sở và đặt tên triển khai của nó trong file .env, sử dụng biến `AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT`.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Phân loại mô hình - Lựa chọn mô hình nhúng\n",
    "\n",
    "**Phân loại mô hình**: {family} - {capability} - {input-type} - {identifier}  \n",
    "\n",
    "{family}     --> text-embedding  (họ mô hình nhúng)  \n",
    "{capability} --> ada             (tất cả các mô hình nhúng khác sẽ bị ngừng sử dụng vào năm 2024)  \n",
    "{input-type} --> n/a             (chỉ được chỉ định cho các mô hình tìm kiếm)  \n",
    "{identifier} --> 002             (phiên bản 002)  \n",
    "\n",
    "model = 'text-embedding-ada-002'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  > [!LƯU Ý] Bước sau đây không cần thiết nếu chạy sổ tay này trên Codespaces hoặc trong một Devcontainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dependencies for embeddings_utils\n",
    "%pip install matplotlib plotly scikit-learn pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829364153
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829424097
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "text = 'the quick brown fox jumped over the lazy dog'\n",
    "model= os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "client.embeddings.create(input='[text]', model=model).data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829555255
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# compare several words\n",
    "automobile_embedding  = client.embeddings.create(input='automobile', model=model).data[0].embedding\n",
    "vehicle_embedding     = client.embeddings.create(input='vehicle', model=model).data[0].embedding\n",
    "dinosaur_embedding    = client.embeddings.create(input='dinosaur', model=model).data[0].embedding\n",
    "stick_embedding       = client.embeddings.create(input='stick', model=model).data[0].embedding\n",
    "\n",
    "print(cosine_similarity(automobile_embedding, vehicle_embedding))\n",
    "print(cosine_similarity(automobile_embedding, dinosaur_embedding))\n",
    "print(cosine_similarity(automobile_embedding, stick_embedding))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## So sánh bài báo từ bộ dữ liệu tin tức hàng ngày của cnn\n",
    "nguồn: https://huggingface.co/datasets/cnn_dailymail\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674831122093
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "cnn_daily_articles = ['BREMEN, Germany -- Carlos Alberto, who scored in FC Porto\\'s Champions League final victory against Monaco in 2004, has joined Bundesliga club Werder Bremen for a club record fee of 7.8 million euros ($10.7 million). Carlos Alberto enjoyed success at FC Porto under Jose Mourinho. \"I\\'m here to win titles with Werder,\" the 22-year-old said after his first training session with his new club. \"I like Bremen and would only have wanted to come here.\" Carlos Alberto started his career with Fluminense, and helped them to lift the Campeonato Carioca in 2002. In January 2004 he moved on to FC Porto, who were coached by José Mourinho, and the club won the Portuguese title as well as the Champions League. Early in 2005, he moved to Corinthians, where he impressed as they won the Brasileirão,but in 2006 Corinthians had a poor season and Carlos Alberto found himself at odds with manager, Emerson Leão. Their poor relationship came to a climax at a Copa Sul-Americana game against Club Atlético Lanús, and Carlos Alberto declared that he would not play for Corinthians again while Leão remained as manager. Since January this year he has been on loan with his first club Fluminense. Bundesliga champions VfB Stuttgart said on Sunday that they would sign a loan agreement with Real Zaragoza on Monday for Ewerthon, the third top Brazilian player to join the German league in three days. A VfB spokesman said Ewerthon, who played in the Bundesliga for Borussia Dortmund from 2001 to 2005, was expected to join the club for their pre-season training in Austria on Monday. On Friday, Ailton returned to Germany where he was the league\\'s top scorer in 2004, signing a one-year deal with Duisburg on a transfer from Red Star Belgrade. E-mail to a friend .',\n",
    "                        '(CNN) -- Football superstar, celebrity, fashion icon, multimillion-dollar heartthrob. Now, David Beckham is headed for the Hollywood Hills as he takes his game to U.S. Major League Soccer. CNN looks at how Bekham fulfilled his dream of playing for Manchester United, and his time playing for England. The world\\'s famous footballer has begun a five-year contract with the Los Angeles Galaxy team, and on Friday Beckham will meet the press and reveal his new shirt number. This week, we take an in depth look at the life and times of Beckham, as CNN\\'s very own \"Becks,\" Becky Anderson, sets out to examine what makes the man tick -- as footballer, fashion icon and global phenomenon. It\\'s a long way from the streets of east London to the Hollywood Hills and Becky charts Beckham\\'s incredible rise to football stardom, a journey that has seen his skills grace the greatest stages in world soccer. She goes in pursuit of the current hottest property on the sports/celebrity circuit in the U.S. and along the way explores exactly what\\'s behind the man with the golden boot. CNN will look back at the life of Beckham, the wonderfully talented youngster who fulfilled his dream of playing for Manchester United, his marriage to pop star Victoria, and the trials and tribulations of playing for England. We\\'ll look at the highs (scoring against Greece), the lows (being sent off during the World Cup), the Man. U departure for the Galacticos of Madrid -- and now the Home Depot stadium in L.A. We\\'ll ask how Beckham and his family will adapt to life in Los Angeles -- the people, the places to see and be seen and the celebrity endorsement. Beckham is no stranger to exposure. He has teamed with Reggie Bush in an Adidas commercial, is the face of Motorola, is the face on a PlayStation game and doesn\\'t need fashion tips as he has his own international clothing line. But what does the star couple need to do to become an accepted part of Tinseltown\\'s glitterati? The road to major league football in the U.S.A. is a well-worn route for some of the world\\'s greatest players. We talk to some of the former greats who came before him and examine what impact these overseas stars had on U.S. soccer and look at what is different now. We also get a rare glimpse inside the David Beckham academy in L.A, find out what drives the kids and who are their heroes. The perception that in the U.S.A. soccer is a \"game for girls\" after the teenage years is changing. More and more young kids are choosing the European game over the traditional U.S. sports. E-mail to a friend .',\n",
    "                        'LOS ANGELES, California (CNN) -- Youssif, the 5-year-old burned Iraqi boy, rounded the corner at Universal Studios when suddenly the little boy hero met his favorite superhero. Youssif has always been a huge Spider-Man fan. Meeting him was \"my favorite thing,\" he said. Spider-Man was right smack dab in front of him, riding a four-wheeler amid a convoy of other superheroes. The legendary climber of buildings and fighter of evil dismounted, walked over to Youssif and introduced himself. Spidey then gave the boy from a far-away land a gentle hug, embracing him in his iconic blue and red tights. He showed Youssif a few tricks, like how to shoot a web from his wrist. Only this time, no web was spun. \"All right Youssif!\" Spider-Man said after the boy mimicked his wrist movement. Other superheroes crowded around to get a closer look. Even the Green Goblin stopped his villainous ways to tell the boy hi. Youssif remained unfazed. He didn\\'t take a liking to Spider-Man\\'s nemesis. Spidey was just too cool. \"It was my favorite thing,\" the boy said later. \"I want to see him again.\" He then felt compelled to add: \"I know it\\'s not the real Spider-Man.\" This was the day of dreams when the boy\\'s nightmares were, at least temporarily, forgotten. He met SpongeBob, Lassie and a 3-year-old orangutan named Archie. The hairy, brownish-red primate took to the boy, grabbing his hand and holding it. Even when Youssif pulled away, Archie would inch his hand back toward the boy\\'s and then snatch it. See Youssif enjoy being a boy again » . The boy giggled inside a play area where sponge-like balls shot out of toy guns. It was a far different artillery than what he was used to seeing in central Baghdad, as recently as a week ago. He squealed with delight and raced around the room collecting as many balls as he could. He rode a tram through the back stages at Universal Studios. At one point, the car shook. Fire and smoke filled the air, debris cascaded down and a big rig skidded toward the vehicle. The boy and his family survived the pretend earthquake unscathed. \"Even I was scared,\" the dad said. \"Well, I wasn\\'t,\" Youssif replied. The father and mother grinned from ear to ear throughout the day. Youssif pushed his 14-month-old sister, Ayaa, in a stroller. \"Did you even need to ask us if we were interested in coming here?\" Youssif\\'s father said in amazement. \"Other than my wedding day, this is the happiest day of my life,\" he said. Just a day earlier, the mother and father talked about their journey out of Iraq and to the United States. They also discussed that day nine months ago when masked men grabbed their son outside the family home, doused him in gas and set him on fire. His mother heard her boy screaming from inside. The father sought help for his boy across Baghdad, but no one listened. He remembers his son\\'s two months of hospitalization. The doctors didn\\'t use anesthetics. He could hear his boy\\'s piercing screams from the other side of the hospital. Watch Youssif meet his doctor and play with his little sister » . The father knew that speaking to CNN would put his family\\'s lives in jeopardy. The possibility of being killed was better than seeing his son suffer, he said. \"Anything for Youssif,\" he said. \"We had to do it.\" They described a life of utter chaos in Baghdad. Neighbors had recently given birth to a baby girl. Shortly afterward, the father was kidnapped and killed. Then, there was the time when some girls wore tanktops and jeans. They were snatched off the street by gunmen. The stories can be even more gruesome. The couple said they had heard reports that a young girl was kidnapped and beheaded --and her killers sewed a dog\\'s head on the corpse and delivered it to her family\\'s doorstep. \"These are just some of the stories,\" said Youssif\\'s mother, Zainab. Under Saddam Hussein, there was more security and stability, they said. There was running water and electricity most of the time. But still life was tough under the dictator, like the time when Zainab\\'s uncle disappeared and was never heard from again after he read a \"religious book,\" she said. Sitting in the parking lot of a Target in suburban Los Angeles, Youssif\\'s father watched as husbands and wives, boyfriends and girlfriends, parents and their children, came and went. Some held hands. Others smiled and laughed. \"Iraq finished,\" he said in what few English words he knows. He elaborated in Arabic: His homeland won\\'t be enjoying such freedoms anytime soon. It\\'s just not possible. Too much violence. Too many killings. His two children have only seen war. But this week, the family has seen a much different side of America -- an outpouring of generosity and a peaceful nation at home. \"It\\'s been a dream,\" the father said. He used to do a lot of volunteer work back in Baghdad. \"Maybe that\\'s why I\\'m being helped now,\" the father said. At Universal Studios, he looked out across the valley below. The sun glistened off treetops and buildings. It was a picturesque sight fit for a Hollywood movie. \"Good America, good America,\" he said in English. E-mail to a friend . CNN\\'s Arwa Damon contributed to this report.'\n",
    "]\n",
    "\n",
    "cnn_daily_article_highlights = ['Werder Bremen pay a club record $10.7 million for Carlos Alberto .\\nThe Brazilian midfielder won the Champions League with FC Porto in 2004 .\\nSince January he has been on loan with his first club, Fluminense .',\n",
    "                                'Beckham has agreed to a five-year contract with Los Angeles Galaxy .\\nNew contract took effect July 1, 2007 .\\nFormer English captain to meet press, unveil new shirt number Friday .\\nCNN to look at Beckham as footballer, fashion icon and global phenomenon .',\n",
    "                                'Boy on meeting Spider-Man: \"It was my favorite thing\"\\nYoussif also met SpongeBob, Lassie and an orangutan at Universal Studios .\\nDad: \"Other than my wedding day, this is the happiest day of my life\"'\n",
    "]\n",
    "\n",
    "cnn_df = pd.DataFrame({\"articles\":cnn_daily_articles, \"highligths\":cnn_daily_article_highlights})\n",
    "\n",
    "cnn_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674831294043
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "article1_embedding    = client.embeddings.create(input=cnn_df.articles.iloc[0], model=model).data[0].embedding\n",
    "article2_embedding    = client.embeddings.create(input=cnn_df.articles.iloc[1], model=model).data[0].embedding\n",
    "article3_embedding    = client.embeddings.create(input=cnn_df.articles.iloc[2], model=model).data[0].embedding\n",
    "\n",
    "print(cosine_similarity(article1_embedding, article2_embedding))\n",
    "print(cosine_similarity(article1_embedding, article3_embedding))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# References  \n",
    "- [Azure Documentation - Azure OpenAI Models](https://learn.microsoft.com/azure/cognitive-services/openai/concepts/models?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Examples](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Để được hỗ trợ thêm  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Những người đóng góp\n",
    "* Louis Li  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Tuyên bố từ chối trách nhiệm**:  \nTài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ gốc của nó nên được coi là nguồn chính xác và đáng tin cậy. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp do con người thực hiện. Chúng tôi không chịu trách nhiệm về bất kỳ sự hiểu lầm hoặc giải thích sai nào phát sinh từ việc sử dụng bản dịch này.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "0028b01848da8f2e46fd18198119c210",
   "translation_date": "2025-12-19T10:55:25+00:00",
   "source_file": "07-building-chat-applications/python/aoai-assignment.ipynb",
   "language_code": "vi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}