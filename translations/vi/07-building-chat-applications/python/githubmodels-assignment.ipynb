{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Chương 7: Xây Dựng Ứng Dụng Chat\n",
    "## Bắt Đầu Nhanh với Github Models API\n",
    "\n",
    "Notebook này được điều chỉnh từ [Kho Mẫu Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), bao gồm các notebook truy cập dịch vụ [Azure OpenAI](notebook-azure-openai.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Tổng quan  \n",
    "\"Mô hình ngôn ngữ lớn là các hàm ánh xạ văn bản sang văn bản. Khi nhận một chuỗi văn bản đầu vào, mô hình ngôn ngữ lớn sẽ cố gắng dự đoán đoạn văn bản tiếp theo\" (1). Notebook \"bắt đầu nhanh\" này sẽ giới thiệu cho người dùng các khái niệm LLM ở mức độ tổng quan, các yêu cầu gói cốt lõi để bắt đầu với AML, phần giới thiệu nhẹ về thiết kế prompt, cùng một số ví dụ ngắn về các trường hợp sử dụng khác nhau.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Mục lục  \n",
    "\n",
    "[Tổng quan](../../../../07-building-chat-applications/python)  \n",
    "[Cách sử dụng Dịch vụ OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[1. Tạo Dịch vụ OpenAI của bạn](../../../../07-building-chat-applications/python)  \n",
    "[2. Cài đặt](../../../../07-building-chat-applications/python)    \n",
    "[3. Thông tin xác thực](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Các trường hợp sử dụng](../../../../07-building-chat-applications/python)    \n",
    "[1. Tóm tắt văn bản](../../../../07-building-chat-applications/python)  \n",
    "[2. Phân loại văn bản](../../../../07-building-chat-applications/python)  \n",
    "[3. Tạo tên sản phẩm mới](../../../../07-building-chat-applications/python)  \n",
    "[4. Tinh chỉnh bộ phân loại](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Tài liệu tham khảo](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Tạo prompt đầu tiên của bạn  \n",
    "Bài tập ngắn này sẽ giúp bạn làm quen với cách gửi prompt cho một mô hình trong Github Models với nhiệm vụ đơn giản là \"tóm tắt\".\n",
    "\n",
    "**Các bước thực hiện**:  \n",
    "1. Cài đặt thư viện `azure-ai-inference` vào môi trường python của bạn, nếu bạn chưa cài.  \n",
    "2. Tải các thư viện hỗ trợ tiêu chuẩn và thiết lập thông tin xác thực cho Github Models.  \n",
    "3. Chọn một mô hình phù hợp với nhiệm vụ của bạn  \n",
    "4. Tạo một prompt đơn giản cho mô hình  \n",
    "5. Gửi yêu cầu của bạn đến API của mô hình!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Cài đặt `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Tìm mô hình phù hợp  \n",
    "Các mô hình GPT-3.5-turbo hoặc GPT-4 có khả năng hiểu và tạo ra ngôn ngữ tự nhiên.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Thiết kế Prompt  \n",
    "\n",
    "\"Điều kỳ diệu của các mô hình ngôn ngữ lớn là khi được huấn luyện để giảm thiểu lỗi dự đoán trên một lượng lớn văn bản, các mô hình này sẽ học được những khái niệm hữu ích cho việc dự đoán. Ví dụ, chúng học được các khái niệm như\"(1):\n",
    "\n",
    "* cách đánh vần\n",
    "* cách sử dụng ngữ pháp\n",
    "* cách diễn đạt lại câu\n",
    "* cách trả lời câu hỏi\n",
    "* cách trò chuyện\n",
    "* cách viết bằng nhiều ngôn ngữ\n",
    "* cách lập trình\n",
    "* v.v.\n",
    "\n",
    "#### Cách kiểm soát một mô hình ngôn ngữ lớn  \n",
    "\"Trong tất cả các đầu vào của một mô hình ngôn ngữ lớn, văn bản prompt là yếu tố có ảnh hưởng lớn nhất(1).\n",
    "\n",
    "Các mô hình ngôn ngữ lớn có thể được hướng dẫn để tạo ra đầu ra theo một số cách:\n",
    "\n",
    "Chỉ dẫn: Nói cho mô hình biết bạn muốn gì\n",
    "Hoàn thành: Gợi ý để mô hình hoàn thành phần đầu của nội dung bạn muốn\n",
    "Minh họa: Cho mô hình thấy bạn muốn gì, bằng cách:\n",
    "Một vài ví dụ trong prompt\n",
    "Hàng trăm hoặc hàng nghìn ví dụ trong bộ dữ liệu huấn luyện fine-tuning\"\n",
    "\n",
    "\n",
    "\n",
    "#### Có ba nguyên tắc cơ bản để tạo prompt:\n",
    "\n",
    "**Chỉ rõ và minh họa**. Hãy làm rõ bạn muốn gì thông qua chỉ dẫn, ví dụ, hoặc kết hợp cả hai. Nếu bạn muốn mô hình sắp xếp một danh sách theo thứ tự chữ cái hoặc phân loại một đoạn văn theo cảm xúc, hãy cho nó thấy đó là điều bạn mong muốn.\n",
    "\n",
    "**Cung cấp dữ liệu chất lượng**. Nếu bạn đang cố xây dựng một bộ phân loại hoặc muốn mô hình tuân theo một mẫu nhất định, hãy đảm bảo có đủ ví dụ. Đừng quên kiểm tra lại các ví dụ của bạn — mô hình thường đủ thông minh để nhận ra lỗi chính tả cơ bản và vẫn trả lời, nhưng nó cũng có thể cho rằng đó là chủ ý và điều này có thể ảnh hưởng đến kết quả.\n",
    "\n",
    "**Kiểm tra các thiết lập.** Các thiết lập temperature và top_p kiểm soát mức độ xác định của mô hình khi tạo ra câu trả lời. Nếu bạn cần một câu trả lời mà chỉ có một đáp án đúng, hãy đặt các giá trị này thấp. Nếu bạn muốn có nhiều câu trả lời đa dạng hơn, có thể tăng các giá trị này lên. Sai lầm phổ biến nhất khi sử dụng các thiết lập này là nghĩ rằng chúng kiểm soát \"độ thông minh\" hoặc \"sự sáng tạo\" của mô hình.\n",
    "\n",
    "\n",
    "Nguồn: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Tóm tắt văn bản  \n",
    "#### Thử thách  \n",
    "Tóm tắt văn bản bằng cách thêm 'tl;dr:' vào cuối một đoạn văn. Lưu ý cách mô hình hiểu và thực hiện nhiều nhiệm vụ mà không cần hướng dẫn bổ sung. Bạn có thể thử nghiệm với các prompt mô tả hơn thay cho tl;dr để điều chỉnh hành vi của mô hình và cá nhân hóa bản tóm tắt mà bạn nhận được(3).  \n",
    "\n",
    "Những nghiên cứu gần đây đã cho thấy sự tiến bộ đáng kể trong nhiều nhiệm vụ và tiêu chuẩn NLP nhờ huấn luyện trước trên một tập dữ liệu văn bản lớn, sau đó tinh chỉnh cho từng nhiệm vụ cụ thể. Mặc dù kiến trúc thường không phụ thuộc vào nhiệm vụ, phương pháp này vẫn cần các bộ dữ liệu tinh chỉnh riêng biệt với hàng nghìn hoặc hàng chục nghìn ví dụ. Ngược lại, con người thường có thể thực hiện một nhiệm vụ ngôn ngữ mới chỉ với vài ví dụ hoặc chỉ dẫn đơn giản – điều mà các hệ thống NLP hiện tại vẫn còn gặp khó khăn. Ở đây, chúng tôi cho thấy rằng việc mở rộng quy mô các mô hình ngôn ngữ giúp cải thiện đáng kể hiệu suất với ít ví dụ, không phụ thuộc vào nhiệm vụ, thậm chí đôi khi còn đạt mức cạnh tranh với các phương pháp tinh chỉnh tiên tiến trước đó. \n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bài tập cho nhiều trường hợp sử dụng  \n",
    "1. Tóm tắt văn bản  \n",
    "2. Phân loại văn bản  \n",
    "3. Tạo tên sản phẩm mới\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Phân loại Văn bản  \n",
    "#### Thử thách  \n",
    "Phân loại các mục vào các danh mục được cung cấp tại thời điểm suy luận. Trong ví dụ sau, chúng ta cung cấp cả các danh mục và văn bản cần phân loại trong prompt (*playground_reference).\n",
    "\n",
    "Yêu cầu từ khách hàng: Xin chào, một trong các phím trên bàn phím laptop của tôi vừa bị hỏng gần đây và tôi cần thay thế:\n",
    "\n",
    "Danh mục đã phân loại:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Tạo Tên Sản Phẩm Mới\n",
    "#### Thử thách\n",
    "Tạo tên sản phẩm từ các từ ví dụ. Ở đây, chúng tôi đưa vào phần gợi ý thông tin về sản phẩm mà chúng tôi sẽ tạo tên. Chúng tôi cũng cung cấp một ví dụ tương tự để thể hiện mẫu mà chúng tôi mong muốn nhận được. Ngoài ra, chúng tôi đã đặt giá trị temperature cao để tăng tính ngẫu nhiên và các phản hồi sáng tạo hơn.\n",
    "\n",
    "Mô tả sản phẩm: Máy làm sữa lắc tại nhà\n",
    "Từ khóa: nhanh, lành mạnh, nhỏ gọn.\n",
    "Tên sản phẩm: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Mô tả sản phẩm: Một đôi giày có thể vừa với mọi cỡ chân.\n",
    "Từ khóa: linh hoạt, vừa vặn, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Tài liệu tham khảo  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Ví dụ về OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Các phương pháp tốt nhất để tinh chỉnh GPT-3 phân loại văn bản](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Để Được Hỗ Trợ Thêm  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Người đóng góp\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Tuyên bố miễn trừ trách nhiệm**:  \nTài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn tham khảo chính thức. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm đối với bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:43:34+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "vi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}