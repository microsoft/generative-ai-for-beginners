{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giới thiệu về Kỹ thuật Thiết kế Prompt\n",
    "Kỹ thuật thiết kế prompt là quá trình xây dựng và tối ưu hóa các prompt cho các nhiệm vụ xử lý ngôn ngữ tự nhiên. Quá trình này bao gồm việc lựa chọn prompt phù hợp, điều chỉnh các tham số của chúng và đánh giá hiệu quả hoạt động. Kỹ thuật thiết kế prompt đóng vai trò quan trọng trong việc đạt được độ chính xác và hiệu suất cao cho các mô hình NLP. Trong phần này, chúng ta sẽ tìm hiểu những kiến thức cơ bản về kỹ thuật thiết kế prompt bằng cách sử dụng các mô hình của OpenAI để khám phá.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 1: Tách từ (Tokenization)\n",
    "Khám phá cách tách từ bằng tiktoken, một công cụ tách từ mã nguồn mở, nhanh của OpenAI  \n",
    "Xem thêm ví dụ tại [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 2: Kiểm tra Thiết lập Khóa Github Models\n",
    "\n",
    "Chạy đoạn mã dưới đây để xác minh rằng endpoint Github Models của bạn đã được thiết lập đúng cách. Đoạn mã này chỉ thử một prompt cơ bản và kiểm tra kết quả trả về. Đầu vào `oh say can you see` nên được hoàn thành theo kiểu như `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That line is the opening lyric of \"The Star-Spangled Banner,\" the national anthem of the United States, written by Francis Scott Key. If you'd like more information or analysis, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, client, model_name, temperature=1.0, max_tokens=1000, top_p=1.0):\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 3: Thông tin bịa đặt\n",
    "\n",
    "Khám phá điều gì xảy ra khi bạn yêu cầu LLM trả về các câu trả lời cho một chủ đề có thể không tồn tại, hoặc về những chủ đề mà nó có thể không biết vì nằm ngoài bộ dữ liệu đã được huấn luyện trước (gần đây hơn). Xem cách phản hồi thay đổi như thế nào nếu bạn thử một lời nhắc khác, hoặc một mô hình khác.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 4: Dựa trên hướng dẫn  \n",
    "Sử dụng biến \"text\" để đặt nội dung chính  \n",
    "và biến \"prompt\" để đưa ra một hướng dẫn liên quan đến nội dung chính đó.\n",
    "\n",
    "Ở đây, chúng ta yêu cầu mô hình tóm tắt đoạn văn cho một học sinh lớp hai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter is the fifth planet from the Sun and the biggest one in our Solar System. It's made of gas and is much bigger than all the other planets put together! You can see Jupiter in the night sky because it's very bright. People have noticed it for a really long time and named it after a Roman god.\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập 5: Yêu cầu phức tạp\n",
    "Hãy thử một yêu cầu có cả tin nhắn của hệ thống, người dùng và trợ lý\n",
    "Hệ thống thiết lập ngữ cảnh cho trợ lý\n",
    "Tin nhắn của người dùng & trợ lý tạo nên bối cảnh hội thoại nhiều lượt\n",
    "\n",
    "Lưu ý cách tính cách của trợ lý được thiết lập là \"mỉa mai\" trong ngữ cảnh hệ thống.\n",
    "Hãy thử sử dụng một ngữ cảnh tính cách khác. Hoặc thử một chuỗi tin nhắn đầu vào/đầu ra khác.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you mean the famous 2020 World Series that wasn’t in a regular location? That was the year they played in the glamorous Arlington, Texas, at Globe Life Field.\n"
     ]
    }
   ],
   "source": [
    "response = client.complete(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bài tập: Khám phá trực giác của bạn\n",
    "Các ví dụ trên cung cấp cho bạn những mẫu mà bạn có thể sử dụng để tạo ra các prompt mới (đơn giản, phức tạp, hướng dẫn, v.v.) - hãy thử tạo thêm các bài tập khác để khám phá một số ý tưởng khác mà chúng ta đã thảo luận như ví dụ, gợi ý và nhiều hơn nữa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Tuyên bố miễn trừ trách nhiệm**:  \nTài liệu này đã được dịch bằng dịch vụ dịch thuật AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mặc dù chúng tôi cố gắng đảm bảo độ chính xác, xin lưu ý rằng các bản dịch tự động có thể chứa lỗi hoặc không chính xác. Tài liệu gốc bằng ngôn ngữ bản địa nên được coi là nguồn tham khảo chính thức. Đối với các thông tin quan trọng, nên sử dụng dịch vụ dịch thuật chuyên nghiệp bởi con người. Chúng tôi không chịu trách nhiệm đối với bất kỳ sự hiểu lầm hoặc diễn giải sai nào phát sinh từ việc sử dụng bản dịch này.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4beg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "40586ff9e0ba4574f88e59700b9a0088",
   "translation_date": "2025-08-25T13:28:29+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/githubmodels-assignment.ipynb",
   "language_code": "vi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}