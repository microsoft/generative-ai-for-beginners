<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b4b0266fbadbba7ded891b6485adc66d",
  "translation_date": "2025-10-17T20:03:46+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "he"
}
-->
# 爪专转 转砖转 注砖专转 注 住住 注 (RAG) 专 转 拽专

[![爪专转 转砖转 注砖专转 注 住住 注 (RAG) 专 转 拽专](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.he.png)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

砖注专 注 砖 驻砖,  拽爪专 爪 砖 转 砖  砖驻  (LLMs). 砖注专 , 注拽 转专 砖 砖 注 转 砖 砖 LLM, 拽 砖 转 砖转 住 转,  注转 拽住.

> ** 拽专**

## 

砖注专  注住拽 砖 :

-  -RAG,    砖转砖   转转.

- 转   专 转 拽专 爪专转  注专 砖 砖.

-  注砖转 爪 砖 RAG 砖.

## 专转 

专 住 砖注专, 转:

- 住专 转 砖转 砖 RAG 砖驻转 转 注.

- 专 砖 RAG 注 转 转 砖 -LLM.

- 砖 爪专 注 转 RAG 专 转 拽专 砖 LLM.

## 转专砖 砖: 砖驻专 -LLM 砖 注 转 砖

砖注专 ,  专爪 住祝 转 注专转 砖 住专驻 , 砖驻砖专 爪' 拽 注 住祝 注 砖 砖. 爪注转 注专转 砖砖 ,     转专  转 砖 砖,  砖拽 注 转 .  爪专 转 转专砖 砖, 砖转砖 :

- `Azure OpenAI:` -LLM 砖 砖转砖  爪专 转 爪' 砖.

- `砖注专 转 注 专砖转转 专:`   转 砖注 注 转 -LLM 砖.

- `Azure AI Search` -`Azure Cosmos DB:` 专 转 拽专 住 转 砖 爪专转 拽住 驻砖.

砖转砖  爪专  转专 注专转 砖, 专住 专 住 转爪转.  转,     RAG 爪  注:

## 爪专转 转砖转 注砖专转 注 住住 注 (RAG)

爪' 住住 LLM 注 驻转 砖转砖  爪专 转转.  注 转 专拽 转拽砖专 注 砖转砖  专 砖 砖. 注 转, 转转 砖 转 拽砖专 砖住驻拽 转  住住 砖. , 注 砖 GPT-4  住驻专 2021, 专,  住专 注 注 专注 砖转专砖 专 转拽驻 . 住祝, 转 砖砖砖  LLMs   注 住  注专转 砖转  专 爪专 砖 专.

### 爪 驻注 RAGs (爪专转 转砖转 注砖专转 注 住住 注)

![砖专 砖专 爪 驻注 RAGs](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.he.png)

 砖转 专爪 驻专住 爪' 砖爪专  注专转 砖, 转爪专 专 住住 注.  住 转 RAG. RAGs 驻注 :

- **住住 注:** 驻 砖驻, 砖 住 注 转 住 , 专  注  驻专拽 住  拽 拽 转专, 驻转 注转 拽住 住 专 转.

- **砖转 砖转砖:** 砖转砖 砖 砖.

- **砖驻:** 砖专 砖转砖 砖 砖,  注 砖祝 注 专 住住 注 砖  住驻拽 转专 拽砖专 砖砖 驻.

- **爪专 注砖专转:** -LLM 砖驻专 转 转转 注 住 转 砖砖驻.  驻砖专 转 砖爪专转 转住住  专拽 注 转    注 注 专 拽砖专 砖住祝. 转 砖砖驻 砖砖 注砖专 转 转转 -LLM. 专  -LLM 专 转砖 砖转 砖转砖.

![砖专 砖专 转 专拽专 砖 RAGs](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.he.png)

专拽专 砖 RAGs 砖转 爪注转 专住驻专专 专 砖 拽: 拽 驻注. , 砖专 砖转砖 砖 砖, 拽住 拽 '拽' 拽专 砖转驻住 转 砖注转  拽专 '驻注' 拽住 住 砖 爪专 拽住 砖 注 住 砖转 砖转砖. -LLM 砖转砖   拽-驻注  爪专 转 驻.

砖转 砖转 砖 RAG 驻 专 爪注: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) :

- **_RAG-Sequence_** 砖砖 住 砖砖驻  转 转 转砖  转专 砖转 砖转砖.

- **RAG-Token** 砖砖 住  爪专 转 拽 ,  砖祝 转  注转 注 砖转 砖转砖.

###  砖转砖 -RAGs?

- **注砖专 注:**  砖转砖转 拽住转  注转 注转. ,  砖驻专 爪注 砖转 住驻爪驻转 转 注  砖 住住 注 驻.

- 驻转 爪专转 注 砖 注  砖砖 **转 转** 住住 注  住驻拽 拽砖专 砖转 砖转砖.

-  **住**  砖 住 转专 砖 转 砖转 砖 LLM.

## 爪专转 住住 注

砖 砖 住住 注 转 砖 砖, 专, 砖注专 注 专砖转转 专 转转  砖 AI 转.

### 专 转 拽专

专 转 拽专,  专 转 住专转,  专 转  砖注 住,  驻砖 拽专 注.  住 爪 住驻专 砖 住. 驻专拽 转 注转 住驻专转 拽 注 注专转  转转 砖  注 转 转.

 住 转 注转 砖 专 转 拽专  砖-LLMs 砖  注 住驻专 拽 砖 拽 拽.  砖 转 注专 转  注转 -LLM, 爪专 驻专拽 转 拽 砖专 砖转砖 砖 砖, 注转 转 转专 砖 专  注 驻. 驻专拽  驻转 注转 注 住驻专 拽 砖注专 专 LLM.

 专 转 拽专 驻驻专  Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant -DeepLake. 转 爪专  Azure Cosmos DB 爪注转 Azure CLI 注 驻拽 :

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### 拽住 注转

驻 砖住 转 转 砖, 爪专 专 转 注转 拽专转 驻 砖 住 专 转.  转 注 注 住   拽住 专, 转 驻专拽 转 注 住 砖转 砖转 爪驻. 驻专拽  转爪注 专转 砖驻  专转 驻住拽.  砖驻专拽 专 砖注转  住, 转 住祝 拽砖专 住祝 拽, , 注  住驻转 转专转 住  转 拽住 驻  专 拽. 转 驻专拽 转 转 :

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

专 驻专拽,  注 转 拽住 砖 爪注转  砖 注.   砖转 砖转砖  : word2vec, ada-002 砖 OpenAI, Azure Computer Vision 注 专. 专转  砖砖 转 砖驻转 砖 转 砖转砖, 住 转 拽 (拽住/转转/),  拽 砖  拽 专 驻 砖 注.

 拽住 注 爪注转  `text-embedding-ada-002` 砖 OpenAI :
![注 砖  转](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.he.png)

## 砖驻 驻砖 拽专

砖专 砖转砖 砖 砖, 注专转 专 转 拽专 爪注转 拽 砖转,  驻砖转 拽住 住 砖 拽专 专 住 砖拽砖专 拽. 专 ,  专 转 拽专 拽 转 拽专 住 拽住 注专 转 专 -LLM.

### 砖驻

砖驻 转专砖转 砖专 注专转 住 爪 专转 转 住 拽住 砖 转 拽专专 驻砖. 专转 砖驻  砖 住 砖砖砖 住驻拽 拽砖专 注 转 -LLM 注 转 砖.

砖 住驻专 专 爪注 驻砖 转 专 转 砖 :

- **驻砖 驻 转 驻转** - 砖砖 驻砖 拽住.

- **驻砖 住** - 砖转砖 砖注转 住转 砖 .

- **驻砖 拽专** - 专 住 拽住 爪 拽专 爪注转  注. 砖驻 转转爪注 注  砖转 住 砖爪 拽专 拽专 转专 砖转 砖转砖.

- **专** - 砖 砖 驻砖 驻 转 驻转 驻砖 拽专.

转专 注 砖驻 转专砖 砖专  转  砖 专 转, 注专转 转专 转 注  转专 砖  砖, 注 转, 转 砖转砖 拽拽转  专转 专拽 专 专转  砖砖 驻砖 专 砖砖  转 驻转  驻砖 拽专. 砖注专  砖转砖 驻砖 专, 砖 砖 驻砖 拽专 驻砖 驻 转 驻转. 住 转 转 砖 住专转 转 注 注转 转 转 拽   转 注转.

###  拽专

注专转 转驻砖 住住 注 注转 砖拽专转  , 砖 拽专 转专,  砖 拽住 砖. 转专砖 砖 砖转砖 砖 砖,  拽 注转  转转 注转 转.  驻爪 砖砖砖转  爪 注  拽专 砖    拽住住 住住 注 转  砖 拽专.

转   爪注转 驻转 专转  专拽 拽 砖 拽 砖专  拽转 拽爪 砖 拽专 驻 驻转 砖转 转 住 驻转 砖  转 砖 砖 拽专.

### 拽住 驻砖

砖专 爪注 砖驻, 爪专 转 拽住 驻砖 注专 住住 注 砖 驻 砖爪注 驻砖. 拽住 住 转 注转 砖  砖祝 专转 转 拽  转专  专 转 . 转 爪专 转 拽住 砖 驻 拽 爪注转:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### 专 砖

专 砖砖转 转 专 转, 转 砖转爪专  转 转爪转  专转. LLM 专 砖 砖转砖 转   砖驻专 转 专转 砖 转爪转 驻砖 注  住专  专转. 爪注转 Azure AI Search, 专 砖 转爪注 转 注专 爪注转 专 住.  驻 砖 专 砖 注 爪注转 砖 拽专:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## 专  

砖 专  住驻转 -LLM 砖 转  拽 转转 砖住住转 注 转 砖. 转 砖 转 :

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## 注专转 砖 砖

###  注专

- 转 转转 住驻拽转,  砖 砖注转 注转, 砖驻转 转 砖转.

- 注 转: 注专转  转 注 住 砖住驻拽.

- 专转: 注专转  转 转转 转拽砖专转 砖 砖砖.

- 砖驻转 -  转 转  拽拽转.

## 砖砖 -RAG (爪专转 转砖转 注砖专转 注 住住 注) 专 转 拽专

砖 砖砖 专 砖 拽专转 驻拽爪 转 砖驻专 转 砖 砖 :

- 砖转 转砖转: 注 转 专 砖 爪' 砖转 砖转砖  注  注 砖 砖转.

- 注专转 爪: 砖 转 爪专 注专转 砖转 转 注专  转专, , 住专, 住注转 注.

- 砖专转 爪': 转 住 住专转 爪' 转 砖转 转 砖 注 住 转 砖转砖.

- 驻砖 转转 注 住住 注转 拽专转, 砖砖 砖专 注砖  转转  专转.

## 住

住 转 转 住住 砖 RAG 住驻转 转 砖 砖, 砖转 砖转砖 驻 转砖.  驻砖 转 爪专转 RAG, 转 砖转砖 住专转  Semantic Kernel, Langchain  Autogen.

## 砖

 砖  注 爪专转 转砖转 注砖专转 注 住住 注 (RAG) 转 转:

- 转 砖拽 拽 砖 爪注转 住专转 专转.

- 砖转砖 住专转,   LangChain  Semantic Kernel, 砖专 转 砖 砖.

专转 注 住 砖注专 .

##   注爪专转 , 砖 住注

专 住 砖注专, 拽 转 [住祝  砖 AI 专](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)  砖 注拽 转 注 砖  转转 专转!

---

**转 转专**:  
住  转专 爪注转 砖专转 转专 AI [Co-op Translator](https://github.com/Azure/co-op-translator). 专转 砖 砖驻 拽, 砖 拽转 砖 砖转专  注砖  砖转   拽. 住 拽专 砖驻转 拽专转 爪专 砖 拽专 住转. 注专 注 拽专, 抓 砖转砖 转专 拽爪注 砖.  专  转  驻专砖转 砖转 注转 砖砖 转专 .