{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# פרק 7: בניית יישומי צ'אט\n",
    "## התחלה מהירה עם OpenAI API\n",
    "\n",
    "מחברת זו מותאמת ממאגר הדוגמאות של [Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) שכולל מחברות המתחברות לשירותי [Azure OpenAI](notebook-azure-openai.ipynb).\n",
    "\n",
    "ה-API של OpenAI בפייתון עובד גם עם מודלים של Azure OpenAI, עם כמה התאמות קטנות. למידע נוסף על ההבדלים, ראו כאן: [כיצד לעבור בין נקודות קצה של OpenAI ו-Azure OpenAI בפייתון](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# סקירה כללית  \n",
    "\"מודלים גדולים של שפה הם פונקציות שממפות טקסט לטקסט. כאשר מקבלים מחרוזת טקסט כקלט, מודל שפה גדול מנסה לחזות את הטקסט שיגיע אחריו\" (1). מחברת \"התחלה מהירה\" זו תציג למשתמשים מושגים מרכזיים על מודלים גדולים של שפה, דרישות עיקריות להתחלת עבודה עם AML, היכרות רכה עם עיצוב פקודות (prompt design), וכמה דוגמאות קצרות לשימושים שונים.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## תוכן העניינים  \n",
    "\n",
    "[סקירה כללית](../../../../07-building-chat-applications/python)  \n",
    "[איך להשתמש בשירות OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[1. יצירת שירות OpenAI שלך](../../../../07-building-chat-applications/python)  \n",
    "[2. התקנה](../../../../07-building-chat-applications/python)    \n",
    "[3. פרטי גישה](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[שימושים אפשריים](../../../../07-building-chat-applications/python)    \n",
    "[1. סיכום טקסט](../../../../07-building-chat-applications/python)  \n",
    "[2. סיווג טקסט](../../../../07-building-chat-applications/python)  \n",
    "[3. יצירת שמות חדשים למוצרים](../../../../07-building-chat-applications/python)  \n",
    "[4. כיוונון מדויק של מסווג](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[מקורות](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### בנה את הפרומפט הראשון שלך  \n",
    "תרגיל קצר זה יספק היכרות בסיסית עם שליחת פרומפטים למודל של OpenAI עבור משימה פשוטה של \"סיכום\".\n",
    "\n",
    "**שלבים**:  \n",
    "1. התקן את ספריית OpenAI בסביבת הפייתון שלך  \n",
    "2. טען ספריות עזר סטנדרטיות והגדר את פרטי האבטחה הרגילים שלך עבור שירות ה-OpenAI שיצרת  \n",
    "3. בחר מודל למשימה שלך  \n",
    "4. צור פרומפט פשוט עבור המודל  \n",
    "5. שלח את הבקשה שלך ל-API של המודל!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. התקן את OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. ייבוא ספריות עזר ואתחול אישורים\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. מציאת המודל המתאים  \n",
    "המודלים GPT-3.5-turbo או GPT-4 מסוגלים להבין וליצור שפה טבעית.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. עיצוב פקודות  \n",
    "\n",
    "\"הקסם של מודלים גדולים לשפה הוא שבזמן שהם מתאמנים למזער את שגיאת החיזוי על כמויות אדירות של טקסט, הם בסופו של דבר לומדים מושגים שמועילים לחיזויים האלה. לדוגמה, הם לומדים מושגים כמו\"(1):\n",
    "\n",
    "* איך לאיית מילים\n",
    "* איך עובדת הדקדוק\n",
    "* איך לנסח מחדש\n",
    "* איך לענות על שאלות\n",
    "* איך לנהל שיחה\n",
    "* איך לכתוב בשפות רבות\n",
    "* איך לתכנת\n",
    "* ועוד.\n",
    "\n",
    "#### איך לשלוט במודל שפה גדול  \n",
    "\"מכל הקלטים למודל שפה גדול, הקלט המשפיע ביותר הוא הטקסט של הפקודה\"(1).\n",
    "\n",
    "מודלים גדולים לשפה אפשר להפעיל בכמה דרכים:\n",
    "\n",
    "הוראה: להגיד למודל מה אתה רוצה\n",
    "השלמה: לגרום למודל להשלים את ההתחלה של מה שאתה רוצה\n",
    "הדגמה: להראות למודל מה אתה רוצה, עם:\n",
    "כמה דוגמאות בתוך הפקודה\n",
    "מאות או אלפי דוגמאות בתוך מערך אימון מותאם אישית\"\n",
    "\n",
    "\n",
    "\n",
    "#### יש שלוש הנחיות בסיסיות ליצירת פקודות:\n",
    "\n",
    "**להראות ולהסביר**. תבהיר מה אתה רוצה, דרך הוראות, דוגמאות, או שילוב של שניהם. אם אתה רוצה שהמודל ידורג רשימה בסדר אלפביתי או יסווג פסקה לפי רגש, תראה לו שזה מה שאתה רוצה.\n",
    "\n",
    "**תספק נתונים איכותיים**. אם אתה מנסה לבנות מסווג או לגרום למודל לעקוב אחרי דפוס מסוים, תוודא שיש מספיק דוגמאות. תבדוק את הדוגמאות שלך — המודל בדרך כלל מספיק חכם כדי להתעלם משגיאות כתיב בסיסיות ולתת לך תשובה, אבל הוא גם עלול להניח שזה מכוון וזה יכול להשפיע על התשובה.\n",
    "\n",
    "**תבדוק את ההגדרות שלך.** ההגדרות של temperature ו-top_p קובעות עד כמה המודל יהיה דטרמיניסטי בתגובה שלו. אם אתה מבקש תשובה שיש לה רק תשובה אחת נכונה, כדאי להוריד את הערכים האלה. אם אתה מחפש תגובות מגוונות יותר, אולי תרצה להעלות אותם. הטעות הכי נפוצה שאנשים עושים עם ההגדרות האלה היא לחשוב שהן שולטות ב\"תחכום\" או \"יצירתיות\" של המודל.\n",
    "\n",
    "\n",
    "מקור: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### חזור על אותה קריאה, כיצד התוצאות משוות?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## סכם טקסט  \n",
    "#### אתגר  \n",
    "סכם טקסט על ידי הוספת 'tl;dr:' בסוף קטע הטקסט. שים לב כיצד המודל מבין לבצע מגוון משימות ללא הוראות נוספות. אפשר להתנסות בהנחיות מפורטות יותר מ-tl;dr כדי לשנות את אופן הפעולה של המודל ולהתאים את הסיכום שתקבל(3).\n",
    "\n",
    "עבודות עדכניות הראו שיפור משמעותי במשימות NLP רבות ובמדדים שונים, על ידי אימון מקדים על מאגר טקסטים גדול ואחריו כיוונון עדין למשימה מסוימת. למרות שהשיטה לרוב אינה תלויה במשימה מבחינת הארכיטקטורה, היא עדיין דורשת מערכי נתונים ייעודיים לכיוונון עדין עם אלפי או עשרות אלפי דוגמאות. לעומת זאת, בני אדם בדרך כלל מסוגלים לבצע משימת שפה חדשה בעזרת כמה דוגמאות בודדות או הוראות פשוטות – דבר שמערכות NLP כיום עדיין מתקשות בו. כאן אנו מראים שהגדלת מודלים לשפה משפרת מאוד את הביצועים במצבים של מעט דוגמאות וללא תלות במשימה, ולעיתים אף מתקרבת או משתווה לשיטות כיוונון עדין שהיו המובילות עד כה.\n",
    "\n",
    "tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# תרגילים למספר מקרי שימוש  \n",
    "1. סכם טקסט  \n",
    "2. סווג טקסט  \n",
    "3. צור שמות חדשים למוצרים\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## סיווג טקסט  \n",
    "#### אתגר  \n",
    "סווג פריטים לקטגוריות שניתנות בזמן הרצה. בדוגמה הבאה, אנו מספקים גם את הקטגוריות וגם את הטקסט לסיווג בתוך ההנחיה (*playground_reference).\n",
    "\n",
    "פניית לקוח: שלום, אחד המקשים במקלדת המחשב הנייד שלי נשבר לאחרונה ואני צריך מקש חלופי:\n",
    "\n",
    "קטגוריה מסווגת:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## צור שמות חדשים למוצרים\n",
    "#### אתגר\n",
    "צור שמות למוצרים מתוך מילים לדוגמה. כאן אנו כוללים בתיאור מידע על המוצר עבורו אנו יוצרים שמות. בנוסף, אנו מספקים דוגמה דומה כדי להמחיש את הסגנון הרצוי. קבענו ערך טמפרטורה גבוה כדי להגדיל את רמת האקראיות ולקבל תשובות חדשניות יותר.\n",
    "\n",
    "תיאור מוצר: מכשיר ביתי להכנת שייקים\n",
    "מילות מפתח: מהיר, בריא, קומפקטי.\n",
    "שמות מוצרים: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "תיאור מוצר: זוג נעליים שמתאים לכל גודל רגל.\n",
    "מילות מפתח: מתכוונן, מתאים, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# מקורות  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Examples](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [שיטות עבודה מומלצות לכיול עדין של GPT-3 לסיווג טקסט](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# לעזרה נוספת  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# תורמים\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\nCertainly! Here is your text translated into Hebrew:\n\n**כתב ויתור**:  \nמסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עלולים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפת המקור ייחשב כמקור הסמכותי. למידע קריטי, מומלץ לפנות לתרגום מקצועי על ידי אדם. איננו אחראים לכל אי-הבנה או פרשנות שגויה הנובעת מהשימוש בתרגום זה.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:22:05+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "he"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}