{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "כדי להריץ את המחברות הבאות, אם עדיין לא עשית זאת, עליך לפרוס מודל שמשתמש ב־`text-embedding-ada-002` כמודל בסיס ולהגדיר את שם הפריסה בתוך קובץ ‎.env כ־`AZURE_OPENAI_EMBEDDINGS_ENDPOINT`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "לאחר מכן, נטען את אינדקס ההטמעות אל תוך Dataframe של Pandas. אינדקס ההטמעות מאוחסן בקובץ JSON בשם `embedding_index_3m.json`. אינדקס ההטמעות מכיל את ההטמעות עבור כל תמלולי YouTube עד לסוף אוקטובר 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "בהמשך, ניצור פונקציה בשם `get_videos` שתחפש את השאילתה בתוך אינדקס ההטמעות. הפונקציה תחזיר את חמשת הסרטונים שהכי דומים לשאילתה. כך הפונקציה פועלת:\n",
    "\n",
    "1. קודם כל, נוצרת עותק של אינדקס ההטמעות.\n",
    "2. לאחר מכן, מחושבת ההטמעה עבור השאילתה בעזרת OpenAI Embedding API.\n",
    "3. אז נוצרת עמודה חדשה באינדקס ההטמעות בשם `similarity`. עמודת `similarity` מכילה את הדמיון הקוסיני בין ההטמעה של השאילתה לבין ההטמעות של כל קטע וידאו.\n",
    "4. בשלב הבא, אינדקס ההטמעות מסונן לפי עמודת `similarity`. האינדקס מסונן כך שיכלול רק סרטונים עם דמיון קוסיני של 0.75 ומעלה.\n",
    "5. לבסוף, אינדקס ההטמעות ממויין לפי עמודת `similarity` ומוחזרים חמשת הסרטונים המובילים.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "הפונקציה הזו מאוד פשוטה, היא פשוט מדפיסה את תוצאות שאילתת החיפוש.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ראשית, אינדקס ההטמעות נטען לתוך Dataframe של Pandas.\n",
    "2. לאחר מכן, המשתמש מתבקש להזין שאילתה.\n",
    "3. אז פונקציית `get_videos` נקראת כדי לחפש את השאילתה באינדקס ההטמעות.\n",
    "4. לבסוף, פונקציית `display_results` נקראת כדי להציג את התוצאות למשתמש.\n",
    "5. המשתמש מתבקש להזין שאילתה נוספת. התהליך הזה ממשיך עד שהמשתמש מזין `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.he.png)\n",
    "\n",
    "תתבקשו להזין שאילתה. הזינו שאילתה ולחצו על Enter. האפליקציה תחזיר רשימה של סרטונים שרלוונטיים לשאילתה. בנוסף, האפליקציה תספק קישור למקום בסרטון שבו נמצאת התשובה לשאלה.\n",
    "\n",
    "הנה כמה שאילתות שכדאי לנסות:\n",
    "\n",
    "- מה זה Azure Machine Learning?\n",
    "- איך רשתות עצביות קונבולוציוניות עובדות?\n",
    "- מהי רשת עצבית?\n",
    "- האם אפשר להשתמש ב-Jupyter Notebooks עם Azure Machine Learning?\n",
    "- מה זה ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\nCertainly! Here is your text translated into Hebrew:\n\n**כתב ויתור**:  \nמסמך זה תורגם באמצעות שירות תרגום מבוסס בינה מלאכותית [Co-op Translator](https://github.com/Azure/co-op-translator). למרות שאנו שואפים לדיוק, יש להיות מודעים לכך שתרגומים אוטומטיים עלולים להכיל שגיאות או אי-דיוקים. המסמך המקורי בשפת המקור ייחשב כמקור הסמכותי. למידע קריטי, מומלץ לפנות לתרגום מקצועי על ידי אדם. איננו אחראים לכל אי-הבנה או פירוש שגוי הנובעים מהשימוש בתרגום זה.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "32c6b8e9e87156b9c63ee62a6fd7f526",
   "translation_date": "2025-08-25T18:45:43+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "he"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}