{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giriş \n",
    "\n",
    "Bu ders şunları kapsayacaktır: \n",
    "- Fonksiyon çağrısı nedir ve kullanım alanları \n",
    "- OpenAI kullanarak fonksiyon çağrısı nasıl oluşturulur \n",
    "- Bir uygulamaya fonksiyon çağrısı nasıl entegre edilir \n",
    "\n",
    "## Öğrenme Hedefleri \n",
    "\n",
    "Bu dersi tamamladıktan sonra şunları bilecek ve anlayacaksınız: \n",
    "\n",
    "- Fonksiyon çağrısı kullanmanın amacı \n",
    "- OpenAI Servisi kullanarak Fonksiyon Çağrısı kurulumu \n",
    "- Uygulamanızın kullanım durumu için etkili fonksiyon çağrıları tasarlama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fonksiyon Çağrılarını Anlamak\n",
    "\n",
    "Bu ders için, kullanıcıların teknik kursları bulmak için bir sohbet botu kullanmasına olanak tanıyan bir özellik oluşturmak istiyoruz. Kullanıcıların beceri seviyelerine, mevcut rollerine ve ilgi duydukları teknolojiye uygun kurslar önereceğiz.\n",
    "\n",
    "Bunu tamamlamak için şu kombinasyonu kullanacağız:\n",
    " - Kullanıcı için bir sohbet deneyimi oluşturmak üzere `OpenAI`\n",
    " - Kullanıcının isteğine göre kurs bulmasına yardımcı olmak için `Microsoft Learn Catalog API`\n",
    " - Kullanıcının sorgusunu alıp API isteği yapmak için bir fonksiyona göndermek üzere `Fonksiyon Çağrısı`\n",
    "\n",
    "Başlamak için, öncelikle neden fonksiyon çağrısı kullanmak istediğimize bakalım:\n",
    "\n",
    "print(\"Bir sonraki istekteki Mesajlar:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # Fonksiyon yanıtını görebileceği yeni bir GPT yanıtı alın\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neden Fonksiyon Çağrısı\n",
    "\n",
    "Bu kurstaki başka bir dersi tamamladıysanız, Muazzam Dil Modelleri'nin (LLM'ler) gücünü muhtemelen anlamışsınızdır. Umarım aynı zamanda bazı sınırlamalarını da görebilirsiniz.\n",
    "\n",
    "Fonksiyon Çağrısı, OpenAI Hizmeti'nin aşağıdaki zorlukları ele almak için tasarlanmış bir özelliğidir:\n",
    "\n",
    "Tutarsız Yanıt Formatlama:\n",
    "- Fonksiyon çağrısından önce, büyük dil modelinden gelen yanıtlar yapılandırılmamış ve tutarsızdı. Geliştiricilerin çıktının her varyasyonunu işlemek için karmaşık doğrulama kodları yazması gerekiyordu.\n",
    "\n",
    "Dış Veri ile Sınırlı Entegrasyon:\n",
    "- Bu özellikten önce, bir uygulamanın diğer bölümlerinden gelen verileri sohbet bağlamına dahil etmek zordu.\n",
    "\n",
    "Yanıt formatlarını standartlaştırarak ve dış veri ile sorunsuz entegrasyon sağlayarak, fonksiyon çağrısı geliştirmeyi basitleştirir ve ek doğrulama mantığı ihtiyacını azaltır.\n",
    "\n",
    "Kullanıcılar \"Stockholm'deki güncel hava durumu nedir?\" gibi cevaplar alamıyordu. Bunun nedeni, modellerin yalnızca verilerin eğitildiği zamana kadar sınırlı olmasıydı.\n",
    "\n",
    "Bu sorunu gösteren aşağıdaki örneğe bakalım:\n",
    "\n",
    "Öğrencilere doğru kursu önerebilmek için bir öğrenci veri tabanı oluşturmak istediğimizi varsayalım. Aşağıda, içerdiği veriler açısından çok benzer olan iki öğrenci açıklaması bulunmaktadır.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu veriyi ayrıştırması için bir LLM'ye göndermek istiyoruz. Bu daha sonra uygulamamızda bir API'ye göndermek veya bir veritabanında saklamak için kullanılabilir.\n",
    "\n",
    "LLM'ye hangi bilgileri istediğimizi belirttiğimiz iki özdeş istem oluşturalım:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bunu, ürünümüz için önemli olan kısımları ayrıştırması için bir LLM'ye göndermek istiyoruz. Böylece LLM'yi yönlendirmek için iki özdeş istem oluşturabiliriz:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu iki istemi oluşturduktan sonra, onları `openai.ChatCompletion` kullanarak LLM'ye göndereceğiz. İstemi `messages` değişkeninde saklıyoruz ve role olarak `user` atıyoruz. Bu, bir kullanıcının bir sohbet botuna mesaj yazmasını taklit etmek içindir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi her iki isteği de LLM'ye gönderebilir ve aldığımız yanıtı inceleyebiliriz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aynı istemler ve benzer açıklamalar olmasına rağmen, `Grades` özelliğinin farklı formatlarını alabiliriz.\n",
    "\n",
    "Yukarıdaki hücreyi birden çok kez çalıştırırsanız, format `3.7` veya `3.7 GPA` olabilir.\n",
    "\n",
    "Bunun nedeni, LLM'nin yazılı istem biçiminde yapılandırılmamış veriler alması ve yine yapılandırılmamış veriler döndürmesidir. Bu veriyi depolarken veya kullanırken ne bekleyeceğimizi bilmek için yapılandırılmış bir formata ihtiyacımız var.\n",
    "\n",
    "Fonksiyon çağrısı kullanarak, yapılandırılmış verileri geri aldığımızdan emin olabiliriz. Fonksiyon çağrısı kullanıldığında, LLM aslında herhangi bir fonksiyonu çağırmaz veya çalıştırmaz. Bunun yerine, LLM'nin yanıtları için takip etmesi gereken bir yapı oluştururuz. Daha sonra bu yapılandırılmış yanıtları, uygulamalarımızda hangi fonksiyonun çalıştırılacağını bilmek için kullanırız.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fonksiyon Çağrısı Akış Diyagramı](../../../../translated_images/tr/Function-Flow.083875364af4f4bb.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daha sonra fonksiyondan dönen değeri alabilir ve bunu LLM'ye geri gönderebiliriz. LLM, kullanıcının sorgusunu yanıtlamak için doğal dil kullanarak cevap verecektir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonksiyon çağrıları kullanmanın kullanım durumları\n",
    "\n",
    "**Dış Araçları Çağırma**  \n",
    "Chatbotlar, kullanıcılardan gelen sorulara cevap vermede iyidir. Fonksiyon çağrısı kullanarak, chatbotlar kullanıcı mesajlarını belirli görevleri tamamlamak için kullanabilir. Örneğin, bir öğrenci chatbot'a \"Bu konuda daha fazla yardıma ihtiyacım olduğunu öğretmenime e-posta gönder\" diyebilir. Bu, `send_email(to: string, body: string)` fonksiyonunu çağırabilir.\n",
    "\n",
    "**API veya Veritabanı Sorguları Oluşturma**  \n",
    "Kullanıcılar, doğal dil kullanarak bilgi bulabilir ve bu dil biçimlendirilmiş bir sorgu veya API isteğine dönüştürülebilir. Bunun bir örneği, \"Son ödevi tamamlayan öğrenciler kimler\" diye soran bir öğretmen olabilir; bu, `get_completed(student_name: string, assignment: int, current_status: string)` adlı bir fonksiyonu çağırabilir.\n",
    "\n",
    "**Yapılandırılmış Veri Oluşturma**  \n",
    "Kullanıcılar bir metin bloğunu veya CSV'yi alıp önemli bilgileri çıkarmak için LLM'yi kullanabilir. Örneğin, bir öğrenci barış anlaşmaları hakkında bir Wikipedia makalesini AI flash kartları oluşturmak için dönüştürebilir. Bu, `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` adlı bir fonksiyon kullanılarak yapılabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. İlk Fonksiyon Çağrınızı Oluşturma\n",
    "\n",
    "Bir fonksiyon çağrısı oluşturma süreci 3 ana adımdan oluşur:  \n",
    "1. Fonksiyonlarınızın bir listesi ve bir kullanıcı mesajı ile Chat Completions API'sini çağırmak  \n",
    "2. Bir işlem gerçekleştirmek için modelin yanıtını okumak, yani bir fonksiyonu veya API Çağrısını yürütmek  \n",
    "3. Fonksiyonunuzdan gelen yanıtla Chat Completions API'sine başka bir çağrı yapmak ve bu bilgiyi kullanıcıya yanıt oluşturmak için kullanmak.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bir Fonksiyon Çağrısının Akışı](../../../../translated_images/tr/LLM-Flow.3285ed8caf4796d7.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bir fonksiyon çağrısının öğeleri\n",
    "\n",
    "#### Kullanıcı Girişi\n",
    "\n",
    "İlk adım bir kullanıcı mesajı oluşturmaktır. Bu, bir metin girişinin değerini alarak dinamik olarak atanabilir veya burada bir değer atayabilirsiniz. Eğer Chat Completions API ile ilk kez çalışıyorsanız, mesajın `role` ve `content` öğelerini tanımlamamız gerekir.\n",
    "\n",
    "`role` ya `system` (kuralları oluşturma), `assistant` (model) ya da `user` (son kullanıcı) olabilir. Fonksiyon çağrısı için bunu `user` olarak atayacağız ve bir örnek soru vereceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonksiyon oluşturma.\n",
    "\n",
    "Sonraki adımda bir fonksiyon ve o fonksiyonun parametrelerini tanımlayacağız. Burada sadece `search_courses` adlı bir fonksiyon kullanacağız ancak birden fazla fonksiyon oluşturabilirsiniz.\n",
    "\n",
    "**Önemli** : Fonksiyonlar, LLM'ye gönderilen sistem mesajına dahil edilir ve kullanılabilir token miktarınıza dahil edilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tanımlar** \n",
    "\n",
    "Fonksiyon tanımı yapısı, her biri kendi özelliklerine sahip birden çok seviyeye sahiptir. İşte iç içe yapının bir dökümü:\n",
    "\n",
    "**En Üst Düzey Fonksiyon Özellikleri:**\n",
    "\n",
    "`name` - Çağrılmasını istediğimiz fonksiyonun adı.\n",
    "\n",
    "`description` - Fonksiyonun nasıl çalıştığına dair açıklama. Burada spesifik ve net olmak önemlidir.\n",
    "\n",
    "`parameters` - Modelin yanıtında üretmesini istediğiniz değerler ve formatların listesi.\n",
    "\n",
    "**Parametreler Nesnesi Özellikleri:**\n",
    "\n",
    "`type` - Parametreler nesnesinin veri tipi (genellikle \"object\")\n",
    "\n",
    "`properties` - Modelin yanıtında kullanacağı belirli değerlerin listesi.\n",
    "\n",
    "**Bireysel Parametre Özellikleri:**\n",
    "\n",
    "`name` - Özellik anahtarı tarafından örtük olarak tanımlanır (örneğin, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Bu belirli parametrenin veri tipi (örneğin, \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Belirli parametrenin açıklaması.\n",
    "\n",
    "**İsteğe Bağlı Özellikler:**\n",
    "\n",
    "`required` - Fonksiyon çağrısının tamamlanması için hangi parametrelerin gerekli olduğunu listeleyen bir dizi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonksiyon çağrısı yapma  \n",
    "Bir fonksiyon tanımladıktan sonra, şimdi onu Chat Completion API çağrısına dahil etmemiz gerekiyor. Bunu, isteğe `functions` ekleyerek yapıyoruz. Bu durumda `functions=functions`.  \n",
    "\n",
    "Ayrıca `function_call` değerini `auto` olarak ayarlama seçeneği de vardır. Bu, fonksiyon çağrısını kendimiz atamak yerine, hangi fonksiyonun çağrılacağına LLM'nin kullanıcı mesajına göre karar vermesine izin vereceğimiz anlamına gelir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi yanıtı inceleyelim ve nasıl formatlandığına bakalım:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Fonksiyonun adı çağrılmış ve kullanıcı mesajından, LLM'nin fonksiyonun argümanlarına uyan veriyi bulabildiğini görebilirsiniz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Bir Uygulamaya Fonksiyon Çağrılarını Entegre Etme. \n",
    "\n",
    "\n",
    "LLM'den biçimlendirilmiş yanıtı test ettikten sonra, şimdi bunu bir uygulamaya entegre edebiliriz. \n",
    "\n",
    "### Akışı Yönetme \n",
    "\n",
    "Bunu uygulamamıza entegre etmek için, aşağıdaki adımları izleyelim: \n",
    "\n",
    "Öncelikle, OpenAI hizmetlerine çağrı yapalım ve mesajı `response_message` adlı bir değişkende saklayalım. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi Microsoft Learn API'sini çağırarak kurs listesini alacak fonksiyonu tanımlayacağız:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En iyi uygulama olarak, modelin bir fonksiyonu çağırmak isteyip istemediğine bakacağız. Bundan sonra, mevcut fonksiyonlardan birini oluşturup çağrılan fonksiyonla eşleştireceğiz.  \n",
    "Ardından, fonksiyonun argümanlarını alıp bunları LLM'den gelen argümanlarla eşleştireceğiz.\n",
    "\n",
    "Son olarak, fonksiyon çağrısı mesajını ve `search_courses` mesajı tarafından döndürülen değerleri ekleyeceğiz. Bu, LLM'ye kullanıcıya doğal dil kullanarak yanıt vermesi için gereken tüm bilgileri sağlar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Şimdi, API JSON formatında bir yanıt yerine doğal dil yanıtı alabilmemiz için güncellenmiş mesajı LLM'ye göndereceğiz.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kod Meydan Okuması\n",
    "\n",
    "Harika iş! OpenAI Fonksiyon Çağrısı öğreniminize devam etmek için şunları oluşturabilirsiniz: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Öğrencilerin daha fazla kurs bulmasına yardımcı olabilecek fonksiyonun daha fazla parametresi. Mevcut API parametrelerini burada bulabilirsiniz:  \n",
    " - Öğrencinin ana dili gibi daha fazla bilgi alan başka bir fonksiyon çağrısı oluşturun  \n",
    " - Fonksiyon çağrısı ve/veya API çağrısı uygun kurslar döndürmediğinde hata yönetimi oluşturun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Feragatname**:  \nBu belge, AI çeviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba gösterilse de, otomatik çevirilerin hatalar veya yanlışlıklar içerebileceğini lütfen unutmayın. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımı sonucu oluşabilecek yanlış anlamalar veya yorum hatalarından sorumlu değiliz.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T10:16:38+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "tr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}