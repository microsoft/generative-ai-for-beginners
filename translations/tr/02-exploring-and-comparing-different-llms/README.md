<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:25:43+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "tr"
}
-->
# FarklÄ± LLMâ€™leri KeÅŸfetmek ve KarÅŸÄ±laÅŸtÄ±rmak

[![FarklÄ± LLMâ€™leri KeÅŸfetmek ve KarÅŸÄ±laÅŸtÄ±rmak](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.tr.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Bu dersin videosunu izlemek iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n_

Ã–nceki derste, Ãœretken Yapay ZekÃ¢â€™nÄ±n teknoloji dÃ¼nyasÄ±nÄ± nasÄ±l deÄŸiÅŸtirdiÄŸini, BÃ¼yÃ¼k Dil Modelleriâ€™nin (LLMâ€™ler) nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± ve bir iÅŸletmenin â€“ bizim startupâ€™Ä±mÄ±z gibi â€“ bunlarÄ± nasÄ±l kendi kullanÄ±m senaryolarÄ±na uygulayÄ±p bÃ¼yÃ¼yebileceÄŸini gÃ¶rdÃ¼k! Bu bÃ¶lÃ¼mde ise farklÄ± tÃ¼rde bÃ¼yÃ¼k dil modellerini karÅŸÄ±laÅŸtÄ±rarak avantaj ve dezavantajlarÄ±nÄ± anlamaya Ã§alÄ±ÅŸacaÄŸÄ±z.

Startupâ€™Ä±mÄ±zÄ±n yolculuÄŸundaki bir sonraki adÄ±m, mevcut LLM manzarasÄ±nÄ± keÅŸfetmek ve hangi modellerin bizim kullanÄ±m senaryomuza uygun olduÄŸunu anlamak.

## GiriÅŸ

Bu derste ÅŸunlar ele alÄ±nacak:

- Mevcut ortamda farklÄ± LLM tÃ¼rleri.
- Azureâ€™da kullanÄ±m senaryonuza uygun modelleri test etme, yineleme ve karÅŸÄ±laÅŸtÄ±rma.
- Bir LLMâ€™nin nasÄ±l daÄŸÄ±tÄ±lacaÄŸÄ±.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra:

- KullanÄ±m senaryonuza en uygun modeli seÃ§ebileceksiniz.
- Modelinizi nasÄ±l test edeceÄŸinizi, yineleyeceÄŸinizi ve performansÄ±nÄ± nasÄ±l artÄ±racaÄŸÄ±nÄ±zÄ± anlayacaksÄ±nÄ±z.
- Ä°ÅŸletmelerin modelleri nasÄ±l daÄŸÄ±ttÄ±ÄŸÄ±nÄ± bileceksiniz.

## FarklÄ± LLM TÃ¼rlerini Anlamak

LLMâ€™ler, mimarileri, eÄŸitim verileri ve kullanÄ±m amaÃ§larÄ±na gÃ¶re farklÄ± kategorilere ayrÄ±labilir. Bu farklarÄ± anlamak, startupâ€™Ä±mÄ±zÄ±n senaryoya uygun doÄŸru modeli seÃ§mesine ve modeli test edip performansÄ±nÄ± artÄ±rmasÄ±na yardÄ±mcÄ± olur.

Ã‡ok sayÄ±da farklÄ± LLM modeli var; hangi modeli seÃ§eceÄŸiniz, onlarÄ± ne amaÃ§la kullanacaÄŸÄ±nÄ±za, verinize, ne kadar harcama yapmaya hazÄ±r olduÄŸunuza ve daha fazlasÄ±na baÄŸlÄ±dÄ±r.

Modelleri metin, ses, video, gÃ¶rsel Ã¼retimi gibi farklÄ± amaÃ§larla kullanmayÄ± planlÄ±yorsanÄ±z, farklÄ± model tÃ¼rlerine yÃ¶nelebilirsiniz.

- **Ses ve konuÅŸma tanÄ±ma**. Bu amaÃ§ iÃ§in Whisper tipi modeller harika bir seÃ§imdir Ã§Ã¼nkÃ¼ genel amaÃ§lÄ±dÄ±r ve konuÅŸma tanÄ±maya yÃ¶neliktir. Ã‡eÅŸitli ses verileriyle eÄŸitilmiÅŸtir ve Ã§ok dilli konuÅŸma tanÄ±ma yapabilir. [Whisper tipi modeller hakkÄ±nda daha fazla bilgi edinin](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **GÃ¶rsel Ã¼retimi**. GÃ¶rsel Ã¼retimi iÃ§in DALL-E ve Midjourney Ã§ok bilinen iki seÃ§enektir. DALL-E, Azure OpenAI tarafÄ±ndan sunulmaktadÄ±r. [DALL-E hakkÄ±nda daha fazla bilgi edinin](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) ve ayrÄ±ca bu mÃ¼fredatÄ±n 9. bÃ¶lÃ¼mÃ¼nde.

- **Metin Ã¼retimi**. Ã‡oÄŸu model metin Ã¼retimi iÃ§in eÄŸitilmiÅŸtir ve GPT-3.5â€™ten GPT-4â€™e kadar geniÅŸ bir seÃ§enek yelpazesi vardÄ±r. FarklÄ± maliyetlerle gelir; GPT-4 en pahalÄ± olanÄ±dÄ±r. [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) Ã¼zerinden yetenek ve maliyet aÃ§Ä±sÄ±ndan ihtiyaÃ§larÄ±nÄ±za en uygun modelleri deÄŸerlendirmek faydalÄ± olacaktÄ±r.

- **Ã‡oklu modalite**. Girdi ve Ã§Ä±ktÄ±da birden fazla veri tÃ¼rÃ¼yle Ã§alÄ±ÅŸmak istiyorsanÄ±z, doÄŸal dil iÅŸleme ile gÃ¶rsel anlayÄ±ÅŸÄ± birleÅŸtiren ve Ã§ok modlu arayÃ¼zlerle etkileÅŸim imkanÄ± sunan [gpt-4 turbo with vision veya gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) gibi modelleri inceleyebilirsiniz â€“ bunlar OpenAIâ€™nin en yeni sÃ¼rÃ¼mleridir.

Bir model seÃ§mek, size temel yetenekler saÄŸlar ancak Ã§oÄŸu zaman bu yeterli olmaz. Genellikle ÅŸirketinize Ã¶zgÃ¼ verileri LLMâ€™ye bir ÅŸekilde aktarmanÄ±z gerekir. Bu konuda farklÄ± yaklaÅŸÄ±mlar vardÄ±r, bunlara sonraki bÃ¶lÃ¼mlerde deÄŸineceÄŸiz.

### Foundation Modeller ile LLMâ€™ler ArasÄ±ndaki Fark

Foundation Model terimi, [Stanford araÅŸtÄ±rmacÄ±larÄ± tarafÄ±ndan ortaya atÄ±lmÄ±ÅŸtÄ±r](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) ve ÅŸu kriterlere sahip AI modelleri olarak tanÄ±mlanÄ±r:

- **GÃ¶zetimsiz Ã¶ÄŸrenme veya kendi kendine gÃ¶zetimli Ã¶ÄŸrenme ile eÄŸitilirler**, yani etiketlenmemiÅŸ Ã§ok modlu veriler Ã¼zerinde eÄŸitilirler ve eÄŸitim sÃ¼recinde insan tarafÄ±ndan veri etiketlemesi gerekmez.
- **Ã‡ok bÃ¼yÃ¼k modellerdir**, milyarlarca parametre Ã¼zerinde eÄŸitilmiÅŸ Ã§ok derin sinir aÄŸlarÄ±na dayanÄ±rlar.
- **Genellikle diÄŸer modeller iÃ§in â€˜temelâ€™ olarak hizmet vermek Ã¼zere tasarlanÄ±rlar**, yani Ã¼zerine baÅŸka modeller inÅŸa edilebilir ve ince ayar yapÄ±labilir.

![Foundation Modeller ile LLMâ€™ler ArasÄ±ndaki Fark](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.tr.png)

GÃ¶rsel kaynaÄŸÄ±: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Bu farkÄ± daha iyi anlamak iÃ§in ChatGPT Ã¶rneÄŸine bakalÄ±m. ChatGPTâ€™nin ilk versiyonunu oluÅŸturmak iÃ§in GPT-3.5 adlÄ± bir model temel model olarak kullanÄ±ldÄ±. Bu, OpenAIâ€™nin sohbet odaklÄ± verilerle GPT-3.5â€™i ince ayar yaparak sohbet senaryolarÄ±nda iyi performans gÃ¶steren Ã¶zel bir versiyon oluÅŸturduÄŸu anlamÄ±na gelir.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.tr.png)

GÃ¶rsel kaynaÄŸÄ±: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### AÃ§Ä±k Kaynak Modeller ile Tescilli Modeller

LLMâ€™leri sÄ±nÄ±flandÄ±rmanÄ±n bir diÄŸer yolu, aÃ§Ä±k kaynak mÄ± yoksa tescilli (proprietary) modeller mi olduklarÄ±dÄ±r.

AÃ§Ä±k kaynak modeller, halka aÃ§Ä±k olarak sunulan ve herkesin kullanabileceÄŸi modellerdir. Genellikle onlarÄ± geliÅŸtiren ÅŸirket veya araÅŸtÄ±rma topluluÄŸu tarafÄ±ndan eriÅŸime aÃ§Ä±lÄ±rlar. Bu modeller incelenebilir, deÄŸiÅŸtirilebilir ve farklÄ± kullanÄ±m senaryolarÄ±na gÃ¶re Ã¶zelleÅŸtirilebilir. Ancak, Ã¼retim kullanÄ±mÄ± iÃ§in her zaman optimize edilmemiÅŸ olabilirler ve tescilli modellere gÃ¶re performanslarÄ± daha dÃ¼ÅŸÃ¼k olabilir. AyrÄ±ca, aÃ§Ä±k kaynak modellerin finansmanÄ± sÄ±nÄ±rlÄ± olabilir, uzun vadede bakÄ±m ve gÃ¼ncellemeleri olmayabilir. PopÃ¼ler aÃ§Ä±k kaynak modeller arasÄ±nda [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) ve [LLaMA](https://llama.meta.com) bulunur.

Tescilli modeller ise bir ÅŸirkete ait olup halka aÃ§Ä±k olmayan modellerdir. Genellikle Ã¼retim kullanÄ±mÄ± iÃ§in optimize edilmiÅŸlerdir. Ancak, incelenmeleri, deÄŸiÅŸtirilmesi veya farklÄ± senaryolara gÃ¶re Ã¶zelleÅŸtirilmesi mÃ¼mkÃ¼n deÄŸildir. AyrÄ±ca, genellikle Ã¼cretsiz deÄŸildirler ve kullanmak iÃ§in abonelik veya Ã¶deme gerektirebilirler. KullanÄ±cÄ±lar, modelin eÄŸitildiÄŸi veriler Ã¼zerinde kontrol sahibi deÄŸildir; bu nedenle veri gizliliÄŸi ve yapay zekÃ¢nÄ±n sorumlu kullanÄ±mÄ± konusunda model sahibine gÃ¼venmelidirler. PopÃ¼ler tescilli modellere Ã¶rnek olarak [OpenAI modelleri](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ve [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst) verilebilir.

### Embedding, GÃ¶rsel Ãœretimi ve Metin & Kod Ãœretimi

LLMâ€™ler, Ã¼rettikleri Ã§Ä±ktÄ±ya gÃ¶re de sÄ±nÄ±flandÄ±rÄ±labilir.

Embedding modelleri, metni sayÄ±sal bir forma, yani embeddingâ€™e dÃ¶nÃ¼ÅŸtÃ¼ren modellerdir. Embedding, giriÅŸ metninin sayÄ±sal temsili olup, makinelerin kelimeler veya cÃ¼mleler arasÄ±ndaki iliÅŸkileri anlamasÄ±nÄ± kolaylaÅŸtÄ±rÄ±r. Bu sayÄ±sal temsiller, sÄ±nÄ±flandÄ±rma veya kÃ¼meleme gibi diÄŸer modeller tarafÄ±ndan girdi olarak kullanÄ±labilir ve sayÄ±sal veriler Ã¼zerinde daha iyi performans gÃ¶sterir. Embedding modelleri genellikle transfer Ã¶ÄŸrenme iÃ§in kullanÄ±lÄ±r; bol veri bulunan bir gÃ¶rev iÃ§in model eÄŸitilir ve ardÄ±ndan model aÄŸÄ±rlÄ±klarÄ± (embeddingâ€™ler) diÄŸer gÃ¶revlerde yeniden kullanÄ±lÄ±r. Bu kategoriye Ã¶rnek olarak [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst) verilebilir.

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.tr.png)

GÃ¶rsel Ã¼retim modelleri, gÃ¶rsel oluÅŸturan modellerdir. Genellikle gÃ¶rsel dÃ¼zenleme, sentezleme ve Ã§eviri iÃ§in kullanÄ±lÄ±rlar. Bu modeller, [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst) gibi bÃ¼yÃ¼k gÃ¶rsel veri setleri Ã¼zerinde eÄŸitilir ve yeni gÃ¶rseller oluÅŸturabilir veya mevcut gÃ¶rselleri inpainting, sÃ¼per Ã§Ã¶zÃ¼nÃ¼rlÃ¼k ve renklendirme teknikleriyle dÃ¼zenleyebilirler. Ã–rnekler arasÄ±nda [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) ve [Stable Diffusion modelleri](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst) bulunur.

![GÃ¶rsel Ã¼retimi](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.tr.png)

Metin ve kod Ã¼retim modelleri, metin veya kod Ã¼reten modellerdir. Genellikle metin Ã¶zetleme, Ã§eviri ve soru yanÄ±tlama iÃ§in kullanÄ±lÄ±rlar. Metin Ã¼retim modelleri, [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst) gibi bÃ¼yÃ¼k metin veri setleri Ã¼zerinde eÄŸitilir ve yeni metinler oluÅŸturabilir veya sorularÄ± yanÄ±tlayabilirler. Kod Ã¼retim modelleri, Ã¶rneÄŸin [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), GitHub gibi bÃ¼yÃ¼k kod veri setleri Ã¼zerinde eÄŸitilir ve yeni kod yazabilir veya mevcut kodlardaki hatalarÄ± dÃ¼zeltebilir.

![Metin ve kod Ã¼retimi](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.tr.png)

### Encoder-Decoder ile Sadece Decoder Modelleri

LLMâ€™lerin farklÄ± mimarilerini anlatmak iÃ§in bir benzetme yapalÄ±m.

YÃ¶neticiniz size Ã¶ÄŸrenciler iÃ§in bir quiz hazÄ±rlama gÃ¶revi verdi. Ä°ki iÅŸ arkadaÅŸÄ±nÄ±z var; biri iÃ§eriÄŸi oluÅŸturuyor, diÄŸeri ise gÃ¶zden geÃ§iriyor.

Ä°Ã§erik oluÅŸturucu, sadece Decoder modeline benzer; konuyu gÃ¶rÃ¼r, sizin yazdÄ±klarÄ±nÄ±zÄ± inceler ve buna dayanarak bir ders yazabilir. Ä°lgi Ã§ekici ve bilgilendirici iÃ§erik yazmada Ã§ok iyidirler ama konuyu ve Ã¶ÄŸrenme hedeflerini anlamada o kadar iyi deÄŸiller. Decoder modellerine Ã¶rnek olarak GPT ailesi, Ã¶zellikle GPT-3 verilebilir.

GÃ¶zden geÃ§iren ise sadece Encoder modeline benzer; yazÄ±lan dersi ve cevaplarÄ± inceler, aralarÄ±ndaki iliÅŸkiyi fark eder ve baÄŸlamÄ± anlar ama iÃ§erik Ã¼retmede iyi deÄŸildir. Encoder modellerine Ã¶rnek olarak BERT verilebilir.

Hem iÃ§erik oluÅŸturup hem de gÃ¶zden geÃ§iren biri olsaydÄ±, bu Encoder-Decoder modeli olurdu. Ã–rnekler arasÄ±nda BART ve T5 bulunur.

### Servis ile Model ArasÄ±ndaki Fark

Åimdi, servis ile model arasÄ±ndaki farkÄ± konuÅŸalÄ±m. Servis, Bulut Hizmet SaÄŸlayÄ±cÄ±sÄ± tarafÄ±ndan sunulan bir Ã¼rÃ¼ndÃ¼r ve genellikle modeller, veriler ve diÄŸer bileÅŸenlerin birleÅŸimidir. Model ise servisin temel bileÅŸenidir ve genellikle bir foundation model, Ã¶rneÄŸin bir LLMâ€™dir.

Servisler genellikle Ã¼retim kullanÄ±mÄ± iÃ§in optimize edilmiÅŸtir ve modellerden daha kolay kullanÄ±lÄ±r; genellikle grafiksel kullanÄ±cÄ± arayÃ¼zÃ¼ sunarlar. Ancak servisler her zaman Ã¼cretsiz deÄŸildir ve kullanmak iÃ§in abonelik veya Ã¶deme gerekebilir. Bu, servis sahibinin donanÄ±m ve kaynaklarÄ±nÄ± kullanmak, maliyetleri optimize etmek ve Ã¶lÃ§eklendirmeyi kolaylaÅŸtÄ±rmak iÃ§indir. Ã–rnek olarak [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst) verilebilir; bu servis kullandÄ±kÃ§a Ã¶de fiyatlandÄ±rma sunar ve kurumsal dÃ¼zeyde gÃ¼venlik ile modellerin yetenekleri Ã¼zerine sorumlu yapay zekÃ¢ Ã§erÃ§evesi saÄŸlar.

Modeller ise sadece sinir aÄŸÄ±dÄ±r; parametreler, aÄŸÄ±rlÄ±klar ve diÄŸer bileÅŸenlerden oluÅŸur. Åirketlerin yerel olarak Ã§alÄ±ÅŸtÄ±rmasÄ± mÃ¼mkÃ¼ndÃ¼r ancak bunun iÃ§in donanÄ±m satÄ±n almalarÄ±, Ã¶lÃ§eklendirme yapÄ±larÄ± kurmalarÄ± ve lisans almalarÄ± veya aÃ§Ä±k kaynak model kullanmalarÄ± gerekir. Ã–rneÄŸin LLaMA modeli kullanÄ±labilir ancak Ã§alÄ±ÅŸtÄ±rmak iÃ§in hesaplama gÃ¼cÃ¼ gerektirir.

## Azureâ€™da FarklÄ± Modelleri Test Etme ve PerformansÄ± Anlamak Ä°Ã§in Yineleme Yapma

Ekibimiz mevcut LLM ortamÄ±nÄ± keÅŸfedip senaryolarÄ±na uygun bazÄ± adaylarÄ± belirledikten sonra, bir sonraki adÄ±m bu modelleri kendi verileri ve iÅŸ yÃ¼kleri Ã¼zerinde test etmektir. Bu, deneyler ve Ã¶lÃ§Ã¼mlerle yapÄ±lan yinelemeli bir sÃ¼reÃ§tir.
Ã–nceki paragraflarda bahsettiÄŸimiz modellerin Ã§oÄŸu (OpenAI modelleri, Llama2 gibi aÃ§Ä±k kaynak modeller ve Hugging Face transformerlarÄ±) [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst) iÃ§indeki [Model KataloÄŸu](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) bÃ¶lÃ¼mÃ¼nde mevcuttur.

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst), geliÅŸtiricilerin Ã¼retken yapay zeka uygulamalarÄ± oluÅŸturmasÄ±nÄ± ve deneyden deÄŸerlendirmeye kadar tÃ¼m geliÅŸtirme sÃ¼recini yÃ¶netmesini saÄŸlayan, tÃ¼m Azure AI hizmetlerini kullanÄ±ÅŸlÄ± bir GUI ile tek bir merkezde birleÅŸtiren bir Bulut Platformudur. Azure AI Studioâ€™daki Model KataloÄŸu kullanÄ±cÄ±ya ÅŸu imkÃ¢nlarÄ± sunar:

- Ä°lginizi Ã§eken Temel Modeli katalogda bulun - ister Ã¶zel ister aÃ§Ä±k kaynak olsun, gÃ¶rev, lisans veya isim bazÄ±nda filtreleyin. AramayÄ± kolaylaÅŸtÄ±rmak iÃ§in modeller Azure OpenAI koleksiyonu, Hugging Face koleksiyonu gibi koleksiyonlar halinde dÃ¼zenlenmiÅŸtir.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.tr.png)

- Model kartÄ±nÄ± inceleyin; kullanÄ±m amacÄ± ve eÄŸitim verisi hakkÄ±nda detaylÄ± aÃ§Ä±klamalar, kod Ã¶rnekleri ve dahili deÄŸerlendirme kÃ¼tÃ¼phanesindeki sonuÃ§lar dahil.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.tr.png)

- [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) paneli Ã¼zerinden sektÃ¶rdeki modeller ve veri setleri arasÄ±ndaki karÅŸÄ±laÅŸtÄ±rmalarÄ± yaparak iÅŸ senaryonuza en uygun olanÄ± deÄŸerlendirin.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.tr.png)

- Azure AI Studioâ€™nun deney yapma ve takip Ã¶zelliklerini kullanarak, Ã¶zel eÄŸitim verisiyle modeli ince ayar yaparak belirli iÅŸ yÃ¼klerinde performansÄ±nÄ± artÄ±rÄ±n.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.tr.png)

- Orijinal Ã¶nceden eÄŸitilmiÅŸ modeli veya ince ayar yapÄ±lmÄ±ÅŸ versiyonunu, uygulamalarÄ±n kullanabilmesi iÃ§in uzaktan gerÃ§ek zamanlÄ± Ã§Ä±karÄ±m - yÃ¶netilen hesaplama - veya sunucusuz API uÃ§ noktalarÄ±na - [kullandÄ±kÃ§a Ã¶de](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - daÄŸÄ±tÄ±n.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.tr.png)


> [!NOTE]
> Katalogdaki tÃ¼m modeller ÅŸu anda ince ayar yapma ve/veya kullandÄ±kÃ§a Ã¶de daÄŸÄ±tÄ±mÄ± iÃ§in uygun olmayabilir. Modelin yetenekleri ve sÄ±nÄ±rlamalarÄ± hakkÄ±nda detaylar iÃ§in model kartÄ±nÄ± kontrol edin.

## LLM sonuÃ§larÄ±nÄ± iyileÅŸtirme

Startup ekibimizle farklÄ± tÃ¼rde LLMâ€™leri ve farklÄ± modelleri karÅŸÄ±laÅŸtÄ±rmamÄ±za, test verileri Ã¼zerinde deÄŸerlendirmemize, performanslarÄ±nÄ± artÄ±rmamÄ±za ve Ã§Ä±karÄ±m uÃ§ noktalarÄ±na daÄŸÄ±tmamÄ±za olanak saÄŸlayan bir Bulut Platformu (Azure Machine Learning) Ã¼zerinde Ã§alÄ±ÅŸtÄ±k.

Peki, Ã¶nceden eÄŸitilmiÅŸ bir modeli kullanmak yerine ne zaman ince ayar yapÄ±lmÄ±ÅŸ bir modeli tercih etmeliler? Belirli iÅŸ yÃ¼klerinde model performansÄ±nÄ± artÄ±rmak iÃ§in baÅŸka yaklaÅŸÄ±mlar var mÄ±?

Bir iÅŸletmenin LLMâ€™den ihtiyaÃ§ duyduÄŸu sonuÃ§larÄ± almak iÃ§in kullanabileceÄŸi birkaÃ§ yÃ¶ntem vardÄ±r. Ãœretimde LLM daÄŸÄ±tÄ±rken farklÄ± eÄŸitim seviyelerine sahip farklÄ± model tÃ¼rleri seÃ§ebilirsiniz; bunlar farklÄ± karmaÅŸÄ±klÄ±k, maliyet ve kalite seviyelerine sahiptir. Ä°ÅŸte bazÄ± farklÄ± yaklaÅŸÄ±mlar:

- **BaÄŸlam ile prompt mÃ¼hendisliÄŸi**. Ä°htiyacÄ±nÄ±z olan yanÄ±tlarÄ± almak iÃ§in prompt verirken yeterli baÄŸlam saÄŸlamaktÄ±r.

- **Retrieval Augmented Generation, RAG**. Verileriniz Ã¶rneÄŸin bir veritabanÄ±nda veya web uÃ§ noktasÄ±nda olabilir; bu verilerin veya bir alt kÃ¼mesinin prompt sÄ±rasÄ±nda dahil edilmesini saÄŸlamak iÃ§in ilgili veriyi Ã§ekip kullanÄ±cÄ±nÄ±n promptunun bir parÃ§asÄ± yapabilirsiniz.

- **Ä°nce ayar yapÄ±lmÄ±ÅŸ model**. Burada, modeli kendi verilerinizle daha fazla eÄŸitirsiniz; bu da modelin ihtiyaÃ§larÄ±nÄ±za daha kesin ve duyarlÄ± olmasÄ±nÄ± saÄŸlar ancak maliyetli olabilir.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.tr.png)

Resim kaynaÄŸÄ±: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### BaÄŸlam ile Prompt MÃ¼hendisliÄŸi

Ã–nceden eÄŸitilmiÅŸ LLMâ€™ler, kÄ±sa bir prompt ile bile (tamamlanacak bir cÃ¼mle veya soru gibi) genel doÄŸal dil gÃ¶revlerinde Ã§ok iyi Ã§alÄ±ÅŸÄ±r; buna â€œsÄ±fÄ±r atÄ±ÅŸâ€ Ã¶ÄŸrenme denir.

Ancak kullanÄ±cÄ± sorgusunu detaylÄ± bir istek ve Ã¶rneklerle - yani BaÄŸlam ile - ne kadar iyi Ã§erÃ§evelerse, cevap o kadar doÄŸru ve beklentiye yakÄ±n olur. Prompt sadece bir Ã¶rnek iÃ§eriyorsa buna â€œbir atÄ±ÅŸâ€ Ã¶ÄŸrenme, birden fazla Ã¶rnek varsa â€œbirkaÃ§ atÄ±ÅŸâ€ Ã¶ÄŸrenme denir. BaÄŸlam ile prompt mÃ¼hendisliÄŸi, baÅŸlamak iÃ§in en maliyet etkin yaklaÅŸÄ±mdÄ±r.

### Retrieval Augmented Generation (RAG)

LLMâ€™lerin sÄ±nÄ±rlamasÄ±, yanÄ±t Ã¼retmek iÃ§in yalnÄ±zca eÄŸitim sÄ±rasÄ±nda kullandÄ±klarÄ± verileri kullanabilmeleridir. Bu, eÄŸitim sonrasÄ± gerÃ§ekleÅŸen olaylar hakkÄ±nda bilgi sahibi olmadÄ±klarÄ± ve Ã¶zel bilgilere (Ã¶rneÄŸin ÅŸirket verileri) eriÅŸemedikleri anlamÄ±na gelir.  
Bu, promptâ€™a dÄ±ÅŸ veri parÃ§alarÄ± ekleyen RAG tekniÄŸiyle aÅŸÄ±labilir; prompt uzunluÄŸu sÄ±nÄ±rlarÄ± gÃ¶z Ã¶nÃ¼nde bulundurularak belgelerden alÄ±nan parÃ§alar eklenir. Bu, [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst) gibi VektÃ¶r veritabanÄ± araÃ§larÄ± tarafÄ±ndan desteklenir; bu araÃ§lar Ã§eÅŸitli Ã¶nceden tanÄ±mlanmÄ±ÅŸ veri kaynaklarÄ±ndan faydalÄ± parÃ§alarÄ± bulup prompt baÄŸlamÄ±na ekler.

Bu teknik, bir iÅŸletmenin yeterli veri, zaman veya kaynaÄŸÄ± olmadan LLMâ€™yi ince ayar yapamamasÄ± durumunda, belirli iÅŸ yÃ¼klerinde performansÄ± artÄ±rmak ve gerÃ§ek dÄ±ÅŸÄ± veya zararlÄ± iÃ§erik riskini azaltmak iÃ§in Ã§ok faydalÄ±dÄ±r.

### Ä°nce ayar yapÄ±lmÄ±ÅŸ model

Ä°nce ayar, transfer Ã¶ÄŸrenmeyi kullanarak modeli belirli bir gÃ¶reve uyarlama veya Ã¶zel bir problemi Ã§Ã¶zme sÃ¼recidir. BirkaÃ§ atÄ±ÅŸ Ã¶ÄŸrenme ve RAGâ€™den farklÄ± olarak, gÃ¼ncellenmiÅŸ aÄŸÄ±rlÄ±klar ve biaslarla yeni bir model oluÅŸturulur. EÄŸitim Ã¶rnekleri, tek bir girdi (prompt) ve ona karÅŸÄ±lÄ±k gelen Ã§Ä±ktÄ± (tamamlama) Ã§iftlerinden oluÅŸur.  
Bu yaklaÅŸÄ±m tercih edilir:

- **Ä°nce ayar yapÄ±lmÄ±ÅŸ modelleri kullanmak**. Ä°ÅŸletme, yÃ¼ksek performanslÄ± modeller yerine ince ayar yapÄ±lmÄ±ÅŸ daha az yetenekli modelleri (Ã¶rneÄŸin embedding modelleri) kullanmak isteyebilir; bu daha uygun maliyetli ve hÄ±zlÄ± bir Ã§Ã¶zÃ¼mdÃ¼r.

- **Gecikme sÃ¼resini dikkate almak**. Belirli bir kullanÄ±m durumu iÃ§in gecikme Ã¶nemliyse, Ã§ok uzun promptlar kullanmak mÃ¼mkÃ¼n olmayabilir veya modelin Ã¶ÄŸrenmesi gereken Ã¶rnek sayÄ±sÄ± prompt uzunluÄŸu sÄ±nÄ±rÄ±na uymaz.

- **GÃ¼ncel kalmak**. Ä°ÅŸletmenin Ã§ok sayÄ±da yÃ¼ksek kaliteli veri ve doÄŸru etiketleri varsa ve bu verileri zaman iÃ§inde gÃ¼ncel tutmak iÃ§in kaynaklarÄ± bulunuyorsa.

### EÄŸitilmiÅŸ model

SÄ±fÄ±rdan bir LLM eÄŸitmek kesinlikle en zor ve en karmaÅŸÄ±k yaklaÅŸÄ±mdÄ±r; bÃ¼yÃ¼k miktarda veri, uzman kaynaklar ve uygun hesaplama gÃ¼cÃ¼ gerektirir. Bu seÃ§enek, iÅŸletmenin alanÄ±na Ã¶zgÃ¼ bir kullanÄ±m durumu ve bÃ¼yÃ¼k miktarda alan odaklÄ± verisi olduÄŸu durumlarda dÃ¼ÅŸÃ¼nÃ¼lmelidir.

## Bilgi kontrolÃ¼

LLM tamamlama sonuÃ§larÄ±nÄ± iyileÅŸtirmek iÃ§in iyi bir yaklaÅŸÄ±m ne olabilir?

1. BaÄŸlam ile prompt mÃ¼hendisliÄŸi  
1. RAG  
1. Ä°nce ayar yapÄ±lmÄ±ÅŸ model

Cevap: 3, zamanÄ±nÄ±z, kaynaklarÄ±nÄ±z ve yÃ¼ksek kaliteli veriniz varsa, gÃ¼ncel kalmak iÃ§in ince ayar yapmak daha iyidir. Ancak iyileÅŸtirme yapmak istiyor ve zamanÄ±nÄ±z kÄ±sÄ±tlÄ±ysa Ã¶nce RAGâ€™i deÄŸerlendirmek faydalÄ± olabilir.

## ğŸš€ Meydan Okuma

Ä°ÅŸletmeniz iÃ§in [RAGâ€™i nasÄ±l kullanabileceÄŸinizi](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) daha detaylÄ± inceleyin.

## Harika Ä°ÅŸ, Ã–ÄŸrenmeye Devam Et

Bu dersi tamamladÄ±ktan sonra, Ã¼retken yapay zeka bilginizi geliÅŸtirmeye devam etmek iÃ§in [Generative AI Learning koleksiyonumuza](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) gÃ¶z atÄ±n!

Bir sonraki ders olan Ders 3â€™e geÃ§in; burada [Ãœretken Yapay ZekayÄ± Sorumlu Bir Åekilde NasÄ±l KullanacaÄŸÄ±mÄ±zÄ±](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) inceleyeceÄŸiz!

**Feragatname**:  
Bu belge, AI Ã§eviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶sterilse de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±nÄ±z. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu oluÅŸabilecek yanlÄ±ÅŸ anlamalar veya yorum hatalarÄ±ndan sorumlu deÄŸiliz.