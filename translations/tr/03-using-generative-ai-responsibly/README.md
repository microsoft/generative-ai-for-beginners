<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-17T16:18:21+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "tr"
}
-->
# Ãœretken Yapay ZekayÄ± Sorumlu Åekilde Kullanma

[![Ãœretken Yapay ZekayÄ± Sorumlu Åekilde Kullanma](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.tr.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _Bu dersin videosunu izlemek iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n_

Yapay zeka ve Ã¶zellikle Ã¼retken yapay zeka ile bÃ¼yÃ¼lenmek kolaydÄ±r, ancak bunu sorumlu bir ÅŸekilde nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmeniz gerekir. Ã‡Ä±ktÄ±nÄ±n adil, zararsÄ±z ve daha fazlasÄ± olmasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmelisiniz. Bu bÃ¶lÃ¼m, size bahsedilen baÄŸlamÄ±, dikkate alÄ±nmasÄ± gerekenleri ve yapay zeka kullanÄ±mÄ±nÄ±zÄ± iyileÅŸtirmek iÃ§in aktif adÄ±mlar atmayÄ± nasÄ±l baÅŸaracaÄŸÄ±nÄ±zÄ± sunmayÄ± amaÃ§lamaktadÄ±r.

## GiriÅŸ

Bu derste ele alÄ±nacak konular:

- Ãœretken yapay zeka uygulamalarÄ± oluÅŸtururken neden Sorumlu Yapay ZekayÄ± Ã¶nceliklendirmelisiniz.
- Sorumlu Yapay Zeka'nÄ±n temel ilkeleri ve bunlarÄ±n Ãœretken Yapay Zeka ile nasÄ±l iliÅŸkili olduÄŸu.
- Bu Sorumlu Yapay Zeka ilkelerini strateji ve araÃ§lar aracÄ±lÄ±ÄŸÄ±yla nasÄ±l uygulayabilirsiniz.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra ÅŸunlarÄ± bileceksiniz:

- Ãœretken yapay zeka uygulamalarÄ± oluÅŸtururken Sorumlu Yapay Zeka'nÄ±n Ã¶nemi.
- Ãœretken yapay zeka uygulamalarÄ± oluÅŸtururken Sorumlu Yapay Zeka'nÄ±n temel ilkelerini ne zaman dÃ¼ÅŸÃ¼nmeli ve uygulamalÄ±sÄ±nÄ±z.
- Sorumlu Yapay Zeka kavramÄ±nÄ± uygulamaya koymak iÃ§in hangi araÃ§lar ve stratejiler mevcut.

## Sorumlu Yapay Zeka Ä°lkeleri

Ãœretken yapay zeka heyecanÄ± hiÃ§ olmadÄ±ÄŸÄ± kadar yÃ¼ksek. Bu heyecan, bu alana birÃ§ok yeni geliÅŸtirici, dikkat ve finansman getirdi. Bu, Ãœretken Yapay Zeka kullanarak Ã¼rÃ¼nler ve ÅŸirketler oluÅŸturmak isteyen herkes iÃ§in Ã§ok olumlu bir durum olsa da, aynÄ± zamanda sorumlu bir ÅŸekilde ilerlememiz Ã¶nemlidir.

Bu kurs boyunca, giriÅŸimimizi ve yapay zeka eÄŸitim Ã¼rÃ¼nÃ¼mÃ¼zÃ¼ oluÅŸturmayÄ± odak noktasÄ± olarak alÄ±yoruz. Sorumlu Yapay Zeka ilkelerini kullanacaÄŸÄ±z: Adalet, KapsayÄ±cÄ±lÄ±k, GÃ¼venilirlik/GÃ¼venlik, GÃ¼venlik ve Gizlilik, ÅeffaflÄ±k ve Hesap Verebilirlik. Bu ilkelerle, Ã¼rÃ¼nlerimizde Ãœretken Yapay Zeka kullanÄ±mÄ±mÄ±zla nasÄ±l iliÅŸkili olduklarÄ±nÄ± keÅŸfedeceÄŸiz.

## Neden Sorumlu Yapay ZekayÄ± Ã–nceliklendirmelisiniz?

Bir Ã¼rÃ¼n oluÅŸtururken, kullanÄ±cÄ±larÄ±nÄ±zÄ±n en iyi Ã§Ä±karlarÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurarak insan merkezli bir yaklaÅŸÄ±m benimsemek en iyi sonuÃ§lara yol aÃ§ar.

Ãœretken yapay zekanÄ±n benzersizliÄŸi, kullanÄ±cÄ±lar iÃ§in faydalÄ± cevaplar, bilgiler, rehberlik ve iÃ§erik oluÅŸturma gÃ¼cÃ¼dÃ¼r. Bu, Ã§ok fazla manuel adÄ±m olmadan yapÄ±labilir ve Ã§ok etkileyici sonuÃ§lara yol aÃ§abilir. Ancak, uygun planlama ve stratejiler olmadan, kullanÄ±cÄ±larÄ±nÄ±z, Ã¼rÃ¼nÃ¼nÃ¼z ve toplum iÃ§in bazÄ± zararlÄ± sonuÃ§lara da yol aÃ§abilir.

Bu potansiyel zararlÄ± sonuÃ§lardan bazÄ±larÄ±na (hepsi deÄŸil) bir gÃ¶z atalÄ±m:

### HalÃ¼sinasyonlar

HalÃ¼sinasyonlar, bir LLM'nin tamamen anlamsÄ±z iÃ§erik veya diÄŸer bilgi kaynaklarÄ±na gÃ¶re yanlÄ±ÅŸ olduÄŸunu bildiÄŸimiz bir ÅŸey Ã¼retmesi durumunu tanÄ±mlamak iÃ§in kullanÄ±lan bir terimdir.

Ã–rneÄŸin, giriÅŸimimiz iÃ§in Ã¶ÄŸrencilere tarihsel sorular sormasÄ±na olanak tanÄ±yan bir Ã¶zellik oluÅŸturduÄŸumuzu varsayalÄ±m. Bir Ã¶ÄŸrenci ÅŸu soruyu sorar: `Titanik'in tek kurtulanÄ± kimdi?`

Model aÅŸaÄŸÄ±daki gibi bir yanÄ±t Ã¼retir:

![Titanik'in tek kurtulanÄ± kimdi sorusu](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Kaynak: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Bu Ã§ok kendinden emin ve ayrÄ±ntÄ±lÄ± bir cevap. Ne yazÄ±k ki, yanlÄ±ÅŸtÄ±r. Ã‡ok az bir araÅŸtÄ±rmayla bile, Titanik felaketinden birden fazla kiÅŸinin kurtulduÄŸunu keÅŸfedebilirsiniz. Bu konu hakkÄ±nda araÅŸtÄ±rmaya yeni baÅŸlayan bir Ã¶ÄŸrenci iÃ§in bu cevap, sorgulanmayacak kadar ikna edici olabilir ve gerÃ§ek olarak kabul edilebilir. Bunun sonuÃ§larÄ±, yapay zeka sisteminin gÃ¼venilmez olmasÄ±na ve giriÅŸimimizin itibarÄ±nÄ± olumsuz etkilemesine yol aÃ§abilir.

Herhangi bir LLM'nin her bir yinelemesiyle, halÃ¼sinasyonlarÄ± en aza indirme konusunda performans iyileÅŸtirmeleri gÃ¶rdÃ¼k. Bu iyileÅŸtirmeye raÄŸmen, uygulama geliÅŸtiricileri ve kullanÄ±cÄ±lar olarak bu sÄ±nÄ±rlamalarÄ±n farkÄ±nda olmaya devam etmeliyiz.

### ZararlÄ± Ä°Ã§erik

Bir LLM'nin yanlÄ±ÅŸ veya anlamsÄ±z yanÄ±tlar Ã¼rettiÄŸi Ã¶nceki bÃ¶lÃ¼mde ele aldÄ±k. Dikkat etmemiz gereken bir diÄŸer risk, bir modelin zararlÄ± iÃ§erik Ã¼retmesidir.

ZararlÄ± iÃ§erik ÅŸu ÅŸekilde tanÄ±mlanabilir:

- Kendine zarar verme veya belirli gruplara zarar verme talimatlarÄ± verme veya teÅŸvik etme.
- Nefret dolu veya aÅŸaÄŸÄ±layÄ±cÄ± iÃ§erik.
- Herhangi bir tÃ¼r saldÄ±rÄ± veya ÅŸiddet eylemi planlamasÄ±na rehberlik etme.
- YasadÄ±ÅŸÄ± iÃ§erik bulma veya yasadÄ±ÅŸÄ± eylemler gerÃ§ekleÅŸtirme talimatlarÄ± verme.
- Cinsel aÃ§Ä±dan aÃ§Ä±k iÃ§erik gÃ¶sterme.

GiriÅŸimimiz iÃ§in, Ã¶ÄŸrencilerin bu tÃ¼r iÃ§erikleri gÃ¶rmesini Ã¶nlemek iÃ§in doÄŸru araÃ§lara ve stratejilere sahip olduÄŸumuzdan emin olmak istiyoruz.

### Adalet EksikliÄŸi

Adalet, â€œbir yapay zeka sisteminin Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±ndÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ve herkese adil ve eÅŸit davranmasÄ±nÄ± saÄŸlamakâ€ olarak tanÄ±mlanÄ±r. Ãœretken yapay zeka dÃ¼nyasÄ±nda, modelin Ã§Ä±ktÄ±sÄ±nÄ±n marjinal gruplarÄ±n dÄ±ÅŸlayÄ±cÄ± dÃ¼nya gÃ¶rÃ¼ÅŸlerini pekiÅŸtirmediÄŸinden emin olmak istiyoruz.

Bu tÃ¼r Ã§Ä±ktÄ±lar, kullanÄ±cÄ±larÄ±mÄ±z iÃ§in olumlu Ã¼rÃ¼n deneyimleri oluÅŸturmayÄ± engellemekle kalmaz, aynÄ± zamanda toplumsal zarara da neden olur. Uygulama geliÅŸtiricileri olarak, Ãœretken Yapay Zeka ile Ã§Ã¶zÃ¼mler oluÅŸtururken her zaman geniÅŸ ve Ã§eÅŸitli bir kullanÄ±cÄ± kitlesini akÄ±lda tutmalÄ±yÄ±z.

## Ãœretken Yapay ZekayÄ± Sorumlu Åekilde NasÄ±l Kullanabilirsiniz?

ArtÄ±k Sorumlu Ãœretken Yapay Zeka'nÄ±n Ã¶nemini belirlediÄŸimize gÃ¶re, yapay zeka Ã§Ã¶zÃ¼mlerimizi sorumlu bir ÅŸekilde oluÅŸturmak iÃ§in atabileceÄŸimiz 4 adÄ±ma bakalÄ±m:

![Azaltma DÃ¶ngÃ¼sÃ¼](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.tr.png)

### Potansiyel ZararlarÄ± Ã–lÃ§Ã¼n

YazÄ±lÄ±m testinde, bir kullanÄ±cÄ±nÄ±n bir uygulamadaki beklenen eylemlerini test ederiz. Benzer ÅŸekilde, kullanÄ±cÄ±larÄ±n en olasÄ± ÅŸekilde kullanacaÄŸÄ± Ã§eÅŸitli istemleri test etmek, potansiyel zararÄ± Ã¶lÃ§menin iyi bir yoludur.

GiriÅŸimimiz bir eÄŸitim Ã¼rÃ¼nÃ¼ oluÅŸturduÄŸundan, eÄŸitimle ilgili istemlerin bir listesini hazÄ±rlamak iyi bir fikir olacaktÄ±r. Bu, belirli bir konuyu, tarihsel gerÃ§ekleri ve Ã¶ÄŸrenci hayatÄ±yla ilgili istemleri kapsayabilir.

### Potansiyel ZararlarÄ± AzaltÄ±n

ArtÄ±k modelin ve yanÄ±tlarÄ±nÄ±n neden olabileceÄŸi potansiyel zararÄ± Ã¶nlemek veya sÄ±nÄ±rlamak iÃ§in yollar bulma zamanÄ±. Bunu 4 farklÄ± katmanda inceleyebiliriz:

![Azaltma KatmanlarÄ±](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.tr.png)

- **Model**. DoÄŸru kullanÄ±m durumu iÃ§in doÄŸru modeli seÃ§mek. GPT-4 gibi daha bÃ¼yÃ¼k ve karmaÅŸÄ±k modeller, daha kÃ¼Ã§Ã¼k ve daha spesifik kullanÄ±m durumlarÄ±na uygulandÄ±ÄŸÄ±nda zararlÄ± iÃ§erik riski oluÅŸturabilir. EÄŸitim verilerinizi kullanarak ince ayar yapmak, zararlÄ± iÃ§erik riskini de azaltÄ±r.

- **GÃ¼venlik Sistemi**. GÃ¼venlik sistemi, zararÄ± azaltmaya yardÄ±mcÄ± olan modelin hizmet verdiÄŸi platformdaki araÃ§lar ve yapÄ±landÄ±rmalar setidir. Bunun bir Ã¶rneÄŸi, Azure OpenAI hizmetindeki iÃ§erik filtreleme sistemidir. Sistemler ayrÄ±ca jailbreak saldÄ±rÄ±larÄ±nÄ± ve botlardan gelen istekler gibi istenmeyen etkinlikleri algÄ±lamalÄ±dÄ±r.

- **Metaprompt**. Metapromptlar ve dayanaklar, belirli davranÄ±ÅŸlar ve bilgiler temelinde modeli yÃ¶nlendirme veya sÄ±nÄ±rlama yollarÄ±dÄ±r. Bu, sistem girdilerini kullanarak modelin belirli sÄ±nÄ±rlarÄ±nÄ± tanÄ±mlamak olabilir. AyrÄ±ca, sistemin kapsamÄ±na veya alanÄ±na daha uygun Ã§Ä±ktÄ±lar saÄŸlamak olabilir.

Modelin yalnÄ±zca gÃ¼venilir kaynaklardan seÃ§ilmiÅŸ bilgileri Ã§ekmesini saÄŸlamak iÃ§in Retrieval Augmented Generation (RAG) gibi teknikler kullanmak da mÃ¼mkÃ¼ndÃ¼r. Bu kursun ilerleyen bÃ¶lÃ¼mlerinde [arama uygulamalarÄ± oluÅŸturma](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) Ã¼zerine bir ders bulunmaktadÄ±r.

- **KullanÄ±cÄ± Deneyimi**. Son katman, kullanÄ±cÄ±nÄ±n modelle doÄŸrudan uygulamamÄ±zÄ±n arayÃ¼zÃ¼ aracÄ±lÄ±ÄŸÄ±yla etkileÅŸimde bulunduÄŸu yerdir. Bu ÅŸekilde, kullanÄ±cÄ±yÄ± modele gÃ¶nderebileceÄŸi giriÅŸ tÃ¼rleri ve kullanÄ±cÄ±ya gÃ¶sterilen metin veya gÃ¶rÃ¼ntÃ¼ler konusunda sÄ±nÄ±rlamak iÃ§in UI/UX tasarlayabiliriz. Yapay zeka uygulamasÄ±nÄ± daÄŸÄ±tÄ±rken, Ãœretken Yapay Zeka uygulamamÄ±zÄ±n neler yapabileceÄŸi ve yapamayacaÄŸÄ± konusunda da ÅŸeffaf olmalÄ±yÄ±z.

[AI UygulamalarÄ± iÃ§in UX TasarÄ±mÄ±](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) Ã¼zerine ayrÄ±lmÄ±ÅŸ bir dersimiz var.

- **Modeli DeÄŸerlendirin**. LLM'lerle Ã§alÄ±ÅŸmak zor olabilir Ã§Ã¼nkÃ¼ modelin eÄŸitildiÄŸi veriler Ã¼zerinde her zaman kontrolÃ¼mÃ¼z yoktur. Buna raÄŸmen, modelin performansÄ±nÄ± ve Ã§Ä±ktÄ±sÄ±nÄ± her zaman deÄŸerlendirmeliyiz. Modelin doÄŸruluÄŸunu, benzerliÄŸini, dayanaklÄ±lÄ±ÄŸÄ±nÄ± ve Ã§Ä±ktÄ±nÄ±n alaka dÃ¼zeyini Ã¶lÃ§mek hala Ã¶nemlidir. Bu, paydaÅŸlara ve kullanÄ±cÄ±lara ÅŸeffaflÄ±k ve gÃ¼ven saÄŸlar.

### Sorumlu Ãœretken Yapay Zeka Ã‡Ã¶zÃ¼mÃ¼nÃ¼ Ä°ÅŸletin

Yapay zeka uygulamalarÄ±nÄ±z etrafÄ±nda operasyonel bir uygulama oluÅŸturmak son aÅŸamadÄ±r. Bu, tÃ¼m dÃ¼zenleyici politikalara uygun olduÄŸumuzdan emin olmak iÃ§in giriÅŸimimizin diÄŸer bÃ¶lÃ¼mleriyle, Ã¶rneÄŸin Hukuk ve GÃ¼venlik ile iÅŸ birliÄŸi yapmayÄ± iÃ§erir. Lansmandan Ã¶nce, kullanÄ±cÄ±larÄ±mÄ±za zarar vermeyi Ã¶nlemek iÃ§in teslimat, olay yÃ¶netimi ve geri alma planlarÄ± oluÅŸturmak istiyoruz.

## AraÃ§lar

Sorumlu Yapay Zeka Ã§Ã¶zÃ¼mleri geliÅŸtirme Ã§alÄ±ÅŸmasÄ± Ã§ok gibi gÃ¶rÃ¼nse de, bu Ã§aba kesinlikle deÄŸerli bir Ã§alÄ±ÅŸmadÄ±r. Ãœretken yapay zeka alanÄ± bÃ¼yÃ¼dÃ¼kÃ§e, geliÅŸtiricilerin sorumluluÄŸu iÅŸ akÄ±ÅŸlarÄ±na verimli bir ÅŸekilde entegre etmelerine yardÄ±mcÄ± olacak daha fazla araÃ§ olgunlaÅŸacaktÄ±r. Ã–rneÄŸin, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst), bir API isteÄŸi aracÄ±lÄ±ÄŸÄ±yla zararlÄ± iÃ§erik ve gÃ¶rÃ¼ntÃ¼leri algÄ±lamaya yardÄ±mcÄ± olabilir.

## Bilgi KontrolÃ¼

Sorumlu yapay zeka kullanÄ±mÄ±nÄ± saÄŸlamak iÃ§in dikkat etmeniz gereken bazÄ± ÅŸeyler nelerdir?

1. CevabÄ±n doÄŸru olmasÄ±.
1. ZararlÄ± kullanÄ±m, yapay zekanÄ±n suÃ§ amaÃ§lÄ± kullanÄ±lmamasÄ±.
1. Yapay zekanÄ±n Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±ndÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± saÄŸlamak.

C: 2 ve 3 doÄŸrudur. Sorumlu Yapay Zeka, zararlÄ± etkileri ve Ã¶nyargÄ±larÄ± nasÄ±l azaltacaÄŸÄ±nÄ±zÄ± ve daha fazlasÄ±nÄ± dÃ¼ÅŸÃ¼nmenize yardÄ±mcÄ± olur.

## ğŸš€ Meydan Okuma

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hakkÄ±nda bilgi edinin ve kullanÄ±mÄ±nÄ±z iÃ§in neler benimseyebileceÄŸinizi gÃ¶rÃ¼n.

## Harika Ä°ÅŸ, Ã–ÄŸrenmeye Devam Edin

Bu dersi tamamladÄ±ktan sonra, [Ãœretken Yapay Zeka Ã–ÄŸrenme koleksiyonumuza](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) gÃ¶z atarak Ãœretken Yapay Zeka bilginizi geliÅŸtirmeye devam edin!

[Ä°stek MÃ¼hendisliÄŸi Temelleri](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) konusunu inceleyeceÄŸimiz 4. Derse geÃ§in!

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.