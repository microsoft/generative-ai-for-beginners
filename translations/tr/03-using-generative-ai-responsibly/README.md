<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:55:41+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "tr"
}
-->
# Generatif Yapay ZekayÄ± Sorumlu Bir Åekilde Kullanmak

[![Generatif Yapay ZekayÄ± Sorumlu Bir Åekilde Kullanmak](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.tr.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Bu dersin videosunu izlemek iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n_

Yapay zekaya, Ã¶zellikle de generatif yapay zekaya hayran kalmak kolaydÄ±r, ancak onu nasÄ±l sorumlu bir ÅŸekilde kullanacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmeniz gerekir. Ã‡Ä±ktÄ±nÄ±n adil, zararsÄ±z ve daha fazlasÄ± olmasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±nÄ±zÄ± gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±sÄ±nÄ±z. Bu bÃ¶lÃ¼m, bahsedilen baÄŸlamÄ±, nelere dikkat etmeniz gerektiÄŸini ve yapay zeka kullanÄ±mÄ±nÄ±zÄ± geliÅŸtirmek iÃ§in nasÄ±l aktif adÄ±mlar atabileceÄŸinizi sunmayÄ± amaÃ§lamaktadÄ±r.

## GiriÅŸ

Bu derste ÅŸunlar ele alÄ±nacak:

- Generatif Yapay Zeka uygulamalarÄ± geliÅŸtirirken neden Sorumlu Yapay ZekayÄ± Ã¶nceliklendirmelisiniz.
- Sorumlu Yapay ZekanÄ±n temel prensipleri ve bunlarÄ±n Generatif Yapay Zeka ile iliÅŸkisi.
- Bu Sorumlu Yapay Zeka prensiplerini strateji ve araÃ§lar aracÄ±lÄ±ÄŸÄ±yla nasÄ±l uygulayabileceÄŸiniz.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra ÅŸunlarÄ± bileceksiniz:

- Generatif Yapay Zeka uygulamalarÄ± geliÅŸtirirken Sorumlu Yapay ZekanÄ±n Ã¶nemi.
- Generatif Yapay Zeka uygulamalarÄ± geliÅŸtirirken Sorumlu Yapay ZekanÄ±n temel prensiplerini ne zaman dÃ¼ÅŸÃ¼nÃ¼p uygulamanÄ±z gerektiÄŸi.
- Sorumlu Yapay Zeka kavramÄ±nÄ± pratiÄŸe dÃ¶kmek iÃ§in hangi araÃ§lar ve stratejilerin mevcut olduÄŸu.

## Sorumlu Yapay Zeka Prensipleri

Generatif Yapay ZekanÄ±n heyecanÄ± hiÃ§ bu kadar yÃ¼ksek olmamÄ±ÅŸtÄ±. Bu heyecan, bu alana birÃ§ok yeni geliÅŸtirici, ilgi ve finansman getirdi. Bu, Generatif Yapay Zeka kullanarak Ã¼rÃ¼nler ve ÅŸirketler kurmak isteyen herkes iÃ§in Ã§ok olumlu olsa da, sorumlu bir ÅŸekilde ilerlememiz de Ã¶nemlidir.

Bu kurs boyunca, startupâ€™Ä±mÄ±zÄ± ve yapay zeka eÄŸitim Ã¼rÃ¼nÃ¼mÃ¼zÃ¼ geliÅŸtirmeye odaklanÄ±yoruz. Sorumlu Yapay Zeka prensiplerini kullanacaÄŸÄ±z: Adillik, KapsayÄ±cÄ±lÄ±k, GÃ¼venilirlik/GÃ¼venlik, GÃ¼venlik & Gizlilik, ÅeffaflÄ±k ve Hesap Verebilirlik. Bu prensiplerle, Ã¼rÃ¼nlerimizde Generatif Yapay ZekayÄ± nasÄ±l kullandÄ±ÄŸÄ±mÄ±zÄ± keÅŸfedeceÄŸiz.

## Neden Sorumlu Yapay ZekayÄ± Ã–nceliklendirmelisiniz

Bir Ã¼rÃ¼n geliÅŸtirirken, kullanÄ±cÄ±larÄ±nÄ±zÄ±n Ã§Ä±karlarÄ±nÄ± Ã¶n planda tutan insan merkezli bir yaklaÅŸÄ±m en iyi sonuÃ§larÄ± getirir.

Generatif Yapay ZekanÄ±n benzersizliÄŸi, kullanÄ±cÄ±lara faydalÄ± cevaplar, bilgi, rehberlik ve iÃ§erik yaratma gÃ¼cÃ¼dÃ¼r. Bu, birÃ§ok manuel adÄ±ma gerek kalmadan yapÄ±labilir ve Ã§ok etkileyici sonuÃ§lar ortaya Ã§Ä±karabilir. Ancak doÄŸru planlama ve stratejiler olmadan, maalesef kullanÄ±cÄ±larÄ±nÄ±z, Ã¼rÃ¼nÃ¼nÃ¼z ve toplum iÃ§in zararlÄ± sonuÃ§lara yol aÃ§abilir.

Åimdi bu potansiyel zararlÄ± sonuÃ§lardan bazÄ±larÄ±na (ama hepsine deÄŸil) bakalÄ±m:

### HalÃ¼sinasyonlar

HalÃ¼sinasyonlar, bir LLMâ€™nin tamamen anlamsÄ±z iÃ§erik Ã¼retmesi veya diÄŸer bilgi kaynaklarÄ±na gÃ¶re gerÃ§eÄŸe aykÄ±rÄ± olan iÃ§erik Ã¼retmesi durumunu tanÄ±mlamak iÃ§in kullanÄ±lan bir terimdir.

Ã–rneÄŸin, startupâ€™Ä±mÄ±z iÃ§in Ã¶ÄŸrencilere tarihsel sorular sorma imkanÄ± veren bir Ã¶zellik geliÅŸtirdiÄŸimizi dÃ¼ÅŸÃ¼nelim. Bir Ã¶ÄŸrenci â€œTitanikâ€™in tek kurtulanÄ± kimdi?â€ sorusunu soruyor.

Model aÅŸaÄŸÄ±daki gibi bir yanÄ±t Ã¼retiyor:

![â€œTitanikâ€™in tek kurtulanÄ± kimdiâ€ sorusunu gÃ¶steren istem](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Kaynak: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Bu Ã§ok kendinden emin ve detaylÄ± bir cevap. Ne yazÄ±k ki, yanlÄ±ÅŸ. Az bir araÅŸtÄ±rmayla bile Titanik felaketinde birden fazla kurtulan olduÄŸu ortaya Ã§Ä±kar. Bu konuyu yeni araÅŸtÄ±rmaya baÅŸlayan bir Ã¶ÄŸrenci iÃ§in bu cevap sorgulanmadan doÄŸru kabul edilebilir. Bunun sonucu, yapay zeka sisteminin gÃ¼venilmez hale gelmesi ve startupâ€™Ä±mÄ±zÄ±n itibarÄ±nÄ±n zarar gÃ¶rmesi olabilir.

Her yeni LLM sÃ¼rÃ¼mÃ¼nde halÃ¼sinasyonlarÄ± minimize etme konusunda performans iyileÅŸtirmeleri gÃ¶rdÃ¼k. Bu iyileÅŸtirmelere raÄŸmen, biz uygulama geliÅŸtiricileri ve kullanÄ±cÄ±lar olarak bu sÄ±nÄ±rlamalarÄ±n farkÄ±nda olmaya devam etmeliyiz.

### ZararlÄ± Ä°Ã§erik

Ã–nceki bÃ¶lÃ¼mde, bir LLMâ€™nin yanlÄ±ÅŸ veya anlamsÄ±z yanÄ±tlar Ã¼retmesinden bahsettik. Dikkat etmemiz gereken bir diÄŸer risk ise modelin zararlÄ± iÃ§erik Ã¼retmesidir.

ZararlÄ± iÃ§erik ÅŸu ÅŸekilde tanÄ±mlanabilir:

- KiÅŸiye veya belirli gruplara zarar verme ya da kendine zarar verme talimatlarÄ± verme veya teÅŸvik etme.
- Nefret dolu veya aÅŸaÄŸÄ±layÄ±cÄ± iÃ§erik.
- Herhangi bir saldÄ±rÄ± veya ÅŸiddet eyleminin planlanmasÄ±na rehberlik etme.
- YasadÄ±ÅŸÄ± iÃ§erik bulma veya yasadÄ±ÅŸÄ± eylemler gerÃ§ekleÅŸtirme talimatlarÄ± verme.
- Cinsel aÃ§Ä±dan aÃ§Ä±k iÃ§erik gÃ¶sterme.

Startupâ€™Ä±mÄ±z iÃ§in Ã¶ÄŸrencilerin bu tÃ¼r iÃ§eriklerle karÅŸÄ±laÅŸmamasÄ± adÄ±na doÄŸru araÃ§lar ve stratejiler geliÅŸtirmek istiyoruz.

### Adaletsizlik

Adillik, â€œbir yapay zeka sisteminin Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±nmÄ±ÅŸ olmasÄ± ve herkese adil ve eÅŸit davranmasÄ±â€ olarak tanÄ±mlanÄ±r. Generatif Yapay Zeka dÃ¼nyasÄ±nda, marjinalize edilmiÅŸ gruplarÄ±n dÄ±ÅŸlayÄ±cÄ± dÃ¼nya gÃ¶rÃ¼ÅŸlerinin model Ã§Ä±ktÄ±larÄ±yla pekiÅŸtirilmemesini saÄŸlamalÄ±yÄ±z.

Bu tÃ¼r Ã§Ä±ktÄ±lar, kullanÄ±cÄ±larÄ±mÄ±za olumlu Ã¼rÃ¼n deneyimleri sunmayÄ± engellemekle kalmaz, aynÄ± zamanda toplumsal zarara da yol aÃ§ar. Uygulama geliÅŸtiricileri olarak, Generatif Yapay Zeka ile Ã§Ã¶zÃ¼mler geliÅŸtirirken geniÅŸ ve Ã§eÅŸitli bir kullanÄ±cÄ± kitlesini her zaman gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±yÄ±z.

## Generatif Yapay ZekayÄ± Sorumlu Bir Åekilde NasÄ±l Kullanabilirsiniz

Sorumlu Generatif Yapay ZekanÄ±n Ã¶nemini belirledikten sonra, yapay zeka Ã§Ã¶zÃ¼mlerimizi sorumlu bir ÅŸekilde geliÅŸtirmek iÃ§in atabileceÄŸimiz 4 adÄ±ma bakalÄ±m:

![Azaltma DÃ¶ngÃ¼sÃ¼](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.tr.png)

### Potansiyel ZararlarÄ± Ã–lÃ§Ã¼n

YazÄ±lÄ±m testinde, bir kullanÄ±cÄ±nÄ±n uygulama Ã¼zerindeki beklenen davranÄ±ÅŸlarÄ±nÄ± test ederiz. Benzer ÅŸekilde, kullanÄ±cÄ±larÄ±n en Ã§ok kullanmasÄ± muhtemel Ã§eÅŸitli istemleri test etmek potansiyel zararÄ± Ã¶lÃ§mek iÃ§in iyi bir yoldur.

Startupâ€™Ä±mÄ±z eÄŸitim Ã¼rÃ¼nÃ¼ geliÅŸtirdiÄŸi iÃ§in, eÄŸitimle ilgili istemlerin bir listesini hazÄ±rlamak faydalÄ± olur. Bu, belirli bir konuyu, tarihsel gerÃ§ekleri ve Ã¶ÄŸrenci yaÅŸamÄ±yla ilgili istemleri kapsayabilir.

### Potansiyel ZararlarÄ± AzaltÄ±n

ArtÄ±k modelin ve yanÄ±tlarÄ±nÄ±n neden olabileceÄŸi potansiyel zararÄ± Ã¶nlemek veya sÄ±nÄ±rlamak iÃ§in yollar bulma zamanÄ±. Bunu 4 farklÄ± katmanda ele alabiliriz:

![Azaltma KatmanlarÄ±](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.tr.png)

- **Model**. DoÄŸru kullanÄ±m durumu iÃ§in doÄŸru modeli seÃ§mek. GPT-4 gibi daha bÃ¼yÃ¼k ve karmaÅŸÄ±k modeller, daha kÃ¼Ã§Ã¼k ve spesifik kullanÄ±m durumlarÄ±nda zararlÄ± iÃ§erik riski yaratabilir. EÄŸitim verilerinizi kullanarak ince ayar yapmak da zararlÄ± iÃ§erik riskini azaltÄ±r.

- **GÃ¼venlik Sistemi**. GÃ¼venlik sistemi, modeli sunan platformda zararÄ± azaltmaya yardÄ±mcÄ± olan araÃ§lar ve yapÄ±landÄ±rmalar setidir. Ã–rneÄŸin, Azure OpenAI servisindeki iÃ§erik filtreleme sistemi. Sistemler ayrÄ±ca jailbreak saldÄ±rÄ±larÄ±nÄ± ve botlardan gelen istenmeyen aktiviteleri tespit etmelidir.

- **Metaistek**. Metaistekler ve temel oluÅŸturma, modeli belirli davranÄ±ÅŸlar ve bilgiler doÄŸrultusunda yÃ¶nlendirmek veya sÄ±nÄ±rlamak iÃ§in kullanÄ±lÄ±r. Bu, modelin belirli sÄ±nÄ±rlarÄ±nÄ± tanÄ±mlamak iÃ§in sistem girdileri kullanmak olabilir. AyrÄ±ca, sistemin kapsamÄ±na veya alanÄ±na daha uygun Ã§Ä±ktÄ±lar saÄŸlamak da buna dahildir.

AyrÄ±ca, Retrieval Augmented Generation (RAG) gibi tekniklerle modelin yalnÄ±zca gÃ¼venilir kaynaklardan bilgi Ã§ekmesini saÄŸlayabiliriz. Bu kursun ilerleyen bÃ¶lÃ¼mlerinde [arama uygulamalarÄ± geliÅŸtirme](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) dersi bulunmaktadÄ±r.

- **KullanÄ±cÄ± Deneyimi**. Son katman, kullanÄ±cÄ±nÄ±n uygulama arayÃ¼zÃ¼mÃ¼z aracÄ±lÄ±ÄŸÄ±yla modelle doÄŸrudan etkileÅŸimde bulunduÄŸu yerdir. Bu ÅŸekilde, kullanÄ±cÄ±larÄ±n modele gÃ¶nderebileceÄŸi girdi tÃ¼rlerini ve kullanÄ±cÄ±ya gÃ¶sterilen metin veya gÃ¶rselleri sÄ±nÄ±rlamak iÃ§in UI/UX tasarlanabilir. AI uygulamasÄ±nÄ± daÄŸÄ±tÄ±rken, Generatif Yapay Zeka uygulamamÄ±zÄ±n neler yapÄ±p yapamayacaÄŸÄ± konusunda ÅŸeffaf olmalÄ±yÄ±z.

[AI UygulamalarÄ± iÃ§in UX TasarÄ±mÄ±](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) adlÄ± dersimiz bu konuya tamamen ayrÄ±lmÄ±ÅŸtÄ±r.

- **Modeli DeÄŸerlendirin**. LLMâ€™lerle Ã§alÄ±ÅŸmak zordur Ã§Ã¼nkÃ¼ modelin eÄŸitildiÄŸi veriler Ã¼zerinde her zaman kontrolÃ¼mÃ¼z olmaz. Yine de, modelin performansÄ±nÄ± ve Ã§Ä±ktÄ±larÄ± her zaman deÄŸerlendirmeliyiz. Modelin doÄŸruluÄŸunu, benzerliÄŸini, temelliliÄŸini ve Ã§Ä±ktÄ±larÄ±n alaka dÃ¼zeyini Ã¶lÃ§mek Ã¶nemlidir. Bu, paydaÅŸlara ve kullanÄ±cÄ±lara ÅŸeffaflÄ±k ve gÃ¼ven saÄŸlar.

### Sorumlu Bir Generatif Yapay Zeka Ã‡Ã¶zÃ¼mÃ¼ Ä°ÅŸletin

Yapay zeka uygulamalarÄ±nÄ±z etrafÄ±nda operasyonel bir uygulama oluÅŸturmak son aÅŸamadÄ±r. Bu, startupâ€™Ä±mÄ±zÄ±n Hukuk ve GÃ¼venlik gibi diÄŸer bÃ¶lÃ¼mleriyle iÅŸ birliÄŸi yaparak tÃ¼m dÃ¼zenleyici politikalara uyduÄŸumuzdan emin olmayÄ± iÃ§erir. Lansmandan Ã¶nce, teslimat, olay yÃ¶netimi ve geri alma planlarÄ± yaparak kullanÄ±cÄ±larÄ±mÄ±za zarar gelmesini Ã¶nlemek isteriz.

## AraÃ§lar

Sorumlu Yapay Zeka Ã§Ã¶zÃ¼mleri geliÅŸtirmek zor gÃ¶rÃ¼nebilir, ancak bu Ã§abaya kesinlikle deÄŸer. Generatif Yapay Zeka alanÄ± bÃ¼yÃ¼dÃ¼kÃ§e, geliÅŸtiricilerin sorumluluÄŸu iÅŸ akÄ±ÅŸlarÄ±na verimli ÅŸekilde entegre etmelerine yardÄ±mcÄ± olacak daha fazla araÃ§ geliÅŸecektir. Ã–rneÄŸin, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) API isteÄŸi yoluyla zararlÄ± iÃ§erik ve gÃ¶rselleri tespit etmeye yardÄ±mcÄ± olabilir.

## Bilgi KontrolÃ¼

Sorumlu yapay zeka kullanÄ±mÄ± iÃ§in nelere dikkat etmelisiniz?

1. CevabÄ±n doÄŸru olmasÄ±.
1. ZararlÄ± kullanÄ±m, yapay zekanÄ±n suÃ§ amaÃ§lÄ± kullanÄ±lmamasÄ±.
1. Yapay zekanÄ±n Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±nmÄ±ÅŸ olmasÄ±.

Cevap: 2 ve 3 doÄŸru. Sorumlu Yapay Zeka, zararlÄ± etkileri ve Ã¶nyargÄ±larÄ± nasÄ±l azaltacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmenize yardÄ±mcÄ± olur.

## ğŸš€ Meydan Okuma

[Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hakkÄ±nda bilgi edinin ve kullanÄ±mÄ±nÄ±z iÃ§in neleri benimseyebileceÄŸinize bakÄ±n.

## Harika Ä°ÅŸ Ã‡Ä±kardÄ±nÄ±z, Ã–ÄŸrenmeye Devam Edin

Bu dersi tamamladÄ±ktan sonra, Generatif Yapay Zeka bilginizi geliÅŸtirmeye devam etmek iÃ§in [Generative AI Learning koleksiyonumuza](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) gÃ¶z atÄ±n!

Bir sonraki derse, [Prompt Engineering Fundamentals](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) bakmak iÃ§in geÃ§ebilirsiniz!

**Feragatname**:  
Bu belge, AI Ã§eviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±nÄ±z. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu oluÅŸabilecek yanlÄ±ÅŸ anlamalar veya yorum hatalarÄ±ndan sorumlu deÄŸiliz.