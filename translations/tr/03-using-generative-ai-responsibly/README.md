<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:39:02+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "tr"
}
-->
# Ãœretken Yapay ZekayÄ± Sorumlu Kullanma

[![Ãœretken Yapay ZekayÄ± Sorumlu Kullanma](../../../translated_images/03-lesson-banner.63a265562d8a9f9230f5c636ab303a0137d11420177528f475b0a05c5f6a9ff9.tr.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Bu dersin videosunu izlemek iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n_

Yapay zeka ve Ã¶zellikle Ã¼retken yapay zeka ile bÃ¼yÃ¼lenmek kolaydÄ±r, ancak bunu sorumlu bir ÅŸekilde nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmelisiniz. Ã‡Ä±ktÄ±nÄ±n adil, zararsÄ±z olmasÄ±nÄ± saÄŸlamak gibi konularÄ± gÃ¶z Ã¶nÃ¼nde bulundurmanÄ±z gerekir. Bu bÃ¶lÃ¼m, bahsedilen baÄŸlamÄ±, dikkate alÄ±nmasÄ± gerekenleri ve yapay zeka kullanÄ±mÄ±nÄ±zÄ± iyileÅŸtirmek iÃ§in atabileceÄŸiniz aktif adÄ±mlarÄ± saÄŸlamayÄ± amaÃ§lamaktadÄ±r.

## GiriÅŸ

Bu derste ele alÄ±nacak konular:

- Ãœretken yapay zeka uygulamalarÄ± geliÅŸtirirken neden Sorumlu Yapay ZekayÄ± Ã¶nceliklendirmeniz gerektiÄŸi.
- Sorumlu Yapay Zeka'nÄ±n temel ilkeleri ve bunlarÄ±n Ãœretken Yapay Zeka ile nasÄ±l iliÅŸkili olduÄŸu.
- Bu Sorumlu Yapay Zeka ilkelerini strateji ve araÃ§lar yoluyla nasÄ±l uygulamaya koyabileceÄŸiniz.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra ÅŸunlarÄ± bileceksiniz:

- Ãœretken yapay zeka uygulamalarÄ± geliÅŸtirirken Sorumlu Yapay ZekanÄ±n Ã¶nemi.
- Ãœretken yapay zeka uygulamalarÄ± geliÅŸtirirken Sorumlu Yapay ZekanÄ±n temel ilkelerini ne zaman dÃ¼ÅŸÃ¼nmeniz ve uygulamanÄ±z gerektiÄŸi.
- Sorumlu Yapay Zeka kavramÄ±nÄ± uygulamaya koymak iÃ§in hangi araÃ§ ve stratejilerin mevcut olduÄŸu.

## Sorumlu Yapay Zeka Ä°lkeleri

Ãœretken Yapay Zeka'nÄ±n heyecanÄ± hiÃ§ bu kadar yÃ¼ksek olmamÄ±ÅŸtÄ±. Bu heyecan, bu alana birÃ§ok yeni geliÅŸtirici, dikkat ve finansman getirdi. Bu, Ãœretken Yapay ZekayÄ± kullanarak Ã¼rÃ¼nler ve ÅŸirketler oluÅŸturmak isteyen herkes iÃ§in Ã§ok olumlu olsa da, sorumlu bir ÅŸekilde ilerlemek de Ã¶nemlidir.

Bu kurs boyunca, startup'Ä±mÄ±zÄ± ve yapay zeka eÄŸitim Ã¼rÃ¼nÃ¼mÃ¼zÃ¼ geliÅŸtirmeye odaklanÄ±yoruz. Sorumlu Yapay Zeka ilkelerini kullanacaÄŸÄ±z: Adalet, KapsayÄ±cÄ±lÄ±k, GÃ¼venilirlik/GÃ¼venlik, GÃ¼venlik ve Gizlilik, ÅeffaflÄ±k ve Hesap Verebilirlik. Bu ilkelerle, Ã¼rÃ¼nlerimizde Ãœretken Yapay ZekayÄ± kullanmamÄ±zla nasÄ±l iliÅŸkili olduklarÄ±nÄ± keÅŸfedeceÄŸiz.

## Neden Sorumlu Yapay ZekayÄ± Ã–nceliklendirmelisiniz?

Bir Ã¼rÃ¼n geliÅŸtirirken, kullanÄ±cÄ±larÄ±nÄ±zÄ±n en iyi Ã§Ä±karlarÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurarak insan merkezli bir yaklaÅŸÄ±m benimsemek en iyi sonuÃ§lara yol aÃ§ar.

Ãœretken Yapay ZekanÄ±n benzersizliÄŸi, kullanÄ±cÄ±lara faydalÄ± cevaplar, bilgi, rehberlik ve iÃ§erik yaratma gÃ¼cÃ¼dÃ¼r. Bu, birÃ§ok manuel adÄ±m olmadan yapÄ±labilir ve Ã§ok etkileyici sonuÃ§lara yol aÃ§abilir. Ancak, uygun planlama ve stratejiler olmadan, kullanÄ±cÄ±larÄ±nÄ±z, Ã¼rÃ¼nÃ¼nÃ¼z ve toplumun tamamÄ± iÃ§in bazÄ± zararlÄ± sonuÃ§lara da yol aÃ§abilir.

Bu potansiyel zararlÄ± sonuÃ§lardan bazÄ±larÄ±na (ancak hepsine deÄŸil) bakalÄ±m:

### HalÃ¼sinasyonlar

HalÃ¼sinasyonlar, bir LLM'nin ya tamamen anlamsÄ±z ya da diÄŸer bilgi kaynaklarÄ±na gÃ¶re kesinlikle yanlÄ±ÅŸ olduÄŸunu bildiÄŸimiz iÃ§erik Ã¼rettiÄŸinde kullanÄ±lan bir terimdir.

Ã–rneÄŸin, Ã¶ÄŸrencilerin bir modele tarihsel sorular sormasÄ±na izin veren bir Ã¶zellik geliÅŸtirdiÄŸimizi dÃ¼ÅŸÃ¼nelim. Bir Ã¶ÄŸrenci `Who was the sole survivor of Titanic?` sorusunu sorar.

Model aÅŸaÄŸÄ±daki gibi bir yanÄ±t Ã¼retir:

![Titanic'in tek kurtulanÄ± kimdi diyen yÃ¶nlendirme](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Kaynak: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Bu Ã§ok kendinden emin ve kapsamlÄ± bir cevap. Ne yazÄ±k ki, yanlÄ±ÅŸtÄ±r. Ã‡ok az bir araÅŸtÄ±rma ile Titanic felaketinden birden fazla kurtulan olduÄŸunu keÅŸfedebilirsiniz. Bu konuya yeni baÅŸlayan bir Ã¶ÄŸrenci iÃ§in bu cevap sorgulanmayacak ve gerÃ§ek olarak kabul edilebilecek kadar ikna edici olabilir. Bunun sonuÃ§larÄ±, yapay zeka sisteminin gÃ¼venilmez olmasÄ±na ve startup'Ä±mÄ±zÄ±n itibarÄ±nÄ± olumsuz etkilemesine yol aÃ§abilir.

Herhangi bir LLM'nin her yinelemesinde, halÃ¼sinasyonlarÄ± en aza indirme konusunda performans iyileÅŸtirmeleri gÃ¶rdÃ¼k. Bu iyileÅŸtirmeye raÄŸmen, uygulama geliÅŸtiricileri ve kullanÄ±cÄ±lar olarak bu sÄ±nÄ±rlamalarÄ±n farkÄ±nda olmamÄ±z gerekiyor.

### ZararlÄ± Ä°Ã§erik

Ã–nceki bÃ¶lÃ¼mde, bir LLM'nin yanlÄ±ÅŸ veya anlamsÄ±z yanÄ±tlar Ã¼rettiÄŸi durumlarÄ± ele aldÄ±k. Dikkat etmemiz gereken bir diÄŸer risk, bir modelin zararlÄ± iÃ§erik ile yanÄ±t vermesidir.

ZararlÄ± iÃ§erik ÅŸu ÅŸekilde tanÄ±mlanabilir:

- Kendine zarar verme veya belirli gruplara zarar verme talimatlarÄ± verme veya teÅŸvik etme.
- Nefret dolu veya aÅŸaÄŸÄ±layÄ±cÄ± iÃ§erik.
- Herhangi bir saldÄ±rÄ± veya ÅŸiddet eylemi planlamayÄ± yÃ¶nlendirme.
- YasadÄ±ÅŸÄ± iÃ§eriÄŸi bulma veya yasadÄ±ÅŸÄ± eylemler gerÃ§ekleÅŸtirme talimatlarÄ± verme.
- Cinsel iÃ§erikli iÃ§erik gÃ¶sterme.

Startup'Ä±mÄ±z iÃ§in, Ã¶ÄŸrenciler tarafÄ±ndan gÃ¶rÃ¼lmesini Ã¶nlemek iÃ§in bu tÃ¼r iÃ§eriklerin doÄŸru araÃ§ ve stratejilerle Ã¶nlenmesini saÄŸlamak istiyoruz.

### Adalet EksikliÄŸi

Adalet, â€œbir yapay zeka sisteminin Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±ndÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ve herkesle adil ve eÅŸit ÅŸekilde muamele etmesini saÄŸlamakâ€ olarak tanÄ±mlanÄ±r. Ãœretken Yapay Zeka dÃ¼nyasÄ±nda, marjinal gruplarÄ±n dÄ±ÅŸlayÄ±cÄ± dÃ¼nya gÃ¶rÃ¼ÅŸlerinin modelin Ã§Ä±ktÄ±sÄ± tarafÄ±ndan pekiÅŸtirilmediÄŸinden emin olmak istiyoruz.

Bu tÃ¼r Ã§Ä±ktÄ±lar, kullanÄ±cÄ±larÄ±mÄ±z iÃ§in olumlu Ã¼rÃ¼n deneyimleri oluÅŸturmanÄ±n yanÄ± sÄ±ra toplumsal zarara da neden olur. Uygulama geliÅŸtiricileri olarak, Ãœretken Yapay Zeka ile Ã§Ã¶zÃ¼mler geliÅŸtirirken her zaman geniÅŸ ve Ã§eÅŸitli bir kullanÄ±cÄ± tabanÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurmalÄ±yÄ±z.

## Ãœretken Yapay ZekayÄ± Sorumlu Kullanma

ArtÄ±k Sorumlu Ãœretken Yapay ZekanÄ±n Ã¶nemini belirlediÄŸimize gÃ¶re, yapay zeka Ã§Ã¶zÃ¼mlerimizi sorumlu bir ÅŸekilde geliÅŸtirmek iÃ§in atabileceÄŸimiz 4 adÄ±ma bakalÄ±m:

![Azaltma DÃ¶ngÃ¼sÃ¼](../../../translated_images/mitigate-cycle.f82610b2048bda5a84aaa3a3cb2cda8b35fe614a7269743fdc63cbc2cbb8f20f.tr.png)

### Potansiyel ZararlarÄ± Ã–lÃ§me

YazÄ±lÄ±m testinde, bir kullanÄ±cÄ±nÄ±n bir uygulama Ã¼zerindeki beklenen eylemlerini test ederiz. Benzer ÅŸekilde, kullanÄ±cÄ±larÄ±n en olasÄ± ÅŸekilde kullanacaklarÄ± Ã§eÅŸitli yÃ¶nlendirmeleri test etmek, potansiyel zararÄ± Ã¶lÃ§menin iyi bir yoludur.

Startup'Ä±mÄ±z bir eÄŸitim Ã¼rÃ¼nÃ¼ geliÅŸtirdiÄŸi iÃ§in, eÄŸitimle ilgili yÃ¶nlendirmelerin bir listesini hazÄ±rlamak iyi olurdu. Bu, belirli bir konuyu kapsamak, tarihsel gerÃ§ekleri ele almak ve Ã¶ÄŸrenci hayatÄ± hakkÄ±nda yÃ¶nlendirmeler olabilir.

### Potansiyel ZararlarÄ± Azaltma

ArtÄ±k modelin ve yanÄ±tlarÄ±nÄ±n neden olabileceÄŸi potansiyel zararÄ± Ã¶nlemek veya sÄ±nÄ±rlamak iÃ§in yollar bulma zamanÄ±. Bunu 4 farklÄ± katmanda ele alabiliriz:

![Azaltma KatmanlarÄ±](../../../translated_images/mitigation-layers.db2d802e3affb2f49681cf8ae39e8f1a67ff1ce29c3f1099c96948a841d62037.tr.png)

- **Model**. DoÄŸru kullanÄ±m durumu iÃ§in doÄŸru modeli seÃ§mek. GPT-4 gibi daha bÃ¼yÃ¼k ve daha karmaÅŸÄ±k modeller, daha kÃ¼Ã§Ã¼k ve daha spesifik kullanÄ±m durumlarÄ±na uygulandÄ±ÄŸÄ±nda zararlÄ± iÃ§erik riski oluÅŸturabilir. EÄŸitim verilerinizi kullanarak ince ayar yapmak da zararlÄ± iÃ§erik riskini azaltÄ±r.

- **GÃ¼venlik Sistemi**. Bir gÃ¼venlik sistemi, zararÄ± azaltmaya yardÄ±mcÄ± olan platformda modele hizmet eden bir dizi araÃ§ ve yapÄ±landÄ±rmadÄ±r. Azure OpenAI hizmetindeki iÃ§erik filtreleme sistemi buna bir Ã¶rnektir. Sistemler ayrÄ±ca jailbreak saldÄ±rÄ±larÄ±nÄ± ve botlardan gelen istekler gibi istenmeyen etkinlikleri tespit etmelidir.

- **Metaprompt**. Metapromptlar ve temel ayarlamalar, belirli davranÄ±ÅŸlar ve bilgilere dayalÄ± olarak modeli yÃ¶nlendirme veya sÄ±nÄ±rlama yollarÄ±dÄ±r. Bu, modelin belirli sÄ±nÄ±rlarÄ±nÄ± tanÄ±mlamak iÃ§in sistem girdilerini kullanmak olabilir. AyrÄ±ca, sistemin kapsamÄ±na veya alanÄ±na daha uygun Ã§Ä±ktÄ±lar saÄŸlamak.

AyrÄ±ca, modelin yalnÄ±zca gÃ¼venilir kaynaklardan bilgi Ã§ekmesini saÄŸlamak iÃ§in Retrieval Augmented Generation (RAG) gibi teknikler kullanÄ±labilir. Bu kursun ilerleyen bÃ¶lÃ¼mlerinde [arama uygulamalarÄ± geliÅŸtirme](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) Ã¼zerine bir ders var.

- **KullanÄ±cÄ± Deneyimi**. Son katman, kullanÄ±cÄ±nÄ±n modelle uygulamamÄ±zÄ±n arayÃ¼zÃ¼ aracÄ±lÄ±ÄŸÄ±yla bir ÅŸekilde doÄŸrudan etkileÅŸime geÃ§tiÄŸi yerdir. Bu ÅŸekilde, kullanÄ±cÄ±larÄ±n modele gÃ¶nderebileceÄŸi girdilerin tÃ¼rlerini sÄ±nÄ±rlamak iÃ§in UI/UX tasarlayabiliriz ve kullanÄ±cÄ±ya gÃ¶sterilen metin veya gÃ¶rÃ¼ntÃ¼ler Ã¼zerinde sÄ±nÄ±rlamalar koyabiliriz. Yapay zeka uygulamasÄ±nÄ± daÄŸÄ±tÄ±rken, Ãœretken Yapay Zeka uygulamamÄ±zÄ±n ne yapÄ±p yapamayacaÄŸÄ± konusunda da ÅŸeffaf olmalÄ±yÄ±z.

[AI UygulamalarÄ± iÃ§in UX TasarÄ±mÄ±](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) Ã¼zerine ayrÄ±lmÄ±ÅŸ bir dersimiz var.

- **Modeli DeÄŸerlendirme**. LLM'lerle Ã§alÄ±ÅŸmak zor olabilir Ã§Ã¼nkÃ¼ modelin eÄŸitildiÄŸi veriler Ã¼zerinde her zaman kontrolÃ¼mÃ¼z olmayabilir. Buna raÄŸmen, modelin performansÄ±nÄ± ve Ã§Ä±ktÄ±sÄ±nÄ± her zaman deÄŸerlendirmeliyiz. Modelin doÄŸruluÄŸunu, benzerliÄŸini, temellendirmesini ve Ã§Ä±ktÄ±nÄ±n alaka dÃ¼zeyini Ã¶lÃ§mek hala Ã¶nemlidir. Bu, paydaÅŸlara ve kullanÄ±cÄ±lara ÅŸeffaflÄ±k ve gÃ¼ven saÄŸlar.

### Sorumlu Ãœretken Yapay Zeka Ã‡Ã¶zÃ¼mÃ¼ Ä°ÅŸletme

Yapay zeka uygulamalarÄ±nÄ±z etrafÄ±nda operasyonel bir uygulama oluÅŸturmak son aÅŸamadÄ±r. Bu, tÃ¼m yasal dÃ¼zenlemelere uygun olduÄŸumuzdan emin olmak iÃ§in startup'Ä±mÄ±zÄ±n diÄŸer bÃ¶lÃ¼mleriyle, Ã¶rneÄŸin Hukuk ve GÃ¼venlik ile iÅŸbirliÄŸi yapmayÄ± iÃ§erir. BaÅŸlatmadan Ã¶nce, teslimat, olaylarÄ± ele alma ve geri alma planlarÄ± oluÅŸturmak da kullanÄ±cÄ±larÄ±mÄ±za zarar vermeyi Ã¶nlemek iÃ§in Ã¶nemlidir.

## AraÃ§lar

Sorumlu Yapay Zeka Ã§Ã¶zÃ¼mleri geliÅŸtirme Ã§alÄ±ÅŸmasÄ± Ã§ok gibi gÃ¶rÃ¼nse de, bu Ã§abaya deÄŸer bir Ã§alÄ±ÅŸmadÄ±r. Ãœretken Yapay Zeka alanÄ± bÃ¼yÃ¼dÃ¼kÃ§e, geliÅŸtiricilerin sorumluluÄŸu iÅŸ akÄ±ÅŸlarÄ±na verimli bir ÅŸekilde entegre etmelerine yardÄ±mcÄ± olacak daha fazla araÃ§ olgunlaÅŸacaktÄ±r. Ã–rneÄŸin, [Azure AI Ä°Ã§erik GÃ¼venliÄŸi](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst), zararlÄ± iÃ§erik ve gÃ¶rÃ¼ntÃ¼leri bir API isteÄŸi ile tespit etmenize yardÄ±mcÄ± olabilir.

## Bilgi KontrolÃ¼

Sorumlu yapay zeka kullanÄ±mÄ±nÄ± saÄŸlamak iÃ§in dikkat etmeniz gereken bazÄ± ÅŸeyler nelerdir?

1. CevabÄ±n doÄŸru olmasÄ±.
1. ZararlÄ± kullanÄ±m, yapay zekanÄ±n suÃ§ amaÃ§lÄ± kullanÄ±lmamasÄ±.
1. Yapay zekanÄ±n Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±ndÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± saÄŸlamak.

C: 2 ve 3 doÄŸrudur. Sorumlu Yapay Zeka, zararlÄ± etkileri ve Ã¶nyargÄ±larÄ± nasÄ±l azaltabileceÄŸinizi dÃ¼ÅŸÃ¼nmenize yardÄ±mcÄ± olur ve daha fazlasÄ±nÄ± saÄŸlar.

## ğŸš€ Meydan Okuma

[Azure AI Ä°Ã§erik GÃ¼venliÄŸi](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hakkÄ±nda bilgi edinin ve kullanÄ±mÄ±nÄ±z iÃ§in neler benimseyebileceÄŸinizi gÃ¶rÃ¼n.

## Harika Ä°ÅŸ, Ã–ÄŸrenmeye Devam Edin

Bu dersi tamamladÄ±ktan sonra, Ãœretken Yapay Zeka bilginizi artÄ±rmaya devam etmek iÃ§in [Ãœretken Yapay Zeka Ã–ÄŸrenme koleksiyonumuza](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) gÃ¶z atÄ±n!

[Prompt MÃ¼hendisliÄŸi Temelleri](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) konusunu inceleyeceÄŸimiz 4. Derse geÃ§in!

**Sorumluluk Reddi**: 
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlama veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.