{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI Modellerini İnce Ayar Yapma\n",
    "\n",
    "Bu not defteri, Open AI tarafından sağlanan [İnce Ayar](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) belgelerindeki mevcut rehbere dayanmaktadır.\n",
    "\n",
    "İnce ayar, temel modellerin performansını, belirli kullanım durumu veya senaryoya ilişkin ek veri ve bağlamla yeniden eğiterek uygulamanız için iyileştirir. _few shot learning_ ve _retrieval augmented generation_ gibi prompt mühendisliği tekniklerinin, kaliteyi artırmak için varsayılan prompt'u ilgili verilerle geliştirmenize olanak tanıdığını unutmayın. Ancak, bu yaklaşımlar hedeflenen temel modelin maksimum token pencere boyutuyla sınırlıdır.\n",
    "\n",
    "İnce ayar ile, modeli gerekli verilerle etkili bir şekilde yeniden eğitiyoruz (maksimum token penceresine sığabilecekten çok daha fazla örnek kullanmamıza izin veriyor) - ve çıkarım zamanında örneklerin sağlanmasına artık ihtiyaç duymayan _özel_ bir model sürümünü dağıtıyoruz. Bu, prompt tasarımımızın etkinliğini artırmakla kalmaz (token penceresini diğer şeyler için kullanmada daha fazla esneklik sağlar) aynı zamanda maliyetlerimizi de potansiyel olarak iyileştirir (çıkarım zamanında modele göndermemiz gereken token sayısını azaltarak).\n",
    "\n",
    "İnce ayar 4 adımdan oluşur:\n",
    "1. Eğitim verilerini hazırlayın ve yükleyin.\n",
    "1. İnce ayarlı modeli elde etmek için eğitim işini çalıştırın.\n",
    "1. İnce ayarlı modeli değerlendirin ve kalite için yineleyin.\n",
    "1. Memnun kaldığınızda ince ayarlı modeli çıkarım için dağıtın.\n",
    "\n",
    "Tüm temel modellerin ince ayarı desteklemediğini unutmayın - en güncel bilgi için [OpenAI belgelerini kontrol edin](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst). Ayrıca daha önce ince ayar yapılmış bir modeli de ince ayar yapabilirsiniz. Bu öğreticide, ince ayar için hedef temel model olarak `gpt-35-turbo` kullanacağız.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adım 1.1: Veri Kümenizi Hazırlayın\n",
    "\n",
    "Bir element hakkında soruları bir limerik ile yanıtlayarak periyodik tabloyu anlamanıza yardımcı olan bir sohbet botu oluşturalım. _Bu_ basit öğreticide, verilerin beklenen formatını gösteren birkaç örnek yanıtla modeli eğitmek için sadece bir veri kümesi oluşturacağız. Gerçek dünya kullanımında, çok daha fazla örnek içeren bir veri kümesi oluşturmanız gerekir. Ayrıca, uygulama alanınız için mevcutsa açık bir veri kümesini kullanabilir ve ince ayar için yeniden biçimlendirebilirsiniz.\n",
    "\n",
    "`gpt-35-turbo` üzerine odaklandığımız ve tek turlu yanıt (sohbet tamamlama) aradığımız için, OpenAI sohbet tamamlama gereksinimlerini yansıtan [bu önerilen formatı](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) kullanarak örnekler oluşturabiliriz. Çok turlu sohbet içeriği bekliyorsanız, ince ayar sürecinde hangi mesajların kullanılacağını (veya kullanılmayacağını) belirtmek için `weight` parametresini içeren [çok turlu örnek formatını](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) kullanırsınız.\n",
    "\n",
    "Burada öğreticimiz için daha basit tek turlu formatı kullanacağız. Veriler, her satırda 1 kayıt bulunan ve her biri JSON formatında nesne olarak temsil edilen [jsonl formatındadır](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst). Aşağıdaki kesit, örnek olarak 2 kayıt göstermektedir - tam örnek seti için [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) dosyasına bakabilirsiniz (10 örnek) ve bunları ince ayar öğreticimizde kullanacağız. **Not:** Her kayıt _tek satırda_ tanımlanmalıdır (biçimlendirilmiş JSON dosyasında olduğu gibi satırlara bölünmemelidir).\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Gerçek dünya kullanımında iyi sonuçlar için çok daha büyük bir örnek setine ihtiyacınız olacak - burada kalite ile ince ayar için gereken zaman/maliyetler arasında bir denge olacaktır. Süreci göstermek için ince ayarı hızlıca tamamlayabilmek adına küçük bir set kullanıyoruz. Daha karmaşık bir ince ayar öğreticisi için [bu OpenAI Cookbook örneğine](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) bakabilirsiniz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adım 1.2 Veri Kümenizi Yükleyin\n",
    "\n",
    "Verileri, Dosyalar API'sini kullanarak [burada açıklandığı gibi](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file) yükleyin. Bu kodu çalıştırabilmek için öncelikle aşağıdaki adımları tamamlamış olmanız gerekir:\n",
    " - `openai` Python paketini yüklediniz (en son özellikler için >=0.28.0 sürümünü kullandığınızdan emin olun)\n",
    " - `OPENAI_API_KEY` ortam değişkenini OpenAI API anahtarınız olarak ayarladınız\n",
    "Daha fazla bilgi için, kurs için sağlanan [Kurulum rehberine](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) bakın.\n",
    "\n",
    "Şimdi, yerel JSONL dosyanızdan yükleme için bir dosya oluşturmak üzere kodu çalıştırın.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adım 2.1: SDK ile İnce Ayar işini oluşturma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adım 2.2: İşin Durumunu Kontrol Etme\n",
    "\n",
    "`client.fine_tuning.jobs` API'si ile yapabileceğiniz birkaç şey şunlardır:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Son n ince ayar işini listele\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Belirli bir ince ayar işinin detaylarını al\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Bir ince ayar işini iptal et\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - İşten n olayı listele\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Sürecin ilk adımı, verilerin doğru formatta olduğundan emin olmak için _eğitim dosyasını doğrulamaktır_.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adım 2.3: İlerlemenin izlenmesi için olayları takip etme\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adım 2.4: Durumu OpenAI Kontrol Panelinde Görüntüleyin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durumu ayrıca OpenAI web sitesini ziyaret ederek ve platformun _İnce Ayar_ bölümünü keşfederek görüntüleyebilirsiniz. Bu, mevcut işin durumunu gösterir ve ayrıca önceki iş yürütme geçmişini takip etmenizi sağlar. Bu ekran görüntüsünde, önceki yürütmenin başarısız olduğunu ve ikinci çalışmanın başarılı olduğunu görebilirsiniz. Bağlam için, bu durum ilk çalışmanın yanlış biçimlendirilmiş kayıtlar içeren bir JSON dosyası kullandığında meydana geldi - düzeltildikten sonra, ikinci çalışma başarıyla tamamlandı ve modeli kullanıma sundu. \n",
    "\n",
    "![İnce ayar iş durumu](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba.tr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Durum mesajlarını ve metrikleri, görsel panoda aşağı doğru kaydırarak da görüntüleyebilirsiniz:\n",
    "\n",
    "| Mesajlar | Metrikler |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b.tr.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a65229.tr.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adım 3.1: Kimliği Alın ve İnce Ayarlı Modeli Kodda Test Edin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Adım 3.2: İnce Ayarlı Modeli Playground'da Yükleyin ve Test Edin\n",
    "\n",
    "Artık ince ayarlı modeli iki şekilde test edebilirsiniz. İlk olarak, Playground'a gidip Modeller açılır menüsünden yeni ince ayarlı modelinizi listelenen seçenekler arasından seçebilirsiniz. Diğer seçenek ise, yukarıdaki ekran görüntüsünde görülen İnce Ayar panelinde gösterilen \"Playground\" seçeneğini kullanmaktır; bu, temel ve ince ayarlı model sürümlerini yan yana gösteren aşağıdaki _karşılaştırmalı_ görünümü başlatır ve hızlı değerlendirme yapmanızı sağlar.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016.tr.png)\n",
    "\n",
    "Eğitim verilerinizde kullanılan sistem bağlamını doldurun ve test sorunuzla devam edin. Her iki tarafın da aynı bağlam ve soruyla güncellendiğini fark edeceksiniz. Karşılaştırmayı çalıştırın ve çıktılar arasındaki farkı göreceksiniz. _İnce ayarlı modelin yanıtı örneklerinizde sağladığınız formatta sunduğunu, temel modelin ise sadece sistem istemini takip ettiğini not edin_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350.tr.png)\n",
    "\n",
    "Karşılaştırmanın ayrıca her model için token sayılarını ve çıkarım için geçen süreyi sağladığını fark edeceksiniz. **Bu özel örnek, süreci göstermek için basit bir örnektir ve gerçek bir veri seti veya senaryoyu yansıtmaz**. Her iki örneğin de aynı sayıda token gösterdiğini (sistem bağlamı ve kullanıcı istemi aynıdır) ve ince ayarlı modelin çıkarım için daha fazla zaman aldığını fark edebilirsiniz (özel model).\n",
    "\n",
    "Gerçek dünya senaryolarında, bu tür oyuncak bir örnek kullanmayacak, gerçek verilerle ince ayar yapacaksınız (örneğin, müşteri hizmetleri için ürün kataloğu) ve yanıt kalitesi çok daha belirgin olacaktır. _Bu_ bağlamda, temel modelle eşdeğer yanıt kalitesi elde etmek, daha fazla özel istem mühendisliği gerektirecek ve bu da token kullanımını ve muhtemelen çıkarım için ilgili işlem süresini artıracaktır. _Bunu denemek için, OpenAI Cookbook'taki ince ayar örneklerine göz atabilirsiniz._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Feragatname**:  \nBu belge, AI çeviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba gösterilse de, otomatik çevirilerin hatalar veya yanlışlıklar içerebileceğini lütfen unutmayın. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımı sonucu oluşabilecek yanlış anlamalar veya yorum hatalarından sorumlu değiliz.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T10:17:20+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "tr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}