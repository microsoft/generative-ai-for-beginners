{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bölüm 7: Sohbet Uygulamaları Oluşturmak\n",
    "## Github Modelleri API Hızlı Başlangıç\n",
    "\n",
    "Bu not defteri, [Azure OpenAI Örnekleri Deposu](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) adresinden uyarlanmıştır ve [Azure OpenAI](notebook-azure-openai.ipynb) hizmetlerine erişen not defterlerini içerir.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Genel Bakış  \n",
    "\"Büyük dil modelleri, metni metne eşleyen fonksiyonlardır. Bir metin dizesi verildiğinde, büyük bir dil modeli bir sonraki gelecek metni tahmin etmeye çalışır\"(1). Bu \"hızlı başlangıç\" not defteri, kullanıcılara üst düzey LLM kavramlarını, AML ile başlamada gerekli temel paketleri, istem tasarımına yumuşak bir giriş ve farklı kullanım senaryolarına dair birkaç kısa örnek sunacaktır.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## İçindekiler  \n",
    "\n",
    "[Genel Bakış](../../../../07-building-chat-applications/python)  \n",
    "[OpenAI Servisi Nasıl Kullanılır](../../../../07-building-chat-applications/python)  \n",
    "[1. OpenAI Servisinizi Oluşturma](../../../../07-building-chat-applications/python)  \n",
    "[2. Kurulum](../../../../07-building-chat-applications/python)    \n",
    "[3. Kimlik Bilgileri](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Kullanım Alanları](../../../../07-building-chat-applications/python)    \n",
    "[1. Metni Özetle](../../../../07-building-chat-applications/python)  \n",
    "[2. Metni Sınıflandır](../../../../07-building-chat-applications/python)  \n",
    "[3. Yeni Ürün İsimleri Oluştur](../../../../07-building-chat-applications/python)  \n",
    "[4. Bir Sınıflandırıcıyı İnce Ayarla](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Referanslar](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### İlk isteminizi oluşturun  \n",
    "Bu kısa alıştırma, Github Modelleri'nde bir modele \"özetleme\" gibi basit bir görev için istem göndermeye temel bir giriş sağlayacaktır.\n",
    "\n",
    "**Adımlar**:  \n",
    "1. Python ortamınıza `azure-ai-inference` kütüphanesini yükleyin, eğer henüz yüklemediyseniz.  \n",
    "2. Standart yardımcı kütüphaneleri yükleyin ve Github Modelleri kimlik bilgilerinizi ayarlayın.  \n",
    "3. Göreviniz için bir model seçin  \n",
    "4. Model için basit bir istem oluşturun  \n",
    "5. İsteğinizi model API'sine gönderin!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. `azure-ai-inference` paketini yükleyin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Doğru modeli bulmak  \n",
    "GPT-3.5-turbo veya GPT-4 modelleri, doğal dili anlayabilir ve üretebilir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. İstem Tasarımı  \n",
    "\n",
    "\"Büyük dil modellerinin sihri, tahmin hatasını devasa miktarda metin üzerinde en aza indirmek için eğitildiklerinde, bu tahminler için faydalı olan kavramları öğrenmeleridir. Örneğin, şu gibi kavramları öğrenirler\"(1):\n",
    "\n",
    "* nasıl yazılır\n",
    "* dilbilgisi nasıl çalışır\n",
    "* nasıl farklı şekilde ifade edilir\n",
    "* sorulara nasıl cevap verilir\n",
    "* nasıl sohbet edilir\n",
    "* birçok dilde nasıl yazılır\n",
    "* nasıl kod yazılır\n",
    "* vb.\n",
    "\n",
    "#### Büyük bir dil modelini nasıl kontrol edersiniz  \n",
    "\"Büyük bir dil modeline verilen girdiler arasında, açık ara en etkili olanı metin istemidir(1).\n",
    "\n",
    "Büyük dil modelleri birkaç farklı şekilde çıktı üretmek için yönlendirilebilir:\n",
    "\n",
    "Talimat: Modele ne istediğinizi söyleyin\n",
    "Tamamlama: Modele istediğiniz şeyin başlangıcını tamamlatın\n",
    "Gösterim: Modele ne istediğinizi gösterin, şu yollarla:\n",
    "İstem içinde birkaç örnekle\n",
    "İnce ayar eğitim veri setinde yüzlerce veya binlerce örnekle\"\n",
    "\n",
    "\n",
    "\n",
    "#### İstem oluşturmak için üç temel kural vardır:\n",
    "\n",
    "**Göster ve anlat**. Ne istediğinizi talimatlarla, örneklerle veya ikisinin birleşimiyle açıkça belirtin. Modelden bir listeyi alfabetik olarak sıralamasını veya bir paragrafı duyguya göre sınıflandırmasını istiyorsanız, ona tam olarak bunu istediğinizi gösterin.\n",
    "\n",
    "**Kaliteli veri sağlayın**. Bir sınıflandırıcı oluşturmak veya modelin bir deseni takip etmesini istiyorsanız, yeterli sayıda örnek olduğundan emin olun. Örneklerinizi mutlaka gözden geçirin — model genellikle basit yazım hatalarını görebilecek kadar akıllıdır ve size bir yanıt verebilir, ancak bunun kasıtlı olduğunu da varsayabilir ve bu yanıtı etkileyebilir.\n",
    "\n",
    "**Ayarlarınızı kontrol edin.** Temperature ve top_p ayarları, modelin yanıt üretirken ne kadar belirleyici olduğunu kontrol eder. Eğer modelden yalnızca tek bir doğru yanıt bekliyorsanız, bu ayarları düşük tutmak istersiniz. Daha çeşitli yanıtlar arıyorsanız, bu ayarları daha yüksek tutabilirsiniz. İnsanların bu ayarlarla ilgili en sık yaptığı hata, bunların \"zekâ\" veya \"yaratıcılık\" kontrolleri olduğunu varsaymalarıdır.\n",
    "\n",
    "\n",
    "Kaynak: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Metni Özetle  \n",
    "#### Zorluk  \n",
    "Bir metin pasajının sonuna 'tl;dr:' ekleyerek metni özetleyin. Modelin, ek bir talimat olmadan birçok görevi nasıl yerine getirebildiğine dikkat edin. Modelin davranışını değiştirmek ve aldığınız özeti kişiselleştirmek için tl;dr'den daha açıklayıcı istemlerle de deneyler yapabilirsiniz(3).  \n",
    "\n",
    "Son zamanlarda yapılan çalışmalar, büyük bir metin korpusu üzerinde ön eğitim yapıp ardından belirli bir görevde ince ayar yapmanın, birçok NLP görevi ve kıyaslamasında önemli ilerlemeler sağladığını gösterdi. Mimari olarak genellikle görevden bağımsız olsa da, bu yöntem yine de binlerce veya on binlerce örnekten oluşan göreve özel ince ayar veri kümeleri gerektiriyor. Buna karşılık, insanlar genellikle yalnızca birkaç örnekten veya basit talimatlardan yeni bir dil görevini yerine getirebiliyor - bu, mevcut NLP sistemlerinin hâlâ büyük ölçüde zorlandığı bir konu. Burada, dil modellerinin ölçeğini büyütmenin, görevden bağımsız ve az örnekli performansı büyük ölçüde artırdığını, bazen önceki en iyi ince ayar yaklaşımlarıyla rekabet edebilecek seviyeye ulaştığını gösteriyoruz.\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Birkaç kullanım durumu için alıştırmalar  \n",
    "1. Metni özetle  \n",
    "2. Metni sınıflandır  \n",
    "3. Yeni ürün isimleri oluştur\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Metni Sınıflandır  \n",
    "#### Zorluk  \n",
    "Öğeleri, çıkarım sırasında verilen kategorilere göre sınıflandırın. Aşağıdaki örnekte, hem kategorileri hem de sınıflandırılacak metni istemde sağlıyoruz (*playground_reference).\n",
    "\n",
    "Müşteri Sorgusu: Merhaba, dizüstü bilgisayarımın klavyesindeki tuşlardan biri yakın zamanda kırıldı ve bir yedeğe ihtiyacım olacak:\n",
    "\n",
    "Sınıflandırılan kategori:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Yeni Ürün İsimleri Oluşturma\n",
    "#### Zorluk\n",
    "Örnek kelimelerden ürün isimleri oluşturun. Burada, isimlerini üreteceğimiz ürün hakkında bilgi veriyoruz. Ayrıca, almak istediğimiz kalıbı göstermek için benzer bir örnek de sunuyoruz. Rastgeleliği ve yenilikçi yanıtları artırmak için temperature değerini yüksek tuttuk.\n",
    "\n",
    "Ürün açıklaması: Ev tipi milkshake makinesi\n",
    "Tohum kelimeler: hızlı, sağlıklı, kompakt.\n",
    "Ürün isimleri: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Ürün açıklaması: Her ayak numarasına uyabilen bir çift ayakkabı.\n",
    "Tohum kelimeler: uyarlanabilir, uyum, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Referanslar  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Örnekleri](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [GPT-3'ü metin sınıflandırmak için ince ayar yapmada en iyi uygulamalar](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Daha Fazla Yardım İçin  \n",
    "[OpenAI Ticarileştirme Ekibi](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Katkıda Bulunanlar\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Feragatname**:\nBu belge, AI çeviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanılarak çevrilmiştir. Doğruluk için çaba göstersek de, otomatik çevirilerin hata veya yanlışlıklar içerebileceğini lütfen unutmayın. Belgenin orijinal diliyle hazırlanmış hali esas alınmalıdır. Kritik bilgiler için profesyonel insan çevirisi önerilir. Bu çevirinin kullanımından doğabilecek yanlış anlama veya yanlış yorumlamalardan sorumlu değiliz.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:36:43+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "tr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}