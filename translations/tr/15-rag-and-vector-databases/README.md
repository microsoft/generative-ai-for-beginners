<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-07-09T16:12:12+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "tr"
}
-->
# Retrieval Augmented Generation (RAG) ve VektÃ¶r VeritabanlarÄ±

[![Retrieval Augmented Generation (RAG) ve VektÃ¶r VeritabanlarÄ±](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.tr.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

Arama uygulamalarÄ± dersinde, kendi verilerinizi BÃ¼yÃ¼k Dil Modellerine (LLM) nasÄ±l entegre edeceÄŸinizi kÄ±saca Ã¶ÄŸrenmiÅŸtik. Bu derste, LLM uygulamanÄ±zda verilerinizi temel alma kavramlarÄ±na, sÃ¼recin iÅŸleyiÅŸine ve hem gÃ¶mme (embedding) hem de metin verilerini depolama yÃ¶ntemlerine daha derinlemesine bakacaÄŸÄ±z.

> **Video YakÄ±nda Gelecek**

## GiriÅŸ

Bu derste aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

- RAGâ€™a giriÅŸ, ne olduÄŸu ve yapay zekada (AI) neden kullanÄ±ldÄ±ÄŸÄ±.

- VektÃ¶r veritabanlarÄ±nÄ±n ne olduÄŸunu anlamak ve uygulamamÄ±z iÃ§in bir tane oluÅŸturmak.

- RAGâ€™Ä± bir uygulamaya nasÄ±l entegre edeceÄŸimize dair pratik bir Ã¶rnek.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra ÅŸunlarÄ± yapabileceksiniz:

- RAGâ€™Ä±n veri alma ve iÅŸleme sÃ¼reÃ§lerindeki Ã¶nemini aÃ§Ä±klamak.

- RAG uygulamasÄ±nÄ± kurmak ve verilerinizi bir LLMâ€™e temel almak.

- RAG ve VektÃ¶r VeritabanlarÄ±nÄ±n LLM uygulamalarÄ±nda etkili entegrasyonu.

## Senaryomuz: LLMâ€™lerimizi kendi verilerimizle geliÅŸtirmek

Bu derste, eÄŸitim giriÅŸimimize kendi notlarÄ±mÄ±zÄ± eklemek istiyoruz; bÃ¶ylece sohbet botu farklÄ± konular hakkÄ±nda daha fazla bilgi edinebilecek. Elimizdeki notlarÄ± kullanarak, Ã¶ÄŸrenenler daha iyi Ã§alÄ±ÅŸabilecek ve farklÄ± konularÄ± anlayarak sÄ±navlarÄ±na daha kolay hazÄ±rlanabilecekler. Senaryomuzu oluÅŸturmak iÃ§in ÅŸunlarÄ± kullanacaÄŸÄ±z:

- `Azure OpenAI:` sohbet botumuzu oluÅŸturmak iÃ§in kullanacaÄŸÄ±mÄ±z LLM

- `AI for beginners' lesson on Neural Networks:` LLMâ€™imizi temel alacaÄŸÄ±mÄ±z veri

- `Azure AI Search` ve `Azure Cosmos DB:` verilerimizi depolamak ve arama dizini oluÅŸturmak iÃ§in vektÃ¶r veritabanÄ±

KullanÄ±cÄ±lar notlarÄ±ndan pratik quizler oluÅŸturabilecek, tekrar kartlarÄ± hazÄ±rlayabilecek ve bunlarÄ± kÄ±sa Ã¶zetlere dÃ¶nÃ¼ÅŸtÃ¼rebilecekler. BaÅŸlamak iÃ§in, RAGâ€™Ä±n ne olduÄŸuna ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na bakalÄ±m:

## Retrieval Augmented Generation (RAG)

LLM destekli bir sohbet botu, kullanÄ±cÄ±dan gelen girdileri iÅŸleyerek yanÄ±tlar Ã¼retir. EtkileÅŸimli olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r ve kullanÄ±cÄ±larla Ã§ok Ã§eÅŸitli konularda iletiÅŸim kurar. Ancak yanÄ±tlarÄ±, saÄŸlanan baÄŸlam ve temel eÄŸitim verileriyle sÄ±nÄ±rlÄ±dÄ±r. Ã–rneÄŸin, GPT-4â€™Ã¼n bilgi kesim tarihi EylÃ¼l 2021â€™dir; yani bu tarihten sonraki olaylar hakkÄ±nda bilgisi yoktur. AyrÄ±ca, LLMâ€™leri eÄŸitmek iÃ§in kullanÄ±lan veriler, kiÅŸisel notlar veya bir ÅŸirketin Ã¼rÃ¼n kÄ±lavuzu gibi gizli bilgileri iÃ§ermez.

### RAGâ€™lar (Retrieval Augmented Generation) nasÄ±l Ã§alÄ±ÅŸÄ±r

![RAGâ€™larÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren Ã§izim](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.tr.png)

Diyelim ki notlarÄ±nÄ±zdan quizler oluÅŸturan bir sohbet botu daÄŸÄ±tmak istiyorsunuz, bilgi tabanÄ±na baÄŸlantÄ± gerekecek. Ä°ÅŸte burada RAG devreye girer. RAGâ€™lar ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:

- **Bilgi tabanÄ±:** Geri getirme iÅŸleminden Ã¶nce, bu belgeler alÄ±nÄ±r ve Ã¶n iÅŸleme tabi tutulur; genellikle bÃ¼yÃ¼k belgeler kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼nÃ¼r, metin gÃ¶mme (embedding) haline dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve bir veritabanÄ±nda saklanÄ±r.

- **KullanÄ±cÄ± Sorgusu:** kullanÄ±cÄ± bir soru sorar

- **Geri Getirme:** KullanÄ±cÄ± soru sorduÄŸunda, gÃ¶mme modeli bilgi tabanÄ±mÄ±zdan ilgili bilgileri alÄ±r ve baÄŸlamÄ± artÄ±rarak isteme (prompt) dahil edilir.

- **GeliÅŸtirilmiÅŸ Ãœretim:** LLM, alÄ±nan verilere dayanarak yanÄ±tÄ±nÄ± geliÅŸtirir. BÃ¶ylece yanÄ±t sadece Ã¶nceden eÄŸitilmiÅŸ verilere deÄŸil, eklenen baÄŸlamdan gelen ilgili bilgilere de dayanÄ±r. AlÄ±nan veriler LLMâ€™nin yanÄ±tlarÄ±nÄ± zenginleÅŸtirmek iÃ§in kullanÄ±lÄ±r. LLM ardÄ±ndan kullanÄ±cÄ±nÄ±n sorusuna yanÄ±t verir.

![RAG mimarisini gÃ¶steren Ã§izim](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.tr.png)

RAG mimarisi, iki bÃ¶lÃ¼mden oluÅŸan transformer yapÄ±sÄ±yla uygulanÄ±r: bir encoder ve bir decoder. Ã–rneÄŸin, kullanÄ±cÄ± bir soru sorduÄŸunda, giriÅŸ metni kelimelerin anlamÄ±nÄ± yakalayan vektÃ¶rlere 'kodlanÄ±r' ve bu vektÃ¶rler belge dizinimize 'Ã§Ã¶zÃ¼lÃ¼r' ve kullanÄ±cÄ± sorgusuna dayalÄ± yeni metin oluÅŸturulur. LLM, Ã§Ä±ktÄ± Ã¼retmek iÃ§in hem encoder-decoder modelini kullanÄ±r.

Ã–nerilen makaleye gÃ¶re RAG uygulamasÄ±nda iki yaklaÅŸÄ±m vardÄ±r: [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst):

- **_RAG-Sequence_**: alÄ±nan belgeleri kullanarak kullanÄ±cÄ± sorgusuna en iyi cevabÄ± tahmin etmek

- **RAG-Token**: belgeleri kullanarak sonraki tokenâ€™Ä± Ã¼retmek, ardÄ±ndan kullanÄ±cÄ± sorgusuna yanÄ±t vermek iÃ§in belgeleri geri getirmek

### Neden RAG kullanmalÄ±sÄ±nÄ±z?

- **Bilgi zenginliÄŸi:** metin yanÄ±tlarÄ±nÄ±n gÃ¼ncel ve doÄŸru olmasÄ±nÄ± saÄŸlar. BÃ¶ylece, dahili bilgi tabanÄ±na eriÅŸerek alan bazlÄ± gÃ¶revlerde performansÄ± artÄ±rÄ±r.

- **DoÄŸrulanabilir veri** kullanarak uydurmayÄ± azaltÄ±r ve kullanÄ±cÄ± sorgularÄ±na baÄŸlam saÄŸlar.

- **Maliyet etkin:** LLMâ€™yi ince ayar yapmaya kÄ±yasla daha ekonomiktir.

## Bilgi tabanÄ± oluÅŸturma

UygulamamÄ±z kiÅŸisel verilerimize dayanÄ±yor, yani AI For Beginners mÃ¼fredatÄ±ndaki Neural Network dersi.

### VektÃ¶r VeritabanlarÄ±

VektÃ¶r veritabanÄ±, geleneksel veritabanlarÄ±ndan farklÄ± olarak, gÃ¶mÃ¼lÃ¼ vektÃ¶rleri depolamak, yÃ¶netmek ve aramak iÃ§in tasarlanmÄ±ÅŸ Ã¶zel bir veritabanÄ±dÄ±r. Belgelerin sayÄ±sal temsillerini saklar. Veriyi sayÄ±sal gÃ¶mme haline getirmek, yapay zeka sistemimizin veriyi anlamasÄ±nÄ± ve iÅŸlemesini kolaylaÅŸtÄ±rÄ±r.

GÃ¶mme verilerimizi vektÃ¶r veritabanlarÄ±nda saklarÄ±z Ã§Ã¼nkÃ¼ LLMâ€™lerin kabul ettiÄŸi token sayÄ±sÄ± sÄ±nÄ±rlÄ±dÄ±r. TÃ¼m gÃ¶mmeleri LLMâ€™ye veremeyeceÄŸimiz iÃ§in, bunlarÄ± parÃ§alara bÃ¶lmemiz gerekir ve kullanÄ±cÄ± soru sorduÄŸunda, soruya en uygun gÃ¶mmeler istemle birlikte dÃ¶ndÃ¼rÃ¼lÃ¼r. ParÃ§alama ayrÄ±ca LLMâ€™ye gÃ¶nderilen token sayÄ±sÄ±nÄ± azaltarak maliyetleri dÃ¼ÅŸÃ¼rÃ¼r.

PopÃ¼ler vektÃ¶r veritabanlarÄ± arasÄ±nda Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ve DeepLake bulunur. Azure CLI kullanarak Azure Cosmos DB modeli oluÅŸturabilirsiniz:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Metinden gÃ¶mme oluÅŸturma

Verilerimizi depolamadan Ã¶nce, veriyi veritabanÄ±na kaydetmeden Ã¶nce vektÃ¶r gÃ¶mme haline dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekir. BÃ¼yÃ¼k belgeler veya uzun metinlerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, beklediÄŸiniz sorgulara gÃ¶re parÃ§alayabilirsiniz. ParÃ§alama cÃ¼mle veya paragraf seviyesinde yapÄ±labilir. ParÃ§alama, Ã§evresindeki kelimelerden anlam Ã§Ä±kardÄ±ÄŸÄ± iÃ§in, parÃ§aya belge baÅŸlÄ±ÄŸÄ± veya parÃ§adan Ã¶nce/sonra gelen metin gibi ek baÄŸlamlar ekleyebilirsiniz. Veriyi ÅŸu ÅŸekilde parÃ§alayabilirsiniz:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

ParÃ§alandÄ±ktan sonra, metnimizi farklÄ± gÃ¶mme modelleri kullanarak gÃ¶mebiliriz. KullanabileceÄŸiniz bazÄ± modeller: word2vec, OpenAIâ€™nin ada-002 modeli, Azure Computer Vision ve daha fazlasÄ±. KullanÄ±lacak model, kullandÄ±ÄŸÄ±nÄ±z dil, kodlanan iÃ§erik tÃ¼rÃ¼ (metin/gÃ¶rÃ¼ntÃ¼/ses), kodlayabileceÄŸi giriÅŸ boyutu ve gÃ¶mme Ã§Ä±ktÄ±sÄ±nÄ±n uzunluÄŸuna baÄŸlÄ±dÄ±r.

OpenAIâ€™nin `text-embedding-ada-002` modeliyle gÃ¶mÃ¼len bir metin Ã¶rneÄŸi:
![cat kelimesinin gÃ¶mme hali](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.tr.png)

## Geri getirme ve VektÃ¶r Arama

KullanÄ±cÄ± bir soru sorduÄŸunda, geri getirme modeli bunu sorgu kodlayÄ±cÄ± ile vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, ardÄ±ndan belge arama dizinimizde giriÅŸle ilgili vektÃ¶rleri arar. Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda, hem giriÅŸ vektÃ¶rÃ¼ hem de belge vektÃ¶rleri metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve LLMâ€™ye iletilir.

### Geri getirme

Geri getirme, sistemin arama kriterlerini karÅŸÄ±layan belgeleri dizinden hÄ±zlÄ±ca bulmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ± aÅŸamadÄ±r. Geri getirme modelinin amacÄ±, baÄŸlam saÄŸlamak ve LLMâ€™yi verilerinizle temel almaktÄ±r.

VeritabanÄ±mÄ±zda arama yapmak iÃ§in birkaÃ§ yÃ¶ntem vardÄ±r:

- **Anahtar kelime aramasÄ±** - metin aramalarÄ± iÃ§in kullanÄ±lÄ±r

- **Anlamsal arama** - kelimelerin anlamsal anlamÄ±nÄ± kullanÄ±r

- **VektÃ¶r aramasÄ±** - belgeleri metinden gÃ¶mme vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Geri getirme, kullanÄ±cÄ± sorusuna en yakÄ±n vektÃ¶rlere sahip belgeler sorgulanarak yapÄ±lÄ±r.

- **Hibrit** - anahtar kelime ve vektÃ¶r aramasÄ±nÄ±n birleÅŸimi.

Geri getirmede zorluk, veritabanÄ±nda sorguya benzer yanÄ±t olmadÄ±ÄŸÄ±nda ortaya Ã§Ä±kar; sistem en iyi bilgiyi dÃ¶ndÃ¼rÃ¼r. Ancak, alaka dÃ¼zeyi iÃ§in maksimum mesafe ayarlamak veya anahtar kelime ile vektÃ¶r aramasÄ±nÄ± birleÅŸtiren hibrit arama gibi taktikler kullanabilirsiniz. Bu derste hibrit arama kullanacaÄŸÄ±z. Verilerimizi, parÃ§alar ve gÃ¶mmeleri iÃ§eren sÃ¼tunlara sahip bir dataframeâ€™de saklayacaÄŸÄ±z.

### VektÃ¶r BenzerliÄŸi

Geri getirme modeli, bilgi tabanÄ±nda birbirine yakÄ±n gÃ¶mmeleri arar; en yakÄ±n komÅŸu, benzer metinlerdir. KullanÄ±cÄ± bir sorgu sorduÄŸunda, Ã¶nce gÃ¶mÃ¼lÃ¼r ve benzer gÃ¶mmelerle eÅŸleÅŸtirilir. FarklÄ± vektÃ¶rlerin ne kadar benzer olduÄŸunu Ã¶lÃ§mek iÃ§in yaygÄ±n kullanÄ±lan yÃ¶ntem, iki vektÃ¶r arasÄ±ndaki aÃ§Ä±ya dayanan kosinÃ¼s benzerliÄŸidir.

BenzerliÄŸi Ã¶lÃ§mek iÃ§in kullanabileceÄŸimiz diÄŸer yÃ¶ntemler Euclidean mesafesi (vektÃ¶r uÃ§ noktalarÄ± arasÄ±ndaki dÃ¼z Ã§izgi) ve nokta Ã§arpÄ±mÄ±dÄ±r (iki vektÃ¶rÃ¼n karÅŸÄ±lÄ±k gelen elemanlarÄ±nÄ±n Ã§arpÄ±mlarÄ±nÄ±n toplamÄ±nÄ± Ã¶lÃ§er).

### Arama dizini

Geri getirme yaparken, arama yapmadan Ã¶nce bilgi tabanÄ±mÄ±z iÃ§in bir arama dizini oluÅŸturmamÄ±z gerekir. Dizin, gÃ¶mmelerimizi saklar ve bÃ¼yÃ¼k bir veritabanÄ±nda bile en benzer parÃ§alarÄ± hÄ±zlÄ±ca bulabilir. Dizini yerel olarak ÅŸu ÅŸekilde oluÅŸturabiliriz:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Yeniden sÄ±ralama

VeritabanÄ±nÄ± sorguladÄ±ktan sonra, sonuÃ§larÄ± en alakalÄ±dan baÅŸlayarak sÄ±ralamanÄ±z gerekebilir. Yeniden sÄ±ralama LLMâ€™si, makine Ã¶ÄŸrenimi kullanarak arama sonuÃ§larÄ±nÄ±n alaka dÃ¼zeyini artÄ±rÄ±r ve en alakalÄ±dan baÅŸlayarak sÄ±ralar. Azure AI Search kullanÄ±ldÄ±ÄŸÄ±nda, yeniden sÄ±ralama semantik yeniden sÄ±ralayÄ±cÄ± ile otomatik yapÄ±lÄ±r. En yakÄ±n komÅŸular kullanÄ±larak yeniden sÄ±ralamanÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na Ã¶rnek:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Hepsini bir araya getirmek

Son adÄ±m, yanÄ±tlarÄ±n verilerimize dayalÄ± olmasÄ±nÄ± saÄŸlamak iÃ§in LLMâ€™imizi sÃ¼rece dahil etmektir. Bunu ÅŸu ÅŸekilde uygulayabiliriz:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## UygulamamÄ±zÄ± deÄŸerlendirme

### DeÄŸerlendirme Ã–lÃ§Ã¼tleri

- SaÄŸlanan yanÄ±tlarÄ±n kalitesi: doÄŸal, akÄ±cÄ± ve insan benzeri olmasÄ±

- Verinin temelliliÄŸi: yanÄ±tÄ±n saÄŸlanan belgelerden gelip gelmediÄŸinin deÄŸerlendirilmesi

- Alaka dÃ¼zeyi: yanÄ±tÄ±n soruyla uyumlu ve ilgili olmasÄ±

- AkÄ±cÄ±lÄ±k: yanÄ±tÄ±n dilbilgisel olarak anlamlÄ± olmasÄ±

## RAG (Retrieval Augmented Generation) ve vektÃ¶r veritabanlarÄ± kullanÄ±m alanlarÄ±

Fonksiyon Ã§aÄŸrÄ±larÄ±nÄ±n uygulamanÄ±zÄ± geliÅŸtirebileceÄŸi birÃ§ok farklÄ± kullanÄ±m alanÄ± vardÄ±r, Ã¶rneÄŸin:

- Soru-Cevap: ÅŸirket verilerinizi temel alan ve Ã§alÄ±ÅŸanlarÄ±n soru sorabileceÄŸi bir sohbet oluÅŸturmak.

- Tavsiye Sistemleri: en benzer deÄŸerleri eÅŸleÅŸtiren sistemler oluÅŸturmak, Ã¶rneÄŸin filmler, restoranlar ve daha fazlasÄ±.

- Sohbet botu hizmetleri: sohbet geÃ§miÅŸini saklayabilir ve kullanÄ±cÄ± verilerine gÃ¶re kiÅŸiselleÅŸtirilmiÅŸ konuÅŸmalar yapabilirsiniz.

- VektÃ¶r gÃ¶mmelerine dayalÄ± gÃ¶rsel arama, gÃ¶rÃ¼ntÃ¼ tanÄ±ma ve anomali tespiti iÃ§in faydalÄ±dÄ±r.

## Ã–zet

RAGâ€™Ä±n temel alanlarÄ±nÄ±, verilerimizi uygulamaya eklemekten kullanÄ±cÄ± sorgusu ve Ã§Ä±ktÄ±sÄ±na kadar ele aldÄ±k. RAG oluÅŸturmayÄ± kolaylaÅŸtÄ±rmak iÃ§in Semanti Kernel, Langchain veya Autogen gibi Ã§erÃ§eveleri kullanabilirsiniz.

## Ã–dev

Retrieval Augmented Generation (RAG) Ã¶ÄŸreniminize devam etmek iÃ§in ÅŸunlarÄ± yapabilirsiniz:

- SeÃ§tiÄŸiniz bir Ã§erÃ§eveyi kullanarak uygulama iÃ§in bir Ã¶n yÃ¼z oluÅŸturun

- LangChain veya Semantic Kernel gibi bir Ã§erÃ§eve kullanarak uygulamanÄ±zÄ± yeniden oluÅŸturun.

Dersi tamamladÄ±ÄŸÄ±nÄ±z iÃ§in tebrikler ğŸ‘.

## Ã–ÄŸrenme burada bitmiyor, yolculuÄŸa devam edin

Bu dersi tamamladÄ±ktan sonra, Generative AI bilginizi geliÅŸtirmeye devam etmek iÃ§in [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) koleksiyonumuza gÃ¶z atÄ±n!

**Feragatname**:  
Bu belge, AI Ã§eviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±nÄ±z. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu ortaya Ã§Ä±kabilecek yanlÄ±ÅŸ anlamalar veya yorum hatalarÄ±ndan sorumlu deÄŸiliz.