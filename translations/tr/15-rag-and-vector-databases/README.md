<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b4b0266fbadbba7ded891b6485adc66d",
  "translation_date": "2025-10-17T16:18:47+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "tr"
}
-->
# Bilgi Getirme Destekli Ãœretim (RAG) ve VektÃ¶r VeritabanlarÄ±

[![Bilgi Getirme Destekli Ãœretim (RAG) ve VektÃ¶r VeritabanlarÄ±](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.tr.png)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Arama uygulamalarÄ± dersinde, kendi verilerinizi BÃ¼yÃ¼k Dil Modellerine (LLM'ler) entegre etmenin nasÄ±l yapÄ±lacaÄŸÄ±nÄ± kÄ±saca Ã¶ÄŸrenmiÅŸtik. Bu derste, verilerinizi LLM uygulamanÄ±za dayandÄ±rma kavramlarÄ±nÄ±, sÃ¼recin mekaniklerini ve verilerin depolanmasÄ± yÃ¶ntemlerini, hem gÃ¶mÃ¼lÃ¼ veriler hem de metinler dahil olmak Ã¼zere daha ayrÄ±ntÄ±lÄ± bir ÅŸekilde inceleyeceÄŸiz.

> **Video YakÄ±nda Geliyor**

## GiriÅŸ

Bu derste aÅŸaÄŸÄ±daki konularÄ± ele alacaÄŸÄ±z:

- RAG'a giriÅŸ, ne olduÄŸu ve yapay zekada (AI) neden kullanÄ±ldÄ±ÄŸÄ±.

- VektÃ¶r veritabanlarÄ±nÄ±n ne olduÄŸunu anlamak ve uygulamamÄ±z iÃ§in bir tane oluÅŸturmak.

- RAG'Ä± bir uygulamaya entegre etme Ã¼zerine pratik bir Ã¶rnek.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra:

- RAG'Ä±n veri getirme ve iÅŸleme aÃ§Ä±sÄ±ndan Ã¶nemini aÃ§Ä±klayabileceksiniz.

- RAG uygulamasÄ±nÄ± kurabilecek ve verilerinizi bir LLM'ye dayandÄ±rabileceksiniz.

- LLM uygulamalarÄ±nda RAG ve VektÃ¶r VeritabanlarÄ±nÄ± etkili bir ÅŸekilde entegre edebileceksiniz.

## Senaryomuz: LLM'lerimizi kendi verilerimizle geliÅŸtirmek

Bu ders iÃ§in, eÄŸitim giriÅŸimimize kendi notlarÄ±mÄ±zÄ± eklemek istiyoruz, bÃ¶ylece chatbot farklÄ± konular hakkÄ±nda daha fazla bilgi alabilir. Sahip olduÄŸumuz notlarÄ± kullanarak, Ã¶ÄŸrenciler daha iyi Ã§alÄ±ÅŸabilecek ve farklÄ± konularÄ± anlayabilecek, bu da sÄ±navlarÄ±na hazÄ±rlanmayÄ± kolaylaÅŸtÄ±racaktÄ±r. Senaryomuzu oluÅŸturmak iÃ§in ÅŸunlarÄ± kullanacaÄŸÄ±z:

- `Azure OpenAI:` Chatbotumuzu oluÅŸturmak iÃ§in kullanacaÄŸÄ±mÄ±z LLM

- `AI iÃ§in baÅŸlangÄ±Ã§ dersi: Sinir AÄŸlarÄ±`: LLM'mizi dayandÄ±racaÄŸÄ±mÄ±z veri

- `Azure AI Search` ve `Azure Cosmos DB:` Verilerimizi depolamak ve bir arama dizini oluÅŸturmak iÃ§in vektÃ¶r veritabanÄ±

KullanÄ±cÄ±lar notlarÄ±ndan pratik sÄ±navlar oluÅŸturabilecek, revizyon kartlarÄ± hazÄ±rlayabilecek ve bunlarÄ± kÄ±sa Ã¶zetlere dÃ¶nÃ¼ÅŸtÃ¼rebilecek. BaÅŸlamak iÃ§in, RAG'Ä±n ne olduÄŸunu ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyelim:

## Bilgi Getirme Destekli Ãœretim (RAG)

Bir LLM destekli chatbot, kullanÄ±cÄ± istemlerini iÅŸleyerek yanÄ±tlar Ã¼retir. EtkileÅŸimli olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r ve kullanÄ±cÄ±larla geniÅŸ bir konu yelpazesinde iletiÅŸim kurar. Ancak, yanÄ±tlarÄ± saÄŸlanan baÄŸlam ve temel eÄŸitim verileriyle sÄ±nÄ±rlÄ±dÄ±r. Ã–rneÄŸin, GPT-4'Ã¼n bilgi kesim tarihi EylÃ¼l 2021'dir, yani bu tarihten sonra meydana gelen olaylar hakkÄ±nda bilgi sahibi deÄŸildir. AyrÄ±ca, LLM'leri eÄŸitmek iÃ§in kullanÄ±lan veriler, kiÅŸisel notlar veya bir ÅŸirketin Ã¼rÃ¼n kÄ±lavuzu gibi gizli bilgileri iÃ§ermez.

### RAG'larÄ±n (Bilgi Getirme Destekli Ãœretim) nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±

![RAG'larÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren Ã§izim](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.tr.png)

Diyelim ki notlarÄ±nÄ±zdan sÄ±navlar oluÅŸturan bir chatbot daÄŸÄ±tmak istiyorsunuz, bilgi tabanÄ±na bir baÄŸlantÄ± gerekecektir. Ä°ÅŸte burada RAG devreye girer. RAG'lar ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:

- **Bilgi tabanÄ±:** Getirme iÅŸleminden Ã¶nce, bu belgelerin genellikle bÃ¼yÃ¼k belgeleri daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rarak, metin gÃ¶mÃ¼lÃ¼ verilere dÃ¶nÃ¼ÅŸtÃ¼rerek ve bir veritabanÄ±nda depolayarak alÄ±nmasÄ± ve Ã¶n iÅŸleme tabi tutulmasÄ± gerekir.

- **KullanÄ±cÄ± Sorgusu:** KullanÄ±cÄ± bir soru sorar.

- **Getirme:** KullanÄ±cÄ± bir soru sorduÄŸunda, gÃ¶mme modeli bilgi tabanÄ±mÄ±zdan daha fazla baÄŸlam saÄŸlamak iÃ§in ilgili bilgileri alÄ±r ve isteme dahil eder.

- **Destekli Ãœretim:** LLM, alÄ±nan verilere dayanarak yanÄ±tÄ±nÄ± geliÅŸtirir. Bu, Ã¼retilen yanÄ±tÄ±n yalnÄ±zca Ã¶nceden eÄŸitilmiÅŸ verilere deÄŸil, aynÄ± zamanda ek baÄŸlamdan gelen ilgili bilgilere dayanmasÄ±nÄ± saÄŸlar. AlÄ±nan veriler, LLM'nin yanÄ±tlarÄ±nÄ± desteklemek iÃ§in kullanÄ±lÄ±r. LLM daha sonra kullanÄ±cÄ±nÄ±n sorusuna bir yanÄ±t dÃ¶ndÃ¼rÃ¼r.

![RAG'larÄ±n mimarisini gÃ¶steren Ã§izim](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.tr.png)

RAG'larÄ±n mimarisi, bir kodlayÄ±cÄ± ve bir kod Ã§Ã¶zÃ¼cÃ¼den oluÅŸan dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ler kullanÄ±larak uygulanÄ±r. Ã–rneÄŸin, bir kullanÄ±cÄ± bir soru sorduÄŸunda, giriÅŸ metni 'kodlanÄ±r' ve kelimelerin anlamÄ±nÄ± yakalayan vektÃ¶rlere dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r, ardÄ±ndan vektÃ¶rler belge dizinimize 'kod Ã§Ã¶zÃ¼lÃ¼r' ve kullanÄ±cÄ± sorgusuna dayalÄ± yeni metin oluÅŸturur. LLM, Ã§Ä±ktÄ±yÄ± oluÅŸturmak iÃ§in hem kodlayÄ±cÄ± hem de kod Ã§Ã¶zÃ¼cÃ¼ model kullanÄ±r.

Ã–nerilen makaleye gÃ¶re RAG'Ä± uygularken iki yaklaÅŸÄ±m: [Bilgi YoÄŸun NLP (doÄŸal dil iÅŸleme yazÄ±lÄ±mÄ±) GÃ¶revleri iÃ§in Bilgi Getirme Destekli Ãœretim](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst):

- **_RAG-Sequence_** alÄ±nan belgeleri kullanarak bir kullanÄ±cÄ± sorgusuna en iyi olasÄ± yanÄ±tÄ± tahmin etmek

- **RAG-Token** belgeleri kullanarak bir sonraki token'Ä± oluÅŸturmak, ardÄ±ndan kullanÄ±cÄ± sorgusuna yanÄ±t vermek iÃ§in bunlarÄ± almak

### Neden RAG kullanmalÄ±sÄ±nÄ±z?Â 

- **Bilgi zenginliÄŸi:** metin yanÄ±tlarÄ±nÄ±n gÃ¼ncel ve gÃ¼ncel olmasÄ±nÄ± saÄŸlar. Bu nedenle, iÃ§ bilgi tabanÄ±na eriÅŸerek alan spesifik gÃ¶revlerde performansÄ± artÄ±rÄ±r.

- **DoÄŸrulanabilir veri** kullanarak kullanÄ±cÄ± sorgularÄ±na baÄŸlam saÄŸlamak iÃ§in sahte bilgileri azaltÄ±r.

- **Maliyet etkinliÄŸi:** LLM'yi ince ayar yapmaya kÄ±yasla daha ekonomiktir.

## Bilgi tabanÄ± oluÅŸturma

UygulamamÄ±z, kiÅŸisel verilerimize, yani AI For Beginners mÃ¼fredatÄ±ndaki Sinir AÄŸÄ± dersine dayanmaktadÄ±r.

### VektÃ¶r VeritabanlarÄ±

VektÃ¶r veritabanÄ±, geleneksel veritabanlarÄ±ndan farklÄ± olarak, gÃ¶mÃ¼lÃ¼ vektÃ¶rleri depolamak, yÃ¶netmek ve aramak iÃ§in tasarlanmÄ±ÅŸ Ã¶zel bir veritabanÄ±dÄ±r. Belgelerin sayÄ±sal temsillerini depolar. Verileri sayÄ±sal gÃ¶mÃ¼lÃ¼ verilere ayÄ±rmak, AI sistemimizin verileri anlamasÄ±nÄ± ve iÅŸlemesini kolaylaÅŸtÄ±rÄ±r.

GÃ¶mÃ¼lÃ¼ verilerimizi vektÃ¶r veritabanlarÄ±nda depolarÄ±z Ã§Ã¼nkÃ¼ LLM'lerin giriÅŸ olarak kabul ettiÄŸi token sayÄ±sÄ±nda bir sÄ±nÄ±r vardÄ±r. GÃ¶mÃ¼lÃ¼ verilerin tamamÄ±nÄ± bir LLM'ye aktaramayacaÄŸÄ±nÄ±z iÃ§in, bunlarÄ± parÃ§alara ayÄ±rmamÄ±z gerekecek ve bir kullanÄ±cÄ± bir soru sorduÄŸunda, soruya en Ã§ok benzeyen gÃ¶mÃ¼lÃ¼ veriler istemle birlikte dÃ¶ndÃ¼rÃ¼lecektir. ParÃ§alama ayrÄ±ca bir LLM'den geÃ§en token sayÄ±sÄ±ndaki maliyetleri azaltÄ±r.

PopÃ¼ler vektÃ¶r veritabanlarÄ±ndan bazÄ±larÄ± Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ve DeepLake'dir. Azure CLI kullanarak aÅŸaÄŸÄ±daki komutla bir Azure Cosmos DB modeli oluÅŸturabilirsiniz:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Metinden gÃ¶mÃ¼lÃ¼ verilere

Verilerimizi depolamadan Ã¶nce, veritabanÄ±nda depolanmadan Ã¶nce vektÃ¶r gÃ¶mÃ¼lÃ¼ verilere dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekecek. BÃ¼yÃ¼k belgeler veya uzun metinlerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, beklediÄŸiniz sorgulara gÃ¶re bunlarÄ± parÃ§alara ayÄ±rabilirsiniz. ParÃ§alama cÃ¼mle dÃ¼zeyinde veya paragraf dÃ¼zeyinde yapÄ±labilir. ParÃ§alama, etrafÄ±ndaki kelimelerden anlamlar Ã§Ä±kardÄ±ÄŸÄ± iÃ§in, bir parÃ§aya biraz baÄŸlam ekleyebilirsiniz, Ã¶rneÄŸin belge baÅŸlÄ±ÄŸÄ±nÄ± ekleyerek veya parÃ§adan Ã¶nce veya sonra biraz metin ekleyerek. Verileri ÅŸu ÅŸekilde parÃ§alara ayÄ±rabilirsiniz:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

ParÃ§alara ayrÄ±ldÄ±ktan sonra, metnimizi farklÄ± gÃ¶mme modelleri kullanarak gÃ¶mebiliriz. KullanabileceÄŸiniz bazÄ± modeller ÅŸunlardÄ±r: word2vec, OpenAI tarafÄ±ndan ada-002, Azure Computer Vision ve daha birÃ§ok model. KullanÄ±lacak bir model seÃ§mek, kullandÄ±ÄŸÄ±nÄ±z dillere, kodlanan iÃ§eriÄŸin tÃ¼rÃ¼ne (metin/gÃ¶rÃ¼ntÃ¼/ses), kodlayabileceÄŸi giriÅŸ boyutuna ve gÃ¶mme Ã§Ä±ktÄ±sÄ±nÄ±n uzunluÄŸuna baÄŸlÄ± olacaktÄ±r.

OpenAI'nin `text-embedding-ada-002` modeli kullanÄ±larak gÃ¶mÃ¼lÃ¼ bir metin Ã¶rneÄŸi:
![kedi kelimesinin gÃ¶mÃ¼lÃ¼ hali](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.tr.png)

## Getirme ve VektÃ¶r Arama

Bir kullanÄ±cÄ± bir soru sorduÄŸunda, alÄ±cÄ± bunu sorgu kodlayÄ±cÄ± kullanarak bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, ardÄ±ndan belgelerimizin arama dizininde giriÅŸle ilgili belgeler iÃ§in ilgili vektÃ¶rleri arar. Ä°ÅŸlem tamamlandÄ±ktan sonra, hem giriÅŸ vektÃ¶rÃ¼nÃ¼ hem de belge vektÃ¶rlerini metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve LLM'ye iletir.

### Getirme

Getirme, sistemin arama kriterlerini karÅŸÄ±layan belgeleri dizinden hÄ±zlÄ± bir ÅŸekilde bulmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ±nda gerÃ§ekleÅŸir. AlÄ±cÄ±nÄ±n amacÄ±, baÄŸlam saÄŸlamak ve LLM'yi verilerinize dayandÄ±rmak iÃ§in kullanÄ±lacak belgeleri elde etmektir.

VeritabanÄ±mÄ±zda arama yapmak iÃ§in birkaÃ§ yÃ¶ntem vardÄ±r, Ã¶rneÄŸin:

- **Anahtar kelime aramasÄ±** - metin aramalarÄ± iÃ§in kullanÄ±lÄ±r.

- **Anlamsal arama** - kelimelerin anlamsal anlamÄ±nÄ± kullanÄ±r.

- **VektÃ¶r aramasÄ±** - belgeleri gÃ¶mme modelleri kullanarak metinden vektÃ¶r temsillerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Getirme, kullanÄ±cÄ± sorusuna en yakÄ±n vektÃ¶r temsillerine sahip belgeleri sorgulayarak yapÄ±lÄ±r.

- **Hibrit** - hem anahtar kelime hem de vektÃ¶r aramasÄ±nÄ± birleÅŸtirir.

Getirme ile ilgili bir zorluk, veritabanÄ±nda sorguya benzer bir yanÄ±t olmadÄ±ÄŸÄ±nda ortaya Ã§Ä±kar, sistem o zaman elde edebileceÄŸi en iyi bilgiyi dÃ¶ndÃ¼rÃ¼r, ancak maksimum alaka mesafesini ayarlamak veya hem anahtar kelimeleri hem de vektÃ¶r aramayÄ± birleÅŸtiren hibrit arama kullanmak gibi taktikler kullanabilirsiniz. Bu derste, hem vektÃ¶r hem de anahtar kelime aramasÄ±nÄ± birleÅŸtiren hibrit arama kullanacaÄŸÄ±z. Verilerimizi, parÃ§alarÄ± ve gÃ¶mÃ¼lÃ¼ verileri iÃ§eren sÃ¼tunlarla bir veri Ã§erÃ§evesine depolayacaÄŸÄ±z.

### VektÃ¶r BenzerliÄŸi

AlÄ±cÄ±, bilgi veritabanÄ±nda birbirine yakÄ±n olan gÃ¶mÃ¼lÃ¼ verileri arayacaktÄ±r, en yakÄ±n komÅŸu, Ã§Ã¼nkÃ¼ bunlar benzer metinlerdir. Bir kullanÄ±cÄ± bir sorgu sorduÄŸunda, Ã¶nce gÃ¶mÃ¼lÃ¼r, ardÄ±ndan benzer gÃ¶mÃ¼lÃ¼ verilerle eÅŸleÅŸtirilir. FarklÄ± vektÃ¶rlerin ne kadar benzer olduÄŸunu bulmak iÃ§in kullanÄ±lan yaygÄ±n Ã¶lÃ§Ã¼m, iki vektÃ¶r arasÄ±ndaki aÃ§Ä±ya dayalÄ± olan kosinÃ¼s benzerliÄŸidir.

BenzerliÄŸi Ã¶lÃ§mek iÃ§in kullanabileceÄŸimiz diÄŸer alternatifler, vektÃ¶r uÃ§ noktalarÄ± arasÄ±ndaki dÃ¼z Ã§izgi olan Ã–klid mesafesi ve iki vektÃ¶rÃ¼n karÅŸÄ±lÄ±k gelen elemanlarÄ±nÄ±n Ã§arpÄ±mlarÄ±nÄ±n toplamÄ±nÄ± Ã¶lÃ§en nokta Ã§arpÄ±mÄ±dÄ±r.

### Arama dizini

Getirme iÅŸlemi yaparken, arama yapmadan Ã¶nce bilgi tabanÄ±mÄ±z iÃ§in bir arama dizini oluÅŸturmamÄ±z gerekecek. Bir dizin, gÃ¶mÃ¼lÃ¼ verilerimizi depolar ve bÃ¼yÃ¼k bir veritabanÄ±nda bile en benzer parÃ§alarÄ± hÄ±zlÄ± bir ÅŸekilde alabilir. Dizini yerel olarak ÅŸu ÅŸekilde oluÅŸturabiliriz:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Yeniden sÄ±ralama

VeritabanÄ±nÄ± sorguladÄ±ktan sonra, sonuÃ§larÄ± en alakalÄ± olanlardan baÅŸlayarak sÄ±ralamanÄ±z gerekebilir. Yeniden sÄ±ralama LLM, arama sonuÃ§larÄ±nÄ±n alaka dÃ¼zeyini iyileÅŸtirmek iÃ§in bunlarÄ± en alakalÄ±dan baÅŸlayarak sÄ±ralamak iÃ§in Makine Ã–ÄŸrenimi kullanÄ±r. Azure AI Search kullanarak, yeniden sÄ±ralama sizin iÃ§in otomatik olarak yapÄ±lÄ±r ve bir anlamsal yeniden sÄ±ralayÄ±cÄ± kullanÄ±lÄ±r. En yakÄ±n komÅŸularÄ± kullanarak yeniden sÄ±ralamanÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na bir Ã¶rnek:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Hepsini bir araya getirmek

Son adÄ±m, LLM'mizi karÄ±ÅŸÄ±ma ekleyerek yanÄ±tlarÄ±n verilerimize dayalÄ± olmasÄ±nÄ± saÄŸlamaktÄ±r. Bunu ÅŸu ÅŸekilde uygulayabiliriz:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## UygulamamÄ±zÄ± deÄŸerlendirme

### DeÄŸerlendirme Ã–lÃ§Ã¼tleri

- YanÄ±tlarÄ±n doÄŸal, akÄ±cÄ± ve insan gibi duyulmasÄ±nÄ± saÄŸlama kalitesi

- Verilerin dayandÄ±rÄ±lmasÄ±: yanÄ±tÄ±n saÄŸlanan belgelerden gelip gelmediÄŸini deÄŸerlendirme

- Alaka dÃ¼zeyi: yanÄ±tÄ±n sorulan soruyla eÅŸleÅŸip eÅŸleÅŸmediÄŸini ve ilgili olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirme

- AkÄ±cÄ±lÄ±k - yanÄ±tÄ±n dilbilgisel olarak mantÄ±klÄ± olup olmadÄ±ÄŸÄ±nÄ± deÄŸerlendirme

## RAG (Bilgi Getirme Destekli Ãœretim) ve vektÃ¶r veritabanlarÄ±nÄ± kullanma senaryolarÄ±

Fonksiyon Ã§aÄŸrÄ±larÄ±nÄ±n uygulamanÄ±zÄ± geliÅŸtirebileceÄŸi birÃ§ok farklÄ± kullanÄ±m durumu vardÄ±r, Ã¶rneÄŸin:

- Soru ve Cevaplama: ÅŸirket verilerinizi bir sohbete dayandÄ±rarak Ã§alÄ±ÅŸanlarÄ±n sorular sormasÄ± iÃ§in kullanÄ±labilir.

- Ã–neri Sistemleri: en benzer deÄŸerleri eÅŸleÅŸtiren bir sistem oluÅŸturabileceÄŸiniz yerler, Ã¶rneÄŸin filmler, restoranlar ve daha fazlasÄ±.

- Chatbot hizmetleri: sohbet geÃ§miÅŸini depolayabilir ve kullanÄ±cÄ± verilerine dayalÄ± olarak konuÅŸmayÄ± kiÅŸiselleÅŸtirebilirsiniz.

- GÃ¶rÃ¼ntÃ¼ tanÄ±ma ve anomali tespiti yaparken faydalÄ± olan vektÃ¶r gÃ¶mÃ¼lÃ¼ verilere dayalÄ± gÃ¶rÃ¼ntÃ¼ arama.

## Ã–zet

Bu derste, verilerimizi uygulamaya eklemekten, kullanÄ±cÄ± sorgusuna ve Ã§Ä±ktÄ±sÄ±na kadar RAG'Ä±n temel alanlarÄ±nÄ± ele aldÄ±k. RAG oluÅŸturmayÄ± basitleÅŸtirmek iÃ§in Semanti Kernel, Langchain veya Autogen gibi Ã§erÃ§eveler kullanabilirsiniz.

## Ã–dev

Bilgi Getirme Destekli Ãœretim (RAG) Ã¶ÄŸreniminize devam etmek iÃ§in ÅŸunlarÄ± yapabilirsiniz:

- SeÃ§tiÄŸiniz bir Ã§erÃ§eveyi kullanarak uygulama iÃ§in bir Ã¶n yÃ¼z oluÅŸturun.

- LangChain veya Semantic Kernel Ã§erÃ§evesini kullanarak uygulamanÄ±zÄ± yeniden oluÅŸturun.

Dersi tamamladÄ±ÄŸÄ±nÄ±z iÃ§in tebrikler ğŸ‘.

## Ã–ÄŸrenme burada bitmiyor, yolculuÄŸa devam edin

Bu dersi tamamladÄ±ktan sonra, Generative AI bilginizi geliÅŸtirmeye devam etmek iÃ§in [Generative AI Ã–ÄŸrenme koleksiyonumuzu](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) inceleyin!

---

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Belgenin orijinal dili, yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalar iÃ§in sorumluluk kabul etmiyoruz.