<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2210a0466c812d9defc4df2d9a709ff9",
  "translation_date": "2026-01-18T18:16:20+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "tr"
}
-->
# Retrieval Augmented Generation (RAG) ve VektÃ¶r VeritabanlarÄ±

[![Retrieval Augmented Generation (RAG) ve VektÃ¶r VeritabanlarÄ±](../../../../../translated_images/tr/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Arama uygulamalarÄ± dersinde, kendi verilerinizi BÃ¼yÃ¼k Dil Modellerine (LLM'ler) nasÄ±l entegre edeceÄŸinizi kÄ±saca Ã¶ÄŸrendik. Bu derste, LLM uygulamanÄ±zda verilerinizi temel alma kavramÄ±na, sÃ¼recin mekaniklerine ve hem gÃ¶mme hem de metin verilerinin depolanma yÃ¶ntemlerine daha derinlemesine bakacaÄŸÄ±z.

> **Video YakÄ±nda Gelecek**

## GiriÅŸ

Bu derste ÅŸunlarÄ± ele alacaÄŸÄ±z:

- RAG'Ä±n tanÄ±tÄ±mÄ±, ne olduÄŸu ve yapay zekada (AI) neden kullanÄ±ldÄ±ÄŸÄ±.

- VektÃ¶r veritabanlarÄ±nÄ±n ne olduÄŸunu anlamak ve uygulamamÄ±z iÃ§in bir tane oluÅŸturmak.

- RAG'Ä± bir uygulamaya entegre etme Ã¼zerine pratik bir Ã¶rnek.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra:

- RAG'Ä±n veri eriÅŸimi ve iÅŸleme aÃ§Ä±sÄ±ndan Ã¶nemini aÃ§Ä±klayabileceksiniz.

- RAG uygulamasÄ±nÄ± kurup verilerinizi bir LLM'ye dayandÄ±rabileceksiniz.

- RAG ve VektÃ¶r VeritabanlarÄ±nÄ±n LLM uygulamalarÄ±nda etkili entegrasyonunu gerÃ§ekleÅŸtirebileceksiniz.

## Senaryomuz: Kendi verilerimizle LLM'lerimizi geliÅŸtirmek

Bu ders iÃ§in, eÄŸitim giriÅŸimimize kendi notlarÄ±mÄ±zÄ± eklemek istiyoruz; bÃ¶ylece sohbet botu farklÄ± konular hakkÄ±nda daha fazla bilgi alabilir. Elimizdeki notlarÄ± kullanarak, Ã¶ÄŸrenciler daha iyi Ã§alÄ±ÅŸÄ±p farklÄ± konularÄ± anlayabilecek ve sÄ±navlarÄ±na hazÄ±rlanmak daha kolay olacak. Senaryomuzu oluÅŸturmak iÃ§in ÅŸunlarÄ± kullanacaÄŸÄ±z:

- `Azure OpenAI:` sohbet botumuzu oluÅŸturmak iÃ§in kullanacaÄŸÄ±mÄ±z LLM

- `AI for beginners' lesson on Neural Networks`: LLM'imizi dayandÄ±racaÄŸÄ±mÄ±z veri

- `Azure AI Search` ve `Azure Cosmos DB:` verilerimizi depolamak ve bir arama dizini oluÅŸturmak iÃ§in vektÃ¶r veritabanÄ±

KullanÄ±cÄ±lar notlarÄ±ndan pratik quizler oluÅŸturabilecek, tekrar kartlarÄ± hazÄ±rlayabilecek ve bunlarÄ± Ã¶zetleyerek kÄ±sa genel bakÄ±ÅŸlar elde edebilecekler. BaÅŸlamak iÃ§in RAG'Ä±n ne olduÄŸunu ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyelim:

## Retrieval Augmented Generation (RAG)

LLM destekli bir sohbet botu, kullanÄ±cÄ± istemlerini iÅŸleyerek yanÄ±tlar oluÅŸturur. EtkileÅŸimli olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r ve kullanÄ±cÄ±larla Ã§ok Ã§eÅŸitli konularda etkileÅŸime girer. Ancak yanÄ±tlarÄ±, saÄŸlanan baÄŸlam ve temel eÄŸitim verileri ile sÄ±nÄ±rlÄ±dÄ±r. Ã–rneÄŸin, GPT-4'Ã¼n bilgi kesim tarihi EylÃ¼l 2021'dir; bu, bu tarihten sonra gerÃ§ekleÅŸen olaylarÄ± bilmediÄŸi anlamÄ±na gelir. AyrÄ±ca, LLM'leri eÄŸitmek iÃ§in kullanÄ±lan veri, kiÅŸisel notlar veya bir ÅŸirketin Ã¼rÃ¼n kÄ±lavuzu gibi gizli bilgileri iÃ§ermez.

### RAG'lar (Retrieval Augmented Generation) nasÄ±l Ã§alÄ±ÅŸÄ±r?

![RAG'larÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren Ã§izim](../../../../../translated_images/tr/how-rag-works.f5d0ff63942bd3a6.webp)

Diyelim ki notlarÄ±nÄ±zdan quizler oluÅŸturan bir sohbet botu daÄŸÄ±tmak istiyorsunuz; bilgi tabanÄ±na baÄŸlantÄ±ya ihtiyacÄ±nÄ±z olacak. Ä°ÅŸte burada RAG devreye girer. RAG'lar ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:

- **Bilgi tabanÄ±:** EriÅŸimden Ã¶nce, bu belgelerin alÄ±nmasÄ± ve Ã¶n iÅŸlenmesi gerekir; genellikle bÃ¼yÃ¼k belgeler kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lÃ¼nÃ¼r, metin gÃ¶mmeye dÃ¶nÃ¼ÅŸtÃ¼rÃ¼lÃ¼r ve bir veritabanÄ±na kaydedilir.

- **KullanÄ±cÄ± Sorgusu:** kullanÄ±cÄ± soru sorar

- **EriÅŸim:** KullanÄ±cÄ± soru sorduÄŸunda, gÃ¶mme modeli bilgi tabanÄ±mÄ±zdan ilgili bilgileri alÄ±r ve isteÄŸe baÄŸlanacak daha fazla baÄŸlam saÄŸlamak iÃ§in kullanÄ±r.

- **GeliÅŸtirilmiÅŸ Ãœretim:** LLM, alÄ±nan verilere dayanarak yanÄ±tÄ±nÄ± geliÅŸtirir. Bu, oluÅŸturulan yanÄ±tÄ±n sadece Ã¶nceden eÄŸitilmiÅŸ verilere deÄŸil, eklenen baÄŸlamdan alÄ±nan ilgili bilgilere dayanmasÄ±nÄ± saÄŸlar. EriÅŸilen veriler, LLM yanÄ±tlarÄ±nÄ± geliÅŸtirmek iÃ§in kullanÄ±lÄ±r. Sonra LLM, kullanÄ±cÄ±nÄ±n sorusuna cevap verir.

![RAG'larÄ±n mimarisini gÃ¶steren Ã§izim](../../../../../translated_images/tr/encoder-decode.f2658c25d0eadee2.webp)

RAG mimarisi iki bÃ¶lÃ¼mden oluÅŸan transformer kullanÄ±larak uygulanÄ±r: bir kodlayÄ±cÄ± (encoder) ve bir Ã§Ã¶zÃ¼cÃ¼ (decoder). Ã–rneÄŸin, kullanÄ±cÄ± bir soru sorduÄŸunda, giriÅŸ metni kelimelerin anlamÄ±nÄ± yakalayan vektÃ¶rlere 'kodlanÄ±r' ve bu vektÃ¶rler belgesi dizinine 'Ã§Ã¶zÃ¼mlenir' ve kullanÄ±cÄ± sorgusuna gÃ¶re yeni metin oluÅŸturulur. LLM, Ã§Ä±ktÄ±yÄ± Ã¼retmek iÃ§in hem kodlayÄ±cÄ±-Ã§Ã¶zÃ¼cÃ¼ modelini kullanÄ±r.

Ã–nerilen makaleye gÃ¶re RAG uygulamalarÄ±nda iki yaklaÅŸÄ±m vardÄ±r: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst):

- **_RAG-Sequence_**: KullanÄ±cÄ±nÄ±n sorgusuna en iyi olasÄ± cevabÄ± tahmin etmek iÃ§in eriÅŸilen belgeleri kullanma

- **RAG-Token**: Belgeyi sonraki token'Ä± Ã¼retmek iÃ§in kullanÄ±r, ardÄ±ndan kullanÄ±cÄ± sorgusunu yanÄ±tlamak iÃ§in geri getirir

### Neden RAG kullanÄ±rsÄ±nÄ±z?

- **Bilgi zenginliÄŸi:** Metin yanÄ±tlarÄ±nÄ±n gÃ¼ncel ve gÃ¼ncel kalmasÄ±nÄ± saÄŸlar. BÃ¶ylece, dahili bilgi tabanÄ±na eriÅŸerek alan Ã¶zel gÃ¶revlerde performansÄ± artÄ±rÄ±r.

- DoÄŸrulanabilir veriyi kullanarak **uydurma**yÄ± azaltÄ±r ve kullanÄ±cÄ± sorgularÄ±na baÄŸlam saÄŸlar.

- Bir LLM'yi ince ayar yapmaya gÃ¶re daha **maliyet etkili**dir.

## Bir bilgi tabanÄ± oluÅŸturmak

UygulamamÄ±z kiÅŸisel verilere dayanÄ±r; yani AI For Beginners mÃ¼fredatÄ±ndaki Sinir AÄŸlarÄ± dersi.

### VektÃ¶r VeritabanlarÄ±

VektÃ¶r veritabanÄ±, geleneksel veritabanlarÄ±ndan farklÄ± olarak gÃ¶mÃ¼lÃ¼ vektÃ¶rleri saklamak, yÃ¶netmek ve aramak iÃ§in tasarlanmÄ±ÅŸ Ã¶zel bir veritabanÄ±dÄ±r. Belgelerin sayÄ±sal temsillerini depolar. Verileri sayÄ±sal gÃ¶mme vektÃ¶rlerine dÃ¶nÃ¼ÅŸtÃ¼rmek, yapay zeka sistemimizin verileri anlamasÄ±nÄ± ve iÅŸlemesini kolaylaÅŸtÄ±rÄ±r.

GÃ¶mme verilerimizi vektÃ¶r veritabanlarÄ±nda depolarÄ±z Ã§Ã¼nkÃ¼ LLM'lerin giriÅŸ olarak kabul ettiÄŸi token sayÄ±sÄ±nda bir sÄ±nÄ±r vardÄ±r. TÃ¼m gÃ¶mmeleri bir LLM'ye gÃ¶nderemezsiniz, bu yÃ¼zden bunlarÄ± parÃ§alara ayÄ±rmanÄ±z gerekir ve kullanÄ±cÄ± bir soru sorduÄŸunda, soruyla en Ã§ok eÅŸleÅŸen gÃ¶mmeler isteÄŸe birlikte geri dÃ¶ner. ParÃ§alama, LLM'ye gÃ¶nderilen token sayÄ±sÄ±nÄ±n maliyetini de azaltÄ±r.

PopÃ¼ler bazÄ± vektÃ¶r veritabanlarÄ± Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ve DeepLake'dir. Azure CLI kullanarak Azure Cosmos DB modeli oluÅŸturmak iÃ§in ÅŸu komutu kullanabilirsiniz:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Metinden gÃ¶mme vektÃ¶rlerine

Verilerimizi depolamadan Ã¶nce, Ã¶nce onlarÄ± vektÃ¶r gÃ¶mme biÃ§imine dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekir. BÃ¼yÃ¼k belgeler veya uzun metinlerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, beklediÄŸiniz sorgulara gÃ¶re parÃ§alayabilirsiniz. ParÃ§alama cÃ¼mle veya paragraf seviyesinde yapÄ±labilir. ParÃ§alama, Ã§evresindeki kelimelerden anlam Ã§Ä±kardÄ±ÄŸÄ± iÃ§in, bÃ¶lÃ¼me baÅŸka baÄŸlamlar ekleyebilirsiniz; Ã¶rneÄŸin, belge baÅŸlÄ±ÄŸÄ±nÄ± ekleyerek veya bÃ¶lÃ¼me Ã¶nce veya sonra bir metin ekleyerek. Verileri ÅŸÃ¶yle parÃ§alayabilirsiniz:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # Son parÃ§a minimum uzunluÄŸa ulaÅŸmadÄ±ysa bile yine de ekle
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

BÃ¶lÃ¼mlendikten sonra, metnimizi Ã§eÅŸitli gÃ¶mme modelleri ile gÃ¶mebiliriz. KullanabileceÄŸiniz modeller arasÄ±nda word2vec, OpenAI tarafÄ±ndan ada-002, Azure Computer Vision ve daha fazlasÄ± vardÄ±r. KullanÄ±lacak model, kullandÄ±ÄŸÄ±nÄ±z diller, kodlanan iÃ§erik tÃ¼rÃ¼ (metin/gÃ¶rsel/ses), kodlanabilecek giriÅŸ boyutu ve gÃ¶mme Ã§Ä±ktÄ±sÄ±nÄ±n uzunluÄŸuna baÄŸlÄ±dÄ±r.

OpenAI'nin `text-embedding-ada-002` modeli ile oluÅŸturulmuÅŸ gÃ¶mÃ¼lÃ¼ metne bir Ã¶rnek:
![cat kelimesinin gÃ¶mmesi](../../../../../translated_images/tr/cat.74cbd7946bc9ca38.webp)

## EriÅŸim ve VektÃ¶r Arama

KullanÄ±cÄ± bir soru sorduÄŸunda, eriÅŸici (retriever) sorguyu sorgu kodlayÄ±cÄ±sÄ± kullanarak vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, ardÄ±ndan belge arama dizinimizde girdiyle ilgili belgelerden ilgili vektÃ¶rleri arar. Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda, hem giriÅŸ vektÃ¶rÃ¼nÃ¼ hem de belge vektÃ¶rlerini metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve bunlarÄ± LLM'ye geÃ§irir.

### EriÅŸim

EriÅŸim, sistemin dizindeki arama kriterlerini karÅŸÄ±layan belgeleri hÄ±zlÄ±ca bulmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ± andÄ±r. EriÅŸimcinin (retriever's) amacÄ±, baÄŸlam saÄŸlamak ve LLM'yi verilerinize dayandÄ±rmak Ã¼zere kullanÄ±lacak belgeleri almaktÄ±r.

VeritabanÄ±mÄ±zda arama yapmak iÃ§in birkaÃ§ yÃ¶ntem vardÄ±r:

- **Anahtar kelime aramasÄ±** - metin aramalarÄ± iÃ§in kullanÄ±lÄ±r

- **VektÃ¶r aramasÄ±** - belgeleri metinden gÃ¶mme modelleri aracÄ±lÄ±ÄŸÄ±yla vektÃ¶r temsillerine dÃ¶nÃ¼ÅŸtÃ¼rerek, kelimelerin anlamÄ±nÄ± kullanarak **anlamsal arama** yapÄ±lmasÄ±na izin verir. EriÅŸim, kullanÄ±cÄ±nÄ±n sorusuna en yakÄ±n vektÃ¶r temsiline sahip belgeleri sorgulayarak gerÃ§ekleÅŸtirilir.

- **Hibrit** - hem anahtar kelime hem de vektÃ¶r aramasÄ±nÄ±n birleÅŸimidir.

EriÅŸim sorunlarÄ±, veritabanÄ±nda sorguya benzer yanÄ±t olmadÄ±ÄŸÄ±nda ortaya Ã§Ä±kar; sistem o zaman elde edebildiÄŸi en iyi bilgiyi dÃ¶ndÃ¼recektir. Ancak, uygunluÄŸu maksimum mesafe ile sÄ±nÄ±rlandÄ±rmak veya hem anahtar kelime hem vektÃ¶r aramasÄ±nÄ± birleÅŸtiren karma arama kullanmak gibi taktikler uygulanabilir. Bu derste, hem vektÃ¶r hem anahtar kelime aramasÄ±nÄ±n birleÅŸimi olan hibrit aramayÄ± kullanacaÄŸÄ±z. Verilerimizi, parÃ§alarÄ± ve gÃ¶mmeleri iÃ§eren sÃ¼tunlarÄ± olan bir veri Ã§erÃ§evesinde depolayacaÄŸÄ±z.

### VektÃ¶r BenzerliÄŸi

EriÅŸimci, bilgi veritabanÄ±nda yakÄ±n olan gÃ¶mmeleri arar; en yakÄ±n komÅŸu, Ã§Ã¼nkÃ¼ metinler benzerdir. Bir kullanÄ±cÄ± sorgu sorduÄŸunda, Ã¶ncelikle gÃ¶mÃ¼lÃ¼r ve ardÄ±ndan benzer gÃ¶mmelerle eÅŸleÅŸtirilir. FarklÄ± vektÃ¶rlerin ne kadar benzer olduÄŸunu Ã¶lÃ§mek iÃ§in yaygÄ±n kullanÄ±lan Ã¶lÃ§Ã¼m, iki vektÃ¶r arasÄ±ndaki aÃ§Ä±ya gÃ¶re hesaplanan kosinÃ¼s benzerliÄŸidir.

BenzerliÄŸi Ã¶lÃ§mek iÃ§in kullanÄ±labilecek diÄŸer alternatifler, vektÃ¶r uÃ§ noktalarÄ± arasÄ±ndaki doÄŸru Ã§izgi olan Ã–klid uzaklÄ±ÄŸÄ± ve iki vektÃ¶rÃ¼n karÅŸÄ±lÄ±k gelen elemanlarÄ±nÄ±n Ã§arpÄ±mlarÄ±nÄ±n toplamÄ±nÄ± Ã¶lÃ§en nokta Ã§arpÄ±mÄ±dÄ±r.

### Arama dizini

EriÅŸim yaparken, arama gerÃ§ekleÅŸtirmeden Ã¶nce bilgi tabanÄ±mÄ±z iÃ§in bir arama dizini oluÅŸturmalÄ±yÄ±z. Dizinimiz gÃ¶mmelerimizi depolar ve bÃ¼yÃ¼k bir veritabanÄ±nda bile en benzer parÃ§alarÄ± hÄ±zlÄ±ca geri getirebilir. Dizini yerel olarak ÅŸÃ¶yle oluÅŸturabiliriz:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Arama indeksini oluÅŸturun
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# Ä°ndeksi sorgulamak iÃ§in kneighbors metodunu kullanabilirsiniz
distances, indices = nbrs.kneighbors(embeddings)
```

### Yeniden sÄ±ralama

VeritabanÄ±nÄ± sorguladÄ±ktan sonra, sonuÃ§larÄ± en uygun olandan baÅŸlayarak sÄ±ralamanÄ±z gerekebilir. Yeniden sÄ±ralama LLM'si, makine Ã¶ÄŸrenimi kullanarak arama sonuÃ§larÄ±nÄ±n uygunluÄŸunu artÄ±rÄ±r ve onlarÄ± en alakalÄ±dan itibaren sÄ±ralar. Azure AI Search kullanÄ±lÄ±rken, yeniden sÄ±ralama semantik bir yeniden sÄ±ralayÄ±cÄ± ile otomatik olarak yapÄ±lÄ±r. En yakÄ±n komÅŸularÄ± kullanarak yeniden sÄ±ralamanÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na bir Ã¶rnek:

```python
# En benzer belgeleri bulun
distances, indices = nbrs.kneighbors([query_vector])

index = []
# En benzer belgeleri yazdÄ±rÄ±n
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Hepsini bir araya getirmek

Son adÄ±m, verilerimize dayalÄ± yanÄ±tlar alabilmek iÃ§in LLM'imizi karÄ±ÅŸÄ±ma eklemektir. Bunu ÅŸÃ¶yle uygulayabiliriz:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Soruyu bir sorgu vektÃ¶rÃ¼ne dÃ¶nÃ¼ÅŸtÃ¼r
    query_vector = create_embeddings(user_input)

    # En benzer belgeleri bul
    distances, indices = nbrs.kneighbors([query_vector])

    # BaÄŸlam saÄŸlamak iÃ§in belgelere sorgu ekle
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # GeÃ§miÅŸi ve kullanÄ±cÄ± girdisini birleÅŸtir
    history.append(user_input)

    # Bir mesaj nesnesi oluÅŸtur
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # YanÄ±t oluÅŸturmak iÃ§in sohbet tamamlamasÄ±nÄ± kullan
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## UygulamamÄ±zÄ± deÄŸerlendirmek

### DeÄŸerlendirme Ã–lÃ§Ã¼tleri

- SaÄŸlanan yanÄ±tlarÄ±n kalitesi: doÄŸal, akÄ±cÄ± ve insan benzeri olmasÄ±

- Verilerin dayandÄ±rÄ±lmÄ±ÅŸlÄ±ÄŸÄ±: yanÄ±tÄ±n saÄŸlanan belgelerden gelip gelmediÄŸinin deÄŸerlendirilmesi

- Uygunluk: yanÄ±tÄ±n soruyla eÅŸleÅŸip iliÅŸkili olmasÄ±

- AkÄ±cÄ±lÄ±k: yanÄ±tÄ±n dilbilgisel olarak mantÄ±klÄ± olup olmadÄ±ÄŸÄ±

## RAG (Retrieval Augmented Generation) ve vektÃ¶r veritabanlarÄ± kullanÄ±m durumlarÄ±

Fonksiyon Ã§aÄŸrÄ±larÄ± uygulamanÄ±zÄ± iyileÅŸtirebileceÄŸi birÃ§ok farklÄ± kullanÄ±m durumu vardÄ±r, Ã¶rneÄŸin:

- Soru ve Cevaplama: ÅŸirket verilerinizi Ã§alÄ±ÅŸanlarÄ±n soru sormak iÃ§in kullanabileceÄŸi bir sohbete dayandÄ±rmak.

- Ã–neri Sistemleri: en benzer deÄŸerleri eÅŸleÅŸtiren sistemler oluÅŸturmak, Ã¶rneÄŸin film, restoran ve daha fazlasÄ±.

- Sohbet botu hizmetleri: sohbet geÃ§miÅŸini depolayabilir ve kullanÄ±cÄ± verilerine gÃ¶re kiÅŸiselleÅŸtirilmiÅŸ konuÅŸma saÄŸlayabilirsiniz.

- VektÃ¶r gÃ¶mmelerine dayalÄ± gÃ¶rsel arama, gÃ¶rsel tanÄ±ma ve anomali tespitinde faydalÄ±dÄ±r.

## Ã–zet

RAG'Ä±n temel alanlarÄ±nÄ±, verilerimizin uygulamaya eklenmesinden kullanÄ±cÄ± sorgularÄ±na ve Ã§Ä±ktÄ±ya kadar ele aldÄ±k. RAG oluÅŸturmayÄ± kolaylaÅŸtÄ±rmak iÃ§in Semanti Kernel, Langchain veya Autogen gibi Ã§erÃ§eveleri kullanabilirsiniz.

## Ã–dev

Retrieval Augmented Generation (RAG) Ã¶ÄŸreniminize devam etmek iÃ§in ÅŸunlarÄ± yapabilirsiniz:

- Tercih ettiÄŸiniz Ã§erÃ§eveyi kullanarak uygulama iÃ§in bir Ã¶n yÃ¼z oluÅŸturun

- LangChain veya Semantic Kernel gibi bir Ã§erÃ§eveyi kullanarak uygulamanÄ±zÄ± yeniden oluÅŸturun.

Dersi tamamladÄ±ÄŸÄ±nÄ±z iÃ§in tebrikler ğŸ‘.

## Ã–ÄŸrenme burada bitmiyor, yolculuÄŸa devam edin

Bu dersi tamamladÄ±ktan sonra, [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) koleksiyonumuzu inceleyerek Ãœretken Yapay Zeka bilginizi geliÅŸtirmeye devam edin!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶sterilse de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±nÄ±z. Orijinal belge, ana dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucunda ortaya Ã§Ä±kabilecek yanlÄ±ÅŸ anlamalar veya yorum hatalarÄ±ndan sorumlu deÄŸiliz.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->