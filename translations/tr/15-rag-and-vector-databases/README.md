<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-05-20T01:17:08+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "tr"
}
-->
# Geri Alma Destekli Ãœretim (RAG) ve VektÃ¶r VeritabanlarÄ±

[![Geri Alma Destekli Ãœretim (RAG) ve VektÃ¶r VeritabanlarÄ±](../../../translated_images/15-lesson-banner.799d0cd2229970edb365f6667a4c7b3a0f526eb8698baa7d2e05c3bd49a5d83f.tr.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

Arama uygulamalarÄ± dersinde, kendi verilerinizi BÃ¼yÃ¼k Dil Modellerine (LLM'ler) nasÄ±l entegre edeceÄŸimizi kÄ±saca Ã¶ÄŸrendik. Bu derste, verilerinizi LLM uygulamanÄ±za nasÄ±l dayandÄ±racaÄŸÄ±nÄ±zÄ±, sÃ¼recin mekaniklerini ve verileri saklama yÃ¶ntemlerini, hem gÃ¶mme hem de metin dahil olmak Ã¼zere, daha ayrÄ±ntÄ±lÄ± olarak inceleyeceÄŸiz.

> **Video Ã‡ok YakÄ±nda**

## GiriÅŸ

Bu derste ÅŸunlarÄ± ele alacaÄŸÄ±z:

- RAG'e giriÅŸ, nedir ve neden AI (yapay zeka) alanÄ±nda kullanÄ±lÄ±r.

- VektÃ¶r veritabanlarÄ±nÄ±n ne olduÄŸunu anlamak ve uygulamamÄ±z iÃ§in bir tane oluÅŸturmak.

- RAG'i bir uygulamaya nasÄ±l entegre edeceÄŸimize dair pratik bir Ã¶rnek.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra ÅŸunlarÄ± yapabileceksiniz:

- RAG'in veri alma ve iÅŸleme aÃ§Ä±sÄ±ndan Ã¶nemini aÃ§Ä±klamak.

- RAG uygulamasÄ±nÄ± kurmak ve verilerinizi bir LLM'ye dayandÄ±rmak.

- LLM UygulamalarÄ±nda RAG ve VektÃ¶r VeritabanlarÄ±nÄ±n etkili entegrasyonu.

## Senaryomuz: Kendi verilerimizle LLM'lerimizi geliÅŸtirmek

Bu ders iÃ§in, eÄŸitim giriÅŸimine kendi notlarÄ±mÄ±zÄ± eklemek istiyoruz, bu da sohbet botunun farklÄ± konular hakkÄ±nda daha fazla bilgi edinmesini saÄŸlar. Sahip olduÄŸumuz notlarÄ± kullanarak, Ã¶ÄŸrenenler daha iyi Ã§alÄ±ÅŸabilecek ve farklÄ± konularÄ± anlayabilecek, bu da sÄ±navlarÄ±na hazÄ±rlanmayÄ± kolaylaÅŸtÄ±racaktÄ±r. Senaryomuzu oluÅŸturmak iÃ§in ÅŸunlarÄ± kullanacaÄŸÄ±z:

- `Azure OpenAI:` sohbet botumuzu oluÅŸturmak iÃ§in kullanacaÄŸÄ±mÄ±z LLM

- `AI for beginners' lesson on Neural Networks`: LLM'mizi dayandÄ±racaÄŸÄ±mÄ±z veri bu olacak

- `Azure AI Search` ve `Azure Cosmos DB:` veritabanÄ± verilerimizi saklamak ve bir arama dizini oluÅŸturmak iÃ§in

KullanÄ±cÄ±lar notlarÄ±ndan pratik sÄ±navlar oluÅŸturabilecek, revizyon kartlarÄ± hazÄ±rlayabilecek ve bunlarÄ± kÄ±sa Ã¶zetlere dÃ¶nÃ¼ÅŸtÃ¼rebilecekler. BaÅŸlamak iÃ§in, RAG'in ne olduÄŸunu ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± inceleyelim:

## Geri Alma Destekli Ãœretim (RAG)

Bir LLM destekli sohbet botu, kullanÄ±cÄ± isteklerini iÅŸleyerek yanÄ±tlar Ã¼retir. EtkileÅŸimli olacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r ve kullanÄ±cÄ±larla geniÅŸ bir konu yelpazesinde etkileÅŸime girer. Ancak, yanÄ±tlarÄ± saÄŸlanan baÄŸlam ve temel eÄŸitim verileriyle sÄ±nÄ±rlÄ±dÄ±r. Ã–rneÄŸin, GPT-4'Ã¼n bilgi kesim noktasÄ± EylÃ¼l 2021'dir, bu da bu tarihten sonra meydana gelen olaylar hakkÄ±nda bilgi sahibi olmadÄ±ÄŸÄ± anlamÄ±na gelir. AyrÄ±ca, LLM'leri eÄŸitmek iÃ§in kullanÄ±lan veriler, kiÅŸisel notlar veya bir ÅŸirketin Ã¼rÃ¼n kÄ±lavuzu gibi gizli bilgileri iÃ§ermez.

### RAG'ler (Geri Alma Destekli Ãœretim) nasÄ±l Ã§alÄ±ÅŸÄ±r

![RAG'lerin nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶steren Ã§izim](../../../translated_images/how-rag-works.d87a7ed9c30f43126bb9e8e259be5d66e16cd1fef65374e6914746ba9bfb0b2f.tr.png)

Diyelim ki notlarÄ±nÄ±zdan sÄ±navlar oluÅŸturan bir sohbet botu daÄŸÄ±tmak istiyorsunuz, bilgi tabanÄ±na bir baÄŸlantÄ± gerekecektir. Ä°ÅŸte burada RAG devreye girer. RAG'ler ÅŸu ÅŸekilde Ã§alÄ±ÅŸÄ±r:

- **Bilgi tabanÄ±:** Geri almadan Ã¶nce, bu belgelerin alÄ±nmasÄ± ve Ã¶n iÅŸleme tabi tutulmasÄ± gerekir, genellikle bÃ¼yÃ¼k belgeleri daha kÃ¼Ã§Ã¼k parÃ§alara ayÄ±rarak, metin gÃ¶mme dÃ¶nÃ¼ÅŸtÃ¼rerek ve bir veritabanÄ±nda saklayarak.

- **KullanÄ±cÄ± Sorgusu:** KullanÄ±cÄ± bir soru sorar.

- **Geri Alma:** KullanÄ±cÄ± bir soru sorduÄŸunda, gÃ¶mme modeli bilgi tabanÄ±mÄ±zdan ilgili bilgileri alarak isteme dahil edilecek daha fazla baÄŸlam saÄŸlar.

- **Destekli Ãœretim:** LLM, alÄ±nan verilere dayanarak yanÄ±tÄ±nÄ± geliÅŸtirir. Bu, Ã¼retilen yanÄ±tÄ±n yalnÄ±zca Ã¶nceden eÄŸitilmiÅŸ verilere deÄŸil, aynÄ± zamanda ek baÄŸlamdan gelen ilgili bilgilere de dayanmasÄ±nÄ± saÄŸlar. AlÄ±nan veriler, LLM'nin yanÄ±tlarÄ±nÄ± desteklemek iÃ§in kullanÄ±lÄ±r. LLM daha sonra kullanÄ±cÄ±nÄ±n sorusuna bir yanÄ±t dÃ¶ndÃ¼rÃ¼r.

![RAG'lerin mimarisini gÃ¶steren Ã§izim](../../../translated_images/encoder-decode.75eebc7093ccefec17568eebc80d3d0b831ecf2ea204566377a04c77a5a57ebb.tr.png)

RAG'lerin mimarisi, bir kodlayÄ±cÄ± ve bir kod Ã§Ã¶zÃ¼cÃ¼den oluÅŸan dÃ¶nÃ¼ÅŸtÃ¼rÃ¼cÃ¼ler kullanÄ±larak uygulanÄ±r. Ã–rneÄŸin, bir kullanÄ±cÄ± bir soru sorduÄŸunda, giriÅŸ metni kelimelerin anlamÄ±nÄ± yakalayan vektÃ¶rlere 'kodlanÄ±r' ve vektÃ¶rler belge dizinimize 'kod Ã§Ã¶zÃ¼lÃ¼r' ve kullanÄ±cÄ± sorgusuna dayalÄ± yeni metin oluÅŸturur. LLM, Ã§Ä±ktÄ±yÄ± oluÅŸturmak iÃ§in hem bir kodlayÄ±cÄ±-kod Ã§Ã¶zÃ¼cÃ¼ modelini kullanÄ±r.

Ã–nerilen makaleye gÃ¶re RAG'i uygularken iki yaklaÅŸÄ±m: [Bilgi YoÄŸun NLP (doÄŸal dil iÅŸleme yazÄ±lÄ±mÄ±) GÃ¶revleri iÃ§in Geri Alma Destekli Ãœretim](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) ÅŸunlardÄ±r:

- **_RAG-Dizi_** kullanÄ±cÄ± sorgusuna en iyi olasÄ± yanÄ±tÄ± tahmin etmek iÃ§in alÄ±nan belgeleri kullanarak

- **RAG-Token** belgeleri kullanarak bir sonraki tokeni oluÅŸturmak, ardÄ±ndan bunlarÄ± kullanÄ±cÄ±nÄ±n sorgusuna yanÄ±t vermek iÃ§in almak

### Neden RAG'leri kullanmalÄ±sÄ±nÄ±z?

- **Bilgi zenginliÄŸi:** metin yanÄ±tlarÄ±nÄ±n gÃ¼ncel ve gÃ¼ncel olmasÄ±nÄ± saÄŸlar. Bu nedenle, iÃ§ bilgi tabanÄ±na eriÅŸerek alan Ã¶zel gÃ¶revlerde performansÄ± artÄ±rÄ±r.

- KullanÄ±cÄ± sorgularÄ±na baÄŸlam saÄŸlamak iÃ§in bilgi tabanÄ±ndaki **doÄŸrulanabilir verileri** kullanarak uydurmayÄ± azaltÄ±r.

- Bir LLM'yi ince ayarlamaya gÃ¶re daha ekonomik olduklarÄ± iÃ§in **maliyet etkilidir**.

## Bilgi tabanÄ± oluÅŸturma

UygulamamÄ±z, AI For Beginners mÃ¼fredatÄ±ndaki Sinir AÄŸÄ± dersi olan kiÅŸisel verilerimize dayanmaktadÄ±r.

### VektÃ¶r VeritabanlarÄ±

VektÃ¶r veritabanÄ±, geleneksel veritabanlarÄ±ndan farklÄ± olarak, gÃ¶mÃ¼lÃ¼ vektÃ¶rleri depolamak, yÃ¶netmek ve aramak iÃ§in tasarlanmÄ±ÅŸ Ã¶zel bir veritabanÄ±dÄ±r. Belgelerin sayÄ±sal temsillerini depolar. Verileri sayÄ±sal gÃ¶mmelere ayÄ±rmak, AI sistemimizin verileri anlamasÄ±nÄ± ve iÅŸlemesini kolaylaÅŸtÄ±rÄ±r.

GÃ¶mme verilerimizi vektÃ¶r veritabanlarÄ±nda saklÄ±yoruz Ã§Ã¼nkÃ¼ LLM'lerin giriÅŸ olarak kabul ettikleri belirteÃ§ sayÄ±sÄ±nda bir sÄ±nÄ±r vardÄ±r. TÃ¼m gÃ¶mmeleri bir LLM'ye geÃ§emeyeceÄŸiniz iÃ§in, onlarÄ± parÃ§alara ayÄ±rmamÄ±z gerekecek ve bir kullanÄ±cÄ± bir soru sorduÄŸunda, soruya en Ã§ok benzeyen gÃ¶mmeler istemle birlikte dÃ¶ndÃ¼rÃ¼lecektir. ParÃ§alama ayrÄ±ca bir LLM Ã¼zerinden geÃ§irilen belirteÃ§ sayÄ±sÄ±nda maliyetleri azaltÄ±r.

BazÄ± popÃ¼ler vektÃ¶r veritabanlarÄ± arasÄ±nda Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ve DeepLake bulunur. AÅŸaÄŸÄ±daki komutu kullanarak Azure CLI ile bir Azure Cosmos DB modeli oluÅŸturabilirsiniz:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Metinden gÃ¶mmelere

Verilerimizi saklamadan Ã¶nce, veritabanÄ±nda saklanmadan Ã¶nce vektÃ¶r gÃ¶mmelerine dÃ¶nÃ¼ÅŸtÃ¼rmemiz gerekecek. BÃ¼yÃ¼k belgeler veya uzun metinlerle Ã§alÄ±ÅŸÄ±yorsanÄ±z, beklediÄŸiniz sorgulara gÃ¶re parÃ§alayabilirsiniz. ParÃ§alama, cÃ¼mle dÃ¼zeyinde veya paragraf dÃ¼zeyinde yapÄ±labilir. ParÃ§alama, etraflarÄ±ndaki kelimelerden anlamlar Ã§Ä±kardÄ±ÄŸÄ± iÃ§in, bir parÃ§aya baÅŸka bir baÄŸlam ekleyebilirsiniz, Ã¶rneÄŸin, belge baÅŸlÄ±ÄŸÄ±nÄ± ekleyerek veya parÃ§anÄ±n Ã¶ncesine veya sonrasÄ±na biraz metin ekleyerek. Verileri ÅŸu ÅŸekilde parÃ§alayabilirsiniz:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Bir kez parÃ§alandÄ±ÄŸÄ±nda, metnimizi farklÄ± gÃ¶mme modelleri kullanarak gÃ¶mebiliriz. KullanabileceÄŸiniz bazÄ± modeller arasÄ±nda: word2vec, OpenAI tarafÄ±ndan ada-002, Azure Computer Vision ve daha birÃ§oklarÄ± bulunur. KullanÄ±lacak modeli seÃ§mek, kullandÄ±ÄŸÄ±nÄ±z dillere, kodlanan iÃ§eriÄŸin tÃ¼rÃ¼ne (metin/gÃ¶rÃ¼ntÃ¼/ses), kodlayabileceÄŸi giriÅŸ boyutuna ve gÃ¶mme Ã§Ä±ktÄ±sÄ±nÄ±n uzunluÄŸuna baÄŸlÄ± olacaktÄ±r.

OpenAI'nin `text-embedding-ada-002` modelini kullanarak gÃ¶mÃ¼lÃ¼ metin Ã¶rneÄŸi:
![kedi kelimesinin gÃ¶mÃ¼lmesi](../../../translated_images/cat.3db013cbca4fd5d90438ea7b312ad0364f7686cf79931ab15cd5922151aea53e.tr.png)

## Geri Alma ve VektÃ¶r Arama

Bir kullanÄ±cÄ± bir soru sorduÄŸunda, alÄ±cÄ± bunu sorgu kodlayÄ±cÄ± kullanarak bir vektÃ¶re dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r, ardÄ±ndan belgede giriÅŸle ilgili olan belgede ilgili vektÃ¶rleri aramak iÃ§in belge arama dizinimizde arama yapar. Ä°ÅŸlem tamamlandÄ±ÄŸÄ±nda, hem giriÅŸ vektÃ¶rÃ¼nÃ¼ hem de belge vektÃ¶rlerini metne dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r ve LLM Ã¼zerinden geÃ§irir.

### Geri Alma

Geri alma, sistemin arama kriterlerini karÅŸÄ±layan belgeleri hÄ±zla bulmaya Ã§alÄ±ÅŸtÄ±ÄŸÄ± zaman gerÃ§ekleÅŸir. AlÄ±cÄ±nÄ±n amacÄ±, LLM'yi verilerinizle dayandÄ±rmak ve baÄŸlam saÄŸlamak iÃ§in kullanÄ±lacak belgeleri elde etmektir.

VeritabanÄ±mÄ±zda arama yapmak iÃ§in birkaÃ§ yol vardÄ±r, Ã¶rneÄŸin:

- **Anahtar kelime aramasÄ±** - metin aramalarÄ± iÃ§in kullanÄ±lÄ±r

- **Anlamsal arama** - kelimelerin anlamsal anlamÄ±nÄ± kullanÄ±r

- **VektÃ¶r arama** - belgeleri gÃ¶mme modelleri kullanarak metinden vektÃ¶r temsillerine dÃ¶nÃ¼ÅŸtÃ¼rÃ¼r. Geri alma, kullanÄ±cÄ± sorusuna en yakÄ±n vektÃ¶r temsillerine sahip belgeleri sorgulayarak yapÄ±lacaktÄ±r.

- **Hibrit** - hem anahtar kelime hem de vektÃ¶r aramasÄ±nÄ±n bir kombinasyonu.

Geri alma ile ilgili bir zorluk, veritabanÄ±nda sorguya benzer bir yanÄ±t olmadÄ±ÄŸÄ±nda ortaya Ã§Ä±kar, sistem o zaman elde edebilecekleri en iyi bilgiyi dÃ¶ndÃ¼recektir, ancak, maksimum alaka mesafesini ayarlamak veya hem anahtar kelimeleri hem de vektÃ¶r aramayÄ± birleÅŸtiren hibrit aramayÄ± kullanmak gibi taktikler kullanabilirsiniz. Bu derste, hem vektÃ¶r hem de anahtar kelime aramasÄ±nÄ±n bir kombinasyonu olan hibrit aramayÄ± kullanacaÄŸÄ±z. Verilerimizi, parÃ§alara ve gÃ¶mmelere sahip sÃ¼tunlar iÃ§eren bir veri Ã§erÃ§evesine kaydedeceÄŸiz.

### VektÃ¶r BenzerliÄŸi

AlÄ±cÄ±, bilgi veritabanÄ±nda birbirine yakÄ±n olan gÃ¶mmeleri arayacak, en yakÄ±n komÅŸu, benzer metinler olduklarÄ±ndan. Bir kullanÄ±cÄ± bir sorgu sorduÄŸunda, Ã¶nce gÃ¶mÃ¼lÃ¼r ve ardÄ±ndan benzer gÃ¶mmelerle eÅŸleÅŸtirilir. FarklÄ± vektÃ¶rlerin ne kadar benzer olduÄŸunu bulmak iÃ§in kullanÄ±lan yaygÄ±n Ã¶lÃ§Ã¼m, iki vektÃ¶r arasÄ±ndaki aÃ§Ä±ya dayalÄ± olan kosinÃ¼s benzerliÄŸidir.

BenzerliÄŸi Ã¶lÃ§mek iÃ§in kullanabileceÄŸimiz diÄŸer alternatifler, vektÃ¶r uÃ§ noktalarÄ± arasÄ±ndaki doÄŸru Ã§izgi olan Ã–klid mesafesi ve iki vektÃ¶rÃ¼n karÅŸÄ±lÄ±k gelen elemanlarÄ±nÄ±n Ã§arpÄ±mlarÄ±nÄ±n toplamÄ±nÄ± Ã¶lÃ§en nokta Ã§arpÄ±mÄ±dÄ±r.

### Arama dizini

Geri alma yaparken, arama yapmadan Ã¶nce bilgi tabanÄ±mÄ±z iÃ§in bir arama dizini oluÅŸturmamÄ±z gerekecek. Bir dizin, gÃ¶mmelerimizi depolayacak ve bÃ¼yÃ¼k bir veritabanÄ±nda bile en benzer parÃ§alarÄ± hÄ±zla alabilecektir. Dizinimizi yerel olarak ÅŸu ÅŸekilde oluÅŸturabiliriz:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Yeniden sÄ±ralama

VeritabanÄ±nÄ± sorguladÄ±ktan sonra, en alakalÄ± olanlardan sonuÃ§larÄ± sÄ±ralamanÄ±z gerekebilir. Bir yeniden sÄ±ralama LLM, arama sonuÃ§larÄ±nÄ±n alaka dÃ¼zeyini en alakalÄ± olanlardan baÅŸlayarak sÄ±ralayarak iyileÅŸtirmek iÃ§in Makine Ã–ÄŸrenimini kullanÄ±r. Azure AI Arama'yÄ± kullanarak, yeniden sÄ±ralama sizin iÃ§in otomatik olarak yapÄ±lÄ±r. En yakÄ±n komÅŸularÄ± kullanarak yeniden sÄ±ralamanÄ±n nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±na bir Ã¶rnek:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Hepsini bir araya getirmek

Son adÄ±m, verilerimize dayalÄ± yanÄ±tlar alabilmek iÃ§in LLM'mizi karÄ±ÅŸÄ±ma eklemektir. Åu ÅŸekilde uygulayabiliriz:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## UygulamamÄ±zÄ± deÄŸerlendirme

### DeÄŸerlendirme Ã–lÃ§Ã¼tleri

- DoÄŸal, akÄ±cÄ± ve insan benzeri ses Ã§Ä±karan yanÄ±tlarÄ±n kalitesi

- SaÄŸlanan belgelerden gelen yanÄ±tÄ±n deÄŸerlendirilmesi

- YanÄ±tÄ±n sorulan soruyla eÅŸleÅŸip eÅŸleÅŸmediÄŸinin ve ilgili olup olmadÄ±ÄŸÄ±nÄ±n deÄŸerlendirilmesi

- YanÄ±tÄ±n dilbilgisel olarak mantÄ±klÄ± olup olmadÄ±ÄŸÄ±

## RAG (Geri Alma Destekli Ãœretim) ve vektÃ¶r veritabanlarÄ± kullanÄ±mÄ± iÃ§in kullanÄ±m durumlarÄ±

Fonksiyon Ã§aÄŸrÄ±larÄ±nÄ±n uygulamanÄ±zÄ± geliÅŸtirebileceÄŸi birÃ§ok farklÄ± kullanÄ±m durumu vardÄ±r, Ã¶rneÄŸin:

- Soru ve Cevaplama: ÅŸirket verilerinizi bir sohbete dayandÄ±rarak Ã§alÄ±ÅŸanlarÄ±n soru sormasÄ± iÃ§in kullanÄ±labilir.

- Ã–neri Sistemleri: en benzer deÄŸerleri eÅŸleÅŸtiren bir sistem oluÅŸturabileceÄŸiniz yerler, Ã¶rneÄŸin filmler, restoranlar ve daha fazlasÄ±.

- Sohbet botu hizmetleri: sohbet geÃ§miÅŸini saklayabilir ve kullanÄ±cÄ± verilerine dayalÄ± olarak konuÅŸmayÄ± kiÅŸiselleÅŸtirebilirsiniz.

- VektÃ¶r gÃ¶mmelerine dayalÄ± gÃ¶rÃ¼ntÃ¼ aramasÄ±, gÃ¶rÃ¼ntÃ¼ tanÄ±ma ve anomali tespiti yaparken faydalÄ±dÄ±r.

## Ã–zet

RAG'in temel alanlarÄ±nÄ±, verilerimizi uygulamaya eklemekten kullanÄ±cÄ± sorgusuna ve Ã§Ä±ktÄ±ya kadar ele aldÄ±k. RAG oluÅŸturmayÄ± basitleÅŸtirmek iÃ§in Semanti Kernel, Langchain veya Autogen gibi Ã§erÃ§eveler kullanabilirsiniz.

## Ã–dev

Geri Alma Destekli Ãœretim (RAG) Ã¶ÄŸreniminize devam etmek iÃ§in ÅŸunlarÄ± yapabilirsiniz:

- SeÃ§tiÄŸiniz Ã§erÃ§eveyi kullanarak uygulama iÃ§in bir Ã¶n yÃ¼z oluÅŸturun.

- Bir Ã§erÃ§eve, ya LangChain ya da Semantik Kernel kullanarak uygulamanÄ±zÄ± yeniden oluÅŸturun.

Dersi tamamladÄ±ÄŸÄ±nÄ±z iÃ§in tebrikler ğŸ‘.

## Ã–ÄŸrenme burada bitmez, YolculuÄŸa devam edin

Bu dersi tamamladÄ±ktan sonra, Generatif AI bilginizi geliÅŸtirmeye devam etmek iÃ§in [Generatif AI Ã–ÄŸrenme koleksiyonumuzu](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) inceleyin!

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶stersek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belgenin kendi dilindeki hali yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlama veya yanlÄ±ÅŸ yorumlamalardan dolayÄ± sorumluluk kabul etmiyoruz.