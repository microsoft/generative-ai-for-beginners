<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-05-20T01:58:17+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "tr"
}
-->
# Sinir AÄŸÄ± Ã‡erÃ§eveleri

Daha Ã¶nce Ã¶ÄŸrendiÄŸimiz gibi, sinir aÄŸlarÄ±nÄ± verimli bir ÅŸekilde eÄŸitebilmek iÃ§in iki ÅŸey yapmamÄ±z gerekiyor:

* TensÃ¶rler Ã¼zerinde iÅŸlem yapmak, Ã¶rneÄŸin Ã§arpma, toplama ve sigmoid veya softmax gibi bazÄ± fonksiyonlarÄ± hesaplamak
* TÃ¼m ifadelerin gradyanlarÄ±nÄ± hesaplamak, bÃ¶ylece gradyan iniÅŸ optimizasyonu gerÃ§ekleÅŸtirebilmek

`numpy` kÃ¼tÃ¼phanesi ilk kÄ±smÄ± yapabilirken, gradyanlarÄ± hesaplamak iÃ§in bir mekanizmaya ihtiyacÄ±mÄ±z var. Ã–nceki bÃ¶lÃ¼mde geliÅŸtirdiÄŸimiz Ã§erÃ§evede, `backward` metodunun iÃ§inde tÃ¼m tÃ¼rev fonksiyonlarÄ± manuel olarak programlamamÄ±z gerekiyordu, bu yÃ¶ntem geri yayÄ±lÄ±m yapar. Ä°deal olarak, bir Ã§erÃ§eve bize tanÄ±mlayabileceÄŸimiz *herhangi bir ifadenin* gradyanlarÄ±nÄ± hesaplama fÄ±rsatÄ± vermelidir.

BaÅŸka bir Ã¶nemli nokta, GPU veya TPU gibi Ã¶zel hesaplama birimleri Ã¼zerinde hesaplamalar yapabilmektir. Derin sinir aÄŸÄ± eÄŸitimi *Ã§ok fazla* hesaplama gerektirir ve bu hesaplamalarÄ± GPU'larda paralelleÅŸtirebilmek Ã§ok Ã¶nemlidir.

> âœ… 'ParalelleÅŸtirme' terimi, hesaplamalarÄ± birden fazla cihaz Ã¼zerinde daÄŸÄ±tmak anlamÄ±na gelir.

Åu anda en popÃ¼ler iki sinir Ã§erÃ§evesi: TensorFlow ve PyTorch. Her ikisi de hem CPU hem de GPU Ã¼zerinde tensÃ¶rlerle Ã§alÄ±ÅŸmak iÃ§in dÃ¼ÅŸÃ¼k seviyeli bir API saÄŸlar. DÃ¼ÅŸÃ¼k seviyeli API'nin Ã¼zerinde, sÄ±rasÄ±yla Keras ve PyTorch Lightning olarak adlandÄ±rÄ±lan daha yÃ¼ksek seviyeli bir API bulunmaktadÄ±r.

DÃ¼ÅŸÃ¼k Seviyeli API | TensorFlow| PyTorch
--------------|-------------------------------------|--------------------------------
YÃ¼ksek Seviyeli API| Keras| Pytorch

Her iki Ã§erÃ§evedeki **dÃ¼ÅŸÃ¼k seviyeli API'ler** size **hesaplama grafikleri** oluÅŸturma imkanÄ± tanÄ±r. Bu grafik, verilen giriÅŸ parametreleriyle Ã§Ä±ktÄ±nÄ±n (genellikle kayÄ±p fonksiyonu) nasÄ±l hesaplanacaÄŸÄ±nÄ± tanÄ±mlar ve eÄŸer varsa GPU'da hesaplama iÃ§in gÃ¶nderilebilir. Bu hesaplama grafiÄŸini farklÄ±laÅŸtÄ±rmak ve gradyanlarÄ± hesaplamak iÃ§in fonksiyonlar vardÄ±r, bunlar daha sonra model parametrelerini optimize etmek iÃ§in kullanÄ±labilir.

**YÃ¼ksek seviyeli API'ler**, sinir aÄŸlarÄ±nÄ± genellikle **katmanlar dizisi** olarak ele alÄ±r ve Ã§oÄŸu sinir aÄŸÄ±nÄ± oluÅŸturmayÄ± Ã§ok daha kolay hale getirir. Modeli eÄŸitmek genellikle veriyi hazÄ±rlamayÄ± ve ardÄ±ndan iÅŸi yapmak iÃ§in `fit` fonksiyonunu Ã§aÄŸÄ±rmayÄ± gerektirir.

YÃ¼ksek seviyeli API, tipik sinir aÄŸlarÄ±nÄ± Ã§ok hÄ±zlÄ± bir ÅŸekilde oluÅŸturmanÄ±za olanak tanÄ±r, birÃ§ok detayla uÄŸraÅŸmanÄ±za gerek kalmaz. AynÄ± zamanda, dÃ¼ÅŸÃ¼k seviyeli API, eÄŸitim sÃ¼reci Ã¼zerinde Ã§ok daha fazla kontrol saÄŸlar ve bu nedenle yeni sinir aÄŸÄ± mimarileriyle uÄŸraÅŸÄ±rken araÅŸtÄ±rmada Ã§okÃ§a kullanÄ±lÄ±r.

Her iki API'yi birlikte kullanabileceÄŸinizi anlamak da Ã¶nemlidir, Ã¶rneÄŸin kendi aÄŸ katmanÄ± mimarinizi dÃ¼ÅŸÃ¼k seviyeli API kullanarak geliÅŸtirebilir ve ardÄ±ndan yÃ¼ksek seviyeli API ile oluÅŸturulan ve eÄŸitilen daha bÃ¼yÃ¼k bir aÄŸ iÃ§inde kullanabilirsiniz. Ya da yÃ¼ksek seviyeli API kullanarak bir katman dizisi olarak bir aÄŸ tanÄ±mlayabilir ve ardÄ±ndan optimizasyon yapmak iÃ§in kendi dÃ¼ÅŸÃ¼k seviyeli eÄŸitim dÃ¶ngÃ¼nÃ¼zÃ¼ kullanabilirsiniz. Her iki API de aynÄ± temel kavramlarÄ± kullanÄ±r ve birlikte iyi Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

## Ã–ÄŸrenme

Bu derste, PyTorch ve TensorFlow iÃ§in Ã§oÄŸu iÃ§eriÄŸi sunuyoruz. Tercih ettiÄŸiniz Ã§erÃ§eveyi seÃ§ebilir ve yalnÄ±zca ilgili defterleri inceleyebilirsiniz. Hangi Ã§erÃ§eveyi seÃ§eceÄŸinizden emin deÄŸilseniz, **PyTorch vs. TensorFlow** ile ilgili internetteki bazÄ± tartÄ±ÅŸmalarÄ± okuyun. Daha iyi bir anlayÄ±ÅŸ kazanmak iÃ§in her iki Ã§erÃ§eveye de gÃ¶z atabilirsiniz.

MÃ¼mkÃ¼n olduÄŸunda, basitlik iÃ§in YÃ¼ksek Seviyeli API'leri kullanacaÄŸÄ±z. Ancak, sinir aÄŸlarÄ±nÄ±n temelden nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamanÄ±n Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yoruz, bu nedenle baÅŸlangÄ±Ã§ta dÃ¼ÅŸÃ¼k seviyeli API ve tensÃ¶rlerle Ã§alÄ±ÅŸarak baÅŸlÄ±yoruz. Ancak, hÄ±zlÄ± bir ÅŸekilde ilerlemek ve bu detaylarÄ± Ã¶ÄŸrenmek iÃ§in fazla zaman harcamak istemiyorsanÄ±z, bunlarÄ± atlayabilir ve doÄŸrudan yÃ¼ksek seviyeli API defterlerine geÃ§ebilirsiniz.

## âœï¸ Egzersizler: Ã‡erÃ§eveler

Ã–ÄŸrenmenizi aÅŸaÄŸÄ±daki defterlerde devam ettirin:

DÃ¼ÅŸÃ¼k Seviyeli API | TensorFlow+Keras Defteri | PyTorch
--------------|-------------------------------------|--------------------------------
YÃ¼ksek Seviyeli API| Keras | *PyTorch Lightning*

Ã‡erÃ§eveleri ustalÄ±kla Ã¶ÄŸrendikten sonra, aÅŸÄ±rÄ± uyum kavramÄ±nÄ± tekrar gÃ¶zden geÃ§irelim.

# AÅŸÄ±rÄ± Uyum

AÅŸÄ±rÄ± uyum, makine Ã¶ÄŸreniminde son derece Ã¶nemli bir kavramdÄ±r ve doÄŸru anlamak Ã§ok Ã¶nemlidir!

AÅŸaÄŸÄ±daki 5 noktayÄ± (grafiklerde `x` ile temsil edilen) yaklaÅŸÄ±k olarak belirleme sorununu dÃ¼ÅŸÃ¼nÃ¼n:

!doÄŸrusal | aÅŸÄ±rÄ± uyum
-------------------------|--------------------------
**DoÄŸrusal model, 2 parametre** | **DoÄŸrusal olmayan model, 7 parametre**
EÄŸitim hatasÄ± = 5.3 | EÄŸitim hatasÄ± = 0
DoÄŸrulama hatasÄ± = 5.1 | DoÄŸrulama hatasÄ± = 20

* Solda, iyi bir doÄŸru Ã§izgisi yaklaÅŸÄ±mÄ± gÃ¶rÃ¼yoruz. Parametre sayÄ±sÄ± uygun olduÄŸu iÃ§in model, nokta daÄŸÄ±lÄ±mÄ±nÄ±n arkasÄ±ndaki fikri doÄŸru anlÄ±yor.
* SaÄŸda, model Ã§ok gÃ¼Ã§lÃ¼. Sadece 5 noktamÄ±z var ve modelin 7 parametresi olduÄŸu iÃ§in, tÃ¼m noktalardan geÃ§ecek ÅŸekilde ayarlanabiliyor, bÃ¶ylece eÄŸitim hatasÄ± 0 oluyor. Ancak, bu modelin verilerin arkasÄ±ndaki doÄŸru modeli anlamasÄ±nÄ± engelliyor, bu nedenle doÄŸrulama hatasÄ± Ã§ok yÃ¼ksek.

Modelin zenginliÄŸi (parametre sayÄ±sÄ±) ile eÄŸitim Ã¶rnekleri sayÄ±sÄ± arasÄ±nda doÄŸru dengeyi kurmak Ã§ok Ã¶nemlidir.

## AÅŸÄ±rÄ± Uyum Neden OluÅŸur?

  * Yeterli eÄŸitim verisi yok
  * Ã‡ok gÃ¼Ã§lÃ¼ model
  * GiriÅŸ verilerinde Ã§ok fazla gÃ¼rÃ¼ltÃ¼

## AÅŸÄ±rÄ± Uyumu NasÄ±l Tespit Edilir?

YukarÄ±daki grafikten gÃ¶rebileceÄŸiniz gibi, aÅŸÄ±rÄ± uyum Ã§ok dÃ¼ÅŸÃ¼k eÄŸitim hatasÄ± ve yÃ¼ksek doÄŸrulama hatasÄ± ile tespit edilebilir. Normalde eÄŸitim sÄ±rasÄ±nda hem eÄŸitim hem de doÄŸrulama hatalarÄ±nÄ±n azalmaya baÅŸladÄ±ÄŸÄ±nÄ± gÃ¶rÃ¼rÃ¼z ve sonra bir noktada doÄŸrulama hatasÄ± azalmayÄ± durdurabilir ve yÃ¼kselmeye baÅŸlayabilir. Bu aÅŸÄ±rÄ± uyumun bir iÅŸareti olacak ve bu noktada eÄŸitimi durdurmamÄ±z gerektiÄŸinin bir gÃ¶stergesi olacak (veya en azÄ±ndan modelin bir anlÄ±k gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ almamÄ±z gerektiÄŸi).

## AÅŸÄ±rÄ± Uyumu NasÄ±l Ã–nleyebiliriz?

AÅŸÄ±rÄ± uyumun meydana geldiÄŸini gÃ¶rÃ¼yorsanÄ±z, aÅŸaÄŸÄ±dakilerden birini yapabilirsiniz:

 * EÄŸitim verilerinin miktarÄ±nÄ± artÄ±rÄ±n
 * Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltÄ±n
 * Daha sonra ele alacaÄŸÄ±mÄ±z Dropout gibi bir dÃ¼zenleme tekniÄŸi kullanÄ±n.

## AÅŸÄ±rÄ± Uyum ve YanlÄ±lÄ±k-Ã‡eÅŸitlilik Dengesi

AÅŸÄ±rÄ± uyum, aslÄ±nda istatistiklerde YanlÄ±lÄ±k-Ã‡eÅŸitlilik Dengesi olarak adlandÄ±rÄ±lan daha genel bir problemin bir Ã¶rneÄŸidir. Modelimizdeki olasÄ± hata kaynaklarÄ±nÄ± dÃ¼ÅŸÃ¼nÃ¼rsek, iki tÃ¼r hata gÃ¶rebiliriz:

* **YanlÄ±lÄ±k hatalarÄ±**, algoritmamÄ±zÄ±n eÄŸitim verileri arasÄ±ndaki iliÅŸkiyi doÄŸru bir ÅŸekilde yakalayamamasÄ±ndan kaynaklanÄ±r. Modelimizin yeterince gÃ¼Ã§lÃ¼ olmamasÄ±ndan kaynaklanabilir (**eksik uyum**).
* **Ã‡eÅŸitlilik hatalarÄ±**, modelin giriÅŸ verilerindeki gÃ¼rÃ¼ltÃ¼yÃ¼ anlamlÄ± iliÅŸki yerine yakalamaya Ã§alÄ±ÅŸmasÄ±ndan kaynaklanÄ±r (**aÅŸÄ±rÄ± uyum**).

EÄŸitim sÄ±rasÄ±nda, yanlÄ±lÄ±k hatasÄ± azalÄ±r (modelimiz verileri yaklaÅŸÄ±k olarak Ã¶ÄŸrenirken) ve Ã§eÅŸitlilik hatasÄ± artar. AÅŸÄ±rÄ± uyumu Ã¶nlemek iÃ§in eÄŸitimi durdurmak - ya manuel olarak (aÅŸÄ±rÄ± uyumu tespit ettiÄŸimizde) ya da otomatik olarak (dÃ¼zenleme getirerek) - Ã¶nemlidir.

## SonuÃ§

Bu derste, en popÃ¼ler iki AI Ã§erÃ§evesi olan TensorFlow ve PyTorch iÃ§in Ã§eÅŸitli API'ler arasÄ±ndaki farklarÄ± Ã¶ÄŸrendiniz. AyrÄ±ca, Ã§ok Ã¶nemli bir konu olan aÅŸÄ±rÄ± uyumu Ã¶ÄŸrendiniz.

## ğŸš€ Meydan Okuma

Ä°lgili defterlerde, 'gÃ¶revler' bÃ¶lÃ¼mÃ¼nde bulacaÄŸÄ±nÄ±z gÃ¶revleri tamamlayÄ±n; defterleri inceleyin ve gÃ¶revleri tamamlayÄ±n.

## Ä°nceleme ve Kendi Kendine Ã‡alÄ±ÅŸma

AÅŸaÄŸÄ±daki konular hakkÄ±nda biraz araÅŸtÄ±rma yapÄ±n:

- TensorFlow
- PyTorch
- AÅŸÄ±rÄ± Uyum

Kendinize ÅŸu sorularÄ± sorun:

- TensorFlow ve PyTorch arasÄ±ndaki fark nedir?
- AÅŸÄ±rÄ± uyum ve eksik uyum arasÄ±ndaki fark nedir?

## Ã–dev

Bu laboratuvarda, PyTorch veya TensorFlow kullanarak tek ve Ã§ok katmanlÄ± tam baÄŸlantÄ±lÄ± aÄŸlar kullanarak iki sÄ±nÄ±flandÄ±rma problemini Ã§Ã¶zmeniz isteniyor.

**Feragatname**:  
Bu belge, AI Ã§eviri hizmeti [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba sarf etsek de, otomatik Ã§evirilerin hata veya yanlÄ±ÅŸlÄ±k iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±n. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ±ndan kaynaklanan yanlÄ±ÅŸ anlamalar veya yanlÄ±ÅŸ yorumlamalardan sorumlu deÄŸiliz.