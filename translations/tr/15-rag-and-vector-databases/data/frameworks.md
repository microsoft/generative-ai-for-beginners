<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:31:36+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "tr"
}
-->
# Sinir AÄŸÄ± Ã‡erÃ§eveleri

Zaten Ã¶ÄŸrendiÄŸimiz gibi, sinir aÄŸlarÄ±nÄ± verimli bir ÅŸekilde eÄŸitebilmek iÃ§in iki ÅŸey yapmamÄ±z gerekiyor:

* TensÃ¶rler Ã¼zerinde iÅŸlem yapmak, Ã¶rneÄŸin Ã§arpmak, toplamak ve sigmoid veya softmax gibi bazÄ± fonksiyonlarÄ± hesaplamak
* TÃ¼m ifadelerin gradyanlarÄ±nÄ± hesaplamak, bÃ¶ylece gradyan iniÅŸi optimizasyonu yapabilmek

`numpy` kÃ¼tÃ¼phanesi ilk kÄ±smÄ± yapabilirken, gradyanlarÄ± hesaplamak iÃ§in bir mekanizmaya ihtiyacÄ±mÄ±z var. Ã–nceki bÃ¶lÃ¼mde geliÅŸtirdiÄŸimiz Ã§erÃ§evede, geri yayÄ±lÄ±m yapan `backward` metodunun iÃ§inde tÃ¼m tÃ¼rev fonksiyonlarÄ±nÄ± manuel olarak programlamak zorundaydÄ±k. Ä°deal olarak, bir Ã§erÃ§eve bize tanÄ±mlayabileceÄŸimiz *herhangi bir ifadenin* gradyanlarÄ±nÄ± hesaplama imkanÄ± vermelidir.

Bir diÄŸer Ã¶nemli konu ise GPU veya TPU gibi Ã¶zel hesaplama birimleri Ã¼zerinde iÅŸlem yapabilmektir. Derin sinir aÄŸÄ± eÄŸitimi *Ã§ok fazla* hesaplama gerektirir ve bu hesaplamalarÄ± GPUâ€™larda paralel olarak yapabilmek Ã§ok Ã¶nemlidir.

> âœ… 'ParalelleÅŸtirmek' terimi, hesaplamalarÄ±n birden fazla cihaz arasÄ±nda daÄŸÄ±tÄ±lmasÄ± anlamÄ±na gelir.

Åu anda en popÃ¼ler iki sinir aÄŸÄ± Ã§erÃ§evesi TensorFlow ve PyTorchâ€™tur. Her ikisi de CPU ve GPU Ã¼zerinde tensÃ¶rlerle Ã§alÄ±ÅŸmak iÃ§in dÃ¼ÅŸÃ¼k seviyeli API saÄŸlar. DÃ¼ÅŸÃ¼k seviyeli APIâ€™nin Ã¼zerinde ise sÄ±rasÄ±yla Keras ve PyTorch Lightning adÄ±nda yÃ¼ksek seviyeli APIâ€™ler bulunur.

DÃ¼ÅŸÃ¼k Seviyeli API | TensorFlow | PyTorch
------------------|------------|---------
YÃ¼ksek Seviyeli API | Keras | PyTorch

Her iki Ã§erÃ§evedeki **dÃ¼ÅŸÃ¼k seviyeli APIâ€™ler**, sÃ¶zde **hesaplama grafikleri** oluÅŸturmanÄ±za olanak tanÄ±r. Bu grafik, verilen giriÅŸ parametreleriyle Ã§Ä±ktÄ±nÄ±n (genellikle kayÄ±p fonksiyonu) nasÄ±l hesaplanacaÄŸÄ±nÄ± tanÄ±mlar ve eÄŸer varsa GPUâ€™da hesaplama iÃ§in gÃ¶nderilebilir. Bu hesaplama grafiÄŸini tÃ¼rev alma ve gradyanlarÄ± hesaplama fonksiyonlarÄ± vardÄ±r; bu gradyanlar model parametrelerini optimize etmek iÃ§in kullanÄ±lÄ±r.

**YÃ¼ksek seviyeli APIâ€™ler** ise sinir aÄŸlarÄ±nÄ± Ã§oÄŸunlukla **katmanlar dizisi** olarak ele alÄ±r ve sinir aÄŸlarÄ±nÄ±n Ã§oÄŸunu Ã§ok daha kolay kurmanÄ±zÄ± saÄŸlar. Model eÄŸitimi genellikle veriyi hazÄ±rlamayÄ± ve ardÄ±ndan iÅŸi yapmak iÃ§in `fit` fonksiyonunu Ã§aÄŸÄ±rmayÄ± gerektirir.

YÃ¼ksek seviyeli API, tipik sinir aÄŸlarÄ±nÄ± Ã§ok hÄ±zlÄ± bir ÅŸekilde, birÃ§ok detayÄ± dÃ¼ÅŸÃ¼nmeden oluÅŸturmanÄ±za olanak tanÄ±r. AynÄ± zamanda dÃ¼ÅŸÃ¼k seviyeli API, eÄŸitim sÃ¼reci Ã¼zerinde Ã§ok daha fazla kontrol sunar ve bu yÃ¼zden yeni sinir aÄŸÄ± mimarileriyle uÄŸraÅŸÄ±rken araÅŸtÄ±rmalarda sÄ±kÃ§a kullanÄ±lÄ±r.

AyrÄ±ca her iki APIâ€™yi birlikte kullanabileceÄŸinizi anlamak Ã¶nemlidir; Ã¶rneÄŸin, dÃ¼ÅŸÃ¼k seviyeli API ile kendi aÄŸ katman mimarinizi geliÅŸtirebilir ve bunu yÃ¼ksek seviyeli API ile oluÅŸturulup eÄŸitilen daha bÃ¼yÃ¼k aÄŸ iÃ§inde kullanabilirsiniz. Ya da yÃ¼ksek seviyeli API ile katmanlar dizisi olarak bir aÄŸ tanÄ±mlayÄ±p, optimizasyonu gerÃ§ekleÅŸtirmek iÃ§in kendi dÃ¼ÅŸÃ¼k seviyeli eÄŸitim dÃ¶ngÃ¼nÃ¼zÃ¼ kullanabilirsiniz. Her iki API aynÄ± temel kavramlarÄ± kullanÄ±r ve birlikte iyi Ã§alÄ±ÅŸacak ÅŸekilde tasarlanmÄ±ÅŸtÄ±r.

## Ã–ÄŸrenme

Bu kursta, iÃ§eriÄŸin Ã§oÄŸunu hem PyTorch hem de TensorFlow iÃ§in sunuyoruz. Tercih ettiÄŸiniz Ã§erÃ§eveyi seÃ§ip sadece ilgili not defterlerini inceleyebilirsiniz. Hangi Ã§erÃ§eveyi seÃ§eceÄŸinizden emin deÄŸilseniz, internet Ã¼zerindeki **PyTorch vs. TensorFlow** tartÄ±ÅŸmalarÄ±nÄ± okuyabilirsiniz. AyrÄ±ca her iki Ã§erÃ§eveyi de inceleyerek daha iyi anlayabilirsiniz.

MÃ¼mkÃ¼n olduÄŸunda, basitlik iÃ§in YÃ¼ksek Seviyeli APIâ€™leri kullanacaÄŸÄ±z. Ancak sinir aÄŸlarÄ±nÄ±n temelden nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamanÄ±n Ã¶nemli olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼yoruz, bu yÃ¼zden baÅŸlangÄ±Ã§ta dÃ¼ÅŸÃ¼k seviyeli API ve tensÃ¶rlerle Ã§alÄ±ÅŸarak baÅŸlÄ±yoruz. Yine de hÄ±zlÄ± baÅŸlamak ve bu detaylara Ã§ok zaman harcamak istemiyorsanÄ±z, bunlarÄ± atlayÄ±p doÄŸrudan yÃ¼ksek seviyeli API not defterlerine geÃ§ebilirsiniz.

## âœï¸ AlÄ±ÅŸtÄ±rmalar: Ã‡erÃ§eveler

Ã–ÄŸrenmenize aÅŸaÄŸÄ±daki not defterlerinde devam edin:

DÃ¼ÅŸÃ¼k Seviyeli API | TensorFlow+Keras Not Defteri | PyTorch
-------------------|------------------------------|---------
YÃ¼ksek Seviyeli API | Keras | *PyTorch Lightning*

Ã‡erÃ§evelerde ustalaÅŸtÄ±ktan sonra, aÅŸÄ±rÄ± Ã¶ÄŸrenme kavramÄ±nÄ± tekrar gÃ¶zden geÃ§irelim.

# AÅŸÄ±rÄ± Ã–ÄŸrenme (Overfitting)

AÅŸÄ±rÄ± Ã¶ÄŸrenme, makine Ã¶ÄŸreniminde son derece Ã¶nemli bir kavramdÄ±r ve doÄŸru anlaÅŸÄ±lmasÄ± Ã§ok Ã¶nemlidir!

AÅŸaÄŸÄ±daki 5 noktayÄ± (grafiklerde `x` ile gÃ¶sterilmiÅŸtir) yaklaÅŸÄ±k olarak modelleme problemini dÃ¼ÅŸÃ¼nelim:

!linear | overfit
-------------------------|--------------------------
**DoÄŸrusal model, 2 parametre** | **DoÄŸrusal olmayan model, 7 parametre**
EÄŸitim hatasÄ± = 5.3 | EÄŸitim hatasÄ± = 0
DoÄŸrulama hatasÄ± = 5.1 | DoÄŸrulama hatasÄ± = 20

* Solda, iyi bir doÄŸru Ã§izgi yaklaÅŸÄ±mÄ± gÃ¶rÃ¼yoruz. Parametre sayÄ±sÄ± yeterli olduÄŸu iÃ§in model, nokta daÄŸÄ±lÄ±mÄ±nÄ±n arkasÄ±ndaki mantÄ±ÄŸÄ± doÄŸru anlÄ±yor.
* SaÄŸda ise model Ã§ok gÃ¼Ã§lÃ¼. Sadece 5 nokta varken modelin 7 parametresi var, bu yÃ¼zden tÃ¼m noktalardan geÃ§ecek ÅŸekilde ayarlanabiliyor ve eÄŸitim hatasÄ± 0 oluyor. Ancak bu, modelin verinin arkasÄ±ndaki doÄŸru deseni anlamasÄ±nÄ± engelliyor, bu yÃ¼zden doÄŸrulama hatasÄ± Ã§ok yÃ¼ksek.

Modelin karmaÅŸÄ±klÄ±ÄŸÄ± (parametre sayÄ±sÄ±) ile eÄŸitim Ã¶rneklerinin sayÄ±sÄ± arasÄ±nda doÄŸru dengeyi kurmak Ã§ok Ã¶nemlidir.

## AÅŸÄ±rÄ± Ã¶ÄŸrenme neden olur?

  * Yeterli eÄŸitim verisi olmamasÄ±
  * Ã‡ok gÃ¼Ã§lÃ¼ model
  * GiriÅŸ verisinde Ã§ok fazla gÃ¼rÃ¼ltÃ¼ olmasÄ±

## AÅŸÄ±rÄ± Ã¶ÄŸrenme nasÄ±l tespit edilir?

YukarÄ±daki grafikten gÃ¶rebileceÄŸiniz gibi, aÅŸÄ±rÄ± Ã¶ÄŸrenme Ã§ok dÃ¼ÅŸÃ¼k eÄŸitim hatasÄ± ve yÃ¼ksek doÄŸrulama hatasÄ± ile tespit edilir. Normalde eÄŸitim sÄ±rasÄ±nda hem eÄŸitim hem doÄŸrulama hatalarÄ± azalmaya baÅŸlar, ancak bir noktada doÄŸrulama hatasÄ± azalmayÄ± durdurup artmaya baÅŸlayabilir. Bu aÅŸÄ±rÄ± Ã¶ÄŸrenmenin iÅŸaretidir ve muhtemelen bu noktada eÄŸitimi durdurmamÄ±z gerektiÄŸinin gÃ¶stergesidir (ya da en azÄ±ndan modelin bir anlÄ±k gÃ¶rÃ¼ntÃ¼sÃ¼nÃ¼ almalÄ±yÄ±z).

aÅŸÄ±rÄ± Ã¶ÄŸrenme

## AÅŸÄ±rÄ± Ã¶ÄŸrenme nasÄ±l Ã¶nlenir?

AÅŸÄ±rÄ± Ã¶ÄŸrenme olduÄŸunu gÃ¶rÃ¼rseniz, aÅŸaÄŸÄ±dakilerden birini yapabilirsiniz:

 * EÄŸitim verisi miktarÄ±nÄ± artÄ±rmak
 * Modelin karmaÅŸÄ±klÄ±ÄŸÄ±nÄ± azaltmak
 * Daha sonra ele alacaÄŸÄ±mÄ±z Dropout gibi bazÄ± dÃ¼zenleme (regularization) teknikleri kullanmak

## AÅŸÄ±rÄ± Ã¶ÄŸrenme ve Bias-Variance Dengesi

AÅŸÄ±rÄ± Ã¶ÄŸrenme, istatistikte Bias-Variance Dengesi olarak adlandÄ±rÄ±lan daha genel bir problemin Ã¶zel bir durumudur. Modelimizdeki hata kaynaklarÄ±nÄ± dÃ¼ÅŸÃ¼ndÃ¼ÄŸÃ¼mÃ¼zde iki tÃ¼r hata gÃ¶rÃ¼rÃ¼z:

* **Bias hatalarÄ±**, algoritmamÄ±zÄ±n eÄŸitim verisi ile iliÅŸkiyi doÄŸru yakalayamamasÄ±ndan kaynaklanÄ±r. Bu, modelimizin yeterince gÃ¼Ã§lÃ¼ olmamasÄ±ndan kaynaklanabilir (**az Ã¶ÄŸrenme, underfitting**).
* **Variance hatalarÄ±**, modelin anlamlÄ± iliÅŸki yerine giriÅŸ verisindeki gÃ¼rÃ¼ltÃ¼yÃ¼ yakalamasÄ±ndan kaynaklanÄ±r (**aÅŸÄ±rÄ± Ã¶ÄŸrenme, overfitting**).

EÄŸitim sÄ±rasÄ±nda bias hatasÄ± azalÄ±rken (model veriyi Ã¶ÄŸrenirken), variance hatasÄ± artar. AÅŸÄ±rÄ± Ã¶ÄŸrenmeyi Ã¶nlemek iÃ§in eÄŸitimi durdurmak Ã¶nemlidir - ya manuel olarak (aÅŸÄ±rÄ± Ã¶ÄŸrenme tespit edildiÄŸinde) ya da otomatik olarak (dÃ¼zenleme teknikleri ile).

## SonuÃ§

Bu derste, en popÃ¼ler iki yapay zeka Ã§erÃ§evesi olan TensorFlow ve PyTorch iÃ§in farklÄ± API tÃ¼rleri arasÄ±ndaki farklarÄ± Ã¶ÄŸrendiniz. AyrÄ±ca Ã§ok Ã¶nemli bir konu olan aÅŸÄ±rÄ± Ã¶ÄŸrenme hakkÄ±nda bilgi edindiniz.

## ğŸš€ GÃ¶rev

EÅŸlik eden not defterlerinde, en altta 'gÃ¶revler' bulacaksÄ±nÄ±z; not defterlerini inceleyip gÃ¶revleri tamamlayÄ±n.

## GÃ¶zden GeÃ§irme & Kendi Kendine Ã‡alÄ±ÅŸma

AÅŸaÄŸÄ±daki konularda araÅŸtÄ±rma yapÄ±n:

- TensorFlow
- PyTorch
- AÅŸÄ±rÄ± Ã¶ÄŸrenme

Kendinize ÅŸu sorularÄ± sorun:

- TensorFlow ve PyTorch arasÄ±ndaki fark nedir?
- AÅŸÄ±rÄ± Ã¶ÄŸrenme ile az Ã¶ÄŸrenme arasÄ±ndaki fark nedir?

## Ã–dev

Bu laboratuvarda, PyTorch veya TensorFlow kullanarak tek katmanlÄ± ve Ã§ok katmanlÄ± tam baÄŸlÄ± aÄŸlarla iki sÄ±nÄ±flandÄ±rma problemi Ã§Ã¶zmeniz istenmektedir.

**Feragatname**:  
Bu belge, AI Ã§eviri servisi [Co-op Translator](https://github.com/Azure/co-op-translator) kullanÄ±larak Ã§evrilmiÅŸtir. DoÄŸruluk iÃ§in Ã§aba gÃ¶sterilse de, otomatik Ã§evirilerin hatalar veya yanlÄ±ÅŸlÄ±klar iÃ§erebileceÄŸini lÃ¼tfen unutmayÄ±nÄ±z. Orijinal belge, kendi dilinde yetkili kaynak olarak kabul edilmelidir. Kritik bilgiler iÃ§in profesyonel insan Ã§evirisi Ã¶nerilir. Bu Ã§evirinin kullanÄ±mÄ± sonucu oluÅŸabilecek yanlÄ±ÅŸ anlamalar veya yorum hatalarÄ±ndan sorumlu deÄŸiliz.