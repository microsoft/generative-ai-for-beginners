# Fondamentaux de l'Ing√©nierie des Prompts

[![Fondamentaux de l'Ing√©nierie des Prompts](../../../translated_images/fr/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introduction
Ce module couvre les concepts et techniques essentiels pour cr√©er des prompts efficaces dans les mod√®les d'IA g√©n√©rative. La mani√®re dont vous r√©digez votre prompt √† un LLM importe √©galement. Un prompt soigneusement √©labor√© peut obtenir une meilleure qualit√© de r√©ponse. Mais que signifient exactement des termes comme _prompt_ et _ing√©nierie des prompts_ ? Et comment am√©liorer le _texte du prompt_ que j‚Äôenvoie au LLM ? Ce sont les questions auxquelles nous allons essayer de r√©pondre dans ce chapitre et le suivant.

_L‚ÄôIA g√©n√©rative_ est capable de cr√©er de nouveaux contenus (par exemple, texte, images, audio, code, etc.) en r√©ponse aux requ√™tes des utilisateurs. Elle y parvient en utilisant des _grands mod√®les de langage_ comme la s√©rie GPT d'OpenAI ("Generative Pre-trained Transformer") qui sont entra√Æn√©s pour utiliser le langage naturel et le code.

Les utilisateurs peuvent d√©sormais interagir avec ces mod√®les en utilisant des paradigmes familiers comme le chat, sans n√©cessiter d‚Äôexpertise technique ni de formation. Les mod√®les sont _bas√©s sur des prompts_ - les utilisateurs envoient un texte (prompt) et re√ßoivent la r√©ponse de l‚ÄôIA (compl√©tion). Ils peuvent ensuite "dialoguer avec l‚ÄôIA" de fa√ßon it√©rative, dans des conversations √† plusieurs tours, affinant leur prompt jusqu‚Äô√† ce que la r√©ponse corresponde √† leurs attentes.

Les "prompts" deviennent d√©sormais la principale _interface de programmation_ pour les applications d‚ÄôIA g√©n√©rative, indiquant aux mod√®les ce qu‚Äôils doivent faire et influen√ßant la qualit√© des r√©ponses retourn√©es. L‚Äô"ing√©nierie des prompts" est un domaine d‚Äô√©tude en forte croissance, ax√© sur la _conception et l‚Äôoptimisation_ des prompts afin de fournir des r√©ponses coh√©rentes et de qualit√© √† grande √©chelle.

## Objectifs d‚Äôapprentissage

Dans cette le√ßon, nous apprendrons ce qu‚Äôest l‚Äôing√©nierie des prompts, pourquoi elle est importante, et comment concevoir des prompts plus efficaces pour un mod√®le donn√© et un objectif applicatif. Nous comprendrons les concepts cl√©s et les bonnes pratiques de l‚Äôing√©nierie des prompts - et d√©couvrirons un environnement "bac √† sable" interactif Jupyter Notebook o√π nous pourrons voir ces concepts appliqu√©s √† des exemples concrets.

√Ä la fin de cette le√ßon, nous serons capables de :

1. Expliquer ce qu‚Äôest l‚Äôing√©nierie des prompts et pourquoi elle est importante.
2. D√©crire les composants d‚Äôun prompt et comment ils sont utilis√©s.
3. Apprendre les meilleures pratiques et techniques pour l‚Äôing√©nierie des prompts.
4. Appliquer les techniques apprises √† des exemples r√©els, en utilisant un point de terminaison OpenAI.

## Termes Cl√©s

Ing√©nierie des Prompts : La pratique de concevoir et affiner les entr√©es pour guider les mod√®les d‚ÄôIA √† produire des sorties d√©sir√©es.  
Tokenisation : Le processus de conversion du texte en unit√©s plus petites, appel√©es tokens, qu‚Äôun mod√®le peut comprendre et traiter.  
LLMs Ajust√©s par Instruction : Grands mod√®les de langage (LLMs) qui ont √©t√© affin√©s avec des instructions sp√©cifiques pour am√©liorer la pr√©cision et la pertinence de leurs r√©ponses.

## Bac √† sable d‚Äôapprentissage

L‚Äôing√©nierie des prompts est aujourd‚Äôhui plus un art qu‚Äôune science. La meilleure fa√ßon d‚Äôam√©liorer notre intuition est de _pratiquer davantage_ et d‚Äôadopter une approche d‚Äôessais-erreurs qui combine expertise du domaine applicatif avec les techniques recommand√©es et les optimisations sp√©cifiques au mod√®le.

Le Jupyter Notebook accompagn√© de cette le√ßon fournit un environnement _bac √† sable_ o√π vous pouvez exp√©rimenter ce que vous apprenez - au fur et √† mesure ou dans le cadre du d√©fi de code √† la fin. Pour ex√©cuter les exercices, vous aurez besoin de :

1. **Une cl√© API Azure OpenAI** - le point de terminaison du service pour un LLM d√©ploy√©.  
2. **Un environnement d‚Äôex√©cution Python** - dans lequel le Notebook peut √™tre ex√©cut√©.  
3. **Variables d‚Äôenvironnement locales** - _compl√©tez les √©tapes [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) maintenant pour √™tre pr√™t_.

Le notebook propose des exercices _initiaux_ - mais vous √™tes encourag√© √† ajouter vos propres sections _Markdown_ (description) et _Code_ (requ√™tes de prompt) pour tester plus d‚Äôexemples ou d‚Äôid√©es - et d√©velopper votre intuition pour la conception de prompts.

## Guide Illustr√©

Vous souhaitez avoir une vue d‚Äôensemble de ce que couvre cette le√ßon avant de plonger dedans ? D√©couvrez ce guide illustr√©, qui vous donne une id√©e des principaux sujets abord√©s et des points cl√©s √† retenir pour chacun. La feuille de route de la le√ßon vous m√®ne de la compr√©hension des concepts et d√©fis fondamentaux √† leur r√©solution avec les techniques et bonnes pratiques pertinentes d‚Äôing√©nierie des prompts. Notez que la section "Techniques avanc√©es" de ce guide fait r√©f√©rence au contenu trait√© dans le _chapitre suivant_ de ce cursus.

![Guide Illustr√© de l‚ÄôIng√©nierie des Prompts](../../../translated_images/fr/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## Notre Startup

Maintenant, parlons de la fa√ßon dont _ce sujet_ se rapporte √† la mission de notre startup visant √† [apporter l‚Äôinnovation IA √† l‚Äô√©ducation](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Nous voulons cr√©er des applications d‚ÄôIA bas√©es sur _l‚Äôapprentissage personnalis√©_ ‚Äì r√©fl√©chissons donc √† la fa√ßon dont diff√©rents utilisateurs de notre application pourraient "concevoir" des prompts :

- **Les administrateurs** pourraient demander √† l‚ÄôIA d‚Äô_analyser les donn√©es du programme pour identifier les lacunes dans la couverture_. L‚ÄôIA peut r√©sumer les r√©sultats ou les visualiser avec du code.  
- **Les enseignants** pourraient demander √† l‚ÄôIA de _g√©n√©rer un plan de cours pour un public cible et un sujet donn√©_. L‚ÄôIA peut construire le plan personnalis√© dans un format sp√©cifi√©.  
- **Les √©tudiants** pourraient demander √† l‚ÄôIA _de les accompagner dans une mati√®re difficile_. L‚ÄôIA peut d√©sormais guider les √©tudiants avec des le√ßons, des indices et des exemples adapt√©s √† leur niveau.

Ce n‚Äôest que la partie √©merg√©e de l‚Äôiceberg. Consultez [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - une biblioth√®que open-source de prompts s√©lectionn√©e par des experts en √©ducation - pour avoir une id√©e plus large des possibilit√©s ! _Essayez d‚Äôex√©cuter certains de ces prompts dans le bac √† sable ou dans l‚ÄôOpenAI Playground pour voir ce qui se passe !_

<!--
TEMPLATE DE LE√áON :
Cette unit√© doit couvrir le concept fondamental #1.
Renforcez le concept avec des exemples et r√©f√©rences.

CONCEPT #1 :
Ing√©nierie des Prompts.
D√©finissez-le et expliquez pourquoi c‚Äôest n√©cessaire.
-->

## Qu‚Äôest-ce que l‚ÄôIng√©nierie des Prompts ?

Nous avons commenc√© cette le√ßon en d√©finissant **l‚ÄôIng√©nierie des Prompts** comme le processus de _conception et d‚Äôoptimisation_ des entr√©es textuelles (prompts) pour fournir des r√©ponses coh√©rentes et de qualit√© (compl√©tions) pour un objectif applicatif et un mod√®le donn√©s. Nous pouvons voir cela comme un processus en 2 √©tapes :

- _concevoir_ le prompt initial pour un mod√®le et un objectif donn√©s  
- _affiner_ le prompt de fa√ßon it√©rative pour am√©liorer la qualit√© de la r√©ponse

C‚Äôest n√©cessairement un processus d‚Äôessais-et-erreurs qui n√©cessite intuition et efforts de la part de l‚Äôutilisateur pour obtenir des r√©sultats optimaux. Alors pourquoi est-ce important ? Pour r√©pondre √† cette question, il faut d‚Äôabord comprendre trois concepts :

- _Tokenisation_ = comment le mod√®le "voit" le prompt  
- _LLMs de base_ = comment le mod√®le fondation "traite" un prompt  
- _LLMs ajust√©s par instruction_ = comment le mod√®le peut d√©sormais "comprendre des t√¢ches"

### Tokenisation

Un LLM voit les prompts comme une _s√©quence de tokens_ o√π diff√©rents mod√®les (ou versions d‚Äôun m√™me mod√®le) peuvent tokeniser un m√™me prompt de fa√ßons diff√©rentes. Comme les LLMs sont entra√Æn√©s sur des tokens (et non sur du texte brut), la mani√®re dont les prompts sont tokenis√©s a un impact direct sur la qualit√© de la r√©ponse g√©n√©r√©e.

Pour comprendre intuitivement la tokenisation, essayez des outils comme le [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) pr√©sent√© ci-dessous. Copiez-y votre prompt - et voyez comment il est converti en tokens, en faisant attention √† la gestion des espaces et des ponctuations. Notez que cet exemple montre un ancien LLM (GPT-3) - l‚Äôessayer avec un mod√®le plus r√©cent peut donner un r√©sultat diff√©rent.

![Tokenisation](../../../translated_images/fr/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Concept : Mod√®les Fondation

Une fois un prompt tokenis√©, la fonction premi√®re du ["LLM de base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou mod√®le fondation) est de pr√©dire le token suivant dans cette s√©quence. Comme les LLMs sont entra√Æn√©s sur d‚Äôimmenses corpus textuels, ils ont une bonne connaissance des relations statistiques entre tokens et peuvent faire cette pr√©diction avec confiance. Notez qu‚Äôils ne comprennent pas le _sens_ des mots dans le prompt ou le token ; ils per√ßoivent juste un sch√©ma qu‚Äôils peuvent "compl√©ter" avec leur pr√©diction suivante. Ils peuvent continuer √† pr√©dire la suite jusqu‚Äô√† interruption par l‚Äôutilisateur ou condition pr√©√©tablie.

Vous voulez voir comment fonctionne la compl√©tion bas√©e sur prompt ? Saisissez le prompt ci-dessus dans le [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) du Azure OpenAI Studio avec les r√©glages par d√©faut. Le syst√®me est configur√© pour consid√©rer les prompts comme des requ√™tes d‚Äôinformation - vous devriez donc voir une compl√©tion qui respecte ce contexte.

Mais que se passe-t-il si l‚Äôutilisateur souhaite voir quelque chose de sp√©cifique r√©pondant √† certains crit√®res ou objectifs de t√¢che ? C‚Äôest l√† qu‚Äôentrent en jeu les LLMs _ajust√©s par instruction_.

![Compl√©tion Chat LLM de base](../../../translated_images/fr/04-playground-chat-base.65b76fcfde0caa67.webp)

### Concept : LLMs Ajust√©s par Instruction

Un [LLM ajust√© par instruction](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) commence avec le mod√®le fondation et l‚Äôaffine en utilisant des exemples ou paires entr√©e/sortie (par exemple, des "messages" √† plusieurs tours) qui contiennent des consignes claires - et la r√©ponse de l‚ÄôIA s‚Äôefforce de suivre ces consignes.

Cela utilise des techniques telles que le Reinforcement Learning with Human Feedback (RLHF) qui permettent au mod√®le de _suivre des instructions_ et _d‚Äôapprendre des retours_ pour produire des r√©ponses mieux adapt√©es aux applications pratiques et plus pertinentes pour les objectifs utilisateurs.

Essayons - reprenez le prompt pr√©c√©dent mais modifiez le _message syst√®me_ pour fournir l‚Äôinstruction suivante en contexte :

> _R√©sumez le contenu fourni pour un √©l√®ve de CE1. Limitez le r√©sultat √† un paragraphe avec 3-5 points cl√©s._

Voyez comment le r√©sultat est d√©sormais ajust√© pour refl√©ter l‚Äôobjectif et le format d√©sir√©s ? Un enseignant peut d√©sormais utiliser directement cette r√©ponse dans ses diapositives pour cette classe.

![Compl√©tion Chat LLM ajust√© par instruction](../../../translated_images/fr/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## Pourquoi avons-nous besoin de l‚Äôing√©nierie des prompts ?

Maintenant que nous savons comment les prompts sont trait√©s par les LLMs, parlons de _pourquoi_ nous avons besoin de l‚Äôing√©nierie des prompts. La r√©ponse tient au fait que les LLMs actuels posent plusieurs d√©fis qui rendent les _compl√©tions fiables et coh√©rentes_ plus difficiles √† obtenir sans effort de construction et optimisation de prompts. Par exemple :

1. **Les r√©ponses des mod√®les sont stochastiques.** Le _m√™me prompt_ produira probablement des r√©ponses diff√©rentes selon les mod√®les ou versions de mod√®le. Et il peut m√™me produire des r√©sultats diff√©rents avec le _m√™me mod√®le_ √† diff√©rents moments. _Les techniques d‚Äôing√©nierie des prompts peuvent aider √† minimiser ces variations en fournissant de meilleures limites_.

1. **Les mod√®les peuvent inventer des r√©ponses.** Les mod√®les sont pr√©-entra√Æn√©s avec des ensembles de donn√©es _grands mais finis_, ce qui signifie qu‚Äôils manquent de connaissances sur des concepts hors de ce p√©rim√®tre. En cons√©quence, ils peuvent produire des compl√©tions inexactes, imaginaires, ou directement contradictoires √† des faits connus. _Les techniques d‚Äôing√©nierie des prompts aident les utilisateurs √† identifier et att√©nuer ces fabrications, par exemple en demandant des citations ou un raisonnement √† l‚ÄôIA_.

1. **Les capacit√©s des mod√®les varient.** Les mod√®les plus r√©cents ou de nouvelles g√©n√©rations ont des capacit√©s plus riches mais apportent aussi des singularit√©s et compromis uniques en co√ªt et complexit√©. _L‚Äôing√©nierie des prompts peut nous aider √† d√©velopper des bonnes pratiques et flux de travail qui abstraient ces diff√©rences et s‚Äôadaptent aux exigences sp√©cifiques des mod√®les de fa√ßon √©volutive et fluide_.

Voyons cela en action dans l‚ÄôOpenAI ou Azure OpenAI Playground :

- Utilisez le m√™me prompt avec diff√©rents d√©ploiements de LLM (par exemple OpenAI, Azure OpenAI, Hugging Face) - avez-vous constat√© des variations ?  
- Utilisez le m√™me prompt plusieurs fois avec le _m√™me_ d√©ploiement LLM (par exemple Azure OpenAI playground) - comment ces variations diff√®rent-elles ?

### Exemple de fabrications

Dans ce cours, nous utilisons le terme **"fabrication"** pour d√©signer le ph√©nom√®ne o√π les LLMs g√©n√®rent parfois des informations factuellement incorrectes √† cause des limites de leur entra√Ænement ou autres contraintes. Vous avez peut-√™tre aussi entendu ce ph√©nom√®ne nomm√© _"hallucinations"_ dans certains articles ou travaux de recherche. Cependant, nous recommandons fortement d‚Äôutiliser _"fabrication"_ afin d‚Äô√©viter d‚Äôanthropomorphiser ce comportement en attribuant un trait humain √† un r√©sultat g√©n√©r√© par une machine. Cela renforce aussi les [directives d‚ÄôIA responsable](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) du point de vue terminologique, en supprimant des termes pouvant √™tre consid√©r√©s offensants ou non inclusifs dans certains contextes.

Vous voulez comprendre comment fonctionnent les fabrications ? Pensez √† un prompt qui demande √† l‚ÄôIA de g√©n√©rer du contenu sur un sujet inexistant (pour s‚Äôassurer qu‚Äôil ne figure pas dans les donn√©es d‚Äôentra√Ænement). Par exemple - j‚Äôai essay√© ce prompt :

> **Prompt :** g√©n√©rer un plan de cours sur la guerre martienne de 2076.
Une recherche sur le web m‚Äôa montr√© qu‚Äôil existait des r√©cits fictifs (par exemple, des s√©ries t√©l√©vis√©es ou des livres) sur des guerres martiennes ‚Äì mais aucun en 2076. Le bon sens nous dit aussi que 2076 est _dans le futur_ et ne peut donc pas √™tre associ√© √† un √©v√©nement r√©el.

Alors, que se passe-t-il lorsque nous soumettons cette requ√™te √† diff√©rents fournisseurs de LLM ?

> **R√©ponse 1**¬†: OpenAI Playground (GPT-35)

![Response 1](../../../translated_images/fr/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **R√©ponse 2**¬†: Azure OpenAI Playground (GPT-35)

![Response 2](../../../translated_images/fr/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **R√©ponse 3**¬†: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../../translated_images/fr/04-fabrication-huggingchat.faf82a0a51278956.webp)

Comme pr√©vu, chaque mod√®le (ou version de mod√®le) produit des r√©ponses l√©g√®rement diff√©rentes gr√¢ce au comportement stochastique et aux variations de capacit√© des mod√®les. Par exemple, un mod√®le cible un public de niveau 8e tandis qu‚Äôun autre suppose un lyc√©en. Mais les trois mod√®les ont g√©n√©r√© des r√©ponses qui pourraient convaincre un utilisateur non inform√© que l‚Äô√©v√©nement √©tait r√©el.

Les techniques d‚Äôing√©nierie de prompt comme le _metaprompting_ et la _configuration de la temp√©rature_ peuvent r√©duire quelque peu les fabrications des mod√®les. De nouvelles _architectures_ d‚Äôing√©nierie de prompt int√®grent aussi de nouveaux outils et techniques de mani√®re fluide dans le flux du prompt, pour att√©nuer ou r√©duire certains de ces effets.

## √âtude de cas : GitHub Copilot

Terminons cette section en ayant une id√©e de la fa√ßon dont l‚Äôing√©nierie de prompt est utilis√©e dans des solutions r√©elles en regardant une √©tude de cas¬†: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot est votre ¬´¬†Programmeur IA en bin√¥me¬†¬ª ‚Äì il convertit des requ√™tes textuelles en compl√©tions de code et est int√©gr√© dans votre environnement de d√©veloppement (par exemple, Visual Studio Code) pour une exp√©rience utilisateur fluide. Comme document√© dans la s√©rie de blogs ci-dessous, la premi√®re version reposait sur le mod√®le OpenAI Codex ‚Äì les ing√©nieurs r√©alisant rapidement la n√©cessit√© d‚Äôaffiner le mod√®le et de d√©velopper de meilleures techniques d‚Äôing√©nierie de prompt, pour am√©liorer la qualit√© du code. En juillet, ils ont [lanc√© un mod√®le IA am√©lior√© qui d√©passe Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) pour des suggestions encore plus rapides.

Lisez les articles dans l‚Äôordre pour suivre leur parcours d‚Äôapprentissage.

- **Mai 2023** | [GitHub Copilot s‚Äôam√©liore dans la compr√©hension de votre code](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mai 2023** | [√Ä l‚Äôint√©rieur de GitHub : Travailler avec les LLMs derri√®re GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Juin 2023** | [Comment √©crire de meilleurs prompts pour GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Juillet 2023** | [.. GitHub Copilot d√©passe Codex avec un mod√®le IA am√©lior√©](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juillet 2023** | [Guide du d√©veloppeur pour l‚Äôing√©nierie de prompt et les LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Septembre 2023** | [Comment construire une application LLM d‚Äôentreprise¬†: le√ßons de GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Vous pouvez aussi parcourir leur [blog sur l‚Äôing√©nierie](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) pour d‚Äôautres articles comme [celui-ci](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) qui montre comment ces mod√®les et techniques sont _appliqu√©s_ pour piloter des applications concr√®tes.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Construction de Prompt

Nous avons vu pourquoi l‚Äôing√©nierie de prompt est importante ‚Äì maintenant comprenons comment les prompts sont _construits_ pour que nous puissions √©valuer diff√©rentes techniques pour concevoir des prompts plus efficaces.

### Prompt basique

Commen√ßons par le prompt basique¬†: une saisie textuelle envoy√©e au mod√®le sans autre contexte. Voici un exemple ‚Äì lorsque nous envoyons les premiers mots de l‚Äôhymne national am√©ricain √† l‚Äô[API de compl√©tion OpenAI](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) il compl√®te instantan√©ment la r√©ponse avec les lignes suivantes, illustrant le comportement de pr√©diction basique.

| Prompt (Entr√©e)     | Compl√©tion (Sortie)                                                                                                                         |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | On dirait que vous commencez les paroles de ¬´¬†The Star-Spangled Banner¬†¬ª, l‚Äôhymne national des √âtats-Unis. Les paroles compl√®tes sont ... |

### Prompt complexe

Maintenant, ajoutons contexte et instructions √† ce prompt basique. L‚Äô[API de chat completions](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nous permet de construire un prompt complexe comme une collection de _messages_ avec¬†:

- Paires entr√©e/sortie refl√©tant l‚Äôentr√©e _utilisateur_ et la r√©ponse _assistant_.
- Message syst√®me fixant le contexte pour le comportement ou la personnalit√© de l‚Äôassistant.

La requ√™te est maintenant sous la forme ci-dessous, o√π la _tokenisation_ capture efficacement les informations pertinentes du contexte et de la conversation. Maintenant, changer le contexte syst√®me peut √™tre aussi impactant sur la qualit√© des compl√©tions, que les entr√©es utilisateur fournies.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt d‚Äôinstruction

Dans les exemples ci-dessus, le prompt utilisateur √©tait une simple requ√™te texte pouvant √™tre interpr√©t√©e comme une demande d‚Äôinformation. Avec les prompts _d‚Äôinstruction_, nous pouvons utiliser ce texte pour sp√©cifier une t√¢che plus en d√©tail, fournissant ainsi une meilleure orientation √† l‚ÄôIA. Voici un exemple :

| Prompt (Entr√©e)                                                                                                                                                                                                                         | Compl√©tion (Sortie)                                                                                                         | Type d‚Äôinstruction |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| √âcris une description de la Guerre Civile                                                                                                                                                                                             | _a retourn√© un paragraphe simple_                                                                                           | Simple              |
| √âcris une description de la Guerre Civile. Fournis les dates et √©v√©nements cl√©s et d√©cris leur importance                                                                                                                                 | _a retourn√© un paragraphe suivi d‚Äôune liste des dates cl√©s avec descriptions_                                               | Complexe            |
| √âcris une description de la Guerre Civile en 1 paragraphe. Fournis 3 points √† puces avec les dates cl√©s et leur importance. Fournis 3 autres points √† puces avec des figures historiques cl√©s et leurs contributions. Renvoie le r√©sultat sous forme de fichier JSON | _retourne plus de d√©tails dans une zone de texte, format√©e en JSON que vous pouvez copier-coller dans un fichier et valider_ | Complexe. Format√©.   |

## Contenu principal

Dans les exemples ci-dessus, le prompt restait assez ouvert afin de laisser le LLM d√©cider quelle partie de son ensemble de donn√©es pr√©-entra√Æn√©es √©tait pertinente. Avec le patron de conception _contenu principal_, le texte d‚Äôentr√©e est divis√© en deux parties :

- une consigne (action)
- contenu pertinent (qui influence l‚Äôaction)

Voici un exemple o√π la consigne est ¬´¬†r√©sume ceci en 2 phrases¬†¬ª.

| Prompt (Entr√©e)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Compl√©tion (Sortie)                                                                                                                                                                                                                                                                           |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter est la cinqui√®me plan√®te √† partir du Soleil et la plus grande du Syst√®me solaire. C‚Äôest une g√©ante gazeuse avec une masse mille fois inf√©rieure √† celle du Soleil, mais deux fois et demie celle de toutes les autres plan√®tes du Syst√®me solaire r√©unies. Jupiter est l‚Äôun des objets les plus brillants visibles √† l‚Äô≈ìil nu dans le ciel nocturne, et √©tait connu des civilisations anciennes bien avant l‚Äôhistoire √©crite. Il tire son nom du dieu romain Jupiter.[19]¬†Vu depuis la Terre, Jupiter peut √™tre assez lumineux pour que sa lumi√®re r√©fl√©chie projette des ombres visibles,[20] et est en moyenne le troisi√®me objet naturel le plus brillant du ciel nocturne, apr√®s la Lune et V√©nus. <br/> **R√©sume ceci en 2 courtes phrases** | Jupiter, cinqui√®me plan√®te √† partir du Soleil, est la plus grande du Syst√®me solaire et est connue pour √™tre l‚Äôun des objets les plus brillants du ciel nocturne. Nomm√©e d‚Äôapr√®s le dieu romain Jupiter, c‚Äôest une g√©ante gazeuse dont la masse est deux fois et demie celle de toutes les autres plan√®tes du Syst√®me solaire r√©unies. |

Le segment de contenu principal peut √™tre utilis√© de diff√©rentes fa√ßons pour g√©n√©rer des instructions plus efficaces :

- **Exemples** ‚Äì au lieu de dire explicitement au mod√®le quoi faire par une instruction claire, donnez-lui des exemples de ce qu‚Äôil doit faire et laissez-le d√©duire le sch√©ma.
- **Indices** ‚Äì suivez la consigne avec un ¬´¬†indice¬†¬ª qui amorce la compl√©tion, guidant le mod√®le vers des r√©ponses plus pertinentes.
- **Mod√®les** ‚Äì ce sont des ¬´¬†recettes¬†¬ª r√©p√©tables pour les prompts avec des espaces r√©serv√©s (variables) que l‚Äôon peut personnaliser avec des donn√©es pour des cas d‚Äôusage sp√©cifiques.

Explorons tout cela en pratique.

### Utiliser des exemples

C‚Äôest une m√©thode o√π vous utilisez le contenu principal pour ¬´¬†nourrir le mod√®le¬†¬ª avec des exemples de la sortie souhait√©e pour une t√¢che donn√©e, et laissez-le d√©duire le sch√©ma de sortie attendu. Selon le nombre d‚Äôexemples fournis, on peut avoir du zero-shot prompting, one-shot prompting, few-shot prompting, etc.

Le prompt comporte maintenant trois composants :

- Une description de la t√¢che
- Quelques exemples de la sortie souhait√©e
- Le d√©but d‚Äôun nouvel exemple (qui devient une description implicite de la t√¢che)

| Type d‚Äôapprentissage | Prompt (Entr√©e)                                                                                                                                        | Compl√©tion (Sortie)      |
| :-------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------- |
| Zero-shot             | ¬´¬†The Sun is Shining¬†¬ª. Traduire en espagnol                                                                                                          | ¬´¬†El Sol est√° brillando.¬†¬ª |
| One-shot              | ¬´¬†The Sun is Shining¬†¬ª => ¬´¬†El Sol est√° brillando.¬†¬ª <br> ¬´¬†It‚Äôs a Cold and Windy Day¬†¬ª =>                                                           | ¬´¬†Es un d√≠a fr√≠o y ventoso.¬†¬ª |
| Few-shot              | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>     | Basketball               |
|                       |                                                                                                                                                       |                          |

Notez comment on a d√ª fournir une instruction explicite (¬´¬†Traduire en espagnol¬†¬ª) dans le zero-shot prompting, mais qu‚Äôelle est d√©duite dans l‚Äôexemple one-shot. L‚Äôexemple few-shot montre comment ajouter plus d‚Äôexemples permet aux mod√®les de faire des inf√©rences plus pr√©cises sans instructions suppl√©mentaires.

### Indices de prompt

Une autre technique pour utiliser le contenu principal est de fournir des _indices_ plut√¥t que des exemples. Dans ce cas, on donne au mod√®le un coup de pouce dans la bonne direction en _le d√©marrant_ par un extrait qui refl√®te le format de r√©ponse souhait√©. Le mod√®le ¬´¬†prend l‚Äôindice¬†¬ª pour continuer dans cette veine.

| Nombre d‚Äôindices | Prompt (Entr√©e)                                                                                                                                                                                                                                                                                                                                                                                          | Compl√©tion (Sortie)                                                                                                                                                                                                                                                                             |
| :---------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                | Jupiter est la cinqui√®me plan√®te √† partir du Soleil et la plus grande du Syst√®me solaire. C‚Äôest une g√©ante gazeuse avec une masse mille fois inf√©rieure √† celle du Soleil, mais deux fois et demie celle de toutes les autres plan√®tes du Syst√®me solaire r√©unies. Jupiter est l‚Äôun des objets les plus brillants visibles √† l‚Äô≈ìil nu dans le ciel nocturne, et √©tait connu des civilisations anciennes bien avant l‚Äôhistoire √©crite. <br/>**R√©sume ceci**             | Jupiter est la plus grande plan√®te de notre Syst√®me solaire et la cinqui√®me √† partir du Soleil. C‚Äôest une g√©ante gazeuse dont la masse est 1/1000 de celle du Soleil, mais elle est plus lourde que toutes les autres plan√®tes r√©unies. Les civilisations anciennes connaissent Jupiter depuis longtemps, et il est facilement visible dans le ciel nocturne. |
| 1              | Jupiter est la cinqui√®me plan√®te √† partir du Soleil et la plus grande du Syst√®me solaire. C'est une g√©ante gazeuse dont la masse est un milli√®me de celle du Soleil, mais deux fois et demie celle de toutes les autres plan√®tes du Syst√®me solaire r√©unies. Jupiter est l‚Äôun des objets les plus brillants visibles √† l'≈ìil nu dans le ciel nocturne, et elle est connue des civilisations anciennes depuis avant l‚Äôhistoire enregistr√©e. <br/>**R√©sumez ceci** <br/> Ce que nous avons appris, c‚Äôest que Jupiter | est la cinqui√®me plan√®te √† partir du Soleil et la plus grande du Syst√®me solaire. C'est une g√©ante gazeuse dont la masse est un milli√®me de celle du Soleil, mais deux fois et demie celle de toutes les autres plan√®tes r√©unies. Elle est facilement visible √† l'≈ìil nu et est connue depuis l‚Äôantiquit√©.                        |
| 2              | Jupiter est la cinqui√®me plan√®te √† partir du Soleil et la plus grande du Syst√®me solaire. C'est une g√©ante gazeuse dont la masse est un milli√®me de celle du Soleil, mais deux fois et demie celle de toutes les autres plan√®tes du Syst√®me solaire r√©unies. Jupiter est l‚Äôun des objets les plus brillants visibles √† l'≈ìil nu dans le ciel nocturne, et elle est connue des civilisations anciennes depuis avant l‚Äôhistoire enregistr√©e. <br/>**R√©sumez ceci** <br/> Top 3 des faits que nous avons appris :         | 1. Jupiter est la cinqui√®me plan√®te √† partir du Soleil et la plus grande du Syst√®me solaire. <br/> 2. C'est une g√©ante gazeuse dont la masse est un milli√®me de celle du Soleil...<br/> 3. Jupiter est visible √† l'≈ìil nu depuis l‚Äôantiquit√© ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Mod√®les de prompt

Un mod√®le de prompt est une _recette pr√©-d√©finie pour un prompt_ qui peut √™tre stock√©e et r√©utilis√©e selon les besoins, afin de garantir des exp√©riences utilisateurs plus coh√©rentes √† grande √©chelle. Dans sa forme la plus simple, il s'agit simplement d'une collection d'exemples de prompt comme [celui-ci d'OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) qui fournit √† la fois les composants interactifs du prompt (messages utilisateur et syst√®me) et le format de requ√™te pilot√© par API ‚Äì pour supporter la r√©utilisation.

Dans sa forme plus complexe comme [cet exemple de LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), il contient des _espaces r√©serv√©s_ qui peuvent √™tre remplac√©s par des donn√©es issues de diverses sources (entr√©e utilisateur, contexte syst√®me, sources de donn√©es externes, etc.) pour g√©n√©rer un prompt dynamiquement. Cela nous permet de cr√©er une biblioth√®que de prompts r√©utilisables qui peuvent √™tre utilis√©s pour offrir des exp√©riences utilisateurs coh√©rentes **programmatiquement** √† grande √©chelle.

Enfin, la vraie valeur des mod√®les r√©side dans la capacit√© √† cr√©er et publier des _biblioth√®ques de prompts_ pour des domaines d'application verticaux ‚Äì o√π le mod√®le de prompt est d√©sormais _optimis√©_ pour refl√©ter un contexte sp√©cifique √† l'application ou des exemples qui rendent les r√©ponses plus pertinentes et pr√©cises pour le public cible. Le r√©f√©rentiel [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) est un excellent exemple de cette approche, regroupant une biblioth√®que de prompts pour le domaine de l‚Äô√©ducation avec un accent sur les objectifs cl√©s tels que la planification des le√ßons, la conception des programmes, le tutorat des √©tudiants, etc.

## Contenu de soutien

Si l‚Äôon consid√®re la construction d‚Äôun prompt comme ayant une instruction (t√¢che) et un contenu cible (contenu principal), alors le _contenu secondaire_ est comme un contexte suppl√©mentaire que nous fournissons pour **influencer la sortie d‚Äôune certaine mani√®re**. Ce peuvent √™tre des param√®tres d‚Äôajustement, des instructions de mise en forme, des taxonomies de sujets, etc. qui aident le mod√®le √† _adapter_ sa r√©ponse pour correspondre aux objectifs ou attentes souhait√©s de l‚Äôutilisateur.

Par exemple : √©tant donn√© un catalogue de cours avec des m√©tadonn√©es √©tendues (nom, description, niveau, √©tiquettes de m√©tadonn√©es, enseignant, etc.) sur tous les cours disponibles dans le programme :

- on peut d√©finir une instruction pour ¬´ r√©sumer le catalogue de cours de l‚Äôautomne 2023 ¬ª
- on peut utiliser le contenu principal pour fournir quelques exemples du r√©sultat attendu
- on peut utiliser le contenu secondaire pour identifier les 5 principales ¬´ √©tiquettes ¬ª d‚Äôint√©r√™t.

Le mod√®le peut alors fournir un r√©sum√© dans le format montr√© par les exemples ‚Äì mais si un r√©sultat contient plusieurs √©tiquettes, il peut prioriser les 5 √©tiquettes identifi√©es dans le contenu secondaire.

---

<!--
MOD√àLE DE LE√áON :
Cette unit√© devrait couvrir le concept principal #1.
Renforcer le concept avec des exemples et des r√©f√©rences.

CONCEPT #3 :
Techniques de prompt engineering.
Quelles sont quelques techniques de base pour le prompt engineering ?
Illustrer avec des exercices.
-->

## Bonnes pratiques de prompt

Maintenant que nous savons comment les prompts peuvent √™tre _construits_, nous pouvons commencer √† r√©fl√©chir √† leur _conception_ pour refl√©ter les meilleures pratiques. On peut y r√©fl√©chir en deux parties ‚Äì adopter le bon _√©tat d‚Äôesprit_ et appliquer les bonnes _techniques_.

### √âtat d‚Äôesprit pour le prompt engineering

Le prompt engineering est un processus par essais et erreurs, gardez donc √† l‚Äôesprit trois grands facteurs directeurs :

1. **La compr√©hension du domaine est importante.** La pr√©cision et la pertinence des r√©ponses d√©pendent du _domaine_ dans lequel l‚Äôapplication ou l‚Äôutilisateur op√®re. Appliquez votre intuition et votre expertise de domaine pour **personnaliser davantage les techniques**. Par exemple, d√©finissez des _personnalit√©s sp√©cifiques au domaine_ dans vos prompts syst√®me, ou utilisez des _mod√®les sp√©cifiques au domaine_ dans les prompts utilisateurs. Fournissez un contenu secondaire qui refl√®te les contextes sp√©cifiques au domaine, ou utilisez des _indices et exemples sp√©cifiques au domaine_ pour guider le mod√®le vers des usages familiers.

2. **La compr√©hension du mod√®le compte.** Nous savons que les mod√®les sont stochastiques par nature. Mais les impl√©mentations peuvent aussi varier selon le jeu de donn√©es d‚Äôentra√Ænement utilis√© (connaissances pr√©-entra√Æn√©es), les capacit√©s disponibles (API ou SDK) et le type de contenu pour lequel ils sont optimis√©s (par exemple, code vs images vs texte). Comprenez les forces et limites du mod√®le que vous utilisez, et utilisez ces connaissances pour _prioriser les t√¢ches_ ou construire des _mod√®les personnalis√©s_ optimis√©s pour les capacit√©s du mod√®le.

3. **L‚Äôit√©ration et la validation sont essentielles.** Les mod√®les √©voluent rapidement, tout comme les techniques de prompt engineering. En tant qu‚Äôexpert du domaine, vous pouvez avoir un autre contexte ou des crit√®res propres √† _votre_ application sp√©cifique, qui peuvent ne pas s‚Äôappliquer √† la communaut√© plus large. Utilisez les outils et techniques de prompt engineering pour ¬´ d√©marrer ¬ª la construction des prompts, puis it√©rez et validez les r√©sultats avec votre propre intuition et expertise du domaine. Enregistrez vos id√©es et cr√©ez une **base de connaissances** (ex. biblioth√®ques de prompts) qui pourra servir de nouvelle r√©f√©rence pour d‚Äôautres, pour acc√©l√©rer les it√©rations futures.

## Bonnes pratiques

Examinons maintenant les bonnes pratiques recommand√©es par les praticiens de [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) et [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Quoi                              | Pourquoi                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| √âvaluer les mod√®les r√©cents.       | Les nouvelles g√©n√©rations de mod√®les ont probablement des fonctionnalit√©s et qualit√©s am√©lior√©es ‚Äì mais peuvent aussi engendrer des co√ªts plus √©lev√©s. √âvaluez-les pour leur impact, puis prenez des d√©cisions de migration.                                                                               |
| S√©parer instructions & contexte   | V√©rifiez si votre mod√®le/fournisseur d√©finit des _d√©limiteurs_ pour distinguer plus clairement les instructions, le contenu principal et le contenu secondaire. Cela aide les mod√®les √† attribuer plus pr√©cis√©ment les poids aux tokens.                                      |
| Soyez pr√©cis et clair             | Fournissez plus de d√©tails sur le contexte, le r√©sultat, la longueur, le format, le style souhait√©s, etc. Cela am√©liore √† la fois la qualit√© et la coh√©rence des r√©ponses. Capturez les recettes dans des mod√®les r√©utilisables.                                                       |
| Soyez descriptif, utilisez des exemples | Les mod√®les peuvent mieux r√©pondre √† une approche de type "montrer et expliquer". Commencez avec une approche `zero-shot` o√π vous donnez une instruction (sans exemple), puis essayez `few-shot` comme raffinement, en fournissant quelques exemples du r√©sultat attendu. Utilisez des analogies. |
| Utilisez des indices pour amorcer les compl√©tions | Orientez le mod√®le vers le r√©sultat souhait√© en lui fournissant quelques mots ou phrases d‚Äôamorce qu‚Äôil pourra utiliser comme point de d√©part pour la r√©ponse.                                                                                                               |
| Renforcez                        | Parfois, vous devrez peut-√™tre vous r√©p√©ter aupr√®s du mod√®le. Donnez des instructions avant et apr√®s votre contenu principal, utilisez une instruction et un indice, etc. It√©rez et validez pour voir ce qui fonctionne.                                                         |
| L‚Äôordre compte                   | L‚Äôordre dans lequel vous pr√©sentez l‚Äôinformation au mod√®le peut influencer la sortie, m√™me dans les exemples d‚Äôapprentissage, √† cause du biais de r√©cence. Essayez diff√©rentes options pour trouver ce qui fonctionne le mieux.                                                               |
| Donnez une "issue de secours" au mod√®le  | Donnez au mod√®le une r√©ponse de _repli_ qu‚Äôil peut fournir s‚Äôil ne peut pas accomplir la t√¢che pour une raison quelconque. Cela r√©duit les chances que le mod√®le g√©n√®re des r√©ponses fausses ou invent√©es.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Comme pour toute bonne pratique, rappelez-vous que _vos r√©sultats peuvent varier_ selon le mod√®le, la t√¢che et le domaine. Utilisez-les comme point de d√©part et it√©rez pour trouver ce qui convient le mieux pour vous. R√©√©valuez continuellement votre processus de prompt engineering √† mesure que de nouveaux mod√®les et outils apparaissent, en mettant l‚Äôaccent sur la mont√©e en √©chelle du processus et la qualit√© des r√©ponses.

<!--
MOD√àLE DE LE√áON :
Cette unit√© devrait fournir un d√©fi de code si applicable

D√âFI :
Lien vers un Jupyter Notebook avec seulement les commentaires dans le code (sections de code vides).

SOLUTION :
Lien vers une copie de ce Notebook avec les prompts remplis et ex√©cut√©s, montrant un exemple de sortie.
-->

## Devoir

F√©licitations ! Vous √™tes arriv√© √† la fin de la le√ßon ! Il est temps de mettre certains de ces concepts et techniques √† l‚Äô√©preuve avec des exemples concrets !

Pour notre devoir, nous utiliserons un Jupyter Notebook avec des exercices que vous pouvez compl√©ter de mani√®re interactive. Vous pouvez aussi √©tendre le Notebook avec vos propres cellules Markdown et Code pour explorer des id√©es et techniques par vous-m√™me.

### Pour commencer, forkez le d√©p√¥t, puis

- (Recommand√©) Lancez GitHub Codespaces
- (Alternativement) Clonez le d√©p√¥t sur votre appareil local et utilisez-le avec Docker Desktop
- (Alternativement) Ouvrez le Notebook avec l‚Äôenvironnement de Notebook de votre choix.

### Ensuite, configurez vos variables d‚Äôenvironnement

- Copiez le fichier `.env.copy` √† la racine du d√©p√¥t dans `.env` puis remplissez les valeurs `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` et `AZURE_OPENAI_DEPLOYMENT`. Revenez √† la [section Learning Sandbox](../../../04-prompt-engineering-fundamentals) pour apprendre comment faire.

### Ensuite, ouvrez le Jupyter Notebook

- S√©lectionnez le kernel d‚Äôex√©cution. Si vous utilisez les options 1 ou 2, s√©lectionnez simplement le kernel Python 3.10.x par d√©faut fourni par le conteneur de d√©veloppement.

Vous √™tes pr√™t √† ex√©cuter les exercices. Notez qu‚Äôil n‚Äôy a pas de r√©ponses _justes ou fausses_ ici ‚Äì il s‚Äôagit d‚Äôexplorer des options par essais et erreurs et de construire une intuition sur ce qui fonctionne pour un mod√®le donn√© et un domaine d‚Äôapplication.

_Pour cette raison, il n‚Äôy a pas de segments de solution de code dans cette le√ßon. √Ä la place, le Notebook comportera des cellules Markdown intitul√©es "Ma Solution :" qui montrent un exemple de sortie pour r√©f√©rence._

 <!--
MOD√àLE DE LE√áON :
Concluez la section avec un r√©sum√© et des ressources pour l‚Äôauto-apprentissage.
-->

## V√©rification des connaissances

Lequel des prompts suivants est un bon exemple respectant quelques bonnes pratiques raisonnables ?

1. Montre-moi une image d‚Äôune voiture rouge
2. Montre-moi une image d‚Äôune voiture rouge de marque Volvo et mod√®le XC90 gar√©e au bord d‚Äôune falaise avec le soleil couchant
3. Montre-moi une image d‚Äôune voiture rouge de marque Volvo et mod√®le XC90

R : 2, c‚Äôest le meilleur prompt car il fournit des d√©tails sur le "quoi" et entre dans les sp√©cificit√©s (pas n‚Äôimporte quelle voiture mais une marque et mod√®le pr√©cis) et d√©crit aussi le cadre g√©n√©ral. 3 est le deuxi√®me meilleur car il contient √©galement beaucoup de description.

## üöÄ D√©fi

Voyez si vous pouvez exploiter la technique de "l‚Äôindice" avec le prompt : Compl√©tez la phrase "Montre-moi une image d‚Äôune voiture rouge de marque Volvo et ". Que r√©pond-il, et comment l‚Äôam√©lioreriez-vous ?

## Excellent travail ! Continuez votre apprentissage

Vous souhaitez en savoir plus sur les diff√©rents concepts de prompt engineering ? Rendez-vous sur la [page d‚Äôapprentissage continu](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour trouver d‚Äôautres excellentes ressources sur ce sujet.

Dirigez-vous vers la le√ßon 5 o√π nous aborderons les [techniques avanc√©es de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst) !

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Avis de non-responsabilit√©** :
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous effor√ßons d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour les informations critiques, il est recommand√© de recourir √† une traduction professionnelle humaine. Nous ne saurions √™tre tenus responsables des malentendus ou des mauvaises interpr√©tations r√©sultant de l‚Äôutilisation de cette traduction.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->