# Cadres de R√©seaux Neuraux

Comme nous l'avons d√©j√† appris, pour pouvoir entra√Æner des r√©seaux neuronaux efficacement, nous devons faire deux choses :

* Op√©rer sur des tenseurs, par exemple pour multiplier, additionner et calculer certaines fonctions telles que sigmoid ou softmax
* Calculer les gradients de toutes les expressions, afin de r√©aliser l'optimisation par descente de gradient

Bien que la biblioth√®que `numpy` puisse faire la premi√®re partie, nous avons besoin d'un m√©canisme pour calculer les gradients. Dans notre cadre que nous avons d√©velopp√© dans la section pr√©c√©dente, nous devions programmer manuellement toutes les fonctions d√©riv√©es √† l'int√©rieur de la m√©thode `backward`, qui effectue la r√©tropropagation. Id√©alement, un cadre devrait nous offrir la possibilit√© de calculer les gradients de *n'importe quelle expression* que nous pouvons d√©finir.

Un autre aspect important est de pouvoir effectuer des calculs sur GPU, ou sur toute autre unit√© de calcul sp√©cialis√©e, comme le TPU. L'entra√Ænement de r√©seaux neuronaux profonds n√©cessite *beaucoup* de calculs, et pouvoir parall√©liser ces calculs sur les GPU est tr√®s important.

> ‚úÖ Le terme 'parall√©liser' signifie distribuer les calculs sur plusieurs dispositifs.

Actuellement, les deux cadres neuronaux les plus populaires sont : TensorFlow et PyTorch. Les deux fournissent une API de bas niveau pour op√©rer avec des tenseurs √† la fois sur CPU et GPU. En plus de l'API de bas niveau, il existe √©galement une API de plus haut niveau, appel√©e Keras et PyTorch Lightning respectivement.

API de Bas Niveau | TensorFlow| PyTorch
-------------------|-------------------------------------|--------------------------------
API de Haut Niveau | Keras| Pytorch

**Les API de bas niveau** dans les deux cadres vous permettent de construire ce qu'on appelle des **graphes computationnels**. Ce graphe d√©finit comment calculer la sortie (g√©n√©ralement la fonction de perte) avec des param√®tres d'entr√©e donn√©s, et peut √™tre envoy√© pour calcul sur GPU, si disponible. Il existe des fonctions pour diff√©rencier ce graphe computationnel et calculer les gradients, qui peuvent ensuite √™tre utilis√©s pour optimiser les param√®tres du mod√®le.

**Les API de haut niveau** consid√®rent essentiellement les r√©seaux neuronaux comme une **s√©quence de couches**, et facilitent la construction de la plupart des r√©seaux neuronaux. L'entra√Ænement du mod√®le n√©cessite g√©n√©ralement de pr√©parer les donn√©es puis d'appeler une fonction `fit` pour faire le travail.

L'API de haut niveau vous permet de construire des r√©seaux neuronaux typiques tr√®s rapidement sans vous soucier de nombreux d√©tails. En m√™me temps, les API de bas niveau offrent beaucoup plus de contr√¥le sur le processus d'entra√Ænement, et sont donc beaucoup utilis√©es en recherche, lorsque vous travaillez avec de nouvelles architectures de r√©seaux neuronaux.

Il est √©galement important de comprendre que vous pouvez utiliser les deux API ensemble, par exemple, vous pouvez d√©velopper votre propre architecture de couche de r√©seau en utilisant l'API de bas niveau, puis l'utiliser √† l'int√©rieur du r√©seau plus large construit et entra√Æn√© avec l'API de haut niveau. Ou vous pouvez d√©finir un r√©seau en utilisant l'API de haut niveau comme une s√©quence de couches, puis utiliser votre propre boucle d'entra√Ænement de bas niveau pour effectuer l'optimisation. Les deux API utilisent les m√™mes concepts de base sous-jacents, et elles sont con√ßues pour bien fonctionner ensemble.

## Apprentissage

Dans ce cours, nous proposons la plupart du contenu √† la fois pour PyTorch et TensorFlow. Vous pouvez choisir votre cadre pr√©f√©r√© et parcourir uniquement les notebooks correspondants. Si vous n'√™tes pas s√ªr de quel cadre choisir, lisez quelques discussions sur Internet concernant **PyTorch vs. TensorFlow**. Vous pouvez √©galement jeter un ≈ìil aux deux cadres pour mieux comprendre.

Dans la mesure du possible, nous utiliserons les API de haut niveau pour plus de simplicit√©. Cependant, nous pensons qu'il est important de comprendre comment fonctionnent les r√©seaux neuronaux depuis la base, donc au d√©but, nous commen√ßons par travailler avec l'API de bas niveau et les tenseurs. Cependant, si vous souhaitez avancer rapidement et ne pas passer beaucoup de temps √† apprendre ces d√©tails, vous pouvez les ignorer et passer directement aux notebooks de l'API de haut niveau.

## ‚úçÔ∏è Exercices : Cadres

Poursuivez votre apprentissage dans les notebooks suivants :

API de Bas Niveau | Notebook TensorFlow+Keras | PyTorch
-------------------|-------------------------------------|--------------------------------
API de Haut Niveau | Keras | *PyTorch Lightning*

Apr√®s avoir ma√Ætris√© les cadres, r√©capitulons la notion de surapprentissage.

# Surapprentissage

Le surapprentissage est un concept extr√™mement important en apprentissage automatique, et il est tr√®s important de bien le comprendre !

Consid√©rons le probl√®me suivant d'approximation de 5 points (repr√©sent√©s par `x` sur les graphiques ci-dessous) :

!lin√©aire | surajust√©
-------------------------|--------------------------
**Mod√®le lin√©aire, 2 param√®tres** | **Mod√®le non-lin√©aire, 7 param√®tres**
Erreur d'entra√Ænement = 5.3 | Erreur d'entra√Ænement = 0
Erreur de validation = 5.1 | Erreur de validation = 20

* √Ä gauche, nous voyons une bonne approximation par ligne droite. Parce que le nombre de param√®tres est ad√©quat, le mod√®le comprend correctement la distribution des points.
* √Ä droite, le mod√®le est trop puissant. Parce que nous n'avons que 5 points et que le mod√®le a 7 param√®tres, il peut s'ajuster de mani√®re √† passer par tous les points, rendant l'erreur d'entra√Ænement √©gale √† 0. Cependant, cela emp√™che le mod√®le de comprendre le bon sch√©ma derri√®re les donn√©es, d'o√π l'erreur de validation tr√®s √©lev√©e.

Il est tr√®s important de trouver un bon √©quilibre entre la richesse du mod√®le (nombre de param√®tres) et le nombre d'√©chantillons d'entra√Ænement.

## Pourquoi le surapprentissage se produit-il ?

  * Pas assez de donn√©es d'entra√Ænement
  * Mod√®le trop puissant
  * Trop de bruit dans les donn√©es d'entr√©e

## Comment d√©tecter le surapprentissage

Comme vous pouvez le voir sur le graphique ci-dessus, le surapprentissage peut √™tre d√©tect√© par une erreur d'entra√Ænement tr√®s faible et une erreur de validation √©lev√©e. Normalement, pendant l'entra√Ænement, nous verrons √† la fois les erreurs d'entra√Ænement et de validation commencer √† diminuer, puis √† un moment donn√©, l'erreur de validation pourrait cesser de diminuer et commencer √† augmenter. Ce sera un signe de surapprentissage, et l'indicateur que nous devrions probablement arr√™ter l'entra√Ænement √† ce moment-l√† (ou au moins faire une capture du mod√®le).

## Comment pr√©venir le surapprentissage

Si vous constatez que le surapprentissage se produit, vous pouvez faire l'une des choses suivantes :

 * Augmenter la quantit√© de donn√©es d'entra√Ænement
 * R√©duire la complexit√© du mod√®le
 * Utiliser une technique de r√©gularisation, telle que Dropout, que nous examinerons plus tard.

## Surapprentissage et Compromis Biais-Variance

Le surapprentissage est en fait un cas d'un probl√®me plus g√©n√©ral en statistiques appel√© Compromis Biais-Variance. Si nous consid√©rons les sources possibles d'erreur dans notre mod√®le, nous pouvons voir deux types d'erreurs :

* **Erreurs de biais** caus√©es par notre algorithme qui n'est pas capable de capturer correctement la relation entre les donn√©es d'entra√Ænement. Cela peut r√©sulter du fait que notre mod√®le n'est pas assez puissant (**sous-ajustement**).
* **Erreurs de variance**, qui sont caus√©es par le mod√®le qui approxime le bruit dans les donn√©es d'entr√©e au lieu d'une relation significative (**surajustement**).

Pendant l'entra√Ænement, l'erreur de biais diminue (car notre mod√®le apprend √† approximer les donn√©es), et l'erreur de variance augmente. Il est important d'arr√™ter l'entra√Ænement - soit manuellement (lorsque nous d√©tectons le surapprentissage) soit automatiquement (en introduisant une r√©gularisation) - pour pr√©venir le surapprentissage.

## Conclusion

Dans cette le√ßon, vous avez appris les diff√©rences entre les diff√©rentes API pour les deux cadres d'IA les plus populaires, TensorFlow et PyTorch. De plus, vous avez appris un sujet tr√®s important, le surapprentissage.

## üöÄ D√©fi

Dans les notebooks qui accompagnent, vous trouverez des 't√¢ches' en bas ; parcourez les notebooks et compl√©tez les t√¢ches.

## R√©vision & Auto-√âtude

Faites des recherches sur les sujets suivants :

- TensorFlow
- PyTorch
- Surapprentissage

Posez-vous les questions suivantes :

- Quelle est la diff√©rence entre TensorFlow et PyTorch ?
- Quelle est la diff√©rence entre surapprentissage et sous-ajustement ?

## Devoir

Dans ce laboratoire, il vous est demand√© de r√©soudre deux probl√®mes de classification en utilisant des r√©seaux enti√®rement connect√©s √† une ou plusieurs couches en utilisant PyTorch ou TensorFlow.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatis√©s par intelligence artificielle. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations cruciales, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des mauvaises interpr√©tations r√©sultant de l'utilisation de cette traduction.