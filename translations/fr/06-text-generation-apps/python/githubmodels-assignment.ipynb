{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créez des applications de génération de texte\n",
    "\n",
    "Vous avez vu dans ce parcours qu’il existe des concepts clés comme les prompts et même une discipline entière appelée « ingénierie de prompt ». De nombreux outils avec lesquels vous pouvez interagir, comme ChatGPT, Office 365, Microsoft Power Platform et bien d’autres, vous permettent d’utiliser des prompts pour accomplir des tâches.\n",
    "\n",
    "Pour ajouter ce type d’expérience à une application, il faut comprendre des notions comme les prompts, les complétions et choisir une bibliothèque adaptée. C’est exactement ce que vous allez apprendre dans ce chapitre.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans ce chapitre, vous allez :\n",
    "\n",
    "- Découvrir la bibliothèque openai et ses concepts principaux.\n",
    "- Créer une application de génération de texte avec openai.\n",
    "- Comprendre comment utiliser des notions comme le prompt, la température et les tokens pour concevoir une application de génération de texte.\n",
    "\n",
    "## Objectifs d’apprentissage\n",
    "\n",
    "À la fin de cette leçon, vous serez capable de :\n",
    "\n",
    "- Expliquer ce qu’est une application de génération de texte.\n",
    "- Créer une application de génération de texte avec openai.\n",
    "- Configurer votre application pour utiliser plus ou moins de tokens et aussi modifier la température, afin d’obtenir des résultats variés.\n",
    "\n",
    "## Qu’est-ce qu’une application de génération de texte ?\n",
    "\n",
    "En général, quand vous développez une application, elle possède une interface comme celles-ci :\n",
    "\n",
    "- Basée sur des commandes. Les applications console sont typiquement des applications où vous tapez une commande et elle exécute une tâche. Par exemple, `git` est une application basée sur des commandes.\n",
    "- Interface utilisateur (UI). Certaines applications ont une interface graphique (GUI) où vous cliquez sur des boutons, saisissez du texte, sélectionnez des options, etc.\n",
    "\n",
    "### Les applications console et UI sont limitées\n",
    "\n",
    "Comparez cela à une application basée sur des commandes où vous tapez une commande :\n",
    "\n",
    "- **C’est limité**. Vous ne pouvez pas taper n’importe quelle commande, seulement celles que l’application prend en charge.\n",
    "- **Spécifique à une langue**. Certaines applications prennent en charge plusieurs langues, mais par défaut, elles sont conçues pour une langue précise, même si vous pouvez ajouter la prise en charge d’autres langues.\n",
    "\n",
    "### Avantages des applications de génération de texte\n",
    "\n",
    "Alors, en quoi une application de génération de texte est-elle différente ?\n",
    "\n",
    "Dans une application de génération de texte, vous avez plus de flexibilité, vous n’êtes pas limité à un ensemble de commandes ou à une langue d’entrée spécifique. Au contraire, vous pouvez utiliser le langage naturel pour interagir avec l’application. Un autre avantage est que vous interagissez avec une source de données qui a été entraînée sur une vaste quantité d’informations, alors qu’une application traditionnelle peut être limitée à ce qui se trouve dans une base de données.\n",
    "\n",
    "### Que peut-on créer avec une application de génération de texte ?\n",
    "\n",
    "Il existe de nombreuses possibilités. Par exemple :\n",
    "\n",
    "- **Un chatbot**. Un chatbot qui répond à des questions sur des sujets comme votre entreprise et ses produits peut être très utile.\n",
    "- **Assistant**. Les LLM sont excellents pour résumer des textes, extraire des informations, produire des textes comme des CV, etc.\n",
    "- **Assistant de code**. Selon le modèle de langage utilisé, vous pouvez créer un assistant qui vous aide à écrire du code. Par exemple, vous pouvez utiliser des outils comme GitHub Copilot ou ChatGPT pour vous assister dans la rédaction de code.\n",
    "\n",
    "## Comment commencer ?\n",
    "\n",
    "Il faut trouver un moyen d’intégrer un LLM, ce qui implique généralement deux approches :\n",
    "\n",
    "- Utiliser une API. Vous construisez des requêtes web avec votre prompt et vous recevez du texte généré en retour.\n",
    "- Utiliser une bibliothèque. Les bibliothèques encapsulent les appels à l’API et les rendent plus simples à utiliser.\n",
    "\n",
    "## Bibliothèques/SDKs\n",
    "\n",
    "Il existe quelques bibliothèques bien connues pour travailler avec les LLM, comme :\n",
    "\n",
    "- **openai**, cette bibliothèque facilite la connexion à votre modèle et l’envoi de prompts.\n",
    "\n",
    "Il existe aussi des bibliothèques qui fonctionnent à un niveau plus élevé, comme :\n",
    "\n",
    "- **Langchain**. Langchain est très connu et prend en charge Python.\n",
    "- **Semantic Kernel**. Semantic Kernel est une bibliothèque de Microsoft qui prend en charge C#, Python et Java.\n",
    "\n",
    "## Première application avec GitHub Models Playground et Azure AI Inference SDK\n",
    "\n",
    "Voyons comment créer notre première application, quelles bibliothèques sont nécessaires, ce qu’il faut préparer, etc.\n",
    "\n",
    "### Qu’est-ce que GitHub Models ?\n",
    "\n",
    "Bienvenue sur [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst) ! Tout est prêt pour que vous puissiez explorer différents modèles d’IA hébergés sur Azure AI, accessibles via un playground sur GitHub ou directement dans votre IDE préféré, gratuitement.\n",
    "\n",
    "### De quoi ai-je besoin ?\n",
    "\n",
    "* Un compte GitHub : [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* S’inscrire à GitHub Models : [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "C’est parti !\n",
    "\n",
    "### Trouver un modèle et le tester\n",
    "\n",
    "Allez sur [GitHub Models dans le Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Écran principal de GitHub Models affichant une liste de cartes de modèles comme Cohere, Meta llama, Mistral et GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.fr.png)\n",
    "\n",
    "Choisissez un modèle – par exemple [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Vous verrez la carte du modèle. Vous pouvez :\n",
    "* Interagir avec le modèle directement en saisissant un message dans la zone de texte\n",
    "* Lire les détails sur le modèle dans les onglets readme, Évaluation, Transparence et Licence\n",
    "* Consulter la section « À propos » à droite pour les informations d’accès au modèle\n",
    "\n",
    "![Carte du modèle GPT-4o sur GitHub Models](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.fr.png)\n",
    "\n",
    "Mais nous allons aller directement au playground en cliquant sur le bouton ['Playground' en haut à droite](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Ici, vous pouvez interagir avec le modèle, ajouter des prompts système et modifier les paramètres – mais aussi récupérer tout le code nécessaire pour l’exécuter où vous voulez. Disponible à partir de septembre 2024 : Python, Javascript, C# et REST.\n",
    "\n",
    "![Expérience Playground de GitHub Models avec code et langages affichés](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.fr.png)  \n",
    "\n",
    "### Utiliser le modèle dans votre propre IDE\n",
    "\n",
    "Deux options s’offrent à vous :\n",
    "1. **GitHub Codespaces** – intégration transparente avec Codespaces, aucun token nécessaire pour commencer\n",
    "2. **VS Code (ou tout autre IDE préféré)** – il faut obtenir un [Personal Access Token sur GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Dans tous les cas, les instructions sont disponibles via le bouton vert « Get started » en haut à droite.\n",
    "\n",
    "![Écran Get Started montrant comment accéder à Codespaces ou utiliser un token personnel pour configurer dans votre IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.fr.png)\n",
    "\n",
    "### 1. Codespaces \n",
    "\n",
    "* Depuis la fenêtre « Get started », choisissez « Run codespace »\n",
    "* Créez un nouveau codespace (ou utilisez un existant)\n",
    "* VS Code s’ouvre dans votre navigateur avec un ensemble de notebooks d’exemple dans plusieurs langages à tester\n",
    "* Exécutez l’exemple ```./githubmodels-app.py```. \n",
    "\n",
    "> Note : Dans Codespaces, il n’est pas nécessaire de définir la variable Github Token, ignorez cette étape\n",
    "\n",
    "**Passez maintenant à la section « Générer du texte » ci-dessous pour continuer cet exercice**\n",
    "\n",
    "### 2. VS Code (ou tout autre IDE préféré)\n",
    "\n",
    "Depuis le bouton vert « Get started », vous avez toutes les informations nécessaires pour exécuter dans votre IDE préféré. Cet exemple montre VS Code\n",
    "\n",
    "* Sélectionnez le langage et le SDK – dans cet exemple, nous choisissons Python et Azure AI Inference SDK\n",
    "* Créez un token d’accès personnel sur GitHub. Cela se trouve dans la section Developer Settings. Il n’est pas nécessaire d’accorder des permissions au token. Notez que le token sera envoyé à un service Microsoft.\n",
    "* Créez une variable d’environnement pour stocker votre token personnel GitHub – exemples disponibles pour bash, powershell et l’invite de commande Windows\n",
    "* Installez les dépendances : ```pip install azure-ai-inference```\n",
    "* Copiez le code d’exemple de base dans un fichier .py\n",
    "* Naviguez là où votre code est enregistré et exécutez le fichier : ```python filename.py```\n",
    "\n",
    "N’oubliez pas qu’avec Azure AI Inference SDK, vous pouvez facilement tester différents modèles en modifiant la valeur de `model_name` dans le code.\n",
    "\n",
    "Les modèles suivants sont disponibles dans le service GitHub Models à partir de septembre 2024 :\n",
    "\n",
    "* AI21 Labs : AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere : Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta : Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI : Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft : Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI : OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Passez maintenant à la section « Générer du texte » ci-dessous pour continuer cet exercice**\n",
    "\n",
    "## Générer du texte avec ChatCompletions\n",
    "\n",
    "Pour générer du texte, il faut utiliser la classe `ChatCompletionsClient`.\n",
    "Dans `samples/python/azure_ai_inference/basic.py`, dans la section de réponse du code, modifiez le rôle utilisateur en changeant le paramètre content comme ci-dessous :\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Exécutez le fichier modifié pour voir le résultat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Différents types de prompts, pour différents besoins\n",
    "\n",
    "Vous avez maintenant vu comment générer du texte à l’aide d’un prompt. Vous avez même un programme qui fonctionne et que vous pouvez modifier pour générer différents types de textes.\n",
    "\n",
    "Les prompts peuvent être utilisés pour toutes sortes de tâches. Par exemple :\n",
    "\n",
    "- **Générer un type de texte**. Par exemple, vous pouvez générer un poème, des questions pour un quiz, etc.\n",
    "- **Rechercher des informations**. Vous pouvez utiliser des prompts pour chercher des informations, comme dans l’exemple suivant : « Que signifie CORS en développement web ? ».\n",
    "- **Générer du code**. Vous pouvez utiliser des prompts pour générer du code, par exemple pour créer une expression régulière qui valide des adresses e-mail ou même générer un programme complet, comme une application web.\n",
    "\n",
    "## Exercice : un générateur de recettes\n",
    "\n",
    "Imaginez que vous avez des ingrédients chez vous et que vous souhaitez cuisiner quelque chose. Pour cela, il vous faut une recette. Une façon de trouver des recettes est d’utiliser un moteur de recherche, ou bien vous pouvez utiliser un LLM pour cela.\n",
    "\n",
    "Vous pourriez écrire un prompt comme celui-ci :\n",
    "\n",
    "> « Montre-moi 5 recettes pour un plat avec les ingrédients suivants : poulet, pommes de terre et carottes. Pour chaque recette, liste tous les ingrédients utilisés »\n",
    "\n",
    "Avec ce prompt, vous pourriez obtenir une réponse similaire à :\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Ce résultat est super, je sais quoi cuisiner. À ce stade, ce qui pourrait être utile comme amélioration :\n",
    "\n",
    "- Éliminer les ingrédients que je n’aime pas ou auxquels je suis allergique.\n",
    "- Générer une liste de courses, au cas où je n’aurais pas tous les ingrédients chez moi.\n",
    "\n",
    "Pour ces cas, ajoutons un prompt supplémentaire :\n",
    "\n",
    "> « Merci de retirer les recettes contenant de l’ail car j’y suis allergique et de le remplacer par autre chose. Aussi, merci de produire une liste de courses pour les recettes, en considérant que j’ai déjà du poulet, des pommes de terre et des carottes à la maison. »\n",
    "\n",
    "Vous obtenez alors un nouveau résultat, à savoir :\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Voilà vos cinq recettes, sans ail mentionné, et vous avez aussi une liste de courses qui tient compte de ce que vous avez déjà chez vous.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercice - créer un générateur de recettes\n",
    "\n",
    "Maintenant que nous avons exploré un scénario, écrivons du code pour correspondre à ce qui a été montré. Pour cela, suivez ces étapes :\n",
    "\n",
    "1. Utilisez le fichier existant comme point de départ\n",
    "1. Créez une variable `prompt` et modifiez le code d'exemple comme indiqué ci-dessous :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous exécutez maintenant le code, vous devriez voir un résultat similaire à :\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, votre LLM est non déterministe, donc vous pourriez obtenir des résultats différents à chaque exécution du programme.\n",
    "\n",
    "Parfait, voyons comment nous pouvons améliorer les choses. Pour améliorer cela, nous voulons nous assurer que le code est flexible, afin que les ingrédients et le nombre de recettes puissent être modifiés et améliorés.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faire un test du code pourrait ressembler à ceci :\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Améliorer en ajoutant un filtre et une liste de courses\n",
    "\n",
    "Nous avons maintenant une application fonctionnelle capable de générer des recettes, et elle est flexible car elle dépend des entrées de l'utilisateur, à la fois sur le nombre de recettes et sur les ingrédients utilisés.\n",
    "\n",
    "Pour l'améliorer davantage, nous souhaitons ajouter les éléments suivants :\n",
    "\n",
    "- **Filtrer des ingrédients**. Nous voulons pouvoir exclure des ingrédients que nous n'aimons pas ou auxquels nous sommes allergiques. Pour réaliser ce changement, nous pouvons modifier notre prompt existant et ajouter une condition de filtre à la fin, comme ceci :\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Ici, nous ajoutons `{filter}` à la fin du prompt et nous récupérons aussi la valeur du filtre auprès de l'utilisateur.\n",
    "\n",
    "    Un exemple d'entrée lors de l'exécution du programme pourrait ressembler à ceci :\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Générer une liste de courses**. Nous voulons créer une liste de courses, en tenant compte de ce que nous avons déjà à la maison.\n",
    "\n",
    "    Pour cette fonctionnalité, on peut soit tout résoudre en un seul prompt, soit diviser en deux prompts. Essayons la deuxième approche. Ici, on propose d'ajouter un prompt supplémentaire, mais pour que cela fonctionne, il faut ajouter le résultat du premier prompt comme contexte au second.\n",
    "\n",
    "    Repérez la partie du code qui affiche le résultat du premier prompt et ajoutez le code suivant juste en dessous :\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    À noter :\n",
    "\n",
    "    - On construit un nouveau prompt en ajoutant le résultat du premier prompt au nouveau prompt :\n",
    "\n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - On fait une nouvelle requête, en tenant compte aussi du nombre de tokens demandé dans le premier prompt, donc cette fois on indique `max_tokens` à 1200. **À propos de la longueur des tokens**. Il faut réfléchir au nombre de tokens nécessaires pour générer le texte souhaité. Les tokens coûtent de l'argent, donc il vaut mieux être économe quand c'est possible. Par exemple, peut-on formuler le prompt pour utiliser moins de tokens ?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        En testant ce code, on obtient maintenant la sortie suivante :\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Expérimenter avec la température**. La température est un paramètre dont nous n'avons pas encore parlé, mais qui est important pour le comportement du programme. Plus la valeur de la température est élevée, plus la sortie sera aléatoire. À l'inverse, plus la température est basse, plus la sortie sera prévisible. Réfléchissez à si vous souhaitez ou non de la variation dans votre résultat.\n",
    "\n",
    "   Pour modifier la température, vous pouvez utiliser le paramètre `temperature`. Par exemple, si vous voulez une température de 0.5, vous feriez :\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Notez que plus on se rapproche de 1.0, plus le résultat sera varié.\n",
    "\n",
    "\n",
    "## Exercice\n",
    "\n",
    "Pour cet exercice, vous pouvez choisir ce que vous souhaitez créer.\n",
    "\n",
    "Voici quelques suggestions :\n",
    "\n",
    "- Modifiez l'application de génération de recettes pour l'améliorer encore. Testez différentes valeurs de température et modifiez les prompts pour voir ce que vous pouvez obtenir.\n",
    "- Créez un \"compagnon d'étude\". Cette application doit pouvoir répondre à des questions sur un sujet, par exemple Python. Vous pourriez avoir des prompts comme \"Qu'est-ce que tel sujet en Python ?\", ou un prompt qui demande de montrer du code sur un sujet précis, etc.\n",
    "- Bot historique, faites revivre l'histoire, demandez au bot d'incarner un personnage historique et posez-lui des questions sur sa vie et son époque.\n",
    "\n",
    "## Solution\n",
    "\n",
    "### Compagnon d'étude\n",
    "\n",
    "- \"Tu es un expert du langage Python\n",
    "\n",
    "    Propose une leçon pour débutant en Python au format suivant :\n",
    "    \n",
    "    Format :\n",
    "    - concepts :\n",
    "    - brève explication de la leçon :\n",
    "    - exercice en code avec solutions\"\n",
    "\n",
    "Ci-dessus, c'est un prompt de départ, voyez comment vous pouvez l'utiliser et l'adapter à votre goût.\n",
    "\n",
    "### Bot historique\n",
    "\n",
    "Voici quelques prompts que vous pouvez utiliser :\n",
    "\n",
    "- \"Tu es Abe Lincoln, parle-moi de toi en 3 phrases, et réponds en utilisant la grammaire et les mots qu'Abe aurait utilisés\"\n",
    "- \"Tu es Abe Lincoln, réponds en utilisant la grammaire et les mots qu'Abe aurait utilisés :\n",
    "\n",
    "   Parle-moi de tes plus grands accomplissements, en 300 mots :\"\n",
    "\n",
    "## Vérification des connaissances\n",
    "\n",
    "À quoi sert le concept de température ?\n",
    "\n",
    "1. Il contrôle le niveau d'aléatoire de la sortie.\n",
    "1. Il contrôle la taille de la réponse.\n",
    "1. Il contrôle le nombre de tokens utilisés.\n",
    "\n",
    "R : 1\n",
    "\n",
    "Quelle est une bonne façon de stocker des secrets comme des clés API ?\n",
    "\n",
    "1. Dans le code.\n",
    "1. Dans un fichier.\n",
    "1. Dans des variables d'environnement.\n",
    "\n",
    "R : 3, car les variables d'environnement ne sont pas stockées dans le code et peuvent être chargées depuis le code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Avertissement** :  \nCe document a été traduit à l’aide du service de traduction par IA [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d’assurer l’exactitude de la traduction, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d’origine doit être considéré comme la source faisant autorité. Pour les informations critiques, il est recommandé de recourir à une traduction humaine professionnelle. Nous déclinons toute responsabilité en cas de malentendus ou d’interprétations erronées résultant de l’utilisation de cette traduction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T14:43:25+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "fr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}