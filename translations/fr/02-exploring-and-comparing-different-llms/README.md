<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T09:15:16+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "fr"
}
-->
# Exploration et comparaison des diff√©rents LLM

[![Exploration et comparaison des diff√©rents LLM](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.fr.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Cliquez sur l'image ci-dessus pour voir la vid√©o de cette le√ßon_

Dans la le√ßon pr√©c√©dente, nous avons vu comment l'IA g√©n√©rative transforme le paysage technologique, comment les grands mod√®les de langage (LLM) fonctionnent et comment une entreprise - comme notre startup - peut les appliquer √† ses cas d'utilisation et se d√©velopper ! Dans ce chapitre, nous cherchons √† comparer et contraster diff√©rents types de grands mod√®les de langage (LLM) pour comprendre leurs avantages et inconv√©nients.

La prochaine √©tape dans le parcours de notre startup est d'explorer le paysage actuel des LLM et de comprendre lesquels sont adapt√©s √† notre cas d'utilisation.

## Introduction

Cette le√ßon couvrira :

- Diff√©rents types de LLM dans le paysage actuel.
- Tester, it√©rer et comparer diff√©rents mod√®les pour votre cas d'utilisation sur Azure.
- Comment d√©ployer un LLM.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous serez capable de :

- S√©lectionner le bon mod√®le pour votre cas d'utilisation.
- Comprendre comment tester, it√©rer et am√©liorer la performance de votre mod√®le.
- Savoir comment les entreprises d√©ploient des mod√®les.

## Comprendre les diff√©rents types de LLM

Les LLM peuvent avoir plusieurs cat√©gorisations bas√©es sur leur architecture, leurs donn√©es d'entra√Ænement et leur cas d'utilisation. Comprendre ces diff√©rences aidera notre startup √† s√©lectionner le bon mod√®le pour le sc√©nario, et √† comprendre comment tester, it√©rer et am√©liorer la performance.

Il existe de nombreux types de mod√®les LLM, votre choix de mod√®le d√©pend de ce que vous souhaitez en faire, de vos donn√©es, de combien vous √™tes pr√™t √† payer et plus encore.

Selon que vous souhaitez utiliser les mod√®les pour la g√©n√©ration de texte, d'audio, de vid√©o, d'image, etc., vous pourriez opter pour un type de mod√®le diff√©rent.

- **Reconnaissance audio et vocale**. Pour cet objectif, les mod√®les de type Whisper sont un excellent choix car ils sont polyvalents et destin√©s √† la reconnaissance vocale. Ils sont entra√Æn√©s sur des audios divers et peuvent effectuer une reconnaissance vocale multilingue. Apprenez-en plus sur les [mod√®les de type Whisper ici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **G√©n√©ration d'images**. Pour la g√©n√©ration d'images, DALL-E et Midjourney sont deux choix tr√®s connus. DALL-E est propos√© par Azure OpenAI. [Lisez-en plus sur DALL-E ici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) et √©galement dans le chapitre 9 de ce programme.

- **G√©n√©ration de texte**. La plupart des mod√®les sont entra√Æn√©s sur la g√©n√©ration de texte et vous avez un grand choix allant de GPT-3.5 √† GPT-4. Ils ont des co√ªts diff√©rents, GPT-4 √©tant le plus cher. Cela vaut la peine de consulter le [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pour √©valuer quels mod√®les conviennent le mieux √† vos besoins en termes de capacit√©s et de co√ªts.

- **Multi-modalit√©**. Si vous cherchez √† g√©rer plusieurs types de donn√©es en entr√©e et sortie, vous pourriez vouloir examiner des mod√®les comme [gpt-4 turbo avec vision ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - les derni√®res versions des mod√®les OpenAI - qui sont capables de combiner le traitement du langage naturel √† la compr√©hension visuelle, permettant des interactions via des interfaces multimodales.

S√©lectionner un mod√®le signifie que vous obtenez certaines capacit√©s de base, ce qui pourrait ne pas √™tre suffisant cependant. Souvent, vous avez des donn√©es sp√©cifiques √† l'entreprise que vous devez d'une mani√®re ou d'une autre communiquer au LLM. Il existe plusieurs choix sur la fa√ßon d'aborder cela, plus √† ce sujet dans les sections √† venir.

### Mod√®les de fondation versus LLM

Le terme Mod√®le de fondation a √©t√© [invent√© par des chercheurs de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) et d√©fini comme un mod√®le d'IA qui suit certains crit√®res, tels que :

- **Ils sont entra√Æn√©s en utilisant l'apprentissage non supervis√© ou l'apprentissage auto-supervis√©**, ce qui signifie qu'ils sont entra√Æn√©s sur des donn√©es multimodales non √©tiquet√©es, et qu'ils ne n√©cessitent pas d'annotation ou d'√©tiquetage humain des donn√©es pour leur processus d'entra√Ænement.
- **Ce sont des mod√®les tr√®s grands**, bas√©s sur des r√©seaux neuronaux tr√®s profonds entra√Æn√©s sur des milliards de param√®tres.
- **Ils sont normalement destin√©s √† servir de 'fondation' pour d'autres mod√®les**, ce qui signifie qu'ils peuvent √™tre utilis√©s comme point de d√©part pour d'autres mod√®les √† construire par-dessus, ce qui peut √™tre fait par ajustement fin.

![Mod√®les de fondation versus LLM](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.fr.png)

Source de l'image : [Essential Guide to Foundation Models and Large Language Models | par Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pour clarifier davantage cette distinction, prenons ChatGPT comme exemple. Pour construire la premi√®re version de ChatGPT, un mod√®le appel√© GPT-3.5 a servi de mod√®le de fondation. Cela signifie qu'OpenAI a utilis√© des donn√©es sp√©cifiques au chat pour cr√©er une version ajust√©e de GPT-3.5 qui √©tait sp√©cialis√©e pour bien performer dans des sc√©narios de conversation, tels que les chatbots.

![Mod√®le de fondation](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.fr.png)

Source de l'image : [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Mod√®les open source versus propri√©taires

Une autre fa√ßon de cat√©goriser les LLM est de savoir s'ils sont open source ou propri√©taires.

Les mod√®les open source sont des mod√®les qui sont mis √† disposition du public et peuvent √™tre utilis√©s par n'importe qui. Ils sont souvent mis √† disposition par l'entreprise qui les a cr√©√©s, ou par la communaut√© de recherche. Ces mod√®les peuvent √™tre inspect√©s, modifi√©s et personnalis√©s pour les diff√©rents cas d'utilisation des LLM. Cependant, ils ne sont pas toujours optimis√©s pour une utilisation en production, et peuvent ne pas √™tre aussi performants que les mod√®les propri√©taires. De plus, le financement des mod√®les open source peut √™tre limit√©, et ils peuvent ne pas √™tre maintenus √† long terme ou ne pas √™tre mis √† jour avec les derni√®res recherches. Des exemples de mod√®les open source populaires incluent [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) et [LLaMA](https://llama.meta.com).

Les mod√®les propri√©taires sont des mod√®les qui sont d√©tenus par une entreprise et ne sont pas mis √† disposition du public. Ces mod√®les sont souvent optimis√©s pour une utilisation en production. Cependant, ils ne peuvent pas √™tre inspect√©s, modifi√©s ou personnalis√©s pour diff√©rents cas d'utilisation. De plus, ils ne sont pas toujours disponibles gratuitement, et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s. Les utilisateurs n'ont pas non plus de contr√¥le sur les donn√©es utilis√©es pour entra√Æner le mod√®le, ce qui signifie qu'ils doivent faire confiance au propri√©taire du mod√®le pour garantir l'engagement envers la confidentialit√© des donn√©es et l'utilisation responsable de l'IA. Des exemples de mod√®les propri√©taires populaires incluent [mod√®les OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Incorporation versus G√©n√©ration d'images versus G√©n√©ration de texte et de code

Les LLM peuvent √©galement √™tre cat√©goris√©s par le type de sortie qu'ils g√©n√®rent.

Les incorporations sont un ensemble de mod√®les qui peuvent convertir du texte en une forme num√©rique, appel√©e incorporation, qui est une repr√©sentation num√©rique du texte d'entr√©e. Les incorporations facilitent la compr√©hension par les machines des relations entre les mots ou les phrases et peuvent √™tre consomm√©es comme entr√©es par d'autres mod√®les, tels que les mod√®les de classification ou les mod√®les de regroupement qui ont de meilleures performances sur les donn√©es num√©riques. Les mod√®les d'incorporation sont souvent utilis√©s pour l'apprentissage par transfert, o√π un mod√®le est construit pour une t√¢che de substitution pour laquelle il y a une abondance de donn√©es, puis les poids du mod√®le (incorporations) sont r√©utilis√©s pour d'autres t√¢ches en aval. Un exemple de cette cat√©gorie est [incorporations OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Incorporation](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.fr.png)

Les mod√®les de g√©n√©ration d'images sont des mod√®les qui g√©n√®rent des images. Ces mod√®les sont souvent utilis√©s pour l'√©dition d'images, la synth√®se d'images et la traduction d'images. Les mod√®les de g√©n√©ration d'images sont souvent entra√Æn√©s sur de grands ensembles de donn√©es d'images, tels que [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer de nouvelles images ou pour √©diter des images existantes avec des techniques de peinture, de super-r√©solution et de colorisation. Des exemples incluent [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) et [mod√®les de diffusion stable](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![G√©n√©ration d'images](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.fr.png)

Les mod√®les de g√©n√©ration de texte et de code sont des mod√®les qui g√©n√®rent du texte ou du code. Ces mod√®les sont souvent utilis√©s pour la synth√®se de texte, la traduction et la r√©ponse √† des questions. Les mod√®les de g√©n√©ration de texte sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de texte, tels que [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer de nouveaux textes ou pour r√©pondre √† des questions. Les mod√®les de g√©n√©ration de code, comme [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de code, tels que GitHub, et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau code ou pour corriger des bogues dans le code existant.

![G√©n√©ration de texte et de code](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.fr.png)

### Encodeur-D√©codeur versus D√©codeur uniquement

Pour parler des diff√©rents types d'architectures de LLM, utilisons une analogie.

Imaginez que votre responsable vous a donn√© une t√¢che pour r√©diger un quiz pour les √©tudiants. Vous avez deux coll√®gues ; l'un s'occupe de cr√©er le contenu et l'autre s'occupe de le r√©viser.

Le cr√©ateur de contenu est comme un mod√®le de D√©codeur uniquement, il peut regarder le sujet et voir ce que vous avez d√©j√† √©crit, puis il peut r√©diger un cours bas√© sur cela. Il est tr√®s bon pour √©crire du contenu engageant et informatif, mais il n'est pas tr√®s bon pour comprendre le sujet et les objectifs d'apprentissage. Quelques exemples de mod√®les de D√©codeur sont les mod√®les de la famille GPT, tels que GPT-3.

Le r√©viseur est comme un mod√®le d'Encodeur uniquement, il regarde le cours √©crit et les r√©ponses, remarque la relation entre eux et comprend le contexte, mais il n'est pas bon pour g√©n√©rer du contenu. Un exemple de mod√®le d'Encodeur uniquement serait BERT.

Imaginez que nous puissions avoir quelqu'un aussi qui pourrait cr√©er et r√©viser le quiz, c'est un mod√®le Encodeur-D√©codeur. Quelques exemples seraient BART et T5.

### Service versus Mod√®le

Parlons maintenant de la diff√©rence entre un service et un mod√®le. Un service est un produit propos√© par un fournisseur de services cloud, et est souvent une combinaison de mod√®les, de donn√©es et d'autres composants. Un mod√®le est le composant central d'un service, et est souvent un mod√®le de fondation, tel qu'un LLM.

Les services sont souvent optimis√©s pour une utilisation en production et sont souvent plus faciles √† utiliser que les mod√®les, via une interface utilisateur graphique. Cependant, les services ne sont pas toujours disponibles gratuitement, et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s, en √©change de l'utilisation des √©quipements et des ressources du propri√©taire du service, optimisant les d√©penses et facilitant la mise √† l'√©chelle. Un exemple de service est [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), qui propose un plan tarifaire √† la consommation, ce qui signifie que les utilisateurs sont factur√©s proportionnellement √† leur utilisation du service. De plus, Azure OpenAI Service offre une s√©curit√© de niveau entreprise et un cadre d'IA responsable en plus des capacit√©s des mod√®les.

Les mod√®les sont juste le r√©seau neuronal, avec les param√®tres, les poids et autres. Permettant aux entreprises de fonctionner localement, cependant, elles auraient besoin d'acheter des √©quipements, de construire une structure pour √©voluer et d'acheter une licence ou d'utiliser un mod√®le open source. Un mod√®le comme LLaMA est disponible pour √™tre utilis√©, n√©cessitant une puissance de calcul pour ex√©cuter le mod√®le.

## Comment tester et it√©rer avec diff√©rents mod√®les pour comprendre la performance sur Azure

Une fois que notre √©quipe a explor√© le paysage actuel des LLM et identifi√© quelques bons candidats pour leurs sc√©narios, la prochaine √©tape est de les tester sur leurs donn√©es et sur leur charge de travail. C'est un processus it√©ratif, r√©alis√© par des exp√©riences et des mesures. La plupart des mod√®les que nous avons mentionn√©s dans les paragraphes pr√©c√©dents (mod√®les OpenAI, mod√®les open source comme Llama2, et transformateurs Hugging Face) sont disponibles dans le [Catalogue de mod√®les](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) dans [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) est une plateforme cloud con√ßue pour les d√©veloppeurs afin de cr√©er des applications d'IA g√©n√©rative et de g√©rer l'ensemble du cycle de d√©veloppement - de l'exp√©rimentation √† l'√©valuation - en combinant tous les services Azure AI en un seul hub avec une interface utilisateur pratique. Le Catalogue de mod√®les dans Azure AI Studio permet √† l'utilisateur de :

- Trouver le mod√®le de fondation d'int√©r√™t dans le catalogue - soit propri√©taire soit open source, en filtrant par t√¢che, licence ou nom. Pour am√©liorer la recherche, les mod√®les sont organis√©s en collections, comme la collection Azure OpenAI, la collection Hugging Face, et plus encore.

![Catalogue de mod√®les](../../../translated_images/AzureAIStudioModelCatalog.e34ac207ac348d31e74246c4f91d10086444783b72bbee3658e0453918aa5d22.fr.png)

- Examiner la carte du mod√®le, y compris une description d√©taill√©e de l'utilisation pr√©vue et des donn√©es d'entra√Ænement, des exemples de code et des r√©sultats d'√©valuation sur la biblioth√®que d'√©valuations internes.

![Carte du mod√®le](../../../translated_images/ModelCard.8b25784bb406028655a12ea87d1ef3d52302e5d692ae4ec559c2dce7682027c7.fr.png)
- Comparez les benchmarks entre les mod√®les et les ensembles de donn√©es disponibles dans l'industrie pour √©valuer lequel r√©pond au sc√©nario commercial, via le volet [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarks de mod√®le](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.fr.png)

- Affinez le mod√®le sur des donn√©es d'entra√Ænement personnalis√©es pour am√©liorer les performances du mod√®le dans une charge de travail sp√©cifique, en tirant parti des capacit√©s d'exp√©rimentation et de suivi d'Azure AI Studio.

![Affinage du mod√®le](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.fr.png)

- D√©ployez le mod√®le pr√©-entra√Æn√© original ou la version affin√©e pour une inf√©rence en temps r√©el √† distance - calcul g√©r√© - ou un point de terminaison API sans serveur - [paiement √† l'utilisation](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - pour permettre aux applications de l'utiliser.

![D√©ploiement du mod√®le](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.fr.png)

> [!NOTE]
> Tous les mod√®les du catalogue ne sont pas actuellement disponibles pour l'affinage et/ou le d√©ploiement √† l'utilisation. Consultez la fiche du mod√®le pour les d√©tails sur les capacit√©s et les limitations du mod√®le.

## Am√©lioration des r√©sultats des LLM

Nous avons explor√© avec notre √©quipe de start-up diff√©rents types de LLM et une plateforme Cloud (Azure Machine Learning) nous permettant de comparer diff√©rents mod√®les, les √©valuer sur des donn√©es de test, am√©liorer les performances et les d√©ployer sur des points de terminaison d'inf√©rence.

Mais quand devraient-ils envisager d'affiner un mod√®le plut√¥t que d'utiliser un mod√®le pr√©-entra√Æn√© ? Y a-t-il d'autres approches pour am√©liorer les performances du mod√®le sur des charges de travail sp√©cifiques ?

Il existe plusieurs approches qu'une entreprise peut utiliser pour obtenir les r√©sultats souhait√©s d'un LLM. Vous pouvez s√©lectionner diff√©rents types de mod√®les avec divers degr√©s de formation lors du d√©ploiement d'un LLM en production, avec diff√©rents niveaux de complexit√©, de co√ªt et de qualit√©. Voici quelques approches diff√©rentes :

- **Ing√©nierie des prompts avec contexte**. L'id√©e est de fournir suffisamment de contexte lorsque vous donnez un prompt pour vous assurer d'obtenir les r√©ponses dont vous avez besoin.

- **G√©n√©ration augment√©e par la r√©cup√©ration, RAG**. Vos donn√©es pourraient exister dans une base de donn√©es ou un point de terminaison web par exemple, pour garantir que ces donn√©es, ou un sous-ensemble d'entre elles, soient incluses au moment du prompt, vous pouvez r√©cup√©rer les donn√©es pertinentes et en faire partie du prompt de l'utilisateur.

- **Mod√®le affin√©**. Ici, vous avez entra√Æn√© le mod√®le davantage sur vos propres donn√©es, ce qui a conduit √† ce que le mod√®le soit plus pr√©cis et r√©actif √† vos besoins, mais cela pourrait √™tre co√ªteux.

![D√©ploiement des LLM](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.fr.png)

Source de l'image : [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ing√©nierie des prompts avec contexte

Les LLM pr√©-entra√Æn√©s fonctionnent tr√®s bien sur les t√¢ches de langage naturel g√©n√©ralis√©es, m√™me en les appelant avec un court prompt, comme une phrase √† compl√©ter ou une question - ce qu'on appelle l'apprentissage "zero-shot".

Cependant, plus l'utilisateur peut encadrer sa requ√™te, avec une demande d√©taill√©e et des exemples - le Contexte - plus la r√©ponse sera pr√©cise et proche des attentes de l'utilisateur. Dans ce cas, on parle d'apprentissage "one-shot" si le prompt inclut seulement un exemple et d'apprentissage "few-shot" s'il inclut plusieurs exemples. L'ing√©nierie des prompts avec contexte est l'approche la plus rentable pour commencer.

### G√©n√©ration augment√©e par la r√©cup√©ration (RAG)

Les LLM ont la limitation qu'ils ne peuvent utiliser que les donn√©es qui ont √©t√© utilis√©es pendant leur entra√Ænement pour g√©n√©rer une r√©ponse. Cela signifie qu'ils ne connaissent rien des faits survenus apr√®s leur processus d'entra√Ænement, et ils ne peuvent pas acc√©der √† des informations non publiques (comme les donn√©es d'entreprise).
Cela peut √™tre surmont√© gr√¢ce √† RAG, une technique qui augmente le prompt avec des donn√©es externes sous forme de morceaux de documents, en consid√©rant les limites de longueur de prompt. Cela est soutenu par des outils de base de donn√©es vectorielle (comme [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) qui r√©cup√®rent les morceaux utiles √† partir de diverses sources de donn√©es pr√©d√©finies et les ajoutent au Contexte du prompt.

Cette technique est tr√®s utile lorsqu'une entreprise n'a pas suffisamment de donn√©es, de temps ou de ressources pour affiner un LLM, mais souhaite tout de m√™me am√©liorer les performances sur une charge de travail sp√©cifique et r√©duire les risques de fabrications, c'est-√†-dire de mystification de la r√©alit√© ou de contenu nuisible.

### Mod√®le affin√©

L'affinage est un processus qui exploite l'apprentissage par transfert pour "adapter" le mod√®le √† une t√¢che en aval ou pour r√©soudre un probl√®me sp√©cifique. Diff√©remment de l'apprentissage few-shot et de RAG, il en r√©sulte un nouveau mod√®le g√©n√©r√©, avec des poids et des biais mis √† jour. Il n√©cessite un ensemble d'exemples d'entra√Ænement consistant en une seule entr√©e (le prompt) et sa sortie associ√©e (la compl√©tion).
Ce serait l'approche pr√©f√©r√©e si :

- **Utilisation de mod√®les affin√©s**. Une entreprise souhaite utiliser des mod√®les moins performants affin√©s (comme des mod√®les d'int√©gration) plut√¥t que des mod√®les haute performance, r√©sultant en une solution plus rentable et rapide.

- **Consid√©ration de la latence**. La latence est importante pour un cas d'utilisation sp√©cifique, donc il n'est pas possible d'utiliser des prompts tr√®s longs ou le nombre d'exemples que le mod√®le devrait apprendre ne correspond pas √† la limite de longueur du prompt.

- **Rester √† jour**. Une entreprise dispose de nombreuses donn√©es de haute qualit√© et de labels de v√©rit√© terrain et des ressources n√©cessaires pour maintenir ces donn√©es √† jour au fil du temps.

### Mod√®le entra√Æn√©

Entra√Æner un LLM √† partir de z√©ro est sans aucun doute l'approche la plus difficile et la plus complexe √† adopter, n√©cessitant des quantit√©s massives de donn√©es, des ressources qualifi√©es et une puissance de calcul appropri√©e. Cette option ne devrait √™tre envisag√©e que dans un sc√©nario o√π une entreprise a un cas d'utilisation sp√©cifique √† un domaine et une grande quantit√© de donn√©es centr√©es sur le domaine.

## V√©rification des connaissances

Quelle pourrait √™tre une bonne approche pour am√©liorer les r√©sultats de compl√©tion des LLM ?

1. Ing√©nierie des prompts avec contexte
1. RAG
1. Mod√®le affin√©

R:3, si vous avez le temps et les ressources et des donn√©es de haute qualit√©, l'affinage est la meilleure option pour rester √† jour. Cependant, si vous cherchez √† am√©liorer les choses et que vous manquez de temps, il vaut la peine de consid√©rer RAG en premier.

## üöÄ D√©fi

Informez-vous davantage sur comment vous pouvez [utiliser RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pour votre entreprise.

## Excellent travail, poursuivez votre apprentissage

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage de l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† am√©liorer vos connaissances en IA g√©n√©rative !

Rendez-vous √† la le√ßon 3 o√π nous examinerons comment [construire avec l'IA g√©n√©rative de mani√®re responsable](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) !

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction IA [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de faire appel √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.