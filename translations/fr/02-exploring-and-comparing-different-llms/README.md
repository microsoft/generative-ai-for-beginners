<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:07:24+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "fr"
}
-->
# Explorer et comparer diffÃ©rents LLMs

[![Explorer et comparer diffÃ©rents LLMs](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.fr.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Cliquez sur lâ€™image ci-dessus pour voir la vidÃ©o de cette leÃ§on_

Avec la leÃ§on prÃ©cÃ©dente, nous avons vu comment lâ€™IA gÃ©nÃ©rative transforme le paysage technologique, comment fonctionnent les Large Language Models (LLMs) et comment une entreprise â€“ comme notre startup â€“ peut les appliquer Ã  ses cas dâ€™usage pour se dÃ©velopper ! Dans ce chapitre, nous allons comparer diffÃ©rents types de grands modÃ¨les de langage (LLMs) afin de comprendre leurs avantages et inconvÃ©nients.

La prochaine Ã©tape dans le parcours de notre startup est dâ€™explorer le paysage actuel des LLMs et de comprendre lesquels conviennent Ã  notre cas dâ€™usage.

## Introduction

Cette leÃ§on couvrira :

- Les diffÃ©rents types de LLMs dans le paysage actuel.
- Tester, itÃ©rer et comparer diffÃ©rents modÃ¨les pour votre cas dâ€™usage dans Azure.
- Comment dÃ©ployer un LLM.

## Objectifs dâ€™apprentissage

AprÃ¨s avoir terminÃ© cette leÃ§on, vous serez capable de :

- Choisir le modÃ¨le adaptÃ© Ã  votre cas dâ€™usage.
- Comprendre comment tester, itÃ©rer et amÃ©liorer les performances de votre modÃ¨le.
- Savoir comment les entreprises dÃ©ploient des modÃ¨les.

## Comprendre les diffÃ©rents types de LLMs

Les LLMs peuvent Ãªtre classÃ©s selon leur architecture, leurs donnÃ©es dâ€™entraÃ®nement et leur cas dâ€™usage. Comprendre ces diffÃ©rences aidera notre startup Ã  sÃ©lectionner le modÃ¨le adaptÃ© au scÃ©nario, et Ã  savoir comment tester, itÃ©rer et amÃ©liorer les performances.

Il existe de nombreux types de modÃ¨les LLM, votre choix dÃ©pendra de lâ€™usage que vous souhaitez en faire, de vos donnÃ©es, de votre budget, et plus encore.

Selon que vous souhaitez utiliser les modÃ¨les pour du texte, de lâ€™audio, de la vidÃ©o, de la gÃ©nÃ©ration dâ€™images, etc., vous choisirez un type de modÃ¨le diffÃ©rent.

- **Reconnaissance audio et vocale**. Pour cela, les modÃ¨les de type Whisper sont un excellent choix car ils sont polyvalents et conÃ§us pour la reconnaissance vocale. Ils sont entraÃ®nÃ©s sur des donnÃ©es audio variÃ©es et peuvent effectuer une reconnaissance vocale multilingue. En savoir plus sur les [modÃ¨les de type Whisper ici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **GÃ©nÃ©ration dâ€™images**. Pour la gÃ©nÃ©ration dâ€™images, DALL-E et Midjourney sont deux choix trÃ¨s connus. DALL-E est proposÃ© par Azure OpenAI. [En savoir plus sur DALL-E ici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) ainsi que dans le chapitre 9 de ce programme.

- **GÃ©nÃ©ration de texte**. La plupart des modÃ¨les sont entraÃ®nÃ©s pour la gÃ©nÃ©ration de texte et vous avez un large choix, de GPT-3.5 Ã  GPT-4. Ils ont des coÃ»ts diffÃ©rents, GPT-4 Ã©tant le plus cher. Il est intÃ©ressant dâ€™explorer le [playground Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pour Ã©valuer quels modÃ¨les correspondent le mieux Ã  vos besoins en termes de capacitÃ©s et de coÃ»t.

- **Multi-modalitÃ©**. Si vous souhaitez traiter plusieurs types de donnÃ©es en entrÃ©e et sortie, vous pouvez vous tourner vers des modÃ¨les comme [gpt-4 turbo avec vision ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) â€“ les derniÃ¨res versions des modÃ¨les OpenAI â€“ capables de combiner traitement du langage naturel et comprÃ©hension visuelle, permettant des interactions via des interfaces multi-modales.

Choisir un modÃ¨le vous donne des capacitÃ©s de base, qui peuvent ne pas suffire. Souvent, vous avez des donnÃ©es spÃ©cifiques Ã  votre entreprise que vous devez dâ€™une maniÃ¨re ou dâ€™une autre transmettre au LLM. Il existe plusieurs approches pour cela, que nous verrons dans les sections suivantes.

### Foundation Models versus LLMs

Le terme Foundation Model a Ã©tÃ© [inventÃ© par des chercheurs de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) et dÃ©signe un modÃ¨le dâ€™IA rÃ©pondant Ã  certains critÃ¨res, tels que :

- **Ils sont entraÃ®nÃ©s en apprentissage non supervisÃ© ou auto-supervisÃ©**, câ€™est-Ã -dire sur des donnÃ©es multi-modales non Ã©tiquetÃ©es, sans nÃ©cessiter dâ€™annotation humaine pour lâ€™entraÃ®nement.
- **Ce sont des modÃ¨les trÃ¨s volumineux**, basÃ©s sur des rÃ©seaux neuronaux profonds entraÃ®nÃ©s sur des milliards de paramÃ¨tres.
- **Ils sont gÃ©nÃ©ralement destinÃ©s Ã  servir de â€˜fondationâ€™ pour dâ€™autres modÃ¨les**, pouvant Ãªtre utilisÃ©s comme point de dÃ©part pour construire dâ€™autres modÃ¨les via du fine-tuning.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.fr.png)

Source de lâ€™image : [Essential Guide to Foundation Models and Large Language Models | par Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pour clarifier cette distinction, prenons ChatGPT en exemple. Pour construire la premiÃ¨re version de ChatGPT, un modÃ¨le appelÃ© GPT-3.5 a servi de foundation model. Cela signifie quâ€™OpenAI a utilisÃ© des donnÃ©es spÃ©cifiques au chat pour crÃ©er une version ajustÃ©e de GPT-3.5, spÃ©cialisÃ©e pour bien fonctionner dans des scÃ©narios conversationnels, comme les chatbots.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.fr.png)

Source de lâ€™image : [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### ModÃ¨les Open Source versus propriÃ©taires

Une autre faÃ§on de classer les LLMs est de savoir sâ€™ils sont open source ou propriÃ©taires.

Les modÃ¨les open source sont accessibles au public et peuvent Ãªtre utilisÃ©s par tous. Ils sont souvent publiÃ©s par lâ€™entreprise qui les a crÃ©Ã©s ou par la communautÃ© de recherche. Ces modÃ¨les peuvent Ãªtre inspectÃ©s, modifiÃ©s et personnalisÃ©s pour diffÃ©rents cas dâ€™usage. Cependant, ils ne sont pas toujours optimisÃ©s pour la production et peuvent Ãªtre moins performants que les modÃ¨les propriÃ©taires. De plus, le financement des modÃ¨les open source peut Ãªtre limitÃ©, ils ne sont pas toujours maintenus sur le long terme ni mis Ã  jour avec les derniÃ¨res avancÃ©es. Parmi les modÃ¨les open source populaires, on trouve [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) et [LLaMA](https://llama.meta.com).

Les modÃ¨les propriÃ©taires appartiennent Ã  une entreprise et ne sont pas accessibles au public. Ils sont souvent optimisÃ©s pour la production. Cependant, ils ne peuvent pas Ãªtre inspectÃ©s, modifiÃ©s ou personnalisÃ©s pour diffÃ©rents cas dâ€™usage. Ils ne sont pas toujours gratuits et peuvent nÃ©cessiter un abonnement ou un paiement. De plus, les utilisateurs nâ€™ont pas le contrÃ´le sur les donnÃ©es utilisÃ©es pour entraÃ®ner le modÃ¨le, ils doivent donc faire confiance au propriÃ©taire du modÃ¨le pour garantir la confidentialitÃ© des donnÃ©es et une utilisation responsable de lâ€™IA. Parmi les modÃ¨les propriÃ©taires populaires, on trouve les [modÃ¨les OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus gÃ©nÃ©ration dâ€™images versus gÃ©nÃ©ration de texte et code

Les LLMs peuvent aussi Ãªtre classÃ©s selon le type de sortie quâ€™ils gÃ©nÃ¨rent.

Les embeddings sont des modÃ¨les qui convertissent du texte en une forme numÃ©rique, appelÃ©e embedding, une reprÃ©sentation numÃ©rique du texte dâ€™entrÃ©e. Les embeddings facilitent la comprÃ©hension des relations entre mots ou phrases par les machines et peuvent Ãªtre utilisÃ©s comme entrÃ©es par dâ€™autres modÃ¨les, comme des modÃ¨les de classification ou de clustering, qui fonctionnent mieux avec des donnÃ©es numÃ©riques. Les modÃ¨les dâ€™embedding sont souvent utilisÃ©s pour le transfert dâ€™apprentissage, oÃ¹ un modÃ¨le est construit pour une tÃ¢che de substitution avec beaucoup de donnÃ©es, puis les poids du modÃ¨le (embeddings) sont rÃ©utilisÃ©s pour dâ€™autres tÃ¢ches en aval. Un exemple dans cette catÃ©gorie est [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.fr.png)

Les modÃ¨les de gÃ©nÃ©ration dâ€™images crÃ©ent des images. Ils sont souvent utilisÃ©s pour lâ€™Ã©dition, la synthÃ¨se et la traduction dâ€™images. Ces modÃ¨les sont entraÃ®nÃ©s sur de grands ensembles dâ€™images, comme [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), et peuvent gÃ©nÃ©rer de nouvelles images ou modifier des images existantes avec des techniques dâ€™inpainting, de super-rÃ©solution et de colorisation. Exemples : [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) et [Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![GÃ©nÃ©ration dâ€™images](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.fr.png)

Les modÃ¨les de gÃ©nÃ©ration de texte et de code produisent du texte ou du code. Ils sont souvent utilisÃ©s pour la synthÃ¨se de texte, la traduction et la rÃ©ponse Ã  des questions. Ces modÃ¨les sont entraÃ®nÃ©s sur de grands ensembles de textes, comme [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), et peuvent gÃ©nÃ©rer du texte nouveau ou rÃ©pondre Ã  des questions. Les modÃ¨les de gÃ©nÃ©ration de code, comme [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sont entraÃ®nÃ©s sur de grands ensembles de code, comme GitHub, et peuvent gÃ©nÃ©rer du code ou corriger des bugs.

![GÃ©nÃ©ration de texte et code](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.fr.png)

### Encoder-Decoder versus Decoder-only

Pour parler des diffÃ©rentes architectures des LLMs, utilisons une analogie.

Imaginez que votre manager vous demande de crÃ©er un quiz pour les Ã©tudiants. Vous avez deux collÃ¨gues : lâ€™un sâ€™occupe de crÃ©er le contenu, lâ€™autre de le relire.

Le crÃ©ateur de contenu est comme un modÃ¨le Decoder-only, il peut regarder le sujet et ce que vous avez dÃ©jÃ  Ã©crit, puis rÃ©diger un cours Ã  partir de cela. Il est trÃ¨s bon pour Ã©crire un contenu engageant et informatif, mais il comprend moins bien le sujet et les objectifs pÃ©dagogiques. Quelques exemples de modÃ¨les Decoder sont les modÃ¨les de la famille GPT, comme GPT-3.

Le relecteur est comme un modÃ¨le Encoder-only, il examine le cours Ã©crit et les rÃ©ponses, remarque les relations entre eux et comprend le contexte, mais il nâ€™est pas bon pour gÃ©nÃ©rer du contenu. Un exemple de modÃ¨le Encoder-only est BERT.

Imaginez maintenant que nous ayons quelquâ€™un qui puisse Ã  la fois crÃ©er et relire le quiz, câ€™est un modÃ¨le Encoder-Decoder. Quelques exemples sont BART et T5.

### Service versus ModÃ¨le

Parlons maintenant de la diffÃ©rence entre un service et un modÃ¨le. Un service est un produit proposÃ© par un fournisseur de services cloud, souvent une combinaison de modÃ¨les, de donnÃ©es et dâ€™autres composants. Un modÃ¨le est le composant central dâ€™un service, souvent un foundation model, comme un LLM.

Les services sont souvent optimisÃ©s pour la production et plus faciles Ã  utiliser que les modÃ¨les, via une interface graphique. Cependant, ils ne sont pas toujours gratuits et peuvent nÃ©cessiter un abonnement ou un paiement, en Ã©change de lâ€™utilisation des Ã©quipements et ressources du fournisseur, optimisant les coÃ»ts et facilitant la montÃ©e en charge. Un exemple de service est [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), qui propose un tarif Ã  lâ€™usage, facturant les utilisateurs proportionnellement Ã  leur consommation. De plus, Azure OpenAI Service offre une sÃ©curitÃ© de niveau entreprise et un cadre dâ€™IA responsable en complÃ©ment des capacitÃ©s des modÃ¨les.

Les modÃ¨les sont simplement les rÃ©seaux neuronaux, avec leurs paramÃ¨tres, poids, etc. Ils permettent aux entreprises de fonctionner localement, mais nÃ©cessitent dâ€™acheter du matÃ©riel, de construire une infrastructure pour monter en charge et dâ€™acheter une licence ou dâ€™utiliser un modÃ¨le open source. Un modÃ¨le comme LLaMA est disponible Ã  lâ€™utilisation, mais demande une puissance de calcul importante.

## Comment tester et itÃ©rer avec diffÃ©rents modÃ¨les pour comprendre leurs performances sur Azure

Une fois que notre Ã©quipe a explorÃ© le paysage actuel des LLMs et identifiÃ© quelques bons candidats pour leurs scÃ©narios, lâ€™Ã©tape suivante est de les tester sur leurs donnÃ©es et leur charge de travail. Câ€™est un processus itÃ©ratif, rÃ©alisÃ© par des expÃ©riences et des mesures.
La plupart des modÃ¨les que nous avons mentionnÃ©s dans les paragraphes prÃ©cÃ©dents (modÃ¨les OpenAI, modÃ¨les open source comme Llama2, et transformers Hugging Face) sont disponibles dans le [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) de [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) est une plateforme Cloud conÃ§ue pour les dÃ©veloppeurs afin de crÃ©er des applications dâ€™IA gÃ©nÃ©rative et gÃ©rer lâ€™ensemble du cycle de vie du dÃ©veloppement â€“ de lâ€™expÃ©rimentation Ã  lâ€™Ã©valuation â€“ en combinant tous les services Azure AI dans un hub unique avec une interface graphique pratique. Le Model Catalog dans Azure AI Studio permet Ã  lâ€™utilisateur de :

- Trouver le Foundation Model qui lâ€™intÃ©resse dans le catalogue â€“ quâ€™il soit propriÃ©taire ou open source, en filtrant par tÃ¢che, licence ou nom. Pour faciliter la recherche, les modÃ¨les sont organisÃ©s en collections, comme la collection Azure OpenAI, la collection Hugging Face, et dâ€™autres.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.fr.png)

- Consulter la fiche du modÃ¨le, incluant une description dÃ©taillÃ©e de lâ€™usage prÃ©vu et des donnÃ©es dâ€™entraÃ®nement, des exemples de code et les rÃ©sultats dâ€™Ã©valuation issus de la bibliothÃ¨que interne dâ€™Ã©valuations.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.fr.png)

- Comparer les benchmarks entre modÃ¨les et jeux de donnÃ©es disponibles dans lâ€™industrie pour dÃ©terminer celui qui correspond le mieux au scÃ©nario mÃ©tier, via le panneau [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.fr.png)

- Affiner le modÃ¨le sur des donnÃ©es dâ€™entraÃ®nement personnalisÃ©es pour amÃ©liorer ses performances sur une charge de travail spÃ©cifique, en tirant parti des capacitÃ©s dâ€™expÃ©rimentation et de suivi dâ€™Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.fr.png)

- DÃ©ployer le modÃ¨le prÃ©-entraÃ®nÃ© original ou la version fine-tunÃ©e sur un endpoint dâ€™infÃ©rence en temps rÃ©el distant â€“ compute managÃ© â€“ ou un endpoint API serverless â€“ [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) â€“ pour permettre aux applications de lâ€™utiliser.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.fr.png)


> [!NOTE]
> Tous les modÃ¨les du catalogue ne sont pas encore disponibles pour le fine-tuning et/ou le dÃ©ploiement pay-as-you-go. Consultez la fiche du modÃ¨le pour connaÃ®tre ses capacitÃ©s et ses limites.

## AmÃ©liorer les rÃ©sultats des LLM

Nous avons explorÃ© avec notre Ã©quipe startup diffÃ©rents types de LLM ainsi quâ€™une plateforme Cloud (Azure Machine Learning) qui nous permet de comparer diffÃ©rents modÃ¨les, de les Ã©valuer sur des donnÃ©es de test, dâ€™amÃ©liorer leurs performances et de les dÃ©ployer sur des endpoints dâ€™infÃ©rence.

Mais quand faut-il envisager de fine-tuner un modÃ¨le plutÃ´t que dâ€™utiliser un modÃ¨le prÃ©-entraÃ®nÃ© ? Existe-t-il dâ€™autres mÃ©thodes pour amÃ©liorer les performances dâ€™un modÃ¨le sur des charges de travail spÃ©cifiques ?

Plusieurs approches sont possibles pour une entreprise afin dâ€™obtenir les rÃ©sultats souhaitÃ©s avec un LLM. Vous pouvez choisir diffÃ©rents types de modÃ¨les avec des degrÃ©s dâ€™entraÃ®nement variÃ©s lors du dÃ©ploiement dâ€™un LLM en production, avec des niveaux de complexitÃ©, de coÃ»t et de qualitÃ© diffÃ©rents. Voici quelques approches possibles :

- **Prompt engineering avec contexte**. Lâ€™idÃ©e est de fournir suffisamment de contexte lors de la requÃªte pour sâ€™assurer dâ€™obtenir les rÃ©ponses attendues.

- **Retrieval Augmented Generation, RAG**. Vos donnÃ©es peuvent exister dans une base de donnÃ©es ou un endpoint web par exemple, pour garantir que ces donnÃ©es, ou un sous-ensemble, soient incluses au moment de la requÃªte, vous pouvez rÃ©cupÃ©rer les donnÃ©es pertinentes et les intÃ©grer dans le prompt de lâ€™utilisateur.

- **ModÃ¨le fine-tunÃ©**. Ici, vous entraÃ®nez davantage le modÃ¨le sur vos propres donnÃ©es, ce qui rend le modÃ¨le plus prÃ©cis et rÃ©actif Ã  vos besoins, mais cela peut Ãªtre coÃ»teux.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.fr.png)

Source image : [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering avec Contexte

Les LLM prÃ©-entraÃ®nÃ©s fonctionnent trÃ¨s bien sur des tÃ¢ches gÃ©nÃ©rales en langage naturel, mÃªme en les appelant avec un prompt court, comme une phrase Ã  complÃ©ter ou une question â€“ ce quâ€™on appelle lâ€™apprentissage â€œzero-shotâ€.

Cependant, plus lâ€™utilisateur peut cadrer sa requÃªte avec une demande dÃ©taillÃ©e et des exemples â€“ le Contexte â€“ plus la rÃ©ponse sera prÃ©cise et proche des attentes. On parle alors dâ€™apprentissage â€œone-shotâ€ si le prompt contient un seul exemple, et â€œfew-shotâ€ sâ€™il en contient plusieurs. Le prompt engineering avec contexte est lâ€™approche la plus Ã©conomique pour dÃ©buter.

### Retrieval Augmented Generation (RAG)

Les LLM ont la limitation de ne pouvoir utiliser que les donnÃ©es sur lesquelles ils ont Ã©tÃ© entraÃ®nÃ©s pour gÃ©nÃ©rer une rÃ©ponse. Cela signifie quâ€™ils ne connaissent rien des faits survenus aprÃ¨s leur entraÃ®nement, et quâ€™ils ne peuvent pas accÃ©der Ã  des informations non publiques (comme des donnÃ©es dâ€™entreprise).  
Cette limite peut Ãªtre contournÃ©e grÃ¢ce Ã  RAG, une technique qui enrichit le prompt avec des donnÃ©es externes sous forme de fragments de documents, en respectant les limites de longueur du prompt. Cela est rendu possible par des outils de bases de donnÃ©es vectorielles (comme [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) qui rÃ©cupÃ¨rent les fragments utiles Ã  partir de diffÃ©rentes sources de donnÃ©es prÃ©dÃ©finies et les ajoutent au contexte du prompt.

Cette technique est trÃ¨s utile lorsquâ€™une entreprise ne dispose pas de suffisamment de donnÃ©es, de temps ou de ressources pour fine-tuner un LLM, mais souhaite tout de mÃªme amÃ©liorer les performances sur une charge de travail spÃ©cifique et rÃ©duire les risques de fabrications, câ€™est-Ã -dire de distorsions de la rÃ©alitÃ© ou de contenus nuisibles.

### ModÃ¨le fine-tunÃ©

Le fine-tuning est un processus qui utilise le transfert dâ€™apprentissage pour â€˜adapterâ€™ le modÃ¨le Ã  une tÃ¢che spÃ©cifique ou rÃ©soudre un problÃ¨me particulier. Contrairement Ã  lâ€™apprentissage few-shot et Ã  RAG, il aboutit Ã  la crÃ©ation dâ€™un nouveau modÃ¨le avec des poids et biais mis Ã  jour. Il nÃ©cessite un ensemble dâ€™exemples dâ€™entraÃ®nement composÃ©s dâ€™une entrÃ©e unique (le prompt) et de sa sortie associÃ©e (la complÃ©tion).  
Cette approche est recommandÃ©e si :

- **Utilisation de modÃ¨les fine-tunÃ©s**. Une entreprise souhaite utiliser des modÃ¨les fine-tunÃ©s moins puissants (comme les modÃ¨les dâ€™embeddings) plutÃ´t que des modÃ¨les trÃ¨s performants, ce qui permet une solution plus Ã©conomique et rapide.

- **ConsidÃ©ration de la latence**. La latence est importante pour un cas dâ€™usage spÃ©cifique, donc il nâ€™est pas possible dâ€™utiliser des prompts trÃ¨s longs ou un nombre dâ€™exemples trop Ã©levÃ© qui ne rentre pas dans la limite de longueur du prompt.

- **Maintenir Ã  jour**. Une entreprise dispose de nombreuses donnÃ©es de haute qualitÃ© et dâ€™Ã©tiquettes fiables, ainsi que des ressources nÃ©cessaires pour maintenir ces donnÃ©es Ã  jour dans le temps.

### ModÃ¨le entraÃ®nÃ©

EntraÃ®ner un LLM depuis zÃ©ro est sans aucun doute lâ€™approche la plus difficile et la plus complexe Ã  adopter, nÃ©cessitant dâ€™Ã©normes quantitÃ©s de donnÃ©es, des ressources qualifiÃ©es et une puissance de calcul adaptÃ©e. Cette option ne devrait Ãªtre envisagÃ©e que dans un scÃ©nario oÃ¹ une entreprise a un cas dâ€™usage trÃ¨s spÃ©cifique au domaine et une grande quantitÃ© de donnÃ©es centrÃ©es sur ce domaine.

## VÃ©rification des connaissances

Quelle pourrait Ãªtre une bonne approche pour amÃ©liorer les rÃ©sultats de complÃ©tion dâ€™un LLM ?

1. Prompt engineering avec contexte  
1. RAG  
1. ModÃ¨le fine-tunÃ©

RÃ©ponse : 3, si vous disposez du temps, des ressources et de donnÃ©es de haute qualitÃ©, le fine-tuning est la meilleure option pour rester Ã  jour. Cependant, si vous cherchez Ã  amÃ©liorer les choses rapidement et que vous manquez de temps, il vaut la peine de considÃ©rer dâ€™abord RAG.

## ğŸš€ DÃ©fi

Informez-vous davantage sur la maniÃ¨re dont vous pouvez [utiliser RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pour votre entreprise.

## Excellent travail, continuez votre apprentissage

AprÃ¨s avoir terminÃ© cette leÃ§on, consultez notre [collection Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer Ã  approfondir vos connaissances en IA gÃ©nÃ©rative !

Rendez-vous Ã  la LeÃ§on 3 oÃ¹ nous verrons comment [construire avec lâ€™IA gÃ©nÃ©rative de maniÃ¨re responsable](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) !

**Avertissement** :  
Ce document a Ã©tÃ© traduit Ã  lâ€™aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions dâ€™assurer lâ€™exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue dâ€™origine doit Ãªtre considÃ©rÃ© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle rÃ©alisÃ©e par un humain est recommandÃ©e. Nous dÃ©clinons toute responsabilitÃ© en cas de malentendus ou de mauvaises interprÃ©tations rÃ©sultant de lâ€™utilisation de cette traduction.