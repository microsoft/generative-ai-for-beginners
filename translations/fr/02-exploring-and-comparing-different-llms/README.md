# Explorer et comparer diff√©rents LLM

[![Explorer et comparer diff√©rents LLM](../../../translated_images/02-lesson-banner.png?WT.96d85175e46909d65f6895923ed5f3ad0ae5e874792ccad49542fcfe8ebd12dd.fr.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Cliquez sur l'image ci-dessus pour visionner la vid√©o de cette le√ßon_

Dans la le√ßon pr√©c√©dente, nous avons vu comment l'IA g√©n√©rative change le paysage technologique, comment fonctionnent les grands mod√®les de langage (LLM) et comment une entreprise - comme notre startup - peut les appliquer √† ses cas d'utilisation et se d√©velopper ! Dans ce chapitre, nous cherchons √† comparer et √† contraster diff√©rents types de grands mod√®les de langage (LLM) pour comprendre leurs avantages et inconv√©nients.

La prochaine √©tape dans le parcours de notre startup est d'explorer le paysage actuel des LLM et de comprendre lesquels sont adapt√©s √† notre cas d'utilisation.

## Introduction

Cette le√ßon couvrira :

- Diff√©rents types de LLM dans le paysage actuel.
- Tester, it√©rer et comparer diff√©rents mod√®les pour votre cas d'utilisation dans Azure.
- Comment d√©ployer un LLM.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous serez capable de :

- S√©lectionner le bon mod√®le pour votre cas d'utilisation.
- Comprendre comment tester, it√©rer et am√©liorer les performances de votre mod√®le.
- Savoir comment les entreprises d√©ploient des mod√®les.

## Comprendre les diff√©rents types de LLM

Les LLM peuvent avoir plusieurs cat√©gorisations bas√©es sur leur architecture, leurs donn√©es d'entra√Ænement et leur cas d'utilisation. Comprendre ces diff√©rences aidera notre startup √† choisir le bon mod√®le pour le sc√©nario, et √† comprendre comment tester, it√©rer et am√©liorer les performances.

Il existe de nombreux types de mod√®les LLM diff√©rents, votre choix de mod√®le d√©pend de l'utilisation que vous souhaitez en faire, de vos donn√©es, du montant que vous √™tes pr√™t √† payer et plus encore.

Selon que vous souhaitez utiliser les mod√®les pour la g√©n√©ration de texte, d'audio, de vid√©o, d'images, etc., vous pourriez opter pour un type de mod√®le diff√©rent.

- **Reconnaissance audio et vocale**. Pour cela, les mod√®les de type Whisper sont un excellent choix car ils sont polyvalents et visent la reconnaissance vocale. Ils sont entra√Æn√©s sur divers audios et peuvent effectuer une reconnaissance vocale multilingue. En savoir plus sur [les mod√®les de type Whisper ici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **G√©n√©ration d'images**. Pour la g√©n√©ration d'images, DALL-E et Midjourney sont deux choix tr√®s connus. DALL-E est propos√© par Azure OpenAI. [Lisez-en plus sur DALL-E ici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) et aussi dans le chapitre 9 de ce programme.

- **G√©n√©ration de texte**. La plupart des mod√®les sont entra√Æn√©s sur la g√©n√©ration de texte et vous avez un large √©ventail de choix allant de GPT-3.5 √† GPT-4. Ils ont des co√ªts diff√©rents, GPT-4 √©tant le plus cher. Cela vaut la peine de regarder dans le [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pour √©valuer quels mod√®les correspondent le mieux √† vos besoins en termes de capacit√© et de co√ªt.

- **Multimodalit√©**. Si vous cherchez √† g√©rer plusieurs types de donn√©es en entr√©e et en sortie, vous pourriez vouloir regarder des mod√®les comme [gpt-4 turbo avec vision ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - les derni√®res versions des mod√®les OpenAI - qui sont capables de combiner le traitement du langage naturel √† la compr√©hension visuelle, permettant des interactions via des interfaces multimodales.

S√©lectionner un mod√®le signifie que vous obtenez certaines capacit√©s de base, qui pourraient ne pas √™tre suffisantes cependant. Souvent, vous avez des donn√©es sp√©cifiques √† l'entreprise que vous devez d'une mani√®re ou d'une autre communiquer au LLM. Il existe plusieurs choix sur la fa√ßon d'aborder cela, plus √† ce sujet dans les sections √† venir.

### Mod√®les de base versus LLM

Le terme mod√®le de base a √©t√© [invent√© par des chercheurs de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) et d√©fini comme un mod√®le d'IA qui suit certains crit√®res, tels que :

- **Ils sont entra√Æn√©s en utilisant l'apprentissage non supervis√© ou auto-supervis√©**, ce qui signifie qu'ils sont entra√Æn√©s sur des donn√©es multimodales non √©tiquet√©es, et qu'ils ne n√©cessitent pas d'annotation ou d'√©tiquetage humain des donn√©es pour leur processus d'entra√Ænement.
- **Ce sont des mod√®les tr√®s larges**, bas√©s sur des r√©seaux de neurones tr√®s profonds entra√Æn√©s sur des milliards de param√®tres.
- **Ils sont normalement destin√©s √† servir de ‚Äòbase‚Äô pour d'autres mod√®les**, ce qui signifie qu'ils peuvent √™tre utilis√©s comme point de d√©part pour d'autres mod√®les √† construire dessus, ce qui peut √™tre fait par ajustement fin.

![Mod√®les de base versus LLM](../../../translated_images/FoundationModel.png?WT.9690c2a9f6be278baf730a5b26ea901ac6d6ede04cad555ef2b59d774ba557eb.fr.mc_id=academic-105485-koreyst)

Source de l'image : [Guide essentiel des mod√®les de base et des grands mod√®les de langage | par Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pour clarifier davantage cette distinction, prenons ChatGPT comme exemple. Pour construire la premi√®re version de ChatGPT, un mod√®le appel√© GPT-3.5 a servi de mod√®le de base. Cela signifie qu'OpenAI a utilis√© des donn√©es sp√©cifiques au chat pour cr√©er une version ajust√©e de GPT-3.5 qui √©tait sp√©cialis√©e pour bien performer dans des sc√©narios conversationnels, tels que les chatbots.

![Mod√®le de base](../../../translated_images/Multimodal.png?WT.29151b07403f77b38d7dc2a3069f4c171198d59c9df6bdfccd4326c209db4432.fr.mc_id=academic-105485-koreyst)

Source de l'image : [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Mod√®les open source versus propri√©taires

Une autre fa√ßon de cat√©goriser les LLM est de savoir s'ils sont open source ou propri√©taires.

Les mod√®les open source sont des mod√®les qui sont mis √† disposition du public et peuvent √™tre utilis√©s par n'importe qui. Ils sont souvent mis √† disposition par l'entreprise qui les a cr√©√©s, ou par la communaut√© de recherche. Ces mod√®les peuvent √™tre inspect√©s, modifi√©s et personnalis√©s pour les divers cas d'utilisation dans les LLM. Cependant, ils ne sont pas toujours optimis√©s pour une utilisation en production, et peuvent ne pas √™tre aussi performants que les mod√®les propri√©taires. De plus, le financement des mod√®les open source peut √™tre limit√©, et ils peuvent ne pas √™tre maintenus √† long terme ou ne pas √™tre mis √† jour avec les derni√®res recherches. Des exemples de mod√®les open source populaires incluent [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) et [LLaMA](https://llama.meta.com).

Les mod√®les propri√©taires sont des mod√®les qui appartiennent √† une entreprise et ne sont pas mis √† disposition du public. Ces mod√®les sont souvent optimis√©s pour une utilisation en production. Cependant, ils ne peuvent pas √™tre inspect√©s, modifi√©s ou personnalis√©s pour diff√©rents cas d'utilisation. De plus, ils ne sont pas toujours disponibles gratuitement, et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s. De plus, les utilisateurs n'ont pas le contr√¥le sur les donn√©es utilis√©es pour entra√Æner le mod√®le, ce qui signifie qu'ils doivent faire confiance au propri√©taire du mod√®le pour garantir l'engagement en mati√®re de confidentialit√© des donn√©es et d'utilisation responsable de l'IA. Des exemples de mod√®les propri√©taires populaires incluent [OpenAI models](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus g√©n√©ration d'images versus g√©n√©ration de texte et de code

Les LLM peuvent √©galement √™tre cat√©goris√©s par la sortie qu'ils g√©n√®rent.

Les embeddings sont un ensemble de mod√®les qui peuvent convertir du texte en une forme num√©rique, appel√©e embedding, qui est une repr√©sentation num√©rique du texte d'entr√©e. Les embeddings facilitent la compr√©hension par les machines des relations entre les mots ou les phrases et peuvent √™tre consomm√©s comme entr√©es par d'autres mod√®les, tels que les mod√®les de classification, ou les mod√®les de clustering qui ont de meilleures performances sur les donn√©es num√©riques. Les mod√®les d'embedding sont souvent utilis√©s pour l'apprentissage par transfert, o√π un mod√®le est construit pour une t√¢che de substitution pour laquelle il y a une abondance de donn√©es, puis les poids du mod√®le (embeddings) sont r√©utilis√©s pour d'autres t√¢ches en aval. Un exemple de cette cat√©gorie est [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.png?WT.15a2282d046c6d94a54f553fa9e7f19e3ef0e65f9eb05f4d476a5d28b2dead18.fr.mc_id=academic-105485-koreyst)

Les mod√®les de g√©n√©ration d'images sont des mod√®les qui g√©n√®rent des images. Ces mod√®les sont souvent utilis√©s pour l'√©dition d'images, la synth√®se d'images et la traduction d'images. Les mod√®les de g√©n√©ration d'images sont souvent entra√Æn√©s sur de grands ensembles de donn√©es d'images, tels que [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer de nouvelles images ou pour √©diter des images existantes avec des techniques de inpainting, de super-r√©solution et de colorisation. Des exemples incluent [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) et [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![G√©n√©ration d'images](../../../translated_images/Image.png?WT.6a1995ff7d9be5a713e6aaee5f1625f31620756937c283e292ef5ffe1e30ed11.fr.mc_id=academic-105485-koreyst)

Les mod√®les de g√©n√©ration de texte et de code sont des mod√®les qui g√©n√®rent du texte ou du code. Ces mod√®les sont souvent utilis√©s pour la synth√®se de texte, la traduction et la r√©ponse √† des questions. Les mod√®les de g√©n√©ration de texte sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de texte, tels que [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau texte ou pour r√©pondre √† des questions. Les mod√®les de g√©n√©ration de code, comme [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de code, tels que GitHub, et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau code ou pour corriger des bugs dans du code existant.

![G√©n√©ration de texte et de code](../../../translated_images/Text.png?WT.b55b7b9b96faac1d758fb555436c56c5a323a55743b75e70198160caca3fb73c.fr.mc_id=academic-105485-koreyst)

### Encodeur-D√©codeur versus D√©codeur uniquement

Pour parler des diff√©rents types d'architectures de LLM, utilisons une analogie.

Imaginez que votre manager vous ait donn√© la t√¢che de r√©diger un quiz pour les √©tudiants. Vous avez deux coll√®gues ; l'un s'occupe de cr√©er le contenu et l'autre de le r√©viser.

Le cr√©ateur de contenu est comme un mod√®le D√©codeur uniquement, il peut regarder le sujet et voir ce que vous avez d√©j√† √©crit, puis il peut r√©diger un cours bas√© l√†-dessus. Ils sont tr√®s bons pour √©crire un contenu engageant et informatif, mais ils ne sont pas tr√®s bons pour comprendre le sujet et les objectifs d'apprentissage. Quelques exemples de mod√®les D√©codeur sont les mod√®les de la famille GPT, tels que GPT-3.

Le r√©viseur est comme un mod√®le Encodeur uniquement, il regarde le cours √©crit et les r√©ponses, remarquant la relation entre eux et comprenant le contexte, mais il n'est pas bon pour g√©n√©rer du contenu. Un exemple de mod√®le Encodeur uniquement serait BERT.

Imaginez que nous puissions √©galement avoir quelqu'un qui pourrait cr√©er et r√©viser le quiz, c'est un mod√®le Encodeur-D√©codeur. Quelques exemples seraient BART et T5.

### Service versus Mod√®le

Maintenant, parlons de la diff√©rence entre un service et un mod√®le. Un service est un produit offert par un fournisseur de services cloud, et est souvent une combinaison de mod√®les, de donn√©es et d'autres composants. Un mod√®le est le composant central d'un service, et est souvent un mod√®le de base, tel qu'un LLM.

Les services sont souvent optimis√©s pour une utilisation en production et sont souvent plus faciles √† utiliser que les mod√®les, via une interface utilisateur graphique. Cependant, les services ne sont pas toujours disponibles gratuitement, et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s, en √©change de l'utilisation des √©quipements et ressources du propri√©taire du service, optimisant les d√©penses et √©voluant facilement. Un exemple de service est [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), qui propose un plan tarifaire √† la consommation, ce qui signifie que les utilisateurs sont factur√©s proportionnellement √† leur utilisation du service. De plus, Azure OpenAI Service offre une s√©curit√© de niveau entreprise et un cadre d'IA responsable en plus des capacit√©s des mod√®les.

Les mod√®les ne sont que le r√©seau de neurones, avec les param√®tres, les poids et autres. Permettant aux entreprises de fonctionner localement, cependant, elles auraient besoin d'acheter de l'√©quipement, de construire une structure pour √©voluer et d'acheter une licence ou d'utiliser un mod√®le open source. Un mod√®le comme LLaMA est disponible pour √™tre utilis√©, n√©cessitant une puissance de calcul pour ex√©cuter le mod√®le.

## Comment tester et it√©rer avec diff√©rents mod√®les pour comprendre les performances sur Azure

Une fois que notre √©quipe a explor√© le paysage actuel des LLM et identifi√© de bons candidats pour leurs sc√©narios, la prochaine √©tape est de les tester sur leurs donn√©es et sur leur charge de travail. C'est un processus it√©ratif, r√©alis√© par des exp√©riences et des mesures. La plupart des mod√®les que nous avons mentionn√©s dans les paragraphes pr√©c√©dents (mod√®les OpenAI, mod√®les open source comme Llama2, et transformers Hugging Face) sont disponibles dans le [Catalogue de mod√®les](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) dans [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) est une plateforme cloud con√ßue pour les d√©veloppeurs pour construire des applications d'IA g√©n√©rative et g√©rer tout le cycle de d√©veloppement - de l'exp√©rimentation √† l'√©valuation - en combinant tous les services Azure AI dans un seul hub avec une interface utilisateur pratique. Le Catalogue de mod√®les dans Azure AI Studio permet √† l'utilisateur de :

- Trouver le mod√®le de base d'int√©r√™t dans le catalogue - soit propri√©taire soit open source, en filtrant par t√¢che, licence ou nom. Pour am√©liorer la recherche, les mod√®les sont organis√©s en collections, comme la collection Azure OpenAI, la collection Hugging Face, et plus encore.

![Catalogue de mod√®les](../../../translated_images/AzureAIStudioModelCatalog.png?WT.cd7b78fc6a7b010869adb0defabce1ea5fbe62131aa7f59e54a083be8d789d24.fr.mc_id=academic-105485-koreyst)

- Examiner la carte du mod√®le, y compris une description d√©taill√©e de l'utilisation pr√©vue et des donn√©es d'entra√Ænement, des exemples de code et des r√©sultats d'√©valuation sur la biblioth√®que d'√©valuations internes.

![Carte du mod√®le](../../../translated_images/ModelCard.png?WT.cd385d3d0228f86cef5987e3074be75f377a95ba505d6805f7c6965dc5972693.fr.mc_id=academic-105485-koreyst)
- Comparez les benchmarks entre les mod√®les et les ensembles de donn√©es disponibles dans l'industrie pour √©valuer lequel r√©pond au sc√©nario commercial, via le volet [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarks des mod√®les](../../../translated_images/ModelBenchmarks.png?WT.634f688bb2a74b3c90a9212ecfb9b99045405b2414be3d17429cfea319c06f61.fr.mc_id=academic-105485-koreyst)

- Affinez le mod√®le sur des donn√©es d'entra√Ænement personnalis√©es pour am√©liorer les performances du mod√®le dans une charge de travail sp√©cifique, en tirant parti des capacit√©s d'exp√©rimentation et de suivi d'Azure AI Studio.

![Affinement du mod√®le](../../../translated_images/FineTuning.png?WT.523a6ab7580c924e42e8478d072fb670f879033779b8ab5a6abb155d2fc63d5a.fr.mc_id=academic-105485-koreyst)

- D√©ployez le mod√®le pr√©-entra√Æn√© original ou la version affin√©e vers une inf√©rence en temps r√©el √† distance - calcul g√©r√© - ou un point de terminaison API sans serveur - [paiement √† l'utilisation](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - pour permettre aux applications de l'utiliser.

![D√©ploiement du mod√®le](../../../translated_images/ModelDeploy.png?WT.a765ca6b7a396eb5d2fd346f8a211542f6fe578e2218bbe16f9fcdb5ca8f3661.fr.mc_id=academic-105485-koreyst)

> [!NOTE]
> Tous les mod√®les du catalogue ne sont pas actuellement disponibles pour l'affinement et/ou le d√©ploiement √† la demande. Consultez la fiche du mod√®le pour conna√Ætre les capacit√©s et les limitations du mod√®le.

## Am√©liorer les r√©sultats des LLM

Nous avons explor√© avec notre √©quipe de startup diff√©rents types de LLM et une plateforme Cloud (Azure Machine Learning) qui nous permet de comparer diff√©rents mod√®les, de les √©valuer sur des donn√©es de test, d'am√©liorer les performances et de les d√©ployer sur des points de terminaison d'inf√©rence.

Mais quand devraient-ils envisager d'affiner un mod√®le plut√¥t que d'utiliser un mod√®le pr√©-entra√Æn√© ? Existe-t-il d'autres approches pour am√©liorer les performances du mod√®le sur des charges de travail sp√©cifiques ?

Il existe plusieurs approches qu'une entreprise peut utiliser pour obtenir les r√©sultats dont elle a besoin √† partir d'un LLM. Vous pouvez s√©lectionner diff√©rents types de mod√®les avec diff√©rents degr√©s d'entra√Ænement lors du d√©ploiement d'un LLM en production, avec diff√©rents niveaux de complexit√©, de co√ªt et de qualit√©. Voici quelques approches diff√©rentes :

- **Conception de prompts avec contexte**. L'id√©e est de fournir suffisamment de contexte lorsque vous faites un prompt pour vous assurer d'obtenir les r√©ponses dont vous avez besoin.

- **G√©n√©ration augment√©e par r√©cup√©ration, RAG**. Vos donn√©es peuvent exister dans une base de donn√©es ou un point de terminaison web par exemple, pour garantir que ces donn√©es, ou un sous-ensemble de celles-ci, soient incluses au moment du prompt, vous pouvez r√©cup√©rer les donn√©es pertinentes et les int√©grer dans le prompt de l'utilisateur.

- **Mod√®le affin√©**. Ici, vous avez entra√Æn√© le mod√®le davantage sur vos propres donn√©es, ce qui rend le mod√®le plus pr√©cis et r√©actif √† vos besoins, mais cela peut √™tre co√ªteux.

![D√©ploiement des LLMs](../../../translated_images/Deploy.png?WT.0eeb36a208bf2bf97ea1058e54c74e13f5c810679cd7f3600cb2084b98d737be.fr.mc_id=academic-105485-koreyst)

Source de l'image : [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Conception de Prompts avec Contexte

Les LLM pr√©-entra√Æn√©s fonctionnent tr√®s bien sur des t√¢ches g√©n√©rales de langage naturel, m√™me en les appelant avec un court prompt, comme une phrase √† compl√©ter ou une question ‚Äì le soi-disant apprentissage "z√©ro-shot".

Cependant, plus l'utilisateur peut formuler sa requ√™te, avec une demande d√©taill√©e et des exemples ‚Äì le Contexte ‚Äì plus la r√©ponse sera pr√©cise et proche des attentes de l'utilisateur. Dans ce cas, on parle d'apprentissage "one-shot" si le prompt inclut un seul exemple et d'apprentissage "few-shot" s'il inclut plusieurs exemples. La conception de prompts avec contexte est l'approche la plus rentable pour commencer.

### G√©n√©ration Augment√©e par R√©cup√©ration (RAG)

Les LLM ont la limitation de ne pouvoir utiliser que les donn√©es qui ont √©t√© utilis√©es lors de leur entra√Ænement pour g√©n√©rer une r√©ponse. Cela signifie qu'ils ne savent rien des faits survenus apr√®s leur processus d'entra√Ænement et qu'ils ne peuvent pas acc√©der √† des informations non publiques (comme les donn√©es de l'entreprise). Cela peut √™tre surmont√© gr√¢ce √† la RAG, une technique qui augmente le prompt avec des donn√©es externes sous forme de morceaux de documents, en tenant compte des limites de longueur du prompt. Cela est soutenu par des outils de base de donn√©es vectorielle (comme [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) qui r√©cup√®rent les morceaux utiles √† partir de diverses sources de donn√©es pr√©d√©finies et les ajoutent au Contexte du prompt.

Cette technique est tr√®s utile lorsqu'une entreprise n'a pas assez de donn√©es, de temps ou de ressources pour affiner un LLM, mais souhaite tout de m√™me am√©liorer les performances sur une charge de travail sp√©cifique et r√©duire les risques de fabrications, c'est-√†-dire la mystification de la r√©alit√© ou du contenu nuisible.

### Mod√®le Affin√©

L'affinement est un processus qui tire parti de l'apprentissage par transfert pour "adapter" le mod√®le √† une t√¢che en aval ou pour r√©soudre un probl√®me sp√©cifique. Contrairement √† l'apprentissage few-shot et √† la RAG, il en r√©sulte un nouveau mod√®le g√©n√©r√©, avec des poids et des biais mis √† jour. Il n√©cessite un ensemble d'exemples d'entra√Ænement compos√© d'une seule entr√©e (le prompt) et de sa sortie associ√©e (la compl√©tion). Cette approche serait pr√©f√©r√©e si :

- **Utilisation de mod√®les affin√©s**. Une entreprise souhaite utiliser des mod√®les affin√©s moins performants (comme les mod√®les d'int√©gration) plut√¥t que des mod√®les √† haute performance, ce qui donne une solution plus rentable et rapide.

- **Consid√©ration de la latence**. La latence est importante pour un cas d'utilisation sp√©cifique, donc il n'est pas possible d'utiliser des prompts tr√®s longs ou le nombre d'exemples qui devraient √™tre appris par le mod√®le ne correspond pas √† la limite de longueur du prompt.

- **Rester √† jour**. Une entreprise dispose de beaucoup de donn√©es de haute qualit√© et d'√©tiquettes de v√©rit√© terrain et des ressources n√©cessaires pour maintenir ces donn√©es √† jour au fil du temps.

### Mod√®le Entra√Æn√©

Entra√Æner un LLM √† partir de z√©ro est sans aucun doute l'approche la plus difficile et la plus complexe √† adopter, n√©cessitant des quantit√©s massives de donn√©es, des ressources qualifi√©es et une puissance de calcul appropri√©e. Cette option devrait √™tre envisag√©e uniquement dans un sc√©nario o√π une entreprise a un cas d'utilisation sp√©cifique au domaine et une grande quantit√© de donn√©es centr√©es sur le domaine.

## V√©rification des connaissances

Quelle pourrait √™tre une bonne approche pour am√©liorer les r√©sultats de compl√©tion des LLM ?

1. Conception de prompts avec contexte
2. RAG
3. Mod√®le affin√©

A:3, si vous avez le temps et les ressources et des donn√©es de haute qualit√©, l'affinement est la meilleure option pour rester √† jour. Cependant, si vous cherchez √† am√©liorer les choses et que vous manquez de temps, il vaut la peine de consid√©rer d'abord la RAG.

## üöÄ D√©fi

Renseignez-vous davantage sur comment vous pouvez [utiliser la RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pour votre entreprise.

## Bon travail, continuez votre apprentissage

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage sur l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† approfondir vos connaissances en IA g√©n√©rative !

Rendez-vous √† la le√ßon 3 o√π nous verrons comment [construire avec l'IA g√©n√©rative de mani√®re responsable](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) !

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide de services de traduction automatique bas√©s sur l'intelligence artificielle. Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.