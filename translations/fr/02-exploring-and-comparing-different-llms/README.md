<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T22:39:57+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "fr"
}
-->
# Explorer et comparer diff√©rents LLM

[![Explorer et comparer diff√©rents LLM](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.fr.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Cliquez sur l'image ci-dessus pour visionner la vid√©o de cette le√ßon_

Dans la le√ßon pr√©c√©dente, nous avons vu comment l'IA g√©n√©rative transforme le paysage technologique, comment fonctionnent les mod√®les de langage √©tendus (LLM) et comment une entreprise - comme notre startup - peut les appliquer √† ses cas d'utilisation et se d√©velopper ! Dans ce chapitre, nous allons comparer et contraster diff√©rents types de mod√®les de langage √©tendus (LLM) pour comprendre leurs avantages et inconv√©nients.

La prochaine √©tape dans le parcours de notre startup est d'explorer le paysage actuel des LLM et de comprendre lesquels sont adapt√©s √† notre cas d'utilisation.

## Introduction

Cette le√ßon couvrira :

- Les diff√©rents types de LLM dans le paysage actuel.
- Tester, it√©rer et comparer diff√©rents mod√®les pour votre cas d'utilisation dans Azure.
- Comment d√©ployer un LLM.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous serez capable de :

- Choisir le bon mod√®le pour votre cas d'utilisation.
- Comprendre comment tester, it√©rer et am√©liorer les performances de votre mod√®le.
- Savoir comment les entreprises d√©ploient des mod√®les.

## Comprendre les diff√©rents types de LLM

Les LLM peuvent √™tre class√©s de diff√©rentes mani√®res en fonction de leur architecture, de leurs donn√©es d'entra√Ænement et de leur cas d'utilisation. Comprendre ces diff√©rences aidera notre startup √† choisir le bon mod√®le pour le sc√©nario et √† comprendre comment tester, it√©rer et am√©liorer les performances.

Il existe de nombreux types de mod√®les LLM, et votre choix d√©pend de ce que vous souhaitez en faire, de vos donn√©es, de votre budget et d'autres facteurs.

Selon que vous souhaitez utiliser les mod√®les pour la g√©n√©ration de texte, d'audio, de vid√©o, d'images, etc., vous pourriez opter pour un type de mod√®le diff√©rent.

- **Reconnaissance audio et vocale**. Pour cet usage, les mod√®les de type Whisper sont un excellent choix car ils sont polyvalents et con√ßus pour la reconnaissance vocale. Ils sont entra√Æn√©s sur des donn√©es audio vari√©es et peuvent effectuer une reconnaissance vocale multilingue. En savoir plus sur les [mod√®les de type Whisper ici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **G√©n√©ration d'images**. Pour la g√©n√©ration d'images, DALL-E et Midjourney sont deux choix tr√®s connus. DALL-E est propos√© par Azure OpenAI. [En savoir plus sur DALL-E ici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) et √©galement dans le chapitre 9 de ce programme.

- **G√©n√©ration de texte**. La plupart des mod√®les sont entra√Æn√©s pour la g√©n√©ration de texte et vous avez un large choix allant de GPT-3.5 √† GPT-4. Ils ont des co√ªts diff√©rents, GPT-4 √©tant le plus cher. Il est int√©ressant de consulter le [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pour √©valuer quels mod√®les conviennent le mieux √† vos besoins en termes de capacit√©s et de co√ªt.

- **Multimodalit√©**. Si vous cherchez √† g√©rer plusieurs types de donn√©es en entr√©e et en sortie, vous pourriez envisager des mod√®les comme [gpt-4 turbo avec vision ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - les derni√®res versions des mod√®les OpenAI - qui sont capables de combiner le traitement du langage naturel avec la compr√©hension visuelle, permettant des interactions via des interfaces multimodales.

Choisir un mod√®le signifie obtenir certaines capacit√©s de base, qui peuvent cependant ne pas √™tre suffisantes. Souvent, vous disposez de donn√©es sp√©cifiques √† votre entreprise que vous devez transmettre au LLM d'une mani√®re ou d'une autre. Il existe plusieurs approches pour cela, que nous aborderons dans les sections suivantes.

### Mod√®les de base versus LLM

Le terme "mod√®le de base" a √©t√© [invent√© par des chercheurs de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) et d√©fini comme un mod√®le d'IA r√©pondant √† certains crit√®res, tels que :

- **Ils sont entra√Æn√©s en utilisant l'apprentissage non supervis√© ou l'apprentissage auto-supervis√©**, ce qui signifie qu'ils sont entra√Æn√©s sur des donn√©es multimodales non √©tiquet√©es et qu'ils ne n√©cessitent pas d'annotation ou de labellisation humaine des donn√©es pour leur processus d'entra√Ænement.
- **Ce sont des mod√®les tr√®s volumineux**, bas√©s sur des r√©seaux neuronaux tr√®s profonds entra√Æn√©s sur des milliards de param√®tres.
- **Ils sont g√©n√©ralement destin√©s √† servir de "fondation" pour d'autres mod√®les**, ce qui signifie qu'ils peuvent √™tre utilis√©s comme point de d√©part pour construire d'autres mod√®les par le biais de l'affinage.

![Mod√®les de base versus LLM](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.fr.png)

Source de l'image : [Essential Guide to Foundation Models and Large Language Models | par Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pour clarifier davantage cette distinction, prenons ChatGPT comme exemple. Pour construire la premi√®re version de ChatGPT, un mod√®le appel√© GPT-3.5 a servi de mod√®le de base. Cela signifie qu'OpenAI a utilis√© des donn√©es sp√©cifiques aux conversations pour cr√©er une version ajust√©e de GPT-3.5, sp√©cialis√©e dans les sc√©narios conversationnels, tels que les chatbots.

![Mod√®le de base](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.fr.png)

Source de l'image : [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Mod√®les open source versus propri√©taires

Une autre fa√ßon de cat√©goriser les LLM est de savoir s'ils sont open source ou propri√©taires.

Les mod√®les open source sont des mod√®les mis √† disposition du public et peuvent √™tre utilis√©s par tout le monde. Ils sont souvent propos√©s par l'entreprise qui les a cr√©√©s ou par la communaut√© de recherche. Ces mod√®les peuvent √™tre inspect√©s, modifi√©s et personnalis√©s pour divers cas d'utilisation des LLM. Cependant, ils ne sont pas toujours optimis√©s pour une utilisation en production et peuvent ne pas √™tre aussi performants que les mod√®les propri√©taires. De plus, le financement des mod√®les open source peut √™tre limit√©, et ils peuvent ne pas √™tre maintenus √† long terme ou mis √† jour avec les derni√®res recherches. Des exemples de mod√®les open source populaires incluent [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) et [LLaMA](https://llama.meta.com).

Les mod√®les propri√©taires sont des mod√®les d√©tenus par une entreprise et ne sont pas mis √† disposition du public. Ces mod√®les sont souvent optimis√©s pour une utilisation en production. Cependant, ils ne peuvent pas √™tre inspect√©s, modifi√©s ou personnalis√©s pour diff√©rents cas d'utilisation. De plus, ils ne sont pas toujours disponibles gratuitement et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s. Les utilisateurs n'ont pas non plus de contr√¥le sur les donn√©es utilis√©es pour entra√Æner le mod√®le, ce qui signifie qu'ils doivent faire confiance au propri√©taire du mod√®le pour garantir l'engagement envers la confidentialit√© des donn√©es et l'utilisation responsable de l'IA. Des exemples de mod√®les propri√©taires populaires incluent [OpenAI models](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus g√©n√©ration d'images versus g√©n√©ration de texte et de code

Les LLM peuvent √©galement √™tre cat√©goris√©s en fonction du type de sortie qu'ils g√©n√®rent.

Les embeddings sont un ensemble de mod√®les capables de convertir du texte en une forme num√©rique, appel√©e embedding, qui est une repr√©sentation num√©rique du texte d'entr√©e. Les embeddings facilitent la compr√©hension des relations entre les mots ou les phrases par les machines et peuvent √™tre utilis√©s comme entr√©es par d'autres mod√®les, tels que les mod√®les de classification ou de regroupement qui ont de meilleures performances sur les donn√©es num√©riques. Les mod√®les d'embedding sont souvent utilis√©s pour l'apprentissage par transfert, o√π un mod√®le est construit pour une t√¢che de substitution pour laquelle il existe une abondance de donn√©es, puis les poids du mod√®le (embeddings) sont r√©utilis√©s pour d'autres t√¢ches en aval. Un exemple de cette cat√©gorie est [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.fr.png)

Les mod√®les de g√©n√©ration d'images sont des mod√®les qui g√©n√®rent des images. Ces mod√®les sont souvent utilis√©s pour l'√©dition d'images, la synth√®se d'images et la traduction d'images. Les mod√®les de g√©n√©ration d'images sont souvent entra√Æn√©s sur de grands ensembles de donn√©es d'images, tels que [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer de nouvelles images ou pour √©diter des images existantes avec des techniques de retouche, de super-r√©solution et de colorisation. Des exemples incluent [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) et [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![G√©n√©ration d'images](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.fr.png)

Les mod√®les de g√©n√©ration de texte et de code sont des mod√®les qui g√©n√®rent du texte ou du code. Ces mod√®les sont souvent utilis√©s pour la synth√®se de texte, la traduction et la r√©ponse aux questions. Les mod√®les de g√©n√©ration de texte sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de texte, tels que [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau texte ou pour r√©pondre √† des questions. Les mod√®les de g√©n√©ration de code, comme [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sont souvent entra√Æn√©s sur de grands ensembles de donn√©es de code, tels que GitHub, et peuvent √™tre utilis√©s pour g√©n√©rer du nouveau code ou pour corriger des bugs dans du code existant.

![G√©n√©ration de texte et de code](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.fr.png)

### Encodeur-D√©codeur versus D√©codeur uniquement

Pour parler des diff√©rents types d'architectures des LLM, utilisons une analogie.

Imaginez que votre responsable vous confie la t√¢che de r√©diger un quiz pour les √©tudiants. Vous avez deux coll√®gues : l'un s'occupe de cr√©er le contenu et l'autre de le r√©viser.

Le cr√©ateur de contenu est comme un mod√®le D√©codeur uniquement, il peut regarder le sujet et voir ce que vous avez d√©j√† √©crit, puis r√©diger un cours en fonction de cela. Il est tr√®s dou√© pour r√©diger un contenu engageant et informatif, mais il n'est pas tr√®s bon pour comprendre le sujet et les objectifs d'apprentissage. Quelques exemples de mod√®les D√©codeur uniquement sont les mod√®les de la famille GPT, comme GPT-3.

Le r√©viseur est comme un mod√®le Encodeur uniquement, il examine le cours √©crit et les r√©ponses, remarque les relations entre eux et comprend le contexte, mais il n'est pas bon pour g√©n√©rer du contenu. Un exemple de mod√®le Encodeur uniquement serait BERT.

Imaginez que nous puissions √©galement avoir quelqu'un capable de cr√©er et de r√©viser le quiz, ce serait un mod√®le Encodeur-D√©codeur. Quelques exemples seraient BART et T5.

### Service versus Mod√®le

Parlons maintenant de la diff√©rence entre un service et un mod√®le. Un service est un produit propos√© par un fournisseur de services cloud, et est souvent une combinaison de mod√®les, de donn√©es et d'autres composants. Un mod√®le est le composant central d'un service, et est souvent un mod√®le de base, tel qu'un LLM.

Les services sont souvent optimis√©s pour une utilisation en production et sont souvent plus faciles √† utiliser que les mod√®les, via une interface utilisateur graphique. Cependant, les services ne sont pas toujours disponibles gratuitement et peuvent n√©cessiter un abonnement ou un paiement pour √™tre utilis√©s, en √©change de l'utilisation des √©quipements et des ressources du propri√©taire du service, optimisant ainsi les d√©penses et facilitant la mise √† l'√©chelle. Un exemple de service est [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), qui propose un plan tarifaire √† la consommation, ce qui signifie que les utilisateurs sont factur√©s proportionnellement √† leur utilisation du service. De plus, Azure OpenAI Service offre une s√©curit√© de niveau entreprise et un cadre d'IA responsable en plus des capacit√©s des mod√®les.

Les mod√®les ne sont que le r√©seau neuronal, avec les param√®tres, les poids, et autres. Permettre aux entreprises de les ex√©cuter localement n√©cessiterait cependant d'acheter des √©quipements, de construire une structure pour √©voluer et d'acheter une licence ou d'utiliser un mod√®le open source. Un mod√®le comme LLaMA est disponible pour √™tre utilis√©, n√©cessitant une puissance de calcul pour ex√©cuter le mod√®le.

## Comment tester et it√©rer avec diff√©rents mod√®les pour comprendre les performances sur Azure

Une fois que notre √©quipe a explor√© le paysage actuel des LLM et identifi√© quelques bons candidats pour leurs sc√©narios, l'√©tape suivante consiste √† les tester sur leurs donn√©es et sur leur charge de travail. C'est un processus it√©ratif, r√©alis√© par des exp√©riences et des mesures.
La plupart des mod√®les mentionn√©s dans les paragraphes pr√©c√©dents (mod√®les OpenAI, mod√®les open source comme Llama2 et transformers de Hugging Face) sont disponibles dans le [Catalogue de Mod√®les](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) dans [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) est une plateforme cloud con√ßue pour les d√©veloppeurs afin de cr√©er des applications d'IA g√©n√©rative et de g√©rer tout le cycle de d√©veloppement - de l'exp√©rimentation √† l'√©valuation - en combinant tous les services Azure AI dans un hub unique avec une interface utilisateur pratique. Le Catalogue de Mod√®les dans Azure AI Studio permet √† l'utilisateur de :

- Trouver le mod√®le de base d'int√©r√™t dans le catalogue - qu'il soit propri√©taire ou open source, en filtrant par t√¢che, licence ou nom. Pour am√©liorer la recherche, les mod√®les sont organis√©s en collections, comme la collection Azure OpenAI, la collection Hugging Face, et plus encore.

![Catalogue de mod√®les](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.fr.png)

- Examiner la fiche du mod√®le, incluant une description d√©taill√©e de l'utilisation pr√©vue et des donn√©es d'entra√Ænement, des exemples de code et des r√©sultats d'√©valuation dans la biblioth√®que d'√©valuations internes.

![Fiche du mod√®le](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.fr.png)

- Comparer les benchmarks entre les mod√®les et les ensembles de donn√©es disponibles dans l'industrie pour √©valuer lequel r√©pond le mieux au sc√©nario commercial, via le volet [Benchmarks de Mod√®les](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarks de mod√®les](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.fr.png)

- Affiner le mod√®le avec des donn√©es d'entra√Ænement personnalis√©es pour am√©liorer les performances du mod√®le dans une charge de travail sp√©cifique, en utilisant les capacit√©s d'exp√©rimentation et de suivi d'Azure AI Studio.

![Affinage du mod√®le](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.fr.png)

- D√©ployer le mod√®le pr√©-entra√Æn√© original ou la version affin√©e pour une inf√©rence en temps r√©el √† distance - calcul g√©r√© - ou un point de terminaison API sans serveur - [paiement √† l'utilisation](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - pour permettre aux applications de l'utiliser.

![D√©ploiement du mod√®le](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.fr.png)

> [!NOTE]
> Tous les mod√®les du catalogue ne sont pas actuellement disponibles pour l'affinage et/ou le d√©ploiement en paiement √† l'utilisation. Consultez la fiche du mod√®le pour les d√©tails sur les capacit√©s et les limitations du mod√®le.

## Am√©liorer les r√©sultats des LLM

Nous avons explor√© avec notre √©quipe de startup diff√©rents types de LLM et une plateforme cloud (Azure Machine Learning) nous permettant de comparer diff√©rents mod√®les, de les √©valuer sur des donn√©es de test, d'am√©liorer leurs performances et de les d√©ployer sur des points de terminaison d'inf√©rence.

Mais quand faut-il envisager d'affiner un mod√®le plut√¥t que d'utiliser un mod√®le pr√©-entra√Æn√© ? Existe-t-il d'autres approches pour am√©liorer les performances du mod√®le sur des charges de travail sp√©cifiques ?

Il existe plusieurs approches qu'une entreprise peut utiliser pour obtenir les r√©sultats souhait√©s d'un LLM. Vous pouvez choisir diff√©rents types de mod√®les avec diff√©rents degr√©s d'entra√Ænement lors du d√©ploiement d'un LLM en production, avec divers niveaux de complexit√©, de co√ªt et de qualit√©. Voici quelques approches diff√©rentes :

- **Ing√©nierie des prompts avec contexte**. L'id√©e est de fournir suffisamment de contexte lors de la requ√™te pour garantir d'obtenir les r√©ponses souhait√©es.

- **G√©n√©ration augment√©e par r√©cup√©ration, RAG**. Vos donn√©es peuvent exister dans une base de donn√©es ou un point de terminaison web, par exemple. Pour garantir que ces donn√©es, ou un sous-ensemble de celles-ci, soient incluses au moment de la requ√™te, vous pouvez r√©cup√©rer les donn√©es pertinentes et les inclure dans le prompt de l'utilisateur.

- **Mod√®le affin√©**. Ici, vous avez entra√Æn√© davantage le mod√®le sur vos propres donn√©es, ce qui le rend plus pr√©cis et adapt√© √† vos besoins, mais cela peut √™tre co√ªteux.

![D√©ploiement des LLM](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.fr.png)

Source de l'image : [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ing√©nierie des prompts avec contexte

Les LLM pr√©-entra√Æn√©s fonctionnent tr√®s bien sur des t√¢ches g√©n√©rales de traitement du langage naturel, m√™me lorsqu'ils sont appel√©s avec un prompt court, comme une phrase √† compl√©ter ou une question ‚Äì ce qu'on appelle l'apprentissage "zero-shot".

Cependant, plus l'utilisateur peut formuler sa requ√™te avec une demande d√©taill√©e et des exemples ‚Äì le contexte ‚Äì plus la r√©ponse sera pr√©cise et proche des attentes de l'utilisateur. Dans ce cas, on parle d'apprentissage "one-shot" si le prompt inclut un seul exemple et d'"apprentissage par quelques exemples" si plusieurs exemples sont inclus. L'ing√©nierie des prompts avec contexte est l'approche la plus √©conomique pour commencer.

### G√©n√©ration augment√©e par r√©cup√©ration (RAG)

Les LLM ont la limitation de ne pouvoir utiliser que les donn√©es qui ont √©t√© utilis√©es lors de leur entra√Ænement pour g√©n√©rer une r√©ponse. Cela signifie qu'ils ne savent rien des faits survenus apr√®s leur processus d'entra√Ænement et qu'ils ne peuvent pas acc√©der √† des informations non publiques (comme les donn√©es d'entreprise).  
Cela peut √™tre surmont√© gr√¢ce √† la RAG, une technique qui augmente le prompt avec des donn√©es externes sous forme de fragments de documents, en tenant compte des limites de longueur du prompt. Cela est soutenu par des outils de base de donn√©es vectorielle (comme [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) qui r√©cup√®rent les fragments utiles √† partir de diverses sources de donn√©es pr√©d√©finies et les ajoutent au contexte du prompt.

Cette technique est tr√®s utile lorsqu'une entreprise n'a pas assez de donn√©es, de temps ou de ressources pour affiner un LLM, mais souhaite tout de m√™me am√©liorer les performances sur une charge de travail sp√©cifique et r√©duire les risques de fabrications, c'est-√†-dire de mystification de la r√©alit√© ou de contenu nuisible.

### Mod√®le affin√©

L'affinage est un processus qui utilise l'apprentissage par transfert pour "adapter" le mod√®le √† une t√¢che sp√©cifique ou pour r√©soudre un probl√®me particulier. Contrairement √† l'apprentissage par quelques exemples et √† la RAG, il en r√©sulte un nouveau mod√®le g√©n√©r√©, avec des poids et des biais mis √† jour. Cela n√©cessite un ensemble d'exemples d'entra√Ænement compos√© d'une seule entr√©e (le prompt) et de sa sortie associ√©e (la compl√©tion).  
Cette approche serait pr√©f√©r√©e si :

- **Utilisation de mod√®les affin√©s**. Une entreprise souhaite utiliser des mod√®les affin√©s moins performants (comme les mod√®les d'embedding) plut√¥t que des mod√®les hautes performances, ce qui permet une solution plus √©conomique et rapide.

- **Prise en compte de la latence**. La latence est importante pour un cas d'utilisation sp√©cifique, donc il n'est pas possible d'utiliser des prompts tr√®s longs ou un grand nombre d'exemples que le mod√®le devrait apprendre, car cela ne correspond pas aux limites de longueur du prompt.

- **Rester √† jour**. Une entreprise dispose de nombreuses donn√©es de haute qualit√© et d'√©tiquettes de v√©rit√© terrain, ainsi que des ressources n√©cessaires pour maintenir ces donn√©es √† jour au fil du temps.

### Mod√®le entra√Æn√©

Entra√Æner un LLM √† partir de z√©ro est sans aucun doute l'approche la plus difficile et la plus complexe √† adopter, n√©cessitant des quantit√©s massives de donn√©es, des ressources qualifi√©es et une puissance de calcul appropri√©e. Cette option ne devrait √™tre envisag√©e que dans un sc√©nario o√π une entreprise a un cas d'utilisation sp√©cifique √† un domaine et une grande quantit√© de donn√©es centr√©es sur ce domaine.

## V√©rification des connaissances

Quelle pourrait √™tre une bonne approche pour am√©liorer les r√©sultats de compl√©tion des LLM ?

1. Ing√©nierie des prompts avec contexte  
1. RAG  
1. Mod√®le affin√©  

R : 3, si vous avez le temps, les ressources et des donn√©es de haute qualit√©, l'affinage est la meilleure option pour rester √† jour. Cependant, si vous cherchez √† am√©liorer les choses et que vous manquez de temps, il vaut la peine de consid√©rer d'abord la RAG.

## üöÄ D√©fi

Renseignez-vous davantage sur la mani√®re dont vous pouvez [utiliser la RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pour votre entreprise.

## Excellent travail, continuez votre apprentissage

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage sur l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† approfondir vos connaissances sur l'IA g√©n√©rative !

Passez √† la le√ßon 3 o√π nous examinerons comment [utiliser l'IA g√©n√©rative de mani√®re responsable](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst) !

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction professionnelle humaine. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.