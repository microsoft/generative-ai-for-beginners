{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Créer une application de génération d’images\n",
    "\n",
    "Les LLM ne se limitent pas à la génération de texte. Il est aussi possible de générer des images à partir de descriptions textuelles. Disposer d’images comme modalité peut s’avérer très utile dans de nombreux domaines, comme la MedTech, l’architecture, le tourisme, le développement de jeux, et bien d’autres. Dans ce chapitre, nous allons nous intéresser aux deux modèles de génération d’images les plus populaires : DALL-E et Midjourney.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "Dans cette leçon, nous allons aborder :\n",
    "\n",
    "- La génération d’images et son utilité.\n",
    "- DALL-E et Midjourney : ce que c’est et comment ça fonctionne.\n",
    "- Comment créer une application de génération d’images.\n",
    "\n",
    "## Objectifs d’apprentissage\n",
    "\n",
    "À la fin de cette leçon, vous serez capable de :\n",
    "\n",
    "- Créer une application de génération d’images.\n",
    "- Définir les limites de votre application avec des méta-prompts.\n",
    "- Travailler avec DALL-E et Midjourney.\n",
    "\n",
    "## Pourquoi créer une application de génération d’images ?\n",
    "\n",
    "Les applications de génération d’images sont un excellent moyen d’explorer les capacités de l’IA générative. Elles peuvent être utilisées, par exemple, pour :\n",
    "\n",
    "- **Édition et synthèse d’images**. Vous pouvez générer des images pour de nombreux cas d’usage, comme l’édition ou la synthèse d’images.\n",
    "\n",
    "- **Utilisation dans de nombreux secteurs**. Elles peuvent aussi servir à générer des images pour différents secteurs comme la MedTech, le tourisme, le développement de jeux, etc.\n",
    "\n",
    "## Scénario : Edu4All\n",
    "\n",
    "Dans le cadre de cette leçon, nous allons continuer à travailler avec notre startup, Edu4All. Les élèves vont créer des images pour leurs évaluations ; le choix des images leur appartient, mais il peut s’agir d’illustrations pour leur propre conte, de la création d’un nouveau personnage pour leur histoire, ou encore d’images pour les aider à visualiser leurs idées et concepts.\n",
    "\n",
    "Voici, par exemple, ce que les élèves d’Edu4All pourraient générer s’ils travaillent en classe sur les monuments :\n",
    "\n",
    "![Startup Edu4All, cours sur les monuments, Tour Eiffel](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.fr.png)\n",
    "\n",
    "en utilisant un prompt comme\n",
    "\n",
    "> « Chien à côté de la Tour Eiffel au lever du soleil »\n",
    "\n",
    "## Qu’est-ce que DALL-E et Midjourney ?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) et [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) sont deux des modèles de génération d’images les plus populaires ; ils permettent de générer des images à partir de prompts.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Commençons par DALL-E, qui est un modèle d’IA générative capable de créer des images à partir de descriptions textuelles.\n",
    "\n",
    "> [DALL-E est une combinaison de deux modèles, CLIP et l’attention diffusée](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** est un modèle qui génère des embeddings, c’est-à-dire des représentations numériques de données, à partir d’images et de texte.\n",
    "\n",
    "- **L’attention diffusée** est un modèle qui génère des images à partir d’embeddings. DALL-E est entraîné sur un ensemble de données d’images et de textes, et peut être utilisé pour générer des images à partir de descriptions textuelles. Par exemple, DALL-E peut servir à créer l’image d’un chat avec un chapeau, ou d’un chien avec une crête.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney fonctionne de façon similaire à DALL-E : il génère des images à partir de prompts textuels. Midjourney peut aussi être utilisé pour créer des images à partir de prompts comme « un chat avec un chapeau » ou « un chien avec une crête ».\n",
    "\n",
    "![Image générée par Midjourney, pigeon mécanique](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Crédit image Wikipedia, image générée par Midjourney*\n",
    "\n",
    "## Comment fonctionnent DALL-E et Midjourney\n",
    "\n",
    "Commençons par [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E est un modèle d’IA générative basé sur l’architecture transformer, avec un *transformer autorégressif*.\n",
    "\n",
    "Un *transformer autorégressif* définit la façon dont un modèle génère des images à partir de descriptions textuelles : il génère un pixel à la fois, puis utilise les pixels déjà générés pour créer le suivant. Ce processus passe par plusieurs couches d’un réseau de neurones, jusqu’à ce que l’image soit complète.\n",
    "\n",
    "Grâce à ce procédé, DALL-E contrôle les attributs, objets, caractéristiques, et bien plus encore dans l’image générée. Cependant, DALL-E 2 et 3 offrent un contrôle encore plus poussé sur l’image produite,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Créer votre première application de génération d’images\n",
    "\n",
    "Alors, que faut-il pour créer une application de génération d’images ? Vous aurez besoin des bibliothèques suivantes :\n",
    "\n",
    "- **python-dotenv**, il est fortement conseillé d’utiliser cette bibliothèque pour garder vos informations sensibles dans un fichier *.env* séparé du code.\n",
    "- **openai**, cette bibliothèque vous permet d’interagir avec l’API OpenAI.\n",
    "- **pillow**, pour manipuler des images en Python.\n",
    "- **requests**, pour faciliter les requêtes HTTP.\n",
    "\n",
    "\n",
    "1. Créez un fichier *.env* avec le contenu suivant :\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Rassemblez les bibliothèques ci-dessus dans un fichier appelé *requirements.txt* comme ceci :\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. Ensuite, créez un environnement virtuel et installez les bibliothèques :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Pour Windows, utilisez les commandes suivantes pour créer et activer votre environnement virtuel :\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Ajoutez le code suivant dans un fichier appelé *app.py* :\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Expliquons ce code :\n",
    "\n",
    "- D'abord, nous importons les bibliothèques nécessaires, y compris la bibliothèque OpenAI, dotenv, requests et Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- Ensuite, nous créons l'objet, qui va récupérer la clé API depuis votre fichier ``.env``.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- Après, nous générons l'image :\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Le code ci-dessus renvoie un objet JSON qui contient l'URL de l'image générée. Nous pouvons utiliser cette URL pour télécharger l'image et l'enregistrer dans un fichier.\n",
    "\n",
    "- Enfin, nous ouvrons l'image et utilisons la visionneuse d'images par défaut pour l'afficher :\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Plus de détails sur la génération de l'image\n",
    "\n",
    "Regardons de plus près le code qui génère l'image :\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** correspond au texte utilisé pour générer l'image. Dans cet exemple, on utilise le prompt « Lapin sur un cheval, tenant une sucette, dans une prairie brumeuse où poussent des jonquilles ».\n",
    "- **size** correspond à la taille de l'image générée. Ici, on génère une image de 1024x1024 pixels.\n",
    "- **n** correspond au nombre d'images générées. Dans ce cas, on génère deux images.\n",
    "\n",
    "Il existe d'autres possibilités avec les images que nous verrons dans la prochaine section.\n",
    "\n",
    "## Capacités supplémentaires de génération d'images\n",
    "\n",
    "Jusqu'à présent, vous avez vu comment générer une image en quelques lignes de Python. Cependant, il y a d'autres choses que vous pouvez faire avec les images.\n",
    "\n",
    "Vous pouvez aussi :\n",
    "\n",
    "- **Faire des modifications**. En fournissant une image existante, un masque et un prompt, vous pouvez modifier une image. Par exemple, vous pouvez ajouter un élément sur une partie de l'image. Imaginez notre image de lapin, vous pouvez ajouter un chapeau au lapin. Pour cela, il suffit de fournir l'image, un masque (qui identifie la zone à modifier) et un prompt texte pour décrire ce qui doit être fait.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    L'image de base ne contiendrait que le lapin, mais l'image finale aurait le chapeau sur le lapin.\n",
    "    \n",
    "- **Créer des variations**. L'idée est de prendre une image existante et de demander la création de variantes. Pour créer une variation, il suffit de fournir une image, un prompt texte et un code comme ceci :\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Avertissement** :  \nCe document a été traduit à l’aide du service de traduction par IA [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d’assurer l’exactitude de la traduction, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d’origine doit être considéré comme la source faisant autorité. Pour les informations critiques, il est recommandé de recourir à une traduction humaine professionnelle. Nous déclinons toute responsabilité en cas de malentendus ou d’interprétations erronées résultant de l’utilisation de cette traduction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:29:02+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "fr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}