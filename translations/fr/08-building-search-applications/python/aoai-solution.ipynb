{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour exécuter les notebooks suivants, si ce n'est pas encore fait, vous devez déployer un modèle qui utilise `text-embedding-ada-002` comme modèle de base et définir le nom du déploiement dans le fichier .env sous le nom `AZURE_OPENAI_EMBEDDINGS_ENDPOINT`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous allons charger l'Index d'Embedding dans un DataFrame Pandas. L'Index d'Embedding est stocké dans un fichier JSON appelé `embedding_index_3m.json`. L'Index d'Embedding contient les Embeddings pour chacune des transcriptions YouTube jusqu'à fin octobre 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensuite, nous allons créer une fonction appelée `get_videos` qui recherchera dans l'Index d'Embedding la requête. La fonction retournera les 5 vidéos les plus similaires à la requête. La fonction fonctionne comme suit :\n",
    "\n",
    "1. Tout d'abord, une copie de l'Index d'Embedding est créée.\n",
    "2. Ensuite, l'Embedding pour la requête est calculé en utilisant l'API d'Embedding OpenAI.\n",
    "3. Puis, une nouvelle colonne est créée dans l'Index d'Embedding appelée `similarity`. La colonne `similarity` contient la similarité cosinus entre l'Embedding de la requête et l'Embedding de chaque segment vidéo.\n",
    "4. Ensuite, l'Index d'Embedding est filtré par la colonne `similarity`. L'Index d'Embedding est filtré pour ne conserver que les vidéos ayant une similarité cosinus supérieure ou égale à 0,75.\n",
    "5. Enfin, l'Index d'Embedding est trié par la colonne `similarity` et les 5 meilleures vidéos sont retournées.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette fonction est très simple, elle affiche simplement les résultats de la requête de recherche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tout d'abord, l'Index d'Embedding est chargé dans un Dataframe Pandas.  \n",
    "2. Ensuite, l'utilisateur est invité à saisir une requête.  \n",
    "3. Puis, la fonction `get_videos` est appelée pour rechercher dans l'Index d'Embedding la requête.  \n",
    "4. Enfin, la fonction `display_results` est appelée pour afficher les résultats à l'utilisateur.  \n",
    "5. L'utilisateur est ensuite invité à saisir une autre requête. Ce processus continue jusqu'à ce que l'utilisateur saisisse `exit`.  \n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc.fr.png)  \n",
    "\n",
    "Vous serez invité à saisir une requête. Entrez une requête et appuyez sur Entrée. L'application retournera une liste de vidéos pertinentes par rapport à la requête. L'application retournera également un lien vers l'endroit dans la vidéo où se trouve la réponse à la question.  \n",
    "\n",
    "Voici quelques requêtes à essayer :  \n",
    "\n",
    "- Qu'est-ce que Azure Machine Learning ?  \n",
    "- Comment fonctionnent les réseaux de neurones convolutionnels ?  \n",
    "- Qu'est-ce qu'un réseau de neurones ?  \n",
    "- Puis-je utiliser Jupyter Notebooks avec Azure Machine Learning ?  \n",
    "- Qu'est-ce que ONNX ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Avertissement** :  \nCe document a été traduit à l’aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d’assurer l’exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d’origine doit être considéré comme la source faisant foi. Pour les informations critiques, une traduction professionnelle réalisée par un humain est recommandée. Nous déclinons toute responsabilité en cas de malentendus ou de mauvaises interprétations résultant de l’utilisation de cette traduction.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "ff5415e24294df268ec7e7a2b12af509",
   "translation_date": "2025-12-19T08:35:01+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "fr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}