<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-17T22:38:54+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "fr"
}
-->
# Utiliser l'IA g√©n√©rative de mani√®re responsable

[![Utiliser l'IA g√©n√©rative de mani√®re responsable](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.fr.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _Cliquez sur l'image ci-dessus pour visionner la vid√©o de cette le√ßon_

Il est facile d'√™tre fascin√© par l'IA, et en particulier par l'IA g√©n√©rative, mais il est essentiel de r√©fl√©chir √† la mani√®re de l'utiliser de mani√®re responsable. Vous devez prendre en compte des aspects tels que la garantie que les r√©sultats soient √©quitables, non nuisibles, et bien plus encore. Ce chapitre vise √† vous fournir le contexte mentionn√©, les √©l√©ments √† consid√©rer et les √©tapes √† suivre pour am√©liorer votre utilisation de l'IA.

## Introduction

Cette le√ßon couvrira :

- Pourquoi vous devriez donner la priorit√© √† l'IA responsable lors de la cr√©ation d'applications d'IA g√©n√©rative.
- Les principes fondamentaux de l'IA responsable et leur lien avec l'IA g√©n√©rative.
- Comment mettre en pratique ces principes d'IA responsable gr√¢ce √† des strat√©gies et des outils.

## Objectifs d'apprentissage

Apr√®s avoir termin√© cette le√ßon, vous saurez :

- L'importance de l'IA responsable lors de la cr√©ation d'applications d'IA g√©n√©rative.
- Quand r√©fl√©chir et appliquer les principes fondamentaux de l'IA responsable lors de la cr√©ation d'applications d'IA g√©n√©rative.
- Quels outils et strat√©gies sont √† votre disposition pour mettre en pratique le concept d'IA responsable.

## Principes de l'IA responsable

L'enthousiasme autour de l'IA g√©n√©rative n'a jamais √©t√© aussi grand. Cet engouement a attir√© de nombreux nouveaux d√©veloppeurs, une attention accrue et des financements dans ce domaine. Bien que cela soit tr√®s positif pour quiconque souhaite cr√©er des produits et des entreprises utilisant l'IA g√©n√©rative, il est √©galement important de proc√©der de mani√®re responsable.

Tout au long de ce cours, nous nous concentrons sur la cr√©ation de notre startup et de notre produit √©ducatif bas√© sur l'IA. Nous utiliserons les principes de l'IA responsable : √âquit√©, Inclusion, Fiabilit√©/S√©curit√©, S√©curit√© et Confidentialit√©, Transparence et Responsabilit√©. Avec ces principes, nous explorerons leur relation avec notre utilisation de l'IA g√©n√©rative dans nos produits.

## Pourquoi donner la priorit√© √† l'IA responsable

Lors de la cr√©ation d'un produit, adopter une approche centr√©e sur l'humain en gardant √† l'esprit les int√©r√™ts de vos utilisateurs conduit aux meilleurs r√©sultats.

La particularit√© de l'IA g√©n√©rative r√©side dans sa capacit√© √† fournir des r√©ponses utiles, des informations, des conseils et du contenu aux utilisateurs. Cela peut √™tre fait sans de nombreuses √©tapes manuelles, ce qui peut conduire √† des r√©sultats tr√®s impressionnants. Cependant, sans planification et strat√©gies appropri√©es, cela peut malheureusement entra√Æner des r√©sultats nuisibles pour vos utilisateurs, votre produit et la soci√©t√© dans son ensemble.

Examinons certains (mais pas tous) de ces r√©sultats potentiellement nuisibles :

### Hallucinations

Les hallucinations d√©signent les cas o√π un mod√®le de langage produit un contenu qui est soit compl√®tement absurde, soit manifestement incorrect selon d'autres sources d'information.

Prenons l'exemple o√π nous cr√©ons une fonctionnalit√© pour notre startup permettant aux √©tudiants de poser des questions historiques √† un mod√®le. Un √©tudiant pose la question : `Qui √©tait le seul survivant du Titanic ?`

Le mod√®le produit une r√©ponse telle que celle-ci :

![Invite disant "Qui √©tait le seul survivant du Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Source : [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

C'est une r√©ponse tr√®s confiante et d√©taill√©e. Malheureusement, elle est incorrecte. M√™me avec un minimum de recherche, on d√©couvrirait qu'il y avait plus d'un survivant de la catastrophe du Titanic. Pour un √©tudiant qui commence tout juste √† rechercher ce sujet, cette r√©ponse peut √™tre suffisamment convaincante pour ne pas √™tre remise en question et √™tre consid√©r√©e comme un fait. Les cons√©quences de cela peuvent rendre le syst√®me d'IA peu fiable et nuire √† la r√©putation de notre startup.

Avec chaque it√©ration d'un mod√®le de langage donn√©, nous avons constat√© des am√©liorations de performance pour minimiser les hallucinations. M√™me avec ces am√©liorations, nous, en tant que cr√©ateurs d'applications et utilisateurs, devons rester conscients de ces limitations.

### Contenu nuisible

Nous avons abord√© dans la section pr√©c√©dente les cas o√π un mod√®le de langage produit des r√©ponses incorrectes ou absurdes. Un autre risque √† prendre en compte est lorsque le mod√®le r√©pond avec un contenu nuisible.

Le contenu nuisible peut √™tre d√©fini comme :

- Fournir des instructions ou encourager l'automutilation ou le pr√©judice envers certains groupes.
- Contenu haineux ou d√©gradant.
- Aider √† planifier tout type d'attaque ou d'actes violents.
- Fournir des instructions sur la mani√®re de trouver du contenu ill√©gal ou de commettre des actes ill√©gaux.
- Afficher du contenu sexuellement explicite.

Pour notre startup, nous voulons nous assurer d'avoir les bons outils et strat√©gies en place pour emp√™cher ce type de contenu d'√™tre vu par les √©tudiants.

### Manque d'√©quit√©

L'√©quit√© est d√©finie comme ¬´ garantir qu'un syst√®me d'IA est exempt de biais et de discrimination et qu'il traite tout le monde de mani√®re √©quitable et √©gale ¬ª. Dans le domaine de l'IA g√©n√©rative, nous voulons nous assurer que les visions du monde excluantes envers les groupes marginalis√©s ne sont pas renforc√©es par les r√©sultats du mod√®le.

Ces types de r√©sultats ne sont pas seulement destructeurs pour cr√©er des exp√©riences positives pour nos utilisateurs, mais ils causent √©galement des dommages suppl√©mentaires √† la soci√©t√©. En tant que cr√©ateurs d'applications, nous devrions toujours garder √† l'esprit une base d'utilisateurs large et diversifi√©e lors de la cr√©ation de solutions avec l'IA g√©n√©rative.

## Comment utiliser l'IA g√©n√©rative de mani√®re responsable

Maintenant que nous avons identifi√© l'importance de l'IA g√©n√©rative responsable, examinons 4 √©tapes que nous pouvons suivre pour cr√©er nos solutions d'IA de mani√®re responsable :

![Cycle d'att√©nuation](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.fr.png)

### Mesurer les dommages potentiels

Dans les tests logiciels, nous testons les actions attendues d'un utilisateur sur une application. De m√™me, tester un ensemble diversifi√© de requ√™tes que les utilisateurs sont le plus susceptibles d'utiliser est une bonne fa√ßon de mesurer les dommages potentiels.

√âtant donn√© que notre startup d√©veloppe un produit √©ducatif, il serait judicieux de pr√©parer une liste de requ√™tes li√©es √† l'√©ducation. Cela pourrait couvrir un certain sujet, des faits historiques et des requ√™tes sur la vie √©tudiante.

### Att√©nuer les dommages potentiels

Il est maintenant temps de trouver des moyens de pr√©venir ou de limiter les dommages potentiels caus√©s par le mod√®le et ses r√©ponses. Nous pouvons examiner cela sous 4 couches diff√©rentes :

![Couches d'att√©nuation](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.fr.png)

- **Mod√®le**. Choisir le bon mod√®le pour le bon cas d'utilisation. Les mod√®les plus grands et plus complexes comme GPT-4 peuvent pr√©senter un risque accru de contenu nuisible lorsqu'ils sont appliqu√©s √† des cas d'utilisation plus petits et sp√©cifiques. Utiliser vos donn√©es d'entra√Ænement pour un ajustement fin r√©duit √©galement le risque de contenu nuisible.

- **Syst√®me de s√©curit√©**. Un syst√®me de s√©curit√© est un ensemble d'outils et de configurations sur la plateforme qui h√©berge le mod√®le et qui aide √† att√©nuer les dommages. Un exemple de cela est le syst√®me de filtrage de contenu sur le service Azure OpenAI. Les syst√®mes doivent √©galement d√©tecter les attaques de contournement et les activit√©s ind√©sirables comme les requ√™tes provenant de bots.

- **M√©taprompt**. Les m√©taprompts et l'ancrage sont des moyens de diriger ou de limiter le mod√®le en fonction de certains comportements et informations. Cela pourrait √™tre l'utilisation d'entr√©es syst√®me pour d√©finir certaines limites du mod√®le. En outre, fournir des r√©sultats plus pertinents au champ ou au domaine du syst√®me.

Cela peut √©galement inclure l'utilisation de techniques comme la g√©n√©ration augment√©e par r√©cup√©ration (RAG) pour que le mod√®le ne puise des informations que dans une s√©lection de sources fiables. Il y a une le√ßon plus tard dans ce cours sur [la cr√©ation d'applications de recherche](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Exp√©rience utilisateur**. La derni√®re couche est celle o√π l'utilisateur interagit directement avec le mod√®le via l'interface de notre application d'une mani√®re ou d'une autre. De cette mani√®re, nous pouvons concevoir l'interface utilisateur/exp√©rience utilisateur pour limiter l'utilisateur sur les types d'entr√©es qu'il peut envoyer au mod√®le ainsi que sur le texte ou les images affich√©s √† l'utilisateur. Lors du d√©ploiement de l'application d'IA, nous devons √©galement √™tre transparents sur ce que notre application d'IA g√©n√©rative peut et ne peut pas faire.

Nous avons une le√ßon enti√®re d√©di√©e √† [Concevoir l'UX pour les applications d'IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **√âvaluer le mod√®le**. Travailler avec des mod√®les de langage peut √™tre difficile car nous n'avons pas toujours le contr√¥le sur les donn√©es sur lesquelles le mod√®le a √©t√© entra√Æn√©. N√©anmoins, nous devrions toujours √©valuer les performances et les r√©sultats du mod√®le. Il est toujours important de mesurer la pr√©cision, la similarit√©, l'ancrage et la pertinence des r√©sultats du mod√®le. Cela aide √† fournir transparence et confiance aux parties prenantes et aux utilisateurs.

### Exploiter une solution d'IA g√©n√©rative responsable

Construire une pratique op√©rationnelle autour de vos applications d'IA est la derni√®re √©tape. Cela inclut de collaborer avec d'autres parties de notre startup comme le service juridique et la s√©curit√© pour garantir que nous respectons toutes les politiques r√©glementaires. Avant de lancer, nous voulons √©galement √©laborer des plans autour de la livraison, de la gestion des incidents et du retour en arri√®re pour √©viter tout pr√©judice √† nos utilisateurs.

## Outils

Bien que le travail de d√©veloppement de solutions d'IA responsable puisse sembler important, il s'agit d'un effort qui en vaut la peine. √Ä mesure que le domaine de l'IA g√©n√©rative se d√©veloppe, davantage d'outils pour aider les d√©veloppeurs √† int√©grer efficacement la responsabilit√© dans leurs flux de travail vont se perfectionner. Par exemple, le [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) peut aider √† d√©tecter les contenus et images nuisibles via une requ√™te API.

## V√©rification des connaissances

Quels sont les √©l√©ments √† prendre en compte pour garantir une utilisation responsable de l'IA ?

1. Que la r√©ponse soit correcte.
1. Une utilisation nuisible, que l'IA ne soit pas utilis√©e √† des fins criminelles.
1. Garantir que l'IA soit exempte de biais et de discrimination.

R : Les r√©ponses 2 et 3 sont correctes. L'IA responsable vous aide √† r√©fl√©chir √† la mani√®re de limiter les effets nuisibles et les biais, entre autres.

## üöÄ D√©fi

Renseignez-vous sur [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) et voyez ce que vous pouvez adopter pour votre utilisation.

## Excellent travail, continuez votre apprentissage

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage sur l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† approfondir vos connaissances sur l'IA g√©n√©rative !

Passez √† la le√ßon 4 o√π nous examinerons les [Fondamentaux de l'ing√©nierie des invites](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) !

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.