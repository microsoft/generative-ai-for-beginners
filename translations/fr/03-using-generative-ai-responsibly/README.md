<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:45:59+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "fr"
}
-->
# Utiliser lâ€™IA GÃ©nÃ©rative de maniÃ¨re responsable

[![Using Generative AI Responsibly](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.fr.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Cliquez sur lâ€™image ci-dessus pour voir la vidÃ©o de cette leÃ§on_

Il est facile dâ€™Ãªtre fascinÃ© par lâ€™IA, et plus particuliÃ¨rement par lâ€™IA gÃ©nÃ©rative, mais il est essentiel de rÃ©flÃ©chir Ã  la maniÃ¨re de lâ€™utiliser de faÃ§on responsable. Il faut prendre en compte des aspects comme garantir que les rÃ©sultats soient justes, non nuisibles, et bien plus encore. Ce chapitre a pour but de vous fournir ce contexte, ce quâ€™il faut considÃ©rer, et comment agir concrÃ¨tement pour amÃ©liorer votre usage de lâ€™IA.

## Introduction

Cette leÃ§on abordera :

- Pourquoi il est important de privilÃ©gier une IA responsable lors de la crÃ©ation dâ€™applications dâ€™IA gÃ©nÃ©rative.
- Les principes fondamentaux de lâ€™IA responsable et leur lien avec lâ€™IA gÃ©nÃ©rative.
- Comment appliquer ces principes dâ€™IA responsable Ã  travers des stratÃ©gies et des outils.

## Objectifs dâ€™apprentissage

Ã€ lâ€™issue de cette leÃ§on, vous saurez :

- Lâ€™importance de lâ€™IA responsable dans la crÃ©ation dâ€™applications dâ€™IA gÃ©nÃ©rative.
- Quand rÃ©flÃ©chir Ã  et appliquer les principes fondamentaux de lâ€™IA responsable dans ce contexte.
- Quels outils et stratÃ©gies sont Ã  votre disposition pour mettre en pratique le concept dâ€™IA responsable.

## Principes de lâ€™IA responsable

Lâ€™engouement pour lâ€™IA gÃ©nÃ©rative nâ€™a jamais Ã©tÃ© aussi fort. Cet engouement a attirÃ© de nombreux nouveaux dÃ©veloppeurs, de lâ€™attention et des financements dans ce domaine. Bien que cela soit trÃ¨s positif pour quiconque souhaite crÃ©er des produits et des entreprises utilisant lâ€™IA gÃ©nÃ©rative, il est aussi crucial dâ€™avancer de maniÃ¨re responsable.

Tout au long de ce cours, nous nous concentrons sur la construction de notre startup et de notre produit Ã©ducatif en IA. Nous utiliserons les principes de lâ€™IA responsable : Ã‰quitÃ©, Inclusion, FiabilitÃ©/SÃ©curitÃ©, SÃ©curitÃ© & ConfidentialitÃ©, Transparence et ResponsabilitÃ©. Avec ces principes, nous explorerons leur lien avec notre utilisation de lâ€™IA gÃ©nÃ©rative dans nos produits.

## Pourquoi prioriser lâ€™IA responsable

Lors de la crÃ©ation dâ€™un produit, adopter une approche centrÃ©e sur lâ€™humain en gardant Ã  lâ€™esprit lâ€™intÃ©rÃªt de lâ€™utilisateur conduit aux meilleurs rÃ©sultats.

La particularitÃ© de lâ€™IA gÃ©nÃ©rative rÃ©side dans sa capacitÃ© Ã  crÃ©er des rÃ©ponses utiles, des informations, des conseils et du contenu pour les utilisateurs. Cela peut se faire sans de nombreuses Ã©tapes manuelles, ce qui peut donner des rÃ©sultats trÃ¨s impressionnants. Sans une planification et des stratÃ©gies appropriÃ©es, cela peut malheureusement aussi entraÃ®ner des rÃ©sultats nuisibles pour vos utilisateurs, votre produit et la sociÃ©tÃ© dans son ensemble.

Examinons quelques-uns (mais pas tous) de ces rÃ©sultats potentiellement nuisibles :

### Hallucinations

Les hallucinations dÃ©signent le phÃ©nomÃ¨ne oÃ¹ un LLM produit un contenu soit complÃ¨tement absurde, soit factuellement incorrect selon dâ€™autres sources dâ€™information.

Par exemple, imaginons que nous dÃ©veloppions une fonctionnalitÃ© pour notre startup permettant aux Ã©tudiants de poser des questions historiques Ã  un modÃ¨le. Un Ã©tudiant demande : `Qui Ã©tait le seul survivant du Titanic ?`

Le modÃ¨le produit une rÃ©ponse comme celle-ci :

![Prompt saying "Who was the sole survivor of the Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Source : [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Câ€™est une rÃ©ponse trÃ¨s confiante et dÃ©taillÃ©e. Malheureusement, elle est incorrecte. Avec un minimum de recherche, on dÃ©couvre quâ€™il y a eu plusieurs survivants du naufrage du Titanic. Pour un Ã©tudiant qui commence Ã  sâ€™informer sur ce sujet, cette rÃ©ponse peut sembler suffisamment convaincante pour ne pas Ãªtre remise en question et Ãªtre prise pour un fait. Les consÃ©quences peuvent rendre le systÃ¨me dâ€™IA peu fiable et nuire Ã  la rÃ©putation de notre startup.

Ã€ chaque nouvelle version dâ€™un LLM, nous constatons des amÃ©liorations pour rÃ©duire les hallucinations. MalgrÃ© ces progrÃ¨s, en tant que dÃ©veloppeurs et utilisateurs, nous devons rester conscients de ces limites.

### Contenu nuisible

Nous avons vu prÃ©cÃ©demment quand un LLM produit des rÃ©ponses incorrectes ou absurdes. Un autre risque Ã  connaÃ®tre est celui dâ€™un modÃ¨le qui gÃ©nÃ¨re du contenu nuisible.

Le contenu nuisible peut Ãªtre dÃ©fini comme :

- Fournir des instructions ou encourager lâ€™automutilation ou la violence envers certains groupes.
- Contenu haineux ou dÃ©gradant.
- Aider Ã  planifier des attaques ou des actes violents.
- Fournir des instructions pour trouver du contenu illÃ©gal ou commettre des actes illÃ©gaux.
- Afficher du contenu sexuellement explicite.

Pour notre startup, nous voulons nous assurer de disposer des bons outils et stratÃ©gies pour empÃªcher que ce type de contenu soit visible par les Ã©tudiants.

### Manque dâ€™Ã©quitÃ©

Lâ€™Ã©quitÃ© signifie Â« sâ€™assurer quâ€™un systÃ¨me dâ€™IA est exempt de biais et de discrimination et quâ€™il traite tout le monde de maniÃ¨re juste et Ã©gale Â». Dans le domaine de lâ€™IA gÃ©nÃ©rative, nous voulons Ã©viter que des visions du monde excluantes envers des groupes marginalisÃ©s soient renforcÃ©es par les rÃ©sultats du modÃ¨le.

Ce type de rÃ©sultats nuit non seulement Ã  la crÃ©ation dâ€™expÃ©riences produit positives pour nos utilisateurs, mais cause aussi des dommages sociaux plus larges. En tant que dÃ©veloppeurs, nous devons toujours garder Ã  lâ€™esprit une base dâ€™utilisateurs large et diversifiÃ©e lors de la conception de solutions avec lâ€™IA gÃ©nÃ©rative.

## Comment utiliser lâ€™IA gÃ©nÃ©rative de maniÃ¨re responsable

Maintenant que nous avons identifiÃ© lâ€™importance de lâ€™IA gÃ©nÃ©rative responsable, voyons 4 Ã©tapes pour construire nos solutions IA de faÃ§on responsable :

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.fr.png)

### Mesurer les risques potentiels

Dans les tests logiciels, on teste les actions attendues dâ€™un utilisateur sur une application. De la mÃªme maniÃ¨re, tester un ensemble diversifiÃ© de requÃªtes que les utilisateurs sont susceptibles dâ€™utiliser est un bon moyen dâ€™Ã©valuer les risques potentiels.

Puisque notre startup dÃ©veloppe un produit Ã©ducatif, il serait pertinent de prÃ©parer une liste de requÃªtes liÃ©es Ã  lâ€™Ã©ducation. Cela pourrait couvrir un certain sujet, des faits historiques, ou des questions sur la vie Ã©tudiante.

### AttÃ©nuer les risques potentiels

Il est temps de trouver des moyens pour prÃ©venir ou limiter les risques causÃ©s par le modÃ¨le et ses rÃ©ponses. Nous pouvons envisager cela Ã  4 niveaux diffÃ©rents :

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.fr.png)

- **ModÃ¨le**. Choisir le bon modÃ¨le pour le bon cas dâ€™usage. Les modÃ¨les plus grands et complexes comme GPT-4 peuvent prÃ©senter un risque plus Ã©levÃ© de contenu nuisible lorsquâ€™ils sont appliquÃ©s Ã  des cas dâ€™usage plus petits et spÃ©cifiques. Utiliser vos donnÃ©es dâ€™entraÃ®nement pour affiner le modÃ¨le rÃ©duit aussi ce risque.

- **SystÃ¨me de sÃ©curitÃ©**. Un systÃ¨me de sÃ©curitÃ© est un ensemble dâ€™outils et de configurations sur la plateforme qui hÃ©berge le modÃ¨le et qui aide Ã  limiter les risques. Par exemple, le systÃ¨me de filtrage de contenu du service Azure OpenAI. Ces systÃ¨mes doivent aussi dÃ©tecter les attaques de type jailbreak et les activitÃ©s indÃ©sirables comme les requÃªtes provenant de bots.

- **Metaprompt**. Les metaprompts et le grounding sont des moyens de diriger ou de limiter le modÃ¨le selon certains comportements et informations. Cela peut passer par des entrÃ©es systÃ¨me dÃ©finissant certaines limites du modÃ¨le. De plus, fournir des rÃ©ponses plus pertinentes par rapport au domaine ou au contexte du systÃ¨me.

Cela peut aussi inclure des techniques comme Retrieval Augmented Generation (RAG) pour que le modÃ¨le ne puise lâ€™information que dans une sÃ©lection de sources fiables. Une leÃ§on plus loin dans ce cours porte sur [la crÃ©ation dâ€™applications de recherche](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **ExpÃ©rience utilisateur**. Le dernier niveau est celui oÃ¹ lâ€™utilisateur interagit directement avec le modÃ¨le via lâ€™interface de notre application. Nous pouvons ainsi concevoir lâ€™UI/UX pour limiter les types dâ€™entrÃ©es que lâ€™utilisateur peut envoyer au modÃ¨le ainsi que les textes ou images affichÃ©s. Lors du dÃ©ploiement de lâ€™application IA, il est aussi important dâ€™Ãªtre transparent sur ce que notre application dâ€™IA gÃ©nÃ©rative peut ou ne peut pas faire.

Nous avons une leÃ§on entiÃ¨re dÃ©diÃ©e Ã  [la conception UX pour les applications IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Ã‰valuer le modÃ¨le**. Travailler avec des LLM peut Ãªtre complexe car nous nâ€™avons pas toujours le contrÃ´le sur les donnÃ©es dâ€™entraÃ®nement du modÃ¨le. Quoi quâ€™il en soit, il faut toujours Ã©valuer la performance et les rÃ©sultats du modÃ¨le. Il est important de mesurer la prÃ©cision, la similaritÃ©, la pertinence et la fiabilitÃ© des rÃ©ponses. Cela aide Ã  instaurer transparence et confiance auprÃ¨s des parties prenantes et des utilisateurs.

### Exploiter une solution dâ€™IA gÃ©nÃ©rative responsable

Mettre en place une pratique opÃ©rationnelle autour de vos applications IA est la derniÃ¨re Ã©tape. Cela inclut de collaborer avec dâ€™autres dÃ©partements de notre startup comme le service juridique et la sÃ©curitÃ© pour garantir la conformitÃ© aux rÃ©glementations. Avant le lancement, il faut aussi Ã©laborer des plans pour la livraison, la gestion des incidents et le retour en arriÃ¨re afin dâ€™Ã©viter tout prÃ©judice croissant pour nos utilisateurs.

## Outils

MÃªme si le travail de dÃ©veloppement de solutions dâ€™IA responsable peut sembler important, il en vaut largement la peine. Ã€ mesure que le domaine de lâ€™IA gÃ©nÃ©rative se dÃ©veloppe, davantage dâ€™outils permettant aux dÃ©veloppeurs dâ€™intÃ©grer efficacement la responsabilitÃ© dans leurs processus vont mÃ»rir. Par exemple, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) peut aider Ã  dÃ©tecter le contenu et les images nuisibles via une requÃªte API.

## VÃ©rification des connaissances

Quelles sont les choses auxquelles vous devez faire attention pour garantir un usage responsable de lâ€™IA ?

1. Que la rÃ©ponse soit correcte.  
1. Lâ€™usage nuisible, que lâ€™IA ne soit pas utilisÃ©e Ã  des fins criminelles.  
1. Sâ€™assurer que lâ€™IA soit exempte de biais et de discrimination.

R : Les points 2 et 3 sont corrects. Lâ€™IA responsable vous aide Ã  envisager comment attÃ©nuer les effets nuisibles, les biais, et plus encore.

## ğŸš€ DÃ©fi

Lisez la documentation sur [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) et voyez ce que vous pouvez adopter pour votre usage.

## Excellent travail, continuez votre apprentissage

AprÃ¨s avoir terminÃ© cette leÃ§on, consultez notre [collection dâ€™apprentissage sur lâ€™IA gÃ©nÃ©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer Ã  approfondir vos connaissances sur lâ€™IA gÃ©nÃ©rative !

Rendez-vous Ã  la leÃ§on 4 oÃ¹ nous aborderons les [fondamentaux de la conception de prompts](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) !

**Avertissement** :  
Ce document a Ã©tÃ© traduit Ã  lâ€™aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions dâ€™assurer lâ€™exactitude, veuillez noter que les traductions automatiques peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue dâ€™origine doit Ãªtre considÃ©rÃ© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle rÃ©alisÃ©e par un humain est recommandÃ©e. Nous dÃ©clinons toute responsabilitÃ© en cas de malentendus ou de mauvaises interprÃ©tations rÃ©sultant de lâ€™utilisation de cette traduction.