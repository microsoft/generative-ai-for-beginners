<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-05-20T07:34:24+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "fr"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.8487555c3e3225eefc1dc84e72c8e00bce1ee76db867a080628fb0fbb04aa0d2.fr.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Ajustement de votre LLM

Utiliser des mod√®les de langage de grande taille pour cr√©er des applications d'IA g√©n√©rative pr√©sente de nouveaux d√©fis. Un probl√®me cl√© est de garantir la qualit√© des r√©ponses (pr√©cision et pertinence) dans le contenu g√©n√©r√© par le mod√®le pour une demande utilisateur donn√©e. Dans les le√ßons pr√©c√©dentes, nous avons discut√© de techniques telles que l'ing√©nierie de prompt et la g√©n√©ration augment√©e par la r√©cup√©ration qui tentent de r√©soudre le probl√®me en _modifiant l'entr√©e du prompt_ du mod√®le existant.

Dans la le√ßon d'aujourd'hui, nous discutons d'une troisi√®me technique, **l'ajustement**, qui tente de relever le d√©fi en _r√©entra√Ænant le mod√®le lui-m√™me_ avec des donn√©es suppl√©mentaires. Plongeons dans les d√©tails.

## Objectifs d'apprentissage

Cette le√ßon introduit le concept d'ajustement pour les mod√®les de langage pr√©-entra√Æn√©s, explore les avantages et les d√©fis de cette approche, et fournit des conseils sur quand et comment utiliser l'ajustement pour am√©liorer les performances de vos mod√®les d'IA g√©n√©rative.

√Ä la fin de cette le√ßon, vous devriez √™tre capable de r√©pondre aux questions suivantes :

- Qu'est-ce que l'ajustement pour les mod√®les de langage ?
- Quand et pourquoi l'ajustement est-il utile ?
- Comment puis-je ajuster un mod√®le pr√©-entra√Æn√© ?
- Quelles sont les limitations de l'ajustement ?

Pr√™t ? Commen√ßons.

## Guide illustr√©

Vous voulez avoir une vue d'ensemble de ce que nous allons couvrir avant de plonger ? Consultez ce guide illustr√© qui d√©crit le parcours d'apprentissage de cette le√ßon - de l'apprentissage des concepts de base et de la motivation pour l'ajustement, √† la compr√©hension du processus et des meilleures pratiques pour ex√©cuter la t√¢che d'ajustement. C'est un sujet fascinant √† explorer, alors n'oubliez pas de consulter la page [Ressources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pour des liens suppl√©mentaires afin de soutenir votre parcours d'apprentissage autonome !

![Guide illustr√© de l'ajustement des mod√®les de langage](../../../translated_images/18-fine-tuning-sketchnote.92733966235199dd260184b1aae3a84b877c7496bc872d8e63ad6fa2dd96bafc.fr.png)

## Qu'est-ce que l'ajustement pour les mod√®les de langage ?

Par d√©finition, les mod√®les de langage de grande taille sont _pr√©-entra√Æn√©s_ sur de grandes quantit√©s de texte provenant de diverses sources, y compris Internet. Comme nous l'avons appris dans les le√ßons pr√©c√©dentes, nous avons besoin de techniques comme _l'ing√©nierie de prompt_ et la _g√©n√©ration augment√©e par la r√©cup√©ration_ pour am√©liorer la qualit√© des r√©ponses du mod√®le aux questions des utilisateurs ("prompts").

Une technique populaire d'ing√©nierie de prompt consiste √† donner au mod√®le plus de directives sur ce qui est attendu dans la r√©ponse, soit en fournissant des _instructions_ (guidage explicite) ou en _lui donnant quelques exemples_ (guidage implicite). Cela est appel√© _apprentissage √† quelques coups_, mais cela pr√©sente deux limitations :

- Les limites de tokens du mod√®le peuvent restreindre le nombre d'exemples que vous pouvez donner et limiter l'efficacit√©.
- Les co√ªts de tokens du mod√®le peuvent rendre co√ªteux l'ajout d'exemples √† chaque prompt et limiter la flexibilit√©.

L'ajustement est une pratique courante dans les syst√®mes d'apprentissage automatique o√π nous prenons un mod√®le pr√©-entra√Æn√© et le r√©entra√Ænons avec de nouvelles donn√©es pour am√©liorer ses performances sur une t√¢che sp√©cifique. Dans le contexte des mod√®les de langage, nous pouvons ajuster le mod√®le pr√©-entra√Æn√© _avec un ensemble d'exemples s√©lectionn√©s pour une t√¢che ou un domaine d'application donn√©_ afin de cr√©er un **mod√®le personnalis√©** qui peut √™tre plus pr√©cis et pertinent pour cette t√¢che ou ce domaine sp√©cifique. Un avantage secondaire de l'ajustement est qu'il peut √©galement r√©duire le nombre d'exemples n√©cessaires pour l'apprentissage √† quelques coups - r√©duisant l'utilisation de tokens et les co√ªts associ√©s.

## Quand et pourquoi devrions-nous ajuster les mod√®les ?

Dans _ce_ contexte, lorsque nous parlons d'ajustement, nous faisons r√©f√©rence √† l'ajustement **supervis√©** o√π le r√©entra√Ænement est effectu√© en **ajoutant de nouvelles donn√©es** qui ne faisaient pas partie du jeu de donn√©es d'entra√Ænement original. Cela est diff√©rent d'une approche d'ajustement non supervis√© o√π le mod√®le est r√©entra√Æn√© sur les donn√©es originales, mais avec des hyperparam√®tres diff√©rents.

La chose importante √† retenir est que l'ajustement est une technique avanc√©e qui n√©cessite un certain niveau d'expertise pour obtenir les r√©sultats souhait√©s. Si cela est mal fait, cela peut ne pas fournir les am√©liorations attendues et peut m√™me d√©grader les performances du mod√®le pour votre domaine cibl√©.

Ainsi, avant d'apprendre "comment" ajuster les mod√®les de langage, vous devez savoir "pourquoi" vous devriez emprunter cette voie et "quand" commencer le processus d'ajustement. Commencez par vous poser ces questions :

- **Cas d'utilisation** : Quel est votre _cas d'utilisation_ pour l'ajustement ? Quel aspect du mod√®le pr√©-entra√Æn√© actuel souhaitez-vous am√©liorer ?
- **Alternatives** : Avez-vous essay√© _d'autres techniques_ pour atteindre les r√©sultats souhait√©s ? Utilisez-les pour cr√©er une base de comparaison.
  - Ing√©nierie de prompt : Essayez des techniques comme le prompt √† quelques coups avec des exemples de r√©ponses de prompt pertinentes. √âvaluez la qualit√© des r√©ponses.
  - G√©n√©ration augment√©e par la r√©cup√©ration : Essayez d'augmenter les prompts avec les r√©sultats de requ√™te r√©cup√©r√©s en recherchant vos donn√©es. √âvaluez la qualit√© des r√©ponses.
- **Co√ªts** : Avez-vous identifi√© les co√ªts pour l'ajustement ?
  - Possibilit√© d'ajustement - le mod√®le pr√©-entra√Æn√© est-il disponible pour l'ajustement ?
  - Effort - pour pr√©parer les donn√©es d'entra√Ænement, √©valuer et affiner le mod√®le.
  - Calcul - pour ex√©cuter les t√¢ches d'ajustement et d√©ployer le mod√®le ajust√©.
  - Donn√©es - acc√®s √† des exemples de qualit√© suffisante pour l'impact de l'ajustement.
- **Avantages** : Avez-vous confirm√© les avantages de l'ajustement ?
  - Qualit√© - le mod√®le ajust√© a-t-il surpass√© la base de comparaison ?
  - Co√ªt - cela r√©duit-il l'utilisation de tokens en simplifiant les prompts ?
  - Extensibilit√© - pouvez-vous r√©utiliser le mod√®le de base pour de nouveaux domaines ?

En r√©pondant √† ces questions, vous devriez √™tre en mesure de d√©cider si l'ajustement est la bonne approche pour votre cas d'utilisation. Id√©alement, l'approche est valide uniquement si les avantages l'emportent sur les co√ªts. Une fois que vous avez d√©cid√© de proc√©der, il est temps de penser √† _comment_ vous pouvez ajuster le mod√®le pr√©-entra√Æn√©.

Vous voulez obtenir plus d'informations sur le processus de prise de d√©cision ? Regardez [Ajuster ou ne pas ajuster](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Comment pouvons-nous ajuster un mod√®le pr√©-entra√Æn√© ?

Pour ajuster un mod√®le pr√©-entra√Æn√©, vous devez avoir :

- un mod√®le pr√©-entra√Æn√© √† ajuster
- un jeu de donn√©es √† utiliser pour l'ajustement
- un environnement d'entra√Ænement pour ex√©cuter la t√¢che d'ajustement
- un environnement d'h√©bergement pour d√©ployer le mod√®le ajust√©

## Ajustement en action

Les ressources suivantes fournissent des tutoriels √©tape par √©tape pour vous guider √† travers un exemple r√©el en utilisant un mod√®le s√©lectionn√© avec un jeu de donn√©es s√©lectionn√©. Pour suivre ces tutoriels, vous avez besoin d'un compte chez le fournisseur sp√©cifique, ainsi que d'un acc√®s au mod√®le et aux jeux de donn√©es pertinents.

| Fournisseur   | Tutoriel                                                                                                                                                                       | Description                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI        | [Comment ajuster les mod√®les de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)          | Apprenez √† ajuster un `gpt-35-turbo` pour un domaine sp√©cifique ("assistant de recettes") en pr√©parant des donn√©es d'entra√Ænement, en ex√©cutant la t√¢che d'ajustement et en utilisant le mod√®le ajust√© pour l'inf√©rence.                                                                                                                                                                                                                                                |
| Azure OpenAI  | [Tutoriel d'ajustement de GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Apprenez √† ajuster un mod√®le `gpt-35-turbo-0613` **sur Azure** en suivant les √©tapes pour cr√©er et t√©l√©charger des donn√©es d'entra√Ænement, ex√©cuter la t√¢che d'ajustement. D√©ployez et utilisez le nouveau mod√®le.                                                                                                                                                                                                                                                         |
| Hugging Face  | [Ajustement des LLMs avec Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                           | Cet article de blog vous guide dans l'ajustement d'un _LLM ouvert_ (ex : `CodeLlama 7B`) en utilisant la biblioth√®que [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) et [l'apprentissage par renforcement des transformateurs (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) avec des [jeux de donn√©es](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) ouverts sur Hugging Face. |
|               |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain  | [Ajustement des LLMs avec AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                      | AutoTrain (ou AutoTrain Advanced) est une biblioth√®que python d√©velopp√©e par Hugging Face qui permet l'ajustement pour de nombreuses t√¢ches diff√©rentes, y compris l'ajustement des LLM. AutoTrain est une solution sans code et l'ajustement peut √™tre effectu√© dans votre propre cloud, sur Hugging Face Spaces ou localement. Il prend en charge une interface graphique web, CLI et l'entra√Ænement via des fichiers de configuration yaml.                             |
|               |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Devoir

S√©lectionnez l'un des tutoriels ci-dessus et parcourez-le. _Nous pourrions reproduire une version de ces tutoriels dans des Jupyter Notebooks dans ce d√©p√¥t √† titre de r√©f√©rence uniquement. Veuillez utiliser les sources originales directement pour obtenir les derni√®res versions_.

## Excellent travail ! Continuez votre apprentissage.

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage sur l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† d√©velopper vos connaissances en IA g√©n√©rative !

F√©licitations !! Vous avez termin√© la derni√®re le√ßon de la s√©rie v2 de ce cours ! Ne cessez pas d'apprendre et de construire. **Consultez la page [RESSOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pour une liste de suggestions suppl√©mentaires pour ce sujet.

Notre s√©rie de le√ßons v1 a √©galement √©t√© mise √† jour avec plus de devoirs et de concepts. Alors prenez une minute pour rafra√Æchir vos connaissances - et veuillez [partager vos questions et commentaires](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) pour nous aider √† am√©liorer ces le√ßons pour la communaut√©.

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.