<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T22:42:05+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "fr"
}
-->
[![Mod√®les Open Source](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.fr.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Affiner votre LLM

Utiliser des mod√®les de langage √©tendus pour cr√©er des applications d'IA g√©n√©rative pr√©sente de nouveaux d√©fis. Un probl√®me cl√© est de garantir la qualit√© des r√©ponses (pr√©cision et pertinence) dans le contenu g√©n√©r√© par le mod√®le pour une demande utilisateur donn√©e. Dans les le√ßons pr√©c√©dentes, nous avons discut√© de techniques telles que l'ing√©nierie des invites et la g√©n√©ration augment√©e par la r√©cup√©ration, qui tentent de r√©soudre le probl√®me en _modifiant l'entr√©e de l'invite_ du mod√®le existant.

Dans la le√ßon d'aujourd'hui, nous abordons une troisi√®me technique, **l'affinage**, qui tente de relever le d√©fi en _r√©entra√Ænant le mod√®le lui-m√™me_ avec des donn√©es suppl√©mentaires. Plongeons dans les d√©tails.

## Objectifs d'apprentissage

Cette le√ßon introduit le concept d'affinage pour les mod√®les de langage pr√©-entra√Æn√©s, explore les avantages et les d√©fis de cette approche, et fournit des conseils sur quand et comment utiliser l'affinage pour am√©liorer les performances de vos mod√®les d'IA g√©n√©rative.

√Ä la fin de cette le√ßon, vous devriez √™tre en mesure de r√©pondre aux questions suivantes :

- Qu'est-ce que l'affinage des mod√®les de langage ?
- Quand, et pourquoi, l'affinage est-il utile ?
- Comment puis-je affiner un mod√®le pr√©-entra√Æn√© ?
- Quelles sont les limites de l'affinage ?

Pr√™t ? C'est parti.

## Guide illustr√©

Vous voulez avoir une vue d'ensemble de ce que nous allons couvrir avant de plonger dans les d√©tails ? Consultez ce guide illustr√© qui d√©crit le parcours d'apprentissage de cette le√ßon - depuis l'apprentissage des concepts de base et la motivation pour l'affinage, jusqu'√† la compr√©hension du processus et des meilleures pratiques pour ex√©cuter la t√¢che d'affinage. C'est un sujet fascinant √† explorer, alors n'oubliez pas de consulter la page [Ressources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pour des liens suppl√©mentaires qui soutiendront votre parcours d'apprentissage autonome !

![Guide illustr√© pour l'affinage des mod√®les de langage](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.fr.png)

## Qu'est-ce que l'affinage des mod√®les de langage ?

Par d√©finition, les mod√®les de langage √©tendus sont _pr√©-entra√Æn√©s_ sur de grandes quantit√©s de texte provenant de diverses sources, y compris Internet. Comme nous l'avons appris dans les le√ßons pr√©c√©dentes, nous avons besoin de techniques comme _l'ing√©nierie des invites_ et _la g√©n√©ration augment√©e par la r√©cup√©ration_ pour am√©liorer la qualit√© des r√©ponses du mod√®le aux questions des utilisateurs ("invites").

Une technique populaire d'ing√©nierie des invites consiste √† donner au mod√®le plus de directives sur ce qui est attendu dans la r√©ponse, soit en fournissant des _instructions_ (guidage explicite), soit en _donnant quelques exemples_ (guidage implicite). Cela est appel√© _apprentissage par quelques exemples_, mais cela pr√©sente deux limites :

- Les limites de tokens du mod√®le peuvent restreindre le nombre d'exemples que vous pouvez fournir et limiter l'efficacit√©.
- Les co√ªts des tokens du mod√®le peuvent rendre co√ªteux l'ajout d'exemples √† chaque invite et limiter la flexibilit√©.

L'affinage est une pratique courante dans les syst√®mes d'apprentissage automatique o√π nous prenons un mod√®le pr√©-entra√Æn√© et le r√©entra√Ænons avec de nouvelles donn√©es pour am√©liorer ses performances sur une t√¢che sp√©cifique. Dans le contexte des mod√®les de langage, nous pouvons affiner le mod√®le pr√©-entra√Æn√© _avec un ensemble d'exemples soigneusement s√©lectionn√©s pour une t√¢che ou un domaine d'application donn√©_ afin de cr√©er un **mod√®le personnalis√©** qui peut √™tre plus pr√©cis et pertinent pour cette t√¢che ou ce domaine sp√©cifique. Un avantage secondaire de l'affinage est qu'il peut √©galement r√©duire le nombre d'exemples n√©cessaires pour l'apprentissage par quelques exemples - r√©duisant ainsi l'utilisation des tokens et les co√ªts associ√©s.

## Quand et pourquoi devrions-nous affiner les mod√®les ?

Dans _ce_ contexte, lorsque nous parlons d'affinage, nous faisons r√©f√©rence √† l'affinage **supervis√©**, o√π le r√©entra√Ænement est effectu√© en **ajoutant de nouvelles donn√©es** qui ne faisaient pas partie du jeu de donn√©es d'entra√Ænement original. Cela diff√®re d'une approche d'affinage non supervis√© o√π le mod√®le est r√©entra√Æn√© sur les donn√©es originales, mais avec des hyperparam√®tres diff√©rents.

La chose cl√© √† retenir est que l'affinage est une technique avanc√©e qui n√©cessite un certain niveau d'expertise pour obtenir les r√©sultats souhait√©s. Si elle est mal r√©alis√©e, elle peut ne pas fournir les am√©liorations attendues et peut m√™me d√©grader les performances du mod√®le pour votre domaine cibl√©.

Donc, avant d'apprendre "comment" affiner les mod√®les de langage, vous devez savoir "pourquoi" vous devriez emprunter cette voie et "quand" commencer le processus d'affinage. Commencez par vous poser ces questions :

- **Cas d'utilisation** : Quel est votre _cas d'utilisation_ pour l'affinage ? Quel aspect du mod√®le pr√©-entra√Æn√© actuel souhaitez-vous am√©liorer ?
- **Alternatives** : Avez-vous essay√© _d'autres techniques_ pour atteindre les r√©sultats souhait√©s ? Utilisez-les pour cr√©er une base de comparaison.
  - Ing√©nierie des invites : Essayez des techniques comme les invites par quelques exemples avec des exemples de r√©ponses pertinentes. √âvaluez la qualit√© des r√©ponses.
  - G√©n√©ration augment√©e par la r√©cup√©ration : Essayez d'augmenter les invites avec des r√©sultats de requ√™te r√©cup√©r√©s en recherchant vos donn√©es. √âvaluez la qualit√© des r√©ponses.
- **Co√ªts** : Avez-vous identifi√© les co√ªts de l'affinage ?
  - Adaptabilit√© - le mod√®le pr√©-entra√Æn√© est-il disponible pour l'affinage ?
  - Effort - pour pr√©parer les donn√©es d'entra√Ænement, √©valuer et affiner le mod√®le.
  - Calcul - pour ex√©cuter les t√¢ches d'affinage et d√©ployer le mod√®le affin√©.
  - Donn√©es - acc√®s √† des exemples de qualit√© suffisante pour un impact d'affinage.
- **Avantages** : Avez-vous confirm√© les avantages de l'affinage ?
  - Qualit√© - le mod√®le affin√© a-t-il surpass√© la base de comparaison ?
  - Co√ªt - r√©duit-il l'utilisation des tokens en simplifiant les invites ?
  - Extensibilit√© - pouvez-vous r√©utiliser le mod√®le de base pour de nouveaux domaines ?

En r√©pondant √† ces questions, vous devriez √™tre en mesure de d√©cider si l'affinage est la bonne approche pour votre cas d'utilisation. Id√©alement, l'approche est valide uniquement si les avantages d√©passent les co√ªts. Une fois que vous d√©cidez de proc√©der, il est temps de r√©fl√©chir √† _comment_ vous pouvez affiner le mod√®le pr√©-entra√Æn√©.

Vous voulez en savoir plus sur le processus de prise de d√©cision ? Regardez [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Comment pouvons-nous affiner un mod√®le pr√©-entra√Æn√© ?

Pour affiner un mod√®le pr√©-entra√Æn√©, vous devez disposer de :

- un mod√®le pr√©-entra√Æn√© √† affiner
- un jeu de donn√©es √† utiliser pour l'affinage
- un environnement d'entra√Ænement pour ex√©cuter la t√¢che d'affinage
- un environnement d'h√©bergement pour d√©ployer le mod√®le affin√©

## Affinage en action

Les ressources suivantes fournissent des tutoriels √©tape par √©tape pour vous guider √† travers un exemple r√©el en utilisant un mod√®le s√©lectionn√© avec un jeu de donn√©es soigneusement pr√©par√©. Pour suivre ces tutoriels, vous avez besoin d'un compte chez le fournisseur sp√©cifique, ainsi que d'un acc√®s au mod√®le et aux jeux de donn√©es pertinents.

| Fournisseur  | Tutoriel                                                                                                                                                                       | Description                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Comment affiner les mod√®les de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)         | Apprenez √† affiner un `gpt-35-turbo` pour un domaine sp√©cifique ("assistant de recettes") en pr√©parant des donn√©es d'entra√Ænement, en ex√©cutant la t√¢che d'affinage et en utilisant le mod√®le affin√© pour l'inf√©rence.                                                                                                                                                                                                             |
| Azure OpenAI | [Tutoriel d'affinage GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Apprenez √† affiner un mod√®le `gpt-35-turbo-0613` **sur Azure** en prenant des mesures pour cr√©er et t√©l√©charger des donn√©es d'entra√Ænement, ex√©cuter la t√¢che d'affinage. D√©ployez et utilisez le nouveau mod√®le.                                                                                                                                                                                                                                                         |
| Hugging Face | [Affiner les LLMs avec Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Ce billet de blog vous guide dans l'affinage d'un _LLM ouvert_ (ex : `CodeLlama 7B`) en utilisant la biblioth√®que [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) et [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) avec des [jeux de donn√©es ouverts](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) sur Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Affiner les LLMs avec AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (ou AutoTrain Advanced) est une biblioth√®que Python d√©velopp√©e par Hugging Face qui permet l'affinage pour de nombreuses t√¢ches diff√©rentes, y compris l'affinage des LLM. AutoTrain est une solution sans code et l'affinage peut √™tre effectu√© dans votre propre cloud, sur Hugging Face Spaces ou localement. Il prend en charge une interface graphique web, une interface en ligne de commande et un entra√Ænement via des fichiers de configuration yaml.             |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Devoir

S√©lectionnez l'un des tutoriels ci-dessus et suivez-le. _Nous pourrions reproduire une version de ces tutoriels dans des Jupyter Notebooks dans ce d√©p√¥t √† titre de r√©f√©rence uniquement. Veuillez utiliser directement les sources originales pour obtenir les derni√®res versions_.

## Bon travail ! Continuez votre apprentissage.

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage sur l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† approfondir vos connaissances en IA g√©n√©rative !

F√©licitations !! Vous avez termin√© la derni√®re le√ßon de la s√©rie v2 de ce cours ! Ne cessez pas d'apprendre et de construire. \*\*Consultez la page [RESSOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pour une liste de suggestions suppl√©mentaires sur ce sujet.

Notre s√©rie de le√ßons v1 a √©galement √©t√© mise √† jour avec plus de devoirs et de concepts. Prenez donc une minute pour rafra√Æchir vos connaissances - et n'h√©sitez pas √† [partager vos questions et commentaires](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) pour nous aider √† am√©liorer ces le√ßons pour la communaut√©.

---

**Avertissement** :  
Ce document a √©t√© traduit √† l'aide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous efforcions d'assurer l'exactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d'origine doit √™tre consid√©r√© comme la source faisant autorit√©. Pour des informations critiques, il est recommand√© de recourir √† une traduction humaine professionnelle. Nous ne sommes pas responsables des malentendus ou des interpr√©tations erron√©es r√©sultant de l'utilisation de cette traduction.