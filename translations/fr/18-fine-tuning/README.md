[![Open Source Models](../../../translated_images/fr/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Affiner Votre LLM

Utiliser de grands mod√®les de langage pour construire des applications d'IA g√©n√©rative implique de nouveaux d√©fis. Un enjeu cl√© est garantir la qualit√© des r√©ponses (pr√©cision et pertinence) dans le contenu g√©n√©r√© par le mod√®le pour une requ√™te utilisateur donn√©e. Dans les le√ßons pr√©c√©dentes, nous avons discut√© des techniques comme l'ing√©nierie des invites et la g√©n√©ration augment√©e par r√©cup√©ration qui tentent de r√©soudre le probl√®me en _modifiant l'entr√©e de l'invite_ au mod√®le existant.

Dans la le√ßon d'aujourd'hui, nous abordons une troisi√®me technique, **l'affinage**, qui tente de relever le d√©fi en _r√©entra√Ænant le mod√®le lui-m√™me_ avec des donn√©es suppl√©mentaires. Entrons dans les d√©tails.

## Objectifs d'apprentissage

Cette le√ßon introduit le concept d'affinage pour les mod√®les de langage pr√©-entra√Æn√©s, explore les avantages et les d√©fis de cette approche, et fournit des conseils sur quand et comment utiliser l'affinage pour am√©liorer les performances de vos mod√®les d'IA g√©n√©rative.

√Ä la fin de cette le√ßon, vous devriez √™tre capable de r√©pondre aux questions suivantes :

- Qu'est-ce que l'affinage des mod√®les de langage ?
- Quand et pourquoi l'affinage est-il utile ?
- Comment puis-je affiner un mod√®le pr√©-entra√Æn√© ?
- Quelles sont les limites de l'affinage ?

Pr√™t ? Commen√ßons.

## Guide Illustr√©

Vous souhaitez avoir une vue d'ensemble de ce que nous allons couvrir avant de plonger ? Consultez ce guide illustr√© qui d√©crit le parcours d'apprentissage pour cette le√ßon - de l'apprentissage des concepts cl√©s et de la motivation pour l'affinage, √† la compr√©hension du processus et des meilleures pratiques pour ex√©cuter la t√¢che d'affinage. C'est un sujet fascinant √† explorer, n'oubliez pas de consulter la page [Ressources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pour des liens suppl√©mentaires afin de soutenir votre parcours d'apprentissage autonome !

![Guide Illustr√© pour l'Affinage des Mod√®les de Langage](../../../translated_images/fr/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Qu'est-ce que l'affinage des mod√®les de langage ?

Par d√©finition, les grands mod√®les de langage sont _pr√©-entra√Æn√©s_ sur de grandes quantit√©s de texte provenant de sources diverses, y compris Internet. Comme nous l'avons appris dans les le√ßons pr√©c√©dentes, nous avons besoin de techniques comme l'_ing√©nierie des invites_ et la _g√©n√©ration augment√©e par r√©cup√©ration_ pour am√©liorer la qualit√© des r√©ponses du mod√®le aux questions de l'utilisateur ("invites").

Une technique populaire d'ing√©nierie des invites consiste √† fournir au mod√®le plus d'orientations sur ce qui est attendu dans la r√©ponse, soit en donnant des _instructions_ (orientation explicite) soit en _fournissant quelques exemples_ (orientation implicite). Cela s'appelle l'_apprentissage par quelques exemples_ mais cela a deux limites :

- Les limites de tokens du mod√®le peuvent restreindre le nombre d'exemples que vous pouvez donner, et limiter l'efficacit√©.
- Le co√ªt en tokens du mod√®le peut rendre on√©reux l'ajout d'exemples √† chaque invite, et limiter la flexibilit√©.

L'affinage est une pratique courante dans les syst√®mes d'apprentissage automatique o√π l'on prend un mod√®le pr√©-entra√Æn√© et on le r√©entra√Æne avec de nouvelles donn√©es pour am√©liorer ses performances sur une t√¢che sp√©cifique. Dans le contexte des mod√®les de langage, on peut affiner le mod√®le pr√©-entra√Æn√© _avec un ensemble s√©lectionn√© d'exemples pour une t√¢che ou un domaine d'application donn√©_ pour cr√©er un **mod√®le personnalis√©** qui peut √™tre plus pr√©cis et pertinent pour cette t√¢che ou ce domaine sp√©cifique. Un avantage secondaire de l'affinage est qu'il peut √©galement r√©duire le nombre d'exemples n√©cessaires pour l'apprentissage par quelques exemples - r√©duisant ainsi l'utilisation des tokens et les co√ªts associ√©s.

## Quand et pourquoi devrions-nous affiner les mod√®les ?

Dans _ce_ contexte, lorsque nous parlons d'affinage, nous faisons r√©f√©rence √† un affinage **supervis√©** o√π le r√©entra√Ænement est effectu√© en **ajoutant de nouvelles donn√©es** qui ne faisaient pas partie du jeu de donn√©es d'entra√Ænement original. Cela diff√®re d'une approche d'affinage non supervis√©e o√π le mod√®le est r√©entra√Æn√© sur les donn√©es originales, mais avec des hyperparam√®tres diff√©rents.

L'essentiel √† retenir est que l'affinage est une technique avanc√©e qui n√©cessite un certain niveau d'expertise pour obtenir les r√©sultats souhait√©s. S'il est mal effectu√©, il peut ne pas apporter les am√©liorations attendues, voire d√©grader les performances du mod√®le pour votre domaine cibl√©.

Donc, avant d'apprendre "comment" affiner les mod√®les de langage, vous devez savoir "pourquoi" vous devriez emprunter cette voie, et "quand" commencer le processus d'affinage. Commencez par vous poser ces questions :

- **Cas d'utilisation** : Quel est votre _cas d'utilisation_ pour l'affinage ? Quel aspect du mod√®le pr√©-entra√Æn√© actuel souhaitez-vous am√©liorer ?
- **Alternatives** : Avez-vous essay√© _d'autres techniques_ pour atteindre les r√©sultats souhait√©s ? Utilisez-les pour √©tablir une base de comparaison.
  - Ing√©nierie des invites : Essayez des techniques comme les invites par quelques exemples avec des exemples de r√©ponses pertinentes. √âvaluez la qualit√© des r√©ponses.
  - G√©n√©ration augment√©e par r√©cup√©ration : Essayez d'augmenter les invites avec les r√©sultats de requ√™tes r√©cup√©r√©s en recherchant dans vos donn√©es. √âvaluez la qualit√© des r√©ponses.
- **Co√ªts** : Avez-vous identifi√© les co√ªts li√©s √† l'affinage ?
  - Possibilit√© d'affinage - le mod√®le pr√©-entra√Æn√© est-il disponible pour √™tre affin√© ?
  - Effort - pour pr√©parer les donn√©es d'entra√Ænement, √©valuer et affiner le mod√®le.
  - Calcul - pour ex√©cuter les travaux d'affinage et d√©ployer le mod√®le affin√©
  - Donn√©es - acc√®s √† des exemples de qualit√© suffisante pour un impact d'affinage
- **Avantages** : Avez-vous confirm√© les avantages de l'affinage ?
  - Qualit√© - le mod√®le affin√© a-t-il surpass√© la base de r√©f√©rence ?
  - Co√ªt - r√©duit-il l'utilisation des tokens en simplifiant les invites ?
  - Extensibilit√© - pouvez-vous r√©utiliser le mod√®le de base pour de nouveaux domaines ?

En r√©pondant √† ces questions, vous devriez √™tre en mesure de d√©cider si l'affinage est la bonne approche pour votre cas d'utilisation. Id√©alement, l'approche est valable uniquement si les avantages l'emportent sur les co√ªts. Une fois que vous d√©cidez de continuer, il est temps de r√©fl√©chir √† _comment_ vous pouvez affiner le mod√®le pr√©-entra√Æn√©.

Vous souhaitez avoir plus d'informations sur le processus de d√©cision ? Regardez [Affiner ou ne pas affiner](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Comment pouvons-nous affiner un mod√®le pr√©-entra√Æn√© ?

Pour affiner un mod√®le pr√©-entra√Æn√©, vous devez disposer de :

- un mod√®le pr√©-entra√Æn√© √† affiner
- un jeu de donn√©es √† utiliser pour l'affinage
- un environnement d'entra√Ænement pour ex√©cuter le travail d'affinage
- un environnement d'h√©bergement pour d√©ployer le mod√®le affin√©

## Affinage en action

Les ressources suivantes fournissent des tutoriels √©tape par √©tape pour vous guider √† travers un exemple r√©el utilisant un mod√®le s√©lectionn√© avec un jeu de donn√©es s√©lectionn√©. Pour suivre ces tutoriels, vous avez besoin d'un compte chez le fournisseur sp√©cifique, ainsi que l'acc√®s aux mod√®les et jeux de donn√©es pertinents.

| Fournisseur | Tutoriel                                                                                                                                                  | Description                                                                                                                                                                                                                                                                                                                                                                                                                           |
| ----------- | --------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [Comment affiner des mod√®les de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Apprenez √† affiner un `gpt-35-turbo` pour un domaine sp√©cifique ("assistant de recettes") en pr√©parant les donn√©es d'entra√Ænement, en ex√©cutant le travail d'affinage et en utilisant le mod√®le affin√© pour l'inf√©rence.                                                                                                                                                                                                               |
| Azure OpenAI | [Tutoriel d'affinage GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Apprenez √† affiner un mod√®le `gpt-35-turbo-0613` **sur Azure** en cr√©ant et t√©l√©chargeant les donn√©es d'entra√Ænement, en ex√©cutant le travail d'affinage. D√©ployez et utilisez le nouveau mod√®le.                                                                                                                                                                                                                                    |
| Hugging Face | [Affiner les LLMs avec Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                          | Cet article de blog vous guide dans l'affinage d'un _LLM ouvert_ (ex : `CodeLlama 7B`) √† l'aide de la biblioth√®que [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) et de [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) avec des [datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) ouverts sur Hugging Face. |
|             |                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| ü§ó AutoTrain | [Affiner les LLMs avec AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                   | AutoTrain (ou AutoTrain Advanced) est une biblioth√®que python d√©velopp√©e par Hugging Face qui permet l'affinage pour de nombreuses t√¢ches diff√©rentes incluant l'affinage des LLM. AutoTrain est une solution sans code et l'affinage peut √™tre fait dans votre propre cloud, sur Hugging Face Spaces ou localement. Il prend en charge une interface graphique web, CLI et la formation via des fichiers de configuration yaml.                                                                        |
|             |                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                     |
| ü¶• Unsloth  | [Affiner les LLMs avec Unsloth](https://github.com/unslothai/unsloth)                                                                                   | Unsloth est un cadre open-source qui prend en charge l'affinage des LLM et l'apprentissage par renforcement (RL). Unsloth simplifie l'entra√Ænement, l'√©valuation et le d√©ploiement locaux avec des [notebooks](https://github.com/unslothai/notebooks) pr√™ts √† l'emploi. Il prend aussi en charge la synth√®se vocale (TTS), BERT et les mod√®les multimodaux. Pour commencer, lisez leur guide pas √† pas [Guide d'affinage des LLM](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                                                                        |
|             |                                                                                                                                                           |                                                                                                                                                                                                                                                                                                                                                                                                                                     |
## Exercice

S√©lectionnez un des tutoriels ci-dessus et suivez-le. _Nous pourrions reproduire une version de ces tutoriels dans des Jupyter Notebooks de ce d√©p√¥t √† titre de r√©f√©rence uniquement. Veuillez utiliser les sources originales directement pour obtenir les derni√®res versions_.

## Tr√®s bon travail ! Continuez √† apprendre.

Apr√®s avoir termin√© cette le√ßon, consultez notre [collection d'apprentissage de l'IA g√©n√©rative](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pour continuer √† monter en comp√©tence sur l'IA g√©n√©rative !

F√©licitations !! Vous avez termin√© la derni√®re le√ßon de la s√©rie v2 de ce cours ! Ne vous arr√™tez pas d'apprendre et de construire. \*\*Consultez la page [RESSOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pour une liste de suggestions suppl√©mentaires sur ce seul sujet.

Notre s√©rie de le√ßons v1 a √©galement √©t√© mise √† jour avec plus d'exercices et de concepts. Prenez donc une minute pour rafra√Æchir vos connaissances - et veuillez [partager vos questions et retours](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) pour nous aider √† am√©liorer ces le√ßons pour la communaut√©.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Avertissement** :  
Ce document a √©t√© traduit √† l‚Äôaide du service de traduction automatique [Co-op Translator](https://github.com/Azure/co-op-translator). Bien que nous nous effor√ßions d‚Äôassurer l‚Äôexactitude, veuillez noter que les traductions automatis√©es peuvent contenir des erreurs ou des inexactitudes. Le document original dans sa langue d‚Äôorigine doit √™tre consid√©r√© comme la source faisant foi. Pour les informations critiques, une traduction professionnelle r√©alis√©e par un humain est recommand√©e. Nous d√©clinons toute responsabilit√© en cas de malentendus ou d‚Äôinterpr√©tations erron√©es r√©sultant de l‚Äôutilisation de cette traduction.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->