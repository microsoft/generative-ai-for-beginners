# ニューラルネットワーク入門: パーセプトロン

現代のニューラルネットワークに似たものを実装する最初の試みの一つは、1957年にコーネル航空研究所のフランク・ローゼンブラットによって行われました。それは「Mark-1」と呼ばれるハードウェア実装で、三角形、四角形、円などの基本的な幾何学的図形を認識するように設計されていました。

|      |      |
|--------------|-----------|
|<img src='images/Rosenblatt-wikipedia.jpg' alt='Frank Rosenblatt'/> | <img src='images/Mark_I_perceptron_wikipedia.jpg' alt='The Mark 1 Perceptron' />|

> 画像はWikipediaから

入力画像は20x20のフォトセル配列で表現されていたため、ニューラルネットワークには400の入力と1つのバイナリ出力がありました。シンプルなネットワークは1つのニューロン、または**しきい値論理ユニット**とも呼ばれるものを含んでいました。ニューラルネットワークの重みはポテンショメータのように機能し、トレーニングフェーズ中に手動で調整する必要がありました。

> ✅ ポテンショメータは、ユーザーが回路の抵抗を調整できるデバイスです。

> 当時、ニューヨーク・タイムズはパーセプトロンについて次のように書いていました: *[海軍が] 歩き、話し、見ることができ、書き、自らを再生産し、自分の存在を意識することができると期待する電子計算機の胚芽。*

## パーセプトロンモデル

モデルにN個の特徴があると仮定すると、入力ベクトルはサイズNのベクトルになります。パーセプトロンは**バイナリ分類**モデル、つまり2つのクラスの入力データを区別することができます。各入力ベクトルxに対して、パーセプトロンの出力がクラスに応じて+1または-1になると仮定します。出力は次の式を用いて計算されます：

y(x) = f(w<sup>T</sup>x)

ここでfはステップ活性化関数です。

## パーセプトロンのトレーニング

パーセプトロンをトレーニングするためには、ほとんどの値を正しく分類する重みベクトルwを見つける必要があります。つまり、最小の**エラー**をもたらす必要があります。このエラーは、次のように**パーセプトロンクライテリオン**によって定義されます：

E(w) = -∑w<sup>T</sup>x<sub>i</sub>t<sub>i</sub>

ここで：

* 和は誤分類をもたらすトレーニングデータポイントiについて取られます
* x<sub>i</sub>は入力データで、t<sub>i</sub>はそれぞれ負の例と正の例に対して-1または+1です。

この基準は重みwの関数として考えられ、これを最小化する必要があります。しばしば、**勾配降下法**と呼ばれる方法が使用され、初期重みw<sup>(0)</sup>から始め、各ステップで次の式に従って重みを更新します：

w<sup>(t+1)</sup> = w<sup>(t)</sup> - η∇E(w)

ここでηは**学習率**と呼ばれ、∇E(w)はEの**勾配**を示します。勾配を計算した後、次のようになります：

w<sup>(t+1)</sup> = w<sup>(t)</sup> + ∑ηx<sub>i</sub>t<sub>i</sub>

Pythonでのアルゴリズムは次のようになります：

```python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)
        
    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```

## 結論

このレッスンでは、バイナリ分類モデルであるパーセプトロンと、重みベクトルを使用してそれをトレーニングする方法について学びました。

## 🚀 チャレンジ

独自のパーセプトロンを構築してみたい場合は、Azure MLデザイナーを使用したMicrosoft Learnのこのラボに挑戦してみてください。

## レビューと自己学習

パーセプトロンを使用しておもちゃの問題や実際の問題を解決する方法を見て学習を続けるには、パーセプトロンノートブックに進んでください。

パーセプトロンに関する興味深い記事もあります。

## 課題

このレッスンでは、バイナリ分類タスクのためにパーセプトロンを実装し、2つの手書き数字を分類するために使用しました。このラボでは、与えられた画像に最も対応する可能性の高い数字を決定する、数字分類の問題を完全に解決するよう求められています。

* 手順
* ノートブック

**免責事項**:  
この文書は、機械翻訳サービスを使用して翻訳されています。正確さを追求していますが、自動翻訳には誤りや不正確さが含まれる可能性があります。元の言語での原文を信頼できる情報源として考慮してください。重要な情報については、専門の人間による翻訳をお勧めします。この翻訳の使用に起因する誤解や誤った解釈について、当方は責任を負いません。