{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像生成アプリケーションの構築\n",
    "\n",
    "LLMはテキスト生成だけではありません。テキストの説明から画像を生成することも可能です。画像というモダリティを活用することで、MedTech、建築、観光、ゲーム開発など、さまざまな分野で非常に役立ちます。この章では、最も人気のある画像生成モデルであるDALL-EとMidjourneyについて見ていきます。\n",
    "\n",
    "## はじめに\n",
    "\n",
    "このレッスンでは、以下の内容を扱います：\n",
    "\n",
    "- 画像生成とは何か、なぜ役立つのか\n",
    "- DALL-EとMidjourneyとは何か、それらがどのように動作するのか\n",
    "- 画像生成アプリをどのように作るか\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このレッスンを終えた後、あなたは以下ができるようになります：\n",
    "\n",
    "- 画像生成アプリケーションを構築する\n",
    "- メタプロンプトを使ってアプリケーションの範囲を定義する\n",
    "- DALL-EとMidjourneyを使いこなす\n",
    "\n",
    "## なぜ画像生成アプリケーションを作るのか？\n",
    "\n",
    "画像生成アプリケーションは、生成AIの可能性を探る素晴らしい方法です。例えば、以下のような用途で活用できます：\n",
    "\n",
    "- **画像編集や合成**  \n",
    "  画像編集や画像合成など、さまざまな用途のために画像を生成できます。\n",
    "\n",
    "- **多様な業界での応用**  \n",
    "  MedTech、観光、ゲーム開発など、さまざまな業界向けの画像生成にも利用できます。\n",
    "\n",
    "## シナリオ：Edu4All\n",
    "\n",
    "このレッスンでは、引き続きスタートアップのEdu4Allを題材に進めます。生徒たちは自分たちの課題のために画像を作成します。どんな画像を作るかは生徒次第ですが、自分の童話のイラストを描いたり、新しいキャラクターを作ったり、アイデアやコンセプトを視覚化するのに役立てたりできます。\n",
    "\n",
    "例えば、Edu4Allの生徒が授業で記念碑について学んでいる場合、次のような画像を生成できます：\n",
    "\n",
    "![Edu4All startup, class on monuments, Eifel Tower](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.ja.png)\n",
    "\n",
    "このようなプロンプトを使って\n",
    "\n",
    "> 「朝日が差し込むエッフェル塔のそばにいる犬」\n",
    "\n",
    "## DALL-EとMidjourneyとは？\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst)と[Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst)は、最も人気のある画像生成モデルの2つで、プロンプトを使って画像を生成できます。\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "まずはDALL-Eから見ていきましょう。DALL-Eは、テキストの説明から画像を生成する生成AIモデルです。\n",
    "\n",
    "> [DALL-Eは、CLIPとdiffused attentionという2つのモデルを組み合わせたものです](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)。\n",
    "\n",
    "- **CLIP**は、画像やテキストから数値的な表現（埋め込み）を生成するモデルです。\n",
    "\n",
    "- **Diffused attention**は、埋め込みから画像を生成するモデルです。DALL-Eは画像とテキストのデータセットで学習されており、テキストの説明から画像を生成できます。例えば、DALL-Eを使えば「帽子をかぶった猫」や「モヒカンの犬」の画像を作ることができます。\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "MidjourneyもDALL-Eと同様に、テキストプロンプトから画像を生成します。Midjourneyでも「帽子をかぶった猫」や「モヒカンの犬」といったプロンプトで画像を作成できます。\n",
    "\n",
    "![Image generated by Midjourney, mechanical pigeon](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*画像提供：Wikipedia、Midjourneyによる生成画像*\n",
    "\n",
    "## DALL-EとMidjourneyはどのように動作するのか\n",
    "\n",
    "まず[DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)について。DALL-Eは、*オートレグレッシブトランスフォーマー*を用いたトランスフォーマーアーキテクチャに基づく生成AIモデルです。\n",
    "\n",
    "*オートレグレッシブトランスフォーマー*は、テキストの説明から画像を生成する際の仕組みを定義しています。1ピクセルずつ生成し、生成したピクセルを使って次のピクセルを作り出します。ニューラルネットワークの複数の層を通過しながら、画像が完成するまでこのプロセスを繰り返します。\n",
    "\n",
    "このプロセスによって、DALL-Eは生成する画像の属性やオブジェクト、特徴などをコントロールできます。ただし、DALL-E 2や3では、さらに細かく生成画像を制御できるようになっています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初めての画像生成アプリケーションを作成する\n",
    "\n",
    "画像生成アプリケーションを作るには何が必要でしょうか？以下のライブラリが必要です。\n",
    "\n",
    "- **python-dotenv**：このライブラリを使うことで、シークレット情報をコードから分離して*.env*ファイルに保存できます。利用を強くおすすめします。\n",
    "- **openai**：OpenAI APIとやり取りするために使うライブラリです。\n",
    "- **pillow**：Pythonで画像を扱うためのライブラリです。\n",
    "- **requests**：HTTPリクエストを送るのに役立ちます。\n",
    "\n",
    "1. *.env*ファイルを作成し、次の内容を記述します。\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 上記のライブラリを *requirements.txt* というファイルにまとめてください。例：\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. 次に、仮想環境を作成し、ライブラリをインストールします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Windowsの場合、仮想環境を作成して有効化するには、以下のコマンドを使用してください。\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. *app.py*というファイルに、次のコードを追加します。\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "このコードについて説明します。\n",
    "\n",
    "- まず、必要なライブラリをインポートします。OpenAIライブラリ、dotenvライブラリ、requestsライブラリ、Pillowライブラリなどです。\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- 次に、APIキーを``.env``から取得するオブジェクトを作成します。\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- 続いて、画像を生成します。\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    上記のコードは、生成された画像のURLを含むJSONオブジェクトを返します。このURLを使って画像をダウンロードし、ファイルとして保存できます。\n",
    "\n",
    "- 最後に、画像を開いて標準の画像ビューアで表示します。\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### 画像生成の詳細\n",
    "\n",
    "画像を生成するコードをもう少し詳しく見てみましょう。\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**は、画像を生成するためのテキストプロンプトです。この例では「Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils」というプロンプトを使っています。\n",
    "- **size**は、生成される画像のサイズです。この場合、1024x1024ピクセルの画像を生成しています。\n",
    "- **n**は、生成する画像の枚数です。この例では2枚の画像を生成しています。\n",
    "\n",
    "画像に関しては、他にもできることがあり、次のセクションで紹介します。\n",
    "\n",
    "## 画像生成の追加機能\n",
    "\n",
    "ここまでで、Pythonの数行のコードで画像を生成できることが分かりました。しかし、画像に対してできることは他にもあります。\n",
    "\n",
    "例えば、次のようなことも可能です。\n",
    "\n",
    "- **編集を行う**  \n",
    "  既存の画像、マスク、プロンプトを指定することで、画像を編集できます。例えば、画像の一部に何かを追加することができます。ウサギの画像を例にすると、ウサギに帽子をかぶせることができます。やり方は、画像、マスク（変更したい部分を指定）、そして何をしたいかを説明するテキストプロンプトを用意します。\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    元の画像にはウサギだけが写っていますが、最終的な画像にはウサギに帽子が追加されます。\n",
    "\n",
    "- **バリエーションを作成する**  \n",
    "  既存の画像をもとに、バリエーションを作成することもできます。バリエーションを作るには、画像とテキストプロンプトを指定し、次のようなコードを書きます。\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責事項**:  \n本書類はAI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性には努めておりますが、自動翻訳には誤りや不正確な表現が含まれる場合があります。原文（原言語の文書）が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は一切の責任を負いかねます。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:33:52+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}