{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 画像生成アプリケーションの構築\n",
    "\n",
    "LLMはテキスト生成だけではありません。テキストの説明から画像を生成することも可能です。画像というモダリティを活用することで、医療技術、建築、観光、ゲーム開発など、さまざまな分野で非常に役立ちます。この章では、最も人気のある画像生成モデルであるDALL-EとMidjourneyについて見ていきます。\n",
    "\n",
    "## はじめに\n",
    "\n",
    "このレッスンでは、以下の内容を扱います：\n",
    "\n",
    "- 画像生成とは何か、なぜ役立つのか\n",
    "- DALL-EとMidjourneyとは何か、それらがどのように動作するのか\n",
    "- 画像生成アプリをどのように作るか\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このレッスンを終えた後、あなたは以下のことができるようになります：\n",
    "\n",
    "- 画像生成アプリケーションを構築する\n",
    "- メタプロンプトを使ってアプリケーションの範囲を定義する\n",
    "- DALL-EとMidjourneyを使いこなす\n",
    "\n",
    "## なぜ画像生成アプリケーションを作るのか？\n",
    "\n",
    "画像生成アプリケーションは、生成AIの可能性を探る素晴らしい方法です。例えば、以下のような用途で活用できます：\n",
    "\n",
    "- **画像編集や合成**  \n",
    "  画像編集や画像合成など、さまざまな用途のために画像を生成できます。\n",
    "\n",
    "- **多様な業界での応用**  \n",
    "  医療技術、観光、ゲーム開発など、さまざまな業界向けの画像生成にも利用できます。\n",
    "\n",
    "## シナリオ：Edu4All\n",
    "\n",
    "このレッスンでは、引き続きスタートアップのEdu4Allを題材に進めていきます。生徒たちは自分たちの課題のために画像を作成します。どんな画像を作るかは生徒次第ですが、自分の童話のイラストを描いたり、新しいキャラクターを作ったり、アイデアやコンセプトを視覚化するのに役立てたりできます。\n",
    "\n",
    "例えば、Edu4Allの生徒が授業で記念碑について学んでいる場合、次のような画像を生成できます：\n",
    "\n",
    "![Edu4Allスタートアップ、記念碑の授業、エッフェル塔](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.ja.png)\n",
    "\n",
    "このようなプロンプトを使って\n",
    "\n",
    "> 「朝日が差し込むエッフェル塔のそばにいる犬」\n",
    "\n",
    "## DALL-EとMidjourneyとは？\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst)と[Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst)は、最も人気のある画像生成モデルの2つで、プロンプトを使って画像を生成できます。\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "まずはDALL-Eから見ていきましょう。DALL-Eは、テキストの説明から画像を生成する生成AIモデルです。\n",
    "\n",
    "> [DALL-Eは、CLIPとdiffused attentionという2つのモデルを組み合わせたものです](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)。\n",
    "\n",
    "- **CLIP**は、画像やテキストからデータの数値表現（埋め込み）を生成するモデルです。\n",
    "\n",
    "- **Diffused attention**は、埋め込みから画像を生成するモデルです。DALL-Eは画像とテキストのデータセットで学習されており、テキストの説明から画像を生成できます。例えば、DALL-Eを使えば「帽子をかぶった猫」や「モヒカンの犬」の画像を作ることができます。\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "MidjourneyもDALL-Eと同様に、テキストプロンプトから画像を生成します。Midjourneyでも「帽子をかぶった猫」や「モヒカンの犬」といったプロンプトで画像を作成できます。\n",
    "\n",
    "![Midjourneyで生成された画像、機械仕掛けのハト](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*画像提供：Wikipedia、Midjourneyで生成*\n",
    "\n",
    "## DALL-EとMidjourneyはどのように動作するのか\n",
    "\n",
    "まず[DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)について。DALL-Eは、*オートレグレッシブトランスフォーマー*を用いたトランスフォーマーアーキテクチャに基づく生成AIモデルです。\n",
    "\n",
    "*オートレグレッシブトランスフォーマー*は、テキストの説明から画像を生成する際の仕組みを定義しています。1ピクセルずつ生成し、生成したピクセルを使って次のピクセルを作り出します。ニューラルネットワークの複数の層を通過しながら、画像が完成するまでこのプロセスを繰り返します。\n",
    "\n",
    "このプロセスによって、DALL-Eは生成する画像の属性やオブジェクト、特徴などをコントロールできます。ただし、DALL-E 2や3では、さらに細かく生成画像を制御できるようになっています。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最初の画像生成アプリケーションを作成する\n",
    "\n",
    "画像生成アプリケーションを作るには何が必要でしょうか？以下のライブラリが必要です。\n",
    "\n",
    "- **python-dotenv**：このライブラリを使うことで、秘密情報をコードから分離して*.env*ファイルに保存することが強く推奨されます。\n",
    "- **openai**：OpenAI APIとやり取りするために使うライブラリです。\n",
    "- **pillow**：Pythonで画像を扱うためのライブラリです。\n",
    "- **requests**：HTTPリクエストを送るのに役立つライブラリです。\n",
    "\n",
    "1. *.env*というファイルを作成し、次の内容を記入します。\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    この情報は、Azure Portalの「キーとエンドポイント」セクションでリソースごとに確認できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 上記のライブラリを *requirements.txt* というファイルにまとめてください。例：\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. 次に、仮想環境を作成し、ライブラリをインストールします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Windowsの場合、仮想環境を作成して有効化するには、次のコマンドを使ってください:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. *app.py*というファイルに、次のコードを追加します:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "このコードについて説明します。\n",
    "\n",
    "- まず、必要なライブラリをインポートします。OpenAIライブラリ、dotenvライブラリ、requestsライブラリ、Pillowライブラリなどです。\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- 次に、*.env*ファイルから環境変数を読み込みます。\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- その後、OpenAI APIのエンドポイント、キー、バージョン、タイプを設定します。\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- 次に、画像を生成します:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    上記のコードは、生成された画像のURLを含むJSONオブジェクトで応答します。このURLを使って画像をダウンロードし、ファイルとして保存できます。\n",
    "\n",
    "- 最後に、画像を開いて標準の画像ビューアで表示します:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### 画像生成の詳細\n",
    "\n",
    "画像を生成するコードをもう少し詳しく見てみましょう。\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** は、画像を生成するためのテキストプロンプトです。この例では「Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils」というプロンプトを使っています。\n",
    "- **size** は、生成される画像のサイズです。この例では1024x1024ピクセルの画像を生成しています。\n",
    "- **n** は、生成する画像の枚数です。この例では2枚の画像を生成しています。\n",
    "- **temperature** は、生成AIモデルの出力のランダム性を制御するパラメータです。0から1の値で、0は出力が決定的、1は出力がランダムになります。デフォルト値は0.7です。\n",
    "\n",
    "画像に関してできることは他にもあり、次のセクションで紹介します。\n",
    "\n",
    "## 画像生成の追加機能\n",
    "\n",
    "ここまでで、Pythonの数行のコードで画像を生成できることが分かりました。しかし、画像に対してできることは他にもあります。\n",
    "\n",
    "例えば、次のようなことも可能です。\n",
    "\n",
    "- **編集を行う**。既存の画像、マスク、プロンプトを指定することで、画像を変更できます。例えば、画像の一部に何かを追加することができます。ウサギの画像を例にすると、ウサギに帽子をかぶせることができます。そのためには、画像、マスク（変更したい部分を指定）、そして何をしたいかを説明するテキストプロンプトを用意します。\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    元の画像にはウサギだけが写っていますが、最終的な画像にはウサギに帽子が追加されます。\n",
    "\n",
    "- **バリエーションを作成する**。  \n",
    "    詳しくは[OpenAIノートブックをご覧ください](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責事項**:  \n本書類は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性には努めておりますが、自動翻訳には誤りや不正確な表現が含まれる場合があります。原文（元の言語の文書）が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は一切の責任を負いかねます。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:10:50+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}