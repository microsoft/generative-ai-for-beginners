{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## はじめに\n",
    "\n",
    "このレッスンでは以下の内容を扱います：\n",
    "- ファンクションコールとは何か、その利用例\n",
    "- OpenAIを使ったファンクションコールの作成方法\n",
    "- アプリケーションへのファンクションコールの組み込み方\n",
    "\n",
    "## 学習目標\n",
    "\n",
    "このレッスンを終えると、次のことができるようになります：\n",
    "\n",
    "- ファンクションコールを使う目的を理解する\n",
    "- OpenAIサービスを使ってファンクションコールを設定する\n",
    "- アプリケーションのユースケースに合わせて効果的なファンクションコールを設計する\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 関数呼び出しの理解\n",
    "\n",
    "このレッスンでは、教育系スタートアップのために、ユーザーがチャットボットを使って技術系コースを探せる機能を作成します。ユーザーのスキルレベル、現在の役割、興味のある技術に合ったコースをおすすめします。\n",
    "\n",
    "これを実現するために、以下を組み合わせて使います：\n",
    " - `OpenAI` を使ってユーザー向けのチャット体験を作成\n",
    " - `Microsoft Learn Catalog API` を使って、ユーザーのリクエストに基づきコースを検索\n",
    " - `Function Calling` を使って、ユーザーの問い合わせを関数に渡し、APIリクエストを実行\n",
    "\n",
    "まず、なぜ関数呼び出しを使うのかを見ていきましょう：\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPTが関数のレスポンスを確認できるように新しいレスポンスを取得\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### なぜFunction Callingが必要なのか\n",
    "\n",
    "このコースの他のレッスンを終えたことがあれば、Large Language Models（LLMs）の強力さはすでにご存知でしょう。同時に、その限界についても感じているかもしれません。\n",
    "\n",
    "Function Callingは、OpenAI Serviceの機能で、次のような課題を解決するために作られました。\n",
    "\n",
    "レスポンスのフォーマットが一貫しない問題:\n",
    "- Function Callingが導入される前は、LLMからの返答は構造化されておらず、一貫性もありませんでした。開発者は、出力のバリエーションごとに複雑なバリデーションコードを書く必要がありました。\n",
    "\n",
    "外部データとの連携が難しい問題:\n",
    "- この機能がなかった頃は、アプリケーションの他の部分からデータをチャットの文脈に組み込むのが困難でした。\n",
    "\n",
    "Function Callingによって、レスポンスのフォーマットが標準化され、外部データとの連携もスムーズになり、開発がシンプルになって追加のバリデーションロジックも減らせます。\n",
    "\n",
    "たとえば「ストックホルムの現在の天気は？」のような質問には、ユーザーは答えを得られませんでした。これは、モデルが学習した時点までのデータしか扱えなかったためです。\n",
    "\n",
    "この問題を示す例を見てみましょう。\n",
    "\n",
    "たとえば、学生データのデータベースを作成して、最適なコースを提案したいとします。下記には、含まれているデータが非常に似ている2人の学生の説明があります。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "このデータを解析するためにLLMに送信したいと考えています。これを後でアプリケーションでAPIに送信したり、データベースに保存したりするのに利用できます。\n",
    "\n",
    "私たちが関心のある情報についてLLMに指示する、まったく同じプロンプトを2つ作成しましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "私たちは、これをLLMに送信して、私たちの製品にとって重要な部分を解析したいと考えています。したがって、LLMに指示するために、2つの同一のプロンプトを作成できます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これら二つのプロンプトを作成した後、`openai.ChatCompletion`を使ってLLMに送信します。プロンプトは`messages`変数に保存し、役割を`user`に割り当てます。これは、ユーザーからチャットボットへのメッセージが書き込まれることを模倣するためです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "プロンプトが同じで説明も似ていても、`Grades` プロパティのフォーマットは異なる場合があります。\n",
    "\n",
    "上記のセルを何度か実行すると、フォーマットが `3.7` だったり `3.7 GPA` だったりすることがあります。\n",
    "\n",
    "これは、LLMがプロンプトという非構造化データを受け取り、同じく非構造化データを返すためです。データを保存したり利用したりする際に予想できるよう、構造化されたフォーマットが必要です。\n",
    "\n",
    "ファンクショナルコーリングを使うことで、構造化されたデータを受け取れるようにできます。ファンクショナルコーリングを使っても、LLMが実際に関数を呼び出したり実行したりするわけではありません。代わりに、LLMが返すレスポンスのための構造をこちらで用意します。その構造化されたレスポンスを使って、アプリケーションでどの関数を実行するか判断できるようになります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![関数呼び出しフローダイアグラム](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ja.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数呼び出しの利用ケース\n",
    "\n",
    "**外部ツールの呼び出し**  \n",
    "チャットボットは、ユーザーからの質問に答えるのが得意です。関数呼び出しを使うことで、チャットボットはユーザーのメッセージをもとに特定の作業を実行できます。例えば、学生が「先生に、この科目でもっとサポートが必要だとメールして」と頼むと、`send_email(to: string, body: string)` という関数を呼び出してメールを送信できます。\n",
    "\n",
    "**APIやデータベースクエリの作成**  \n",
    "ユーザーは自然な言葉で情報を探し、それがフォーマットされたクエリやAPIリクエストに変換されます。例えば、先生が「最後の課題を終えた生徒は誰ですか」と尋ねると、`get_completed(student_name: string, assignment: int, current_status: string)` という関数を呼び出して情報を取得できます。\n",
    "\n",
    "**構造化データの作成**  \n",
    "ユーザーはテキストやCSVデータを使って、LLMで重要な情報を抽出できます。例えば、学生が平和協定に関するWikipediaの記事をAIフラッシュカードに変換したい場合、`get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` という関数を使って、必要な事実を抽出できます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 初めての関数呼び出しを作成する\n",
    "\n",
    "関数呼び出しを作成する手順は、主に3つのステップに分かれています。\n",
    "1. 関数のリストとユーザーからのメッセージを使って、Chat Completions APIを呼び出します\n",
    "2. モデルの応答を確認し、必要なアクション（関数やAPIの呼び出しなど）を実行します\n",
    "3. 関数から得られた応答を使って、再度Chat Completions APIを呼び出し、その情報をもとにユーザーへの返答を作成します\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![関数呼び出しの流れ](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ja.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数呼び出しの要素\n",
    "\n",
    "#### ユーザー入力\n",
    "\n",
    "最初のステップは、ユーザーメッセージを作成することです。これはテキスト入力の値を動的に取得することもできますし、ここで値を指定することもできます。Chat Completions APIを初めて使う場合は、メッセージの`role`と`content`を定義する必要があります。\n",
    "\n",
    "`role`には、`system`（ルールの作成）、`assistant`（モデル）、`user`（エンドユーザー）のいずれかを指定できます。関数呼び出しの場合は、これを`user`として、例となる質問を設定します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数の作成\n",
    "\n",
    "次に、関数とそのパラメータを定義します。ここでは `search_courses` という関数を一つだけ使いますが、複数の関数を作成することもできます。\n",
    "\n",
    "**重要** : 関数はシステムメッセージに含まれ、利用可能なトークン数にも影響します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定義**\n",
    "\n",
    "関数定義の構造は複数の階層に分かれており、それぞれに固有のプロパティがあります。以下は、入れ子構造の概要です。\n",
    "\n",
    "**最上位の関数プロパティ:**\n",
    "\n",
    "`name` - 呼び出したい関数の名前。\n",
    "\n",
    "`description` - 関数の動作についての説明。ここでは具体的かつ明確に記述することが重要です。\n",
    "\n",
    "`parameters` - モデルが応答で生成する値やフォーマットの一覧。\n",
    "\n",
    "**Parametersオブジェクトのプロパティ:**\n",
    "\n",
    "`type` - parametersオブジェクトのデータ型（通常は \"object\"）\n",
    "\n",
    "`properties` - モデルが応答で使用する具体的な値の一覧。\n",
    "\n",
    "**個々のパラメータプロパティ:**\n",
    "\n",
    "`name` - プロパティキーによって暗黙的に定義される（例: \"role\", \"product\", \"level\"）\n",
    "\n",
    "`type` - この特定のパラメータのデータ型（例: \"string\", \"number\", \"boolean\"）\n",
    "\n",
    "`description` - 特定のパラメータの説明。\n",
    "\n",
    "**オプションのプロパティ:**\n",
    "\n",
    "`required` - 関数呼び出しを完了するために必須となるパラメータを列挙した配列。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 関数呼び出しの方法\n",
    "関数を定義した後は、Chat Completion APIの呼び出しにその関数を含める必要があります。これには、リクエストに`functions`を追加します。今回の場合は `functions=functions` です。\n",
    "\n",
    "さらに、`function_call` を `auto` に設定することもできます。これは、ユーザーのメッセージに応じて、どの関数を呼び出すかをLLMに任せるという意味です。自分で関数を指定するのではなく、モデルが最適な関数を選択します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "では、レスポンスを見て、そのフォーマットを確認しましょう。\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "このように、呼び出される関数の名前が表示されており、ユーザーのメッセージから、LLMが関数の引数に合うデータを見つけ出していることが分かります。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.アプリケーションへの関数呼び出しの統合\n",
    "\n",
    "LLMからのフォーマット済みレスポンスをテストした後、これをアプリケーションに統合できます。\n",
    "\n",
    "### フローの管理\n",
    "\n",
    "これをアプリケーションに統合するために、次の手順を踏みましょう。\n",
    "\n",
    "まず、OpenAIサービスにリクエストを送り、そのメッセージを`response_message`という変数に保存します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "これから、Microsoft Learn APIを呼び出してコースのリストを取得する関数を定義します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ベストプラクティスとして、まずモデルが関数を呼び出したいかどうかを確認します。その後、利用可能な関数の中から1つを作成し、呼び出されている関数に一致させます。\n",
    "次に、関数の引数を取得し、LLMからの引数にマッピングします。\n",
    "\n",
    "最後に、関数呼び出しメッセージと `search_courses` メッセージで返された値を追加します。これにより、LLMはユーザーに自然な言葉で\n",
    "応答するために必要なすべての情報を得ることができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## コードチャレンジ\n",
    "\n",
    "素晴らしいですね！OpenAI Function Calling の学習をさらに深めるために、次のことに取り組んでみましょう: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - 学習者がより多くのコースを見つけやすくするために、関数のパラメーターを追加してみましょう。利用可能なAPIパラメーターはこちらで確認できます:\n",
    " - 学習者の母国語など、より多くの情報を受け取る関数呼び出しを作成してみましょう\n",
    " - 関数呼び出しやAPI呼び出しで適切なコースが見つからなかった場合のエラーハンドリングを実装してみましょう\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責事項**:  \n本書類は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性には努めておりますが、自動翻訳には誤りや不正確な表現が含まれる場合があります。原文（元の言語の文書）が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は一切の責任を負いかねます。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T20:51:16+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}