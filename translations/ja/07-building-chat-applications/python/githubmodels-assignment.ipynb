{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 第7章: チャットアプリケーションの構築\n",
    "## Github Models API クイックスタート\n",
    "\n",
    "このノートブックは、[Azure OpenAI サンプルリポジトリ](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst)からのものを元にしています。このリポジトリには、[Azure OpenAI](notebook-azure-openai.ipynb) サービスへアクセスするノートブックが含まれています。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 概要  \n",
    "「大規模言語モデルは、テキストをテキストにマッピングする関数です。入力されたテキストに対して、大規模言語モデルは次に続くテキストを予測しようとします」(1)。この「クイックスタート」ノートブックでは、ユーザーにLLMの基本的な概念、AMLを始めるための主要なパッケージ要件、プロンプト設計の簡単な紹介、そしてさまざまなユースケースの短い例をいくつか紹介します。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 目次\n",
    "\n",
    "[概要](../../../../07-building-chat-applications/python)  \n",
    "[OpenAIサービスの使い方](../../../../07-building-chat-applications/python)  \n",
    "[1. OpenAIサービスの作成](../../../../07-building-chat-applications/python)  \n",
    "[2. インストール](../../../../07-building-chat-applications/python)  \n",
    "[3. 認証情報](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[ユースケース](../../../../07-building-chat-applications/python)  \n",
    "[1. テキストの要約](../../../../07-building-chat-applications/python)  \n",
    "[2. テキストの分類](../../../../07-building-chat-applications/python)  \n",
    "[3. 新しい商品名の生成](../../../../07-building-chat-applications/python)  \n",
    "[4. 分類器のファインチューニング](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[参考資料](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### はじめてのプロンプトを作成しよう  \n",
    "この短い演習では、Github Models でモデルにプロンプトを送信する基本的な方法を、「要約」というシンプルなタスクを例に紹介します。\n",
    "\n",
    "**手順**:  \n",
    "1. まだインストールしていない場合は、Python環境に `azure-ai-inference` ライブラリをインストールしてください。  \n",
    "2. 標準のヘルパーライブラリを読み込み、Github Models の認証情報を設定します。  \n",
    "3. タスクに合ったモデルを選びます。  \n",
    "4. モデル用のシンプルなプロンプトを作成します。  \n",
    "5. モデルAPIにリクエストを送信しましょう！\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. `azure-ai-inference` をインストールする\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. 適切なモデルを見つける\n",
    "\n",
    "GPT-3.5-turboやGPT-4モデルは、自然言語を理解し生成することができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. プロンプト設計\n",
    "\n",
    "「大規模言語モデルの魔法は、膨大な量のテキストで予測誤差を最小化するように訓練されることで、モデルがこの予測に役立つさまざまな概念を学習する点にあります。例えば、次のような概念を学びます」(1):\n",
    "\n",
    "* スペルの仕方\n",
    "* 文法の仕組み\n",
    "* 言い換えの方法\n",
    "* 質問への答え方\n",
    "* 会話の進め方\n",
    "* 多言語での文章作成\n",
    "* コーディングの方法\n",
    "* など\n",
    "\n",
    "#### 大規模言語モデルの制御方法\n",
    "「大規模言語モデルへの入力の中で、圧倒的に影響力が大きいのはテキストプロンプトです」(1)。\n",
    "\n",
    "大規模言語モデルは、いくつかの方法で出力を促すことができます：\n",
    "\n",
    "インストラクション: モデルにやってほしいことを伝える\n",
    "コンプリーション: 欲しい内容の冒頭を与えて続きを生成させる\n",
    "デモンストレーション: モデルにやってほしいことを例で示す（以下のいずれかで）\n",
    "プロンプト内にいくつかの例を入れる\n",
    "ファインチューニング用の学習データセットに数百〜数千の例を用意する\n",
    "\n",
    "#### プロンプト作成の基本的なガイドラインは3つあります：\n",
    "\n",
    "**見せて、伝えること。** 指示や例、またはその両方を使って、何を求めているのかを明確に伝えましょう。例えば、リストをアルファベット順に並べ替えてほしい場合や、段落を感情で分類してほしい場合は、それが目的であることを示してください。\n",
    "\n",
    "**質の高いデータを用意すること。** 分類器を作りたい場合や、モデルにパターンを守らせたい場合は、十分な数の例を用意しましょう。例文は必ず見直してください。モデルは基本的なスペルミスを見抜いて返答してくれることも多いですが、意図的なものだと判断して返答に影響することもあります。\n",
    "\n",
    "**設定を確認すること。** temperatureやtop_pの設定は、モデルの応答がどれだけ決定的かを制御します。正解が一つしかないような応答を求める場合は、これらの値を低く設定しましょう。多様な応答が欲しい場合は、高めに設定するのがよいでしょう。これらの設定でよくある間違いは、「賢さ」や「創造性」をコントロールするものだと勘違いすることです。\n",
    "\n",
    "出典: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## テキストの要約  \n",
    "#### チャレンジ  \n",
    "テキストの最後に「tl;dr:」を追加して要約を作成します。モデルが追加の指示なしでさまざまなタスクを理解して実行できることに注目してください。tl;dr 以外にも、より説明的なプロンプトを使ってモデルの動作を変えたり、要約の内容をカスタマイズしたりすることもできます(3)。\n",
    "\n",
    "最近の研究では、大規模なテキストコーパスで事前学習を行い、その後特定のタスクでファインチューニングすることで、多くのNLPタスクやベンチマークで大きな成果が得られることが示されています。通常、この手法はアーキテクチャとしてはタスク非依存ですが、依然として数千から数万のタスク固有のファインチューニング用データセットが必要です。一方で、人間は少数の例や簡単な指示だけで新しい言語タスクをこなすことが一般的にできますが、現在のNLPシステムはこの点でまだ大きな課題を抱えています。本稿では、言語モデルの規模を拡大することで、タスク非依存かつ少数ショットでのパフォーマンスが大幅に向上し、時には従来の最先端ファインチューニング手法と競えるレベルに達することを示します。\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# いくつかのユースケースのための練習問題  \n",
    "1. テキストの要約  \n",
    "2. テキストの分類  \n",
    "3. 新しい商品名の生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## テキストの分類  \n",
    "#### チャレンジ  \n",
    "推論時に指定されたカテゴリにアイテムを分類します。次の例では、プロンプト内でカテゴリと分類するテキストの両方を指定しています（*playground_reference）。\n",
    "\n",
    "顧客からの問い合わせ：こんにちは、ノートパソコンのキーボードのキーの一つが最近壊れてしまい、交換が必要です。\n",
    "\n",
    "分類されたカテゴリ：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 新しい商品名を考えよう\n",
    "#### チャレンジ\n",
    "例となる単語から商品名を作成します。このプロンプトでは、名前を考える商品の情報も含めています。また、どのようなパターンで名前を作ってほしいかを示すため、似た例も用意しています。さらに、ランダム性や独創性を高めるために、temperature値も高く設定しています。\n",
    "\n",
    "商品説明: 家庭用ミルクセーキメーカー  \n",
    "シードワード: 速い、健康、コンパクト  \n",
    "商品名: ホームシェイカー、フィットシェイカー、クイックシェイク、シェイクメーカー\n",
    "\n",
    "商品説明: どんな足のサイズにも合う靴  \n",
    "シードワード: 適応、フィット、オムニフィット\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 参考文献  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studioのサンプル](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [GPT-3を微調整してテキストを分類するためのベストプラクティス](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 詳しいサポートについて  \n",
    "[OpenAI コマーシャライゼーションチーム](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 貢献者\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責事項**:  \n本書類は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性には努めておりますが、自動翻訳には誤りや不正確な表現が含まれる場合があります。原文（元の言語の文書）が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は一切の責任を負いかねます。\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:28:03+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}