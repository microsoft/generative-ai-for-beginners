{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 第7章: チャットアプリケーションの構築\n",
    "## OpenAI API クイックスタート\n",
    "\n",
    "このノートブックは、[Azure OpenAI サンプルリポジトリ](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst)からのものを元にしています。このリポジトリには、[Azure OpenAI](notebook-azure-openai.ipynb) サービスにアクセスするノートブックが含まれています。\n",
    "\n",
    "Python の OpenAI API は、いくつかの変更を加えることで Azure OpenAI モデルでも利用できます。違いについて詳しくは、こちらをご覧ください: [Python で OpenAI と Azure OpenAI のエンドポイントを切り替える方法](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 概要  \n",
    "「大規模言語モデルは、テキストからテキストへの写像を行う関数です。入力されたテキストに対して、大規模言語モデルは次に続くテキストを予測しようとします」(1)。この「クイックスタート」ノートブックでは、LLMの基本的な概念、AMLを始めるために必要な主要パッケージ、プロンプト設計の簡単な紹介、そしてさまざまなユースケースの短い例をいくつか紹介します。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 目次\n",
    "\n",
    "[概要](../../../../07-building-chat-applications/python)  \n",
    "[OpenAI サービスの使い方](../../../../07-building-chat-applications/python)  \n",
    "[1. OpenAI サービスの作成](../../../../07-building-chat-applications/python)  \n",
    "[2. インストール](../../../../07-building-chat-applications/python)  \n",
    "[3. 認証情報](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[ユースケース](../../../../07-building-chat-applications/python)  \n",
    "[1. テキストの要約](../../../../07-building-chat-applications/python)  \n",
    "[2. テキストの分類](../../../../07-building-chat-applications/python)  \n",
    "[3. 新しい商品名の生成](../../../../07-building-chat-applications/python)  \n",
    "[4. 分類器のファインチューニング](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[参考資料](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 最初のプロンプトを作成しよう  \n",
    "この短い演習では、OpenAIモデルに「要約」というシンプルなタスクのプロンプトを送信する基本的な方法を紹介します。\n",
    "\n",
    "**手順**:  \n",
    "1. Python環境にOpenAIライブラリをインストールする  \n",
    "2. 標準的なヘルパーライブラリを読み込み、作成したOpenAIサービス用のセキュリティ認証情報を設定する  \n",
    "3. タスクに使うモデルを選択する  \n",
    "4. モデル用のシンプルなプロンプトを作成する  \n",
    "5. モデルAPIにリクエストを送信する\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. 適切なモデルを見つける\n",
    "\n",
    "GPT-3.5-turbo や GPT-4 モデルは、自然言語を理解し生成することができます。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. プロンプト設計\n",
    "\n",
    "「大規模言語モデルの魔法は、膨大な量のテキストで予測誤差を最小化するように訓練されることで、モデルがこれらの予測に役立つさまざまな概念を学習する点にあります。たとえば、モデルは次のような概念を学びます」(1):\n",
    "\n",
    "* スペルの仕方\n",
    "* 文法の仕組み\n",
    "* 言い換えの方法\n",
    "* 質問への答え方\n",
    "* 会話の進め方\n",
    "* 多言語での文章の書き方\n",
    "* コードの書き方\n",
    "* など\n",
    "\n",
    "#### 大規模言語モデルの制御方法\n",
    "「大規模言語モデルへの入力の中で、圧倒的に影響力が大きいのはテキストプロンプトです」(1)。\n",
    "\n",
    "大規模言語モデルは、いくつかの方法で出力を促すことができます：\n",
    "\n",
    "インストラクション: モデルにやってほしいことを伝える  \n",
    "コンプリーション: 欲しい内容の冒頭を与えて続きを生成させる  \n",
    "デモンストレーション: モデルにやってほしいことを例で示す（以下のいずれかで）  \n",
    "プロンプト内にいくつかの例を入れる  \n",
    "ファインチューニング用の学習データセットに何百、何千もの例を入れる\n",
    "\n",
    "#### プロンプト作成の基本的なガイドラインは3つあります：\n",
    "\n",
    "**見せて、伝えること。** 指示や例、またはその両方を使って、何をしてほしいのかを明確に伝えましょう。たとえば、リストをアルファベット順に並べ替えてほしい場合や、段落を感情で分類してほしい場合は、それが目的であることを示してください。\n",
    "\n",
    "**質の高いデータを用意すること。** 分類器を作りたい場合や、モデルにパターンを守らせたい場合は、十分な数の例を用意しましょう。例文は必ず見直してください。モデルは基本的なスペルミスを見抜いて返答してくれることも多いですが、意図的なものだと判断して返答に影響することもあります。\n",
    "\n",
    "**設定を確認すること。** temperatureやtop_pの設定は、モデルの応答がどれだけ決定的（ランダム性が少ない）かを制御します。正解が一つしかないような問いの場合は、これらの値を低く設定しましょう。多様な応答が欲しい場合は高めに設定します。よくある間違いは、これらの設定を「賢さ」や「創造性」のコントロールだと勘違いすることです。\n",
    "\n",
    "出典: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## テキストの要約  \n",
    "#### チャレンジ  \n",
    "テキストの最後に「tl;dr:」を追加して要約します。モデルが追加の指示なしで様々なタスクをこなせることに注目してください。tl;dr以外にも、より説明的なプロンプトを使ってモデルの動作を変えたり、要約の内容をカスタマイズすることもできます(3)。  \n",
    "\n",
    "最近の研究では、大規模なテキストコーパスで事前学習し、その後特定のタスクでファインチューニングすることで、多くのNLPタスクやベンチマークで大きな成果が得られることが示されています。通常、この手法はアーキテクチャがタスク非依存ですが、依然として数千から数万のタスク固有のファインチューニング用データセットが必要です。一方で、人間は少数の例や簡単な指示だけで新しい言語タスクをこなすことができますが、現在のNLPシステムはこの点でまだ大きく苦戦しています。本稿では、言語モデルの規模を拡大することで、タスク非依存かつ少数例でのパフォーマンスが大きく向上し、従来の最先端ファインチューニング手法と競合するレベルに達することもあることを示します。\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# いくつかのユースケースのための練習問題  \n",
    "1. テキストの要約  \n",
    "2. テキストの分類  \n",
    "3. 新しい商品名の生成\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## テキストの分類  \n",
    "#### チャレンジ  \n",
    "推論時に指定されたカテゴリにアイテムを分類します。次の例では、プロンプト内でカテゴリと分類するテキストの両方を指定しています（*playground_reference）。\n",
    "\n",
    "顧客からの問い合わせ: こんにちは、ノートパソコンのキーボードのキーの一つが最近壊れてしまい、交換が必要です。\n",
    "\n",
    "分類されたカテゴリ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 新しい商品名を考えよう\n",
    "#### チャレンジ\n",
    "例となる単語から商品名を作成します。このプロンプトでは、名前を考える商品の情報も含めています。また、どのようなパターンで名前を作ってほしいかを示すため、似た例も用意しています。さらに、ランダム性や独創的な回答を増やすために、temperature値を高めに設定しています。\n",
    "\n",
    "商品説明: 家庭用ミルクセーキメーカー  \n",
    "シードワード: 速い、健康、コンパクト  \n",
    "商品名例: HomeShaker、Fit Shaker、QuickShake、Shake Maker\n",
    "\n",
    "商品説明: どんな足のサイズにも合う靴  \n",
    "シードワード: 適応、フィット、オムニフィット\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 参考文献  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studioの例](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [GPT-3を微調整してテキストを分類するためのベストプラクティス](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 詳しいサポートについて  \n",
    "[OpenAI コマーシャライゼーションチーム](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 貢献者\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責事項**:  \n本書類は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性には努めておりますが、自動翻訳には誤りや不正確な表現が含まれる場合があります。原文（元の言語の文書）が正式な情報源と見なされるべきです。重要な情報については、専門の人間による翻訳を推奨します。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は一切の責任を負いません。\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:07:20+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}