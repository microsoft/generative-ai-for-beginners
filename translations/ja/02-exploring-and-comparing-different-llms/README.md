# 異なるLLMの探求と比較

[![異なるLLMの探求と比較](../../../translated_images/02-lesson-banner.png?WT.96d85175e46909d65f6895923ed5f3ad0ae5e874792ccad49542fcfe8ebd12dd.ja.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _このレッスンのビデオを見るには、上の画像をクリックしてください_

前回のレッスンでは、生成AIがどのように技術の風景を変えているか、LLM（大規模言語モデル）がどのように機能するか、そして私たちのスタートアップのようなビジネスがどのようにそれらを適用して成長できるかを学びました。この章では、異なるタイプのLLMを比較してその利点と欠点を理解します。

私たちのスタートアップの次のステップは、現在のLLMの状況を探求し、どのモデルが私たちのユースケースに適しているかを理解することです。

## はじめに

このレッスンでは以下をカバーします：

- 現在の状況におけるさまざまなタイプのLLM。
- Azureでユースケースに合わせて異なるモデルをテスト、反復、比較する方法。
- LLMをデプロイする方法。

## 学習目標

このレッスンを完了すると、次のことができるようになります：

- ユースケースに適したモデルを選択する。
- モデルのテスト、反復、性能向上の方法を理解する。
- ビジネスがモデルをデプロイする方法を知る。

## 異なるタイプのLLMを理解する

LLMはそのアーキテクチャ、トレーニングデータ、ユースケースに基づいてさまざまに分類できます。これらの違いを理解することで、スタートアップはシナリオに適したモデルを選択し、テスト、反復、性能向上の方法を理解できます。

LLMモデルには多くの種類があり、使用目的、データ、予算などによって選択が変わります。

テキスト、音声、ビデオ、画像生成などの目的によって、異なるタイプのモデルを選択することがあります。

- **音声と音声認識**。この目的には、Whisperタイプのモデルが最適です。これらは汎用的で音声認識を目的としています。多言語の音声認識を行うことができます。[Whisperタイプのモデルについてはこちらを参照](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst)。

- **画像生成**。画像生成には、DALL-EとMidjourneyがよく知られた選択肢です。DALL-EはAzure OpenAIで提供されています。[DALL-Eについてはこちらを参照](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst)し、このカリキュラムの第9章でも詳しく説明しています。

- **テキスト生成**。ほとんどのモデルはテキスト生成に特化しており、GPT-3.5からGPT-4まで多くの選択肢があります。コストは異なり、GPT-4が最も高価です。[Azure OpenAIのプレイグラウンド](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst)で能力とコストに応じてどのモデルが最適かを評価する価値があります。

- **マルチモダリティ**。入力と出力で複数のデータタイプを扱う場合は、[gpt-4 turbo with visionやgpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst)などのモデルを検討することができます。これらは自然言語処理と視覚理解を組み合わせ、マルチモーダルインターフェースを通じてのインタラクションを可能にします。

モデルを選択することは、基本的な能力を得ることを意味しますが、それだけでは十分でないことがあります。企業特有のデータをLLMに伝える必要がある場合もあります。これに対するアプローチは複数あり、次のセクションで詳しく説明します。

### 基盤モデルとLLM

基盤モデルという用語は[スタンフォードの研究者によって作られ](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst)、以下のような基準に従うAIモデルとして定義されています：

- **教師なし学習または自己教師あり学習を使用して訓練されている**。これは、ラベルのないマルチモーダルデータで訓練され、人間の注釈やラベル付けを必要としないことを意味します。
- **非常に大きなモデルである**。非常に深いニューラルネットワークに基づき、数十億のパラメータで訓練されています。
- **他のモデルの‘基盤’として機能することを意図している**。これは、他のモデルをその上に構築するための出発点として使用できることを意味し、ファインチューニングによって実現されます。

![基盤モデルとLLM](../../../translated_images/FoundationModel.png?WT.9690c2a9f6be278baf730a5b26ea901ac6d6ede04cad555ef2b59d774ba557eb.ja.mc_id=academic-105485-koreyst)

画像出典: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

この区別をさらに明確にするために、ChatGPTを例にとってみましょう。ChatGPTの最初のバージョンを構築するために、GPT-3.5というモデルが基盤モデルとして使用されました。これは、OpenAIがチャット特有のデータを使用して、チャットボットのような会話シナリオで優れた性能を発揮するように特化したバージョンのGPT-3.5を作成したことを意味します。

![基盤モデル](../../../translated_images/Multimodal.png?WT.29151b07403f77b38d7dc2a3069f4c171198d59c9df6bdfccd4326c209db4432.ja.mc_id=academic-105485-koreyst)

画像出典: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### オープンソースとプロプライエタリモデル

LLMを分類するもう一つの方法は、それがオープンソースかプロプライエタリかということです。

オープンソースモデルは、一般に公開され、誰でも使用できるモデルです。これらは、モデルを作成した会社や研究コミュニティによって提供されることが多いです。これらのモデルは、LLMのさまざまなユースケースに合わせて検査、修正、カスタマイズすることが許可されています。しかし、生産用途に最適化されていない場合があり、プロプライエタリモデルほどの性能を持たないこともあります。また、オープンソースモデルへの資金提供は限られている場合があり、長期間のメンテナンスや最新の研究の更新が行われないこともあります。人気のあるオープンソースモデルの例には、[Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst)、[Bloom](https://huggingface.co/bigscience/bloom)、[LLaMA](https://llama.meta.com)などがあります。

プロプライエタリモデルは、企業が所有し、一般には公開されていないモデルです。これらのモデルは生産用途に最適化されていることが多いです。しかし、異なるユースケースに合わせて検査、修正、カスタマイズすることは許可されていません。また、無料で利用できない場合があり、利用にはサブスクリプションや支払いが必要なこともあります。また、モデルの訓練に使用されたデータに対してユーザーがコントロールできないため、データのプライバシーとAIの責任ある使用に対するモデル所有者のコミットメントを信頼する必要があります。人気のあるプロプライエタリモデルの例には、[OpenAI models](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst)、[Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst)、[Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst)などがあります。

### 埋め込み、画像生成、テキストとコード生成

LLMは生成する出力によっても分類されます。

埋め込みは、テキストを数値形式、すなわち入力テキストの数値表現に変換する一連のモデルです。埋め込みは、単語や文の関係を理解しやすくし、分類モデルや数値データでより良い性能を発揮するクラスタリングモデルなど、他のモデルの入力として利用できます。埋め込みモデルは、データが豊富な代替タスク用に構築されたモデルであり、その後、他の下流タスクのためにモデルの重み（埋め込み）が再利用される転移学習によく使用されます。このカテゴリの例としては、[OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst)があります。

![埋め込み](../../../translated_images/Embedding.png?WT.15a2282d046c6d94a54f553fa9e7f19e3ef0e65f9eb05f4d476a5d28b2dead18.ja.mc_id=academic-105485-koreyst)

画像生成モデルは、画像を生成するモデルです。これらのモデルは、画像編集、画像合成、画像翻訳によく使用されます。画像生成モデルは、[LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst)のような大規模な画像データセットで訓練され、新しい画像を生成したり、既存の画像をインペインティング、超解像、カラー化技術で編集するために使用されます。例としては、[DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst)や[Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst)があります。

![画像生成](../../../translated_images/Image.png?WT.6a1995ff7d9be5a713e6aaee5f1625f31620756937c283e292ef5ffe1e30ed11.ja.mc_id=academic-105485-koreyst)

テキストとコード生成モデルは、テキストやコードを生成するモデルです。これらのモデルは、テキスト要約、翻訳、質問応答によく使用されます。テキスト生成モデルは、[BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst)のような大規模なテキストデータセットで訓練され、新しいテキストを生成したり、質問に答えるために使用されます。コード生成モデルは、[CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst)のように、GitHubのような大規模なコードデータセットで訓練され、新しいコードを生成したり、既存のコードのバグを修正するために使用されます。

![テキストとコード生成](../../../translated_images/Text.png?WT.b55b7b9b96faac1d758fb555436c56c5a323a55743b75e70198160caca3fb73c.ja.mc_id=academic-105485-koreyst)

### エンコーダ-デコーダとデコーダのみ

LLMの異なるアーキテクチャについて話すために、アナロジーを使いましょう。

あなたのマネージャーが学生のためのクイズを書くタスクをあなたに与えたと想像してください。あなたには2人の同僚がいて、一人はコンテンツを作成し、もう一人はそれをレビューします。

コンテンツクリエーターはデコーダのみのモデルのようなもので、トピックを見てすでに書かれた内容を見てからコースを書くことができます。彼らは魅力的で情報豊富なコンテンツを書くのが得意ですが、トピックや学習目標を理解するのは得意ではありません。デコーダモデルの例としては、GPTファミリーモデル、たとえばGPT-3があります。

レビュアーはエンコーダのみのモデルのようなもので、書かれたコースと答えを見て、それらの関係を理解し、コンテキストを理解しますが、コンテンツを生成するのは得意ではありません。エンコーダのみのモデルの例としてはBERTがあります。

クイズを作成し、レビューすることができる人がいると想像してみてください。これがエンコーダ-デコーダモデルです。例としては、BARTやT5があります。

### サービスとモデル

次に、サービスとモデルの違いについて話しましょう。サービスはクラウドサービスプロバイダーによって提供される製品であり、通常、モデル、データ、その他のコンポーネントの組み合わせです。モデルはサービスのコアコンポーネントであり、通常はLLMのような基盤モデルです。

サービスは生産用途に最適化されており、グラフィカルユーザーインターフェースを介してモデルよりも使いやすいことが多いです。ただし、サービスは無料で利用できるわけではなく、使用にはサブスクリプションや支払いが必要な場合があります。サービスの所有者の設備とリソースを利用する代わりに、費用を最適化し、簡単にスケーリングすることができます。サービスの例としては、[Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst)があります。これは、使用に応じた料金プランを提供しており、サービスの使用量に比例して課金されます。また、Azure OpenAI Serviceは、モデルの能力に加えて、エンタープライズグレードのセキュリティと責任あるAIフレームワークを提供しています。

モデルはニューラルネットワークそのものであり、パラメータ、重みなどを含んでいます。企業がローカルで実行することを許可しますが、機器を購入し、スケールするための構造を構築し、ライセンスを購入するかオープンソースモデルを使用する必要があります。LLaMAのようなモデルは使用可能であり、モデルを実行するための計算能力が必要です。

## Azureでの性能を理解するための異なるモデルのテストと反復の方法

私たちのチームが現在のLLMの状況を探求し、シナリオに適した候補を特定した後、次のステップはデータとワークロードでそれらをテストすることです。これは実験と測定による反復プロセスです。
前述のモデルのほとんど（OpenAIモデル、Llama2のようなオープンソースモデル、Hugging Faceトランスフォーマー）は、[Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst)の[Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst)で利用可能です。

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst)は、開発者が生成AIアプリケーションを構築し、実験から評価までの全開発ライフサイクルを管理するためのクラウドプラットフォームであり、すべてのAzure AIサービスを1つのハブに統合し、便利なGUIを提供しています。Azure AI StudioのModel Catalogでは、ユーザーは以下を行うことができます：

- カタログ内で関心のある基盤モデルを見つける - プロプライエタリまたはオープンソース、タスク、ライセンス、名前でフィルタリング。検索性を向上させるために、モデルはAzure OpenAIコレクション、Hugging Faceコレクションなどのコレクションに整理されています。

![モデルカタログ](../../../translated_images/AzureAIStudioModelCatalog.png?WT.cd7b78fc6a7b010869adb0defabce1ea5fbe62131aa7f59e54a083be8d789d24.ja.mc_id=academic-105485-koreyst)

- モデルカードをレビューし、使用目的とトレーニングデータの詳細な説明、コードサンプル、内部評価ライブラリの評価結果を含む。

![モデルカード](../../../translated_images/ModelCard.png?WT.cd385d3d0228f86cef5987e3074be75f377a95ba505d6805f7c6965dc5972693.ja.mc_id=academic-105485-koreyst)
- 業界で利用可能なモデルやデータセットを比較し、ビジネスシナリオに最適なものを評価するために、[Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) ペインを使用します。

![モデルベンチマーク](../../../translated_images/ModelBenchmarks.png?WT.634f688bb2a74b3c90a9212ecfb9b99045405b2414be3d17429cfea319c06f61.ja.mc_id=academic-105485-koreyst)

- カスタムトレーニングデータでモデルを微調整し、特定のワークロードでのモデルのパフォーマンスを向上させるために、Azure AI Studioの実験とトラッキング機能を活用します。

![モデルの微調整](../../../translated_images/FineTuning.png?WT.523a6ab7580c924e42e8478d072fb670f879033779b8ab5a6abb155d2fc63d5a.ja.mc_id=academic-105485-koreyst)

- オリジナルの事前学習済みモデルまたは微調整されたバージョンを、リモートリアルタイム推論のマネージドコンピュートまたはサーバーレスAPIエンドポイントにデプロイし、アプリケーションが利用できるようにします。 - [従量課金制](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - を利用します。

![モデルのデプロイ](../../../translated_images/ModelDeploy.png?WT.a765ca6b7a396eb5d2fd346f8a211542f6fe578e2218bbe16f9fcdb5ca8f3661.ja.mc_id=academic-105485-koreyst)

> [!NOTE]
> カタログ内のすべてのモデルが現在、微調整および/または従量課金制のデプロイメントに対応しているわけではありません。モデルの機能と制限については、モデルカードを確認してください。

## LLMの結果を改善する

私たちはスタートアップチームとともに、さまざまな種類のLLMとクラウドプラットフォーム（Azure Machine Learning）を活用して、異なるモデルを比較し、テストデータで評価し、パフォーマンスを向上させ、推論エンドポイントにデプロイする方法を探りました。

しかし、いつモデルを微調整することを検討すべきでしょうか？事前学習済みのものを使うのではなく、特定のワークロードでモデルのパフォーマンスを向上させる他のアプローチはありますか？

ビジネスがLLMから必要な結果を得るために使用できるいくつかのアプローチがあります。異なるレベルのトレーニングを持つ異なる種類のモデルを選択し、異なる複雑さ、コスト、および品質でLLMを本番環境にデプロイできます。以下はいくつかの異なるアプローチです：

- **コンテキストを持つプロンプトエンジニアリング**。これは、プロンプトを提供する際に必要な応答を得るために十分なコンテキストを提供するというアイデアです。

- **情報検索強化生成 (RAG)**。データがデータベースやウェブエンドポイントに存在する場合に、そのデータまたはその一部をプロンプト時に含めるために、関連するデータを取得してユーザーのプロンプトの一部にすることができます。

- **微調整されたモデル**。ここでは、モデルを自分のデータでさらにトレーニングし、モデルがより正確でニーズに応じた応答をするようになりますが、コストがかかるかもしれません。

![LLMsのデプロイ](../../../translated_images/Deploy.png?WT.0eeb36a208bf2bf97ea1058e54c74e13f5c810679cd7f3600cb2084b98d737be.ja.mc_id=academic-105485-koreyst)

画像出典: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### コンテキストを持つプロンプトエンジニアリング

事前学習済みのLLMは、一般的な自然言語タスクに非常にうまく対応します。短いプロンプトで呼び出すだけで、例えば文の完了や質問など、いわゆる「ゼロショット」学習が可能です。

しかし、ユーザーが詳細なリクエストや例を含めてクエリを構築するほど、回答はユーザーの期待により正確で近いものになります。この場合、プロンプトに例が1つだけ含まれている場合は「ワンショット」学習、複数の例が含まれている場合は「少数ショット」学習と呼びます。コンテキストを持つプロンプトエンジニアリングは、最もコスト効果の高いアプローチです。

### 情報検索強化生成 (RAG)

LLMには、トレーニングに使用されたデータのみを使用して回答を生成するという制限があります。これは、トレーニングプロセス後に発生した事実について何も知らないことを意味し、非公開情報（会社データなど）にアクセスすることもできません。
これは、プロンプトの長さの制限を考慮し、ドキュメントのチャンク形式で外部データを追加するRAGという技術を通じて克服できます。これは、さまざまな事前定義されたデータソースから有用なチャンクを取得し、それらをプロンプトのコンテキストに追加するベクターデータベースツール（[Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst) など）によってサポートされています。

この技術は、ビジネスが十分なデータや時間、リソースを持っていないが、特定のワークロードでのパフォーマンスを向上させ、現実の捏造や有害なコンテンツのリスクを軽減したい場合に非常に役立ちます。

### 微調整されたモデル

微調整は、モデルを下流タスクに「適応」させるか、特定の問題を解決するために転移学習を活用するプロセスです。少数ショット学習やRAGとは異なり、新しいモデルが生成され、重みとバイアスが更新されます。これは、単一の入力（プロンプト）とそれに関連する出力（完了）からなるトレーニング例のセットを必要とします。
このアプローチは、以下の場合に推奨されます：

- **微調整されたモデルの使用**。ビジネスが高性能モデルではなく、よりコスト効果の高い迅速な解決策を提供する微調整された低性能モデル（埋め込みモデルなど）を使用したい場合。

- **レイテンシを考慮する**。特定のユースケースでレイテンシが重要であり、非常に長いプロンプトやモデルが学習するべき例の数がプロンプトの長さ制限に合わない場合。

- **最新の状態を維持する**。ビジネスが多くの高品質データと真実のラベルを持ち、このデータを時間とともに最新の状態に保つためのリソースを持っている場合。

### トレーニングされたモデル

LLMをゼロからトレーニングすることは、間違いなく最も難しく、最も複雑なアプローチであり、大量のデータ、熟練したリソース、および適切な計算能力を必要とします。このオプションは、ビジネスがドメイン固有のユースケースと大量のドメイン中心のデータを持っているシナリオでのみ検討されるべきです。

## 知識の確認

LLMの完了結果を改善するための良いアプローチは何でしょうか？

1. コンテキストを持つプロンプトエンジニアリング
2. RAG
3. 微調整されたモデル

A:3、時間とリソースがあり、高品質のデータがある場合、微調整は最新の状態を維持するためのより良いオプションです。しかし、改善を考えていて時間が不足している場合は、まずRAGを検討する価値があります。

## 🚀 チャレンジ

ビジネスにRAGをどのように活用できるかについて、もっと調べてみましょう。[RAGの使用](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst)を参照してください。

## 素晴らしい仕事、学習を続けましょう

このレッスンを完了した後は、[生成AI学習コレクション](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst)をチェックして、生成AIの知識をさらに高めましょう！

レッスン3に進んで、[生成AIを責任を持って構築する方法](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)を学びましょう！

**免責事項**:  
この文書は機械翻訳AIサービスを使用して翻訳されています。正確性を追求していますが、自動翻訳には誤りや不正確さが含まれる可能性がありますのでご注意ください。原文の言語でのオリジナル文書が権威ある情報源と見なされるべきです。重要な情報については、専門の人間による翻訳をお勧めします。この翻訳の使用に起因する誤解や誤解釈について、当社は責任を負いません。