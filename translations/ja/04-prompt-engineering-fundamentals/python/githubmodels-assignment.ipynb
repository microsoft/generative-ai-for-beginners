{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# プロンプトエンジニアリング入門\n",
    "プロンプトエンジニアリングとは、自然言語処理タスクのためにプロンプトを設計し、最適化するプロセスです。適切なプロンプトの選定やパラメータの調整、パフォーマンスの評価などが含まれます。プロンプトエンジニアリングは、NLPモデルで高い精度と効率を実現するために欠かせません。このセクションでは、OpenAIモデルを使ってプロンプトエンジニアリングの基本を学んでいきます。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習 1: トークナイゼーション\n",
    "OpenAIが提供する高速トークナイザー「tiktoken」を使ってトークナイゼーションを体験しましょう。\n",
    "さらに詳しい例は [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) をご覧ください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習2: Github Modelsキーの設定を確認する\n",
    "\n",
    "以下のコードを実行して、Github Modelsのエンドポイントが正しく設定されているか確認しましょう。このコードはシンプルなプロンプトを試し、応答が正しく返ってくるかを検証します。入力として `oh say can you see` を使うと、`by the dawn's early light..` のような続きが返ってくるはずです。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That line is the opening lyric of \"The Star-Spangled Banner,\" the national anthem of the United States, written by Francis Scott Key. If you'd like more information or analysis, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, client, model_name, temperature=1.0, max_tokens=1000, top_p=1.0):\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習3: 捏造\n",
    "\n",
    "存在しないトピックや、事前学習データセットの範囲外（より最近の話題など）でLLMにプロンプトを与えた場合、どのような回答が返ってくるかを試してみましょう。別のプロンプトや別のモデルを使うと、どのように応答が変化するかも観察してみてください。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習4: 指示ベース\n",
    "「text」変数に主な内容を設定し、\n",
    "「prompt」変数にその主な内容に関する指示を記述します。\n",
    "\n",
    "ここでは、モデルに対して、テキストを小学2年生向けに要約するように指示します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter is the fifth planet from the Sun and the biggest one in our Solar System. It's made of gas and is much bigger than all the other planets put together! You can see Jupiter in the night sky because it's very bright. People have noticed it for a really long time and named it after a Roman god.\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習5: 複雑なプロンプト\n",
    "システム、ユーザー、アシスタントのメッセージを含むリクエストを試してみましょう  \n",
    "システムはアシスタントのコンテキストを設定します  \n",
    "ユーザーとアシスタントのメッセージは複数ターンの会話の流れを提供します\n",
    "\n",
    "システムコンテキストでアシスタントの性格が「皮肉屋」に設定されている点に注目してください。  \n",
    "別の性格コンテキストを使ってみたり、異なる一連の入力/出力メッセージを試してみても良いでしょう\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you mean the famous 2020 World Series that wasn’t in a regular location? That was the year they played in the glamorous Arlington, Texas, at Globe Life Field.\n"
     ]
    }
   ],
   "source": [
    "response = client.complete(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 演習：直感を探求しよう\n",
    "上記の例は、新しいプロンプト（シンプル、複雑、指示など）を作成する際に使えるパターンを示しています。他にも、これまでに話した例やヒントなどのアイデアを探求するために、別の演習を作ってみましょう。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責事項**:  \n本書類は、AI翻訳サービス [Co-op Translator](https://github.com/Azure/co-op-translator) を使用して翻訳されています。正確性には努めておりますが、自動翻訳には誤りや不正確な表現が含まれる場合があります。原文（元の言語の文書）が正式な情報源となります。重要な情報については、専門の人間による翻訳をご利用ください。本翻訳の利用により生じたいかなる誤解や誤訳についても、当方は一切の責任を負いかねます。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4beg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "40586ff9e0ba4574f88e59700b9a0088",
   "translation_date": "2025-08-25T13:21:40+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/githubmodels-assignment.ipynb",
   "language_code": "ja"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}