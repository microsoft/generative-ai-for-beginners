{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pengenalan\n",
    "\n",
    "Pelajaran ini akan merangkumi:\n",
    "- Apa itu pemanggilan fungsi dan kegunaannya\n",
    "- Cara membuat pemanggilan fungsi menggunakan Azure OpenAI\n",
    "- Cara mengintegrasikan pemanggilan fungsi ke dalam aplikasi\n",
    "\n",
    "## Matlamat Pembelajaran\n",
    "\n",
    "Selepas melengkapkan pelajaran ini, anda akan tahu cara dan memahami:\n",
    "\n",
    "- Tujuan menggunakan pemanggilan fungsi\n",
    "- Menyediakan Pemanggilan Fungsi menggunakan Azure Open AI Service\n",
    "- Merangka pemanggilan fungsi yang berkesan untuk kegunaan aplikasi anda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memahami Panggilan Fungsi\n",
    "\n",
    "Untuk pelajaran ini, kita ingin membina satu ciri untuk syarikat permulaan pendidikan kita yang membolehkan pengguna menggunakan chatbot untuk mencari kursus teknikal. Kami akan mencadangkan kursus yang sesuai dengan tahap kemahiran mereka, peranan semasa dan teknologi yang diminati.\n",
    "\n",
    "Untuk menyiapkan ini, kita akan menggunakan gabungan:\n",
    " - `Azure Open AI` untuk mencipta pengalaman chat untuk pengguna\n",
    " - `Microsoft Learn Catalog API` untuk membantu pengguna mencari kursus berdasarkan permintaan mereka\n",
    " - `Function Calling` untuk mengambil pertanyaan pengguna dan menghantarnya ke fungsi bagi membuat permintaan API.\n",
    "\n",
    "Untuk bermula, mari kita lihat mengapa kita ingin menggunakan function calling pada mulanya:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # dapatkan respons baru daripada GPT di mana ia boleh melihat respons fungsi\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kenapa Perlu Function Calling\n",
    "\n",
    "Jika anda telah menyelesaikan mana-mana pelajaran lain dalam kursus ini, anda mungkin sudah faham kehebatan menggunakan Large Language Models (LLMs). Diharapkan anda juga dapat melihat beberapa kekurangannya.\n",
    "\n",
    "Function Calling ialah satu ciri dalam Azure Open AI Service untuk mengatasi kekangan berikut:\n",
    "1) Format respons yang konsisten\n",
    "2) Keupayaan menggunakan data dari sumber lain dalam aplikasi dalam konteks perbualan\n",
    "\n",
    "Sebelum adanya function calling, respons daripada LLM adalah tidak berstruktur dan tidak konsisten. Pembangun perlu menulis kod pengesahan yang rumit untuk memastikan mereka boleh mengendalikan setiap variasi respons.\n",
    "\n",
    "Pengguna tidak boleh mendapatkan jawapan seperti \"Apakah cuaca semasa di Stockholm?\". Ini kerana model-model ini terhad kepada masa data dilatih sahaja.\n",
    "\n",
    "Mari kita lihat contoh di bawah yang menerangkan masalah ini:\n",
    "\n",
    "Katakan kita ingin membina satu pangkalan data maklumat pelajar supaya kita boleh mencadangkan kursus yang sesuai kepada mereka. Di bawah ini terdapat dua penerangan pelajar yang sangat serupa dari segi data yang terkandung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin menghantar ini kepada LLM untuk menganalisis data. Ini boleh digunakan kemudian dalam aplikasi kami untuk dihantar ke API atau disimpan dalam pangkalan data.\n",
    "\n",
    "Mari kita cipta dua arahan yang sama yang akan kita arahkan kepada LLM tentang maklumat apa yang kami minati:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin menghantar ini kepada LLM untuk menganalisis bahagian yang penting untuk produk kami. Jadi kami boleh mencipta dua arahan yang sama untuk mengarahkan LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selepas mencipta dua arahan ini, kita akan menghantarnya kepada LLM dengan menggunakan `openai.ChatCompletion`. Kita menyimpan arahan tersebut dalam pembolehubah `messages` dan menetapkan peranan kepada `user`. Ini adalah untuk meniru mesej daripada pengguna yang ditulis kepada chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita boleh menghantar kedua-dua permintaan kepada LLM dan memeriksa respons yang kita terima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walaupun arahan yang diberikan sama dan penerangannya serupa, kita boleh dapatkan format yang berbeza untuk sifat `Grades`.\n",
    "\n",
    "Jika anda jalankan sel di atas beberapa kali, formatnya boleh jadi `3.7` atau `3.7 GPA`.\n",
    "\n",
    "Ini kerana LLM mengambil data tidak berstruktur dalam bentuk arahan bertulis dan juga memulangkan data yang tidak berstruktur. Kita perlu ada format berstruktur supaya kita tahu apa yang dijangka apabila menyimpan atau menggunakan data ini.\n",
    "\n",
    "Dengan menggunakan pemanggilan fungsi, kita boleh pastikan kita menerima data yang berstruktur. Apabila menggunakan pemanggilan fungsi, LLM sebenarnya tidak memanggil atau menjalankan sebarang fungsi. Sebaliknya, kita cipta satu struktur untuk LLM ikut dalam responsnya. Kemudian, kita gunakan respons berstruktur itu untuk tahu fungsi mana yang perlu dijalankan dalam aplikasi kita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rajah Aliran Pemanggilan Fungsi](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kes Penggunaan untuk menggunakan panggilan fungsi\n",
    "\n",
    "**Memanggil Alat Luaran**  \n",
    "Chatbot sangat bagus untuk memberikan jawapan kepada soalan daripada pengguna. Dengan menggunakan panggilan fungsi, chatbot boleh menggunakan mesej daripada pengguna untuk melengkapkan tugasan tertentu. Contohnya, seorang pelajar boleh meminta chatbot untuk \"Hantar emel kepada pensyarah saya mengatakan saya perlukan lebih bantuan dengan subjek ini\". Ini boleh membuat panggilan fungsi kepada `send_email(to: string, body: string)`\n",
    "\n",
    "**Membuat Permintaan API atau Pangkalan Data**  \n",
    "Pengguna boleh mencari maklumat menggunakan bahasa semula jadi yang akan ditukar kepada permintaan API atau pertanyaan yang diformatkan. Contohnya, seorang guru yang meminta \"Siapa pelajar yang telah menyiapkan tugasan terakhir\" yang boleh memanggil fungsi bernama `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Mewujudkan Data Berstruktur**  \n",
    "Pengguna boleh mengambil satu blok teks atau CSV dan menggunakan LLM untuk mengekstrak maklumat penting daripadanya. Contohnya, seorang pelajar boleh menukar artikel Wikipedia tentang perjanjian damai untuk mencipta kad imbas AI. Ini boleh dilakukan dengan menggunakan fungsi yang dipanggil `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membuat Panggilan Fungsi Pertama Anda\n",
    "\n",
    "Proses untuk membuat panggilan fungsi melibatkan 3 langkah utama:\n",
    "1. Memanggil API Chat Completions dengan senarai fungsi anda dan mesej daripada pengguna\n",
    "2. Membaca respons model untuk melakukan tindakan seperti menjalankan fungsi atau panggilan API\n",
    "3. Membuat panggilan semula ke API Chat Completions dengan respons daripada fungsi anda untuk menggunakan maklumat tersebut bagi menghasilkan jawapan kepada pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Aliran Panggilan Fungsi](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemen dalam panggilan fungsi\n",
    "\n",
    "#### Input Pengguna\n",
    "\n",
    "Langkah pertama adalah mencipta mesej pengguna. Ini boleh diberikan secara dinamik dengan mengambil nilai dari input teks atau anda boleh tetapkan nilai di sini. Jika ini kali pertama anda menggunakan API Chat Completions, kita perlu tetapkan `role` dan `content` untuk mesej tersebut.\n",
    "\n",
    "`role` boleh jadi sama ada `system` (mencipta peraturan), `assistant` (model) atau `user` (pengguna akhir). Untuk panggilan fungsi, kita akan tetapkan ini sebagai `user` dan berikan contoh soalan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat fungsi.\n",
    "\n",
    "Seterusnya kita akan tetapkan satu fungsi dan parameter untuk fungsi tersebut. Kita akan gunakan satu fungsi sahaja di sini iaitu `search_courses` tetapi anda boleh cipta beberapa fungsi lain.\n",
    "\n",
    "**Penting** : Fungsi akan dimasukkan dalam mesej sistem kepada LLM dan akan mengambil sebahagian daripada jumlah token yang anda ada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definisi**\n",
    "\n",
    "`name` - Nama fungsi yang ingin kita panggil.\n",
    "\n",
    "`description` - Ini adalah penerangan tentang bagaimana fungsi tersebut berfungsi. Di sini penting untuk jelaskan dengan terperinci dan jelas.\n",
    "\n",
    "`parameters` - Senarai nilai dan format yang anda mahu model hasilkan dalam responsnya.\n",
    "\n",
    "`type` - Jenis data bagi sifat-sifat yang akan disimpan.\n",
    "\n",
    "`properties` - Senarai nilai khusus yang akan digunakan oleh model untuk responsnya.\n",
    "\n",
    "`name` - Nama sifat yang akan digunakan oleh model dalam respons yang diformat.\n",
    "\n",
    "`type` - Jenis data bagi sifat ini.\n",
    "\n",
    "`description` - Penerangan tentang sifat tertentu ini.\n",
    "\n",
    "**Pilihan**\n",
    "\n",
    "`required` - sifat yang diperlukan supaya panggilan fungsi dapat diselesaikan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat panggilan fungsi\n",
    "Selepas mendefinisikan fungsi, kini kita perlu memasukkannya dalam panggilan ke Chat Completion API. Kita lakukan ini dengan menambah `functions` ke dalam permintaan. Dalam kes ini `functions=functions`.\n",
    "\n",
    "Terdapat juga pilihan untuk menetapkan `function_call` kepada `auto`. Ini bermaksud kita akan membiarkan LLM menentukan fungsi mana yang patut dipanggil berdasarkan mesej pengguna dan bukannya kita tetapkan sendiri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang mari kita lihat respons dan bagaimana ia diformat:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Anda boleh lihat bahawa nama fungsi dipanggil dan daripada mesej pengguna, LLM dapat mencari data untuk dimasukkan ke dalam argumen fungsi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mengintegrasikan Panggilan Fungsi ke dalam Aplikasi.\n",
    "\n",
    "Selepas kita menguji respons yang telah diformat daripada LLM, kini kita boleh mengintegrasikannya ke dalam aplikasi.\n",
    "\n",
    "### Mengurus aliran\n",
    "\n",
    "Untuk mengintegrasikannya ke dalam aplikasi kita, mari ikuti langkah-langkah berikut:\n",
    "\n",
    "Pertama, buat panggilan ke perkhidmatan Open AI dan simpan mesej tersebut dalam pembolehubah yang dipanggil `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita akan mentakrifkan fungsi yang akan memanggil API Microsoft Learn untuk mendapatkan senarai kursus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai amalan terbaik, kita akan lihat sama ada model ingin memanggil sesuatu fungsi. Selepas itu, kita akan cipta salah satu fungsi yang tersedia dan padankan dengan fungsi yang sedang dipanggil. \n",
    "Kemudian, kita akan ambil argumen fungsi tersebut dan padankan dengan argumen daripada LLM.\n",
    "\n",
    "Akhir sekali, kita akan lampirkan mesej panggilan fungsi dan nilai yang dikembalikan oleh mesej `search_courses`. Ini akan memberikan semua maklumat yang diperlukan oleh LLM\n",
    "untuk membalas kepada pengguna menggunakan bahasa semula jadi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabaran Kod\n",
    "\n",
    "Kerja yang bagus! Untuk meneruskan pembelajaran anda tentang Azure Open AI Function Calling, anda boleh bina: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Lebih banyak parameter fungsi yang mungkin membantu pelajar mencari lebih banyak kursus. Anda boleh lihat parameter API yang tersedia di sini:\n",
    " - Cipta satu lagi panggilan fungsi yang mengambil lebih banyak maklumat daripada pelajar seperti bahasa ibunda mereka\n",
    " - Cipta pengendalian ralat apabila panggilan fungsi dan/atau panggilan API tidak memulangkan sebarang kursus yang sesuai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sah. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:24:47+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}