{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pengenalan\n",
    "\n",
    "Pelajaran ini akan merangkumi:\n",
    "- Apa itu pemanggilan fungsi dan kegunaannya\n",
    "- Cara membuat pemanggilan fungsi menggunakan OpenAI\n",
    "- Cara mengintegrasikan pemanggilan fungsi ke dalam aplikasi\n",
    "\n",
    "## Matlamat Pembelajaran\n",
    "\n",
    "Selepas melengkapkan pelajaran ini, anda akan tahu cara dan memahami:\n",
    "\n",
    "- Tujuan menggunakan pemanggilan fungsi\n",
    "- Menyediakan Pemanggilan Fungsi menggunakan Perkhidmatan OpenAI\n",
    "- Reka bentuk pemanggilan fungsi yang berkesan untuk kegunaan aplikasi anda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memahami Panggilan Fungsi\n",
    "\n",
    "Untuk pelajaran ini, kita ingin membina satu ciri untuk syarikat permulaan pendidikan kita yang membolehkan pengguna menggunakan chatbot untuk mencari kursus teknikal. Kami akan mencadangkan kursus yang sesuai dengan tahap kemahiran, peranan semasa dan teknologi yang diminati oleh mereka.\n",
    "\n",
    "Untuk menyiapkan tugasan ini, kita akan menggunakan gabungan:\n",
    " - `OpenAI` untuk mencipta pengalaman chat bagi pengguna\n",
    " - `Microsoft Learn Catalog API` untuk membantu pengguna mencari kursus berdasarkan permintaan mereka\n",
    " - `Function Calling` untuk mengambil pertanyaan pengguna dan menghantarnya ke satu fungsi untuk membuat permintaan API.\n",
    "\n",
    "Untuk memulakan, mari kita lihat mengapa kita ingin menggunakan function calling pada mulanya:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # dapatkan respons baru daripada GPT di mana ia boleh melihat respons fungsi\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kenapa Perlu Function Calling\n",
    "\n",
    "Jika anda telah menyelesaikan mana-mana pelajaran lain dalam kursus ini, anda mungkin sudah faham kehebatan menggunakan Model Bahasa Besar (LLM). Diharapkan anda juga dapat melihat beberapa kekurangannya.\n",
    "\n",
    "Function Calling ialah satu ciri dalam OpenAI Service yang direka untuk menangani cabaran berikut:\n",
    "\n",
    "Format Respons Tidak Konsisten:\n",
    "- Sebelum function calling, respons daripada model bahasa besar adalah tidak berstruktur dan tidak konsisten. Pembangun terpaksa menulis kod pengesahan yang rumit untuk mengendalikan setiap variasi dalam output.\n",
    "\n",
    "Integrasi Terhad dengan Data Luaran:\n",
    "- Sebelum ciri ini, agak sukar untuk memasukkan data dari bahagian lain aplikasi ke dalam konteks perbualan.\n",
    "\n",
    "Dengan menstandardkan format respons dan membolehkan integrasi lancar dengan data luaran, function calling memudahkan pembangunan dan mengurangkan keperluan untuk logik pengesahan tambahan.\n",
    "\n",
    "Pengguna tidak boleh mendapatkan jawapan seperti \"Apakah cuaca semasa di Stockholm?\". Ini kerana model hanya terhad kepada masa data dilatih.\n",
    "\n",
    "Mari kita lihat contoh di bawah yang menggambarkan masalah ini:\n",
    "\n",
    "Katakan kita ingin membina satu pangkalan data maklumat pelajar supaya kita boleh mencadangkan kursus yang sesuai kepada mereka. Di bawah ini terdapat dua penerangan pelajar yang sangat serupa dari segi data yang terkandung.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin menghantar ini kepada LLM untuk menganalisis data. Ini boleh digunakan kemudian dalam aplikasi kami untuk dihantar ke API atau disimpan dalam pangkalan data.\n",
    "\n",
    "Mari kita cipta dua arahan yang sama yang akan kita arahkan kepada LLM tentang maklumat apa yang kami minati:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin menghantar ini kepada LLM untuk menganalisis bahagian-bahagian yang penting untuk produk kami. Jadi kami boleh mencipta dua arahan yang sama untuk mengarahkan LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selepas mencipta dua arahan ini, kita akan menghantarnya kepada LLM dengan menggunakan `openai.ChatCompletion`. Kita menyimpan arahan tersebut dalam pembolehubah `messages` dan menetapkan peranan kepada `user`. Ini adalah untuk meniru mesej daripada pengguna yang ditulis kepada chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita boleh menghantar kedua-dua permintaan kepada LLM dan memeriksa respons yang kita terima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walaupun arahan yang diberikan adalah sama dan penerangannya serupa, kita boleh dapatkan format yang berbeza untuk sifat `Grades`.\n",
    "\n",
    "Jika anda jalankan sel di atas beberapa kali, formatnya boleh jadi `3.7` atau `3.7 GPA`.\n",
    "\n",
    "Ini kerana LLM mengambil data tidak berstruktur dalam bentuk arahan bertulis dan juga memulangkan data yang tidak berstruktur. Kita perlu ada format berstruktur supaya kita tahu apa yang dijangka apabila menyimpan atau menggunakan data ini.\n",
    "\n",
    "Dengan menggunakan pemanggilan fungsi, kita boleh pastikan kita menerima data yang berstruktur. Apabila menggunakan pemanggilan fungsi, LLM sebenarnya tidak memanggil atau menjalankan sebarang fungsi. Sebaliknya, kita cipta satu struktur untuk LLM ikut dalam responsnya. Kemudian, kita gunakan respons berstruktur itu untuk tahu fungsi mana yang perlu dijalankan dalam aplikasi kita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rajah Aliran Pemanggilan Fungsi](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kegunaan untuk menggunakan panggilan fungsi\n",
    "\n",
    "**Memanggil Alat Luaran**\n",
    "Chatbot sangat bagus untuk memberikan jawapan kepada soalan daripada pengguna. Dengan menggunakan panggilan fungsi, chatbot boleh menggunakan mesej daripada pengguna untuk melengkapkan tugasan tertentu. Contohnya, seorang pelajar boleh meminta chatbot untuk \"Hantar emel kepada pensyarah saya mengatakan saya perlukan lebih bantuan dengan subjek ini\". Ini boleh membuat panggilan fungsi kepada `send_email(to: string, body: string)`\n",
    "\n",
    "**Membuat Permintaan API atau Pangkalan Data**\n",
    "Pengguna boleh mencari maklumat menggunakan bahasa semula jadi yang akan ditukar kepada permintaan API atau pertanyaan yang diformatkan. Contohnya, seorang guru boleh meminta \"Siapa pelajar yang telah menyiapkan tugasan terakhir\" yang boleh memanggil fungsi bernama `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Mewujudkan Data Berstruktur**\n",
    "Pengguna boleh mengambil satu blok teks atau CSV dan menggunakan LLM untuk mengekstrak maklumat penting daripadanya. Sebagai contoh, seorang pelajar boleh menukar artikel Wikipedia tentang perjanjian damai untuk mencipta kad imbas AI. Ini boleh dilakukan dengan menggunakan fungsi yang dipanggil `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membuat Panggilan Fungsi Pertama Anda\n",
    "\n",
    "Proses untuk membuat panggilan fungsi merangkumi 3 langkah utama:\n",
    "1. Memanggil Chat Completions API dengan senarai fungsi anda dan mesej pengguna\n",
    "2. Membaca respons model untuk melakukan sesuatu tindakan iaitu melaksanakan fungsi atau Panggilan API\n",
    "3. Membuat satu lagi panggilan ke Chat Completions API dengan respons daripada fungsi anda untuk menggunakan maklumat tersebut bagi membalas kepada pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Aliran Panggilan Fungsi](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemen dalam panggilan fungsi\n",
    "\n",
    "#### Input Pengguna\n",
    "\n",
    "Langkah pertama adalah mencipta mesej pengguna. Ini boleh diberikan secara dinamik dengan mengambil nilai dari input teks atau anda boleh tetapkan nilai di sini. Jika ini kali pertama anda menggunakan API Chat Completions, kita perlu tetapkan `role` dan `content` untuk mesej tersebut.\n",
    "\n",
    "`role` boleh jadi sama ada `system` (mencipta peraturan), `assistant` (model) atau `user` (pengguna akhir). Untuk panggilan fungsi, kita akan tetapkan ini sebagai `user` dan satu contoh soalan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat fungsi.\n",
    "\n",
    "Seterusnya kita akan tetapkan satu fungsi dan parameter untuk fungsi tersebut. Kita akan gunakan satu fungsi sahaja di sini yang dipanggil `search_courses` tetapi anda boleh cipta beberapa fungsi lain.\n",
    "\n",
    "**Penting** : Fungsi akan dimasukkan dalam mesej sistem kepada LLM dan akan mengambil sebahagian daripada jumlah token yang anda ada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definisi**\n",
    "\n",
    "Struktur definisi fungsi mempunyai beberapa peringkat, setiap satu dengan ciri-ciri tersendiri. Berikut adalah pecahan struktur bersarang tersebut:\n",
    "\n",
    "**Ciri-ciri Fungsi Peringkat Atas:**\n",
    "\n",
    "`name` - Nama fungsi yang kita ingin panggil.\n",
    "\n",
    "`description` - Ini adalah penerangan tentang bagaimana fungsi itu berfungsi. Di sini penting untuk menjadi spesifik dan jelas\n",
    "\n",
    "`parameters` - Senarai nilai dan format yang anda mahu model hasilkan dalam responsnya\n",
    "\n",
    "**Ciri-ciri Objek Parameter:**\n",
    "\n",
    "`type` - Jenis data bagi objek parameter (biasanya \"object\")\n",
    "\n",
    "`properties` - Senarai nilai khusus yang akan digunakan oleh model untuk responsnya\n",
    "\n",
    "**Ciri-ciri Setiap Parameter:**\n",
    "\n",
    "`name` - Ditakrif secara tersirat oleh kunci sifat (contohnya, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Jenis data bagi parameter tertentu ini (contohnya, \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Penerangan tentang parameter tertentu\n",
    "\n",
    "**Ciri-ciri Pilihan:**\n",
    "\n",
    "`required` - Satu senarai yang menyenaraikan parameter mana yang diperlukan untuk panggilan fungsi diselesaikan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat panggilan fungsi\n",
    "Selepas mendefinisikan fungsi, kini kita perlu memasukkannya dalam panggilan ke Chat Completion API. Kita lakukan ini dengan menambah `functions` pada permintaan. Dalam kes ini `functions=functions`.\n",
    "\n",
    "Terdapat juga pilihan untuk menetapkan `function_call` kepada `auto`. Ini bermaksud kita akan membiarkan LLM menentukan fungsi mana yang patut dipanggil berdasarkan mesej pengguna dan bukannya kita tetapkan sendiri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang mari kita lihat respons dan bagaimana ia diformatkan:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Anda boleh lihat bahawa nama fungsi dipanggil dan daripada mesej pengguna, LLM dapat mencari data untuk dimasukkan ke dalam argumen fungsi tersebut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mengintegrasikan Panggilan Fungsi ke dalam Aplikasi.\n",
    "\n",
    "Selepas kita menguji respons yang telah diformat daripada LLM, kini kita boleh mengintegrasikannya ke dalam aplikasi.\n",
    "\n",
    "### Mengurus aliran\n",
    "\n",
    "Untuk mengintegrasikannya ke dalam aplikasi kita, mari ikuti langkah-langkah berikut:\n",
    "\n",
    "Pertama, buat panggilan ke perkhidmatan OpenAI dan simpan mesej tersebut dalam pembolehubah yang dipanggil `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita akan mentakrifkan fungsi yang akan memanggil API Microsoft Learn untuk mendapatkan senarai kursus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai amalan terbaik, kita akan lihat sama ada model ingin memanggil sesuatu fungsi. Selepas itu, kita akan cipta salah satu fungsi yang tersedia dan padankan dengan fungsi yang sedang dipanggil. \n",
    "Kemudian, kita akan ambil argumen fungsi tersebut dan padankan dengan argumen daripada LLM.\n",
    "\n",
    "Akhir sekali, kita akan lampirkan mesej panggilan fungsi dan nilai yang dipulangkan oleh mesej `search_courses`. Ini akan memberikan semua maklumat yang diperlukan oleh LLM\n",
    "untuk membalas kepada pengguna menggunakan bahasa semula jadi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabaran Kod\n",
    "\n",
    "Kerja yang bagus! Untuk terus belajar tentang OpenAI Function Calling, anda boleh bina: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Tambah lebih banyak parameter pada fungsi yang boleh membantu pelajar mencari lebih banyak kursus. Anda boleh lihat parameter API yang tersedia di sini:\n",
    " - Cipta satu lagi panggilan fungsi yang mengambil lebih banyak maklumat daripada pelajar seperti bahasa ibunda mereka\n",
    " - Wujudkan pengendalian ralat apabila panggilan fungsi dan/atau panggilan API tidak memulangkan sebarang kursus yang sesuai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sah. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:13:38+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}