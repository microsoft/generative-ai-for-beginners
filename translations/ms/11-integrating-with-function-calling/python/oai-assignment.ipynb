{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Pelajaran ini akan merangkumi: \n",
    "- Apa itu pemanggilan fungsi dan kegunaannya \n",
    "- Cara membuat panggilan fungsi menggunakan OpenAI \n",
    "- Cara mengintegrasikan panggilan fungsi ke dalam aplikasi \n",
    "\n",
    "## Learning Goals \n",
    "\n",
    "Selepas menamatkan pelajaran ini anda akan tahu cara dan memahami: \n",
    "\n",
    "- Tujuan menggunakan pemanggilan fungsi \n",
    "- Menyediakan Panggilan Fungsi menggunakan Perkhidmatan OpenAI \n",
    "- Mereka bentuk panggilan fungsi yang berkesan untuk kes penggunaan aplikasi anda \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memahami Panggilan Fungsi\n",
    "\n",
    "Untuk pelajaran ini, kami ingin membina ciri untuk startup pendidikan kami yang membolehkan pengguna menggunakan chatbot untuk mencari kursus teknikal. Kami akan mengesyorkan kursus yang sesuai dengan tahap kemahiran mereka, peranan semasa dan teknologi yang diminati.\n",
    "\n",
    "Untuk melengkapkan ini, kami akan menggunakan gabungan:\n",
    " - `OpenAI` untuk mencipta pengalaman sembang untuk pengguna\n",
    " - `Microsoft Learn Catalog API` untuk membantu pengguna mencari kursus berdasarkan permintaan pengguna\n",
    " - `Function Calling` untuk mengambil pertanyaan pengguna dan menghantarnya ke fungsi untuk membuat permintaan API.\n",
    "\n",
    "Untuk memulakan, mari kita lihat mengapa kita ingin menggunakan panggilan fungsi pada mulanya:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # dapatkan respons baru dari GPT di mana ia boleh melihat respons fungsi\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengapa Panggilan Fungsi\n",
    "\n",
    "Jika anda telah menyelesaikan mana-mana pelajaran lain dalam kursus ini, anda mungkin memahami kuasa menggunakan Model Bahasa Besar (LLM). Diharapkan anda juga dapat melihat beberapa hadnya.\n",
    "\n",
    "Panggilan Fungsi adalah ciri Perkhidmatan OpenAI yang direka untuk menangani cabaran berikut:\n",
    "\n",
    "Format Respons Tidak Konsisten:\n",
    "- Sebelum panggilan fungsi, respons daripada model bahasa besar adalah tidak berstruktur dan tidak konsisten. Pembangun terpaksa menulis kod pengesahan yang kompleks untuk mengendalikan setiap variasi dalam output.\n",
    "\n",
    "Integrasi Terhad dengan Data Luaran:\n",
    "- Sebelum ciri ini, sukar untuk menggabungkan data dari bahagian lain aplikasi ke dalam konteks sembang.\n",
    "\n",
    "Dengan menstandardkan format respons dan membolehkan integrasi lancar dengan data luaran, panggilan fungsi memudahkan pembangunan dan mengurangkan keperluan logik pengesahan tambahan.\n",
    "\n",
    "Pengguna tidak dapat mendapatkan jawapan seperti \"Apakah cuaca semasa di Stockholm?\". Ini kerana model terhad kepada masa data dilatih.\n",
    "\n",
    "Mari kita lihat contoh di bawah yang menggambarkan masalah ini:\n",
    "\n",
    "Katakan kita ingin membuat pangkalan data data pelajar supaya kita boleh mencadangkan kursus yang sesuai kepada mereka. Di bawah ini kita mempunyai dua penerangan pelajar yang sangat serupa dalam data yang mereka kandungi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin menghantar ini kepada LLM untuk mengurai data. Ini boleh digunakan kemudian dalam aplikasi kami untuk menghantar ini ke API atau menyimpannya dalam pangkalan data.\n",
    "\n",
    "Mari kita cipta dua arahan yang sama yang kami arahkan kepada LLM mengenai maklumat yang kami minati:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin menghantar ini kepada LLM untuk menganalisis bahagian yang penting kepada produk kami. Jadi kami boleh mencipta dua arahan yang sama untuk mengarahkan LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selepas mencipta dua arahan ini, kami akan menghantarnya ke LLM menggunakan `openai.ChatCompletion`. Kami menyimpan arahan dalam pembolehubah `messages` dan menetapkan peranan kepada `user`. Ini adalah untuk meniru mesej daripada pengguna yang ditulis kepada chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita boleh menghantar kedua-dua permintaan kepada LLM dan memeriksa respons yang kita terima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Walaupun arahan adalah sama dan penerangan adalah serupa, kita boleh mendapat format yang berbeza bagi sifat `Grades`.\n",
    "\n",
    "Jika anda menjalankan sel di atas beberapa kali, formatnya boleh menjadi `3.7` atau `3.7 GPA`.\n",
    "\n",
    "Ini kerana LLM mengambil data tidak berstruktur dalam bentuk arahan bertulis dan juga mengembalikan data tidak berstruktur. Kita perlu mempunyai format berstruktur supaya kita tahu apa yang dijangka apabila menyimpan atau menggunakan data ini.\n",
    "\n",
    "Dengan menggunakan pemanggilan fungsi, kita boleh memastikan bahawa kita menerima data berstruktur kembali. Apabila menggunakan pemanggilan fungsi, LLM sebenarnya tidak memanggil atau menjalankan sebarang fungsi. Sebaliknya, kita mencipta satu struktur untuk LLM ikuti bagi responsnya. Kita kemudian menggunakan respons berstruktur itu untuk mengetahui fungsi mana yang perlu dijalankan dalam aplikasi kita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Rajah Aliran Panggilan Fungsi](../../../../translated_images/Function-Flow.083875364af4f4bb.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita kemudian boleh mengambil apa yang dikembalikan dari fungsi tersebut dan menghantarnya kembali ke LLM. LLM kemudian akan memberi respons menggunakan bahasa semula jadi untuk menjawab pertanyaan pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kes Penggunaan untuk menggunakan panggilan fungsi\n",
    "\n",
    "**Memanggil Alat Luaran**  \n",
    "Chatbot sangat baik dalam memberikan jawapan kepada soalan daripada pengguna. Dengan menggunakan panggilan fungsi, chatbot boleh menggunakan mesej daripada pengguna untuk melengkapkan tugas tertentu. Contohnya, seorang pelajar boleh meminta chatbot untuk \"Hantar emel kepada pengajar saya mengatakan saya memerlukan lebih banyak bantuan dengan subjek ini\". Ini boleh membuat panggilan fungsi kepada `send_email(to: string, body: string)`\n",
    "\n",
    "**Mewujudkan Pertanyaan API atau Pangkalan Data**  \n",
    "Pengguna boleh mencari maklumat menggunakan bahasa semula jadi yang ditukar menjadi pertanyaan berformat atau permintaan API. Contohnya ialah seorang guru yang meminta \"Siapakah pelajar yang telah menyiapkan tugasan terakhir\" yang boleh memanggil fungsi bernama `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Mewujudkan Data Berstruktur**  \n",
    "Pengguna boleh mengambil sekeping teks atau CSV dan menggunakan LLM untuk mengekstrak maklumat penting daripadanya. Contohnya, seorang pelajar boleh menukar artikel Wikipedia tentang perjanjian damai untuk membuat kad imbas AI. Ini boleh dilakukan dengan menggunakan fungsi yang dipanggil `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membuat Panggilan Fungsi Pertama Anda\n",
    "\n",
    "Proses membuat panggilan fungsi merangkumi 3 langkah utama:  \n",
    "1. Memanggil API Chat Completions dengan senarai fungsi anda dan mesej pengguna  \n",
    "2. Membaca respons model untuk melaksanakan tindakan iaitu menjalankan fungsi atau Panggilan API  \n",
    "3. Membuat panggilan lain ke API Chat Completions dengan respons dari fungsi anda untuk menggunakan maklumat itu bagi menghasilkan respons kepada pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Aliran Panggilan Fungsi](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemen panggilan fungsi\n",
    "\n",
    "#### Input Pengguna\n",
    "\n",
    "Langkah pertama adalah untuk mencipta mesej pengguna. Ini boleh ditetapkan secara dinamik dengan mengambil nilai daripada input teks atau anda boleh menetapkan nilai di sini. Jika ini adalah kali pertama anda bekerja dengan API Chat Completions, kita perlu mentakrifkan `role` dan `content` mesej tersebut.\n",
    "\n",
    "`role` boleh sama ada `system` (mencipta peraturan), `assistant` (model) atau `user` (pengguna akhir). Untuk panggilan fungsi, kita akan menetapkannya sebagai `user` dan satu contoh soalan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat fungsi.\n",
    "\n",
    "Seterusnya kita akan mentakrifkan satu fungsi dan parameter fungsi tersebut. Kita akan menggunakan hanya satu fungsi di sini yang dipanggil `search_courses` tetapi anda boleh membuat pelbagai fungsi.\n",
    "\n",
    "**Penting** : Fungsi-fungsi dimasukkan dalam mesej sistem kepada LLM dan akan dimasukkan dalam jumlah token yang anda ada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definisi** \n",
    "\n",
    "Struktur definisi fungsi mempunyai pelbagai peringkat, setiap satu dengan sifatnya sendiri. Berikut adalah pecahan struktur bersarang:\n",
    "\n",
    "**Sifat Fungsi Tahap Atas:**\n",
    "\n",
    "`name` - Nama fungsi yang ingin kita panggil. \n",
    "\n",
    "`description` - Ini adalah penerangan tentang bagaimana fungsi berfungsi. Di sini penting untuk menjadi spesifik dan jelas \n",
    "\n",
    "`parameters` - Senarai nilai dan format yang anda mahu model hasilkan dalam responsnya \n",
    "\n",
    "**Sifat Objek Parameter:**\n",
    "\n",
    "`type` - Jenis data objek parameter (biasanya \"object\")\n",
    "\n",
    "`properties` - Senarai nilai khusus yang akan digunakan model untuk responsnya \n",
    "\n",
    "**Sifat Parameter Individu:**\n",
    "\n",
    "`name` - Ditakrifkan secara tersirat oleh kunci sifat (contohnya, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Jenis data parameter khusus ini (contohnya, \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Penerangan tentang parameter khusus \n",
    "\n",
    "**Sifat Pilihan:**\n",
    "\n",
    "`required` - Senarai parameter yang diperlukan untuk panggilan fungsi dapat diselesaikan \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat panggilan fungsi  \n",
    "Selepas mentakrifkan fungsi, kita kini perlu memasukkannya dalam panggilan ke API Chat Completion. Kita lakukan ini dengan menambah `functions` ke dalam permintaan. Dalam kes ini `functions=functions`.  \n",
    "\n",
    "Terdapat juga pilihan untuk menetapkan `function_call` kepada `auto`. Ini bermakna kita akan membiarkan LLM memutuskan fungsi mana yang harus dipanggil berdasarkan mesej pengguna dan bukannya menetapkannya sendiri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang mari kita lihat respons dan bagaimana ia diformatkan:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Anda boleh lihat bahawa nama fungsi dipanggil dan daripada mesej pengguna, LLM dapat mencari data untuk memenuhi argumen fungsi tersebut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Mengintegrasikan Panggilan Fungsi ke dalam Aplikasi. \n",
    "\n",
    "\n",
    "Selepas kita menguji respons yang diformat dari LLM, kini kita boleh mengintegrasikannya ke dalam aplikasi. \n",
    "\n",
    "### Menguruskan aliran \n",
    "\n",
    "Untuk mengintegrasikan ini ke dalam aplikasi kita, mari ambil langkah-langkah berikut: \n",
    "\n",
    "Pertama, mari buat panggilan ke perkhidmatan OpenAI dan simpan mesej dalam pembolehubah yang dipanggil `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita akan mentakrifkan fungsi yang akan memanggil API Microsoft Learn untuk mendapatkan senarai kursus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai amalan terbaik, kita akan melihat sama ada model ingin memanggil fungsi. Selepas itu, kita akan mencipta salah satu fungsi yang tersedia dan memadankannya dengan fungsi yang sedang dipanggil.  \n",
    "Kita kemudian akan mengambil argumen fungsi tersebut dan memetakannya kepada argumen dari LLM.\n",
    "\n",
    "Akhir sekali, kita akan menambah mesej panggilan fungsi dan nilai-nilai yang dikembalikan oleh mesej `search_courses`. Ini memberikan LLM semua maklumat yang diperlukan untuk  \n",
    "memberi respons kepada pengguna menggunakan bahasa semula jadi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kami akan menghantar mesej yang dikemas kini kepada LLM supaya kami dapat menerima respons bahasa semula jadi dan bukannya respons berformat JSON API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cabaran Kod\n",
    "\n",
    "Kerja yang hebat! Untuk meneruskan pembelajaran anda mengenai Panggilan Fungsi OpenAI anda boleh membina: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Lebih banyak parameter fungsi yang mungkin membantu pelajar mencari lebih banyak kursus. Anda boleh mencari parameter API yang tersedia di sini:  \n",
    " - Cipta satu lagi panggilan fungsi yang mengambil lebih banyak maklumat daripada pelajar seperti bahasa ibunda mereka  \n",
    " - Cipta pengendalian ralat apabila panggilan fungsi dan/atau panggilan API tidak mengembalikan sebarang kursus yang sesuai  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sahih. Untuk maklumat penting, terjemahan profesional oleh manusia adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T11:05:00+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}