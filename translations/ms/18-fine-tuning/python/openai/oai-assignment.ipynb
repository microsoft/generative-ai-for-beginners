{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalaan Halus Model Open AI\n",
    "\n",
    "Buku nota ini berdasarkan panduan terkini yang disediakan dalam dokumentasi [Penalaan Halus](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) dari Open AI.\n",
    "\n",
    "Penalaan halus meningkatkan prestasi model asas untuk aplikasi anda dengan melatih semula menggunakan data tambahan dan konteks yang berkaitan dengan kes penggunaan atau senario tertentu itu. Perlu diingat bahawa teknik kejuruteraan prompt seperti _few shot learning_ dan _retrieval augmented generation_ membolehkan anda meningkatkan prompt lalai dengan data yang relevan untuk memperbaiki kualiti. Walau bagaimanapun, pendekatan ini terhad oleh saiz tetingkap token maksimum model asas yang disasarkan.\n",
    "\n",
    "Dengan penalaan halus, kita sebenarnya melatih semula model itu sendiri dengan data yang diperlukan (membolehkan kita menggunakan lebih banyak contoh daripada yang boleh muat dalam tetingkap token maksimum) - dan menggunakan versi _custom_ model yang tidak lagi memerlukan contoh disediakan semasa masa inferens. Ini bukan sahaja meningkatkan keberkesanan reka bentuk prompt kita (kita mempunyai lebih fleksibiliti dalam menggunakan tetingkap token untuk perkara lain) tetapi juga berpotensi memperbaiki kos kita (dengan mengurangkan bilangan token yang perlu dihantar ke model semasa masa inferens).\n",
    "\n",
    "Penalaan halus mempunyai 4 langkah:\n",
    "1. Sediakan data latihan dan muat naiknya.\n",
    "1. Jalankan kerja latihan untuk mendapatkan model yang telah ditala halus.\n",
    "1. Nilai model yang telah ditala halus dan ulangi untuk kualiti.\n",
    "1. Gunakan model yang telah ditala halus untuk inferens apabila berpuas hati.\n",
    "\n",
    "Perlu diingat bahawa tidak semua model asas menyokong penalaan halus - [semak dokumentasi OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) untuk maklumat terkini. Anda juga boleh menala halus model yang telah ditala halus sebelum ini. Dalam tutorial ini, kita akan menggunakan `gpt-35-turbo` sebagai model asas sasaran untuk penalaan halus. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 1.1: Sediakan Dataset Anda\n",
    "\n",
    "Mari bina chatbot yang membantu anda memahami jadual berkala unsur dengan menjawab soalan tentang satu unsur menggunakan limerik. Dalam tutorial mudah _ini_, kita hanya akan mencipta dataset untuk melatih model dengan beberapa contoh respons yang menunjukkan format data yang dijangka. Dalam kes penggunaan dunia sebenar, anda perlu mencipta dataset dengan lebih banyak contoh. Anda juga mungkin boleh menggunakan dataset terbuka (untuk domain aplikasi anda) jika ada, dan memformat semula untuk digunakan dalam penalaan halus.\n",
    "\n",
    "Oleh kerana kita memfokuskan pada `gpt-35-turbo` dan mencari respons satu pusingan (penyempurnaan sembang), kita boleh mencipta contoh menggunakan [format yang dicadangkan ini](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) yang mencerminkan keperluan penyempurnaan sembang OpenAI. Jika anda menjangkakan kandungan perbualan berbilang pusingan, anda akan menggunakan [format contoh berbilang pusingan](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) yang termasuk parameter `weight` untuk menandakan mesej mana yang harus digunakan (atau tidak) dalam proses penalaan halus.\n",
    "\n",
    "Kita akan menggunakan format satu pusingan yang lebih mudah untuk tutorial kita di sini. Data adalah dalam format [jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) dengan 1 rekod setiap baris, setiap satu diwakili sebagai objek berformat JSON. Petikan di bawah menunjukkan 2 rekod sebagai contoh - lihat [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) untuk set contoh penuh (10 contoh) yang akan kita gunakan untuk tutorial penalaan halus kita. **Nota:** Setiap rekod _mesti_ ditakrifkan dalam satu baris sahaja (tidak dibahagi merentasi baris seperti biasa dalam fail JSON yang diformat)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Dalam kes penggunaan dunia sebenar, anda akan memerlukan set contoh yang jauh lebih besar untuk hasil yang baik - pertukaran adalah antara kualiti respons dan masa/kos untuk penalaan halus. Kita menggunakan set kecil supaya kita dapat menyelesaikan penalaan halus dengan cepat untuk menggambarkan proses tersebut. Lihat [contoh OpenAI Cookbook ini](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) untuk tutorial penalaan halus yang lebih kompleks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Langkah 1.2 Muat Naik Dataset Anda\n",
    "\n",
    "Muat naik data menggunakan Files API [seperti yang diterangkan di sini](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Perlu diingat bahawa untuk menjalankan kod ini, anda mesti telah melakukan langkah-langkah berikut terlebih dahulu:\n",
    " - Pasang pakej Python `openai` (pastikan anda menggunakan versi >=0.28.0 untuk ciri terkini)\n",
    " - Tetapkan pembolehubah persekitaran `OPENAI_API_KEY` kepada kunci API OpenAI anda\n",
    "Untuk mengetahui lebih lanjut, lihat [panduan Persediaan](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) yang disediakan untuk kursus ini.\n",
    "\n",
    "Sekarang, jalankan kod untuk mencipta fail untuk dimuat naik dari fail JSONL tempatan anda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Langkah 2.1: Cipta tugasan Penalaan Halus dengan SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Langkah 2.2: Semak Status kerja\n",
    "\n",
    "Berikut adalah beberapa perkara yang anda boleh lakukan dengan API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Senaraikan n kerja penalaan terakhir\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Dapatkan butiran kerja penalaan tertentu\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Batalkan kerja penalaan\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Senaraikan sehingga n acara dari kerja tersebut\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Langkah pertama proses ini adalah _mengesahkan fail latihan_ untuk memastikan data dalam format yang betul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Langkah 2.3: Jejak acara untuk memantau kemajuan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.4: Lihat status dalam Papan Pemuka OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda juga boleh melihat status dengan melawat laman web OpenAI dan meneroka bahagian _Fine-tuning_ platform tersebut. Ini akan menunjukkan status kerja semasa, dan juga membolehkan anda menjejaki sejarah pelaksanaan kerja terdahulu. Dalam tangkapan skrin ini, anda boleh melihat bahawa pelaksanaan terdahulu gagal, dan larian kedua berjaya. Untuk konteks, ini berlaku apabila larian pertama menggunakan fail JSON dengan rekod yang diformatkan dengan tidak betul - setelah diperbaiki, larian kedua selesai dengan jayanya dan menjadikan model tersedia untuk digunakan.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ms/fine-tuned-model-status.563271727bf7bfba.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda juga boleh melihat mesej status dan metrik dengan menatal ke bawah lagi dalam papan pemuka visual seperti yang ditunjukkan:\n",
    "\n",
    "| Mesej | Metrik |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/ms/fine-tuned-messages-panel.4ed0c2da5ea1313b.webp) |  ![Metrics](../../../../../translated_images/ms/fine-tuned-metrics-panel.700d7e4995a65229.webp)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Langkah 3.1: Dapatkan ID & Uji Model Fine-Tuned dalam Kod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Langkah 3.2: Muat & Uji Model Halus yang Telah Disesuaikan di Playground\n",
    "\n",
    "Anda kini boleh menguji model halus yang telah disesuaikan dengan dua cara. Pertama, anda boleh melawat Playground dan menggunakan menu lungsur Models untuk memilih model halus yang baru anda sesuaikan daripada pilihan yang disenaraikan. Pilihan lain adalah menggunakan pilihan \"Playground\" yang ditunjukkan dalam panel Fine-tuning (lihat tangkapan skrin di atas) yang melancarkan paparan _perbandingan_ berikut yang menunjukkan versi model asas dan model halus yang disesuaikan secara berdampingan untuk penilaian cepat.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ms/fine-tuned-playground-compare.56e06f0ad8922016.webp)\n",
    "\n",
    "Isikan sahaja konteks sistem yang digunakan dalam data latihan anda dan berikan soalan ujian anda. Anda akan perasan bahawa kedua-dua sisi dikemas kini dengan konteks dan soalan yang sama. Jalankan perbandingan dan anda akan melihat perbezaan output antara keduanya. _Perhatikan bagaimana model halus yang disesuaikan menghasilkan respons dalam format yang anda berikan dalam contoh anda manakala model asas hanya mengikuti arahan sistem_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ms/fine-tuned-playground-launch.5a26495c983c6350.webp)\n",
    "\n",
    "Anda akan perasan bahawa perbandingan juga menyediakan kiraan token untuk setiap model, dan masa yang diambil untuk inferens. **Contoh khusus ini adalah contoh ringkas yang bertujuan untuk menunjukkan proses tetapi tidak mencerminkan dataset atau senario dunia sebenar**. Anda mungkin perasan bahawa kedua-dua sampel menunjukkan bilangan token yang sama (konteks sistem dan arahan pengguna adalah sama) dengan model halus yang disesuaikan mengambil masa lebih lama untuk inferens (model tersuai).\n",
    "\n",
    "Dalam senario dunia sebenar, anda tidak akan menggunakan contoh mainan seperti ini, tetapi menyesuaikan model dengan data sebenar (contohnya, katalog produk untuk perkhidmatan pelanggan) di mana kualiti respons akan lebih ketara. Dalam _konteks_ itu, mendapatkan kualiti respons yang setara dengan model asas akan memerlukan kejuruteraan arahan tersuai yang lebih banyak yang akan meningkatkan penggunaan token dan berpotensi masa pemprosesan yang berkaitan untuk inferens. _Untuk mencuba ini, lihat contoh fine-tuning dalam OpenAI Cookbook untuk memulakan._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk ketepatan, sila ambil maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sahih. Untuk maklumat penting, terjemahan profesional oleh manusia adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:05:46+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}