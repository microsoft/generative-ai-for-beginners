{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Penalaan Halus Model Open AI\n",
    "\n",
    "Notebook ini berdasarkan panduan semasa yang diberikan dalam dokumentasi [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) dari Open AI.\n",
    "\n",
    "Penalaan halus meningkatkan prestasi model asas untuk aplikasi anda dengan melatih semula model tersebut menggunakan data tambahan dan konteks yang berkaitan dengan kes penggunaan atau senario tertentu. Perlu diingat bahawa teknik kejuruteraan prompt seperti _few shot learning_ dan _retrieval augmented generation_ membolehkan anda menambah baik prompt lalai dengan data yang relevan untuk meningkatkan kualiti. Namun, pendekatan ini terhad oleh saiz tetingkap token maksimum model asas yang digunakan.\n",
    "\n",
    "Dengan penalaan halus, kita sebenarnya melatih semula model itu sendiri dengan data yang diperlukan (membolehkan kita menggunakan lebih banyak contoh berbanding had tetingkap token maksimum) - dan melancarkan versi _kustom_ model yang tidak lagi memerlukan contoh diberikan semasa inferens. Ini bukan sahaja meningkatkan keberkesanan reka bentuk prompt kita (kita mempunyai lebih banyak fleksibiliti untuk menggunakan tetingkap token bagi tujuan lain) malah berpotensi mengurangkan kos (dengan mengurangkan bilangan token yang perlu dihantar ke model semasa inferens).\n",
    "\n",
    "Penalaan halus mempunyai 4 langkah:\n",
    "1. Sediakan data latihan dan muat naik.\n",
    "1. Jalankan tugasan latihan untuk mendapatkan model yang telah ditala halus.\n",
    "1. Nilai model yang telah ditala halus dan ulangi untuk kualiti.\n",
    "1. Gunakan model yang telah ditala halus untuk inferens apabila berpuas hati.\n",
    "\n",
    "Perlu diingat bahawa tidak semua model asas menyokong penalaan halus - [semak dokumentasi OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) untuk maklumat terkini. Anda juga boleh menala halus model yang telah ditala halus sebelum ini. Dalam tutorial ini, kita akan menggunakan `gpt-35-turbo` sebagai model asas sasaran untuk penalaan halus.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 1.1: Sediakan Set Data Anda\n",
    "\n",
    "Mari kita bina chatbot yang membantu anda memahami jadual berkala unsur dengan menjawab soalan tentang sesuatu unsur dalam bentuk limerik. Dalam tutorial _mudah_ ini, kita hanya akan cipta set data untuk melatih model dengan beberapa contoh respons yang menunjukkan format data yang diharapkan. Untuk kegunaan sebenar, anda perlu cipta set data dengan lebih banyak contoh. Anda juga boleh menggunakan set data terbuka (untuk domain aplikasi anda) jika ada, dan ubah suai formatnya untuk digunakan dalam proses penalaan lanjut.\n",
    "\n",
    "Oleh kerana kita fokus pada `gpt-35-turbo` dan mahukan respons satu pusingan (penyelesaian chat), kita boleh cipta contoh menggunakan [format yang disyorkan ini](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) yang memenuhi keperluan penyelesaian chat OpenAI. Jika anda menjangkakan kandungan perbualan berbilang pusingan, anda perlu gunakan [format contoh berbilang pusingan](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) yang menyertakan parameter `weight` untuk menandakan mesej mana yang patut digunakan (atau tidak) dalam proses penalaan lanjut.\n",
    "\n",
    "Kita akan gunakan format satu pusingan yang lebih mudah untuk tutorial ini. Data disimpan dalam [format jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) dengan 1 rekod setiap baris, setiap satu diwakili sebagai objek berformat JSON. Contoh di bawah menunjukkan 2 rekod sebagai sampel - lihat [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) untuk set contoh penuh (10 contoh) yang akan digunakan dalam tutorial penalaan lanjut kita. **Nota:** Setiap rekod _mesti_ ditulis dalam satu baris sahaja (bukan dibahagi ke beberapa baris seperti dalam fail JSON yang diformatkan)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Untuk kegunaan sebenar, anda perlu set contoh yang jauh lebih besar untuk hasil yang baik - pertimbangannya adalah antara kualiti respons dan masa/kos untuk penalaan lanjut. Kita gunakan set kecil supaya proses penalaan lanjut dapat disiapkan dengan cepat untuk tujuan ilustrasi. Lihat [contoh OpenAI Cookbook ini](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) untuk tutorial penalaan lanjut yang lebih kompleks.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 1.2 Muat Naik Set Data Anda\n",
    "\n",
    "Muat naik data menggunakan Files API [seperti yang diterangkan di sini](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Perlu diingat bahawa untuk menjalankan kod ini, anda mesti telah melakukan langkah-langkah berikut terlebih dahulu:\n",
    " - Memasang pakej Python `openai` (pastikan anda menggunakan versi >=0.28.0 untuk ciri-ciri terkini)\n",
    " - Tetapkan pembolehubah persekitaran `OPENAI_API_KEY` kepada kunci API OpenAI anda\n",
    "Untuk maklumat lanjut, lihat [Panduan Persediaan](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) yang disediakan untuk kursus ini.\n",
    "\n",
    "Sekarang, jalankan kod untuk mencipta fail yang akan dimuat naik daripada fail JSONL tempatan anda.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.1: Cipta kerja Penalaan Halus dengan SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.2: Semak Status kerja\n",
    "\n",
    "Berikut adalah beberapa perkara yang anda boleh lakukan dengan API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Senaraikan n kerja fine-tuning yang terakhir\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Dapatkan butiran kerja fine-tuning tertentu\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Batalkan kerja fine-tuning\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Senaraikan sehingga n acara daripada kerja tersebut\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Langkah pertama dalam proses ini ialah _mengesahkan fail latihan_ untuk memastikan data berada dalam format yang betul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.3: Jejak acara untuk memantau kemajuan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 2.4: Lihat status dalam Papan Pemuka OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda juga boleh melihat status dengan melayari laman web OpenAI dan meneroka bahagian _Fine-tuning_ di platform tersebut. Di sini, anda boleh melihat status tugasan semasa, serta menjejak sejarah pelaksanaan tugasan sebelum ini. Dalam tangkapan skrin ini, anda dapat lihat bahawa pelaksanaan sebelum ini gagal, dan percubaan kedua berjaya. Untuk makluman, ini berlaku apabila percubaan pertama menggunakan fail JSON dengan rekod yang tidak diformatkan dengan betul - selepas dibaiki, percubaan kedua selesai dengan jayanya dan model tersebut tersedia untuk digunakan.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.ms.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anda juga boleh melihat mesej status dan metrik dengan menatal ke bawah lagi dalam papan pemuka visual seperti yang ditunjukkan:\n",
    "\n",
    "| Mesej | Metrik |\n",
    "|:---|:---|\n",
    "| ![Mesej](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.ms.png) |  ![Metrik](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.ms.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.1: Dapatkan ID & Uji Model yang Telah Disesuaikan dalam Kod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Langkah 3.2: Muat & Uji Model Fine-Tuned di Playground\n",
    "\n",
    "Anda kini boleh menguji model yang telah di-fine-tune dengan dua cara. Pertama, anda boleh lawati Playground dan gunakan menu drop-down Models untuk memilih model fine-tuned anda daripada senarai yang tersedia. Pilihan lain ialah menggunakan pilihan \"Playground\" yang dipaparkan dalam panel Fine-tuning (rujuk tangkapan skrin di atas) yang akan melancarkan paparan _perbandingan_ di mana versi model asas dan model fine-tuned dipaparkan sebelah-menyebelah untuk penilaian pantas.\n",
    "\n",
    "Isikan sahaja konteks sistem yang digunakan dalam data latihan anda dan berikan soalan ujian anda. Anda akan perasan kedua-dua bahagian dikemas kini dengan konteks dan soalan yang sama. Jalankan perbandingan dan anda akan dapat melihat perbezaan output antara kedua-duanya. _Perhatikan bagaimana model fine-tuned menghasilkan respons dalam format yang anda sediakan dalam contoh anda, manakala model asas hanya mengikut arahan sistem._\n",
    "\n",
    "Anda juga akan perasan bahawa perbandingan ini turut memaparkan bilangan token untuk setiap model, serta masa yang diambil untuk inferens. **Contoh khusus ini adalah contoh mudah yang bertujuan untuk menunjukkan proses sahaja dan bukan mencerminkan set data atau situasi dunia sebenar**. Anda mungkin perasan kedua-dua sampel menunjukkan bilangan token yang sama (konteks sistem dan arahan pengguna adalah sama) dengan model fine-tuned mengambil masa lebih lama untuk inferens (model tersuai).\n",
    "\n",
    "Dalam situasi sebenar, anda tidak akan menggunakan contoh mudah seperti ini, tetapi akan melakukan fine-tuning menggunakan data sebenar (contohnya, katalog produk untuk khidmat pelanggan) di mana kualiti respons akan lebih ketara. Dalam konteks _itu_, untuk mendapatkan kualiti respons yang setara dengan model asas memerlukan lebih banyak kerja kejuruteraan prompt tersuai yang akan meningkatkan penggunaan token dan mungkin juga masa pemprosesan untuk inferens. _Untuk mencubanya, lihat contoh fine-tuning dalam OpenAI Cookbook sebagai permulaan._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sah. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:51:03+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}