{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membina Dengan Model Keluarga Meta\n",
    "\n",
    "## Pengenalan\n",
    "\n",
    "Pelajaran ini akan merangkumi:\n",
    "\n",
    "- Meneroka dua model utama dalam keluarga Meta - Llama 3.1 dan Llama 3.2\n",
    "- Memahami kegunaan dan senario untuk setiap model\n",
    "- Contoh kod untuk menunjukkan ciri unik setiap model\n",
    "\n",
    "## Keluarga Model Meta\n",
    "\n",
    "Dalam pelajaran ini, kita akan meneroka 2 model daripada keluarga Meta atau \"Llama Herd\" - Llama 3.1 dan Llama 3.2\n",
    "\n",
    "Model-model ini hadir dalam beberapa varian dan boleh didapati di pasaran Model Github. Berikut adalah maklumat lanjut tentang menggunakan Github Models untuk [membina prototaip dengan model AI](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "Varian Model:\n",
    "- Llama 3.1 - 70B Instruct\n",
    "- Llama 3.1 - 405B Instruct\n",
    "- Llama 3.2 - 11B Vision Instruct\n",
    "- Llama 3.2 - 90B Vision Instruct\n",
    "\n",
    "*Nota: Llama 3 juga tersedia di Github Models tetapi tidak akan dibincangkan dalam pelajaran ini*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "Dengan 405 Bilion Parameter, Llama 3.1 tergolong dalam kategori LLM sumber terbuka.\n",
    "\n",
    "Model ini merupakan peningkatan daripada keluaran Llama 3 sebelum ini dengan menawarkan:\n",
    "\n",
    "- Tetingkap konteks yang lebih besar - 128k token berbanding 8k token\n",
    "- Maksimum Output Token yang lebih tinggi - 4096 berbanding 2048\n",
    "- Sokongan pelbagai bahasa yang lebih baik - hasil daripada peningkatan jumlah token latihan\n",
    "\n",
    "Ciri-ciri ini membolehkan Llama 3.1 menangani kes penggunaan yang lebih kompleks semasa membina aplikasi GenAI termasuk:\n",
    "- Panggilan Fungsi Asli - keupayaan untuk memanggil alat dan fungsi luaran di luar aliran kerja LLM\n",
    "- Prestasi RAG yang lebih baik - disebabkan tetingkap konteks yang lebih besar\n",
    "- Penjanaan Data Sintetik - keupayaan untuk menghasilkan data yang berkesan untuk tugasan seperti penalaan lanjut\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Panggilan Fungsi Asli\n",
    "\n",
    "Llama 3.1 telah ditala dengan lebih baik untuk menjadi lebih berkesan dalam membuat panggilan fungsi atau alat. Ia juga mempunyai dua alat terbina dalam yang boleh dikenal pasti oleh model sebagai perlu digunakan berdasarkan arahan daripada pengguna. Alat-alat ini ialah:\n",
    "\n",
    "- **Brave Search** - Boleh digunakan untuk mendapatkan maklumat terkini seperti cuaca dengan melakukan carian web\n",
    "- **Wolfram Alpha** - Boleh digunakan untuk pengiraan matematik yang lebih kompleks jadi anda tidak perlu menulis fungsi sendiri.\n",
    "\n",
    "Anda juga boleh mencipta alat tersuai anda sendiri yang boleh dipanggil oleh LLM.\n",
    "\n",
    "Dalam contoh kod di bawah:\n",
    "\n",
    "- Kita tetapkan alat yang tersedia (brave_search, wolfram_alpha) dalam arahan sistem.\n",
    "- Hantar arahan pengguna yang bertanya tentang cuaca di sebuah bandar tertentu.\n",
    "- LLM akan membalas dengan panggilan alat kepada alat Brave Search yang akan kelihatan seperti ini `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`\n",
    "\n",
    "*Nota: Contoh ini hanya membuat panggilan alat, jika anda ingin mendapatkan hasilnya, anda perlu mencipta akaun percuma di laman API Brave dan tetapkan fungsi itu sendiri*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2\n",
    "\n",
    "Walaupun Llama 3.1 adalah sebuah LLM, salah satu kekurangannya ialah multimodaliti. Maksudnya, keupayaan untuk menggunakan pelbagai jenis input seperti imej sebagai arahan dan memberikan respons. Keupayaan ini merupakan salah satu ciri utama Llama 3.2. Ciri-ciri ini juga merangkumi:\n",
    "\n",
    "- Multimodaliti - mempunyai keupayaan untuk menilai kedua-dua arahan teks dan imej\n",
    "- Variasi saiz Kecil hingga Sederhana (11B dan 90B) - ini memberikan pilihan pelaksanaan yang fleksibel,\n",
    "- Variasi hanya-teks (1B dan 3B) - ini membolehkan model digunakan pada peranti edge / mudah alih dan memberikan kependaman yang rendah\n",
    "\n",
    "Sokongan multimodal ini merupakan satu langkah besar dalam dunia model sumber terbuka. Contoh kod di bawah menggunakan kedua-dua imej dan arahan teks untuk mendapatkan analisis imej daripada Llama 3.2 90B.\n",
    "\n",
    "### Sokongan Multimodal dengan Llama 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pembelajaran tidak berhenti di sini, teruskan Perjalanan Anda\n",
    "\n",
    "Selepas menamatkan pelajaran ini, lawati [koleksi Pembelajaran AI Generatif](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kami untuk terus meningkatkan pengetahuan anda tentang AI Generatif!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sah. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:46:38+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}