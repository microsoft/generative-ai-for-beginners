{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bab 7: Membina Aplikasi Sembang\n",
    "## Pengenalan Pantas API Model Github\n",
    "\n",
    "Notebook ini diadaptasi daripada [Repositori Sampel Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) yang merangkumi notebook yang mengakses perkhidmatan [Azure OpenAI](notebook-azure-openai.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Pengenalan  \n",
    "\"Model bahasa besar ialah fungsi yang memetakan teks kepada teks. Diberikan satu rentetan teks sebagai input, model bahasa besar akan cuba meramalkan teks yang akan datang seterusnya\"(1). Notebook \"pantas mula\" ini akan memperkenalkan pengguna kepada konsep LLM secara umum, keperluan utama pakej untuk bermula dengan AML, pengenalan ringkas kepada reka bentuk prompt, dan beberapa contoh ringkas untuk pelbagai kegunaan.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Kandungan  \n",
    "\n",
    "[Tinjauan](../../../../07-building-chat-applications/python)  \n",
    "[Cara menggunakan Perkhidmatan OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[1. Membina Perkhidmatan OpenAI anda](../../../../07-building-chat-applications/python)  \n",
    "[2. Pemasangan](../../../../07-building-chat-applications/python)    \n",
    "[3. Kredential](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Kes Penggunaan](../../../../07-building-chat-applications/python)    \n",
    "[1. Merumuskan Teks](../../../../07-building-chat-applications/python)  \n",
    "[2. Mengklasifikasikan Teks](../../../../07-building-chat-applications/python)  \n",
    "[3. Menjana Nama Produk Baru](../../../../07-building-chat-applications/python)  \n",
    "[4. Melaraskan Pengklasifikasi](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Rujukan](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Bina prompt pertama anda  \n",
    "Latihan ringkas ini akan memberikan pengenalan asas untuk menghantar prompt kepada model dalam Github Models bagi tugasan mudah \"penyusunan ringkas\".\n",
    "\n",
    "\n",
    "**Langkah-langkah**:  \n",
    "1. Pasang pustaka `azure-ai-inference` dalam persekitaran python anda, jika belum dipasang.  \n",
    "2. Muatkan pustaka pembantu standard dan sediakan kelayakan untuk Github Models.  \n",
    "3. Pilih model untuk tugasan anda  \n",
    "4. Cipta prompt ringkas untuk model  \n",
    "5. Hantar permintaan anda kepada API model!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Pasang `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Import perpustakaan pembantu dan wujudkan kelayakan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Mencari model yang sesuai  \n",
    "Model GPT-3.5-turbo atau GPT-4 boleh memahami dan menghasilkan bahasa semula jadi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Reka Bentuk Prompt  \n",
    "\n",
    "\"Keajaiban model bahasa besar ialah dengan dilatih untuk meminimumkan ralat ramalan ini ke atas sejumlah besar teks, model-model ini akhirnya mempelajari konsep-konsep yang berguna untuk ramalan tersebut. Sebagai contoh, mereka mempelajari konsep seperti\"(1):\n",
    "\n",
    "* cara mengeja\n",
    "* cara tatabahasa berfungsi\n",
    "* cara memparafrasa\n",
    "* cara menjawab soalan\n",
    "* cara berkomunikasi\n",
    "* cara menulis dalam pelbagai bahasa\n",
    "* cara menulis kod\n",
    "* dan sebagainya.\n",
    "\n",
    "#### Cara mengawal model bahasa besar  \n",
    "\"Daripada semua input kepada model bahasa besar, yang paling berpengaruh ialah prompt teks(1).\n",
    "\n",
    "Model bahasa besar boleh dipandu untuk menghasilkan output dengan beberapa cara:\n",
    "\n",
    "Arahan: Beritahu model apa yang anda mahu\n",
    "Pelengkap: Galakkan model untuk melengkapkan permulaan apa yang anda mahu\n",
    "Demonstrasi: Tunjukkan kepada model apa yang anda mahu, sama ada dengan:\n",
    "Beberapa contoh dalam prompt\n",
    "Ratusan atau ribuan contoh dalam set data latihan penalaan halus\"\n",
    "\n",
    "\n",
    "\n",
    "#### Terdapat tiga garis panduan asas untuk mencipta prompt:\n",
    "\n",
    "**Tunjuk dan beritahu**. Jelaskan apa yang anda mahu sama ada melalui arahan, contoh, atau gabungan kedua-duanya. Jika anda mahu model menyusun senarai item mengikut abjad atau mengklasifikasikan perenggan mengikut sentimen, tunjukkan bahawa itulah yang anda mahu.\n",
    "\n",
    "**Sediakan data berkualiti**. Jika anda cuba membina pengelas atau mahu model mengikut corak tertentu, pastikan terdapat cukup contoh. Pastikan anda menyemak contoh-contoh anda â€” model biasanya cukup bijak untuk mengesan kesalahan ejaan asas dan tetap memberi respons, tetapi ia juga mungkin menganggap kesilapan itu disengajakan dan ini boleh mempengaruhi respons.\n",
    "\n",
    "**Semak tetapan anda.** Tetapan temperature dan top_p mengawal sejauh mana model itu deterministik dalam menghasilkan respons. Jika anda mahukan respons yang hanya ada satu jawapan betul, anda patut tetapkan nilai ini lebih rendah. Jika anda mahukan respons yang lebih pelbagai, anda boleh tetapkan lebih tinggi. Kesilapan utama yang sering dilakukan orang dengan tetapan ini ialah menganggap ia sebagai kawalan \"kepintaran\" atau \"kreativiti\" model.\n",
    "\n",
    "\n",
    "Sumber: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Ringkaskan Teks  \n",
    "#### Cabaran  \n",
    "Ringkaskan teks dengan menambah 'tl;dr:' di hujung petikan teks. Perhatikan bagaimana model memahami cara melakukan pelbagai tugasan tanpa arahan tambahan. Anda boleh bereksperimen dengan arahan yang lebih terperinci daripada tl;dr untuk mengubah tingkah laku model dan menyesuaikan ringkasan yang anda terima(3).  \n",
    "\n",
    "Kajian terkini menunjukkan peningkatan ketara dalam banyak tugasan dan penanda aras NLP dengan pra-latihan pada korpus teks yang besar diikuti dengan penalaan khusus untuk tugasan tertentu. Walaupun biasanya seni bina ini tidak bergantung pada tugasan, kaedah ini masih memerlukan set data penalaan khusus tugasan yang terdiri daripada ribuan atau puluhan ribu contoh. Sebaliknya, manusia biasanya boleh melakukan tugasan bahasa baru hanya dengan beberapa contoh atau arahan ringkas - sesuatu yang sistem NLP semasa masih sukar untuk lakukan. Di sini kami menunjukkan bahawa meningkatkan skala model bahasa sangat memperbaiki prestasi beberapa contoh yang tidak bergantung pada tugasan, kadang-kadang malah mampu bersaing dengan pendekatan penalaan khusus yang terbaik sebelum ini. \n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Latihan untuk beberapa kes penggunaan  \n",
    "1. Rumuskan Teks  \n",
    "2. Klasifikasikan Teks  \n",
    "3. Jana Nama Produk Baru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klasifikasikan Teks  \n",
    "#### Cabaran  \n",
    "Klasifikasikan item ke dalam kategori yang diberikan semasa inferens. Dalam contoh berikut, kita sediakan kedua-dua kategori dan teks untuk diklasifikasikan dalam prompt (*playground_reference).\n",
    "\n",
    "Pertanyaan Pelanggan: Hai, salah satu kekunci pada papan kekunci komputer riba saya telah rosak baru-baru ini dan saya perlukan pengganti:\n",
    "\n",
    "Kategori yang diklasifikasikan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Jana Nama Produk Baru\n",
    "#### Cabaran\n",
    "Cipta nama produk daripada contoh perkataan. Di sini, kami sertakan maklumat tentang produk yang akan dijana namanya dalam prompt. Kami juga berikan contoh serupa untuk menunjukkan corak yang kami inginkan. Nilai suhu juga ditetapkan tinggi untuk meningkatkan kepelbagaian dan menghasilkan jawapan yang lebih kreatif.\n",
    "\n",
    "Deskripsi produk: Mesin pembuat milkshake di rumah\n",
    "Perkataan asas: pantas, sihat, padat.\n",
    "Nama produk: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Deskripsi produk: Sepasang kasut yang boleh muat untuk semua saiz kaki.\n",
    "Perkataan asas: boleh ubah, muat, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Rujukan  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Contoh OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Amalan terbaik untuk penalaan GPT-3 bagi mengklasifikasikan teks](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Untuk Bantuan Lanjut  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Penyumbang\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan perkhidmatan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Walaupun kami berusaha untuk memastikan ketepatan, sila maklum bahawa terjemahan automatik mungkin mengandungi kesilapan atau ketidaktepatan. Dokumen asal dalam bahasa asalnya harus dianggap sebagai sumber yang sah. Untuk maklumat penting, terjemahan manusia profesional adalah disyorkan. Kami tidak bertanggungjawab atas sebarang salah faham atau salah tafsir yang timbul daripada penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:44:57+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "ms"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}