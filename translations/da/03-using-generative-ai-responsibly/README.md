<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:41:48+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "da"
}
-->
# Brug af Generativ AI Ansvarligt

> _Klik p친 billedet ovenfor for at se videoen af denne lektion_

Det er nemt at blive fascineret af AI og is칝r generativ AI, men du skal overveje, hvordan du bruger det ansvarligt. Du skal t칝nke over, hvordan du sikrer, at outputtet er retf칝rdigt, ikke-skadeligt og mere. Dette kapitel har til form친l at give dig den n칝vnte kontekst, hvad du skal overveje, og hvordan du kan tage aktive skridt til at forbedre din AI-brug.

## Introduktion

Denne lektion vil d칝kke:

- Hvorfor du skal prioritere Ansvarlig AI, n친r du bygger Generative AI-applikationer.
- Kerneprincipper for Ansvarlig AI og hvordan de relaterer sig til Generative AI.
- Hvordan man oms칝tter disse Ansvarlige AI-principper i praksis gennem strategi og v칝rkt칮jer.

## L칝ringsm친l

Efter at have gennemf칮rt denne lektion vil du vide:

- Vigtigheden af Ansvarlig AI, n친r du bygger Generative AI-applikationer.
- Hvorn친r man skal t칝nke og anvende kerneprincipperne for Ansvarlig AI, n친r man bygger Generative AI-applikationer.
- Hvilke v칝rkt칮jer og strategier der er tilg칝ngelige for dig til at oms칝tte konceptet for Ansvarlig AI i praksis.

## Ansvarlige AI-principper

Sp칝ndingen ved Generativ AI har aldrig v칝ret h칮jere. Denne sp칝nding har bragt mange nye udviklere, opm칝rksomhed og finansiering til dette omr친de. Selvom dette er meget positivt for enhver, der 칮nsker at bygge produkter og virksomheder ved hj칝lp af Generativ AI, er det ogs친 vigtigt, at vi forts칝tter ansvarligt.

Gennem dette kursus fokuserer vi p친 at bygge vores startup og vores AI-uddannelsesprodukt. Vi vil bruge principperne for Ansvarlig AI: Retf칝rdighed, Inklusivitet, P친lidelighed/Sikkerhed, Sikkerhed & Privatliv, Gennemsigtighed og Ansvarlighed. Med disse principper vil vi udforske, hvordan de relaterer sig til vores brug af Generativ AI i vores produkter.

## Hvorfor Skal Du Prioritere Ansvarlig AI

N친r du bygger et produkt, f칮rer en menneskecentreret tilgang ved at have din brugers bedste interesse i tankerne til de bedste resultater.

Det unikke ved Generativ AI er dens evne til at skabe nyttige svar, information, vejledning og indhold til brugerne. Dette kan g칮res uden mange manuelle trin, hvilket kan f칮re til meget imponerende resultater. Uden ordentlig planl칝gning og strategier kan det desv칝rre ogs친 f칮re til nogle skadelige resultater for dine brugere, dit produkt og samfundet som helhed.

Lad os se p친 nogle (men ikke alle) af disse potentielt skadelige resultater:

### Hallucinationer

Hallucinationer er et udtryk, der bruges til at beskrive, n친r en LLM producerer indhold, der enten er fuldst칝ndig meningsl칮st eller noget, vi ved er faktuelt forkert baseret p친 andre informationskilder.

Lad os tage et eksempel, hvor vi bygger en funktion til vores startup, der giver elever mulighed for at stille historiske sp칮rgsm친l til en model. En elev stiller sp칮rgsm친let `Who was the sole survivor of Titanic?`

Modellen producerer et svar som det nedenfor:

Dette er et meget selvsikkert og grundigt svar. Desv칝rre er det forkert. Selv med en minimal m칝ngde forskning ville man opdage, at der var mere end 칠n overlevende fra Titanic-katastrofen. For en elev, der lige er begyndt at unders칮ge dette emne, kan dette svar v칝re overbevisende nok til ikke at blive stillet sp칮rgsm친lstegn ved og behandlet som en kendsgerning. Konsekvenserne af dette kan f칮re til, at AI-systemet er up친lideligt og negativt p친virker vores startups omd칮mme.

Med hver iteration af en given LLM har vi set pr칝stationsforbedringer omkring minimering af hallucinationer. Selv med denne forbedring skal vi som applikationsbyggere og brugere stadig v칝re opm칝rksomme p친 disse begr칝nsninger.

### Skadeligt Indhold

Vi d칝kkede i det tidligere afsnit, n친r en LLM producerer forkerte eller meningsl칮se svar. En anden risiko, vi skal v칝re opm칝rksomme p친, er, n친r en model reagerer med skadeligt indhold.

Skadeligt indhold kan defineres som:

- At give instruktioner eller opmuntre til selvskade eller skade p친 bestemte grupper.
- Hadefuldt eller nedg칮rende indhold.
- At vejlede planl칝gning af enhver form for angreb eller voldelige handlinger.
- At give instruktioner om, hvordan man finder ulovligt indhold eller beg친r ulovlige handlinger.
- At vise seksuelt eksplicit indhold.

For vores startup vil vi sikre, at vi har de rigtige v칝rkt칮jer og strategier p친 plads for at forhindre, at denne type indhold bliver set af elever.

### Manglende Retf칝rdighed

Retf칝rdighed defineres som "at sikre, at et AI-system er fri for bias og diskrimination og at de behandler alle retf칝rdigt og lige." I Generativ AI's verden 칮nsker vi at sikre, at ekskluderende verdenssyn af marginaliserede grupper ikke forst칝rkes af modellens output.

Disse typer af output er ikke kun destruktive for at opbygge positive produktopplevelser for vores brugere, men de for친rsager ogs친 yderligere samfundsskade. Som applikationsbyggere b칮r vi altid have en bred og forskelligartet brugerbase i tankerne, n친r vi bygger l칮sninger med Generativ AI.

## Hvordan Man Bruger Generativ AI Ansvarligt

Nu hvor vi har identificeret vigtigheden af Ansvarlig Generativ AI, lad os se p친 4 trin, vi kan tage for at bygge vores AI-l칮sninger ansvarligt:

### M친l Potentielle Skader

I softwaretest tester vi de forventede handlinger fra en bruger p친 en applikation. Tilsvarende er det en god m친de at m친le potentiel skade ved at teste et mangfoldigt s칝t af prompts, som brugerne sandsynligvis vil bruge.

Da vores startup bygger et uddannelsesprodukt, ville det v칝re godt at forberede en liste over uddannelsesrelaterede prompts. Dette kunne v칝re for at d칝kke et bestemt emne, historiske fakta og prompts om studielivet.

### Afb칮d Potentielle Skader

Det er nu tid til at finde m친der, hvor vi kan forhindre eller begr칝nse den potentielle skade for친rsaget af modellen og dens svar. Vi kan se p친 dette i 4 forskellige lag:

- **Model**. V칝lge den rigtige model til den rigtige brugssag. St칮rre og mere komplekse modeller som GPT-4 kan for친rsage mere risiko for skadeligt indhold, n친r de anvendes p친 mindre og mere specifikke brugssager. Brug af dine tr칝ningsdata til at finjustere reducerer ogs친 risikoen for skadeligt indhold.

- **Sikkerhedssystem**. Et sikkerhedssystem er et s칝t v칝rkt칮jer og konfigurationer p친 platformen, der betjener modellen, som hj칝lper med at afb칮de skade. Et eksempel p친 dette er indholdsfiltreringssystemet p친 Azure OpenAI-tjenesten. Systemer b칮r ogs친 opdage jailbreak-angreb og u칮nsket aktivitet som anmodninger fra bots.

- **Metaprompt**. Metaprompts og grounding er m친der, vi kan styre eller begr칝nse modellen baseret p친 visse adf칝rdsm칮nstre og information. Dette kunne v칝re ved at bruge systeminput til at definere visse gr칝nser for modellen. Derudover ved at give output, der er mere relevante for systemets omfang eller dom칝ne.

Det kan ogs친 v칝re ved at bruge teknikker som Retrieval Augmented Generation (RAG) for at f친 modellen til kun at tr칝kke information fra et udvalg af betroede kilder. Der er en lektion senere i dette kursus for [opbygning af s칮geapplikationer](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Brugeroplevelse**. Det sidste lag er, hvor brugeren interagerer direkte med modellen gennem vores applikationsgr칝nseflade p친 en eller anden m친de. P친 denne m친de kan vi designe UI/UX for at begr칝nse brugeren p친 de typer input, de kan sende til modellen, samt tekst eller billeder vist til brugeren. N친r vi implementerer AI-applikationen, skal vi ogs친 v칝re gennemsigtige om, hvad vores Generative AI-applikation kan og ikke kan g칮re.

Vi har en hel lektion dedikeret til [Designing UX for AI Applications](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluer model**. At arbejde med LLM'er kan v칝re udfordrende, fordi vi ikke altid har kontrol over de data, modellen blev tr칝net p친. Uanset hvad, b칮r vi altid evaluere modellens ydeevne og output. Det er stadig vigtigt at m친le modellens n칮jagtighed, lighed, forankring og relevans af output. Dette hj칝lper med at give gennemsigtighed og tillid til interessenter og brugere.

### Drive en Ansvarlig Generativ AI-l칮sning

At bygge en operationel praksis omkring dine AI-applikationer er det sidste trin. Dette inkluderer at samarbejde med andre dele af vores startup som Legal og Security for at sikre, at vi overholder alle lovgivningsm칝ssige politikker. F칮r lancering vil vi ogs친 bygge planer omkring levering, h친ndtering af h칝ndelser og tilbagerulning for at forhindre enhver skade p친 vores brugere fra at vokse.

## V칝rkt칮jer

Mens arbejdet med at udvikle Ansvarlige AI-l칮sninger kan virke som meget, er det arbejde, der er v칝rd at g칮re. Efterh친nden som omr친det for Generativ AI vokser, vil flere v칝rkt칮jer til at hj칝lpe udviklere med effektivt at integrere ansvarlighed i deres arbejdsprocesser modnes. For eksempel kan [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hj칝lpe med at opdage skadeligt indhold og billeder via en API-anmodning.

## Videnscheck

Hvad er nogle ting, du skal tage dig af for at sikre ansvarlig AI-brug?

1. At svaret er korrekt.
1. Skadelig brug, at AI ikke bruges til kriminelle form친l.
1. At sikre, at AI er fri for bias og diskrimination.

A: 2 og 3 er korrekte. Ansvarlig AI hj칝lper dig med at overveje, hvordan du kan afb칮de skadelige effekter og bias og mere.

## 游 Udfordring

L칝s op p친 [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) og se, hvad du kan tage i brug til din brug.

## Godt Arbejde, Forts칝t Din L칝ring

Efter at have gennemf칮rt denne lektion, tjek vores [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at forts칝tte med at forbedre din Generative AI-viden!

G친 videre til Lektion 4, hvor vi vil se p친 [Prompt Engineering Fundamentals](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 n칮jagtighed, bedes du v칝re opm칝rksom p친, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det originale dokument p친 dets oprindelige sprog b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller fejltolkninger, der m친tte opst친 ved brugen af denne overs칝ttelse.