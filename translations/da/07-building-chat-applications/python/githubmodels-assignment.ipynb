{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Kapitel 7: Byg chatapplikationer\n",
    "## Github Models API Kom godt i gang\n",
    "\n",
    "Denne notesbog er tilpasset fra [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), som indeholder notesbøger, der giver adgang til [Azure OpenAI](notebook-azure-openai.ipynb) tjenester.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Oversigt  \n",
    "\"Store sprogmodeller er funktioner, der omsætter tekst til tekst. Givet en inputstreng af tekst forsøger en stor sprogmodel at forudsige, hvilken tekst der kommer bagefter\"(1). Denne \"quickstart\"-notebook vil introducere brugere til overordnede LLM-begreber, centrale pakkekrav for at komme i gang med AML, en blid introduktion til promptdesign og flere korte eksempler på forskellige anvendelsestilfælde.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Indholdsfortegnelse  \n",
    "\n",
    "[Oversigt](../../../../07-building-chat-applications/python)  \n",
    "[Sådan bruger du OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[1. Opret din OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[2. Installation](../../../../07-building-chat-applications/python)    \n",
    "[3. Legitimationer](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Anvendelsesmuligheder](../../../../07-building-chat-applications/python)    \n",
    "[1. Opsummér tekst](../../../../07-building-chat-applications/python)  \n",
    "[2. Klassificér tekst](../../../../07-building-chat-applications/python)  \n",
    "[3. Generér nye produktnavne](../../../../07-building-chat-applications/python)  \n",
    "[4. Finjustér en klassifikator](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Referencer](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Byg din første prompt  \n",
    "Denne korte øvelse giver en grundlæggende introduktion til at indsende prompts til en model i Github Models for en simpel opgave: \"opsummering\".\n",
    "\n",
    "\n",
    "**Trin**:  \n",
    "1. Installer biblioteket `azure-ai-inference` i dit python-miljø, hvis du ikke allerede har gjort det.  \n",
    "2. Indlæs standard hjælpebiblioteker og opsæt Github Models-legitimationsoplysninger.  \n",
    "3. Vælg en model til din opgave  \n",
    "4. Opret en simpel prompt til modellen  \n",
    "5. Send din forespørgsel til model-API'en!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Installer `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Importer hjælperbiblioteker og opret legitimationsoplysninger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Find den rette model  \n",
    "GPT-3.5-turbo eller GPT-4 modellerne kan forstå og generere naturligt sprog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Promptdesign  \n",
    "\n",
    "\"Magien ved store sprogmodeller er, at ved at blive trænet til at minimere denne forudsigelsesfejl på enorme mængder tekst, ender modellerne med at lære begreber, der er nyttige for disse forudsigelser. For eksempel lærer de begreber som\"(1):\n",
    "\n",
    "* hvordan man staver\n",
    "* hvordan grammatik fungerer\n",
    "* hvordan man omformulerer\n",
    "* hvordan man besvarer spørgsmål\n",
    "* hvordan man fører en samtale\n",
    "* hvordan man skriver på mange sprog\n",
    "* hvordan man koder\n",
    "* osv.\n",
    "\n",
    "#### Sådan styrer du en stor sprogmodel  \n",
    "\"Af alle input til en stor sprogmodel er tekstprompten langt den mest indflydelsesrige\"(1).\n",
    "\n",
    "Store sprogmodeller kan promptes til at producere output på flere måder:\n",
    "\n",
    "Instruktion: Fortæl modellen, hvad du vil have\n",
    "Færdiggørelse: Få modellen til at færdiggøre begyndelsen på det, du ønsker\n",
    "Demonstration: Vis modellen, hvad du vil have, enten med:\n",
    "Et par eksempler i prompten\n",
    "Mange hundrede eller tusinder af eksempler i et finjusterings-træningsdatasæt\"\n",
    "\n",
    "\n",
    "\n",
    "#### Der er tre grundlæggende retningslinjer for at lave prompts:\n",
    "\n",
    "**Vis og fortæl**. Gør det tydeligt, hvad du ønsker, enten gennem instruktioner, eksempler eller en kombination af begge. Hvis du vil have modellen til at rangere en liste af elementer i alfabetisk rækkefølge eller til at klassificere et afsnit efter stemning, så vis den, at det er det, du vil have.\n",
    "\n",
    "**Brug kvalitetsdata**. Hvis du prøver at bygge en klassificering eller få modellen til at følge et mønster, så sørg for, at der er nok eksempler. Husk at korrekturlæse dine eksempler — modellen er som regel klog nok til at gennemskue basale stavefejl og give dig et svar, men den kan også antage, at det er med vilje, og det kan påvirke svaret.\n",
    "\n",
    "**Tjek dine indstillinger.** Indstillingerne temperature og top_p styrer, hvor deterministisk modellen er, når den genererer et svar. Hvis du beder om et svar, hvor der kun er ét rigtigt svar, vil du gerne sætte disse lavt. Hvis du ønsker mere varierede svar, kan du sætte dem højere. Den største fejl folk laver med disse indstillinger er at tro, at de styrer \"intelligens\" eller \"kreativitet\".\n",
    "\n",
    "\n",
    "Kilde: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Opsummer tekst  \n",
    "#### Udfordring  \n",
    "Opsummer tekst ved at tilføje et 'tl;dr:' i slutningen af et tekstafsnit. Bemærk, hvordan modellen forstår at udføre en række opgaver uden yderligere instruktioner. Du kan eksperimentere med mere beskrivende prompts end tl;dr for at ændre modellens adfærd og tilpasse den opsummering, du får (3).  \n",
    "\n",
    "Nylig forskning har vist markante fremskridt på mange NLP-opgaver og benchmarks ved at fortræne på et stort tekstkorpus og derefter finjustere på en specifik opgave. Selvom denne metode typisk er opgave-agnostisk i arkitekturen, kræver den stadig opgavespecifikke finjusteringsdatasæt med tusindvis eller titusindvis af eksempler. Til sammenligning kan mennesker generelt udføre en ny sproglig opgave ud fra blot få eksempler eller simple instruktioner – noget nuværende NLP-systemer stadig har svært ved. Her viser vi, at opskalering af sprogmodeller markant forbedrer opgave-agnostisk, få-skuds-præstation, og nogle gange endda når op på niveau med tidligere førende finjusteringsmetoder. \n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Øvelser for forskellige brugsscenarier  \n",
    "1. Opsummér tekst  \n",
    "2. Klassificér tekst  \n",
    "3. Find på nye produktnavne\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klassificér tekst  \n",
    "#### Udfordring  \n",
    "Klassificér elementer i kategorier, der gives ved inferenstidspunktet. I det følgende eksempel giver vi både kategorierne og teksten, der skal klassificeres, i prompten (*playground_reference).\n",
    "\n",
    "Kundehenvendelse: Hej, en af tasterne på mit laptop-tastatur gik i stykker for nylig, og jeg har brug for en erstatning:\n",
    "\n",
    "Klassificeret kategori:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Generér nye produktnavne\n",
    "#### Udfordring\n",
    "Skab produktnavne ud fra eksempler på ord. Her inkluderer vi i prompten information om det produkt, vi skal finde navne til. Vi giver også et lignende eksempel for at vise det mønster, vi ønsker at modtage. Vi har desuden sat temperaturværdien højt for at øge tilfældigheden og få mere innovative svar.\n",
    "\n",
    "Produktbeskrivelse: En milkshake-maskine til hjemmet\n",
    "Stikord: hurtig, sund, kompakt.\n",
    "Produktnavne: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Produktbeskrivelse: Et par sko, der kan passe til enhver fodstørrelse.\n",
    "Stikord: tilpasningsdygtig, pasform, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Referencer  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Eksempler](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Bedste praksis for finjustering af GPT-3 til tekstklassificering](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# For mere hjælp  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bidragydere\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, skal du være opmærksom på, at automatiske oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel, menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå ved brug af denne oversættelse.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:39:42+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}