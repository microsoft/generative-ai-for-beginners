<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T19:11:16+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "da"
}
-->
# Udforskning og sammenligning af forskellige LLM'er

[![Udforskning og sammenligning af forskellige LLM'er](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.da.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Klik p√• billedet ovenfor for at se videoen til denne lektion_

I den forrige lektion har vi set, hvordan Generativ AI √¶ndrer teknologilandskabet, hvordan store sprogmodeller (LLM'er) fungerer, og hvordan en virksomhed - som vores startup - kan anvende dem til deres brugsscenarier og vokse! I dette kapitel vil vi sammenligne og kontrastere forskellige typer af store sprogmodeller (LLM'er) for at forst√• deres fordele og ulemper.

Det n√¶ste skridt i vores startups rejse er at udforske det nuv√¶rende landskab af LLM'er og forst√•, hvilke der er egnede til vores brugsscenarie.

## Introduktion

Denne lektion vil d√¶kke:

- Forskellige typer af LLM'er i det nuv√¶rende landskab.
- Testning, iteration og sammenligning af forskellige modeller til dit brugsscenarie i Azure.
- Hvordan man implementerer en LLM.

## L√¶ringsm√•l

Efter at have gennemf√∏rt denne lektion vil du kunne:

- V√¶lge den rette model til dit brugsscenarie.
- Forst√•, hvordan man tester, itererer og forbedrer modellens ydeevne.
- Vide, hvordan virksomheder implementerer modeller.

## Forst√• forskellige typer af LLM'er

LLM'er kan kategoriseres p√• flere m√•der baseret p√• deres arkitektur, tr√¶ningsdata og brugsscenarier. At forst√• disse forskelle vil hj√¶lpe vores startup med at v√¶lge den rette model til scenariet og forst√•, hvordan man tester, itererer og forbedrer ydeevnen.

Der findes mange forskellige typer af LLM-modeller, og dit valg af model afh√¶nger af, hvad du √∏nsker at bruge dem til, dine data, hvor meget du er villig til at betale og mere.

Afh√¶ngigt af om du √∏nsker at bruge modellerne til tekst, lyd, video, billedgenerering osv., kan du v√¶lge en anden type model.

- **Lyd- og talegenkendelse**. Til dette form√•l er Whisper-typen modeller et godt valg, da de er alsidige og rettet mod talegenkendelse. De er tr√¶net p√• mangfoldig lyd og kan udf√∏re flersproget talegenkendelse. L√¶s mere om [Whisper-typen modeller her](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Billedgenerering**. Til billedgenerering er DALL-E og Midjourney to meget kendte valg. DALL-E tilbydes af Azure OpenAI. [L√¶s mere om DALL-E her](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) og ogs√• i kapitel 9 af dette pensum.

- **Tekstgenerering**. De fleste modeller er tr√¶net til tekstgenerering, og du har et stort udvalg fra GPT-3.5 til GPT-4. De kommer med forskellige omkostninger, hvor GPT-4 er den dyreste. Det er v√¶rd at unders√∏ge [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) for at evaluere, hvilke modeller der bedst passer til dine behov med hensyn til kapacitet og omkostninger.

- **Multimodalitet**. Hvis du √∏nsker at h√•ndtere flere typer data i input og output, kan du overveje modeller som [gpt-4 turbo med vision eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - de nyeste udgivelser af OpenAI-modeller - som er i stand til at kombinere naturlig sprogbehandling med visuel forst√•else, hvilket muligg√∏r interaktioner gennem multimodale gr√¶nseflader.

At v√¶lge en model betyder, at du f√•r nogle grundl√¶ggende kapaciteter, som dog m√•ske ikke er tilstr√¶kkelige. Ofte har du virksomhedsspecifikke data, som du p√• en eller anden m√•de skal informere LLM'en om. Der er flere forskellige m√•der at gribe dette an p√•, mere om det i de kommende afsnit.

### Grundl√¶ggende modeller versus LLM'er

Begrebet Grundl√¶ggende Model blev [skabt af Stanford-forskere](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) og defineret som en AI-model, der opfylder nogle kriterier, s√•som:

- **De er tr√¶net ved hj√¶lp af usuperviseret l√¶ring eller selv-superviseret l√¶ring**, hvilket betyder, at de er tr√¶net p√• ulabelerede multimodale data og ikke kr√¶ver menneskelig annotering eller labeling af data til deres tr√¶ningsproces.
- **De er meget store modeller**, baseret p√• meget dybe neurale netv√¶rk tr√¶net p√• milliarder af parametre.
- **De er normalt beregnet til at fungere som en 'grundl√¶ggelse' for andre modeller**, hvilket betyder, at de kan bruges som udgangspunkt for andre modeller, der kan bygges ovenp√•, hvilket kan g√∏res ved finjustering.

![Grundl√¶ggende modeller versus LLM'er](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.da.png)

Billedkilde: [Essential Guide to Foundation Models and Large Language Models | af Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

For yderligere at afklare denne forskel, lad os tage ChatGPT som et eksempel. For at bygge den f√∏rste version af ChatGPT blev en model kaldet GPT-3.5 brugt som grundl√¶ggende model. Det betyder, at OpenAI brugte nogle chat-specifikke data til at skabe en finjusteret version af GPT-3.5, der var specialiseret i at pr√¶stere godt i samtalescenarier, s√•som chatbots.

![Grundl√¶ggende model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.da.png)

Billedkilde: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source versus Propriet√¶re modeller

En anden m√•de at kategorisere LLM'er p√• er, om de er open source eller propriet√¶re.

Open source-modeller er modeller, der er gjort tilg√¶ngelige for offentligheden og kan bruges af alle. De bliver ofte gjort tilg√¶ngelige af virksomheden, der skabte dem, eller af forskningssamfundet. Disse modeller kan inspiceres, modificeres og tilpasses til forskellige brugsscenarier i LLM'er. Dog er de ikke altid optimeret til produktionsbrug og kan v√¶re mindre effektive end propriet√¶re modeller. Derudover kan finansiering til open source-modeller v√¶re begr√¶nset, og de kan muligvis ikke vedligeholdes p√• lang sigt eller opdateres med den nyeste forskning. Eksempler p√• popul√¶re open source-modeller inkluderer [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) og [LLaMA](https://llama.meta.com).

Propriet√¶re modeller er modeller, der ejes af en virksomhed og ikke er gjort tilg√¶ngelige for offentligheden. Disse modeller er ofte optimeret til produktionsbrug. Dog kan de ikke inspiceres, modificeres eller tilpasses til forskellige brugsscenarier. Derudover er de ikke altid gratis tilg√¶ngelige og kan kr√¶ve et abonnement eller betaling for at bruge. Brugere har heller ikke kontrol over de data, der bruges til at tr√¶ne modellen, hvilket betyder, at de skal stole p√•, at modelens ejer sikrer databeskyttelse og ansvarlig brug af AI. Eksempler p√• popul√¶re propriet√¶re modeller inkluderer [OpenAI-modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) eller [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Billedgenerering versus Tekst- og kodegenerering

LLM'er kan ogs√• kategoriseres efter det output, de genererer.

Embeddings er en r√¶kke modeller, der kan konvertere tekst til en numerisk form, kaldet embedding, som er en numerisk repr√¶sentation af inputteksten. Embeddings g√∏r det lettere for maskiner at forst√• forholdet mellem ord eller s√¶tninger og kan bruges som input af andre modeller, s√•som klassifikationsmodeller eller klyngemodeller, der har bedre ydeevne p√• numeriske data. Embedding-modeller bruges ofte til transfer learning, hvor en model bygges til en surrogatopgave, som der er rigeligt med data til, og derefter genbruges modelv√¶gtene (embeddings) til andre opgaver. Et eksempel p√• denne kategori er [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.da.png)

Billedgenereringsmodeller er modeller, der genererer billeder. Disse modeller bruges ofte til billedredigering, billedsyntese og billedovers√¶ttelse. Billedgenereringsmodeller tr√¶nes ofte p√• store datas√¶t af billeder, s√•som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), og kan bruges til at generere nye billeder eller til at redigere eksisterende billeder med teknikker som inpainting, superopl√∏sning og farvel√¶gning. Eksempler inkluderer [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) og [Stable Diffusion-modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Billedgenerering](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.da.png)

Tekst- og kodegenereringsmodeller er modeller, der genererer tekst eller kode. Disse modeller bruges ofte til tekstopsummering, overs√¶ttelse og besvarelse af sp√∏rgsm√•l. Tekstgenereringsmodeller tr√¶nes ofte p√• store datas√¶t af tekst, s√•som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), og kan bruges til at generere ny tekst eller til at besvare sp√∏rgsm√•l. Kodegenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), tr√¶nes ofte p√• store datas√¶t af kode, s√•som GitHub, og kan bruges til at generere ny kode eller til at rette fejl i eksisterende kode.

![Tekst- og kodegenerering](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.da.png)

### Encoder-Decoder versus Kun Decoder

For at tale om de forskellige typer af LLM-arkitekturer, lad os bruge en analogi.

Forestil dig, at din leder giver dig en opgave med at lave en quiz til eleverne. Du har to kolleger; den ene st√•r for at skabe indholdet, og den anden st√•r for at gennemg√• det.

Indholdsskaberens rolle kan sammenlignes med en model, der kun er en Decoder. De kan se p√• emnet og det, du allerede har skrevet, og derefter skrive et kursus baseret p√• det. De er meget gode til at skrive engagerende og informativt indhold, men de er ikke s√• gode til at forst√• emnet og l√¶ringsm√•lene. Nogle eksempler p√• Decoder-modeller er GPT-familien, s√•som GPT-3.

Anmelderen kan sammenlignes med en model, der kun er en Encoder. De ser p√• det skrevne kursus og svarene, bem√¶rker forholdet mellem dem og forst√•r konteksten, men de er ikke gode til at generere indhold. Et eksempel p√• en Encoder-model ville v√¶re BERT.

Forestil dig, at vi ogs√• kunne have en person, der b√•de kunne skabe og gennemg√• quizzen, dette er en Encoder-Decoder-model. Nogle eksempler ville v√¶re BART og T5.

### Tjeneste versus Model

Lad os nu tale om forskellen mellem en tjeneste og en model. En tjeneste er et produkt, der tilbydes af en Cloud Service Provider og ofte er en kombination af modeller, data og andre komponenter. En model er den centrale komponent i en tjeneste og er ofte en grundl√¶ggende model, s√•som en LLM.

Tjenester er ofte optimeret til produktionsbrug og er ofte lettere at bruge end modeller via en grafisk brugergr√¶nseflade. Dog er tjenester ikke altid gratis tilg√¶ngelige og kan kr√¶ve et abonnement eller betaling for at bruge, i bytte for at udnytte tjenesteudbyderens udstyr og ressourcer, optimere omkostninger og skalere nemt. Et eksempel p√• en tjeneste er [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som tilbyder en pay-as-you-go prisplan, hvilket betyder, at brugere bliver opkr√¶vet proportionalt med, hvor meget de bruger tjenesten. Derudover tilbyder Azure OpenAI Service sikkerhed p√• virksomhedsniveau og en ansvarlig AI-ramme oven p√• modellernes kapaciteter.

Modeller er blot det neurale netv√¶rk med parametre, v√¶gte og andre elementer. Dette giver virksomheder mulighed for at k√∏re lokalt, men kr√¶ver, at de k√∏ber udstyr, opbygger en struktur til skalering og k√∏ber en licens eller bruger en open source-model. En model som LLaMA er tilg√¶ngelig til brug, men kr√¶ver computerkraft for at k√∏re modellen.

## Hvordan man tester og itererer med forskellige modeller for at forst√• ydeevne p√• Azure

N√•r vores team har udforsket det nuv√¶rende LLM-landskab og identificeret nogle gode kandidater til deres scenarier, er det n√¶ste skridt at teste dem p√• deres data og arbejdsbyrde. Dette er en iterativ proces, der udf√∏res gennem eksperimenter og m√•linger.
De fleste af de modeller, vi n√¶vnte i de tidligere afsnit (OpenAI-modeller, open source-modeller som Llama2 og Hugging Face transformers), er tilg√¶ngelige i [Modelkataloget](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) er en cloud-platform designet til udviklere, der √∏nsker at bygge generative AI-applikationer og administrere hele udviklingsprocessen - fra eksperimentering til evaluering - ved at kombinere alle Azure AI-tjenester i √©n samlet hub med en brugervenlig gr√¶nseflade. Modelkataloget i Azure AI Studio giver brugeren mulighed for at:

- Finde den √∏nskede Foundation Model i kataloget - enten propriet√¶r eller open source - ved at filtrere efter opgave, licens eller navn. For at forbedre s√∏gbarheden er modellerne organiseret i samlinger, s√•som Azure OpenAI-samlingen, Hugging Face-samlingen og flere.

![Modelkatalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.da.png)

- Gennemg√• modelkortet, som inkluderer en detaljeret beskrivelse af den tilsigtede anvendelse og tr√¶ningsdata, kodeeksempler og evalueringsresultater fra det interne evalueringsbibliotek.

![Modelkort](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.da.png)

- Sammenligne benchmarks p√• tv√¶rs af modeller og datas√¶t, der er tilg√¶ngelige i branchen, for at vurdere, hvilken der bedst opfylder forretningsscenariet, via [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst)-panelet.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.da.png)

- Finjustere modellen p√• brugerdefinerede tr√¶ningsdata for at forbedre modellens ydeevne i en specifik arbejdsopgave ved at udnytte eksperimenterings- og sporingsfunktionerne i Azure AI Studio.

![Model finjustering](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.da.png)

- Implementere den originale fortr√¶nede model eller den finjusterede version til fjern realtidsinference - administreret beregning - eller serverl√∏s API-endepunkt - [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - for at g√∏re det muligt for applikationer at bruge den.

![Model implementering](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.da.png)

> [!NOTE]
> Ikke alle modeller i kataloget er i √∏jeblikket tilg√¶ngelige for finjustering og/eller pay-as-you-go implementering. Tjek modelkortet for detaljer om modellens kapaciteter og begr√¶nsninger.

## Forbedring af LLM-resultater

Vi har sammen med vores startup-team udforsket forskellige typer LLM'er og en cloud-platform (Azure Machine Learning), der g√∏r det muligt for os at sammenligne forskellige modeller, evaluere dem p√• testdata, forbedre ydeevnen og implementere dem p√• inference-endepunkter.

Men hvorn√•r b√∏r man overveje at finjustere en model frem for at bruge en fortr√¶net? Er der andre metoder til at forbedre modellens ydeevne p√• specifikke arbejdsopgaver?

Der er flere tilgange, en virksomhed kan bruge for at opn√• de √∏nskede resultater fra en LLM. Du kan v√¶lge forskellige typer modeller med forskellige grader af tr√¶ning, n√•r du implementerer en LLM i produktion, med forskellige niveauer af kompleksitet, omkostninger og kvalitet. Her er nogle forskellige tilgange:

- **Prompt engineering med kontekst**. Ideen er at give nok kontekst, n√•r du prompt'er, for at sikre, at du f√•r de svar, du har brug for.

- **Retrieval Augmented Generation, RAG**. Hvis dine data f.eks. findes i en database eller et web-endepunkt, kan du hente relevante data og inkludere dem i brugerens prompt for at sikre, at disse data eller en delm√¶ngde af dem bliver en del af prompten.

- **Finjusteret model**. Her tr√¶ner du modellen yderligere p√• dine egne data, hvilket g√∏r modellen mere pr√¶cis og responsiv i forhold til dine behov, men det kan v√¶re dyrt.

![LLMs implementering](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.da.png)

Billedkilde: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med Kontekst

Fortr√¶nede LLM'er fungerer meget godt p√• generelle naturlige sprogopgaver, selv n√•r de kaldes med en kort prompt, som en s√¶tning der skal fuldf√∏res eller et sp√∏rgsm√•l ‚Äì det s√•kaldte "zero-shot" l√¶ring.

Jo mere brugeren kan rammes√¶tte deres foresp√∏rgsel med en detaljeret anmodning og eksempler ‚Äì konteksten ‚Äì desto mere pr√¶cist og t√¶ttere p√• brugerens forventninger vil svaret v√¶re. I dette tilf√¶lde taler vi om "one-shot" l√¶ring, hvis prompten kun indeholder √©t eksempel, og "few-shot" l√¶ring, hvis den indeholder flere eksempler. Prompt engineering med kontekst er den mest omkostningseffektive tilgang til at komme i gang.

### Retrieval Augmented Generation (RAG)

LLM'er har den begr√¶nsning, at de kun kan bruge de data, der er blevet brugt under deres tr√¶ning, til at generere et svar. Det betyder, at de ikke ved noget om fakta, der er sket efter deres tr√¶ningsproces, og de kan ikke f√• adgang til ikke-offentlige oplysninger (som virksomhedsdata).
Dette kan overvindes gennem RAG, en teknik der udvider prompten med eksterne data i form af dokumentstykker, under hensyntagen til promptens l√¶ngdebegr√¶nsninger. Dette underst√∏ttes af vektordatabasev√¶rkt√∏jer (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), der henter de relevante stykker fra forskellige foruddefinerede datakilder og tilf√∏jer dem til promptens kontekst.

Denne teknik er meget nyttig, n√•r en virksomhed ikke har nok data, tid eller ressourcer til at finjustere en LLM, men stadig √∏nsker at forbedre ydeevnen p√• en specifik arbejdsopgave og reducere risikoen for fejlinformation, dvs. forvr√¶ngning af virkeligheden eller skadeligt indhold.

### Finjusteret model

Finjustering er en proces, der udnytter transfer learning til at 'tilpasse' modellen til en downstream-opgave eller til at l√∏se et specifikt problem. I mods√¶tning til few-shot l√¶ring og RAG resulterer det i en ny model med opdaterede v√¶gte og bias. Det kr√¶ver et s√¶t tr√¶ningseksempler best√•ende af en enkelt input (prompten) og dens tilknyttede output (fuldf√∏relsen).
Dette ville v√¶re den foretrukne tilgang, hvis:

- **Brug af finjusterede modeller**. En virksomhed √∏nsker at bruge finjusterede mindre kapable modeller (som embedding-modeller) frem for h√∏jtydende modeller, hvilket resulterer i en mere omkostningseffektiv og hurtig l√∏sning.

- **Overvejer latenstid**. Latenstid er vigtig for en specifik brugssag, s√• det er ikke muligt at bruge meget lange prompts, eller antallet af eksempler, som modellen skal l√¶re fra, passer ikke med promptens l√¶ngdebegr√¶nsning.

- **Holder sig opdateret**. En virksomhed har mange h√∏j-kvalitets data og sandhedsm√¶rkater samt de ressourcer, der kr√¶ves for at vedligeholde disse data opdateret over tid.

### Tr√¶net model

At tr√¶ne en LLM fra bunden er uden tvivl den mest udfordrende og komplekse tilgang, der kr√¶ver enorme m√¶ngder data, dygtige ressourcer og passende beregningskraft. Denne mulighed b√∏r kun overvejes i et scenarie, hvor en virksomhed har en dom√¶nespecifik brugssag og en stor m√¶ngde dom√¶necentriske data.

## Videnstjek

Hvad kunne v√¶re en god tilgang til at forbedre LLM-fuldf√∏relsesresultater?

1. Prompt engineering med kontekst  
1. RAG  
1. Finjusteret model  

A:3, hvis du har tid og ressourcer samt h√∏j-kvalitets data, er finjustering den bedre mulighed for at holde sig opdateret. Men hvis du √∏nsker at forbedre tingene og mangler tid, er det v√¶rd at overveje RAG f√∏rst.

## üöÄ Udfordring

L√¶s mere om, hvordan du kan [bruge RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) til din virksomhed.

## Godt arbejde, forts√¶t din l√¶ring

Efter at have afsluttet denne lektion, kan du tjekke vores [Generative AI Learning-samling](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at forts√¶tte med at opbygge din viden om Generative AI!

G√• videre til Lektion 3, hvor vi vil se p√•, hvordan man [bygger med Generative AI ansvarligt](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal det bem√¶rkes, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.