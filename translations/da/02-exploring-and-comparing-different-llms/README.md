<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:29:00+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "da"
}
-->
# Udforskning og sammenligning af forskellige LLM'er

[![Udforskning og sammenligning af forskellige LLM'er](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.da.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Klik p√• billedet ovenfor for at se videoen til denne lektion_

I den forrige lektion har vi set, hvordan Generativ AI √¶ndrer teknologilandskabet, hvordan Large Language Models (LLM'er) fungerer, og hvordan en virksomhed ‚Äì som vores startup ‚Äì kan anvende dem til deres brugsscenarier og vokse! I dette kapitel vil vi sammenligne og kontrastere forskellige typer af store sprogmodeller (LLM'er) for at forst√• deres fordele og ulemper.

Det n√¶ste skridt i vores startups rejse er at udforske det nuv√¶rende landskab af LLM'er og forst√•, hvilke der er egnede til vores brugsscenarie.

## Introduktion

Denne lektion vil d√¶kke:

- Forskellige typer af LLM'er i det nuv√¶rende landskab.
- Test, iteration og sammenligning af forskellige modeller til dit brugsscenarie i Azure.
- Hvordan man implementerer en LLM.

## L√¶ringsm√•l

Efter at have gennemf√∏rt denne lektion vil du kunne:

- V√¶lge den rigtige model til dit brugsscenarie.
- Forst√•, hvordan du tester, itererer og forbedrer din models ydeevne.
- Vide, hvordan virksomheder implementerer modeller.

## Forst√• forskellige typer af LLM'er

LLM'er kan kategoriseres p√• flere m√•der baseret p√• deres arkitektur, tr√¶ningsdata og brugsscenarie. At forst√• disse forskelle vil hj√¶lpe vores startup med at v√¶lge den rette model til situationen og forst√•, hvordan man tester, itererer og forbedrer ydeevnen.

Der findes mange forskellige typer af LLM-modeller, og dit valg afh√¶nger af, hvad du √∏nsker at bruge dem til, dine data, hvor meget du er villig til at betale og mere.

Afh√¶ngigt af om du vil bruge modellerne til tekst, lyd, video, billedgenerering osv., kan du v√¶lge en anden type model.

- **Lyd- og talegenkendelse**. Til dette form√•l er Whisper-typer modeller et godt valg, da de er alsidige og rettet mod talegenkendelse. De er tr√¶net p√• forskelligartet lyd og kan udf√∏re flersproget talegenkendelse. L√¶s mere om [Whisper-typer modeller her](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Billedgenerering**. Til billedgenerering er DALL-E og Midjourney to meget kendte valg. DALL-E tilbydes af Azure OpenAI. [L√¶s mere om DALL-E her](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) og ogs√• i kapitel 9 i dette pensum.

- **Tekstgenerering**. De fleste modeller er tr√¶net til tekstgenerering, og du har et stort udvalg fra GPT-3.5 til GPT-4. De har forskellige omkostninger, hvor GPT-4 er den dyreste. Det er v√¶rd at kigge p√• [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) for at vurdere, hvilke modeller der bedst passer til dine behov med hensyn til kapabilitet og pris.

- **Multi-modalitet**. Hvis du √∏nsker at h√•ndtere flere typer data i input og output, kan du overveje modeller som [gpt-4 turbo med vision eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ‚Äì de nyeste OpenAI-modeller ‚Äì som kan kombinere naturlig sprogbehandling med visuel forst√•else og muligg√∏r interaktioner gennem multimodale gr√¶nseflader.

At v√¶lge en model betyder, at du f√•r nogle grundl√¶ggende funktioner, som dog ikke altid er tilstr√¶kkelige. Ofte har man virksomheds-specifikke data, som man p√• en eller anden m√•de skal fort√¶lle LLM‚Äôen om. Der findes flere forskellige tilgange til dette, som vi vil komme n√¶rmere ind p√• i de kommende afsnit.

### Foundation Models versus LLM'er

Begrebet Foundation Model blev [introduceret af forskere fra Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) og defineres som en AI-model, der opfylder visse kriterier, s√•som:

- **De er tr√¶net ved hj√¶lp af unsupervised learning eller self-supervised learning**, hvilket betyder, at de er tr√¶net p√• ikke-m√¶rkede multimodale data og ikke kr√¶ver menneskelig annotering eller m√¶rkning af data til tr√¶ningsprocessen.
- **De er meget store modeller**, baseret p√• dybe neurale netv√¶rk tr√¶net p√• milliarder af parametre.
- **De er normalt designet til at fungere som en ‚Äòfoundation‚Äô for andre modeller**, hvilket betyder, at de kan bruges som udgangspunkt for at bygge andre modeller ovenp√•, hvilket kan g√∏res ved finjustering.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.da.png)

Billedkilde: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

For at tydeligg√∏re denne forskel, lad os tage ChatGPT som eksempel. Til at bygge den f√∏rste version af ChatGPT blev en model kaldet GPT-3.5 brugt som foundation model. Det betyder, at OpenAI brugte noget chat-specifikt data til at skabe en finjusteret version af GPT-3.5, der var specialiseret i at klare sig godt i samtalescenarier, som f.eks. chatbots.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.da.png)

Billedkilde: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source versus Propriet√¶re modeller

En anden m√•de at kategorisere LLM'er p√• er, om de er open source eller propriet√¶re.

Open source-modeller er modeller, der er gjort tilg√¶ngelige for offentligheden og kan bruges af alle. De stilles ofte til r√•dighed af virksomheden, der har skabt dem, eller af forskningsf√¶llesskabet. Disse modeller m√• inspiceres, modificeres og tilpasses til forskellige brugsscenarier inden for LLM‚Äôer. Dog er de ikke altid optimeret til produktionsbrug og kan mangle ydeevne sammenlignet med propriet√¶re modeller. Finansiering til open source-modeller kan v√¶re begr√¶nset, og de vedligeholdes m√•ske ikke p√• lang sigt eller opdateres ikke med den nyeste forskning. Eksempler p√• popul√¶re open source-modeller inkluderer [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) og [LLaMA](https://llama.meta.com).

Propriet√¶re modeller ejes af en virksomhed og er ikke tilg√¶ngelige for offentligheden. Disse modeller er ofte optimeret til produktionsbrug. De m√• ikke inspiceres, modificeres eller tilpasses til forskellige brugsscenarier. De er heller ikke altid gratis og kan kr√¶ve abonnement eller betaling for brug. Brugere har ikke kontrol over de data, der bruges til at tr√¶ne modellen, hvilket betyder, at de skal have tillid til model-ejeren for at sikre databeskyttelse og ansvarlig AI-anvendelse. Eksempler p√• popul√¶re propriet√¶re modeller inkluderer [OpenAI modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) og [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus billedgenerering versus tekst- og kodegenerering

LLM'er kan ogs√• kategoriseres efter den type output, de genererer.

Embeddings er en type modeller, der kan omdanne tekst til en numerisk form, kaldet embedding, som er en numerisk repr√¶sentation af input-teksten. Embeddings g√∏r det lettere for maskiner at forst√• relationerne mellem ord eller s√¶tninger og kan bruges som input til andre modeller, s√•som klassifikationsmodeller eller klyngeanalyser, der har bedre ydeevne p√• numeriske data. Embedding-modeller bruges ofte til transfer learning, hvor en model bygges til en surrogatopgave med rigeligt data, og derefter genbruges modelv√¶gt (embeddings) til andre opgaver. Et eksempel p√• denne kategori er [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.da.png)

Billedgenereringsmodeller er modeller, der genererer billeder. Disse modeller bruges ofte til billedredigering, billedsyntese og billedovers√¶ttelse. De tr√¶nes ofte p√• store billeddatas√¶t, s√•som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), og kan bruges til at generere nye billeder eller redigere eksisterende billeder med teknikker som inpainting, superopl√∏sning og farvel√¶gning. Eksempler inkluderer [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) og [Stable Diffusion modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Billedgenerering](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.da.png)

Tekst- og kodegenereringsmodeller er modeller, der genererer tekst eller kode. De bruges ofte til tekstopsummering, overs√¶ttelse og besvarelse af sp√∏rgsm√•l. Tekstgenereringsmodeller tr√¶nes ofte p√• store tekstdatas√¶t, s√•som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), og kan bruges til at generere ny tekst eller besvare sp√∏rgsm√•l. Kodegenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), tr√¶nes ofte p√• store kodem√¶ngder, s√•som GitHub, og kan bruges til at generere ny kode eller rette fejl i eksisterende kode.

![Tekst- og kodegenerering](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.da.png)

### Encoder-Decoder versus Decoder-only

For at forklare de forskellige typer arkitekturer i LLM'er, lad os bruge en analogi.

Forestil dig, at din leder har givet dig opgaven at skrive en quiz til eleverne. Du har to kolleger; den ene st√•r for at skabe indholdet, og den anden st√•r for at gennemg√• det.

Indholdsskaberen er som en Decoder-only model, de kan se p√• emnet og det, du allerede har skrevet, og s√• skrive et kursus baseret p√• det. De er gode til at skrive engagerende og informativt indhold, men er ikke s√• gode til at forst√• emnet og l√¶ringsm√•lene. Nogle eksempler p√• Decoder-modeller er GPT-familien, s√•som GPT-3.

Gennemg√•eren er som en Encoder-only model, de ser p√• det skrevne kursus og svarene, bem√¶rker relationerne mellem dem og forst√•r konteksten, men er ikke gode til at generere indhold. Et eksempel p√• en Encoder-only model er BERT.

Forestil dig, at vi ogs√• kan have en, der b√•de kan skabe og gennemg√• quizzen ‚Äì det er en Encoder-Decoder model. Eksempler p√• s√•danne modeller er BART og T5.

### Service versus Model

Lad os nu tale om forskellen mellem en service og en model. En service er et produkt, der tilbydes af en Cloud Service Provider, og er ofte en kombination af modeller, data og andre komponenter. En model er den centrale komponent i en service og er ofte en foundation model, s√•som en LLM.

Services er ofte optimeret til produktionsbrug og er ofte nemmere at bruge end modeller via en grafisk brugerflade. Services er dog ikke altid gratis og kan kr√¶ve abonnement eller betaling for brug, til geng√¶ld for at udnytte serviceudbyderens udstyr og ressourcer, optimere omkostninger og let skalere. Et eksempel p√• en service er [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som tilbyder en pay-as-you-go prisplan, hvor brugere betaler proportionalt med deres forbrug. Azure OpenAI Service tilbyder ogs√• sikkerhed p√• virksomhedsniveau og en ansvarlig AI-ramme oven p√• modellernes kapabiliteter.

Modeller er blot det neurale netv√¶rk med parametre, v√¶gte og andet. Virksomheder kan k√∏re dem lokalt, men skal s√• k√∏be udstyr, bygge en struktur til skalering og k√∏be en licens eller bruge en open source-model. En model som LLaMA er tilg√¶ngelig til brug, men kr√¶ver regnekraft for at k√∏re.

## Hvordan man tester og itererer med forskellige modeller for at forst√• ydeevne i Azure

N√•r vores team har udforsket det nuv√¶rende LLM-landskab og identificeret nogle gode kandidater til deres scenarier, er n√¶ste skridt at teste dem p√• deres data og arbejdsbelastning. Dette er en iterativ proces, der foreg√•r gennem eksperimenter og m√•linger.
De fleste af de modeller, vi n√¶vnte i de foreg√•ende afsnit (OpenAI-modeller, open source-modeller som Llama2 og Hugging Face-transformers), er tilg√¶ngelige i [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) er en cloudplatform designet til udviklere, der vil bygge generative AI-applikationer og styre hele udviklingslivscyklussen ‚Äì fra eksperimentering til evaluering ‚Äì ved at samle alle Azure AI-tjenester i et enkelt hub med en brugervenlig GUI. Model Catalog i Azure AI Studio giver brugeren mulighed for at:

- Finde det Foundation Model, man er interesseret i, i kataloget ‚Äì enten propriet√¶rt eller open source, med filtrering efter opgave, licens eller navn. For at g√∏re s√∏gningen lettere er modellerne organiseret i samlinger, som Azure OpenAI-samlingen, Hugging Face-samlingen og flere.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.da.png)

- Gennemg√• modelkortet, som indeholder en detaljeret beskrivelse af tilt√¶nkt brug og tr√¶ningsdata, kodeeksempler og evalueringsresultater fra det interne evalueringsbibliotek.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.da.png)

- Sammenligne benchmarks p√• tv√¶rs af modeller og datas√¶t tilg√¶ngelige i branchen for at vurdere, hvilken der passer til forretningsscenariet, via [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst)-panelet.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.da.png)

- Finjustere modellen p√• egne tr√¶ningsdata for at forbedre modellens ydeevne i en specifik arbejdsbyrde ved at udnytte eksperimenterings- og sporingsfunktionerne i Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.da.png)

- Udrulle den oprindelige fortr√¶nede model eller den finjusterede version til en fjern realtidsinference ‚Äì managed compute ‚Äì eller serverl√∏s API-endpoint ‚Äì [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) ‚Äì for at g√∏re det muligt for applikationer at bruge den.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.da.png)


> [!NOTE]
> Ikke alle modeller i kataloget er i √∏jeblikket tilg√¶ngelige for finjustering og/eller pay-as-you-go-udrulning. Tjek modelkortet for detaljer om modellens kapaciteter og begr√¶nsninger.

## Forbedring af LLM-resultater

Vi har sammen med vores startup-team unders√∏gt forskellige typer LLM‚Äôer og en cloudplatform (Azure Machine Learning), som g√∏r det muligt for os at sammenligne forskellige modeller, evaluere dem p√• testdata, forbedre ydeevnen og udrulle dem p√• inference-endpoints.

Men hvorn√•r b√∏r man overveje at finjustere en model frem for at bruge en fortr√¶net? Findes der andre metoder til at forbedre modellens ydeevne p√• specifikke arbejdsopgaver?

Der er flere tilgange, en virksomhed kan bruge for at opn√• de √∏nskede resultater med en LLM. Man kan v√¶lge forskellige typer modeller med varierende grader af tr√¶ning, n√•r man udruller en LLM i produktion, med forskellige niveauer af kompleksitet, omkostninger og kvalitet. Her er nogle forskellige tilgange:

- **Prompt engineering med kontekst**. Ideen er at give nok kontekst i prompten for at sikre, at man f√•r de svar, man har brug for.

- **Retrieval Augmented Generation, RAG**. Dine data kan for eksempel findes i en database eller et web-endpoint. For at sikre, at disse data eller et udsnit af dem inkluderes ved prompten, kan du hente de relevante data og g√∏re dem til en del af brugerens prompt.

- **Finjusteret model**. Her tr√¶ner du modellen yderligere p√• dine egne data, hvilket g√∏r modellen mere pr√¶cis og lydh√∏r over for dine behov, men det kan v√¶re omkostningstungt.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.da.png)

Billedkilde: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med Kontekst

Fortr√¶nede LLM‚Äôer fungerer rigtig godt p√• generelle opgaver inden for naturligt sprog, selv ved at kalde dem med en kort prompt, som en s√¶tning der skal fuldf√∏res eller et sp√∏rgsm√•l ‚Äì det s√•kaldte ‚Äúzero-shot‚Äù l√¶ring.

Men jo mere brugeren kan indramme sin foresp√∏rgsel med en detaljeret anmodning og eksempler ‚Äì alts√• konteksten ‚Äì desto mere pr√¶cis og t√¶t p√• brugerens forventninger bliver svaret. Her taler vi om ‚Äúone-shot‚Äù l√¶ring, hvis prompten kun indeholder √©t eksempel, og ‚Äúfew-shot‚Äù l√¶ring, hvis den indeholder flere eksempler. Prompt engineering med kontekst er den mest omkostningseffektive m√•de at komme i gang p√•.

### Retrieval Augmented Generation (RAG)

LLM‚Äôer har den begr√¶nsning, at de kun kan bruge de data, der er blevet brugt under deres tr√¶ning, til at generere et svar. Det betyder, at de ikke kender til begivenheder, der er sket efter tr√¶ningsprocessen, og de kan ikke tilg√• ikke-offentlig information (som virksomhedsdata).  
Dette kan overvindes med RAG, en teknik der udvider prompten med eksterne data i form af dokumentstykker, under hensyntagen til promptens l√¶ngdebegr√¶nsninger. Dette underst√∏ttes af vektordatabaser (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), der henter de relevante stykker fra forskellige foruddefinerede datakilder og tilf√∏jer dem til promptens kontekst.

Denne teknik er meget nyttig, n√•r en virksomhed ikke har nok data, tid eller ressourcer til at finjustere en LLM, men stadig √∏nsker at forbedre ydeevnen p√• en specifik arbejdsopgave og mindske risikoen for fejlinformation, alts√• forvr√¶ngning af virkeligheden eller skadeligt indhold.

### Finjusteret model

Finjustering er en proces, der udnytter transfer learning til at ‚Äòtilpasse‚Äô modellen til en specifik opgave eller problemstilling. I mods√¶tning til few-shot l√¶ring og RAG resulterer det i, at der genereres en ny model med opdaterede v√¶gte og bias. Det kr√¶ver et s√¶t tr√¶ningseksempler best√•ende af en enkelt input (prompten) og det tilh√∏rende output (fuldf√∏relsen).  
Dette vil v√¶re den foretrukne tilgang, hvis:

- **Brug af finjusterede modeller**. En virksomhed √∏nsker at bruge finjusterede, mindre kapable modeller (som embedding-modeller) frem for h√∏jtydende modeller, hvilket giver en mere omkostningseffektiv og hurtig l√∏sning.

- **Overvejelse af latenstid**. Latenstid er vigtig for en bestemt brugssag, s√• det er ikke muligt at bruge meget lange prompts, eller antallet af eksempler, som modellen skal l√¶re fra, passer ikke med promptens l√¶ngdebegr√¶nsning.

- **At holde sig opdateret**. En virksomhed har mange h√∏j-kvalitetsdata og ground truth-labels samt de n√∏dvendige ressourcer til at holde disse data opdaterede over tid.

### Tr√¶net model

At tr√¶ne en LLM fra bunden er uden tvivl den mest vanskelige og komplekse tilgang at v√¶lge, da det kr√¶ver enorme m√¶ngder data, dygtige ressourcer og passende regnekraft. Denne mulighed b√∏r kun overvejes i scenarier, hvor en virksomhed har en dom√¶nespecifik brugssag og en stor m√¶ngde dom√¶necentrerede data.

## Videnstjek

Hvad kunne v√¶re en god tilgang til at forbedre LLM-fuldf√∏relsesresultater?

1. Prompt engineering med kontekst  
1. RAG  
1. Finjusteret model

A:3, hvis du har tid, ressourcer og h√∏j-kvalitetsdata, er finjustering den bedste mulighed for at holde sig opdateret. Men hvis du √∏nsker at forbedre tingene og mangler tid, er det v√¶rd at overveje RAG f√∏rst.

## üöÄ Udfordring

L√¶s mere om, hvordan du kan [bruge RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) i din virksomhed.

## Godt arbejde, forts√¶t din l√¶ring

Efter at have gennemf√∏rt denne lektion, kan du tjekke vores [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at forts√¶tte med at styrke din viden om Generative AI!

G√• videre til Lektion 3, hvor vi ser p√•, hvordan man [bygger med Generative AI ansvarligt](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.