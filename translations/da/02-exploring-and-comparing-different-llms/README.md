<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:05:40+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "da"
}
-->
# Udforskning og sammenligning af forskellige LLM'er

> _Klik p√• billedet ovenfor for at se videoen af denne lektion_

I den forrige lektion har vi set, hvordan Generativ AI √¶ndrer teknologiens landskab, hvordan Store Sproglige Modeller (LLM'er) fungerer, og hvordan en virksomhed - som vores startup - kan anvende dem til deres brugsscenarier og vokse! I dette kapitel vil vi sammenligne og kontrastere forskellige typer af store sproglige modeller (LLM'er) for at forst√• deres fordele og ulemper.

Det n√¶ste skridt i vores startup's rejse er at udforske det nuv√¶rende landskab af LLM'er og forst√•, hvilke der er egnede til vores brugsscenarie.

## Introduktion

Denne lektion vil d√¶kke:

- Forskellige typer af LLM'er i det nuv√¶rende landskab.
- Test, iterering og sammenligning af forskellige modeller til dit brugsscenarie i Azure.
- Hvordan man implementerer en LLM.

## L√¶ringsm√•l

Efter at have gennemf√∏rt denne lektion vil du kunne:

- V√¶lge den rigtige model til dit brugsscenarie.
- Forst√•, hvordan man tester, itererer og forbedrer modellens ydeevne.
- Vide, hvordan virksomheder implementerer modeller.

## Forst√• forskellige typer af LLM'er

LLM'er kan have flere kategoriseringer baseret p√• deres arkitektur, tr√¶ningsdata og brugsscenarie. At forst√• disse forskelle vil hj√¶lpe vores startup med at v√¶lge den rigtige model til scenariet og forst√•, hvordan man tester, itererer og forbedrer ydeevnen.

Der er mange forskellige typer af LLM-modeller, dit valg af model afh√¶nger af, hvad du sigter mod at bruge dem til, dine data, hvor meget du er villig til at betale og mere.

Afh√¶ngigt af om du sigter mod at bruge modellerne til tekst, lyd, video, billedgenerering osv., kan du v√¶lge en anden type model.

- **Lyd- og talegenkendelse**. Til dette form√•l er Whisper-type modeller et godt valg, da de er alsidige og rettet mod talegenkendelse. De er tr√¶net p√• diverse lyd og kan udf√∏re flersproget talegenkendelse. L√¶s mere om [Whisper type modeller her](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Billedgenerering**. Til billedgenerering er DALL-E og Midjourney to meget kendte valg. DALL-E tilbydes af Azure OpenAI. [L√¶s mere om DALL-E her](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) og ogs√• i kapitel 9 af denne l√¶seplan.

- **Tekstgenerering**. De fleste modeller er tr√¶net til tekstgenerering, og du har et stort udvalg fra GPT-3.5 til GPT-4. De kommer til forskellige priser, hvor GPT-4 er den dyreste. Det er v√¶rd at unders√∏ge [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) for at evaluere, hvilke modeller der bedst passer til dine behov i forhold til kapacitet og omkostninger.

- **Multi-modalitet**. Hvis du √∏nsker at h√•ndtere flere typer data i input og output, kan du overveje modeller som [gpt-4 turbo med vision eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - de nyeste udgivelser af OpenAI modeller - som er i stand til at kombinere naturlig sprogbehandling med visuel forst√•else, hvilket muligg√∏r interaktioner gennem multi-modale gr√¶nseflader.

Valg af en model betyder, at du f√•r nogle grundl√¶ggende kapaciteter, som dog m√•ske ikke er tilstr√¶kkelige. Ofte har du virksomhedsspecifikke data, som du p√• en eller anden m√•de skal fort√¶lle LLM'en om. Der er et par forskellige valg om, hvordan man n√¶rmer sig det, mere om det i de kommende afsnit.

### Foundation Models versus LLM'er

Begrebet Foundation Model blev [skabt af Stanford forskere](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) og defineret som en AI-model, der f√∏lger nogle kriterier, s√•som:

- **De er tr√¶net ved hj√¶lp af usuperviseret l√¶ring eller selv-superviseret l√¶ring**, hvilket betyder, at de er tr√¶net p√• ulabeleret multi-modal data, og de kr√¶ver ikke menneskelig annotering eller labeling af data til deres tr√¶ningsproces.
- **De er meget store modeller**, baseret p√• meget dybe neurale netv√¶rk tr√¶net p√• milliarder af parametre.
- **De er normalt beregnet til at tjene som en 'foundation' for andre modeller**, hvilket betyder, at de kan bruges som udgangspunkt for andre modeller, der skal bygges ovenp√•, hvilket kan g√∏res ved finjustering.

For yderligere at klarl√¶gge denne forskel, lad os tage ChatGPT som et eksempel. For at bygge den f√∏rste version af ChatGPT, blev en model kaldet GPT-3.5 brugt som foundation model. Dette betyder, at OpenAI brugte nogle chat-specifikke data til at skabe en finjusteret version af GPT-3.5, der var specialiseret i at pr√¶stere godt i samtalescenarier, s√•som chatbots.

### Open Source versus Propriet√¶re Modeller

En anden m√•de at kategorisere LLM'er p√• er, om de er open source eller propriet√¶re.

Open source modeller er modeller, der g√∏res tilg√¶ngelige for offentligheden og kan bruges af alle. De g√∏res ofte tilg√¶ngelige af den virksomhed, der skabte dem, eller af forskningsf√¶llesskabet. Disse modeller kan inspiceres, √¶ndres og tilpasses til de forskellige brugsscenarier i LLM'er. De er dog ikke altid optimeret til produktionsbrug og kan muligvis ikke pr√¶stere lige s√• godt som propriet√¶re modeller. Plus, finansiering til open source modeller kan v√¶re begr√¶nset, og de vedligeholdes muligvis ikke p√• lang sigt eller opdateres med den nyeste forskning. Eksempler p√• popul√¶re open source modeller inkluderer [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) og [LLaMA](https://llama.meta.com).

Propriet√¶re modeller er modeller, der ejes af en virksomhed og ikke g√∏res tilg√¶ngelige for offentligheden. Disse modeller er ofte optimeret til produktionsbrug. De er dog ikke tilladt at blive inspiceret, √¶ndret eller tilpasset til forskellige brugsscenarier. Plus, de er ikke altid tilg√¶ngelige gratis og kan kr√¶ve abonnement eller betaling for at bruge. Brugerne har heller ikke kontrol over de data, der bruges til at tr√¶ne modellen, hvilket betyder, at de skal stole p√•, at modelens ejer sikrer forpligtelse til databeskyttelse og ansvarlig brug af AI. Eksempler p√• popul√¶re propriet√¶re modeller inkluderer [OpenAI modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) eller [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Billedgenerering versus Tekst- og kodegenerering

LLM'er kan ogs√• kategoriseres efter det output, de genererer.

Embeddings er et s√¶t modeller, der kan konvertere tekst til en numerisk form, kaldet embedding, som er en numerisk repr√¶sentation af inputteksten. Embeddings g√∏r det lettere for maskiner at forst√• forholdet mellem ord eller s√¶tninger og kan bruges som input af andre modeller, s√•som klassifikationsmodeller eller klynge-modeller, der har bedre ydeevne p√• numeriske data. Embedding modeller bruges ofte til transfer learning, hvor en model bygges til en surrogatopgave, for hvilken der er en overflod af data, og derefter genbruges modelv√¶gt (embeddings) til andre nedstr√∏ms opgaver. Et eksempel p√• denne kategori er [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

Billedgenereringsmodeller er modeller, der genererer billeder. Disse modeller bruges ofte til billedredigering, billedsyntese og billedovers√¶ttelse. Billedgenereringsmodeller er ofte tr√¶net p√• store datas√¶t af billeder, s√•som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), og kan bruges til at generere nye billeder eller til at redigere eksisterende billeder med inpainting, superopl√∏sning og farvningsteknikker. Eksempler inkluderer [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) og [Stable Diffusion modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

Tekst- og kodegenereringsmodeller er modeller, der genererer tekst eller kode. Disse modeller bruges ofte til tekstopsummering, overs√¶ttelse og sp√∏rgsm√•l-svar. Tekstgenereringsmodeller er ofte tr√¶net p√• store datas√¶t af tekst, s√•som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), og kan bruges til at generere ny tekst eller til at besvare sp√∏rgsm√•l. Kodegenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), er ofte tr√¶net p√• store datas√¶t af kode, s√•som GitHub, og kan bruges til at generere ny kode eller til at rette fejl i eksisterende kode.

### Encoder-Decoder versus Kun-Decoder

For at tale om de forskellige typer af arkitekturer af LLM'er, lad os bruge en analogi.

Forestil dig, at din chef gav dig en opgave med at skrive en quiz til eleverne. Du har to kolleger; den ene har ansvaret for at skabe indholdet, og den anden har ansvaret for at gennemg√• dem.

Indholdsskaberen er som en Kun-Decoder model, de kan se p√• emnet og se, hvad du allerede har skrevet, og derefter kan han skrive et kursus baseret p√• det. De er meget gode til at skrive engagerende og informative indhold, men de er ikke meget gode til at forst√• emnet og l√¶ringsm√•lene. Nogle eksempler p√• Decoder modeller er GPT-familie modeller, s√•som GPT-3.

Gennemgiveren er som en Kun-Encoder model, de ser p√• det skrevne kursus og svarene, bem√¶rker forholdet mellem dem og forst√•r konteksten, men de er ikke gode til at generere indhold. Et eksempel p√• Kun-Encoder model ville v√¶re BERT.

Forestil dig, at vi ogs√• kunne have nogen, der b√•de kunne skabe og gennemg√• quizzen, dette er en Encoder-Decoder model. Nogle eksempler ville v√¶re BART og T5.

### Service versus Model

Lad os nu tale om forskellen mellem en service og en model. En service er et produkt, der tilbydes af en Cloud Service Provider, og er ofte en kombination af modeller, data og andre komponenter. En model er den centrale komponent i en service og er ofte en foundation model, s√•som en LLM.

Services er ofte optimeret til produktionsbrug og er ofte lettere at bruge end modeller, via en grafisk brugergr√¶nseflade. Dog er services ikke altid tilg√¶ngelige gratis og kan kr√¶ve abonnement eller betaling for at bruge, i bytte for at udnytte serviceejerens udstyr og ressourcer, optimere udgifter og skalere nemt. Et eksempel p√• en service er [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som tilbyder en pay-as-you-go rate plan, hvilket betyder, at brugere bliver opkr√¶vet proportionalt med, hvor meget de bruger servicen. Desuden tilbyder Azure OpenAI Service sikkerhed i virksomhedsklasse og en ansvarlig AI-ramme ovenp√• modellernes kapaciteter.

Modeller er bare Neurale Netv√¶rk, med parametrene, v√¶gtene og andre. Dette tillader virksomheder at k√∏re lokalt, men kr√¶ver, at de k√∏ber udstyr, bygger en struktur til skalering og k√∏ber en licens eller bruger en open source model. En model som LLaMA er tilg√¶ngelig til brug, hvilket kr√¶ver computerkraft til at k√∏re modellen.

## Hvordan man tester og itererer med forskellige modeller for at forst√• ydeevne p√• Azure

N√•r vores team har udforsket det nuv√¶rende LLM-landskab og identificeret nogle gode kandidater til deres scenarier, er det n√¶ste skridt at teste dem p√• deres data og deres arbejdsbyrde. Dette er en iterativ proces, udf√∏rt ved eksperimenter og m√•linger.
De fleste af de modeller, vi n√¶vnte i tidligere afsnit (OpenAI modeller, open source modeller som Llama2 og Hugging Face transformers) er tilg√¶ngelige i [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) er en Cloud Platform designet til udviklere til at bygge generative AI-applikationer og administrere hele udviklingslivscyklussen - fra eksperimentering til evaluering - ved at kombinere alle Azure AI-tjenester i et enkelt hub med en praktisk GUI. Modelkataloget i Azure AI Studio g√∏r det muligt for brugeren at:

- Finde Foundation Modellen af interesse i kataloget - enten propriet√¶r eller open source, filtrering efter opgave, licens eller navn. For at forbedre s√∏gbarheden er modellerne organiseret i samlinger, s√•som Azure OpenAI samling, Hugging Face samling og mere.

- Gennemg√• modelkortet, inklusive en detaljeret beskrivelse af det tilsigtede brug og tr√¶ningsdata, kodeeksempler og evalueringsresultater i det interne evalueringsbibliotek.
- Sammenlign benchmarks p√• tv√¶rs af modeller og datas√¶t tilg√¶ngelige i branchen for at vurdere, hvilken der opfylder forretningsscenariet, gennem [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panelet.

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.da.png)

- Finjuster modellen p√• brugerdefinerede tr√¶ningsdata for at forbedre modellens ydeevne i en specifik arbejdsbyrde, ved at udnytte eksperimenterings- og sporingsfunktionerne i Azure AI Studio.

![Model finjustering](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.da.png)

- Udrul den originale fortr√¶nede model eller den finjusterede version til en fjern realtids inferens - administreret beregning - eller serverl√∏s api-endpoint - [betal-efter-forbrug](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - for at g√∏re det muligt for applikationer at anvende den.

![Model udrulning](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.da.png)

> [!NOTE]
> Ikke alle modeller i kataloget er i √∏jeblikket tilg√¶ngelige for finjustering og/eller betal-efter-forbrug udrulning. Tjek modelkortet for detaljer om modellens kapaciteter og begr√¶nsninger.

## Forbedring af LLM resultater

Vi har udforsket med vores startup-team forskellige slags LLM'er og en Cloud Platform (Azure Machine Learning), der giver os mulighed for at sammenligne forskellige modeller, evaluere dem p√• testdata, forbedre ydeevnen og udrulle dem p√• inferensendepunkter.

Men hvorn√•r skal de overveje at finjustere en model i stedet for at bruge en fortr√¶net? Er der andre tilgange til at forbedre modellens ydeevne p√• specifikke arbejdsbyrder?

Der er flere tilgange en virksomhed kan bruge til at opn√• de resultater, de har brug for fra en LLM. Du kan v√¶lge forskellige typer modeller med forskellige grader af tr√¶ning, n√•r du udruller en LLM i produktion, med forskellige niveauer af kompleksitet, omkostninger og kvalitet. Her er nogle forskellige tilgange:

- **Prompt engineering med kontekst**. Ideen er at give nok kontekst, n√•r du prompt, for at sikre, at du f√•r de svar, du har brug for.

- **Retrieval Augmented Generation, RAG**. Dine data kan eksistere i en database eller web-endpoint for eksempel, for at sikre, at disse data, eller en delm√¶ngde af dem, er inkluderet p√• tidspunktet for prompten, kan du hente de relevante data og g√∏re dem til en del af brugerens prompt.

- **Finjusteret model**. Her tr√¶ner du modellen yderligere p√• dine egne data, hvilket f√∏rer til, at modellen bliver mere pr√¶cis og lydh√∏r over for dine behov, men det kan v√¶re dyrt.

![LLMs udrulning](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.da.png)

Billedkilde: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med kontekst

Fortr√¶nede LLM'er fungerer meget godt p√• generelle opgaver inden for naturligt sprog, selv ved at kalde dem med en kort prompt, som en s√¶tning der skal fuldf√∏res eller et sp√∏rgsm√•l ‚Äì det s√•kaldte "zero-shot" l√¶ring.

Men jo mere brugeren kan rammes√¶tte deres foresp√∏rgsel med en detaljeret anmodning og eksempler ‚Äì konteksten ‚Äì desto mere pr√¶cis og t√¶ttere p√• brugerens forventninger vil svaret v√¶re. I dette tilf√¶lde taler vi om "one-shot" l√¶ring, hvis prompten kun inkluderer et eksempel, og "few-shot" l√¶ring, hvis den inkluderer flere eksempler. Prompt engineering med kontekst er den mest omkostningseffektive tilgang at starte med.

### Retrieval Augmented Generation (RAG)

LLM'er har den begr√¶nsning, at de kun kan bruge de data, der er blevet brugt under deres tr√¶ning, til at generere et svar. Dette betyder, at de ikke ved noget om de fakta, der skete efter deres tr√¶ningsproces, og de kan ikke f√• adgang til ikke-offentlig information (som virksomhedsdata). Dette kan overkommes gennem RAG, en teknik, der udvider prompten med eksterne data i form af dokumentbrudstykker, under hensyntagen til promptens l√¶ngdegr√¶nser. Dette underst√∏ttes af vektordatabasev√¶rkt√∏jer (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), der henter de nyttige brudstykker fra forskellige foruddefinerede datakilder og tilf√∏jer dem til promptens kontekst.

Denne teknik er meget nyttig, n√•r en virksomhed ikke har nok data, nok tid eller ressourcer til at finjustere en LLM, men stadig √∏nsker at forbedre ydeevnen p√• en specifik arbejdsbyrde og reducere risici for fabrikationer, dvs. forvanskning af virkeligheden eller skadeligt indhold.

### Finjusteret model

Finjustering er en proces, der udnytter transfer learning til at 'tilpasse' modellen til en nedstr√∏ms opgave eller til at l√∏se et specifikt problem. I mods√¶tning til f√•-shot l√¶ring og RAG resulterer det i en ny model, der genereres, med opdaterede v√¶gte og biaser. Det kr√¶ver et s√¶t af tr√¶ningseksempler best√•ende af en enkelt input (prompten) og dens tilknyttede output (fuldf√∏relsen). Dette ville v√¶re den foretrukne tilgang, hvis:

- **Brug af finjusterede modeller**. En virksomhed √∏nsker at bruge finjusterede mindre kapable modeller (som indlejringsmodeller) i stedet for h√∏jtydende modeller, hvilket resulterer i en mere omkostningseffektiv og hurtig l√∏sning.

- **Overvejelse af latenstid**. Latenstid er vigtig for en specifik brugssag, s√• det er ikke muligt at bruge meget lange prompts eller det antal eksempler, der skal l√¶res fra modellen, passer ikke med promptens l√¶ngdegr√¶nse.

- **At holde sig opdateret**. En virksomhed har en masse data af h√∏j kvalitet og grundl√¶ggende sandhedsm√¶rker og de ressourcer, der kr√¶ves for at vedligeholde disse data opdateret over tid.

### Tr√¶net model

Tr√¶ning af en LLM fra bunden er uden tvivl den mest vanskelige og mest komplekse tilgang at adoptere, der kr√¶ver massive m√¶ngder data, dygtige ressourcer og passende computerkraft. Denne mulighed b√∏r kun overvejes i et scenarie, hvor en virksomhed har en dom√¶nespecifik brugssag og en stor m√¶ngde dom√¶necentriske data.

## Videnstjek

Hvad kunne v√¶re en god tilgang til at forbedre LLM fuldf√∏relsesresultater?

1. Prompt engineering med kontekst
1. RAG
1. Finjusteret model

A:3, hvis du har tid og ressourcer og data af h√∏j kvalitet, er finjustering den bedre mulighed for at holde sig opdateret. Men hvis du kigger p√• at forbedre tingene, og du mangler tid, er det v√¶rd at overveje RAG f√∏rst.

## üöÄ Udfordring

L√¶s mere om, hvordan du kan [bruge RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) til din virksomhed.

## Godt arbejde, forts√¶t din l√¶ring

Efter at have gennemf√∏rt denne lektion, tjek vores [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at forts√¶tte med at forbedre din viden om Generative AI!

G√• videre til Lektion 3, hvor vi vil se p√•, hvordan man [bygger med Generative AI ansvarligt](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• at sikre n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for misforst√•elser eller fejltolkninger, der m√•tte opst√• som f√∏lge af brugen af denne overs√¶ttelse.