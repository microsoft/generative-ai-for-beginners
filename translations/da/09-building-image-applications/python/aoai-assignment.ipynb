{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Byg en billedgenereringsapplikation\n",
    "\n",
    "LLM’er kan mere end bare tekstgenerering. Det er også muligt at generere billeder ud fra tekstbeskrivelser. At have billeder som en modalitet kan være utroligt nyttigt inden for mange områder som MedTech, arkitektur, turisme, spiludvikling og meget mere. I dette kapitel kigger vi nærmere på de to mest populære billedgenereringsmodeller, DALL-E og Midjourney.\n",
    "\n",
    "## Introduktion\n",
    "\n",
    "I denne lektion kommer vi ind på:\n",
    "\n",
    "- Billedgenerering og hvorfor det er nyttigt.\n",
    "- DALL-E og Midjourney, hvad de er, og hvordan de fungerer.\n",
    "- Hvordan du kan bygge en billedgenereringsapp.\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Når du har gennemført denne lektion, vil du kunne:\n",
    "\n",
    "- Bygge en billedgenereringsapplikation.\n",
    "- Sætte rammer for din applikation med metaprompter.\n",
    "- Arbejde med DALL-E og Midjourney.\n",
    "\n",
    "## Hvorfor bygge en billedgenereringsapplikation?\n",
    "\n",
    "Billedgenereringsapplikationer er en god måde at udforske mulighederne med Generativ AI. De kan for eksempel bruges til:\n",
    "\n",
    "- **Billedredigering og syntese**. Du kan generere billeder til mange forskellige formål, som fx billedredigering og syntese.\n",
    "\n",
    "- **Anvendelse på tværs af brancher**. De kan også bruges til at generere billeder til forskellige brancher som MedTech, turisme, spiludvikling og meget mere.\n",
    "\n",
    "## Scenario: Edu4All\n",
    "\n",
    "I denne lektion fortsætter vi med at arbejde med vores startup, Edu4All. Eleverne skal lave billeder til deres opgaver – præcis hvilke billeder, bestemmer de selv, men det kan fx være illustrationer til deres egen eventyrfortælling, skabe en ny karakter til deres historie eller hjælpe dem med at visualisere deres idéer og koncepter.\n",
    "\n",
    "Her er et eksempel på, hvad Edu4All’s elever kunne generere, hvis de arbejder med monumenter i undervisningen:\n",
    "\n",
    "![Edu4All startup, klasse om monumenter, Eiffeltårnet](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.da.png)\n",
    "\n",
    "med en prompt som\n",
    "\n",
    "> \"Hund ved siden af Eiffeltårnet i tidligt morgensollys\"\n",
    "\n",
    "## Hvad er DALL-E og Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) og [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) er to af de mest populære billedgenereringsmodeller, som gør det muligt at bruge prompts til at generere billeder.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Lad os starte med DALL-E, som er en generativ AI-model, der laver billeder ud fra tekstbeskrivelser.\n",
    "\n",
    "> [DALL-E er en kombination af to modeller, CLIP og diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** er en model, der laver embeddings, altså numeriske repræsentationer af data, ud fra billeder og tekst.\n",
    "\n",
    "- **Diffused attention** er en model, der genererer billeder ud fra embeddings. DALL-E er trænet på et datasæt med billeder og tekst og kan bruges til at generere billeder ud fra tekstbeskrivelser. For eksempel kan DALL-E bruges til at lave billeder af en kat med hat eller en hund med mohawk.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney fungerer på samme måde som DALL-E – den genererer billeder ud fra tekstprompter. Midjourney kan også bruges til at lave billeder med prompts som “en kat med hat” eller “en hund med mohawk”.\n",
    "\n",
    "![Billede genereret af Midjourney, mekanisk due](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Billedkilde Wikipedia, billede genereret af Midjourney*\n",
    "\n",
    "## Hvordan fungerer DALL-E og Midjourney\n",
    "\n",
    "Først [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E er en generativ AI-model baseret på transformer-arkitekturen med en *autoregressiv transformer*.\n",
    "\n",
    "En *autoregressiv transformer* definerer, hvordan en model genererer billeder ud fra tekstbeskrivelser – den laver ét pixel ad gangen og bruger de genererede pixels til at lave den næste pixel. Den passerer gennem flere lag i et neuralt netværk, indtil billedet er færdigt.\n",
    "\n",
    "Med denne proces kan DALL-E styre attributter, objekter, karakteristika og meget mere i det billede, der genereres. DALL-E 2 og 3 har dog endnu mere kontrol over det færdige billede,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Byg din første billedgenereringsapplikation\n",
    "\n",
    "Hvad skal der egentlig til for at bygge en billedgenereringsapplikation? Du skal bruge følgende biblioteker:\n",
    "\n",
    "- **python-dotenv**, det anbefales kraftigt at bruge dette bibliotek til at holde dine hemmeligheder i en *.env*-fil væk fra koden.\n",
    "- **openai**, dette bibliotek bruger du til at interagere med OpenAI API'et.\n",
    "- **pillow**, til at arbejde med billeder i Python.\n",
    "- **requests**, som hjælper dig med at lave HTTP-forespørgsler.\n",
    "\n",
    "\n",
    "1. Opret en fil *.env* med følgende indhold:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Find disse oplysninger i Azure Portal for din ressource under sektionen \"Nøgler og endpoint\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Saml ovenstående biblioteker i en fil kaldet *requirements.txt* sådan her:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. Opret derefter et virtuelt miljø og installer bibliotekerne:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> For Windows, brug følgende kommandoer for at oprette og aktivere dit virtuelle miljø:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Tilføj følgende kode i en fil kaldet *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Lad os gennemgå koden:\n",
    "\n",
    "- Først importerer vi de nødvendige biblioteker, herunder OpenAI-biblioteket, dotenv-biblioteket, requests-biblioteket og Pillow-biblioteket.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Dernæst indlæser vi miljøvariablerne fra *.env*-filen.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Herefter sætter vi endpoint, nøgle til OpenAI API, version og type.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Nu genererer vi billedet:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Koden ovenfor svarer med et JSON-objekt, der indeholder URL'en til det genererede billede. Vi kan bruge URL'en til at hente billedet og gemme det i en fil.\n",
    "\n",
    "- Til sidst åbner vi billedet og bruger standard billedfremviser til at vise det:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Flere detaljer om billedgenerering\n",
    "\n",
    "Lad os se nærmere på koden, der genererer billedet:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** er tekstprompten, der bruges til at generere billedet. I dette tilfælde bruger vi prompten \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".\n",
    "- **size** er størrelsen på det billede, der genereres. Her genererer vi et billede, der er 1024x1024 pixels.\n",
    "- **n** er antallet af billeder, der genereres. I dette tilfælde genererer vi to billeder.\n",
    "- **temperature** er en parameter, der styrer tilfældigheden i outputtet fra en Generativ AI-model. Temperature er en værdi mellem 0 og 1, hvor 0 betyder, at outputtet er deterministisk, og 1 betyder, at outputtet er tilfældigt. Standardværdien er 0,7.\n",
    "\n",
    "Der er flere ting, du kan gøre med billeder, som vi gennemgår i næste afsnit.\n",
    "\n",
    "## Yderligere muligheder for billedgenerering\n",
    "\n",
    "Indtil nu har du set, hvordan vi kunne generere et billede med få linjer Python. Men der er flere ting, du kan gøre med billeder.\n",
    "\n",
    "Du kan også gøre følgende:\n",
    "\n",
    "- **Foretage redigeringer**. Ved at give et eksisterende billede, en maske og en prompt kan du ændre et billede. For eksempel kan du tilføje noget til en del af et billede. Forestil dig vores kaninbillede – du kan tilføje en hat til kaninen. Det gør du ved at give billedet, en maske (der identificerer det område, der skal ændres) og en tekstprompt, der beskriver, hvad der skal gøres.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    Grundbilledet vil kun indeholde kaninen, men det endelige billede vil have hatten på kaninen.\n",
    "\n",
    "- **Oprette variationer**.\n",
    "    Se vores [OpenAI-notesbog for mere information](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, skal du være opmærksom på, at automatiske oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel, menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå ved brug af denne oversættelse.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:18:37+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}