# Valg & Konfiguration af en LLM-udbyder 游댐

Opgaver **kan** ogs친 s칝ttes op til at arbejde mod en eller flere Large Language Model (LLM) implementeringer gennem en underst칮ttet serviceudbyder som OpenAI, Azure eller Hugging Face. Disse leverer et _hostet endpoint_ (API), som vi kan tilg친 programmatisk med de rette legitimationsoplysninger (API-n칮gle eller token). I dette kursus diskuterer vi disse udbydere:

 - [OpenAI](https://platform.openai.com/docs/models?WT.mc_id=academic-105485-koreyst) med forskellige modeller inklusive den centrale GPT-serie.
 - [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/?WT.mc_id=academic-105485-koreyst) for OpenAI-modeller med fokus p친 virksomhedsklarhed
 - [Hugging Face](https://huggingface.co/docs/hub/index?WT.mc_id=academic-105485-koreyst) for open source-modeller og inferensserver

**Du skal bruge dine egne konti til disse 칮velser**. Opgaver er valgfrie, s친 du kan v칝lge at s칝tte en, alle - eller ingen - af udbyderne op baseret p친 dine interesser. Her er lidt vejledning til tilmelding:

| Tilmelding | Pris | API-n칮gle | Playground | Kommentarer |
|:---|:---|:---|:---|:---|
| [OpenAI](https://platform.openai.com/signup?WT.mc_id=academic-105485-koreyst)| [Priser](https://openai.com/pricing#language-models?WT.mc_id=academic-105485-koreyst)| [Projektbaseret](https://platform.openai.com/api-keys?WT.mc_id=academic-105485-koreyst) | [No-Code, Web](https://platform.openai.com/playground?WT.mc_id=academic-105485-koreyst) | Flere modeller tilg칝ngelige |
| [Azure](https://aka.ms/azure/free?WT.mc_id=academic-105485-koreyst)| [Priser](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/?WT.mc_id=academic-105485-koreyst)| [SDK Quickstart](https://learn.microsoft.com/azure/ai-services/openai/quickstart?WT.mc_id=academic-105485-koreyst)| [Studio Quickstart](https://learn.microsoft.com/azure/ai-services/openai/quickstart?WT.mc_id=academic-105485-koreyst) |  [Skal ans칮ges om adgang p친 forh친nd](https://learn.microsoft.com/azure/ai-services/openai/?WT.mc_id=academic-105485-koreyst)|
| [Hugging Face](https://huggingface.co/join?WT.mc_id=academic-105485-koreyst) | [Priser](https://huggingface.co/pricing) | [Adgangstokens](https://huggingface.co/docs/hub/security-tokens?WT.mc_id=academic-105485-koreyst) | [Hugging Chat](https://huggingface.co/chat/?WT.mc_id=academic-105485-koreyst)| [Hugging Chat har begr칝nsede modeller](https://huggingface.co/chat/models?WT.mc_id=academic-105485-koreyst) |
| | | | | |

F칮lg nedenst친ende anvisninger for at _konfigurere_ dette repository til brug med forskellige udbydere. Opgaver, der kr칝ver en specifik udbyder, vil indeholde et af disse tags i deres filnavn:

- `aoai` - kr칝ver Azure OpenAI endpoint, n칮gle
- `oai` - kr칝ver OpenAI endpoint, n칮gle
- `hf` - kr칝ver Hugging Face token

Du kan konfigurere en, ingen eller alle udbydere. Relaterede opgaver vil blot give fejl ved manglende legitimationsoplysninger.

## Opret `.env` fil

Vi antager, at du allerede har l칝st vejledningen ovenfor og tilmeldt dig den relevante udbyder, og f친et de n칮dvendige autentificeringsoplysninger (API_KEY eller token). I tilf칝lde af Azure OpenAI antager vi ogs친, at du har en gyldig implementering af en Azure OpenAI Service (endpoint) med mindst 칠n GPT-model implementeret til chat completion.

N칝ste skridt er at konfigurere dine **lokale milj칮variabler** som f칮lger:

1. Kig i rodmappen efter en `.env.copy` fil, som b칮r have indhold som dette:

   ```bash
   # OpenAI Udbyder
   OPENAI_API_KEY='<add your OpenAI API key here>'

   ## Azure OpenAI
   AZURE_OPENAI_API_VERSION='2024-02-01' # Standard er sat!
   AZURE_OPENAI_API_KEY='<add your AOAI key here>'
   AZURE_OPENAI_ENDPOINT='<add your AOIA service endpoint here>'
   AZURE_OPENAI_DEPLOYMENT='<add your chat completion model name here>' 
   AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT='<add your embeddings model name here>'

   ## Hugging Face
   HUGGING_FACE_API_KEY='<add your HuggingFace API or token here>'
   ```

2. Kopi칠r den fil til `.env` med kommandoen nedenfor. Denne fil er _gitignore-d_, s친 hemmeligheder holdes sikre.

   ```bash
   cp .env.copy .env
   ```

3. Udfyld v칝rdierne (erstat pladsholdere til h칮jre for `=`) som beskrevet i n칝ste afsnit.

4. (Valgfrit) Hvis du bruger GitHub Codespaces, har du mulighed for at gemme milj칮variabler som _Codespaces secrets_ tilknyttet dette repository. I s친 fald beh칮ver du ikke s칝tte en lokal .env fil op. **Bem칝rk dog, at denne mulighed kun virker, hvis du bruger GitHub Codespaces.** Du skal stadig s칝tte .env filen op, hvis du bruger Docker Desktop i stedet.

## Udfyld `.env` fil

Lad os hurtigt se p친 variabelnavnene for at forst친, hvad de repr칝senterer:

| Variabel  | Beskrivelse  |
| :--- | :--- |
| HUGGING_FACE_API_KEY | Dette er brugerens adgangstoken, som du har sat op i din profil |
| OPENAI_API_KEY | Dette er autorisationsn칮glen til brug af tjenesten for ikke-Azure OpenAI endpoints |
| AZURE_OPENAI_API_KEY | Dette er autorisationsn칮glen til brug af den tjeneste |
| AZURE_OPENAI_ENDPOINT | Dette er det implementerede endpoint for en Azure OpenAI-ressource |
| AZURE_OPENAI_DEPLOYMENT | Dette er _tekstgenererings_-modelimplementerings-endpointet |
| AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT | Dette er _tekstindlejrings_-modelimplementerings-endpointet |
| | |

Bem칝rk: De sidste to Azure OpenAI variabler afspejler en standardmodel til chat completion (tekstgenerering) og vektors칮gning (indlejringer) henholdsvis. Instruktioner til ops칝tning af dem vil blive defineret i relevante opgaver.

## Konfigurer Azure: Fra Portal

Azure OpenAI endpoint og n칮glev칝rdier findes i [Azure Portal](https://portal.azure.com?WT.mc_id=academic-105485-koreyst), s친 lad os starte der.

1. G친 til [Azure Portal](https://portal.azure.com?WT.mc_id=academic-105485-koreyst)
1. Klik p친 **Keys and Endpoint** valgmuligheden i sidebaren (menu til venstre).
1. Klik p친 **Show Keys** - du b칮r se f칮lgende: KEY 1, KEY 2 og Endpoint.
1. Brug v칝rdien for KEY 1 til AZURE_OPENAI_API_KEY
1. Brug Endpoint v칝rdien til AZURE_OPENAI_ENDPOINT

Dern칝st skal vi bruge endpoints for de specifikke modeller, vi har implementeret.

1. Klik p친 **Model deployments** valgmuligheden i sidebaren (venstre menu) for Azure OpenAI ressourcen.
1. P친 destinationssiden klik p친 **Manage Deployments**

Dette tager dig til Azure OpenAI Studio-websitet, hvor vi finder de andre v칝rdier som beskrevet nedenfor.

## Konfigurer Azure: Fra Studio

1. Naviger til [Azure OpenAI Studio](https://oai.azure.com?WT.mc_id=academic-105485-koreyst) **fra din ressource** som beskrevet ovenfor.
1. Klik p친 fanen **Deployments** (sidebar, venstre) for at se de aktuelt implementerede modeller.
1. Hvis din 칮nskede model ikke er implementeret, brug **Create new deployment** til at implementere den.
1. Du skal bruge en _text-generation_ model - vi anbefaler: **gpt-35-turbo**
1. Du skal bruge en _text-embedding_ model - vi anbefaler **text-embedding-ada-002**

Opdater nu milj칮variablerne til at afspejle det _Deployment name_, der bruges. Dette vil typisk v칝re det samme som modelnavnet, medmindre du har 칝ndret det eksplicit. S친 som eksempel kan du have:

```bash
AZURE_OPENAI_DEPLOYMENT='gpt-35-turbo'
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT='text-embedding-ada-002'
```

**Glem ikke at gemme .env filen, n친r du er f칝rdig**. Du kan nu lukke filen og vende tilbage til instruktionerne for at k칮re notebooken.

## Konfigurer OpenAI: Fra Profil

Din OpenAI API-n칮gle kan findes i din [OpenAI-konto](https://platform.openai.com/api-keys?WT.mc_id=academic-105485-koreyst). Hvis du ikke har en, kan du tilmelde dig en konto og oprette en API-n칮gle. N친r du har n칮glen, kan du bruge den til at udfylde `OPENAI_API_KEY` variablen i `.env` filen.

## Konfigurer Hugging Face: Fra Profil

Din Hugging Face token kan findes i din profil under [Access Tokens](https://huggingface.co/settings/tokens?WT.mc_id=academic-105485-koreyst). Del eller offentligg칮r dem ikke. Opret i stedet en ny token til dette projekt og kopier den ind i `.env` filen under variablen `HUGGING_FACE_API_KEY`. _Bem칝rk:_ Dette er teknisk set ikke en API-n칮gle, men bruges til autentificering, s친 vi bevarer denne navngivningskonvention for konsistens.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 n칮jagtighed, bedes du v칝re opm칝rksom p친, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det oprindelige dokument p친 dets modersm친l b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi p친tager os intet ansvar for misforst친elser eller fejltolkninger, der opst친r som f칮lge af brugen af denne overs칝ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->