{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduktion\n",
    "\n",
    "Denne lektion vil dække:\n",
    "- Hvad funktionkald er, og dets anvendelsestilfælde\n",
    "- Hvordan man opretter et funktionkald ved hjælp af OpenAI\n",
    "- Hvordan man integrerer et funktionkald i en applikation\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Efter at have gennemført denne lektion vil du vide, hvordan man gør, og forstå:\n",
    "\n",
    "- Formålet med at bruge funktionkald\n",
    "- Opsæt funktionkald ved hjælp af OpenAI-tjenesten\n",
    "- Design effektive funktionkald til din applikations anvendelsestilfælde\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forståelse af Funktionskald\n",
    "\n",
    "Til denne lektion vil vi bygge en funktion til vores uddannelsesstartup, der giver brugerne mulighed for at bruge en chatbot til at finde tekniske kurser. Vi vil anbefale kurser, der passer til deres færdighedsniveau, nuværende rolle og interesse for teknologi.\n",
    "\n",
    "For at fuldføre dette vil vi bruge en kombination af:\n",
    " - `OpenAI` til at skabe en chatoplevelse for brugeren\n",
    " - `Microsoft Learn Catalog API` til at hjælpe brugerne med at finde kurser baseret på brugerens forespørgsel\n",
    " - `Function Calling` til at tage brugerens forespørgsel og sende den til en funktion for at lave API-forespørgslen.\n",
    "\n",
    "For at komme i gang, lad os se på, hvorfor vi overhovedet vil bruge funktionskald:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # få et nyt svar fra GPT, hvor det kan se funktionssvaret\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hvorfor Funktionskald\n",
    "\n",
    "Hvis du har gennemført en anden lektion i dette kursus, forstår du sandsynligvis kraften ved at bruge Store Sprogmodeller (LLMs). Forhåbentlig kan du også se nogle af deres begrænsninger.\n",
    "\n",
    "Funktionskald er en funktion i OpenAI Service designet til at løse følgende udfordringer:\n",
    "\n",
    "Uensartet svarformat:\n",
    "- Før funktionskald var svar fra en stor sprogmodel ustrukturerede og inkonsistente. Udviklere måtte skrive kompleks valideringskode for at håndtere hver variation i outputtet.\n",
    "\n",
    "Begrænset integration med eksterne data:\n",
    "- Før denne funktion var det svært at inkorporere data fra andre dele af en applikation i en chat-kontekst.\n",
    "\n",
    "Ved at standardisere svarformater og muliggøre problemfri integration med eksterne data forenkler funktionskald udviklingen og reducerer behovet for yderligere valideringslogik.\n",
    "\n",
    "Brugere kunne ikke få svar som \"Hvad er vejret lige nu i Stockholm?\". Dette skyldes, at modellerne var begrænset til det tidspunkt, hvor dataene blev trænet.\n",
    "\n",
    "Lad os se på eksemplet nedenfor, der illustrerer dette problem:\n",
    "\n",
    "Lad os sige, at vi vil oprette en database med elevdata, så vi kan foreslå det rigtige kursus til dem. Nedenfor har vi to beskrivelser af elever, der er meget ens i de data, de indeholder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vil sende dette til en LLM for at analysere dataene. Dette kan senere bruges i vores applikation til at sende det til en API eller gemme det i en database.\n",
    "\n",
    "Lad os oprette to identiske prompts, hvor vi instruerer LLM om, hvilken information vi er interesserede i:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vil sende dette til en LLM for at analysere de dele, der er vigtige for vores produkt. Så vi kan oprette to identiske prompts til at instruere LLM'en:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efter at have oprettet disse to prompts, sender vi dem til LLM ved at bruge `openai.ChatCompletion`. Vi gemmer prompten i variablen `messages` og tildeler rollen `user`. Dette er for at efterligne en besked fra en bruger, der skrives til en chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kan vi sende begge forespørgsler til LLM og undersøge det svar, vi modtager.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selvom promptene er de samme, og beskrivelserne ligner hinanden, kan vi få forskellige formater af `Grades`-egenskaben.\n",
    "\n",
    "Hvis du kører ovenstående celle flere gange, kan formatet være `3.7` eller `3.7 GPA`.\n",
    "\n",
    "Dette skyldes, at LLM tager ustrukturerede data i form af den skrevne prompt og også returnerer ustrukturerede data. Vi har brug for at have et struktureret format, så vi ved, hvad vi kan forvente, når vi gemmer eller bruger disse data.\n",
    "\n",
    "Ved at bruge funktionel kald kan vi sikre, at vi modtager strukturerede data tilbage. Når vi bruger funktionel kald, kalder eller kører LLM faktisk ikke nogen funktioner. I stedet opretter vi en struktur, som LLM skal følge for sine svar. Vi bruger derefter disse strukturerede svar til at vide, hvilken funktion vi skal køre i vores applikationer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funktionskald Flow Diagram](../../../../translated_images/da/Function-Flow.083875364af4f4bb.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi kan derefter tage det, der returneres fra funktionen, og sende det tilbage til LLM'en. LLM'en vil så svare ved hjælp af naturligt sprog for at besvare brugerens forespørgsel.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brugstilfælde for brug af funktionskald\n",
    "\n",
    "**Kald af eksterne værktøjer**  \n",
    "Chatbots er gode til at give svar på spørgsmål fra brugere. Ved at bruge funktionskald kan chatbots bruge beskeder fra brugere til at udføre bestemte opgaver. For eksempel kan en studerende bede chatbotten om at \"Sende en e-mail til min underviser og sige, at jeg har brug for mere hjælp med dette emne\". Dette kan lave et funktionskald til `send_email(to: string, body: string)`\n",
    "\n",
    "**Opret API- eller databaseforespørgsler**  \n",
    "Brugere kan finde information ved hjælp af naturligt sprog, som bliver konverteret til en formateret forespørgsel eller API-anmodning. Et eksempel på dette kunne være en lærer, der spørger \"Hvem er de studerende, der har fuldført den sidste opgave\", hvilket kunne kalde en funktion med navnet `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Oprettelse af strukturerede data**  \n",
    "Brugere kan tage et tekstafsnit eller CSV og bruge LLM til at udtrække vigtig information fra det. For eksempel kan en studerende konvertere en Wikipedia-artikel om fredsaftaler til at lave AI-flashcards. Dette kan gøres ved at bruge en funktion kaldet `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Oprettelse af dit første funktionskald\n",
    "\n",
    "Processen med at oprette et funktionskald inkluderer 3 hovedtrin:\n",
    "1. Kalde Chat Completions API med en liste over dine funktioner og en brugermeddelelse\n",
    "2. Læse modellens svar for at udføre en handling, dvs. køre en funktion eller API-kald\n",
    "3. Foretage et nyt kald til Chat Completions API med svaret fra din funktion for at bruge den information til at skabe et svar til brugeren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow af et funktionskald](../../../../translated_images/da/LLM-Flow.3285ed8caf4796d7.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementer i et funktionskald\n",
    "\n",
    "#### Brugerinput\n",
    "\n",
    "Det første trin er at oprette en brugermeddelelse. Dette kan tildeles dynamisk ved at tage værdien af en tekstinput, eller du kan tildele en værdi her. Hvis det er første gang, du arbejder med Chat Completions API, skal vi definere `role` og `content` i meddelelsen.\n",
    "\n",
    "`role` kan enten være `system` (opretter regler), `assistant` (modellen) eller `user` (slutbrugeren). Til funktionskald vil vi tildele denne som `user` og et eksempelspørgsmål.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oprettelse af funktioner.\n",
    "\n",
    "Næste trin er at definere en funktion og parametrene for den funktion. Vi vil bruge kun én funktion her kaldet `search_courses`, men du kan oprette flere funktioner.\n",
    "\n",
    "**Vigtigt** : Funktioner er inkluderet i systembeskeden til LLM og vil tælle med i det antal tilgængelige tokens, du har til rådighed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definitioner** \n",
    "\n",
    "Funktionsdefinitionsstrukturen har flere niveauer, hver med sine egne egenskaber. Her er en oversigt over den indlejrede struktur:\n",
    "\n",
    "**Topniveau Funktions Egenskaber:**\n",
    "\n",
    "`name` - Navnet på funktionen, som vi ønsker skal kaldes. \n",
    "\n",
    "`description` - Dette er beskrivelsen af, hvordan funktionen fungerer. Her er det vigtigt at være specifik og klar \n",
    "\n",
    "`parameters` - En liste over værdier og format, som du ønsker, at modellen skal producere i sit svar \n",
    "\n",
    "**Egenskaber for Parameterobjektet:**\n",
    "\n",
    "`type` - Datatypen for parameterobjektet (normalt \"object\")\n",
    "\n",
    "`properties` - Liste over de specifikke værdier, som modellen vil bruge til sit svar \n",
    "\n",
    "**Egenskaber for Individuelle Parametre:**\n",
    "\n",
    "`name` - Implicit defineret af egenskabsnøglen (f.eks. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Datatypen for denne specifikke parameter (f.eks. \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Beskrivelse af den specifikke parameter \n",
    "\n",
    "**Valgfrie Egenskaber:**\n",
    "\n",
    "`required` - Et array, der angiver hvilke parametre, der er nødvendige for, at funktionskaldet kan gennemføres \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Foretage funktionskaldet  \n",
    "Efter at have defineret en funktion, skal vi nu inkludere den i kaldet til Chat Completion API'en. Det gør vi ved at tilføje `functions` til forespørgslen. I dette tilfælde `functions=functions`.  \n",
    "\n",
    "Der er også en mulighed for at sætte `function_call` til `auto`. Det betyder, at vi lader LLM'en beslutte, hvilken funktion der skal kaldes baseret på brugermeddelelsen i stedet for at tildele det selv.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lad os nu se på svaret og se, hvordan det er formateret:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Du kan se, at navnet på funktionen bliver kaldt, og ud fra brugerens besked var LLM i stand til at finde dataene, så de passer til funktionens argumenter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrering af funktionskald i en applikation. \n",
    "\n",
    "\n",
    "Efter vi har testet det formaterede svar fra LLM, kan vi nu integrere dette i en applikation. \n",
    "\n",
    "### Styring af flowet \n",
    "\n",
    "For at integrere dette i vores applikation, lad os tage følgende skridt: \n",
    "\n",
    "Først laver vi kaldet til OpenAI-tjenesterne og gemmer beskeden i en variabel kaldet `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu vil vi definere funktionen, der vil kalde Microsoft Learn API'en for at få en liste over kurser:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som en bedste praksis vil vi derefter se, om modellen ønsker at kalde en funktion. Derefter vil vi oprette en af de tilgængelige funktioner og matche den med den funktion, der bliver kaldt.  \n",
    "Vi vil derefter tage argumenterne til funktionen og kortlægge dem til argumenter fra LLM.\n",
    "\n",
    "Til sidst vil vi tilføje funktionskaldsbeskeden og de værdier, der blev returneret af `search_courses`-beskeden. Dette giver LLM alle de oplysninger, den har brug for,  \n",
    "for at svare brugeren ved hjælp af naturligt sprog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu sender vi den opdaterede besked til LLM, så vi kan modtage et svar i naturligt sprog i stedet for et API JSON-formateret svar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodeudfordring\n",
    "\n",
    "Godt arbejde! For at fortsætte din læring af OpenAI Function Calling kan du bygge: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Flere parametre til funktionen, som kan hjælpe lærende med at finde flere kurser. Du kan finde de tilgængelige API-parametre her:  \n",
    " - Opret et andet funktionskald, der tager flere oplysninger fra den lærende, såsom deres modersmål  \n",
    " - Opret fejlhåndtering, når funktionskaldet og/eller API-kaldet ikke returnerer nogen egnede kurser  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Ansvarsfraskrivelse**:\nDette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, bedes du være opmærksom på, at automatiserede oversættelser kan indeholde fejl eller unøjagtigheder. Det oprindelige dokument på dets modersmål bør betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der opstår som følge af brugen af denne oversættelse.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T10:34:28+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}