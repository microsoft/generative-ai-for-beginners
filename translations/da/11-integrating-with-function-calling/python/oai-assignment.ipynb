{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduktion\n",
    "\n",
    "Denne lektion vil dække:\n",
    "- Hvad funktionskald er, og hvornår de bruges\n",
    "- Hvordan man opretter et funktionskald med OpenAI\n",
    "- Hvordan man integrerer et funktionskald i en applikation\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Når du har gennemført denne lektion, vil du vide hvordan og forstå:\n",
    "\n",
    "- Formålet med at bruge funktionskald\n",
    "- Opsætning af Funktionskald med OpenAI-tjenesten\n",
    "- Designe effektive funktionskald til din applikations brugsscenarie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forståelse af funktionskald\n",
    "\n",
    "I denne lektion vil vi bygge en funktion til vores uddannelses-startup, der gør det muligt for brugere at bruge en chatbot til at finde tekniske kurser. Vi vil anbefale kurser, der passer til deres færdighedsniveau, nuværende rolle og interesseområde inden for teknologi.\n",
    "\n",
    "For at gennemføre dette vil vi bruge en kombination af:\n",
    " - `OpenAI` til at skabe en chatoplevelse for brugeren\n",
    " - `Microsoft Learn Catalog API` til at hjælpe brugere med at finde kurser baseret på deres forespørgsel\n",
    " - `Function Calling` til at tage brugerens forespørgsel og sende den til en funktion, der laver API-forespørgslen.\n",
    "\n",
    "Lad os starte med at se på, hvorfor vi overhovedet vil bruge funktionskald:\n",
    "\n",
    "print(\"Beskeder i næste forespørgsel:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # få et nyt svar fra GPT, hvor den kan se funktionssvaret\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hvorfor Function Calling\n",
    "\n",
    "Hvis du har gennemført en anden lektion i dette kursus, forstår du sikkert allerede, hvor kraftfulde Large Language Models (LLMs) er. Forhåbentlig kan du også se nogle af deres begrænsninger.\n",
    "\n",
    "Function Calling er en funktion i OpenAI Service, der er udviklet for at løse følgende udfordringer:\n",
    "\n",
    "Uensartet svarformat:\n",
    "- Før function calling var svarene fra en large language model ustrukturerede og uensartede. Udviklere var nødt til at skrive kompleks valideringskode for at håndtere alle variationer i outputtet.\n",
    "\n",
    "Begrænset integration med eksterne data:\n",
    "- Før denne funktion var det svært at inddrage data fra andre dele af en applikation i en chatkontekst.\n",
    "\n",
    "Ved at standardisere svarformater og muliggøre problemfri integration med eksterne data, gør function calling udviklingen nemmere og mindsker behovet for ekstra valideringslogik.\n",
    "\n",
    "Brugere kunne ikke få svar som \"Hvad er vejret lige nu i Stockholm?\". Det skyldes, at modellerne kun havde adgang til data fra det tidspunkt, de blev trænet på.\n",
    "\n",
    "Lad os se på eksemplet nedenfor, som illustrerer dette problem:\n",
    "\n",
    "Lad os sige, at vi vil oprette en database med elevdata, så vi kan foreslå det rigtige kursus til dem. Nedenfor har vi to beskrivelser af elever, der minder meget om hinanden i forhold til de data, de indeholder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vil gerne sende dette til en LLM for at analysere dataene. Dette kan senere bruges i vores applikation til at sende det til et API eller gemme det i en database.\n",
    "\n",
    "Lad os lave to identiske prompts, hvor vi instruerer LLM’en om, hvilke oplysninger vi er interesserede i:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ønsker at sende dette til en LLM for at analysere de dele, der er vigtige for vores produkt. Så vi kan oprette to identiske prompts for at instruere LLM'en:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efter at have oprettet disse to prompts, sender vi dem til LLM ved at bruge `openai.ChatCompletion`. Vi gemmer prompten i variablen `messages` og tildeler rollen til `user`. Dette er for at efterligne en besked fra en bruger, der skrives til en chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selvom promptene er de samme og beskrivelserne ligner hinanden, kan vi få forskellige formater af `Grades`-egenskaben.\n",
    "\n",
    "Hvis du kører ovenstående celle flere gange, kan formatet være `3.7` eller `3.7 GPA`.\n",
    "\n",
    "Det skyldes, at LLM'en tager ustrukturerede data i form af den skrevne prompt og også returnerer ustrukturerede data. Vi har brug for et struktureret format, så vi ved, hvad vi kan forvente, når vi gemmer eller bruger disse data.\n",
    "\n",
    "Ved at bruge funktionel kald kan vi sikre, at vi får strukturerede data tilbage. Når vi bruger funktionel kald, kalder eller kører LLM'en faktisk ikke nogen funktioner. I stedet opretter vi en struktur, som LLM'en skal følge i sine svar. Vi bruger derefter de strukturerede svar til at vide, hvilken funktion vi skal køre i vores applikationer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funktionskaldsflowdiagram](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.da.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brugsscenarier for brug af funktionskald\n",
    "\n",
    "**Kald til eksterne værktøjer**  \n",
    "Chatbots er gode til at besvare brugernes spørgsmål. Ved at bruge funktionskald kan chatbots bruge beskeder fra brugerne til at udføre bestemte opgaver. For eksempel kan en studerende bede chatbotten om at \"Sende en mail til min underviser og sige, at jeg har brug for mere hjælp til dette emne\". Dette kan udløse et funktionskald til `send_email(to: string, body: string)`\n",
    "\n",
    "**Oprette API- eller databaseforespørgsler**  \n",
    "Brugere kan finde information ved at bruge naturligt sprog, som bliver omdannet til en formateret forespørgsel eller API-anmodning. Et eksempel kunne være en lærer, der spørger \"Hvem er de elever, der har afleveret den sidste opgave\", hvilket kan kalde en funktion ved navn `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Oprettelse af strukturerede data**  \n",
    "Brugere kan tage et tekstafsnit eller en CSV-fil og bruge LLM til at udtrække vigtige oplysninger fra det. For eksempel kan en studerende omdanne en Wikipedia-artikel om fredsaftaler til at lave AI-flashkort. Dette kan gøres ved at bruge en funktion kaldet `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Oprettelse af dit første funktionskald\n",
    "\n",
    "Processen med at oprette et funktionskald består af 3 hovedtrin:\n",
    "1. Kald Chat Completions API'et med en liste over dine funktioner og en brugermeddelelse\n",
    "2. Læs modellens svar for at udføre en handling, dvs. køre en funktion eller et API-kald\n",
    "3. Lav endnu et kald til Chat Completions API'et med svaret fra din funktion for at bruge den information til at skabe et svar til brugeren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow of a Function Call](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.da.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementer i et funktionskald\n",
    "\n",
    "#### Brugerinput\n",
    "\n",
    "Det første skridt er at oprette en brugermeddelelse. Dette kan gøres dynamisk ved at tage værdien fra et tekstinput, eller du kan tildele en værdi her. Hvis det er første gang, du arbejder med Chat Completions API'en, skal vi definere `role` og `content` for beskeden.\n",
    "\n",
    "`role` kan enten være `system` (opretter regler), `assistant` (modellen) eller `user` (slutbrugeren). Til funktionskald sætter vi dette som `user` og tilføjer et eksempelspørgsmål.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oprettelse af funktioner.\n",
    "\n",
    "Nu skal vi definere en funktion og dens parametre. Vi bruger kun én funktion her, som hedder `search_courses`, men du kan sagtens oprette flere funktioner.\n",
    "\n",
    "**Vigtigt**: Funktioner bliver inkluderet i systembeskeden til LLM’en og vil tælle med i det antal tokens, du har til rådighed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definitioner**\n",
    "\n",
    "Strukturen for funktionsdefinitioner har flere niveauer, hver med sine egne egenskaber. Her er en oversigt over den indlejrede struktur:\n",
    "\n",
    "**Egenskaber for funktion på øverste niveau:**\n",
    "\n",
    "`name` - Navnet på den funktion, vi ønsker at få kaldt.\n",
    "\n",
    "`description` - Dette er beskrivelsen af, hvordan funktionen fungerer. Her er det vigtigt at være specifik og tydelig.\n",
    "\n",
    "`parameters` - En liste over værdier og format, som du ønsker, at modellen skal give i sit svar.\n",
    "\n",
    "**Egenskaber for parameters-objektet:**\n",
    "\n",
    "`type` - Datatypen for parameters-objektet (typisk \"object\")\n",
    "\n",
    "`properties` - Liste over de specifikke værdier, som modellen vil bruge i sit svar\n",
    "\n",
    "**Egenskaber for individuelle parametre:**\n",
    "\n",
    "`name` - Defineres implicit af egenskabens nøgle (f.eks. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Datatypen for denne specifikke parameter (f.eks. \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Beskrivelse af den specifikke parameter\n",
    "\n",
    "**Valgfrie egenskaber:**\n",
    "\n",
    "`required` - Et array, der angiver, hvilke parametre der er påkrævet for at funktionen kan udføres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sådan foretager du funktionskald\n",
    "Efter at have defineret en funktion, skal vi nu inkludere den i kaldet til Chat Completion API'et. Det gør vi ved at tilføje `functions` til forespørgslen. I dette tilfælde `functions=functions`.\n",
    "\n",
    "Der er også mulighed for at sætte `function_call` til `auto`. Det betyder, at vi lader LLM'en vælge, hvilken funktion der skal kaldes, baseret på brugerens besked, i stedet for at vi selv vælger det.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu lad os se på svaret og se, hvordan det er formateret:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Du kan se, at navnet på funktionen bliver kaldt, og ud fra brugerens besked var LLM i stand til at finde dataene til at udfylde argumenterne til funktionen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrering af funktionskald i en applikation.\n",
    "\n",
    "Når vi har testet det formaterede svar fra LLM'en, kan vi nu integrere det i en applikation.\n",
    "\n",
    "### Håndtering af flowet\n",
    "\n",
    "For at integrere dette i vores applikation, lad os tage følgende skridt:\n",
    "\n",
    "Først laver vi kaldet til OpenAI-tjenesterne og gemmer beskeden i en variabel kaldet `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu vil vi definere funktionen, der vil kalde Microsoft Learn API'et for at hente en liste over kurser:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som en god praksis vil vi derefter se, om modellen ønsker at kalde en funktion. Derefter opretter vi en af de tilgængelige funktioner og matcher den med den funktion, der bliver kaldt.\n",
    "Vi tager så argumenterne fra funktionen og matcher dem med argumenterne fra LLM.\n",
    "\n",
    "Til sidst tilføjer vi beskeden om funktionskaldet og de værdier, der blev returneret af `search_courses`-beskeden. Dette giver LLM alle de oplysninger, den har brug for\n",
    "til at svare brugeren med naturligt sprog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodeudfordring\n",
    "\n",
    "Godt arbejde! For at fortsætte din læring om OpenAI Function Calling kan du bygge: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Flere parametre til funktionen, som kan hjælpe brugere med at finde flere kurser. Du kan finde de tilgængelige API-parametre her:\n",
    " - Opret et andet funktionskald, der tager mere information fra brugeren, såsom deres modersmål\n",
    " - Tilføj fejlhåndtering, hvis funktionskaldet og/eller API-kaldet ikke returnerer nogen relevante kurser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, skal du være opmærksom på, at automatiske oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel, menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå ved brug af denne oversættelse.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:06:58+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}