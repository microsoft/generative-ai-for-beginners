{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduktion\n",
    "\n",
    "Denne lektion vil dække:\n",
    "- Hvad funktionskald er, og hvornår de bruges\n",
    "- Hvordan man opretter et funktionskald med Azure OpenAI\n",
    "- Hvordan man integrerer et funktionskald i en applikation\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Når du har gennemført denne lektion, vil du vide hvordan og forstå:\n",
    "\n",
    "- Formålet med at bruge funktionskald\n",
    "- Opsætning af funktionskald med Azure Open AI Service\n",
    "- Designe effektive funktionskald til din applikations brugsscenarie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forståelse af funktionskald\n",
    "\n",
    "I denne lektion vil vi bygge en funktion til vores uddannelses-startup, der gør det muligt for brugere at bruge en chatbot til at finde tekniske kurser. Vi vil anbefale kurser, der passer til deres færdighedsniveau, nuværende rolle og interesse for teknologi.\n",
    "\n",
    "For at gennemføre dette vil vi bruge en kombination af:\n",
    " - `Azure Open AI` til at skabe en chatoplevelse for brugeren\n",
    " - `Microsoft Learn Catalog API` til at hjælpe brugere med at finde kurser baseret på deres forespørgsel\n",
    " - `Function Calling` til at tage brugerens forespørgsel og sende den til en funktion, der laver API-forespørgslen.\n",
    "\n",
    "Lad os starte med at se på, hvorfor vi overhovedet vil bruge funktionskald:\n",
    "\n",
    "print(\"Beskeder i næste forespørgsel:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # få et nyt svar fra GPT, hvor den kan se funktionssvaret\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hvorfor bruge Function Calling\n",
    "\n",
    "Hvis du har gennemført en anden lektion i dette kursus, forstår du sikkert allerede, hvor kraftfulde Large Language Models (LLMs) er. Forhåbentlig kan du også se nogle af deres begrænsninger.\n",
    "\n",
    "Function Calling er en funktion i Azure Open AI Service, der hjælper med at overvinde følgende begrænsninger:\n",
    "1) Ensartet svarformat\n",
    "2) Mulighed for at bruge data fra andre kilder i en applikation i en chatkontekst\n",
    "\n",
    "Før function calling var svarene fra en LLM ustrukturerede og inkonsistente. Udviklere var nødt til at skrive kompleks valideringskode for at kunne håndtere alle variationer af et svar.\n",
    "\n",
    "Brugere kunne ikke få svar som \"Hvad er vejret lige nu i Stockholm?\". Det skyldes, at modellerne kun havde adgang til data fra det tidspunkt, de blev trænet på.\n",
    "\n",
    "Lad os se på eksemplet nedenfor, som illustrerer dette problem:\n",
    "\n",
    "Lad os sige, at vi vil oprette en database med elevdata, så vi kan foreslå det rigtige kursus til dem. Nedenfor har vi to beskrivelser af elever, der minder meget om hinanden i forhold til de data, de indeholder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi vil gerne sende dette til en LLM for at analysere dataene. Dette kan senere bruges i vores applikation til at sende det til et API eller gemme det i en database.\n",
    "\n",
    "Lad os lave to identiske prompts, hvor vi instruerer LLM'en om, hvilke oplysninger vi er interesserede i:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vi ønsker at sende dette til en LLM for at analysere de dele, der er vigtige for vores produkt. Så vi kan oprette to identiske prompts for at instruere LLM'en:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efter at have oprettet disse to prompts, sender vi dem til LLM ved at bruge `openai.ChatCompletion`. Vi gemmer prompten i variablen `messages` og tildeler rollen til `user`. Dette er for at efterligne en besked fra en bruger, der bliver skrevet til en chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selvom promptene er de samme og beskrivelserne ligner hinanden, kan vi få forskellige formater af `Grades`-egenskaben.\n",
    "\n",
    "Hvis du kører ovenstående celle flere gange, kan formatet være `3.7` eller `3.7 GPA`.\n",
    "\n",
    "Det skyldes, at LLM'en tager ustrukturerede data i form af den skrevne prompt og også returnerer ustrukturerede data. Vi har brug for et struktureret format, så vi ved, hvad vi kan forvente, når vi gemmer eller bruger disse data.\n",
    "\n",
    "Ved at bruge funktionel kald kan vi sikre, at vi får strukturerede data tilbage. Når vi bruger funktionel kald, kalder eller kører LLM'en faktisk ikke nogen funktioner. I stedet laver vi en struktur, som LLM'en skal følge i sine svar. Vi bruger så de strukturerede svar til at vide, hvilken funktion vi skal køre i vores applikationer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funktionskaldsflowdiagram](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.da.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brugsscenarier for brug af funktionskald\n",
    "\n",
    "**Kald til eksterne værktøjer**  \n",
    "Chatbots er gode til at besvare brugernes spørgsmål. Ved at bruge funktionskald kan chatbots bruge beskeder fra brugerne til at udføre bestemte opgaver. For eksempel kan en studerende bede chatbotten om at \"Sende en e-mail til min underviser og sige, at jeg har brug for mere hjælp til dette emne\". Dette kan udløse et funktionskald til `send_email(to: string, body: string)`\n",
    "\n",
    "**Oprette API- eller databaseforespørgsler**  \n",
    "Brugere kan finde information ved at bruge naturligt sprog, som bliver omdannet til en formateret forespørgsel eller API-anmodning. Et eksempel kunne være en lærer, der spørger \"Hvem er de studerende, der har afleveret den sidste opgave\", hvilket kan kalde en funktion ved navn `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Oprettelse af strukturerede data**  \n",
    "Brugere kan tage et tekstafsnit eller en CSV-fil og bruge LLM til at udtrække vigtige oplysninger fra det. For eksempel kan en studerende omdanne en Wikipedia-artikel om fredsaftaler til at lave AI-flashkort. Dette kan gøres ved at bruge en funktion kaldet `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Oprettelse af dit første funktionskald\n",
    "\n",
    "Processen med at oprette et funktionskald består af 3 hovedtrin:\n",
    "1. Kald Chat Completions API'et med en liste over dine funktioner og en brugermeddelelse\n",
    "2. Læs modellens svar for at udføre en handling, dvs. køre en funktion eller et API-kald\n",
    "3. Lav endnu et kald til Chat Completions API'et med svaret fra din funktion for at bruge den information til at skabe et svar til brugeren.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow of a Function Call](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.da.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementer i et funktionskald\n",
    "\n",
    "#### Brugerinput\n",
    "\n",
    "Det første skridt er at oprette en brugermeddelelse. Dette kan gøres dynamisk ved at tage værdien fra et tekstinput, eller du kan tildele en værdi her. Hvis det er første gang, du arbejder med Chat Completions API'en, skal vi definere `role` og `content` for beskeden.\n",
    "\n",
    "`role` kan enten være `system` (opretter regler), `assistant` (modellen) eller `user` (slutbrugeren). Til funktionskald sætter vi dette til `user` og tilføjer et eksempelspørgsmål.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oprettelse af funktioner.\n",
    "\n",
    "Nu skal vi definere en funktion og dens parametre. Vi bruger kun én funktion her, som hedder `search_courses`, men du kan oprette flere funktioner.\n",
    "\n",
    "**Vigtigt**: Funktioner bliver inkluderet i systembeskeden til LLM’en og vil tælle med i det antal tokens, du har til rådighed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definitioner**\n",
    "\n",
    "`name` - Navnet på den funktion, vi ønsker skal kaldes.\n",
    "\n",
    "`description` - Dette er en beskrivelse af, hvordan funktionen fungerer. Her er det vigtigt at være specifik og tydelig.\n",
    "\n",
    "`parameters` - En liste over værdier og format, som du ønsker modellen skal give i sit svar.\n",
    "\n",
    "`type` - Datatypen, som egenskaberne vil blive gemt i.\n",
    "\n",
    "`properties` - Liste over de specifikke værdier, som modellen vil bruge i sit svar.\n",
    "\n",
    "`name` - navnet på den egenskab, som modellen vil bruge i sit formaterede svar.\n",
    "\n",
    "`type` - Datatypen for denne egenskab.\n",
    "\n",
    "`description` - Beskrivelse af den specifikke egenskab.\n",
    "\n",
    "**Valgfrit**\n",
    "\n",
    "`required` - påkrævet egenskab for at funktionskaldet kan gennemføres\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sådan foretager du funktionskald\n",
    "Når du har defineret en funktion, skal du nu inkludere den i kaldet til Chat Completion API'et. Det gør du ved at tilføje `functions` til forespørgslen. I dette tilfælde `functions=functions`.\n",
    "\n",
    "Der er også mulighed for at sætte `function_call` til `auto`. Det betyder, at vi lader LLM'en vælge, hvilken funktion der skal kaldes, baseret på brugerens besked, i stedet for at vi selv vælger det.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu lad os se på svaret og se, hvordan det er formateret:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Du kan se, at navnet på funktionen bliver kaldt, og ud fra brugerens besked kunne LLM finde dataene til at udfylde argumenterne til funktionen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrering af funktionskald i en applikation.\n",
    "\n",
    "Når vi har testet det formaterede svar fra LLM'en, kan vi nu integrere det i en applikation.\n",
    "\n",
    "### Håndtering af flowet\n",
    "\n",
    "For at integrere dette i vores applikation, lad os tage følgende skridt:\n",
    "\n",
    "Først laver vi kaldet til Open AI-tjenesterne og gemmer beskeden i en variabel kaldet `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu vil vi definere funktionen, der vil kalde Microsoft Learn API'et for at hente en liste over kurser:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Som en god praksis vil vi derefter se, om modellen ønsker at kalde en funktion. Derefter opretter vi en af de tilgængelige funktioner og matcher den til den funktion, der bliver kaldt.\n",
    "Vi tager så argumenterne fra funktionen og kobler dem til argumenterne fra LLM.\n",
    "\n",
    "Til sidst tilføjer vi beskeden om funktionskaldet og de værdier, der blev returneret af `search_courses`-beskeden. Dette giver LLM alle de oplysninger, den har brug for\n",
    "til at svare brugeren med naturligt sprog.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kodeudfordring\n",
    "\n",
    "Godt arbejde! For at fortsætte din læring om Azure Open AI Function Calling kan du bygge videre på: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Flere parametre til funktionen, som kan hjælpe brugere med at finde flere kurser. Du kan finde de tilgængelige API-parametre her:\n",
    " - Opret et andet funktionskald, der tager mere information fra brugeren, såsom deres modersmål\n",
    " - Tilføj fejlhåndtering, hvis funktionskaldet og/eller API-kaldet ikke returnerer nogen relevante kurser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, skal du være opmærksom på, at automatiske oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritisk information anbefales professionel, menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå ved brug af denne oversættelse.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:17:57+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}