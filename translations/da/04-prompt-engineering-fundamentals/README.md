<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dcbaaae026cb50fee071e690685b5843",
  "translation_date": "2025-08-26T17:29:14+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "da"
}
-->
# Grundl√¶ggende om Prompt Engineering

[![Prompt Engineering Fundamentals](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.da.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduktion
Dette modul d√¶kker vigtige begreber og teknikker til at skabe effektive prompts til generative AI-modeller. M√•den du formulerer din prompt til en LLM p√•, har ogs√• betydning. En omhyggeligt udformet prompt kan give et bedre svar. Men hvad betyder egentlig begreber som _prompt_ og _prompt engineering_? Og hvordan kan jeg forbedre det _input_, jeg sender til LLM‚Äôen? Det er de sp√∏rgsm√•l, vi pr√∏ver at besvare i dette kapitel og det n√¶ste.

_Generativ AI_ kan skabe nyt indhold (fx tekst, billeder, lyd, kode osv.) som svar p√• brugerens foresp√∏rgsler. Det sker ved hj√¶lp af _Large Language Models_ som OpenAI‚Äôs GPT-serie ("Generative Pre-trained Transformer"), der er tr√¶net til at bruge naturligt sprog og kode.

Brugere kan nu interagere med disse modeller via velkendte chat-lignende gr√¶nseflader, uden at have teknisk viden eller tr√¶ning. Modellerne er _prompt-baserede_ ‚Äì brugeren sender en tekst (prompt) og f√•r et AI-svar (completion) tilbage. Man kan s√• "chatte med AI‚Äôen" i flere omgange, og forfine sin prompt, indtil svaret matcher ens forventninger.

"Prompts" er nu den prim√¶re _programmeringsgr√¶nseflade_ for generative AI-apps, der fort√¶ller modellerne, hvad de skal g√∏re, og p√•virker kvaliteten af de svar, der kommer retur. "Prompt Engineering" er et hurtigt voksende felt, der fokuserer p√• _design og optimering_ af prompts for at levere konsistente og kvalitetspr√¶gede svar i stor skala.

## L√¶ringsm√•l

I denne lektion l√¶rer vi, hvad Prompt Engineering er, hvorfor det er vigtigt, og hvordan vi kan udforme mere effektive prompts til en given model og et bestemt form√•l. Vi f√•r styr p√• centrale begreber og bedste praksis for prompt engineering ‚Äì og l√¶rer om et interaktivt Jupyter Notebook "sandbox"-milj√∏, hvor vi kan se disse begreber anvendt p√• rigtige eksempler.

N√•r du er f√¶rdig med denne lektion, kan du:

1. Forklare hvad prompt engineering er, og hvorfor det er vigtigt.
2. Beskrive komponenterne i en prompt og hvordan de bruges.
3. L√¶re bedste praksis og teknikker for prompt engineering.
4. Anvende de l√¶rte teknikker p√• rigtige eksempler, via et OpenAI-endpoint.

## Centrale begreber

Prompt Engineering: Praksis med at designe og forfine input for at guide AI-modeller til at producere √∏nskede output.
Tokenisering: Processen hvor tekst omdannes til mindre enheder, kaldet tokens, som en model kan forst√• og behandle.
Instruction-Tuned LLMs: Store sprogmodeller (LLMs), der er finjusteret med specifikke instruktioner for at forbedre n√∏jagtighed og relevans i deres svar.

## Learning Sandbox

Prompt engineering er i dag mere en kunst end en videnskab. Den bedste m√•de at styrke sin intuition p√• er at _√∏ve sig_ og bruge en trial-and-error tilgang, hvor man kombinerer dom√¶neviden med anbefalede teknikker og model-specifikke optimeringer.

Jupyter Notebooken, der h√∏rer til denne lektion, giver dig et _sandbox_-milj√∏, hvor du kan afpr√∏ve det, du l√¶rer ‚Äì enten l√∏bende eller som en del af kodeudfordringen til sidst. For at kunne udf√∏re √∏velserne skal du bruge:

1. **En Azure OpenAI API-n√∏gle** ‚Äì service-endpoint for en udrullet LLM.
2. **Et Python-milj√∏** ‚Äì hvor Notebooken kan k√∏res.
3. **Lokale milj√∏variabler** ‚Äì _f√∏lg [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) trinnene nu, s√• du er klar_.

Notebooken indeholder _start√∏velser_ ‚Äì men du opfordres til at tilf√∏je dine egne _Markdown_- (beskrivelse) og _Code_- (prompt-foresp√∏rgsler) sektioner for at pr√∏ve flere eksempler eller id√©er ‚Äì og styrke din intuition for prompt-design.

## Illustreret guide

Vil du have et overblik over, hvad denne lektion d√¶kker, f√∏r du g√•r i gang? Tjek denne illustrerede guide, som giver dig et indtryk af de vigtigste emner og pointer, du skal t√¶nke over. Lektionens roadmap tager dig fra at forst√• de centrale begreber og udfordringer til at tackle dem med relevante prompt engineering-teknikker og bedste praksis. Bem√¶rk, at afsnittet "Advanced Techniques" i guiden refererer til indhold, der d√¶kkes i _n√¶ste_ kapitel af dette kursus.

![Illustrated Guide to Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.da.png)

## Vores startup

Lad os nu se p√•, hvordan _dette emne_ h√¶nger sammen med vores startup-mission om at [bringe AI-innovation til uddannelse](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi vil bygge AI-drevne applikationer til _personlig l√¶ring_ ‚Äì s√• lad os t√¶nke over, hvordan forskellige brugere af vores app kan "designe" prompts:

- **Administratorer** kan bede AI‚Äôen om at _analysere l√¶seplansdata for at finde huller i d√¶kningen_. AI‚Äôen kan opsummere resultater eller visualisere dem med kode.
- **Undervisere** kan bede AI‚Äôen om at _generere en lektionsplan til en bestemt m√•lgruppe og emne_. AI‚Äôen kan bygge den personlige plan i et √∏nsket format.
- **Studerende** kan bede AI‚Äôen om at _hj√¶lpe dem med et sv√¶rt fag_. AI‚Äôen kan nu guide dem med lektioner, hints og eksempler tilpasset deres niveau.

Det er kun begyndelsen. Tjek [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì et open source-bibliotek med prompts, kurateret af uddannelseseksperter ‚Äì for at f√• et bredere indblik i mulighederne! _Pr√∏v at k√∏re nogle af disse prompts i sandkassen eller via OpenAI Playground og se, hvad der sker!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Hvad er Prompt Engineering?

Vi startede denne lektion med at definere **Prompt Engineering** som processen med at _designe og optimere_ tekstinput (prompts) for at levere konsistente og kvalitetspr√¶gede svar (completions) til et givent form√•l og en bestemt model. Man kan se det som en 2-trins proces:

- _designe_ den f√∏rste prompt til en given model og form√•l
- _forfine_ prompten l√∏bende for at forbedre kvaliteten af svaret

Det er n√∏dvendigvis en trial-and-error proces, der kr√¶ver brugerens intuition og indsats for at opn√• optimale resultater. Men hvorfor er det vigtigt? For at svare p√• det, skal vi f√∏rst forst√• tre begreber:

- _Tokenisering_ = hvordan modellen "ser" prompten
- _Base LLMs_ = hvordan grundmodellen "behandler" en prompt
- _Instruction-Tuned LLMs_ = hvordan modellen nu kan se "opgaver"

### Tokenisering

En LLM ser prompts som en _sekvens af tokens_, hvor forskellige modeller (eller versioner af en model) kan tokenisere den samme prompt p√• forskellige m√•der. Da LLMs er tr√¶net p√• tokens (og ikke p√• r√• tekst), har m√•den prompts tokeniseres p√• direkte indflydelse p√• kvaliteten af det genererede svar.

Vil du have en fornemmelse af, hvordan tokenisering fungerer? Pr√∏v v√¶rkt√∏jer som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) herunder. Kopi√©r din prompt ind ‚Äì og se, hvordan den bliver omdannet til tokens, og l√¶g m√¶rke til, hvordan mellemrum og tegns√¶tning h√•ndteres. Bem√¶rk, at dette eksempel viser en √¶ldre LLM (GPT-3) ‚Äì s√• hvis du pr√∏ver med en nyere model, kan resultatet v√¶re anderledes.

![Tokenization](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.da.png)

### Begreb: Foundation Models

N√•r en prompt er tokeniseret, er hovedfunktionen for ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller Foundation model) at forudsige det n√¶ste token i sekvensen. Da LLMs er tr√¶net p√• enorme tekstm√¶ngder, har de et godt kendskab til de statistiske relationer mellem tokens og kan lave den forudsigelse med en vis sikkerhed. Bem√¶rk, at de ikke forst√•r _betydningen_ af ordene i prompten eller tokenet; de ser bare et m√∏nster, de kan "fuldf√∏re" med deres n√¶ste forudsigelse. De kan forts√¶tte med at forudsige sekvensen, indtil brugeren stopper dem eller en forudbestemt betingelse er opfyldt.

Vil du se, hvordan prompt-baseret completion fungerer? Indtast ovenst√•ende prompt i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardindstillingerne. Systemet er sat op til at behandle prompts som informationsforesp√∏rgsler ‚Äì s√• du b√∏r se et svar, der matcher denne kontekst.

Men hvad hvis brugeren vil se noget specifikt, der opfylder et bestemt kriterium eller opgave? Her kommer _instruction-tuned_ LLMs ind i billedet.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.da.png)

### Begreb: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grundmodellen og finjusterer den med eksempler eller input/output-par (fx multi-turn "messages"), der kan indeholde klare instruktioner ‚Äì og AI‚Äôens svar fors√∏ger at f√∏lge den instruktion.

Her bruges teknikker som Reinforcement Learning with Human Feedback (RLHF), der kan tr√¶ne modellen til at _f√∏lge instruktioner_ og _l√¶re af feedback_, s√• den leverer svar, der er bedre egnet til praktiske anvendelser og mere relevante for brugerens m√•l.

Lad os pr√∏ve det ‚Äì g√• tilbage til prompten ovenfor, men √¶ndr nu _systembeskeden_ til at give f√∏lgende instruktion som kontekst:

> _Opsummer det indhold, du f√•r, for en elev i 2. klasse. Hold resultatet til √©t afsnit med 3-5 punktform._

Se hvordan resultatet nu er tilpasset det √∏nskede m√•l og format? En underviser kan nu direkte bruge dette svar i sine slides til klassen.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.da.png)

## Hvorfor har vi brug for Prompt Engineering?

Nu hvor vi ved, hvordan prompts behandles af LLMs, lad os tale om _hvorfor_ vi har brug for prompt engineering. Svaret ligger i, at de nuv√¶rende LLMs har en r√¶kke udfordringer, der g√∏r det _sv√¶rere at f√• p√•lidelige og konsistente svar_ uden at l√¶gge arbejde i promptens opbygning og optimering. For eksempel:

1. **Modellens svar er stokastiske.** Den _samme prompt_ vil sandsynligvis give forskellige svar med forskellige modeller eller modelversioner. Og den kan endda give forskellige resultater med _samme model_ p√• forskellige tidspunkter. _Prompt engineering-teknikker kan hj√¶lpe med at minimere disse variationer ved at give bedre rammer._

1. **Modeller kan opfinde svar.** Modellerne er tr√¶net p√• _store, men begr√¶nsede_ datas√¶t, hvilket betyder, at de mangler viden om emner uden for tr√¶ningsdataene. Derfor kan de generere svar, der er un√∏jagtige, opdigtede eller direkte modstridende med kendte fakta. _Prompt engineering-teknikker hj√¶lper brugere med at identificere og afb√∏de s√•danne opdigtede svar, fx ved at bede AI‚Äôen om kilder eller begrundelser._

1. **Modellernes evner varierer.** Nyere modeller eller generationer har flere funktioner, men kan ogs√• have s√¶rlige s√¶rheder og kompromiser i pris og kompleksitet. _Prompt engineering kan hj√¶lpe med at udvikle bedste praksis og arbejdsgange, der abstraherer forskellene og tilpasser sig model-specifikke krav p√• en skalerbar og smidig m√•de._

Lad os se det i praksis i OpenAI eller Azure OpenAI Playground:

- Brug den samme prompt med forskellige LLM-udrulninger (fx OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√• du variationerne?
- Brug den samme prompt gentagne gange med _samme_ LLM-udrulning (fx Azure OpenAI playground) ‚Äì hvordan adskilte disse variationer sig?

### Eksempel p√• opdigtede svar

I dette kursus bruger vi begrebet **"opdigtning"** om det f√¶nomen, hvor LLMs nogle gange genererer faktuelt forkerte oplysninger p√• grund af begr√¶nsninger i deres tr√¶ning eller andre forhold. Du har m√•ske ogs√• h√∏rt det omtalt som _"hallucinationer"_ i artikler eller forskningspapirer. Vi anbefaler dog at bruge _"opdigtning"_ som begreb, s√• vi undg√•r at till√¶gge maskinen menneskelige egenskaber. Det underst√∏tter ogs√• [Responsible AI guidelines](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologisk perspektiv, og fjerner ord, der kan opfattes som st√∏dende eller ikke-inkluderende i visse sammenh√¶nge.

Vil du se, hvordan opdigtede svar opst√•r? T√¶nk p√• en prompt, der instruerer AI‚Äôen i at generere indhold om et ikke-eksisterende emne (s√• det ikke findes i tr√¶ningsdataene). For eksempel ‚Äì jeg pr√∏vede denne prompt:
# Undervisningsplan: Den Marsianske Krig i 2076

## Introduktion
Denne lektion vil d√¶kke de vigtigste begivenheder, √•rsager og konsekvenser af Den Marsianske Krig i 2076. Eleverne vil unders√∏ge, hvordan konflikten opstod, hvilke parter der var involveret, og hvordan krigen p√•virkede b√•de Mars og Jorden.

## L√¶ringsm√•l
- Forst√• de politiske og √∏konomiske √•rsager til krigen
- Identificere de vigtigste akt√∏rer og deres motivationer
- Analysere krigens forl√∏b og dens indflydelse p√• samfundet
- Diskutere de langsigtede konsekvenser for Mars og Jorden

## Materialer
- Tidslinje over krigens begivenheder
- Kort over Mars og de vigtigste kolonier
- √òjenvidneberetninger og prim√¶re kilder
- Artikler om teknologiske fremskridt under krigen

## Lektionens forl√∏b

### 1. Opvarmning (10 minutter)
- Kort diskussion: Hvad ved vi om Mars og dens kolonier?
- Brainstorm: Hvorfor kan der opst√• konflikter mellem kolonier og moderplaneter?

### 2. Baggrund og √•rsager (15 minutter)
- Gennemgang af de politiske sp√¶ndinger mellem Mars og Jorden
- Diskussion af ressourcemangel, selvst√¶ndighedsbev√¶gelser og teknologisk udvikling

### 3. Krigens forl√∏b (20 minutter)
- Pr√¶sentation af de vigtigste slag og strategier
- Analyse af de involverede parter: Mars‚Äô uafh√¶ngighedsbev√¶gelse, Jordens koalition, og neutrale kolonier
- L√¶sning af √∏jenvidneberetninger

### 4. Konsekvenser og efterspil (15 minutter)
- Diskussion af de sociale og √∏konomiske √¶ndringer p√• Mars
- Hvordan krigen √¶ndrede forholdet mellem Mars og Jorden
- Langsigtede effekter p√• teknologi og politik

### 5. Refleksion og debat (10 minutter)
- Eleverne diskuterer: Kunne krigen v√¶re undg√•et? Hvilke alternativer fandtes?
- Skriftlig refleksion: Hvilken indflydelse har krigen haft p√• fremtidens rumfart?

## Evaluering
- Deltagelse i diskussioner
- Kort skriftlig opgave om krigens betydning
- Gruppearbejde: Udarbejd en alternativ slutning p√• konflikten

## Ekstra ressourcer
- Links til dokumentarer og artikler om Mars‚Äô historie
- Forslag til videre l√¶sning om interplanetarisk politik

---

*Kommentar: Denne undervisningsplan kan tilpasses forskellige klassetrin og faglige niveauer. Brug gerne kreative opgaver for at engagere eleverne i emnet.*
Et web-s√∏gning viste mig, at der findes fiktive beretninger (fx tv-serier eller b√∏ger) om krige p√• Mars ‚Äì men ingen i 2076. Sund fornuft fort√¶ller os ogs√•, at 2076 ligger _i fremtiden_ og derfor ikke kan forbindes med en virkelig begivenhed.

S√• hvad sker der, n√•r vi k√∏rer denne prompt med forskellige LLM-udbydere?

> **Svar 1**: OpenAI Playground (GPT-35)

![Svar 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.da.png)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Svar 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.da.png)

> **Svar 3**: Hugging Face Chat Playground (LLama-2)

![Svar 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.da.png)

Som forventet giver hver model (eller modelversion) lidt forskellige svar p√• grund af stokastisk adf√¶rd og variationer i modellernes evner. For eksempel retter √©n model sig mod et publikum p√• 8. klassetrin, mens en anden antager, at brugeren er gymnasieelev. Men alle tre modeller genererede svar, der kunne overbevise en uinformeret bruger om, at begivenheden var virkelig.

Prompt engineering-teknikker som _metaprompting_ og _temperaturindstilling_ kan til en vis grad mindske modellens opfindsomhed. Nye prompt engineering-_arkitekturer_ integrerer ogs√• nye v√¶rkt√∏jer og teknikker direkte i prompt-flowet for at afb√∏de eller reducere nogle af disse effekter.

## Case Study: GitHub Copilot

Lad os afslutte dette afsnit med at f√• en fornemmelse af, hvordan prompt engineering bruges i virkelige l√∏sninger ved at se p√• et case study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI Pair Programmer" ‚Äì den oms√¶tter tekstprompter til kodeforslag og er integreret i dit udviklingsmilj√∏ (fx Visual Studio Code) for en gnidningsfri brugeroplevelse. Som dokumenteret i blogserien nedenfor, var den tidligste version baseret p√• OpenAI Codex-modellen ‚Äì hvor ingeni√∏rerne hurtigt inds√• behovet for at finjustere modellen og udvikle bedre prompt engineering-teknikker for at forbedre kodekvaliteten. I juli [introducerede de en forbedret AI-model, der g√•r ud over Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for endnu hurtigere forslag.

L√¶s indl√¶ggene i r√¶kkef√∏lge for at f√∏lge deres l√¶ringsrejse.

- **Maj 2023** | [GitHub Copilot bliver bedre til at forst√• din kode](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inde i GitHub: Arbejde med LLM'erne bag GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juni 2023** | [S√•dan skriver du bedre prompts til GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juli 2023** | [.. GitHub Copilot g√•r ud over Codex med forbedret AI-model](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [En udviklers guide til Prompt Engineering og LLM'er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **September 2023** | [S√•dan bygger du en enterprise LLM-app: L√¶rdom fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• gennemse deres [Engineering-blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere indl√¶g som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), der viser, hvordan disse modeller og teknikker _anvendes_ til at drive virkelige applikationer.

---

## Promptkonstruktion

Vi har set, hvorfor prompt engineering er vigtigt ‚Äì nu skal vi forst√•, hvordan prompts _konstrueres_, s√• vi kan vurdere forskellige teknikker for mere effektiv promptdesign.

### Grundl√¶ggende prompt

Lad os starte med den grundl√¶ggende prompt: en tekstinput sendt til modellen uden anden kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste par ord af den amerikanske nationalsang til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), _fuldender_ den straks svaret med de n√¶ste linjer, hvilket illustrerer den grundl√¶ggende forudsigelsesadf√¶rd.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det lyder som om du starter teksten til "The Star-Spangled Banner", USA's nationalsang. Hele teksten er ... |

### Kompleks prompt

Nu tilf√∏jer vi kontekst og instruktioner til den grundl√¶ggende prompt. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) lader os konstruere en kompleks prompt som en samling af _beskeder_ med:

- Input/output-par, der afspejler _brugerinput_ og _assistentens_ svar.
- Systembesked, der s√¶tter konteksten for assistentens adf√¶rd eller personlighed.

Foresp√∏rgslen har nu nedenst√•ende form, hvor _tokeniseringen_ effektivt indfanger relevant information fra kontekst og samtale. Nu kan √¶ndring af systemkonteksten have lige s√• stor indflydelse p√• kvaliteten af svarene som de brugerinput, der gives.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I eksemplerne ovenfor var brugerens prompt en simpel tekstforesp√∏rgsel, der kan tolkes som en anmodning om information. Med _instruktionsprompter_ kan vi bruge teksten til at specificere en opgave mere detaljeret og give AI'en bedre vejledning. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruction Type    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivelse af Borgerkrigen                                                                                                                                                                                                   | _returnerede et simpelt afsnit_                                                                                           | Simpel              |
| Skriv en beskrivelse af Borgerkrigen. Angiv vigtige datoer og begivenheder og beskriv deres betydning                                                                                                                                  | _returnerede et afsnit efterfulgt af en liste med vigtige datoer og beskrivelser_                                         | Kompleks             |
| Skriv en beskrivelse af Borgerkrigen i 1 afsnit. Giv 3 punktnedslag med vigtige datoer og deres betydning. Giv 3 yderligere punktnedslag med vigtige historiske personer og deres bidrag. Return√©r outputtet som en JSON-fil             | _returnerer mere omfattende detaljer i en tekstboks, formateret som JSON, som du kan kopiere og validere efter behov_     | Kompleks. Formateret. |

## Prim√¶rt indhold

I eksemplerne ovenfor var prompten stadig ret √•ben, hvilket lod LLM'en bestemme, hvilken del af dens fortr√¶nede datas√¶t der var relevant. Med _prim√¶rt indhold_-designet opdeles inputteksten i to dele:

- en instruktion (handling)
- relevant indhold (der p√•virker handlingen)

Her er et eksempel, hvor instruktionen er "opsummer dette i 2 s√¶tninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gask√¶mpe med en masse p√• en tusindedel af Solens, men to og en halv gange s√• stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og har v√¶ret kendt af oldtidens civilisationer siden f√∏r historisk tid. Den er opkaldt efter den romerske gud Jupiter.[19] Set fra Jorden kan Jupiter v√¶re s√• lysst√¶rk, at dens reflekterede lys kan kaste synlige skygger,[20] og den er i gennemsnit det tredjeklareste naturlige objekt p√• nattehimlen efter M√•nen og Venus. <br/> **Opsummer dette i 2 korte s√¶tninger** | Jupiter, den femte planet fra Solen, er den st√∏rste i Solsystemet og kendt for at v√¶re et af de klareste objekter p√• nattehimlen. Opkaldt efter den romerske gud Jupiter, er det en gask√¶mpe, hvis masse er to og en halv gange st√∏rre end alle de andre planeter tilsammen. |

Segmentet med prim√¶rt indhold kan bruges p√• forskellige m√•der til at skabe mere effektive instruktioner:

- **Eksempler** ‚Äì i stedet for at fort√¶lle modellen, hvad den skal g√∏re med en eksplicit instruktion, giver du den eksempler p√•, hvad den skal g√∏re, og lader den udlede m√∏nsteret.
- **Cues** ‚Äì f√∏lg instruktionen med et "cue", der primet svaret og guider modellen mod mere relevante svar.
- **Skabeloner** ‚Äì dette er gentagelige 'opskrifter' p√• prompts med pladsholdere (variabler), der kan tilpasses med data til specifikke brugsscenarier.

Lad os se n√¶rmere p√• disse i praksis.

### Brug af eksempler

Dette er en tilgang, hvor du bruger det prim√¶re indhold til at "fodre modellen" med nogle eksempler p√• det √∏nskede output for en given instruktion og lader den udlede m√∏nsteret for det √∏nskede output. Afh√¶ngigt af antallet af eksempler kan vi have zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r nu af tre komponenter:

- En opgavebeskrivelse
- Et par eksempler p√• det √∏nskede output
- Starten p√• et nyt eksempel (som bliver en implicit opgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot   | "The Sun is Shining". Translate to Spanish                                                                                                            | "El Sol est√° brillando".    |
| One-shot    | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot    | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk => | Basketball                  |
|             |                                                                                                                                                       |                             |

Bem√¶rk, hvordan vi m√•tte give en eksplicit instruktion ("Translate to Spanish") i zero-shot prompting, men at den bliver udledt i one-shot eksemplet. Few-shot eksemplet viser, hvordan flere eksempler g√∏r det muligt for modeller at lave mere pr√¶cise udledninger uden ekstra instruktioner.

### Prompt-cues

En anden teknik til at bruge prim√¶rt indhold er at give _cues_ i stedet for eksempler. Her giver vi modellen et skub i den rigtige retning ved at _starte den_ med et uddrag, der afspejler det √∏nskede svarformat. Modellen "tager cue'et" og forts√¶tter i samme stil.

| Antal cues | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0          | Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gask√¶mpe med en masse p√• en tusindedel af Solens, men to og en halv gange s√• stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og har v√¶ret kendt af oldtidens civilisationer siden f√∏r historisk tid.

**Opsummer dette**                                       | Jupiter er den st√∏rste planet i vores solsystem og den femte fra Solen. Det er en gask√¶mpe med en masse p√• 1/1000 af Solens, men den er tungere end alle de andre planeter tilsammen. Gamle civilisationer har kendt til Jupiter i lang tid, og den er let synlig p√• nattehimlen. |
| 1              | Jupiter er den femte planet fra Solen og den st√∏rste i solsystemet. Det er en gask√¶mpe med en masse p√• en tusindedel af Solens, men to og en halv gange s√• stor som alle de andre planeter i solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og har v√¶ret kendt af gamle civilisationer siden f√∏r historisk tid. <br/>**Opsummer dette** <br/> Det vi har l√¶rt er, at Jupiter | er den femte planet fra Solen og den st√∏rste i solsystemet. Det er en gask√¶mpe med en masse p√• en tusindedel af Solens, men to og en halv gange s√• stor som alle de andre planeter tilsammen. Den er let synlig med det blotte √∏je og har v√¶ret kendt siden oldtiden.                        |
| 2              | Jupiter er den femte planet fra Solen og den st√∏rste i solsystemet. Det er en gask√¶mpe med en masse p√• en tusindedel af Solens, men to og en halv gange s√• stor som alle de andre planeter i solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og har v√¶ret kendt af gamle civilisationer siden f√∏r historisk tid. <br/>**Opsummer dette** <br/> Top 3 ting vi l√¶rte:         | 1. Jupiter er den femte planet fra Solen og den st√∏rste i solsystemet. <br/> 2. Det er en gask√¶mpe med en masse p√• en tusindedel af Solens...<br/> 3. Jupiter har v√¶ret synlig med det blotte √∏je siden oldtiden ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Promptskabeloner

En promptskabelon er en _foruddefineret opskrift p√• en prompt_, som kan gemmes og genbruges efter behov for at skabe mere ensartede brugeroplevelser i stor skala. I sin simpleste form er det blot en samling af prompteksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), der b√•de indeholder de interaktive promptkomponenter (bruger- og systembeskeder) og det API-drevne foresp√∏rgselsformat ‚Äì for at underst√∏tte genbrug.

I en mere kompleks form som [dette eksempel fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) indeholder den _pladsholdere_, der kan udskiftes med data fra forskellige kilder (brugerinput, systemkontekst, eksterne datakilder osv.) for at generere en prompt dynamisk. Det g√∏r det muligt at oprette et bibliotek af genanvendelige prompts, der kan bruges til at skabe ensartede brugeroplevelser **programmatisk** i stor skala.

Den reelle v√¶rdi af skabeloner ligger dog i muligheden for at oprette og udgive _promptbiblioteker_ til specifikke anvendelsesomr√•der ‚Äì hvor promptskabelonen nu er _optimeret_ til at afspejle applikationsspecifik kontekst eller eksempler, der g√∏r svarene mere relevante og pr√¶cise for den tilt√¶nkte brugergruppe. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) er et godt eksempel p√• denne tilgang, hvor der samles et bibliotek af prompts til uddannelsesomr√•det med fokus p√• n√∏glem√•l som lektionsplanl√¶gning, l√¶seplansdesign, elevvejledning osv.

## Underst√∏ttende indhold

Hvis vi t√¶nker p√• promptkonstruktion som at have en instruktion (opgave) og et m√•l (prim√¶rt indhold), s√• er _sekund√¶rt indhold_ som ekstra kontekst, vi giver for at **p√•virke outputtet p√• en eller anden m√•de**. Det kan v√¶re justeringsparametre, formateringsinstruktioner, emnetaksonomier osv., der kan hj√¶lpe modellen med at _tilpasse_ sit svar, s√• det passer til de √∏nskede brugerbehov eller forventninger.

For eksempel: Givet et kursuskatalog med omfattende metadata (navn, beskrivelse, niveau, metadatatags, underviser osv.) p√• alle tilg√¶ngelige kurser i l√¶seplanen:

- kan vi definere en instruktion om at "opsummere kursuskataloget for efter√•ret 2023"
- vi kan bruge det prim√¶re indhold til at give et par eksempler p√• det √∏nskede output
- vi kan bruge det sekund√¶re indhold til at identificere de 5 vigtigste "tags" af interesse.

Nu kan modellen give et resum√© i det format, der vises i eksemplerne ‚Äì men hvis et resultat har flere tags, kan den prioritere de 5 tags, der er identificeret i det sekund√¶re indhold.

---

<!--
LEKTIONSKABELON:
Denne enhed skal d√¶kke kernekoncept #1.
Underst√∏t konceptet med eksempler og referencer.

KONCEPT #3:
Prompt Engineering-teknikker.
Hvilke grundl√¶ggende teknikker findes der til prompt engineering?
Illustrer det med nogle √∏velser.
-->

## Bedste praksis for prompt engineering

Nu hvor vi ved, hvordan prompts kan _konstrueres_, kan vi begynde at t√¶nke over, hvordan vi _designer_ dem, s√• de afspejler bedste praksis. Vi kan t√¶nke p√• det i to dele ‚Äì at have den rette _tankegang_ og at anvende de rette _teknikker_.

### Tankegang for prompt engineering

Prompt engineering er en proces med fors√∏g og fejl, s√• husk tre brede retningslinjer:

1. **Dom√¶neforst√•else er vigtig.** Svarkvalitet og relevans afh√¶nger af det _dom√¶ne_, som applikationen eller brugeren arbejder i. Brug din intuition og dom√¶neekspertise til at **tilpasse teknikker** yderligere. For eksempel kan du definere _dom√¶nespecifikke personligheder_ i dine systemprompts eller bruge _dom√¶nespecifikke skabeloner_ i dine brugerprompts. Giv sekund√¶rt indhold, der afspejler dom√¶nespecifik kontekst, eller brug _dom√¶nespecifikke cues og eksempler_ til at guide modellen mod velkendte brugsm√∏nstre.

2. **Model-forst√•else er vigtig.** Vi ved, at modeller er stokastiske af natur. Men modelimplementeringer kan ogs√• variere i forhold til det tr√¶ningsdatas√¶t, de bruger (forudtr√¶net viden), de funktioner, de tilbyder (f.eks. via API eller SDK), og den type indhold, de er optimeret til (f.eks. kode vs. billeder vs. tekst). Forst√• styrker og begr√¶nsninger ved den model, du bruger, og brug den viden til at _prioritere opgaver_ eller bygge _tilpassede skabeloner_, der er optimeret til modellens evner.

3. **Iteration & validering er vigtig.** Modeller udvikler sig hurtigt, og det samme g√∏r teknikkerne til prompt engineering. Som dom√¶neekspert kan du have anden kontekst eller kriterier for _din_ specifikke applikation, som ikke g√¶lder for det brede f√¶llesskab. Brug prompt engineering-v√¶rkt√∏jer og -teknikker til at "kickstarte" promptkonstruktionen, og iterer og valider resultaterne med din egen intuition og dom√¶neviden. Not√©r dine indsigter og opret en **vidensbase** (f.eks. promptbiblioteker), som andre kan bruge som nyt udgangspunkt for hurtigere iterationer i fremtiden.

## Bedste praksis

Lad os nu se p√• almindelige bedste praksisser, der anbefales af [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst)-praktikere.

| Hvad                              | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Evaluer de nyeste modeller.       | Nye modelgenerationer har sandsynligvis forbedrede funktioner og kvalitet ‚Äì men kan ogs√• v√¶re dyrere. Vurder dem for effekt, og tag derefter beslutning om at migrere.                                                                                |
| Adskil instruktioner & kontekst   | Tjek om din model/udbyder definerer _afgr√¶nsere_ til tydeligere at adskille instruktioner, prim√¶rt og sekund√¶rt indhold. Det kan hj√¶lpe modeller med at tildele v√¶gt mere pr√¶cist til tokens.                                                         |
| V√¶r specifik og tydelig           | Giv flere detaljer om √∏nsket kontekst, resultat, l√¶ngde, format, stil osv. Det vil forbedre b√•de kvaliteten og konsistensen af svarene. Gem opskrifter i genanvendelige skabeloner.                                                                  |
| V√¶r beskrivende, brug eksempler   | Modeller reagerer ofte bedre p√• en "vis og fort√¶l"-tilgang. Start med en `zero-shot` tilgang, hvor du kun giver en instruktion (men ingen eksempler), og pr√∏v derefter `few-shot` som en forbedring, hvor du giver et par eksempler p√• √∏nsket output. Brug analogier. |
| Brug cues til at kickstarte svar  | Skub modellen i retning af et √∏nsket resultat ved at give den nogle indledende ord eller s√¶tninger, den kan bruge som udgangspunkt for svaret.                                                                                                         |
| Gentag instruktioner              | Nogle gange skal du gentage dig selv over for modellen. Giv instruktioner f√∏r og efter dit prim√¶re indhold, brug en instruktion og et cue osv. Iterer og valider for at se, hvad der virker.                                                          |
| R√¶kkef√∏lge betyder noget          | Den r√¶kkef√∏lge, du pr√¶senterer information for modellen i, kan p√•virke outputtet, selv i l√¶ringseksempler, p√• grund af recency bias. Pr√∏v forskellige muligheder for at se, hvad der fungerer bedst.                                                   |
| Giv modellen en ‚Äúudvej‚Äù           | Giv modellen et _fallback_-svar, den kan give, hvis den ikke kan l√∏se opgaven af en eller anden grund. Det kan mindske risikoen for, at modellen genererer forkerte eller opdigtede svar.                                                             |
|                                   |                                                                                                                                                                                                                                                       |

Som med enhver bedste praksis g√¶lder det, at _dine resultater kan variere_ afh√¶ngigt af model, opgave og dom√¶ne. Brug disse som udgangspunkt, og iterer for at finde det, der fungerer bedst for dig. Genovervej l√∏bende din prompt engineering-proces, efterh√•nden som nye modeller og v√¶rkt√∏jer bliver tilg√¶ngelige, med fokus p√• skalerbarhed og svarkvalitet.

<!--
LEKTIONSKABELON:
Denne enhed skal give en kodeudfordring, hvis det er relevant

UDFORDRING:
Link til en Jupyter Notebook med kun kodekommentarer i instruktionerne (kodestykker er tomme).

L√òSNING:
Link til en kopi af den Notebook med prompts udfyldt og k√∏rt, s√• man kan se et eksempel.
-->

## Opgave

Tillykke! Du er n√•et til slutningen af lektionen! Nu er det tid til at afpr√∏ve nogle af de koncepter og teknikker med rigtige eksempler!

Til denne opgave bruger vi en Jupyter Notebook med √∏velser, du kan l√∏se interaktivt. Du kan ogs√• udvide Notebooken med dine egne Markdown- og kodeceller for at udforske id√©er og teknikker p√• egen h√•nd.

### For at komme i gang, s√• fork repoet, og

- (Anbefalet) Start GitHub Codespaces
- (Alternativt) Klon repoet til din lokale enhed og brug det med Docker Desktop
- (Alternativt) √Öbn Notebooken med din foretrukne Notebook-runtime.

### Konfigurer derefter dine milj√∏variabler

- Kopi√©r `.env.copy`-filen i repo-roden til `.env` og udfyld `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. G√• tilbage til [Learning Sandbox-sektionen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) for at l√¶re hvordan.

### √Öbn derefter Jupyter Notebooken

- V√¶lg runtime-kernen. Hvis du bruger mulighed 1 eller 2, skal du blot v√¶lge standard Python 3.10.x-kernen, som dev-containeren leverer.

Nu er du klar til at k√∏re √∏velserne. Bem√¶rk, at der ikke er _rigtige eller forkerte_ svar her ‚Äì det handler om at udforske muligheder gennem fors√∏g og fejl og opbygge intuition for, hvad der virker for en given model og applikationsdom√¶ne.

_Derfor er der ingen kode-l√∏sningsafsnit i denne lektion. I stedet vil Notebooken have Markdown-celler med titlen "Min l√∏sning:", der viser et eksempeloutput til reference._

 <!--
LEKTIONSKABELON:
Afslut afsnittet med et resum√© og ressourcer til selvstudium.
-->

## Videnscheck

Hvilken af f√∏lgende er en god prompt, der f√∏lger nogle rimelige bedste praksisser?

1. Vis mig et billede af en r√∏d bil
2. Vis mig et billede af en r√∏d bil af m√¶rket Volvo og model XC90 parkeret ved en klippe med solen, der g√•r ned
3. Vis mig et billede af en r√∏d bil af m√¶rket Volvo og model XC90

A: 2, det er den bedste prompt, da den giver detaljer om "hvad" og g√•r i dybden (ikke bare en hvilken som helst bil, men et bestemt m√¶rke og model) og beskriver ogs√• den overordnede scene. 3 er n√¶stbedst, da den ogs√• indeholder mange beskrivelser.

## üöÄ Udfordring

Se om du kan bruge "cue"-teknikken med prompten: Fuldf√∏r s√¶tningen "Vis mig et billede af en r√∏d bil af m√¶rket Volvo og ". Hvad svarer den med, og hvordan ville du forbedre det?

## Godt arbejde! Forts√¶t din l√¶ring

Vil du l√¶re mere om forskellige Prompt Engineering-koncepter? G√• til [siden for videre l√¶ring](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at finde flere gode ressourcer om dette emne.

G√• videre til Lektion 5, hvor vi ser p√• [avancerede prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritiske oplysninger anbefales professionel menneskelig overs√¶ttelse. Vi er ikke ansvarlige for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.