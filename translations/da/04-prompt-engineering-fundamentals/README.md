# Grundl√¶ggende om Prompt Engineering

[![Prompt Engineering Fundamentals](../../../translated_images/da/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introduktion
Dette modul d√¶kker v√¶sentlige begreber og teknikker til at skabe effektive prompts i generative AI-modeller. M√•den, du skriver din prompt til en LLM, betyder ogs√• noget. En omhyggeligt udformet prompt kan opn√• en bedre kvalitet af svar. Men hvad betyder begreber som _prompt_ og _prompt engineering_ egentlig? Og hvordan forbedrer jeg prompt _inputtet_, som jeg sender til LLM'en? Det er de sp√∏rgsm√•l, vi vil fors√∏ge at besvare i dette kapitel og det n√¶ste.

_Generativ AI_ er i stand til at skabe nyt indhold (f.eks. tekst, billeder, lyd, kode osv.) som respons p√• brugerforesp√∏rgsler. Det opn√•s ved hj√¶lp af _Large Language Models_ som OpenAIs GPT ("Generative Pre-trained Transformer") serie, der er tr√¶net til brug af naturligt sprog og kode.

Brugere kan nu interagere med disse modeller ved brug af velkendte paradigmer som chat uden behov for teknisk ekspertise eller tr√¶ning. Modellerne er _prompt-baserede_ - brugere sender en tekstinput (prompt) og modtager AI-svaret (completion). De kan derefter "chatte med AI'en" iterativt, i multi-turn samtaler, og forfine deres prompt indtil svaret matcher deres forventninger.

"Prompts" bliver nu det prim√¶re _programmeringsinterface_ for generative AI-apps, der fort√¶ller modellerne, hvad de skal g√∏re, og p√•virker kvaliteten af de returnerede svar. "Prompt Engineering" er et hastigt voksende studieomr√•de, som fokuserer p√• _design og optimering_ af prompts for at levere konsistente og kvalitetsfulde svar i stor skala.

## L√¶ringsm√•l

I denne lektion l√¶rer vi, hvad Prompt Engineering er, hvorfor det er vigtigt, og hvordan vi kan skabe mere effektive prompts til en given model og et applikationsm√•l. Vi vil forst√• kernebegreber og bedste praksis for prompt engineering - og l√¶re om et interaktivt Jupyter Notebooks "sandbox"-milj√∏, hvor vi kan se disse begreber anvendt p√• virkelige eksempler.

N√•r vi har gennemf√∏rt lektionen, vil vi kunne:

1. Forklare hvad prompt engineering er, og hvorfor det er vigtigt.
2. Beskrive komponenterne i en prompt og hvordan de bruges.
3. L√¶re bedste praksis og teknikker til prompt engineering.
4. Anvende de l√¶rte teknikker p√• virkelige eksempler ved hj√¶lp af en OpenAI-endpoint.

## N√∏glebegreber

Prompt Engineering: Praksis med at designe og forfine input for at styre AI-modeller mod at producere √∏nskede output.
Tokenization: Processen med at konvertere tekst til mindre enheder, kaldet tokens, som en model kan forst√• og behandle.
Instruction-Tuned LLMs: Large Language Models (LLMs), der er finjusteret med specifikke instruktioner for at forbedre deres svarpr√¶cision og relevans.

## L√¶ringssandbox

Prompt engineering er i √∏jeblikket mere en kunst end en videnskab. Den bedste m√•de at forbedre vores intuition for det er at _√∏ve sig mere_ og anvende en trial-and-error tilgang, som kombinerer dom√¶nefaglig ekspertise med anbefalede teknikker og model-specifikke optimeringer.

Jupyter Notebook, der ledsager denne lektion, giver et _sandbox_-milj√∏, hvor du kan pr√∏ve det, du l√¶rer ‚Äì som du g√•r frem, eller som en del af kodeudfordringen til sidst. For at gennemf√∏re √∏velserne skal du bruge:

1. **En Azure OpenAI API-n√∏gle** - serviceendpoint for en implementeret LLM.
2. **Et Python-runtime** - hvor Notebook kan k√∏res.
3. **Lokale milj√∏variabler** - _fuldf√∏r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) trin nu for at v√¶re klar_.

Notebooken kommer med _starter_ √∏velser - men du opfordres til at tilf√∏je dine egne _Markdown_ (beskrivelse) og _Code_ (prompt-foresp√∏rgsler) sektioner for at pr√∏ve flere eksempler eller id√©er - og opbygge din intuition for promptdesign.

## Illustreret Guide

Vil du have det store overblik over, hvad denne lektion d√¶kker, f√∏r du dykker ned? Kig p√• denne illustrerede guide, som giver dig en fornemmelse af hovedtemaerne og n√∏glepointerne, du kan t√¶nke over i hver del. Lektionens k√∏replan tager dig fra forst√•else af kernebegreber og udfordringer til at h√•ndtere dem med relevante teknikker og bedste praksis inden for prompt engineering. Bem√¶rk, at afsnittet "Avancerede teknikker" i denne guide refererer til indhold, der d√¶kkes i det _n√¶ste_ kapitel i dette kursusforl√∏b.

![Illustreret Guide til Prompt Engineering](../../../translated_images/da/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## Vores Startup

Lad os nu tale om, hvordan _dette emne_ relaterer til vores startup-mission om at [bringe AI-innovation til uddannelse](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi √∏nsker at bygge AI-drevne applikationer til _personaliseret l√¶ring_ - s√• lad os t√¶nke over, hvordan forskellige brugere af vores applikation kan "designe" prompts:

- **Administratorer** kan bede AI'en om at _analysere l√¶seplansdata for at identificere mangler i d√¶kningen_. AI kan opsummere resultater eller visualisere dem med kode.
- **Undervisere** kan bede AI'en om at _generere en lektionsplan for et m√•lrettet publikum og emne_. AI kan bygge den personlige plan i et specificeret format.
- **Studerende** kan bede AI'en om at _vejlede dem i et sv√¶rt fag_. AI kan nu guide studerende med lektioner, hints og eksempler tilpasset deres niveau.

Det er bare toppen af isbjerget. Kig p√• [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - et open source prompts-bibliotek kurateret af uddannelseseksperter - for at f√• en bredere fornemmelse af mulighederne! _Pr√∏v at k√∏re nogle af disse prompts i sandboxen eller brug OpenAI Playground for at se, hvad der sker!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Hvad er Prompt Engineering?

Vi startede denne lektion med at definere **Prompt Engineering** som processen med at _designe og optimere_ tekstinputs (prompts) for at levere konsistente og kvalitetsfulde svar (completions) til et givent applikationsm√•l og model. Vi kan betragte dette som en 2-trins proces:

- _designe_ den oprindelige prompt til en given model og form√•l
- _forfine_ prompten iterativt for at forbedre svarenes kvalitet

Dette er n√∏dvendigvis en trial-and-error proces, der kr√¶ver brugerintuition og indsats for at opn√• optimale resultater. S√• hvorfor er det vigtigt? For at besvare det sp√∏rgsm√•l m√• vi f√∏rst forst√• tre begreber:

- _Tokenization_ = hvordan modellen "ser" prompten
- _Base LLMs_ = hvordan grundmodellen "behandler" en prompt
- _Instruction-Tuned LLMs_ = hvordan modellen nu kan se "opgaver"

### Tokenization

En LLM ser prompts som en _sekvens af tokens_, hvor forskellige modeller (eller versioner af en model) kan tokenisere den samme prompt p√• forskellige m√•der. Da LLM'er tr√¶nes p√• tokens (og ikke p√• r√• tekst), har m√•den prompts tokeniseres p√• direkte indflydelse p√• kvaliteten af det genererede svar.

For at f√• en intuition for, hvordan tokenization fungerer, kan du pr√∏ve v√¶rkt√∏jer som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist nedenfor. Kopi√©r din prompt ind ‚Äì og se, hvordan den bliver omdannet til tokens, mens du l√¶gger m√¶rke til, hvordan mellemrum og tegns√¶tning h√•ndteres. Bem√¶rk at dette eksempel viser en √¶ldre LLM (GPT-3) ‚Äì s√• fors√∏g med en nyere model kan give et andet resultat.

![Tokenization](../../../translated_images/da/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Begreb: Foundation Models

N√•r en prompt er tokeniseret, er hovedfunktionen for ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller foundation-model) at forudsige token i den sekvens. Da LLM'er er tr√¶net p√• massive tekstdatas√¶t, har de en god forst√•else af de statistiske relationer mellem tokens og kan lave denne forudsigelse med nogenlunde sikkerhed. Bem√¶rk, at de ikke forst√•r _betydningen_ af ordene i prompten eller token; de ser bare et m√∏nster, de kan "fuldf√∏re" med deres n√¶ste forudsigelse. De kan forts√¶tte med at forudsige sekvensen, indtil den bliver afbrudt af brugerintervention eller en forudfastlagt betingelse.

Vil du se, hvordan promptbaseret completion fungerer? Indtast ovenst√•ende prompt i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardindstillingerne. Systemet er konfigureret til at behandle prompts som foresp√∏rgsler om information ‚Äì s√• du b√∏r se et svar, der opfylder denne kontekst.

Men hvad hvis brugeren ville se noget specifikt, som opfylder et kriterium eller en opgave? Her kommer _instruction-tuned_ LLM'er ind i billedet.

![Base LLM Chat Completion](../../../translated_images/da/04-playground-chat-base.65b76fcfde0caa67.webp)

### Begreb: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med foundation-modellen og finjusterer den med eksempler eller input/output par (f.eks. multi-turn "messages"), som kan indeholde klare instruktioner ‚Äì og AI‚Äôens svar fors√∏ger at f√∏lge denne instruktion.

Dette benytter teknikker som Reinforcement Learning med Human Feedback (RLHF), som kan tr√¶ne modellen til at _f√∏lge instruktioner_ og _l√¶re af feedback_, s√• den producerer svar, der er bedre tilpasset praktiske anvendelser og mere relevante for brugerens m√•l.

Lad os pr√∏ve det ‚Äì bes√∏g prompten ovenfor igen, men √¶ndr nu _systemmeddelelsen_ til at give denne instruktion som kontekst:

> _Opsummer det indhold, du f√•r, for en elev i 2. klasse. Hold resultatet til √©t afsnit med 3-5 punktopstillinger._

Kan du se, hvordan resultatet nu er tilpasset det √∏nskede m√•l og format? En underviser kan nu direkte bruge dette svar i deres slides til den klasse.

![Instruction Tuned LLM Chat Completion](../../../translated_images/da/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## Hvorfor har vi brug for Prompt Engineering?

Nu hvor vi ved, hvordan prompts behandles af LLM'er, lad os tale om _hvorfor_ vi har brug for prompt engineering. Svaret ligger i, at nuv√¶rende LLM'er udg√∏r en r√¶kke udfordringer, som g√∏r _p√•lidelige og konsistente svar_ vanskeligere at opn√• uden indsats i promptkonstruktion og optimering. For eksempel:

1. **Modelsvar er stokastiske.** Den _samme prompt_ vil sandsynligvis producere forskellige svar med forskellige modeller eller modelversioner. Og den kan endda producere forskellige resultater med den _samme model_ p√• forskellige tidspunkter. _Prompt engineering teknikker kan hj√¶lpe os med at minimere disse variationer ved at give bedre sikkerhed_.

1. **Modeller kan fabrikere svar.** Modeller er for-tr√¶net med _store men begr√¶nsede_ datas√¶t, hvilket betyder, at de mangler viden om koncepter uden for dette tr√¶ningsomr√•de. Som f√∏lge heraf kan de producere svar, der er upr√¶cise, opfundne eller direkte i modstrid med kendte fakta. _Prompt engineering teknikker hj√¶lper brugere med at identificere og afb√∏de s√•danne fabrikationer, f.eks. ved at bede AI‚Äôen om kilder eller r√¶sonnement_.

1. **Modellers evner vil variere.** Nyere modeller eller modelgenerationer vil have rigere evner, men medbringe unikke s√¶rheder og kompromiser i omkostning og kompleksitet. _Prompt engineering kan hj√¶lpe os med at udvikle bedste praksis og arbejdsgange, der abstraherer forskelle og tilpasses model-specifikke krav p√• skalerbare, problemfri m√•der_.

Lad os se det i praksis i OpenAI eller Azure OpenAI Playground:

- Brug samme prompt med forskellige LLM-udrulninger (f.eks. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√• du variationerne?
- Brug den samme prompt gentagne gange med den _samme_ LLM-udrulning (f.eks. Azure OpenAI playground) ‚Äì hvordan adskilte disse variationer sig?

### Eksempel p√• fabrikationer

I dette kursus bruger vi begrebet **"fabrikation"** til at referere til f√¶nomenet, hvor LLM'er nogle gange genererer faktuelt ukorrekt information p√• grund af begr√¶nsninger i deres tr√¶ning eller andre forhold. Du kan ogs√• have h√∏rt det omtalt som _"hallucinationer"_ i popul√¶re artikler eller forskningspapirer. Vi anbefaler dog kraftigt at bruge _"fabrikation"_ som termen, s√• vi ikke utilsigtet antropomorfiserer adf√¶rden ved at tilskrive en menneskelig egenskab til en maskinbaseret handling. Dette styrker ogs√• [Ansvarlig AI-retningslinjer](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologisk perspektiv ved at fjerne udtryk, der i nogle kontekster ogs√• kan opfattes som st√∏dende eller ikke-inkluderende.

Vil du have en fornemmelse af, hvordan fabrikationer fungerer? T√¶nk p√• en prompt, der instruerer AI‚Äôen om at generere indhold om et ikke-eksisterende emne (for at sikre, at det ikke findes i tr√¶ningsdatas√¶ttet). For eksempel pr√∏vede jeg denne prompt:

> **Prompt:** generer en lektionsplan om Den Marsianske Krig i 2076.
Et webs√∏gningsresultat viste mig, at der fandtes fiktive fort√¶llinger (f.eks. tv-serier eller b√∏ger) om Martianske krige ‚Äì men ingen i 2076. Sund fornuft fort√¶ller os ogs√•, at 2076 er _i fremtiden_ og derfor ikke kan forbindes med en reel begivenhed.

S√• hvad sker der, n√•r vi k√∏rer denne prompt med forskellige LLM-udbydere?

> **Svar 1**: OpenAI Playground (GPT-35)

![Response 1](../../../translated_images/da/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../../translated_images/da/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Svar 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../../translated_images/da/04-fabrication-huggingchat.faf82a0a51278956.webp)

Som forventet producerer hver model (eller modelversion) lidt forskellige svar takket v√¶re stokastisk adf√¶rd og variationer i modelkapacitet. For eksempel retter en model sig mod et 8. klasses publikum, mens en anden antager en gymnasieelev. Men alle tre modeller genererede svar, der kunne overbevise en uinformeret bruger om, at begivenheden var reel.

Prompt engineering-teknikker som _metaprompting_ og _temperaturkonfiguration_ kan til en vis grad reducere model-fabricationer. Nye prompt engineering _arkitekturer_ inkorporerer ogs√• nye v√¶rkt√∏jer og teknikker s√∏ml√∏st i prompt-flowet for at afb√∏de eller reducere nogle af disse effekter.

## Case Study: GitHub Copilot

Lad os afslutte denne sektion med at f√• en fornemmelse af, hvordan prompt engineering bruges i virkelige l√∏sninger ved at se p√• en Case Study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI parprogrammer" ‚Äì det oms√¶tter tekstprompter til kodeforslag og er integreret i dit udviklingsmilj√∏ (f.eks. Visual Studio Code) for en glidende brugeroplevelse. Som dokumenteret i nedenst√•ende blogserie var den tidligste version baseret p√• OpenAI Codex-modellen ‚Äì hvor ingeni√∏rerne hurtigt inds√• behovet for at finjustere modellen og udvikle bedre prompt engineering-teknikker for at forbedre kodekvaliteten. I juli [debuterede de en forbedret AI-model, der g√•r ud over Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for endnu hurtigere forslag.

L√¶s indl√¶ggene i r√¶kkef√∏lge for at f√∏lge deres l√¶ringsrejse.

- **Maj 2023** | [GitHub Copilot bliver bedre til at forst√• din kode](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inside GitHub: Arbejde med LLM‚Äôerne bag GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jun 2023** | [Hvordan man skriver bedre prompts til GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jul 2023** | [.. GitHub Copilot g√•r ud over Codex med forbedret AI-model](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En udviklers guide til prompt engineering og LLM‚Äôer](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hvordan man bygger en virksomhedsl√∏sning med LLM: L√¶ringer fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• browse deres [Engineering blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere indl√¶g som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), der viser, hvordan disse modeller og teknikker _anvendes_ til at drive virkelige applikationer.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Prompt Konstruktion

Vi har set, hvorfor prompt engineering er vigtigt ‚Äì nu skal vi forst√•, hvordan prompter _konstrueres_, s√• vi kan evaluere forskellige teknikker til mere effektiv promptdesign.

### Grundl√¶ggende Prompt

Lad os starte med den grundl√¶ggende prompt: en tekstinput, der sendes til modellen uden anden kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste f√• ord af USA‚Äôs nationalsang til OpenAI‚Äôs [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), fuldf√∏rer den straks svaret med de n√¶ste linjer, hvilket illustrerer den grundl√¶ggende forudsigelsesadf√¶rd.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det lyder som om, du begynder teksten til "The Star-Spangled Banner," USA‚Äôs nationalsang. Hele teksten er ...                               |

### Komplekst Prompt

Lad os nu tilf√∏je kontekst og instruktioner til denne grundl√¶ggende prompt. [Chat Completion API‚Äôen](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) giver os mulighed for at konstruere en kompleks prompt som en samling af _beskeder_ med:

- Input/output-par, der afspejler _bruger_ input og _assistent_ respons.
- Systembesked, der s√¶tter konteksten for assistentens adf√¶rd eller personlighed.

Foresp√∏rgslen er nu i nedenst√•ende form, hvor _tokeniseringen_ effektivt fanger relevant information fra kontekst og samtale. Nu kan √¶ndring af systemkontexten v√¶re lige s√• indflydelsesrig p√• kvaliteten af svarene som de brugerinput, der gives.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I ovenst√•ende eksempler var brugerprompten en simpel tekstforesp√∏rgsel, der kunne tolkes som en anmodning om information. Med _instruktionsprompter_ kan vi bruge den tekst til at specificere en opgave mere detaljeret og give bedre vejledning til AI‚Äôen. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruktionstype    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivelse af den amerikanske borgerkrig                                                                                                                                                                                   | _returnerede et simpelt afsnit_                                                                                           | Simpel              |
| Skriv en beskrivelse af den amerikanske borgerkrig. Giv n√∏gle datoer og begivenheder og beskriv deres betydning                                                                                                                     | _returnerede et afsnit efterfulgt af en liste med n√∏glebegivenheders datoer og beskrivelser_                                | Komplekst           |
| Skriv en beskrivelse af den amerikanske borgerkrig i 1 afsnit. Giv 3 punktpunkter med n√∏gle datoer og deres betydning. Giv 3 flere punktpunkter med n√∏glehistoriske personer og deres bidrag. Return√©r output som en JSON-fil          | _returnerer mere omfattende detaljer i en tekstboks, formatteret som JSON, som du kan kopiere og validere efter behov_       | Kompleks. Formateret.|

## Prim√¶rt Indhold

I ovenst√•ende eksempler var prompten stadig ret √•ben, hvilket lod LLM‚Äôen beslutte, hvilken del af dets forudtr√¶nede datas√¶t der var relevant. Med designm√∏nstret _prim√¶rt indhold_ opdeles inputteksten i to dele:

- en instruktion (handling)
- relevant indhold (der p√•virker handlingen)

Her er et eksempel, hvor instruktionen er at "opsummere dette i 2 s√¶tninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gasplanet med en masse p√• en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er en af de klareste genstande, der er synlige med det blotte √∏je p√• nattehimlen, og er kendt af gamle civilisationer siden f√∏r historisk tid. Den er opkaldt efter den romerske gud Jupiter.[19] N√•r Jupiter ses fra Jorden, kan den v√¶re lysst√¶rk nok til, at dens reflekterede lys kaster synlige skygger,[20] og er i gennemsnit det tredje klareste naturlige objekt p√• nattehimlen efter M√•nen og Venus. <br/> **Opsummer dette i 2 korte s√¶tninger** | Jupiter, den femte planet fra Solen, er den st√∏rste i Solsystemet og kendt for at v√¶re et af de klareste objekter p√• nattehimlen. Opkaldt efter den romerske gud Jupiter, er det en gasplanet, hvis masse er to og en halv gang s√• stor som alle de andre planeter i Solsystemet tilsammen. |

Segmentet for prim√¶rt indhold kan bruges p√• forskellige m√•der for at skabe mere effektive instruktioner:

- **Eksempler** ‚Äì i stedet for at fort√¶lle modellen, hvad den skal g√∏re med en eksplicit instruktion, giver man den eksempler p√•, hvad der skal g√∏res, og lader den udlede m√∏nsteret.
- **Tips** ‚Äì f√∏l instruktionen med et "tip", der forbereder completion‚Äôen og guider modellen mod mere relevante svar.
- **Skabeloner** ‚Äì disse er gentagelige 'opskrifter' p√• prompts med pladsholdere (variabler), der kan tilpasses med data til specifikke brugsscenarier.

Lad os udforske disse i praksis.

### Brug af Eksempler

Dette er en tilgang, hvor du bruger det prim√¶re indhold til at "fodre modellen" med nogle eksempler p√• det √∏nskede output for en given instruktion og lader den udlede √∏nsket outputm√∏nster. Afh√¶ngigt af antallet af eksempler kan vi have zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r nu af tre komponenter:

- En opgavebeskrivelse
- Nogle f√• eksempler p√• √∏nsket output
- Starten p√• et nyt eksempel (som bliver en implicit opgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :----------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------- |
| Zero-shot    | "The Sun is Shining". Overs√¶t til spansk                                                                                                            | "El Sol est√° brillando".   |
| One-shot     | "The Sun is Shining" => "El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot     | Spilleren l√∏b baserne => Baseball <br/> Spilleren slog en ace => Tennis <br/> Spilleren slog en sekser => Cricket <br/> Spilleren lavede en slam-dunk => | Basketball                 |
|             |                                                                                                                                                       |                            |

Bem√¶rk, hvordan vi m√•tte give eksplicit instruktion ("Overs√¶t til spansk") i zero-shot prompting, men den udledes i one-shot prompt-eksemplet. Few-shot-eksemplet viser, hvordan flere eksempler tillader modeller at lave mere pr√¶cise slutninger uden ekstra instruktioner.

### Prompt Tips

En anden teknik til at bruge prim√¶rt indhold er at give _tips_ i stedet for eksempler. I dette tilf√¶lde giver vi modellen en skub i den rigtige retning ved _at starte den_ med et uddrag, der afspejler det √∏nskede svarformat. Modellen "tager tipset" og forts√¶tter i den stil.

| Antal Tips   | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :----------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0            | Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gasplanet med en masse p√• en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er en af de klareste genstande, der er synlige med det blotte √∏je p√• nattehimlen, og er kendt af gamle civilisationer siden f√∏r historisk tid. <br/>**Opsummer dette**                                       | Jupiter er den st√∏rste planet i vores Solsystem og den femte fra Solen. Det er en gasplanet med en masse p√• 1/1000 af Solens, men den er tungere end alle de andre planeter tilsammen. Gamle civilisationer har kendt Jupiter i lang tid, og den er let synlig p√• nattehimlen. |
| 1              | Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gas-gigant med en masse, der er en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de mest lysst√¶rke objekter synlige med det blotte √∏je p√• nattehimlen og har v√¶ret kendt af gamle civilisationer siden f√∏r skriftlige optegnelser. <br/>**Opsummer dette** <br/> Det vi l√¶rte er, at Jupiter | er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gas-gigant med en masse, der er en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter tilsammen. Den er let synlig med det blotte √∏je og har v√¶ret kendt siden oldtiden.                        |
| 2              | Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. Det er en gas-gigant med en masse, der er en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de mest lysst√¶rke objekter synlige med det blotte √∏je p√• nattehimlen og har v√¶ret kendt af gamle civilisationer siden f√∏r skriftlige optegnelser. <br/>**Opsummer dette** <br/> Top 3 fakta vi l√¶rte:         | 1. Jupiter er den femte planet fra Solen og den st√∏rste i Solsystemet. <br/> 2. Det er en gas-gigant med en masse, der er en tusindedel af Solens...<br/> 3. Jupiter har v√¶ret synlig med det blotte √∏je siden oldtiden ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Prompt Skabeloner

En prompt-skabelon er en _foruddefineret opskrift p√• en prompt_, som kan gemmes og genbruges efter behov for at skabe mere konsistente brugeroplevelser i stor skala. I sin simpleste form er det blot en samling af prompt-eksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), der giver b√•de de interaktive prompt-komponenter (bruger- og systembeskeder) og API-styrede anmodningsformater ‚Äì for at st√∏tte genbrug.

I en mere kompleks form som [dette eksempel fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) indeholder den _pladsholdere_, som kan erstattes med data fra forskellige kilder (brugers input, systemkontekst, eksterne datakilder osv.) for dynamisk at skabe en prompt. Det giver os mulighed for at oprette et bibliotek af genanvendelige prompts, der kan bruges til at skabe konsistente brugeroplevelser **programmatisk** i stor skala.

Endelig ligger den reelle v√¶rdi af skabeloner i evnen til at oprette og offentligg√∏re _prompt-biblioteker_ for vertikale anvendelsesomr√•der ‚Äì hvor prompt-skabelonen nu er _optimeret_ til at afspejle applikationsspecifik kontekst eller eksempler, der g√∏r svarene mere relevante og pr√¶cise for den m√•lrettede brugergruppe. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) repositoriet er et godt eksempel p√• denne tilgang, der kuraterer et bibliotek af prompts til uddannelsesomr√•det med fokus p√• n√∏glem√•l som lektionsplanl√¶gning, pensumdesign, elevvejledning osv.

## Underst√∏ttende Indhold

Hvis vi t√¶nker p√• prompt-konstruktion som at have en instruktion (opgave) og et m√•l (prim√¶rt indhold), s√• er _sekund√¶rt indhold_ som yderligere kontekst, vi giver for at **p√•virke output p√• en eller anden m√•de**. Det kan v√¶re justeringsparametre, formateringsinstruktioner, emnetaksonomier osv., der kan hj√¶lpe modellen med at _tilpasse_ sit svar, s√• det passer til de √∏nskede brugerform√•l eller forventninger.

For eksempel: Givet en kursuskatalog med omfattende metadata (navn, beskrivelse, niveau, metadata-tags, underviser osv.) p√• alle tilg√¶ngelige kurser i pensum:

- vi kan definere en instruktion til "at opsummere kursuskataloget for efter√•r 2023"
- vi kan bruge det prim√¶re indhold til at give nogle eksempler p√• √∏nsket output
- vi kan bruge det sekund√¶re indhold til at identificere de 5 vigtigste "tags" af interesse.

Nu kan modellen give en opsummering i formatet vist ved eksemplerne ‚Äì men hvis et resultat har flere tags, kan den prioritere de 5 tags, der blev identificeret i sekund√¶rt indhold.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #3:
Prompt Engineering Techniques.
What are some basic techniques for prompt engineering?
Illustrate it with some exercises.
-->

## Bedste Fremgangsm√•der for Prompting

Nu hvor vi ved, hvordan prompts kan _konstrueres_, kan vi begynde at t√¶nke p√•, hvordan vi _designer_ dem, s√• de afspejler bedste praksis. Vi kan opdeles det i to dele ‚Äì at have den rette _tankegang_ og anvende de rette _teknikker_.

### Prompt Engineering Tankegang

Prompt Engineering er en pr√∏v-og-fejl proces, s√• hold tre overordnede vejledende faktorer i tankerne:

1. **Dom√¶neforst√•else er afg√∏rende.** Svarets n√∏jagtighed og relevans afh√¶nger af det _dom√¶ne_, hvor applikationen eller brugeren opererer. Brug din intuition og dom√¶neekspertise til at **tilpasse teknikker** yderligere. Definer for eksempel _dom√¶nespecifikke personligheder_ i dine systemprompter, eller brug _dom√¶nespecifikke skabeloner_ i dine brugerprompter. Giv sekund√¶rt indhold, der afspejler dom√¶nespecifikke kontekster, eller brug _dom√¶nespecifikke hints og eksempler_ til at lede modellen mod kendte anvendelsesm√∏nstre.

2. **Modelforst√•else er afg√∏rende.** Vi ved, at modeller er stokastiske af natur. Men modelimplementeringer kan ogs√• variere med hensyn til det tr√¶ningsdatas√¶t, de bruger (forudtr√¶net viden), de kapabiliteter de tilbyder (fx via API eller SDK) og den type indhold, de er optimeret til (fx kode vs. billeder vs. tekst). Forst√• styrker og begr√¶nsninger af den model, du bruger, og brug den viden til at _prioritere opgaver_ eller opbygge _tilpassede skabeloner_, der er optimeret til modellens kapabiliteter.

3. **Iteration og validering er afg√∏rende.** Modeller udvikler sig hurtigt, og det samme g√∏r teknikker for prompt engineering. Som dom√¶neekspert kan du have anden kontekst eller kriterier for _din_ specifikke applikation, som m√•ske ikke g√¶lder for det brede samfund. Brug prompt engineering-v√¶rkt√∏jer og teknikker til at "jumpstarte" prompt-konstruktion, og iterer derefter og valider resultaterne med din egen intuition og dom√¶neekspertise. Not√©r dine indsigter og opret en **vidensbase** (fx prompt-biblioteker), som andre kan bruge som nyt udgangspunkt for hurtigere iterationer fremover.

## Bedste Praksis

Lad os nu se p√• almindelige bedste praksisser, som anbefales af [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Hvad                              | Hvorfor                                                                                                                                                                                                                                              |
| :-------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Evaluer de nyeste modeller.       | Nye modelgenerationer har sandsynligvis forbedrede funktioner og kvalitet ‚Äì men kan ogs√• medf√∏re h√∏jere omkostninger. Evaluer dem for effekt, og tag derefter beslutninger om migration.                                                             |
| Adskil instruktioner & kontekst   | Unders√∏g om din model/udbyder definerer _afgr√¶nsere_ for at skelne instruktioner, prim√¶rt og sekund√¶rt indhold tydeligere. Det kan hj√¶lpe modeller med at tildele v√¶gte mere korrekt til tokens.                                                    |
| V√¶r specifik og klar               | Giv flere detaljer om √∏nsket kontekst, resultat, l√¶ngde, format, stil osv. Dette forbedrer b√•de kvaliteten og konsistensen af svar. Indfang opskrifter i genanvendelige skabeloner.                                                                 |
| V√¶r beskrivende, brug eksempler   | Modeller responderer ofte bedre p√• en "vis og fort√¶l" tilgang. Start med en `zero-shot` tilgang, hvor du giver en instruktion (men ingen eksempler), og pr√∏v derefter `few-shot` som en forfining, hvor du giver nogle eksempler p√• √∏nsket output. Brug analogier. |
| Brug hints til at starte svar     | Skub modellen mod et √∏nsket resultat ved at give nogle ledende ord eller s√¶tninger, som den kan bruge som udgangspunkt for svaret.                                                                                                                |
| Gentag om n√∏dvendigt              | Nogle gange skal du gentage dig overfor modellen. Giv instruktioner f√∏r og efter dit prim√¶re indhold, brug b√•de instruktion og hint osv. Iter√©r og valider for at se, hvad der virker.                                                              |
| R√¶kkef√∏lge betyder noget          | Den r√¶kkef√∏lge, du pr√¶senterer information for modellen i, kan p√•virke output, ogs√• i l√¶ringseksempler, p√• grund af nyhedsbias. Pr√∏v forskellige muligheder for at se, hvad der virker bedst.                                                      |
| Giv modellen en "vej ud"           | Giv modellen et _fallback_-svar, som den kan give, hvis den ikke kan fuldf√∏re opgaven af en eller anden grund. Det kan reducere risikoen for, at modeller genererer falske eller opdigtede svar.                                                     |
|                                   |                                                                                                                                                                                                                                                      |

Som med enhver bedste praksis, husk at _dine resultater kan variere_ afh√¶ngigt af model, opgave og dom√¶ne. Brug dette som udgangspunkt, og iter√©r for at finde ud af, hvad der virker bedst for dig. Evaluer l√∏bende din prompt engineering-proces, efterh√•nden som nye modeller og v√¶rkt√∏jer bliver tilg√¶ngelige, med fokus p√• skalerbarhed og svar-kvalitet.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Opgave

Tillykke! Du er n√•et til slutningen af lektionen! Det er tid til at afpr√∏ve nogle af de koncepter og teknikker med reelle eksempler!

Til vores opgave vil vi bruge en Jupyter Notebook med √∏velser, du kan gennemf√∏re interaktivt. Du kan ogs√• udvide Notebook‚Äôen med dine egne Markdown- og kodeceller for at udforske ideer og teknikker p√• egen h√•nd.

### For at komme i gang, fork repo‚Äôet, og derefter

- (Anbefalet) Start GitHub Codespaces
- (Alternativt) Klon repo‚Äôet til din lokale enhed og brug det med Docker Desktop
- (Alternativt) √Öbn Notebook‚Äôen med dit foretrukne Notebook-runtime-milj√∏.

### Derefter konfigurer dine milj√∏variabler

- Kopi√©r filen `.env.copy` i repo-roden til `.env` og udfyld v√¶rdierne for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. Kom tilbage til [Learning Sandbox sektionen](../../../04-prompt-engineering-fundamentals) for at l√¶re hvordan.

### √Öbn herefter Jupyter Notebook

- V√¶lg runtime-kernen. Hvis du bruger mulighed 1 eller 2, v√¶lg blot den foruddefinerede Python 3.10.x kernel, der leveres med dev-containeren.

Du er klar til at k√∏re √∏velserne. Bem√¶rk, at der ikke findes _rigtige eller forkerte_ svar her ‚Äì det handler om at afpr√∏ve muligheder ved pr√∏v-og-fejl og opbygge intuition for, hvad der virker for en given model og applikationsdom√¶ne.

_Derfor er der ikke Code Solution-segmenter i denne lektion. I stedet indeholder Notebook‚Äôen Markdown-celler med titlen "My Solution:", som viser et eksempel p√• output til reference._

 <!--
LESSON TEMPLATE:
Wrap the section with a summary and resources for self-guided learning.
-->

## Videnstest

Hvilket af f√∏lgende er en god prompt, der f√∏lger nogle rimelige bedste praksisser?

1. Vis mig et billede af en r√∏d bil
2. Vis mig et billede af en r√∏d bil af m√¶rket Volvo og model XC90 parkeret ved en klippeskr√¶nt med solen g√•ende ned
3. Vis mig et billede af en r√∏d bil af m√¶rket Volvo og model XC90

A: 2, det er den bedste prompt, da den giver detaljer om "hvad" og g√•r i detaljer (ikke bare en hvilken som helst bil, men en specifik m√¶rke og model) og den beskriver ogs√• den overordnede kontekst. 3 er n√¶stbedst, eftersom den ogs√• indeholder mange beskrivelser.

## üöÄ Udfordring

Se om du kan udnytte "cue"-teknikken med prompten: Fuldf√∏r s√¶tningen "Vis mig et billede af en r√∏d bil af m√¶rket Volvo og ". Hvad svarer den, og hvordan ville du forbedre det?

## Godt arbejde! Forts√¶t din l√¶ring

Vil du l√¶re mere om forskellige Prompt Engineering-koncept? G√• til [fortsat l√¶ringsside](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at finde andre gode ressourcer om emnet.

G√• videre til Lektion 5, hvor vi ser p√• [avancerede prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, skal du v√¶re opm√¶rksom p√•, at automatiske overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det originale dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->