<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-07-09T10:24:39+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "da"
}
-->
# Grundl√¶ggende om Prompt Engineering

[![Prompt Engineering Fundamentals](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.da.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduktion  
Dette modul d√¶kker v√¶sentlige begreber og teknikker til at skabe effektive prompts i generative AI-modeller. M√•den, du skriver din prompt til en LLM p√•, har ogs√• betydning. En omhyggeligt udformet prompt kan opn√• en bedre kvalitet i svaret. Men hvad betyder begreber som _prompt_ og _prompt engineering_ egentlig? Og hvordan forbedrer jeg det prompt-_input_, jeg sender til LLM‚Äôen? Det er de sp√∏rgsm√•l, vi vil fors√∏ge at besvare i dette kapitel og det n√¶ste.

_Generativ AI_ kan skabe nyt indhold (f.eks. tekst, billeder, lyd, kode osv.) som svar p√• brugerforesp√∏rgsler. Det opn√•s ved hj√¶lp af _Large Language Models_ som OpenAI‚Äôs GPT ("Generative Pre-trained Transformer") serie, der er tr√¶net til at bruge naturligt sprog og kode.

Brugere kan nu interagere med disse modeller via velkendte paradigmer som chat, uden at have teknisk ekspertise eller tr√¶ning. Modellerne er _prompt-baserede_ ‚Äì brugere sender en tekstinput (prompt) og f√•r AI‚Äôs svar (completion) tilbage. De kan derefter "chatte med AI‚Äôen" iterativt i samtaler med flere runder, hvor de finjusterer deres prompt, indtil svaret matcher deres forventninger.

"Prompts" bliver nu den prim√¶re _programmeringsgr√¶nseflade_ for generative AI-apps, der fort√¶ller modellerne, hvad de skal g√∏re, og p√•virker kvaliteten af de returnerede svar. "Prompt Engineering" er et hurtigt voksende studieomr√•de, der fokuserer p√• _design og optimering_ af prompts for at levere konsistente og kvalitetsm√¶ssige svar i stor skala.

## L√¶ringsm√•l

I denne lektion l√¶rer vi, hvad Prompt Engineering er, hvorfor det er vigtigt, og hvordan vi kan skabe mere effektive prompts til en given model og applikationsform√•l. Vi vil forst√• kernebegreber og bedste praksis for prompt engineering ‚Äì og l√¶re om et interaktivt Jupyter Notebooks "sandbox"-milj√∏, hvor vi kan se disse koncepter anvendt p√• virkelige eksempler.

Ved slutningen af denne lektion vil vi kunne:

1. Forklare, hvad prompt engineering er, og hvorfor det er vigtigt.  
2. Beskrive komponenterne i en prompt og hvordan de bruges.  
3. L√¶re bedste praksis og teknikker til prompt engineering.  
4. Anvende l√¶rte teknikker p√• virkelige eksempler ved brug af en OpenAI-endpoint.

## Centrale Begreber

Prompt Engineering: Praksissen med at designe og forfine input for at styre AI-modeller mod at producere √∏nskede output.  
Tokenization: Processen med at omdanne tekst til mindre enheder, kaldet tokens, som en model kan forst√• og behandle.  
Instruction-Tuned LLMs: Store sprogmodeller (LLMs), der er finjusteret med specifikke instruktioner for at forbedre deres svarn√∏jagtighed og relevans.

## L√¶ringssandbox

Prompt engineering er i √∏jeblikket mere en kunst end en videnskab. Den bedste m√•de at forbedre vores intuition for det p√• er at _√∏ve sig mere_ og anvende en trial-and-error tilgang, der kombinerer dom√¶neekspertise med anbefalede teknikker og model-specifikke optimeringer.

Jupyter Notebook, der f√∏lger med denne lektion, giver et _sandbox_-milj√∏, hvor du kan pr√∏ve det, du l√¶rer ‚Äì l√∏bende eller som en del af kodeudfordringen til sidst. For at kunne udf√∏re √∏velserne skal du bruge:

1. **En Azure OpenAI API-n√∏gle** ‚Äì service-endpoint for en implementeret LLM.  
2. **Et Python-runtime** ‚Äì hvor Notebook‚Äôen kan k√∏res.  
3. **Lokale milj√∏variabler** ‚Äì _fuldf√∏r [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) trin nu for at v√¶re klar_.

Notebook‚Äôen indeholder _start√∏velser_ ‚Äì men du opfordres til at tilf√∏je dine egne _Markdown_ (beskrivelser) og _Code_ (prompt-foresp√∏rgsler) sektioner for at pr√∏ve flere eksempler eller id√©er ‚Äì og opbygge din intuition for promptdesign.

## Illustreret Guide

Vil du have et overblik over, hvad denne lektion d√¶kker, inden du g√•r i gang? Tjek denne illustrerede guide, som giver dig en fornemmelse af hovedemnerne og de vigtigste pointer, du kan t√¶nke over i hver del. Lektionens k√∏replan tager dig fra forst√•elsen af kernebegreber og udfordringer til at h√•ndtere dem med relevante prompt engineering-teknikker og bedste praksis. Bem√¶rk, at afsnittet "Avancerede teknikker" i denne guide henviser til indhold, der d√¶kkes i det _n√¶ste_ kapitel i dette kursusforl√∏b.

![Illustreret Guide til Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.da.png)

## Vores Startup

Lad os nu tale om, hvordan _dette emne_ relaterer sig til vores startup-mission om at [bringe AI-innovation til uddannelse](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi √∏nsker at bygge AI-drevne applikationer til _personlig l√¶ring_ ‚Äì s√• lad os t√¶nke over, hvordan forskellige brugere af vores applikation kunne "designe" prompts:

- **Administratorer** kunne bede AI‚Äôen om at _analysere l√¶seplansdata for at identificere huller i d√¶kningen_. AI‚Äôen kan opsummere resultater eller visualisere dem med kode.  
- **Undervisere** kunne bede AI‚Äôen om at _generere en lektionsplan for en m√•lgruppe og et emne_. AI‚Äôen kan bygge den personlige plan i et specificeret format.  
- **Studerende** kunne bede AI‚Äôen om at _vejlede dem i et sv√¶rt fag_. AI‚Äôen kan nu guide elever med lektioner, hints og eksempler tilpasset deres niveau.

Det er kun toppen af isbjerget. Tjek [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì et open source prompt-bibliotek kurateret af uddannelseseksperter ‚Äì for at f√• en bredere fornemmelse af mulighederne! _Pr√∏v at k√∏re nogle af disse prompts i sandboxen eller brug OpenAI Playground for at se, hvad der sker!_

<!--  
LESSON TEMPLATE:  
This unit should cover core concept #1.  
Reinforce the concept with examples and references.  

CONCEPT #1:  
Prompt Engineering.  
Define it and explain why it is needed.  
-->

## Hvad er Prompt Engineering?

Vi startede denne lektion med at definere **Prompt Engineering** som processen med at _designe og optimere_ tekstinput (prompts) for at levere konsistente og kvalitetsm√¶ssige svar (completions) til et givent applikationsform√•l og model. Vi kan t√¶nke p√• det som en 2-trins proces:

- _designe_ den oprindelige prompt til en given model og form√•l  
- _forfine_ prompten iterativt for at forbedre kvaliteten af svaret

Dette er n√∏dvendigvis en trial-and-error proces, der kr√¶ver brugerintuiton og indsats for at opn√• optimale resultater. S√• hvorfor er det vigtigt? For at besvare det sp√∏rgsm√•l skal vi f√∏rst forst√• tre begreber:

- _Tokenization_ = hvordan modellen "ser" prompten  
- _Base LLMs_ = hvordan grundmodellen "behandler" en prompt  
- _Instruction-Tuned LLMs_ = hvordan modellen nu kan se "opgaver"

### Tokenization

En LLM ser prompts som en _sekvens af tokens_, hvor forskellige modeller (eller versioner af en model) kan tokenisere den samme prompt p√• forskellige m√•der. Da LLM‚Äôer er tr√¶net p√• tokens (og ikke r√• tekst), har m√•den, prompts tokeniseres p√•, direkte indflydelse p√• kvaliteten af det genererede svar.

For at f√• en fornemmelse af, hvordan tokenization fungerer, kan du pr√∏ve v√¶rkt√∏jer som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist nedenfor. Kopi√©r din prompt ind ‚Äì og se, hvordan den bliver omdannet til tokens, med s√¶rlig opm√¶rksomhed p√•, hvordan mellemrum og tegns√¶tning h√•ndteres. Bem√¶rk, at dette eksempel viser en √¶ldre LLM (GPT-3) ‚Äì s√• pr√∏v med en nyere model for at se, om resultatet bliver anderledes.

![Tokenization](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.da.png)

### Begreb: Foundation Models

N√•r en prompt er tokeniseret, er hovedfunktionen for ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grundmodellen) at forudsige det n√¶ste token i sekvensen. Da LLM‚Äôer er tr√¶net p√• enorme tekstdatas√¶t, har de en god fornemmelse af de statistiske sammenh√¶nge mellem tokens og kan lave denne forudsigelse med en vis sikkerhed. Bem√¶rk, at de ikke forst√•r _meningen_ med ordene i prompten eller tokenet; de ser blot et m√∏nster, de kan "fuldf√∏re" med deres n√¶ste forudsigelse. De kan forts√¶tte med at forudsige sekvensen, indtil brugeren afbryder eller en forudbestemt betingelse opfyldes.

Vil du se, hvordan prompt-baseret completion fungerer? Indtast ovenst√•ende prompt i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardindstillingerne. Systemet er konfigureret til at behandle prompts som informationsforesp√∏rgsler ‚Äì s√• du b√∏r se et svar, der opfylder denne kontekst.

Men hvad hvis brugeren √∏nskede at se noget specifikt, der opfylder visse kriterier eller et opgaveform√•l? Her kommer _instruction-tuned_ LLM‚Äôer ind i billedet.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.da.png)

### Begreb: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grundmodellen og finjusterer den med eksempler eller input/output-par (f.eks. multi-turn "beskeder"), der kan indeholde klare instruktioner ‚Äì og AI‚Äôens svar fors√∏ger at f√∏lge disse instruktioner.

Dette bruger teknikker som Reinforcement Learning with Human Feedback (RLHF), der kan tr√¶ne modellen til at _f√∏lge instruktioner_ og _l√¶re af feedback_, s√• den producerer svar, der er bedre tilpasset praktiske anvendelser og mere relevante for brugerens m√•l.

Lad os pr√∏ve det ‚Äì g√• tilbage til prompten ovenfor, men skift nu _systembeskeden_ til at give f√∏lgende instruktion som kontekst:

> _Opsummer det indhold, du f√•r, for en elev i 2. klasse. Hold resultatet til et afsnit med 3-5 punktopstillinger._

Kan du se, hvordan resultatet nu er tilpasset det √∏nskede m√•l og format? En underviser kan nu direkte bruge dette svar i deres slides til den klasse.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.da.png)

## Hvorfor har vi brug for Prompt Engineering?

Nu hvor vi ved, hvordan prompts behandles af LLM‚Äôer, lad os tale om _hvorfor_ vi har brug for prompt engineering. Svaret ligger i, at nuv√¶rende LLM‚Äôer har en r√¶kke udfordringer, der g√∏r det sv√¶rere at opn√• _p√•lidelige og konsistente svar_ uden at l√¶gge indsats i promptkonstruktion og optimering. For eksempel:

1. **Model-svar er stokastiske.** Den _samme prompt_ vil sandsynligvis give forskellige svar med forskellige modeller eller modelversioner. Og den kan endda give forskellige resultater med den _samme model_ p√• forskellige tidspunkter. _Prompt engineering-teknikker kan hj√¶lpe os med at minimere disse variationer ved at give bedre rammer_.

1. **Modeller kan finde p√• svar.** Modeller er fortr√¶net med _store, men begr√¶nsede_ datas√¶t, hvilket betyder, at de mangler viden om begreber uden for tr√¶ningsomr√•det. Som f√∏lge heraf kan de producere svar, der er un√∏jagtige, opdigtede eller direkte modstridende med kendte fakta. _Prompt engineering-teknikker hj√¶lper brugere med at identificere og afb√∏de s√•danne opdigtninger, f.eks. ved at bede AI om kildehenvisninger eller begrundelser_.

1. **Modellers kapaciteter vil variere.** Nyere modeller eller modelgenerationer vil have rigere kapaciteter, men ogs√• bringe unikke s√¶rheder og kompromiser i omkostninger og kompleksitet. _Prompt engineering kan hj√¶lpe os med at udvikle bedste praksis og arbejdsgange, der abstraherer forskelle og tilpasser sig model-specifikke krav p√• skalerbare og s√∏ml√∏se m√•der_.

Lad os se dette i praksis i OpenAI eller Azure OpenAI Playground:

- Brug den samme prompt med forskellige LLM-implementeringer (f.eks. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√• du variationerne?  
- Brug den samme prompt gentagne gange med den _samme_ LLM-implementering (f.eks. Azure OpenAI playground) ‚Äì hvordan adskilte disse variationer sig?

### Eksempel p√• opdigtninger

I dette kursus bruger vi begrebet **"fabrication"** til at referere til f√¶nomenet, hvor LLM‚Äôer nogle gange genererer faktuelt ukorrekte oplysninger p√• grund af begr√¶nsninger i deres tr√¶ning eller andre forhold. Du har m√•ske ogs√• h√∏rt dette omtalt som _"hallucinationer"_ i popul√¶re artikler eller forskningspapirer. Vi anbefaler dog kraftigt at bruge _"fabrication"_ som betegnelse, s√• vi undg√•r at antropomorfisere adf√¶rden ved at till√¶gge en menneskelig egenskab til et maskindrevet resultat. Dette underst√∏tter ogs√• [Responsible AI-retningslinjer](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologisk perspektiv ved at fjerne termer, der i visse sammenh√¶nge kan opfattes som st√∏dende eller ikke inkluderende.

Vil du have en fornemmelse af, hvordan fabrication fungerer? T√¶nk p√• en prompt, der instruerer AI‚Äôen til at generere indhold om et ikke-eksisterende emne (for at sikre, at det ikke findes i tr√¶ningsdatas√¶ttet). For eksempel ‚Äì jeg pr√∏vede denne prompt:
# Lektionplan: Den Marsianske Krig i 2076

## Introduktion
I denne lektion vil vi udforske den Marsianske Krig, der fandt sted i 2076. Vi vil unders√∏ge √•rsagerne til konflikten, de vigtigste begivenheder og dens konsekvenser for b√•de Jorden og Mars.

## M√•l
- Forst√• baggrunden for den Marsianske Krig
- Identificere n√∏gleakt√∏rer og begivenheder i krigen
- Analysere krigens indvirkning p√• fremtidige interplanetariske relationer

## Materialer
- Historiske dokumenter og rapporter om Marsianske Krig
- Kort over Mars og Jorden under konflikten
- Videoer og √∏jenvidneberetninger

## Lektionens forl√∏b

### 1. Baggrund og √•rsager (20 minutter)
- Diskuter de politiske og √∏konomiske sp√¶ndinger mellem Jorden og Mars
- Gennemg√• de vigtigste begivenheder, der f√∏rte til krigen

### 2. Krigens forl√∏b (30 minutter)
- Gennemg√• de vigtigste slag og strategier brugt af begge sider
- Analyser teknologier og v√•ben, der blev anvendt

### 3. Konsekvenser og efterspil (20 minutter)
- Diskuter krigens indvirkning p√• Mars' kolonisering og Jordens politik
- Overvej hvordan krigen har formet nutidens interplanetariske samarbejde

### 4. Diskussion og refleksion (15 minutter)
- Lad eleverne diskutere, hvad de mener kunne have forhindret krigen
- Reflekter over betydningen af fred og samarbejde i rummet

## Afslutning
Opsummer de vigtigste punkter fra lektionen og opfordr eleverne til at l√¶se yderligere materiale om emnet.

## Ekstra ressourcer
- Links til dokumentarer og artikler om den Marsianske Krig
- Forslag til projekter og opgaver relateret til emnet
Et web-s√∏g viste mig, at der fandtes fiktive beretninger (f.eks. tv-serier eller b√∏ger) om marskrige ‚Äì men ingen i 2076. Sund fornuft fort√¶ller os ogs√•, at 2076 er _i fremtiden_ og derfor ikke kan forbindes med en virkelig begivenhed.

S√• hvad sker der, n√•r vi k√∏rer denne prompt med forskellige LLM-udbydere?

> **Response 1**: OpenAI Playground (GPT-35)

![Response 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.da.png)

> **Response 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.da.png)

> **Response 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.da.png)

Som forventet producerer hver model (eller modelversion) lidt forskellige svar takket v√¶re stokastisk adf√¶rd og variationer i modelkapacitet. For eksempel retter √©n model sig mod et 8. klasses publikum, mens en anden antager en gymnasieelev. Men alle tre modeller genererede svar, der kunne overbevise en uinformeret bruger om, at begivenheden var √¶gte.

Prompt engineering-teknikker som _metaprompting_ og _temperature configuration_ kan til en vis grad reducere model-fabrikationer. Nye prompt engineering-_arkitekturer_ integrerer ogs√• nye v√¶rkt√∏jer og teknikker problemfrit i prompt-flowet for at afb√∏de eller mindske nogle af disse effekter.

## Case Study: GitHub Copilot

Lad os afslutte dette afsnit med at f√• en fornemmelse af, hvordan prompt engineering bruges i virkelige l√∏sninger ved at se p√• et Case Study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI Pair Programmer" ‚Äì den oms√¶tter tekstprompter til kodeforslag og er integreret i dit udviklingsmilj√∏ (f.eks. Visual Studio Code) for en problemfri brugeroplevelse. Som dokumenteret i blogserien nedenfor, var den tidligste version baseret p√• OpenAI Codex-modellen ‚Äì hvor ingeni√∏rer hurtigt inds√• behovet for at finjustere modellen og udvikle bedre prompt engineering-teknikker for at forbedre kodekvaliteten. I juli [pr√¶senterede de en forbedret AI-model, der g√•r ud over Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for endnu hurtigere forslag.

L√¶s indl√¶ggene i r√¶kkef√∏lge for at f√∏lge deres l√¶ringsrejse.

- **Maj 2023** | [GitHub Copilot bliver bedre til at forst√• din kode](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Indenfor GitHub: Arbejde med LLM‚Äôerne bag GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jun 2023** | [S√•dan skriver du bedre prompts til GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [.. GitHub Copilot g√•r ud over Codex med forbedret AI-model](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En udviklers guide til prompt engineering og LLM‚Äôer](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [S√•dan bygger du en enterprise LLM-app: L√¶ringer fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• bladre i deres [Engineering blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere indl√¶g som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), der viser, hvordan disse modeller og teknikker _anvendes_ til at drive virkelige applikationer.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Prompt Konstruktion

Vi har set, hvorfor prompt engineering er vigtigt ‚Äì nu skal vi forst√•, hvordan prompts _konstrueres_, s√• vi kan evaluere forskellige teknikker for mere effektiv promptdesign.

### Grundl√¶ggende Prompt

Lad os starte med den grundl√¶ggende prompt: en tekstinput sendt til modellen uden anden kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste par ord af den amerikanske nationalsang til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), fuldf√∏rer den straks svaret med de n√¶ste linjer, hvilket illustrerer den grundl√¶ggende forudsigelsesadf√¶rd.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det lyder som om, du starter teksten til "The Star-Spangled Banner," USA‚Äôs nationalsang. Hele teksten er ... |

### Kompleks Prompt

Lad os nu tilf√∏je kontekst og instruktioner til den grundl√¶ggende prompt. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) giver os mulighed for at konstruere en kompleks prompt som en samling af _beskeder_ med:

- Input/output-par, der afspejler _bruger_-input og _assistent_-svar.
- Systembesked, der s√¶tter konteksten for assistentens adf√¶rd eller personlighed.

Anmodningen er nu i nedenst√•ende form, hvor _tokeniseringen_ effektivt fanger relevant information fra kontekst og samtale. At √¶ndre systemkonteksten kan nu have lige s√• stor indflydelse p√• kvaliteten af fuldf√∏relser som de givne brugerinput.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I ovenst√•ende eksempler var brugerprompten en simpel tekstforesp√∏rgsel, der kan tolkes som en anmodning om information. Med _instruktionsprompter_ kan vi bruge den tekst til at specificere en opgave mere detaljeret og give AI‚Äôen bedre vejledning. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruktionstype    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Write a description of the Civil War                                                                                                                                                                                                   | _returnerede et simpelt afsnit_                                                                                            | Simpel              |
| Write a description of the Civil War. Provide key dates and events and describe their significance                                                                                                                                     | _returnerede et afsnit efterfulgt af en liste med n√∏glebegivenheder og beskrivelser_                                       | Kompleks            |
| Write a description of the Civil War in 1 paragraph. Provide 3 bullet points with key dates and their significance. Provide 3 more bullet points with key historical figures and their contributions. Return the output as a JSON file | _returnerer mere omfattende detaljer i en tekstboks, formateret som JSON, som du kan kopiere og inds√¶tte i en fil og validere efter behov_ | Kompleks. Formateret.|

## Prim√¶rt Indhold

I ovenst√•ende eksempler var prompten stadig ret √•ben, hvilket tillod LLM‚Äôen at afg√∏re, hvilken del af dens fortr√¶nede datas√¶t der var relevant. Med designm√∏nsteret _prim√¶rt indhold_ opdeles inputteksten i to dele:

- en instruktion (handling)
- relevant indhold (der p√•virker handlingen)

Her er et eksempel, hvor instruktionen er at "opsummere dette i 2 s√¶tninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planet fra Solen og den st√∏rste i solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter i solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og har v√¶ret kendt af gamle civilisationer siden f√∏r den skrevne historie. Den er opkaldt efter den romerske gud Jupiter.[19] N√•r man ser p√• Jupiter fra Jorden, kan den v√¶re s√• lysst√¶rk, at dens reflekterede lys kaster synlige skygger,[20] og den er i gennemsnit det tredje mest lysst√¶rke naturlige objekt p√• nattehimlen efter M√•nen og Venus. <br/> **Opsummer dette i 2 korte s√¶tninger** | Jupiter, den femte planet fra Solen, er den st√∏rste i solsystemet og kendt for at v√¶re et af de mest lysst√¶rke objekter p√• nattehimlen. Opkaldt efter den romerske gud Jupiter, er det en gasgigant med en masse, der er to og en halv gang s√• stor som alle de andre planeter i solsystemet tilsammen. |

Segmentet med prim√¶rt indhold kan bruges p√• forskellige m√•der til at skabe mere effektive instruktioner:

- **Eksempler** ‚Äì i stedet for at fort√¶lle modellen, hvad den skal g√∏re med en eksplicit instruktion, giver man den eksempler p√•, hvad den skal g√∏re, og lader den udlede m√∏nsteret.
- **Signaler** ‚Äì f√∏lg instruktionen med et "signal", der forbereder fuldf√∏relsen og guider modellen mod mere relevante svar.
- **Skabeloner** ‚Äì disse er gentagelige ‚Äôopskrifter‚Äô til prompts med pladsholdere (variabler), der kan tilpasses med data til specifikke brugsscenarier.

Lad os udforske disse i praksis.

### Brug af Eksempler

Dette er en tilgang, hvor du bruger det prim√¶re indhold til at "fodre modellen" med nogle eksempler p√• det √∏nskede output for en given instruktion og lader den udlede m√∏nsteret for det √∏nskede output. Afh√¶ngigt af antallet af eksempler kan vi have zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r nu af tre komponenter:

- En opgavebeskrivelse
- Nogle f√• eksempler p√• det √∏nskede output
- Starten p√• et nyt eksempel (som bliver en implicit opgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :----------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot    | "The Sun is Shining". Translate to Spanish                                                                                                          | "El Sol est√° brillando".    |
| One-shot     | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                               | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot     | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>   | Basketball                  |
|              |                                                                                                                                                      |                             |

Bem√¶rk, hvordan vi m√•tte give en eksplicit instruktion ("Translate to Spanish") i zero-shot prompting, men den udledes i one-shot prompting-eksemplet. Few-shot-eksemplet viser, hvordan flere eksempler g√∏r det muligt for modeller at lave mere pr√¶cise slutninger uden yderligere instruktioner.

### Prompt Signaler

En anden teknik til at bruge prim√¶rt indhold er at give _signaler_ i stedet for eksempler. I dette tilf√¶lde giver vi modellen et skub i den rigtige retning ved at _starte den_ med et uddrag, der afspejler det √∏nskede svarformat. Modellen "tager signalet" og forts√¶tter i samme stil.

| Antal Signaler | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | Jupiter er den femte planet fra Solen og den st√∏rste i solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang s√• stor som alle de andre planeter i solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og har v√¶ret kendt af gamle civilisationer siden f√∏r den skrevne historie.

**Summarize This**                                       | Jupiter er den st√∏rste planet i vores solsystem og den femte fra solen. Det er en gasgigant med en masse, der er 1/1000 af solens, men den er tungere end alle de andre planeter tilsammen. Oldtidens civilisationer har kendt til Jupiter i lang tid, og den er let synlig p√• nattehimlen. |
| 1              | Jupiter er den femte planet fra solen og den st√∏rste i solsystemet. Det er en gasgigant med en masse, der er en tusindedel af solens, men to og en halv gang s√• stor som alle de andre planeter i solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og den har v√¶ret kendt af oldtidens civilisationer siden f√∏r historisk tid. <br/>**Summarize This** <br/> Det vi l√¶rte er, at Jupiter | er den femte planet fra solen og den st√∏rste i solsystemet. Det er en gasgigant med en masse, der er en tusindedel af solens, men to og en halv gang s√• stor som alle de andre planeter tilsammen. Den er let synlig med det blotte √∏je og har v√¶ret kendt siden oldtiden.                        |
| 2              | Jupiter er den femte planet fra solen og den st√∏rste i solsystemet. Det er en gasgigant med en masse, der er en tusindedel af solens, men to og en halv gang s√• stor som alle de andre planeter i solsystemet tilsammen. Jupiter er et af de klareste objekter, der kan ses med det blotte √∏je p√• nattehimlen, og den har v√¶ret kendt af oldtidens civilisationer siden f√∏r historisk tid. <br/>**Summarize This** <br/> Top 3 fakta vi l√¶rte:         | 1. Jupiter er den femte planet fra solen og den st√∏rste i solsystemet. <br/> 2. Det er en gasgigant med en masse, der er en tusindedel af solens...<br/> 3. Jupiter har v√¶ret synlig for det blotte √∏je siden oldtiden ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Prompt Templates

En prompt-skabelon er en _foruddefineret opskrift p√• en prompt_, som kan gemmes og genbruges efter behov for at skabe mere konsistente brugeroplevelser i stor skala. I sin enkleste form er det blot en samling af prompt-eksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), der b√•de indeholder de interaktive prompt-komponenter (bruger- og systembeskeder) og API-drevne anmodningsformater ‚Äì for at underst√∏tte genbrug.

I en mere kompleks form som [dette eksempel fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) indeholder den _pladsholdere_, som kan erstattes med data fra forskellige kilder (brugerinput, systemkontekst, eksterne datakilder osv.) for at generere en prompt dynamisk. Det giver os mulighed for at opbygge et bibliotek af genanvendelige prompts, der kan bruges til at skabe konsistente brugeroplevelser **programmatisk** i stor skala.

Endelig ligger den egentlige v√¶rdi i skabeloner i muligheden for at oprette og offentligg√∏re _prompt-biblioteker_ til vertikale anvendelsesomr√•der ‚Äì hvor prompt-skabelonen nu er _optimeret_ til at afspejle applikationsspecifik kontekst eller eksempler, der g√∏r svarene mere relevante og pr√¶cise for den m√•lrettede brugergruppe. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) er et godt eksempel p√• denne tilgang, hvor man samler et bibliotek af prompts til uddannelsesomr√•det med fokus p√• n√∏glem√•l som lektionsplanl√¶gning, l√¶seplanl√¶gning, elevvejledning osv.

## Supporting Content

Hvis vi ser p√• prompt-konstruktion som best√•ende af en instruktion (opgave) og et m√•l (prim√¶rt indhold), s√• er _sekund√¶rt indhold_ som ekstra kontekst, vi giver for at **p√•virke output p√• en eller anden m√•de**. Det kan v√¶re justeringsparametre, formateringsinstruktioner, emnetaksonomier osv., som hj√¶lper modellen med at _tilpasse_ sit svar, s√• det passer til de √∏nskede brugerform√•l eller forventninger.

For eksempel: Givet en kursuskatalog med omfattende metadata (navn, beskrivelse, niveau, metadata-tags, underviser osv.) for alle tilg√¶ngelige kurser i l√¶seplanen:

- kan vi definere en instruktion om at "opsummere kursuskataloget for efter√•ret 2023"
- kan vi bruge det prim√¶re indhold til at give nogle eksempler p√• det √∏nskede output
- kan vi bruge det sekund√¶re indhold til at identificere de 5 vigtigste "tags" af interesse.

Nu kan modellen levere et resum√© i det format, som eksemplerne viser ‚Äì men hvis et resultat har flere tags, kan den prioritere de 5 tags, der er identificeret i det sekund√¶re indhold.

---

<!--
LESSON TEMPLATE:
Denne enhed skal d√¶kke kernebegreb #1.
Underst√∏t begrebet med eksempler og referencer.

BEGREB #3:
Prompt Engineering teknikker.
Hvad er nogle grundl√¶ggende teknikker til prompt engineering?
Illustrer det med nogle √∏velser.
-->

## Prompting Best Practices

Nu hvor vi ved, hvordan prompts kan _konstrueres_, kan vi begynde at t√¶nke over, hvordan vi _designer_ dem, s√• de afspejler bedste praksis. Vi kan opdele det i to dele ‚Äì at have den rette _tankegang_ og anvende de rette _teknikker_.

### Prompt Engineering Mindset

Prompt Engineering er en pr√∏ve-og-fejl proces, s√• husk tre brede vejledende faktorer:

1. **Dom√¶neforst√•else er vigtig.** Svarenes n√∏jagtighed og relevans afh√¶nger af det _dom√¶ne_, som applikationen eller brugeren opererer i. Brug din intuition og dom√¶neekspertise til at **tilpasse teknikkerne** yderligere. For eksempel kan du definere _dom√¶nespecifikke personligheder_ i dine systemprompter eller bruge _dom√¶nespecifikke skabeloner_ i dine brugerprompter. Giv sekund√¶rt indhold, der afspejler dom√¶nespecifik kontekst, eller brug _dom√¶nespecifikke signaler og eksempler_ for at guide modellen mod velkendte brugsm√∏nstre.

2. **Modelforst√•else er vigtig.** Vi ved, at modeller er stokastiske af natur. Men modelimplementeringer kan ogs√• variere med hensyn til tr√¶ningsdatas√¶ttet (forudindl√¶rt viden), de funktioner, de tilbyder (f.eks. via API eller SDK) og typen af indhold, de er optimeret til (f.eks. kode vs. billeder vs. tekst). Forst√• styrker og begr√¶nsninger ved den model, du bruger, og brug den viden til at _prioritere opgaver_ eller bygge _tilpassede skabeloner_, der er optimeret til modellens kapaciteter.

3. **Iteration & validering er vigtig.** Modeller udvikler sig hurtigt, og det samme g√∏r teknikkerne til prompt engineering. Som dom√¶neekspert kan du have anden kontekst eller kriterier for _din_ specifikke applikation, som m√•ske ikke g√¶lder for det bredere f√¶llesskab. Brug prompt engineering-v√¶rkt√∏jer og teknikker til at "komme godt i gang" med prompt-konstruktionen, og iterer og valider resultaterne med din egen intuition og dom√¶neekspertise. Registrer dine indsigter og opbyg en **vidensbase** (f.eks. prompt-biblioteker), som andre kan bruge som ny baseline for hurtigere iterationer fremover.

## Best Practices

Lad os nu se p√• almindelige bedste praksisser, som anbefales af [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) praktikere.

| Hvad                              | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evaluer de nyeste modeller.       | Nye modelgenerationer har sandsynligvis forbedrede funktioner og kvalitet ‚Äì men kan ogs√• medf√∏re h√∏jere omkostninger. Evaluer dem for effekt, og tr√¶f derefter beslutning om migrering.                                                                |
| Adskil instruktioner & kontekst   | Tjek om din model/udbyder definerer _afgr√¶nsere_ for tydeligere at adskille instruktioner, prim√¶rt og sekund√¶rt indhold. Det kan hj√¶lpe modeller med at tildele v√¶gte mere pr√¶cist til tokens.                                                         |
| V√¶r specifik og klar              | Giv flere detaljer om √∏nsket kontekst, resultat, l√¶ngde, format, stil osv. Det forbedrer b√•de kvalitet og konsistens i svarene. Gem opskrifter i genanvendelige skabeloner.                                                                            |
| V√¶r beskrivende, brug eksempler   | Modeller reagerer ofte bedre p√• en "vis og fort√¶l"-tilgang. Start med en `zero-shot` tilgang, hvor du giver en instruktion (men ingen eksempler), og pr√∏v derefter `few-shot` som en finjustering, hvor du giver nogle f√• eksempler p√• √∏nsket output. Brug analogier. |
| Brug signaler til at kickstarte svar | Skub modellen mod et √∏nsket resultat ved at give nogle ledende ord eller s√¶tninger, som den kan bruge som udgangspunkt for svaret.                                                                                                               |
| Gentag for at forst√¶rke           | Nogle gange skal du gentage dig selv over for modellen. Giv instruktioner f√∏r og efter dit prim√¶re indhold, brug en instruktion og et signal osv. Iterer og valider for at se, hvad der virker.                                                         |
| R√¶kkef√∏lge betyder noget          | Den r√¶kkef√∏lge, du pr√¶senterer information for modellen i, kan p√•virke output, ogs√• i l√¶ringseksempler, p√• grund af recency bias. Pr√∏v forskellige muligheder for at finde det, der virker bedst.                                                       |
| Giv modellen en ‚Äúudvej‚Äù            | Giv modellen et _fallback_-svar, den kan bruge, hvis den ikke kan fuldf√∏re opgaven af en eller anden grund. Det kan mindske risikoen for, at modellen genererer falske eller opdigtede svar.                                                             |
|                                   |                                                                                                                                                                                                                                                   |

Som med enhver bedste praksis, husk at _din oplevelse kan variere_ afh√¶ngigt af model, opgave og dom√¶ne. Brug disse som udgangspunkt, og iterer for at finde det, der virker bedst for dig. Evaluer l√∏bende din prompt engineering-proces, efterh√•nden som nye modeller og v√¶rkt√∏jer bliver tilg√¶ngelige, med fokus p√• skalerbarhed og svar-kvalitet.

<!--
LESSON TEMPLATE:
Denne enhed skal indeholde en kodeudfordring, hvis relevant

UDFORDRING:
Link til en Jupyter Notebook med kun kodekommentarer i instruktionerne (kodeafsnit er tomme).

L√òSNING:
Link til en kopi af den Notebook med udfyldte prompts og k√∏rsel, der viser et eksempel.
-->

## Assignment

Tillykke! Du er n√•et til slutningen af lektionen! Det er tid til at pr√∏ve nogle af de koncepter og teknikker af med rigtige eksempler!

Til vores opgave bruger vi en Jupyter Notebook med √∏velser, du kan gennemf√∏re interaktivt. Du kan ogs√• udvide Notebooken med dine egne Markdown- og kodeceller for at udforske ideer og teknikker p√• egen h√•nd.

### For at komme i gang, fork repoet, og

- (Anbefalet) Start GitHub Codespaces
- (Alternativt) Klon repoet til din lokale enhed og brug det med Docker Desktop
- (Alternativt) √Öbn Notebooken i dit foretrukne Notebook-runtime-milj√∏.

### Dern√¶st, konfigurer dine milj√∏variabler

- Kopi√©r `.env.copy`-filen i repoets rod til `.env` og udfyld v√¶rdierne for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. G√• tilbage til [Learning Sandbox sektionen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) for at l√¶re hvordan.

### Dern√¶st, √•bn Jupyter Notebooken

- V√¶lg runtime-kernen. Hvis du bruger mulighed 1 eller 2, v√¶lg blot den standard Python 3.10.x kerne, som dev-containeren leverer.

Du er klar til at k√∏re √∏velserne. Bem√¶rk, at der ikke findes _rigtige eller forkerte_ svar her ‚Äì det handler om at pr√∏ve sig frem og opbygge intuition for, hvad der virker for en given model og applikationsdom√¶ne.

_Af denne grund er der ingen kode-l√∏sningsafsnit i denne lektion. I stedet vil Notebooken indeholde Markdown-celler med titlen "My Solution:", som viser et eksempel p√• output til reference._

 <!--
LESSON TEMPLATE:
Afslut afsnittet med en opsummering og ressourcer til selvstyret l√¶ring.
-->

## Knowledge check

Hvilken af f√∏lgende er en god prompt, der f√∏lger nogle rimelige bedste praksisser?

1. Vis mig et billede af en r√∏d bil  
2. Vis mig et billede af en r√∏d bil af m√¶rket Volvo og model XC90 parkeret ved en klippe med solen g√•ende ned  
3. Vis mig et billede af en r√∏d bil af m√¶rket Volvo og model XC90

A: 2, det er den bedste prompt, da den giver detaljer om "hvad" og g√•r i dybden med specifikationer (ikke bare en hvilken som helst bil, men et bestemt m√¶rke og model) og beskriver ogs√• omgivelserne. 3 er n√¶stbedst, da den ogs√• indeholder mange beskrivelser.

## üöÄ Challenge

Pr√∏v at bruge "cue"-teknikken med prompten: Fuldf√∏r s√¶tningen "Vis mig et billede af en r√∏d bil af m√¶rket Volvo og ". Hvad svarer den, og hvordan ville du forbedre det?

## Godt arbejde! Forts√¶t din l√¶ring

Vil du l√¶re mere om forskellige Prompt Engineering-koncept? G√• til [den fortsatte l√¶ringsside](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at finde andre gode ressourcer om emnet.

G√• videre til Lektion 5, hvor vi ser p√• [avancerede prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj√¶lp af AI-overs√¶ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr√¶ber os p√• n√∏jagtighed, bedes du v√¶re opm√¶rksom p√•, at automatiserede overs√¶ttelser kan indeholde fejl eller un√∏jagtigheder. Det oprindelige dokument p√• dets oprindelige sprog b√∏r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs√¶ttelse. Vi p√•tager os intet ansvar for misforst√•elser eller fejltolkninger, der opst√•r som f√∏lge af brugen af denne overs√¶ttelse.