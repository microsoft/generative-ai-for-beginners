<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b3cb38518cf4fe7714d2f5e74dfa3eb",
  "translation_date": "2025-10-03T09:38:06+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "da"
}
-->
# Grundl칝ggende om Prompt Engineering

[![Grundl칝ggende om Prompt Engineering](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.da.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduktion
Dette modul d칝kker essentielle begreber og teknikker til at skabe effektive prompts i generative AI-modeller. Den m친de, du skriver din prompt til en LLM, har betydning. En omhyggeligt udformet prompt kan give en bedre kvalitet af svar. Men hvad betyder begreber som _prompt_ og _prompt engineering_ egentlig? Og hvordan kan jeg forbedre den _input-prompt_, jeg sender til LLM'en? Disse sp칮rgsm친l vil vi fors칮ge at besvare i dette kapitel og det n칝ste.

_Generativ AI_ er i stand til at skabe nyt indhold (f.eks. tekst, billeder, lyd, kode osv.) som svar p친 brugerforesp칮rgsler. Den opn친r dette ved hj칝lp af _Large Language Models_ som OpenAI's GPT ("Generative Pre-trained Transformer") serie, der er tr칝net til at bruge naturligt sprog og kode.

Brugere kan nu interagere med disse modeller via velkendte paradigmer som chat, uden at have teknisk ekspertise eller tr칝ning. Modellerne er _prompt-baserede_ - brugere sender en tekstinput (prompt) og f친r et AI-svar (completion) tilbage. De kan derefter "chatte med AI'en" iterativt i samtaler med flere omgange og finjustere deres prompt, indtil svaret matcher deres forventninger.

"Prompts" bliver nu det prim칝re _programmeringsinterface_ for generative AI-applikationer, der fort칝ller modellerne, hvad de skal g칮re, og p친virker kvaliteten af de returnerede svar. "Prompt Engineering" er et hurtigt voksende studieomr친de, der fokuserer p친 _design og optimering_ af prompts for at levere konsistente og kvalitetspr칝stationer i stor skala.

## L칝ringsm친l

I denne lektion l칝rer vi, hvad Prompt Engineering er, hvorfor det er vigtigt, og hvordan vi kan udforme mere effektive prompts til en given model og applikationsm친l. Vi vil forst친 kernebegreber og bedste praksis for prompt engineering - og l칝re om et interaktivt Jupyter Notebooks "sandbox"-milj칮, hvor vi kan se disse begreber anvendt p친 virkelige eksempler.

Ved slutningen af denne lektion vil vi kunne:

1. Forklare, hvad prompt engineering er, og hvorfor det er vigtigt.
2. Beskrive komponenterne i en prompt og hvordan de bruges.
3. L칝re bedste praksis og teknikker for prompt engineering.
4. Anvende l칝rte teknikker p친 virkelige eksempler ved hj칝lp af en OpenAI-endpoint.

## N칮glebegreber

Prompt Engineering: Praksis med at designe og finjustere inputs for at guide AI-modeller mod at producere 칮nskede outputs.  
Tokenization: Processen med at konvertere tekst til mindre enheder, kaldet tokens, som en model kan forst친 og behandle.  
Instruction-Tuned LLMs: Store sprogmodeller (LLMs), der er blevet finjusteret med specifikke instruktioner for at forbedre deres svarn칮jagtighed og relevans.

## L칝ringssandbox

Prompt engineering er i 칮jeblikket mere kunst end videnskab. Den bedste m친de at forbedre vores intuition for det er at _칮ve mere_ og anvende en trial-and-error tilgang, der kombinerer ekspertise inden for applikationsdom칝net med anbefalede teknikker og model-specifikke optimeringer.

Jupyter Notebook, der ledsager denne lektion, giver et _sandbox_-milj칮, hvor du kan pr칮ve det, du l칝rer - enten l칮bende eller som en del af kodeudfordringen i slutningen. For at udf칮re 칮velserne skal du bruge:

1. **En Azure OpenAI API-n칮gle** - serviceendpointet for en implementeret LLM.  
2. **En Python-runtime** - hvor Notebook kan udf칮res.  
3. **Lokale milj칮variabler** - _fuldf칮r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) trin nu for at blive klar_.  

Notebooken kommer med _start칮velser_ - men du opfordres til at tilf칮je dine egne _Markdown_- (beskrivelse) og _Code_- (promptforesp칮rgsler) sektioner for at pr칮ve flere eksempler eller ideer - og opbygge din intuition for promptdesign.

## Illustreret guide

Vil du have det store overblik over, hvad denne lektion d칝kker, f칮r du dykker ned? Tjek denne illustrerede guide, som giver dig en fornemmelse af de vigtigste emner, der d칝kkes, og de vigtigste pointer, du skal t칝nke over i hver enkelt. Lektionens roadmap tager dig fra at forst친 kernebegreber og udfordringer til at adressere dem med relevante prompt engineering-teknikker og bedste praksis. Bem칝rk, at afsnittet "Avancerede teknikker" i denne guide refererer til indhold, der d칝kkes i det _n칝ste_ kapitel af dette pensum.

![Illustreret guide til Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.da.png)

## Vores startup

Lad os nu tale om, hvordan _dette emne_ relaterer til vores startup-mission om at [bringe AI-innovation til uddannelse](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi 칮nsker at bygge AI-drevne applikationer til _personlig l칝ring_ - s친 lad os t칝nke over, hvordan forskellige brugere af vores applikation kan "designe" prompts:

- **Administratorer** kan bede AI om at _analysere pensumdata for at identificere huller i d칝kningen_. AI kan opsummere resultaterne eller visualisere dem med kode.  
- **Undervisere** kan bede AI om at _generere en lektionsplan for en m친lgruppe og et emne_. AI kan opbygge den personlige plan i et specificeret format.  
- **Studerende** kan bede AI om at _tutorere dem i et vanskeligt emne_. AI kan nu vejlede studerende med lektioner, hints og eksempler skr칝ddersyet til deres niveau.  

Det er kun toppen af isbjerget. Tjek [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - et open-source prompt-bibliotek kurateret af uddannelseseksperter - for at f친 en bredere fornemmelse af mulighederne! _Pr칮v at k칮re nogle af disse prompts i sandboxen eller ved hj칝lp af OpenAI Playground for at se, hvad der sker!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Hvad er Prompt Engineering?

Vi startede denne lektion med at definere **Prompt Engineering** som processen med at _designe og optimere_ tekstinputs (prompts) for at levere konsistente og kvalitetspr칝stationer (completions) for en given applikationsm친l og model. Vi kan t칝nke p친 dette som en 2-trins proces:

- _designe_ den oprindelige prompt til en given model og m친l  
- _finjustere_ prompten iterativt for at forbedre kvaliteten af svaret  

Dette er n칮dvendigvis en trial-and-error proces, der kr칝ver brugerens intuition og indsats for at opn친 optimale resultater. S친 hvorfor er det vigtigt? For at besvare det sp칮rgsm친l skal vi f칮rst forst친 tre begreber:

- _Tokenization_ = hvordan modellen "ser" prompten  
- _Base LLMs_ = hvordan grundmodellen "behandler" en prompt  
- _Instruction-Tuned LLMs_ = hvordan modellen nu kan se "opgaver"  

### Tokenization

En LLM ser prompts som en _sekvens af tokens_, hvor forskellige modeller (eller versioner af en model) kan tokenisere den samme prompt p친 forskellige m친der. Da LLM'er er tr칝net p친 tokens (og ikke p친 r친 tekst), har m친den, hvorp친 prompts bliver tokeniseret, en direkte indvirkning p친 kvaliteten af det genererede svar.

For at f친 en intuition for, hvordan tokenization fungerer, kan du pr칮ve v칝rkt칮jer som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist nedenfor. Kopier din prompt ind - og se, hvordan den bliver konverteret til tokens, og v칝r opm칝rksom p친, hvordan mellemrumstegn og tegns칝tning h친ndteres. Bem칝rk, at dette eksempel viser en 칝ldre LLM (GPT-3) - s친 at pr칮ve dette med en nyere model kan give et andet resultat.

![Tokenization](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.da.png)

### Begreb: Grundmodeller

N친r en prompt er blevet tokeniseret, er den prim칝re funktion af ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grundmodel) at forudsige token i den sekvens. Da LLM'er er tr칝net p친 massive tekstdatas칝t, har de en god fornemmelse af de statistiske relationer mellem tokens og kan lave den forudsigelse med en vis sikkerhed. Bem칝rk, at de ikke forst친r _betydningen_ af ordene i prompten eller token; de ser bare et m칮nster, de kan "fuldf칮re" med deres n칝ste forudsigelse. De kan forts칝tte med at forudsige sekvensen, indtil de bliver afbrudt af brugerintervention eller en forudbestemt betingelse.

Vil du se, hvordan prompt-baseret completion fungerer? Indtast ovenst친ende prompt i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardindstillingerne. Systemet er konfigureret til at behandle prompts som foresp칮rgsler om information - s친 du b칮r se en completion, der tilfredsstiller denne kontekst.

Men hvad hvis brugeren 칮nskede at se noget specifikt, der opfyldte nogle kriterier eller opgavem친l? Her kommer _instruction-tuned_ LLM'er ind i billedet.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.da.png)

### Begreb: Instruction-Tuned LLMs

En [Instruction-Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grundmodellen og finjusterer den med eksempler eller input/output-par (f.eks. multi-turn "beskeder"), der kan indeholde klare instruktioner - og svaret fra AI fors칮ger at f칮lge den instruktion.

Dette bruger teknikker som Reinforcement Learning with Human Feedback (RLHF), der kan tr칝ne modellen til at _f칮lge instruktioner_ og _l칝re af feedback_, s친 den producerer svar, der er bedre egnet til praktiske applikationer og mere relevante for brugerens m친l.

Lad os pr칮ve det - genbes칮g ovenst친ende prompt, men 칝ndr nu _systembeskeden_ for at give f칮lgende instruktion som kontekst:

> _Opsummer indholdet, du f친r, for en andenklasses elev. Hold resultatet til 칠t afsnit med 3-5 punktlister._

Se, hvordan resultatet nu er tilpasset til at afspejle det 칮nskede m친l og format? En underviser kan nu direkte bruge dette svar i sine slides til den klasse.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.da.png)

## Hvorfor har vi brug for Prompt Engineering?

Nu hvor vi ved, hvordan prompts behandles af LLM'er, lad os tale om _hvorfor_ vi har brug for prompt engineering. Svaret ligger i det faktum, at nuv칝rende LLM'er udg칮r en r칝kke udfordringer, der g칮r _p친lidelige og konsistente completions_ mere udfordrende at opn친 uden at l칝gge indsats i promptkonstruktion og optimering. For eksempel:

1. **Modelresponser er stokastiske.** Den _samme prompt_ vil sandsynligvis producere forskellige svar med forskellige modeller eller modelversioner. Og den kan endda producere forskellige resultater med den _samme model_ p친 forskellige tidspunkter. _Prompt engineering-teknikker kan hj칝lpe os med at minimere disse variationer ved at give bedre rammer_.  

1. **Modeller kan fabrikere svar.** Modeller er forudtr칝net med _store men begr칝nsede_ datas칝t, hvilket betyder, at de mangler viden om begreber uden for den tr칝ningsramme. Som et resultat kan de producere completions, der er un칮jagtige, imagin칝re eller direkte modstridende med kendte fakta. _Prompt engineering-teknikker hj칝lper brugere med at identificere og afb칮de s친danne fabrikationer, f.eks. ved at bede AI om citater eller r칝sonnement_.  

1. **Modellers kapaciteter vil variere.** Nyere modeller eller modelgenerationer vil have rigere kapaciteter, men ogs친 bringe unikke s칝rheder og afvejninger i omkostninger og kompleksitet. _Prompt engineering kan hj칝lpe os med at udvikle bedste praksis og arbejdsgange, der abstraherer forskelle og tilpasser sig model-specifikke krav p친 skalerbare, problemfri m친der_.  

Lad os se dette i aktion i OpenAI eller Azure OpenAI Playground:

- Brug den samme prompt med forskellige LLM-implementeringer (f.eks. OpenAI, Azure OpenAI, Hugging Face) - s친 du variationerne?  
- Brug den samme prompt gentagne gange med den _samme_ LLM-implementering (f.eks. Azure OpenAI Playground) - hvordan adskilte disse variationer sig?  

### Eksempel p친 fabrikationer

I dette kursus bruger vi udtrykket **"fabrikation"** til at referere til f칝nomenet, hvor LLM'er nogle gange genererer faktuelt ukorrekt information p친 grund af begr칝nsninger i deres tr칝ning eller andre begr칝nsninger. Du har m친ske ogs친 h칮rt dette omtalt som _"hallucinationer"_ i popul칝re artikler eller forskningspapirer. Vi anbefaler dog st칝rkt at bruge _"fabrikation"_ som udtryk, s친 vi ikke utilsigtet antropomorfiserer adf칝rden ved at tilskrive en menneskelignende egenskab til et maskindrevet resultat. Dette underst칮tter ogs친 [Retningslinjer for ansvarlig AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologisk perspektiv, ved at fjerne udtryk, der ogs친 kan betragtes som st칮dende eller ikke-inkluderende i visse kontekster.

Vil du f친 en fornemmelse af, hvordan fabrikationer fungerer? T칝nk p친 en prompt, der instruerer AI'en i at generere indhold for et ikke-eksisterende emne (for at sikre, at det ikke findes i tr칝ningsdatas칝ttet). For eksempel - jeg pr칮vede denne prompt:

> **Prompt:** generer en lektionsplan om den Marskrig i 2076.
En web-s칮gning viste mig, at der findes fiktive beretninger (f.eks. tv-serier eller b칮ger) om krige p친 Mars - men ingen fra 친r 2076. Almindelig logik fort칝ller os ogs친, at 2076 er _i fremtiden_ og derfor ikke kan forbindes med en virkelig begivenhed.

S친 hvad sker der, n친r vi tester denne prompt med forskellige LLM-udbydere?

> **Svar 1**: OpenAI Playground (GPT-35)

![Svar 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.da.png)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Svar 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.da.png)

> **Svar 3**: Hugging Face Chat Playground (LLama-2)

![Svar 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.da.png)

Som forventet producerer hver model (eller modelversion) lidt forskellige svar takket v칝re stokastisk adf칝rd og variationer i modelkapacitet. For eksempel retter 칠n model sig mod et publikum p친 8. klasses niveau, mens en anden antager en gymnasieelev. Men alle tre modeller genererede svar, der kunne overbevise en uinformeret bruger om, at begivenheden var reel.

Prompt engineering-teknikker som _metaprompting_ og _temperature configuration_ kan reducere model-fabrikationer til en vis grad. Nye prompt engineering-_arkitekturer_ integrerer ogs친 nye v칝rkt칮jer og teknikker problemfrit i prompt-flowet for at afb칮de eller reducere nogle af disse effekter.

## Case Study: GitHub Copilot

Lad os afslutte denne sektion med at f친 en fornemmelse af, hvordan prompt engineering bruges i virkelige l칮sninger ved at se p친 en case study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI-parprogrammer" - den konverterer tekstprompter til kodeforslag og er integreret i dit udviklingsmilj칮 (f.eks. Visual Studio Code) for en problemfri brugeroplevelse. Som dokumenteret i serien af blogs nedenfor, var den tidligste version baseret p친 OpenAI Codex-modellen - med ingeni칮rer, der hurtigt inds친 behovet for at finjustere modellen og udvikle bedre prompt engineering-teknikker for at forbedre kodekvaliteten. I juli [debuterede de en forbedret AI-model, der g친r ud over Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for endnu hurtigere forslag.

L칝s blogindl칝ggene i r칝kkef칮lge for at f칮lge deres l칝ringsrejse.

- **Maj 2023** | [GitHub Copilot bliver bedre til at forst친 din kode](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inde i GitHub: Arbejde med LLM'erne bag GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jun 2023** | [S친dan skriver du bedre prompts til GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jul 2023** | [.. GitHub Copilot g친r ud over Codex med forbedret AI-model](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En udviklers guide til prompt engineering og LLM'er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [S친dan bygger du en enterprise LLM-app: L칝rdom fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs친 gennemse deres [Engineering blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere indl칝g som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), der viser, hvordan disse modeller og teknikker _anvendes_ til at drive virkelige applikationer.

---

## Prompt Konstruktion

Vi har set, hvorfor prompt engineering er vigtigt - nu skal vi forst친, hvordan prompts _konstrueres_, s친 vi kan evaluere forskellige teknikker for mere effektiv prompt design.

### Grundl칝ggende Prompt

Lad os starte med den grundl칝ggende prompt: en tekstinput sendt til modellen uden anden kontekst. Her er et eksempel - n친r vi sender de f칮rste ord af den amerikanske nationalsang til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), fuldf칮rer den straks svaret med de n칝ste linjer, hvilket illustrerer den grundl칝ggende forudsigelsesadf칝rd.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det lyder som om, du starter teksten til "The Star-Spangled Banner," USA's nationalsang. Den fulde tekst er ... |

### Kompleks Prompt

Nu tilf칮jer vi kontekst og instruktioner til den grundl칝ggende prompt. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) giver os mulighed for at konstruere en kompleks prompt som en samling af _beskeder_ med:

- Input/output-par, der afspejler _bruger_-input og _assistent_-svar.
- Systembesked, der s칝tter konteksten for assistentens adf칝rd eller personlighed.

Foresp칮rgslen er nu i nedenst친ende form, hvor _tokeniseringen_ effektivt fanger relevant information fra kontekst og samtale. Nu kan 칝ndring af systemkonteksten v칝re lige s친 afg칮rende for kvaliteten af svarene som de brugerinput, der gives.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I ovenst친ende eksempler var brugerprompten en simpel tekstforesp칮rgsel, der kan tolkes som en anmodning om information. Med _instruktions_-prompter kan vi bruge den tekst til at specificere en opgave mere detaljeret og give bedre vejledning til AI'en. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruktionstype    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivelse af den amerikanske borgerkrig                                                                                                                                                                                     | _returnerede et simpelt afsnit_                                                                                           | Simpel              |
| Skriv en beskrivelse af den amerikanske borgerkrig. Angiv n칮gledatoer og begivenheder og beskriv deres betydning                                                                                                                       | _returnerede et afsnit efterfulgt af en liste over n칮glebegivenheder med datoer og beskrivelser_                           | Kompleks            |
| Skriv en beskrivelse af den amerikanske borgerkrig i 칠t afsnit. Angiv 3 punktlister med n칮gledatoer og deres betydning. Angiv 3 yderligere punktlister med n칮glehistoriske personer og deres bidrag. Returner output som en JSON-fil      | _returnerede mere omfattende detaljer i en tekstboks, formateret som JSON, som du kan kopiere og inds칝tte i en fil_       | Kompleks. Formateret. |

## Prim칝rt Indhold

I ovenst친ende eksempler var prompten stadig ret 친ben, hvilket tillod LLM'en at beslutte, hvilken del af dens forudtr칝nede datas칝t der var relevant. Med designm칮nsteret _prim칝rt indhold_ opdeles inputteksten i to dele:

- en instruktion (handling)
- relevant indhold (der p친virker handlingen)

Her er et eksempel, hvor instruktionen er "Opsummer dette i 2 s칝tninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planet fra Solen og den st칮rste i Solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang s친 stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de lyseste objekter, der er synlige for det blotte 칮je p친 nattehimlen, og har v칝ret kendt af gamle civilisationer siden f칮r den skrevne historie. Den er opkaldt efter den romerske gud Jupiter. N친r den ses fra Jorden, kan Jupiter v칝re s친 lysst칝rk, at dens reflekterede lys kan kaste synlige skygger og er i gennemsnit det tredje-lyseste naturlige objekt p친 nattehimlen efter M친nen og Venus. <br/> **Opsummer dette i 2 korte s칝tninger** | Jupiter, den femte planet fra Solen, er den st칮rste i Solsystemet og kendt for at v칝re et af de lyseste objekter p친 nattehimlen. Opkaldt efter den romerske gud Jupiter, er det en gasgigant med en masse, der er to og en halv gang s친 stor som alle de andre planeter tilsammen. |

Segmentet med prim칝rt indhold kan bruges p친 forskellige m친der til at drive mere effektive instruktioner:

- **Eksempler** - i stedet for at fort칝lle modellen, hvad den skal g칮re med en eksplicit instruktion, giv den eksempler p친, hvad den skal g칮re, og lad den udlede m칮nsteret.
- **Cues** - f칮lg instruktionen med en "cue", der prim칝rt guider modellen mod mere relevante svar.
- **Templates** - disse er gentagelige 'opskrifter' for prompts med pladsholdere (variabler), der kan tilpasses med data til specifikke anvendelser.

Lad os udforske disse i praksis.

### Brug af Eksempler

Dette er en tilgang, hvor du bruger det prim칝re indhold til at "fodre modellen" med nogle eksempler p친 det 칮nskede output for en given instruktion og lader den udlede m칮nsteret for det 칮nskede output. Baseret p친 antallet af eksempler, der gives, kan vi have zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best친r nu af tre komponenter:

- En opgavebeskrivelse
- Et par eksempler p친 det 칮nskede output
- Starten p친 et nyt eksempel (som bliver en implicit opgavebeskrivelse)

| L칝ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot   | "Solen skinner". Overs칝t til spansk                                                                                                                  | "El Sol est치 brillando".    |
| One-shot    | "Solen skinner" => ""El Sol est치 brillando". <br> "Det er en kold og bl칝sende dag" =>                                                                | "Es un d칤a fr칤o y ventoso". |
| Few-shot    | Spilleren l칮b baserne => Baseball <br/> Spilleren slog et es => Tennis <br/> Spilleren slog en sekser => Cricket <br/> Spilleren lavede et slam-dunk => | Basketball                  |
|             |                                                                                                                                                       |                             |

Bem칝rk, hvordan vi m친tte give eksplicit instruktion ("Overs칝t til spansk") i zero-shot prompting, men det bliver udledt i one-shot prompting-eksemplet. Few-shot eksemplet viser, hvordan tilf칮jelse af flere eksempler tillader modeller at lave mere pr칝cise udledninger uden yderligere instruktioner.

### Prompt Cues

En anden teknik til at bruge prim칝rt indhold er at give _cues_ i stedet for eksempler. I dette tilf칝lde giver vi modellen et skub i den rigtige retning ved _at starte den_ med et snippet, der afspejler det 칮nskede svarformat. Modellen "tager cue'et" og forts칝tter i samme stil.

| Antal Cues | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :--------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0          | Jupiter er den femte planet fra Solen og den st칮rste i Solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang s친 stor som alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de lyseste objekter, der er synlige for det blotte 칮je p친 nattehimlen, og har v칝ret kendt af gamle civilisationer siden f칮r den skrevne historie. <br/>**Opsummer Dette**                                       | Jupiter er den st칮rste planet i vores Solsystem og den femte fra Solen. Det er en gasgigant med en masse, der er 1/1000 af Solens, men den er tungere end alle de andre planeter tilsammen. Gamle civilisationer har kendt til Jupiter i lang tid, og den er let synlig p친 nattehimlen. |
| 1              | Jupiter er den femte planet fra Solen og den st칮rste i Solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang st칮rre end alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de klareste objekter, der er synlige for det blotte 칮je p친 nattehimlen, og har v칝ret kendt af gamle civilisationer siden f칮r historien blev nedskrevet. <br/>**Opsummer Dette** <br/> Det vi l칝rte er, at Jupiter | er den femte planet fra Solen og den st칮rste i Solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang st칮rre end alle de andre planeter tilsammen. Den er let synlig for det blotte 칮je og har v칝ret kendt siden oldtiden.                        |
| 2              | Jupiter er den femte planet fra Solen og den st칮rste i Solsystemet. Det er en gasgigant med en masse, der er en tusindedel af Solens, men to og en halv gang st칮rre end alle de andre planeter i Solsystemet tilsammen. Jupiter er et af de klareste objekter, der er synlige for det blotte 칮je p친 nattehimlen, og har v칝ret kendt af gamle civilisationer siden f칮r historien blev nedskrevet. <br/>**Opsummer Dette** <br/> Top 3 Fakta Vi L칝rte:         | 1. Jupiter er den femte planet fra Solen og den st칮rste i Solsystemet. <br/> 2. Det er en gasgigant med en masse, der er en tusindedel af Solens...<br/> 3. Jupiter har v칝ret synlig for det blotte 칮je siden oldtiden ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Prompt Skabeloner

En prompt-skabelon er en _foruddefineret opskrift p친 en prompt_, som kan gemmes og genbruges efter behov for at skabe mere konsistente brugeroplevelser i stor skala. I sin enkleste form er det blot en samling af prompt-eksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), der indeholder b친de de interaktive prompt-komponenter (bruger- og systemmeddelelser) og det API-drevne anmodningsformat - for at underst칮tte genbrug.

I sin mere komplekse form, som [dette eksempel fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), indeholder den _pladsholdere_, der kan erstattes med data fra forskellige kilder (brugerinput, systemkontekst, eksterne datakilder osv.) for dynamisk at generere en prompt. Dette giver os mulighed for at skabe et bibliotek af genanvendelige prompts, der kan bruges til at skabe konsistente brugeroplevelser **programmatisk** i stor skala.

Endelig ligger den reelle v칝rdi af skabeloner i evnen til at oprette og udgive _prompt-biblioteker_ for vertikale applikationsdom칝ner - hvor prompt-skabelonen nu er _optimeret_ til at afspejle applikationsspecifik kontekst eller eksempler, der g칮r svarene mere relevante og pr칝cise for den m친lrettede brugergruppe. Repositoriet [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) er et godt eksempel p친 denne tilgang, hvor der kurateres et bibliotek af prompts til uddannelsesomr친det med fokus p친 n칮glem친l som lektionsplanl칝gning, curriculum design, elevvejledning osv.

## Underst칮ttende Indhold

Hvis vi t칝nker p친 prompt-konstruktion som at have en instruktion (opgave) og et m친l (prim칝rt indhold), s친 er _sekund칝rt indhold_ som yderligere kontekst, vi giver for at **p친virke output p친 en eller anden m친de**. Det kan v칝re justeringsparametre, formateringsinstruktioner, emnetaksonomier osv., der kan hj칝lpe modellen med at _tilpasse_ sit svar til at opfylde de 칮nskede brugerform친l eller forventninger.

For eksempel: Givet en kursuskatalog med omfattende metadata (navn, beskrivelse, niveau, metadata-tags, instrukt칮r osv.) om alle de tilg칝ngelige kurser i pensum:

- vi kan definere en instruktion til "opsummer kursuskataloget for efter친ret 2023"
- vi kan bruge det prim칝re indhold til at give nogle eksempler p친 det 칮nskede output
- vi kan bruge det sekund칝re indhold til at identificere de 5 vigtigste "tags" af interesse.

Nu kan modellen give en opsummering i det format, der vises af de f친 eksempler - men hvis et resultat har flere tags, kan den prioritere de 5 tags, der er identificeret i det sekund칝re indhold.

---

<!--
LEKTIONS SKABELON:
Denne enhed b칮r d칝kke kernekoncept #1.
Styrk konceptet med eksempler og referencer.

KONCEPT #3:
Prompt Engineering Teknikker.
Hvad er nogle grundl칝ggende teknikker til prompt engineering?
Illustrer det med nogle 칮velser.
-->

## Bedste Fremgangsm친der for Prompting

Nu hvor vi ved, hvordan prompts kan _konstrueres_, kan vi begynde at t칝nke p친, hvordan vi kan _designe_ dem til at afspejle bedste praksis. Vi kan t칝nke p친 dette i to dele - at have den rette _tankegang_ og anvende de rette _teknikker_.

### Tankegang for Prompt Engineering

Prompt Engineering er en proces med pr칮vning og fejl, s친 husk tre brede vejledende faktorer:

1. **Dom칝neforst친else er vigtigt.** Svarets n칮jagtighed og relevans er en funktion af det _dom칝ne_, hvor applikationen eller brugeren opererer. Brug din intuition og dom칝neekspertise til at **tilpasse teknikker** yderligere. For eksempel kan du definere _dom칝nespecifikke personligheder_ i dine systemprompts eller bruge _dom칝nespecifikke skabeloner_ i dine brugerprompts. Giv sekund칝rt indhold, der afspejler dom칝nespecifikke kontekster, eller brug _dom칝nespecifikke cues og eksempler_ til at guide modellen mod velkendte brugsm칮nstre.

2. **Modelforst친else er vigtigt.** Vi ved, at modeller er stokastiske af natur. Men modelimplementeringer kan ogs친 variere med hensyn til det tr칝ningsdatas칝t, de bruger (forudindl칝rt viden), de funktioner, de tilbyder (f.eks. via API eller SDK), og den type indhold, de er optimeret til (f.eks. kode vs. billeder vs. tekst). Forst친 styrkerne og begr칝nsningerne ved den model, du bruger, og brug den viden til at _prioritere opgaver_ eller bygge _tilpassede skabeloner_, der er optimeret til modellens kapaciteter.

3. **Iteration og validering er vigtigt.** Modeller udvikler sig hurtigt, og det samme g칮r teknikkerne til prompt engineering. Som dom칝neekspert kan du have anden kontekst eller kriterier for _din_ specifikke applikation, som m친ske ikke g칝lder for det bredere samfund. Brug v칝rkt칮jer og teknikker til prompt engineering til at "springe i gang" med prompt-konstruktion, og iterer og valider resultaterne ved hj칝lp af din egen intuition og dom칝neekspertise. Registrer dine indsigter og opret en **vidensbase** (f.eks. prompt-biblioteker), der kan bruges som en ny baseline af andre for hurtigere iterationer i fremtiden.

## Bedste Fremgangsm친der

Lad os nu se p친 almindelige bedste praksis, der anbefales af [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) praktikere.

| Hvad                              | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evaluer de nyeste modeller.       | Nye modelgenerationer har sandsynligvis forbedrede funktioner og kvalitet - men kan ogs친 medf칮re h칮jere omkostninger. Evaluer dem for deres effekt, og tr칝f derefter migrationsbeslutninger.                                                                                |
| Adskil instruktioner og kontekst   | Tjek om din model/udbyder definerer _afgr칝nsninger_ for tydeligere at skelne instruktioner, prim칝rt og sekund칝rt indhold. Dette kan hj칝lpe modeller med mere pr칝cist at tildele v칝gte til tokens.                                                         |
| V칝r specifik og klar             | Giv flere detaljer om den 칮nskede kontekst, resultat, l칝ngde, format, stil osv. Dette vil forbedre b친de kvaliteten og konsistensen af svarene. Fang opskrifter i genanvendelige skabeloner.                                                          |
| V칝r beskrivende, brug eksempler      | Modeller kan reagere bedre p친 en "vis og fort칝l"-tilgang. Start med en `zero-shot` tilgang, hvor du giver en instruktion (men ingen eksempler), og pr칮v derefter `few-shot` som en forbedring, hvor du giver nogle eksempler p친 det 칮nskede output. Brug analogier. |
| Brug cues til at starte fuldf칮relser | Skub det mod et 칮nsket resultat ved at give det nogle ledende ord eller s칝tninger, som det kan bruge som udgangspunkt for svaret.                                                                                                               |
| Gentag dig selv                       | Nogle gange kan det v칝re n칮dvendigt at gentage dig selv over for modellen. Giv instruktioner f칮r og efter dit prim칝re indhold, brug en instruktion og et cue osv. Iterer og valider for at se, hvad der fungerer.                                                         |
| R칝kkef칮lge betyder noget                     | Den r칝kkef칮lge, du pr칝senterer information for modellen, kan p친virke outputtet, selv i l칝ringseksemplerne, takket v칝re recency bias. Pr칮v forskellige muligheder for at se, hvad der fungerer bedst.                                                               |
| Giv modellen en "udvej"           | Giv modellen et _fallback_-svar, den kan give, hvis den ikke kan fuldf칮re opgaven af en eller anden grund. Dette kan reducere chancerne for, at modeller genererer falske eller fabrikerede svar.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Som med enhver bedste praksis, husk at _din erfaring kan variere_ afh칝ngigt af modellen, opgaven og dom칝net. Brug disse som et udgangspunkt, og iterer for at finde ud af, hvad der fungerer bedst for dig. Genovervej konstant din prompt engineering-proces, efterh친nden som nye modeller og v칝rkt칮jer bliver tilg칝ngelige, med fokus p친 proces-skalerbarhed og svarkvalitet.

<!--
LEKTIONS SKABELON:
Denne enhed b칮r give en kodeudfordring, hvis det er relevant

UDFORDRING:
Link til en Jupyter Notebook med kun kodekommentarer i instruktionerne (kodeafsnit er tomme).

L칒SNING:
Link til en kopi af den Notebook med prompts udfyldt og k칮rt, der viser, hvad et eksempel kunne v칝re.
-->

## Opgave

Tillykke! Du n친ede til slutningen af lektionen! Det er tid til at teste nogle af de begreber og teknikker med rigtige eksempler!

Til vores opgave vil vi bruge en Jupyter Notebook med 칮velser, du kan gennemf칮re interaktivt. Du kan ogs친 udvide Notebooken med dine egne Markdown- og kodeceller for at udforske ideer og teknikker p친 egen h친nd.

### For at komme i gang, fork repoen, og derefter

- (Anbefalet) Start GitHub Codespaces
- (Alternativt) Klon repoen til din lokale enhed og brug den med Docker Desktop
- (Alternativt) 칀bn Notebooken med dit foretrukne Notebook runtime-milj칮.

### Konfigurer derefter dine milj칮variabler

- Kopier `.env.copy`-filen i repo-roden til `.env` og udfyld v칝rdierne for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. G친 tilbage til [Learning Sandbox sektionen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) for at l칝re hvordan.

### 칀bn derefter Jupyter Notebooken

- V칝lg runtime-kernen. Hvis du bruger mulighed 1 eller 2, skal du blot v칝lge standard Python 3.10.x-kernen, der leveres af udviklingscontaineren.

Du er klar til at k칮re 칮velserne. Bem칝rk, at der ikke er _rigtige og forkerte_ svar her - bare udforskning af muligheder gennem pr칮vning og fejl og opbygning af intuition for, hvad der fungerer for en given model og applikationsdom칝ne.

_Af denne grund er der ingen kode-l칮sningssegmenter i denne lektion. I stedet vil Notebooken have Markdown-celler med titlen "Min l칮sning:" der viser et eksempeloutput som reference._

 <!--
LEKTIONS SKABELON:
Afslut sektionen med en opsummering og ressourcer til selvstyret l칝ring.
-->

## Videnscheck

Hvilket af f칮lgende er en god prompt, der f칮lger nogle rimelige bedste praksis?

1. Vis mig et billede af en r칮d bil
2. Vis mig et billede af en r칮d bil af m칝rket Volvo og model XC90 parkeret ved en klippe med solnedgang
3. Vis mig et billede af en r칮d bil af m칝rket Volvo og model XC90

A: 2, det er den bedste prompt, da den giver detaljer om "hvad" og g친r i detaljer (ikke bare en hvilken som helst bil, men et specifikt m칝rke og model), og den beskriver ogs친 den overordnede setting. 3 er n칝stbedst, da den ogs친 indeholder mange beskrivelser.

## 游 Udfordring

Se om du kan udnytte "cue"-teknikken med prompten: Fuldf칮r s칝tningen "Vis mig et billede af en r칮d bil af m칝rket Volvo og ". Hvad svarer den med, og hvordan ville du forbedre det?

## Godt Arbejde! Forts칝t Din L칝ring

Vil du l칝re mere om forskellige begreber inden for Prompt Engineering? G친 til [siden for fortsat l칝ring](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for at finde andre gode ressourcer om dette emne.

G친 videre til Lektion 5, hvor vi vil se p친 [avancerede prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfraskrivelse**:  
Dette dokument er blevet oversat ved hj칝lp af AI-overs칝ttelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestr칝ber os p친 at opn친 n칮jagtighed, skal det bem칝rkes, at automatiserede overs칝ttelser kan indeholde fejl eller un칮jagtigheder. Det originale dokument p친 dets oprindelige sprog b칮r betragtes som den autoritative kilde. For kritisk information anbefales professionel menneskelig overs칝ttelse. Vi p친tager os ikke ansvar for misforst친elser eller fejltolkninger, der m친tte opst친 som f칮lge af brugen af denne overs칝ttelse.