{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den følgende notesbog blev automatisk genereret af GitHub Copilot Chat og er kun beregnet til indledende opsætning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduktion til Prompt Engineering\n",
    "Prompt engineering er processen med at designe og optimere prompts til opgaver inden for naturlig sprogbehandling. Det handler om at vælge de rigtige prompts, justere deres parametre og vurdere deres præstation. Prompt engineering er afgørende for at opnå høj nøjagtighed og effektivitet i NLP-modeller. I dette afsnit vil vi gennemgå det grundlæggende i prompt engineering ved hjælp af OpenAI-modeller til udforskning.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse 1: Tokenisering\n",
    "Undersøg tokenisering med tiktoken, en open source og hurtig tokenizer fra OpenAI\n",
    "Se [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) for flere eksempler.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse 2: Bekræft opsætning af OpenAI API-nøgle\n",
    "\n",
    "Kør koden nedenfor for at sikre, at din OpenAI-endpoint er sat korrekt op. Koden prøver blot en simpel prompt og validerer svaret. Inputtet `oh say can you see` bør blive fulgt op med noget i stil med `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]       \n",
    "    response = client.chat.completions.create(   \n",
    "        model=deployment,                                         \n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse 3: Opdigtede svar\n",
    "Undersøg hvad der sker, når du beder LLM’en om at give svar på en prompt om et emne, der måske ikke eksisterer, eller om emner, den måske ikke kender til, fordi de ligger uden for dens fortrænede datasæt (mere nylige emner). Se hvordan svaret ændrer sig, hvis du prøver en anden prompt eller en anden model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse 4: Instruktionsbaseret\n",
    "Brug variablen \"text\" til at angive det primære indhold \n",
    "og variablen \"prompt\" til at give en instruktion, der relaterer sig til det primære indhold.\n",
    "\n",
    "Her beder vi modellen om at opsummere teksten for en elev i 2. klasse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse 5: Kompleks prompt\n",
    "Prøv en forespørgsel, der har system-, bruger- og assistentbeskeder\n",
    "Systemet sætter assistentens kontekst\n",
    "Bruger- og assistentbeskeder giver kontekst til en samtale over flere omgange\n",
    "\n",
    "Bemærk, hvordan assistentens personlighed er sat til \"sarkastisk\" i systemkonteksten.\n",
    "Prøv at bruge en anden personlighedskontekst. Eller prøv en anden række input/output-beskeder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Øvelse: Udforsk din intuition\n",
    "Eksemplerne ovenfor giver dig mønstre, du kan bruge til at lave nye prompts (simple, komplekse, instruktioner osv.) – prøv at lave andre øvelser for at udforske nogle af de andre idéer, vi har talt om, som eksempler, hints og mere.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokument er blevet oversat ved hjælp af AI-oversættelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selvom vi bestræber os på nøjagtighed, skal du være opmærksom på, at automatiske oversættelser kan indeholde fejl eller unøjagtigheder. Det originale dokument på dets oprindelige sprog bør betragtes som den autoritative kilde. For kritiske oplysninger anbefales professionel, menneskelig oversættelse. Vi påtager os intet ansvar for misforståelser eller fejltolkninger, der måtte opstå ved brug af denne oversættelse.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "9b900544221c8d986e06ee6d25debef7",
   "translation_date": "2025-08-25T13:09:39+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/aoai-assignment.ipynb",
   "language_code": "da"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}