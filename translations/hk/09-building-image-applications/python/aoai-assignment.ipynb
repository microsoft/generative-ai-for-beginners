{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立圖像生成應用程式\n",
    "\n",
    "大型語言模型（LLM）不只可以生成文字，還可以根據文字描述生成圖像。圖像這種媒介在醫療科技、建築、旅遊、遊戲開發等領域都非常有用。本章會介紹兩個最受歡迎的圖像生成模型：DALL-E 和 Midjourney。\n",
    "\n",
    "## 前言\n",
    "\n",
    "本課程會涵蓋：\n",
    "\n",
    "- 圖像生成及其用途\n",
    "- DALL-E 和 Midjourney 的原理及運作方式\n",
    "- 如何建立一個圖像生成應用程式\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "完成本課後，你將能夠：\n",
    "\n",
    "- 建立一個圖像生成應用程式\n",
    "- 用 meta prompts 為你的應用程式設定界限\n",
    "- 使用 DALL-E 和 Midjourney\n",
    "\n",
    "## 為什麼要建立圖像生成應用程式？\n",
    "\n",
    "圖像生成應用程式是探索生成式 AI 能力的好方法。它們可以用於：\n",
    "\n",
    "- **圖像編輯及合成**：你可以根據不同需求生成圖像，例如圖像編輯或合成。\n",
    "\n",
    "- **應用於多個行業**：可以為醫療科技、旅遊、遊戲開發等行業生成各種圖像。\n",
    "\n",
    "## 情境：Edu4All\n",
    "\n",
    "在這一課，我們會繼續以我們的初創公司 Edu4All 為例。學生可以為他們的評估創作圖像，圖像內容由學生自行決定，例如為自己的童話故事畫插圖、創造新角色，或幫助他們將想法和概念視覺化。\n",
    "\n",
    "例如，Edu4All 的學生在課堂上學習地標時，可以生成以下圖像：\n",
    "\n",
    "![Edu4All startup, class on monuments, Eifel Tower](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.hk.png)\n",
    "\n",
    "用這樣的 prompt：\n",
    "\n",
    "> 「狗狗在清晨陽光下的艾菲爾鐵塔旁邊」\n",
    "\n",
    "## 什麼是 DALL-E 和 Midjourney？\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) 和 [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) 是目前最受歡迎的圖像生成模型之一，讓你可以用 prompt 生成圖像。\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "先講 DALL-E，它是一個生成式 AI 模型，可以根據文字描述生成圖像。\n",
    "\n",
    "> [DALL-E 是由兩個模型組成，CLIP 和 diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)。\n",
    "\n",
    "- **CLIP** 是一個模型，可以從圖像和文字中生成 embedding（數值化的資料表示）。\n",
    "\n",
    "- **Diffused attention** 是一個根據 embedding 生成圖像的模型。DALL-E 在大量圖像和文字的數據集上訓練，可以根據文字描述生成圖像。例如，DALL-E 可以生成戴帽子的貓，或是有莫霍克頭的狗。\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney 的運作方式和 DALL-E 類似，也是根據文字 prompt 生成圖像。你可以用 prompt 例如「戴帽子的貓」或「有莫霍克頭的狗」來生成圖像。\n",
    "\n",
    "![Image generated by Midjourney, mechanical pigeon](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*圖片來源：Wikipedia，圖像由 Midjourney 生成*\n",
    "\n",
    "## DALL-E 和 Midjourney 的運作原理\n",
    "\n",
    "首先，[DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)。DALL-E 是一個基於 transformer 架構的生成式 AI 模型，採用 *autoregressive transformer*。\n",
    "\n",
    "*Autoregressive transformer* 是指模型如何根據文字描述逐步生成圖像：每次生成一個像素，然後用已生成的像素去生成下一個像素。這個過程會經過神經網絡的多層，直到整張圖像完成。\n",
    "\n",
    "透過這個流程，DALL-E 可以控制圖像中的屬性、物件、特徵等。不過，DALL-E 2 和 3 對生成圖像的控制力更高，\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立你的第一個圖像生成應用程式\n",
    "\n",
    "咁要點樣先可以建立一個圖像生成應用程式呢？你需要以下幾個程式庫：\n",
    "\n",
    "- **python-dotenv**，強烈建議你用呢個程式庫，將你的密碼放喺 *.env* 檔案，唔好直接寫喺程式碼入面。\n",
    "- **openai**，你會用呢個程式庫同 OpenAI API 溝通。\n",
    "- **pillow**，用嚟喺 Python 處理圖像。\n",
    "- **requests**，幫你發送 HTTP 請求。\n",
    "\n",
    "1. 建立一個 *.env* 檔案，內容如下：\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    你可以喺 Azure Portal 嘅「Keys and Endpoint」部分搵到呢啲資料。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 將以上嘅 library 集合喺一個叫做 *requirements.txt* 嘅檔案入面，方法如下：\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. 之後，建立虛擬環境並安裝呢啲 library：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 對於 Windows，用以下指令去建立同啟動你嘅虛擬環境：\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. 喺一個叫 *app.py* 嘅檔案入面加以下程式碼：\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "解釋下呢段程式碼：\n",
    "\n",
    "- 首先，我哋引入咗需要用到嘅 library，包括 OpenAI library、dotenv library、requests library 同埋 Pillow library。\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- 跟住，我哋會由 *.env* 檔案載入環境變數。\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- 之後，我哋設定 OpenAI API 嘅 endpoint、key、version 同 type。\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- 然後，我哋會產生張圖片：\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    上面嘅程式碼會回傳一個 JSON 物件，入面包含咗生成圖片嘅 URL。我哋可以用呢個 URL 下載張圖片，然後儲存落檔案。\n",
    "\n",
    "- 最後，我哋會打開張圖片，並用標準圖片檢視器去顯示佢：\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### 更詳細解釋點樣生成圖片\n",
    "\n",
    "我哋再詳細睇下產生圖片嘅程式碼：\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**，就係用嚟生成圖片嘅文字提示。呢個例子用咗 \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\"。\n",
    "- **size**，就係生成出嚟嘅圖片尺寸。呢度我哋生成一張 1024x1024 像素嘅圖片。\n",
    "- **n**，就係要生成幾多張圖片。呢個例子會生成兩張圖片。\n",
    "- **temperature**，係一個控制生成式 AI 輸出隨機程度嘅參數。temperature 介乎 0 至 1，0 代表輸出係固定，1 代表輸出好隨機。預設值係 0.7。\n",
    "\n",
    "仲有更多同圖片有關嘅功能，我哋會喺下一節再講。\n",
    "\n",
    "## 圖片生成嘅進階功能\n",
    "\n",
    "你見到我哋只用幾行 Python code 就可以生成一張圖片。不過，其實仲有更多嘢可以做到。\n",
    "\n",
    "你仲可以做到以下幾樣嘢：\n",
    "\n",
    "- **進行編輯**。只要提供一張現有圖片、一個遮罩同一個提示，你就可以改變張圖片。例如，你可以喺圖片某個部分加啲嘢。好似我哋隻兔仔圖片，你可以幫兔仔加頂帽。做法就係提供張圖片、一個遮罩（指出要改變嘅區域），再加個文字提示講要做咩。\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    原本嘅圖片只會有隻兔仔，但最終嘅圖片就會有頂帽喺兔仔頭上。\n",
    "    \n",
    "- **創建變化版本**。\n",
    "    想知多啲可以睇下我哋嘅 [OpenAI notebook](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst)。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責聲明**：  \n本文件經由 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 翻譯。我們致力確保翻譯準確，但請注意，自動翻譯可能會出現錯誤或不準確之處。原始語言的文件應被視為具權威性的來源。如涉及重要資訊，建議尋求專業人手翻譯。本翻譯所引致的任何誤解或曲解，我們概不負責。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:09:50+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "hk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}