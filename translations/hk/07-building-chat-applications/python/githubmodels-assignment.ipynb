{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 第七章：建立聊天應用程式\n",
    "## Github Models API 快速入門\n",
    "\n",
    "本筆記本改編自 [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst)，當中包含了可以存取 [Azure OpenAI](notebook-azure-openai.ipynb) 服務的筆記本。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 概覽  \n",
    "「大型語言模型其實就係一個將文字對應到文字嘅函數。當你輸入一段文字，大型語言模型會嘗試預測下一段會出現咩文字」(1)。呢份「快速入門」筆記會為用戶介紹高層次嘅LLM概念、開始使用AML所需嘅核心套件、簡單介紹提示設計，仲有幾個唔同應用場景嘅短例子。\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 目錄\n",
    "\n",
    "[概覽](../../../../07-building-chat-applications/python)  \n",
    "[如何使用 OpenAI 服務](../../../../07-building-chat-applications/python)  \n",
    "[1. 建立你的 OpenAI 服務](../../../../07-building-chat-applications/python)  \n",
    "[2. 安裝](../../../../07-building-chat-applications/python)  \n",
    "[3. 認證資料](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[使用案例](../../../../07-building-chat-applications/python)  \n",
    "[1. 文字摘要](../../../../07-building-chat-applications/python)  \n",
    "[2. 文字分類](../../../../07-building-chat-applications/python)  \n",
    "[3. 產生新產品名稱](../../../../07-building-chat-applications/python)  \n",
    "[4. 微調分類器](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[參考資料](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 建立你的第一個提示  \n",
    "這個簡短練習會為你介紹如何在 Github Models 提交提示，完成一個簡單的「摘要」任務。\n",
    "\n",
    "**步驟**:  \n",
    "1. 如果你未安裝過，請先在你的 python 環境安裝 `azure-ai-inference` 套件。  \n",
    "2. 載入標準輔助函式庫，並設定 Github Models 的認證。  \n",
    "3. 選擇一個適合你任務的模型  \n",
    "4. 為模型建立一個簡單的提示  \n",
    "5. 將你的請求提交到模型 API！\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. 安裝 `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. 搵啱嘅模型  \n",
    "GPT-3.5-turbo 或 GPT-4 模型可以理解同產生自然語言。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. 提示設計\n",
    "\n",
    "「大型語言模型的神奇之處在於，透過在大量文本上訓練以減少預測錯誤，模型最終會學到對這些預測有用的概念。例如，佢哋會學識以下概念」(1):\n",
    "\n",
    "* 點樣串字\n",
    "* 文法點運作\n",
    "* 點樣改寫句子\n",
    "* 點樣答問題\n",
    "* 點樣同人對話\n",
    "* 點樣用唔同語言寫作\n",
    "* 點樣寫程式\n",
    "* 等等\n",
    "\n",
    "#### 點樣控制大型語言模型\n",
    "「喺所有輸入大型語言模型嘅方法之中，最有影響力嘅就係文字提示」(1)。\n",
    "\n",
    "大型語言模型可以用幾種方式提示去產生輸出：\n",
    "\n",
    "指令：直接話俾模型知你想要咩\n",
    "補全：引導模型去補完你想要嘅開頭\n",
    "示範：用以下方法俾模型睇你想要咩：\n",
    "提示入面有幾個例子\n",
    "喺微調訓練數據集入面有幾百甚至幾千個例子\n",
    "\n",
    "#### 創建提示有三個基本指引：\n",
    "\n",
    "**展示同講明**。無論用指令、例子，定係兩者結合，都要清楚表達你想要咩。如果你想模型將一個清單按字母順序排列，或者將一段文字按情感分類，就要俾佢睇到你想要咁做。\n",
    "\n",
    "**提供高質素數據**。如果你想建立一個分類器，或者想模型跟住某個模式行，記住要有足夠例子。記得校對你嘅例子——模型通常夠聰明，可以識穿基本嘅串字錯誤，照樣俾你回應，但佢有時都會以為你係特登咁做，咁就會影響回應。\n",
    "\n",
    "**檢查你嘅設定。** temperature 同 top_p 呢兩個設定會影響模型產生回應時有幾大隨機性。如果你問嘅問題只得一個正確答案，就應該將呢啲設定調低。如果你想要多啲唔同嘅回應，就可以調高啲。最多人犯嘅錯誤就係以為呢啲設定係「聰明度」或者「創意」控制。\n",
    "\n",
    "來源：https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 摘要文字  \n",
    "#### 挑戰  \n",
    "透過在文字段落結尾加上「tl;dr:」來進行摘要。留意模型如何在沒有額外指示下完成多項任務。你可以嘗試用更具描述性的提示詞來調整模型行為，從而自訂你想要的摘要效果(3)。\n",
    "\n",
    "最近的研究顯示，先在大量文本語料庫上進行預訓練，再針對特定任務微調，可以在許多 NLP 任務和基準上取得顯著進步。雖然這種方法的架構通常與任務無關，但仍然需要數千甚至數萬個任務專屬的微調數據集。相比之下，人類通常只需少量例子或簡單指示就能完成新的語言任務——這是現有 NLP 系統仍然難以做到的。我們發現，擴大語言模型規模能大幅提升無需任務專屬微調的少量示例表現，有時甚至能與過去最先進的微調方法媲美。\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 多個使用情境的練習  \n",
    "1. 摘要文本  \n",
    "2. 分類文本  \n",
    "3. 產生新產品名稱\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 分類文本  \n",
    "#### 挑戰  \n",
    "將項目分類到推理時提供的類別中。在以下例子中，我們會在提示中同時提供類別和需要分類的文本（*playground_reference）。\n",
    "\n",
    "客戶查詢：你好，我手提電腦鍵盤有一粒鍵最近壞咗，我需要換一粒新嘅：\n",
    "\n",
    "分類類別：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 產生新產品名稱\n",
    "#### 挑戰\n",
    "根據範例字詞創作產品名稱。我哋會喺提示入面加入關於要為邊款產品起名嘅資訊，亦會提供一個類似嘅例子，展示我哋期望收到嘅命名模式。我哋亦將 temperature 數值調高，令結果更有創意同多變。\n",
    "\n",
    "產品描述：家用奶昔機\n",
    "種子字詞：快、健康、細小。\n",
    "產品名稱：HomeShaker、Fit Shaker、QuickShake、Shake Maker\n",
    "\n",
    "產品描述：一對可以適合任何腳型嘅鞋。\n",
    "種子字詞：適應、合腳、全適配。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 參考資料  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio 範例](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [微調 GPT-3 以分類文本的最佳實踐](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 需要更多協助\n",
    "\n",
    "[OpenAI 商業化團隊](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# 貢獻者\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責聲明**：  \n本文件經由 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 翻譯。我們致力於提供準確的翻譯，但請注意，自動翻譯可能會出現錯誤或不準確之處。原始語言的文件應被視為具權威性的來源。如涉及重要資訊，建議尋求專業人工翻譯。本翻譯所引致的任何誤解或誤釋，我們概不負責。\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:26:23+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "hk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}