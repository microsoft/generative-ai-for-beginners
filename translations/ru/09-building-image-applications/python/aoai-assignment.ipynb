{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание приложения для генерации изображений\n",
    "\n",
    "LLM могут делать гораздо больше, чем просто генерировать текст. С их помощью также можно создавать изображения по текстовым описаниям. Использование изображений как отдельной модальности может быть очень полезно в самых разных сферах — от медицины и архитектуры до туризма и разработки игр. В этой главе мы рассмотрим две самые популярные модели генерации изображений: DALL-E и Midjourney.\n",
    "\n",
    "## Введение\n",
    "\n",
    "В этом уроке мы разберём:\n",
    "\n",
    "- Генерацию изображений и её преимущества.\n",
    "- DALL-E и Midjourney: что это такое и как они работают.\n",
    "- Как создать собственное приложение для генерации изображений.\n",
    "\n",
    "## Цели обучения\n",
    "\n",
    "После прохождения этого урока вы сможете:\n",
    "\n",
    "- Создать приложение для генерации изображений.\n",
    "- Определять рамки вашего приложения с помощью мета-промптов.\n",
    "- Работать с DALL-E и Midjourney.\n",
    "\n",
    "## Зачем создавать приложение для генерации изображений?\n",
    "\n",
    "Приложения для генерации изображений — отличный способ познакомиться с возможностями генеративного ИИ. Их можно использовать, например, для:\n",
    "\n",
    "- **Редактирования и синтеза изображений**. Можно создавать изображения для самых разных задач, например, для редактирования или синтеза новых изображений.\n",
    "\n",
    "- **Применения в различных отраслях**. Такие приложения находят применение в медицине, туризме, игровой индустрии и других сферах.\n",
    "\n",
    "## Сценарий: Edu4All\n",
    "\n",
    "В рамках этого урока мы продолжим работать с нашим стартапом Edu4All. Студенты будут создавать изображения для своих заданий — какие именно, решают они сами: это могут быть иллюстрации к собственной сказке, новый персонаж для истории или визуализация идей и концепций.\n",
    "\n",
    "Вот пример того, что могут создать студенты Edu4All, если на уроке они изучают памятники:\n",
    "\n",
    "![Стартап Edu4All, урок о памятниках, Эйфелева башня](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.ru.png)\n",
    "\n",
    "используя такой промпт, как\n",
    "\n",
    "> \"Собака рядом с Эйфелевой башней на рассвете\"\n",
    "\n",
    "## Что такое DALL-E и Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) и [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) — две самые популярные модели генерации изображений, которые позволяют создавать изображения по текстовым запросам.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Начнём с DALL-E — это генеративная модель ИИ, которая создаёт изображения по текстовым описаниям.\n",
    "\n",
    "> [DALL-E — это комбинация двух моделей: CLIP и diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** — модель, которая создаёт эмбеддинги (числовые представления данных) для изображений и текста.\n",
    "\n",
    "- **Diffused attention** — модель, которая генерирует изображения на основе эмбеддингов. DALL-E обучена на большом наборе изображений и текстов и может создавать изображения по текстовым описаниям. Например, с помощью DALL-E можно получить изображение кота в шляпе или собаки с ирокезом.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney работает похожим образом: она также создаёт изображения по текстовым промптам. С помощью Midjourney можно, например, сгенерировать изображение “кота в шляпе” или “собаки с ирокезом”.\n",
    "\n",
    "![Изображение, сгенерированное Midjourney, механический голубь](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Изображение сгенерировано Midjourney, источник — Wikipedia*\n",
    "\n",
    "## Как работают DALL-E и Midjourney\n",
    "\n",
    "Сначала рассмотрим [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E — это генеративная модель ИИ, основанная на архитектуре трансформеров с использованием *авторегрессионного трансформера*.\n",
    "\n",
    "*Авторегрессионный трансформер* определяет, как модель создаёт изображения по текстовым описаниям: изображение генерируется по одному пикселю за раз, и уже созданные пиксели используются для генерации следующих. Этот процесс проходит через несколько слоёв нейронной сети, пока изображение не будет полностью готово.\n",
    "\n",
    "Благодаря такому подходу DALL-E может управлять атрибутами, объектами, характеристиками и другими деталями создаваемого изображения. Однако DALL-E 2 и 3 дают ещё больше контроля над результатом,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создание вашего первого приложения для генерации изображений\n",
    "\n",
    "Что нужно для создания приложения для генерации изображений? Вам понадобятся следующие библиотеки:\n",
    "\n",
    "- **python-dotenv** — настоятельно рекомендуется использовать эту библиотеку, чтобы хранить секретные данные в файле *.env* отдельно от кода.\n",
    "- **openai** — с помощью этой библиотеки вы будете взаимодействовать с OpenAI API.\n",
    "- **pillow** — для работы с изображениями в Python.\n",
    "- **requests** — чтобы выполнять HTTP-запросы.\n",
    "\n",
    "1. Создайте файл *.env* со следующим содержимым:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Найдите эту информацию в Azure Portal для вашего ресурса в разделе \"Ключи и конечная точка\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Соберите перечисленные выше библиотеки в файл *requirements.txt* следующим образом:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. Затем создайте виртуальное окружение и установите библиотеки:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Для Windows используйте следующие команды для создания и активации виртуального окружения:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Добавьте следующий код в файл с именем *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Давайте разберём этот код:\n",
    "\n",
    "- Сначала мы импортируем необходимые библиотеки, включая библиотеку OpenAI, dotenv, requests и Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Затем мы загружаем переменные окружения из файла *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- После этого мы указываем endpoint, ключ для OpenAI API, версию и тип.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Далее мы генерируем изображение:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Приведённый выше код возвращает JSON-объект, который содержит ссылку на сгенерированное изображение. Мы можем использовать эту ссылку, чтобы скачать изображение и сохранить его в файл.\n",
    "\n",
    "- В конце мы открываем изображение и используем стандартную программу просмотра изображений для его отображения:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Подробнее о генерации изображения\n",
    "\n",
    "Давайте подробнее рассмотрим код, который отвечает за генерацию изображения:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** — это текстовый запрос, который используется для генерации изображения. В данном случае мы используем запрос: \"Кролик на лошади, держит леденец, на туманном лугу, где растут нарциссы\".\n",
    "- **size** — размер генерируемого изображения. В этом примере мы создаём изображение размером 1024x1024 пикселей.\n",
    "- **n** — количество генерируемых изображений. В данном случае мы создаём два изображения.\n",
    "- **temperature** — параметр, который определяет степень случайности результата генеративной модели ИИ. Значение температуры находится в диапазоне от 0 до 1: 0 означает полностью детерминированный результат, а 1 — максимально случайный. Значение по умолчанию — 0.7.\n",
    "\n",
    "С изображениями можно делать и другие вещи, о которых мы расскажем в следующем разделе.\n",
    "\n",
    "## Дополнительные возможности генерации изображений\n",
    "\n",
    "Вы уже увидели, как можно сгенерировать изображение с помощью нескольких строк кода на Python. Однако с изображениями можно делать гораздо больше.\n",
    "\n",
    "Вы также можете:\n",
    "\n",
    "- **Редактировать изображения**. Предоставив существующее изображение, маску и текстовый запрос, вы можете изменить изображение. Например, можно добавить что-то на определённую часть изображения. Представьте наше изображение с кроликом — вы можете добавить кролику шляпу. Для этого нужно передать само изображение, маску (обозначающую область для изменения) и текстовый запрос, описывающий, что нужно сделать.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    Базовое изображение будет содержать только кролика, а итоговое — кролика в шляпе.\n",
    "\n",
    "- **Создавать вариации**.\n",
    "    Подробнее смотрите в нашем [блокноте OpenAI](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Отказ от ответственности**:  \nЭтот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:07:02+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "ru"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}