{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Глава 7: Создание чат-приложений\n",
    "## Быстрый старт с Github Models API\n",
    "\n",
    "Этот ноутбук адаптирован из [репозитория примеров Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), который содержит ноутбуки для работы с сервисами [Azure OpenAI](notebook-azure-openai.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Обзор  \n",
    "«Большие языковые модели — это функции, которые преобразуют текст в текст. Получив входную строку текста, большая языковая модель пытается предсказать, какой текст будет следующим»(1). Этот «быстрый старт» познакомит пользователей с основными понятиями LLM, ключевыми требованиями пакета для начала работы с AML, даст простое введение в проектирование подсказок и приведет несколько коротких примеров различных сценариев использования.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Оглавление  \n",
    "\n",
    "[Обзор](../../../../07-building-chat-applications/python)  \n",
    "[Как использовать OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[1. Создание вашего OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[2. Установка](../../../../07-building-chat-applications/python)    \n",
    "[3. Учетные данные](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Примеры использования](../../../../07-building-chat-applications/python)    \n",
    "[1. Суммирование текста](../../../../07-building-chat-applications/python)  \n",
    "[2. Классификация текста](../../../../07-building-chat-applications/python)  \n",
    "[3. Генерация новых названий продуктов](../../../../07-building-chat-applications/python)  \n",
    "[4. Тонкая настройка классификатора](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Ссылки](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Создайте свой первый промпт  \n",
    "Это короткое упражнение даст базовое представление о том, как отправлять промпты модели в Github Models для простой задачи \"суммирования\".\n",
    "\n",
    "\n",
    "**Шаги**:  \n",
    "1. Установите библиотеку `azure-ai-inference` в вашу среду Python, если она ещё не установлена.  \n",
    "2. Загрузите стандартные вспомогательные библиотеки и настройте учетные данные для Github Models.  \n",
    "3. Выберите модель для вашей задачи  \n",
    "4. Сформулируйте простой промпт для модели  \n",
    "5. Отправьте ваш запрос в API модели!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Установите `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Поиск подходящей модели  \n",
    "Модели GPT-3.5-turbo или GPT-4 способны понимать и генерировать естественный язык.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Проектирование запросов  \n",
    "\n",
    "«Волшебство больших языковых моделей заключается в том, что, обучаясь минимизировать ошибку предсказания на огромных объемах текста, модели в итоге осваивают понятия, полезные для этих предсказаний. Например, они осваивают такие вещи, как»(1):\n",
    "\n",
    "* как правильно писать слова\n",
    "* как работает грамматика\n",
    "* как перефразировать\n",
    "* как отвечать на вопросы\n",
    "* как вести диалог\n",
    "* как писать на разных языках\n",
    "* как программировать\n",
    "* и многое другое\n",
    "\n",
    "#### Как управлять большой языковой моделью  \n",
    "«Из всех входных данных для большой языковой модели самым значимым является текстовый запрос»(1).\n",
    "\n",
    "Большие языковые модели можно побудить к генерации ответа несколькими способами:\n",
    "\n",
    "Инструкция: Скажите модели, что вы хотите получить  \n",
    "Завершение: Побудите модель закончить начатое вами  \n",
    "Демонстрация: Покажите модели, что вы хотите, с помощью:\n",
    "Нескольких примеров в самом запросе  \n",
    "Сотен или тысяч примеров в обучающем датасете для дообучения»\n",
    "\n",
    "\n",
    "\n",
    "#### Существует три основных правила создания запросов:\n",
    "\n",
    "**Показывайте и объясняйте**. Дайте понять, что вы хотите, с помощью инструкций, примеров или их сочетания. Если вы хотите, чтобы модель отсортировала список по алфавиту или определила тональность абзаца, покажите ей, что именно это вы ожидаете.\n",
    "\n",
    "**Используйте качественные данные**. Если вы хотите создать классификатор или чтобы модель следовала определенному шаблону, убедитесь, что у вас достаточно примеров. Обязательно проверьте свои примеры на ошибки — модель обычно достаточно умна, чтобы игнорировать простые опечатки и все равно дать ответ, но она может решить, что это сделано специально, и это повлияет на результат.\n",
    "\n",
    "**Проверьте настройки.** Параметры temperature и top_p определяют, насколько детерминированно модель будет генерировать ответ. Если вы ожидаете единственно правильный ответ, эти параметры стоит понизить. Если же вам нужны более разнообразные ответы, их можно повысить. Самая частая ошибка — думать, что эти параметры отвечают за «ум» или «креативность» модели.\n",
    "\n",
    "\n",
    "Источник: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Суммирование текста  \n",
    "#### Задача  \n",
    "Суммируйте текст, добавив 'tl;dr:' в конце отрывка. Обратите внимание, что модель понимает, как выполнять множество задач без дополнительных инструкций. Вы можете поэкспериментировать с более описательными подсказками, чем tl;dr, чтобы изменить поведение модели и настроить получаемое вами суммирование(3).  \n",
    "\n",
    "Недавние исследования показали значительный прогресс во многих задачах и бенчмарках обработки естественного языка благодаря предварительному обучению на большом корпусе текстов с последующей донастройкой под конкретную задачу. Хотя архитектура обычно не зависит от задачи, этот метод всё равно требует специализированных датасетов для дообучения, содержащих тысячи или десятки тысяч примеров. В отличие от этого, люди обычно могут выполнять новую языковую задачу, имея всего несколько примеров или простые инструкции — с чем современные системы обработки языка всё ещё в основном не справляются. Здесь мы показываем, что увеличение масштабов языковых моделей значительно улучшает универсальную работу в режиме few-shot, иногда даже достигая уровня конкуренции с предыдущими лучшими подходами дообучения.\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Упражнения для различных сценариев  \n",
    "1. Суммировать текст  \n",
    "2. Классифицировать текст  \n",
    "3. Придумывать новые названия продуктов\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Классификация текста  \n",
    "#### Задача  \n",
    "Классифицируйте элементы по категориям, которые задаются во время выполнения. В следующем примере мы указываем как категории, так и текст для классификации в подсказке (*playground_reference).\n",
    "\n",
    "Запрос клиента: Здравствуйте, одна из клавиш на моей клавиатуре ноутбука недавно сломалась, и мне нужен заменитель:\n",
    "\n",
    "Классифицированная категория:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Генерация новых названий продуктов\n",
    "#### Задача\n",
    "Придумайте названия продуктов на основе примеров слов. В этом задании мы указываем информацию о продукте, для которого нужно придумать название. Также приводим похожий пример, чтобы показать желаемый шаблон. Мы установили высокое значение температуры, чтобы повысить случайность и получить более креативные варианты.\n",
    "\n",
    "Описание продукта: Домашний аппарат для приготовления молочных коктейлей\n",
    "Ключевые слова: быстро, полезно, компактно.\n",
    "Названия продуктов: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Описание продукта: Пара обуви, которая подходит на любую ногу.\n",
    "Ключевые слова: адаптивный, подходит, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Ссылки  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Примеры OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Лучшие практики дообучения GPT-3 для классификации текста](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Для дополнительной помощи  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Участники\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Отказ от ответственности**:  \nЭтот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:21:26+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "ru"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}