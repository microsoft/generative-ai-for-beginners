{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Создание приложений для генерации текста\n",
    "\n",
    "В ходе этого курса вы уже познакомились с такими ключевыми понятиями, как подсказки (prompts), а также с целой областью, называемой \"инженерия подсказок\". Многие инструменты, с которыми вы можете работать, такие как ChatGPT, Office 365, Microsoft Power Platform и другие, позволяют использовать подсказки для решения различных задач.\n",
    "\n",
    "Чтобы добавить такой функционал в своё приложение, нужно понимать, что такое подсказки, завершения (completions) и выбрать подходящую библиотеку для работы. Именно этому вы научитесь в этой главе.\n",
    "\n",
    "## Введение\n",
    "\n",
    "В этой главе вы:\n",
    "\n",
    "- Познакомитесь с библиотекой openai и её основными понятиями.\n",
    "- Создадите приложение для генерации текста с помощью openai.\n",
    "- Узнаете, как использовать такие параметры, как prompt, temperature и tokens для создания приложения генерации текста.\n",
    "\n",
    "## Цели обучения\n",
    "\n",
    "В конце этого урока вы сможете:\n",
    "\n",
    "- Объяснить, что такое приложение для генерации текста.\n",
    "- Создать приложение для генерации текста с помощью openai.\n",
    "- Настроить приложение для использования большего или меньшего количества токенов, а также изменить температуру для получения разного результата.\n",
    "\n",
    "## Что такое приложение для генерации текста?\n",
    "\n",
    "Обычно, когда вы создаёте приложение, у него есть какой-то интерфейс, например:\n",
    "\n",
    "- На основе команд. Консольные приложения — это типичные приложения, где вы вводите команду, и она выполняет задачу. Например, `git` — это приложение на основе команд.\n",
    "- Графический интерфейс пользователя (UI). Некоторые приложения имеют графический интерфейс, где вы нажимаете кнопки, вводите текст, выбираете опции и так далее.\n",
    "\n",
    "### Ограничения консольных и UI приложений\n",
    "\n",
    "Сравните это с приложением на основе команд, где вы вводите команду:\n",
    "\n",
    "- **Ограниченность**. Вы не можете вводить любые команды, только те, которые поддерживает приложение.\n",
    "- **Языковая специфика**. Некоторые приложения поддерживают много языков, но по умолчанию они созданы для конкретного языка, даже если можно добавить поддержку других языков.\n",
    "\n",
    "### Преимущества приложений для генерации текста\n",
    "\n",
    "Чем же отличается приложение для генерации текста?\n",
    "\n",
    "В таком приложении у вас больше свободы, вы не ограничены набором команд или конкретным языком ввода. Вместо этого вы можете использовать естественный язык для взаимодействия с приложением. Ещё одно преимущество — вы работаете с источником данных, который обучен на огромном объёме информации, тогда как традиционное приложение может быть ограничено содержимым базы данных.\n",
    "\n",
    "### Что можно создать с помощью приложения для генерации текста?\n",
    "\n",
    "Вариантов очень много. Например:\n",
    "\n",
    "- **Чат-бот**. Чат-бот, отвечающий на вопросы по темам, связанным с вашей компанией и её продуктами, отлично подойдёт.\n",
    "- **Помощник**. LLM хорошо справляются с задачами вроде суммирования текста, извлечения инсайтов, создания резюме и многого другого.\n",
    "- **Ассистент по коду**. В зависимости от используемой языковой модели, можно создать помощника для написания кода. Например, можно использовать GitHub Copilot или ChatGPT для помощи в программировании.\n",
    "\n",
    "## Как начать?\n",
    "\n",
    "Вам нужно найти способ интеграции с LLM, обычно это делается двумя способами:\n",
    "\n",
    "- Использовать API. В этом случае вы формируете веб-запросы с вашей подсказкой и получаете сгенерированный текст.\n",
    "- Использовать библиотеку. Библиотеки упрощают работу с API и делают её удобнее.\n",
    "\n",
    "## Библиотеки/SDK\n",
    "\n",
    "Есть несколько известных библиотек для работы с LLM, например:\n",
    "\n",
    "- **openai** — эта библиотека позволяет легко подключаться к вашей модели и отправлять подсказки.\n",
    "\n",
    "Есть и более высокоуровневые библиотеки, такие как:\n",
    "\n",
    "- **Langchain**. Langchain хорошо известна и поддерживает Python.\n",
    "- **Semantic Kernel**. Semantic Kernel — библиотека от Microsoft, поддерживающая C#, Python и Java.\n",
    "\n",
    "## Первое приложение с GitHub Models Playground и Azure AI Inference SDK\n",
    "\n",
    "Давайте посмотрим, как можно создать первое приложение, какие библиотеки понадобятся, сколько потребуется настроек и так далее.\n",
    "\n",
    "### Что такое GitHub Models?\n",
    "\n",
    "Добро пожаловать в [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Здесь вы найдёте различные AI-модели, размещённые на Azure AI, к которым можно получить доступ через playground на GitHub или прямо из любимой среды разработки, бесплатно для тестирования.\n",
    "\n",
    "### Что потребуется?\n",
    "\n",
    "* Аккаунт на GitHub: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Регистрация в GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Давайте начнём!\n",
    "\n",
    "### Найдите модель и протестируйте её\n",
    "\n",
    "Перейдите на [GitHub Models в Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Главный экран GitHub Models с карточками моделей, такими как Cohere, Meta llama, Mistral и GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.ru.png)\n",
    "\n",
    "Выберите модель — например, [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Здесь вы увидите карточку модели. Можно:\n",
    "* Взаимодействовать с моделью прямо здесь, введя сообщение в текстовое поле\n",
    "* Прочитать подробности о модели во вкладках readme, Evaluation, Transparency и License\n",
    "* А также посмотреть раздел 'About' для доступа к модели справа\n",
    "\n",
    "![Карточка модели GitHub Models GPT-4o](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.ru.png)\n",
    "\n",
    "Но мы перейдём сразу к playground, нажав на ['Playground' в правом верхнем углу](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Здесь можно взаимодействовать с моделью, добавлять системные подсказки и менять параметры, а также получить весь необходимый код для запуска из любой среды. Доступно с сентября 2024: Python, Javascript, C# и REST.\n",
    "\n",
    "![Окно Playground GitHub Models с кодом и языками](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.ru.png)  \n",
    "\n",
    "\n",
    "### Используем модель в своей среде разработки\n",
    "\n",
    "Два варианта:\n",
    "1. **GitHub Codespaces** — интеграция с Codespaces, не нужен токен для начала работы\n",
    "2. **VS Code (или любой другой IDE)** — потребуется получить [Personal Access Token на GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "\n",
    "В любом случае инструкции доступны через зелёную кнопку 'Get started' в правом верхнем углу.\n",
    "\n",
    "![Экран Get Started с инструкциями по доступу к Codespaces или использованию персонального токена для настройки в своей IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.ru.png)\n",
    "\n",
    "### 1. Codespaces \n",
    "\n",
    "* В окне 'Get started' выберите \"Run codespace\"\n",
    "* Создайте новый codespace (или используйте существующий)\n",
    "* VS Code откроется в браузере с набором примеров на разных языках, которые можно попробовать\n",
    "* Запустите пример ```./githubmodels-app.py```. \n",
    "\n",
    "> Note: В codespaces не нужно задавать переменную Github Token, этот шаг можно пропустить\n",
    "\n",
    "**Теперь переходите к разделу 'Генерация текста' ниже для продолжения задания**\n",
    "\n",
    "### 2. VS Code (или любой другой IDE)\n",
    "\n",
    "Через зелёную кнопку 'Get started' вы получите всю информацию для запуска в любимой среде разработки. В этом примере используется VS Code\n",
    "\n",
    "* Выберите язык и SDK — в примере выбираем Python и Azure AI Inference SDK\n",
    "* Создайте персональный токен доступа на GitHub. Это делается в разделе Developer Settings. Не нужно давать токену никаких разрешений. Обратите внимание, что токен будет отправлен в сервис Microsoft.\n",
    "* Создайте переменную окружения для хранения персонального токена — примеры есть для bash, powershell и командной строки Windows\n",
    "* Установите зависимости: ```pip install azure-ai-inference```\n",
    "* Скопируйте базовый пример кода в файл .py\n",
    "* Перейдите в папку с вашим кодом и запустите файл: ```python filename.py```\n",
    "\n",
    "Не забывайте, что используя Azure AI Inference SDK, вы можете легко экспериментировать с разными моделями, просто меняя значение `model_name` в коде.\n",
    "\n",
    "На момент сентября 2024 в GitHub Models доступны следующие модели:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "\n",
    "\n",
    "**Теперь переходите к разделу 'Генерация текста' ниже для продолжения задания**\n",
    "\n",
    "## Генерация текста с помощью ChatCompletions\n",
    "\n",
    "Для генерации текста используется класс `ChatCompletionsClient`. \n",
    "В файле `samples/python/azure_ai_inference/basic.py`, в секции с ответом, обновите код роли пользователя, изменив параметр content на следующий:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Запустите обновлённый файл, чтобы увидеть результат\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разные типы промптов для разных задач\n",
    "\n",
    "Теперь вы увидели, как можно генерировать текст с помощью промпта. У вас даже есть программа, которую можно изменять и настраивать для создания разных видов текста.\n",
    "\n",
    "Промпты можно использовать для множества задач. Например:\n",
    "\n",
    "- **Генерация определённого типа текста**. Например, можно создать стихотворение, вопросы для викторины и так далее.\n",
    "- **Поиск информации**. С помощью промптов можно искать информацию, например: «Что означает CORS в веб-разработке?».\n",
    "- **Генерация кода**. Промпты можно использовать для написания кода, например, для создания регулярного выражения для проверки email или даже для генерации целой программы, например, веб-приложения.\n",
    "\n",
    "## Упражнение: генератор рецептов\n",
    "\n",
    "Представьте, что у вас дома есть определённые продукты, и вы хотите что-то приготовить. Для этого нужен рецепт. Один из способов найти рецепт — воспользоваться поисковой системой, либо можно использовать LLM.\n",
    "\n",
    "Можно написать такой промпт:\n",
    "\n",
    "> «Покажи мне 5 рецептов блюда с такими ингредиентами: курица, картофель и морковь. Для каждого рецепта перечисли все используемые ингредиенты»\n",
    "\n",
    "В ответ на такой промпт вы можете получить что-то вроде:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Это отличный результат — теперь я знаю, что приготовить. На этом этапе полезно было бы добавить:\n",
    "\n",
    "- Исключить ингредиенты, которые мне не нравятся или на которые у меня аллергия.\n",
    "- Составить список покупок, если каких-то продуктов нет дома.\n",
    "\n",
    "Для этих случаев добавим ещё один промпт:\n",
    "\n",
    "> «Пожалуйста, убери рецепты с чесноком, так как у меня на него аллергия, и замени его чем-нибудь другим. Также составь список покупок для этих рецептов, учитывая, что курица, картофель и морковь у меня уже есть.»\n",
    "\n",
    "Теперь у вас новый результат:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Вот ваши пять рецептов без чеснока, а также список покупок с учётом того, что у вас уже есть дома.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Упражнение — создаём генератор рецептов\n",
    "\n",
    "Теперь, когда мы рассмотрели сценарий, давайте напишем код, соответствующий показанному примеру. Для этого выполните следующие шаги:\n",
    "\n",
    "1. Используйте существующий файл как отправную точку\n",
    "1. Создайте переменную `prompt` и измените пример кода следующим образом:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если теперь запустить этот код, вы увидите примерно такой результат:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, ваш LLM работает недетерминированно, поэтому каждый раз при запуске программы результат может отличаться.\n",
    "\n",
    "Отлично, давайте посмотрим, как можно улучшить ситуацию. Чтобы сделать код лучше, нужно обеспечить его гибкость, чтобы можно было легко менять ингредиенты и количество рецептов.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Запуск кода для тестирования может выглядеть так:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Улучшаем, добавляя фильтр и список покупок\n",
    "\n",
    "Теперь у нас есть рабочее приложение, которое может генерировать рецепты, и оно гибкое, так как зависит от пользовательских вводов — как по количеству рецептов, так и по используемым ингредиентам.\n",
    "\n",
    "Чтобы сделать его еще лучше, добавим следующее:\n",
    "\n",
    "- **Фильтрация ингредиентов**. Мы хотим иметь возможность исключать ингредиенты, которые нам не нравятся или на которые у нас аллергия. Для этого можно отредактировать существующий prompt и добавить условие фильтрации в его конец, вот так:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Здесь мы добавляем `{filter}` в конец prompt и также получаем значение фильтра от пользователя.\n",
    "\n",
    "    Пример ввода при запуске программы теперь может выглядеть так:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Создание списка покупок**. Мы хотим составить список покупок, учитывая то, что уже есть дома.\n",
    "\n",
    "    Для этой функции можно попробовать решить всё одним prompt, либо разбить на два. Давайте попробуем второй вариант. Здесь предлагается добавить дополнительный prompt, но для этого нужно передать результат первого prompt как контекст для второго.\n",
    "\n",
    "    Найдите часть кода, где выводится результат первого prompt, и добавьте следующий код ниже:\n",
    "\n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Обратите внимание на следующее:\n",
    "\n",
    "    - Мы формируем новый prompt, добавляя результат первого prompt к новому prompt:\n",
    "\n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Мы делаем новый запрос, но также учитываем количество токенов, которое использовали в первом prompt, поэтому теперь указываем `max_tokens` равным 1200. **Пару слов о длине токенов**. Нужно учитывать, сколько токенов потребуется для генерации нужного текста. Токены стоят денег, поэтому желательно использовать их экономно. Например, можно ли сформулировать prompt так, чтобы использовать меньше токенов?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Запустив этот код, получаем следующий результат:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Эксперименты с температурой**. О температуре мы пока не говорили, но это важный параметр, влияющий на работу программы. Чем выше значение температуры, тем более случайным будет результат. Чем ниже — тем более предсказуемым. Подумайте, хотите ли вы разнообразия в результатах или нет.\n",
    "\n",
    "   Чтобы изменить температуру, используйте параметр `temperature`. Например, если хотите температуру 0.5, используйте:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Обратите внимание: чем ближе к 1.0, тем более разнообразным будет результат.\n",
    "\n",
    "\n",
    "## Задание\n",
    "\n",
    "В этом задании вы сами выбираете, что строить.\n",
    "\n",
    "Вот несколько идей:\n",
    "\n",
    "- Доработайте приложение-генератор рецептов, чтобы сделать его еще лучше. Поиграйте со значениями температуры и prompt'ами, чтобы посмотреть, что получится.\n",
    "- Создайте \"учебного помощника\". Это приложение должно отвечать на вопросы по какой-либо теме, например, по Python. Можно использовать prompt'ы вроде \"Что такое определенная тема в Python?\", или попросить показать код по определенной теме и т.д.\n",
    "- Исторический бот — оживите историю, попросите бота сыграть роль исторического персонажа и задавайте ему вопросы о его жизни и эпохе.\n",
    "\n",
    "## Решение\n",
    "\n",
    "### Учебный помощник\n",
    "\n",
    "- \"Вы — эксперт по языку Python\n",
    "\n",
    "    Предложите урок для новичков по Python в следующем формате:\n",
    "    \n",
    "    Формат:\n",
    "    - понятия:\n",
    "    - краткое объяснение урока:\n",
    "    - упражнение с кодом и решениями\"\n",
    "\n",
    "Это стартовый prompt, попробуйте использовать его и адаптировать под себя.\n",
    "\n",
    "### Исторический бот\n",
    "\n",
    "Вот примеры prompt'ов, которые можно использовать:\n",
    "\n",
    "- \"Вы — Авраам Линкольн, расскажите о себе в 3 предложениях, используя грамматику и слова, как это делал бы Авраам\"\n",
    "- \"Вы — Авраам Линкольн, отвечайте, используя грамматику и слова, как это делал бы Авраам:\n",
    "\n",
    "   Расскажите о своих главных достижениях, в 300 словах:\"\n",
    "\n",
    "## Проверка знаний\n",
    "\n",
    "Что делает параметр temperature?\n",
    "\n",
    "1. Он управляет случайностью результата.\n",
    "1. Он управляет размером ответа.\n",
    "1. Он управляет количеством используемых токенов.\n",
    "\n",
    "A: 1\n",
    "\n",
    "Как лучше всего хранить секреты, такие как API-ключи?\n",
    "\n",
    "1. В коде.\n",
    "1. В файле.\n",
    "1. В переменных окружения.\n",
    "\n",
    "A: 3, потому что переменные окружения не хранятся в коде и могут быть загружены из кода.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Отказ от ответственности**:  \nЭтот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T14:46:41+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "ru"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}