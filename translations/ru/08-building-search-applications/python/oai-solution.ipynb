{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы запустить следующие ноутбуки, если вы еще этого не сделали, вам нужно установить ключ openai в файле .env как `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы загрузим Индекс Встраивания в DataFrame Pandas. Индекс Встраивания хранится в JSON-файле под названием `embedding_index_3m.json`. Индекс Встраивания содержит встраивания для каждой из расшифровок YouTube до конца октября 2023 года.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее мы создадим функцию под названием `get_videos`, которая будет искать в Индексе Встраиваний по запросу. Функция вернёт 5 лучших видео, наиболее похожих на запрос. Функция работает следующим образом:\n",
    "\n",
    "1. Сначала создаётся копия Индекса Встраиваний.\n",
    "2. Затем вычисляется Встраивание для запроса с помощью OpenAI Embedding API.\n",
    "3. После этого в Индексе Встраиваний создаётся новый столбец под названием `similarity`. Столбец `similarity` содержит косинусное сходство между Встраиванием запроса и Встраиванием для каждого сегмента видео.\n",
    "4. Далее Индекс Встраиваний фильтруется по столбцу `similarity`. В Индекс Встраиваний включаются только видео с косинусным сходством, большим или равным 0.75.\n",
    "5. Наконец, Индекс Встраиваний сортируется по столбцу `similarity`, и возвращаются 5 лучших видео.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта функция очень простая, она просто выводит результаты поискового запроса.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Сначала индекс встраивания загружается в Dataframe Pandas.  \n",
    "2. Затем пользователю предлагается ввести запрос.  \n",
    "3. После этого вызывается функция `get_videos` для поиска по индексу встраивания по запросу.  \n",
    "4. Наконец, вызывается функция `display_results` для отображения результатов пользователю.  \n",
    "5. Затем пользователю снова предлагается ввести запрос. Этот процесс продолжается, пока пользователь не введет `exit`.  \n",
    "\n",
    "![](../../../../translated_images/ru/notebook-search.1e320b9c7fcbb0bc.png)\n",
    "\n",
    "Вам будет предложено ввести запрос. Введите запрос и нажмите Enter. Приложение вернет список видео, которые соответствуют запросу. Приложение также вернет ссылку на место в видео, где находится ответ на вопрос.\n",
    "\n",
    "Вот несколько запросов для проверки:\n",
    "\n",
    "- Что такое Azure Machine Learning?  \n",
    "- Как работают сверточные нейронные сети?  \n",
    "- Что такое нейронная сеть?  \n",
    "- Могу ли я использовать Jupyter Notebooks с Azure Machine Learning?  \n",
    "- Что такое ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Отказ от ответственности**:  \nЭтот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Несмотря на наши усилия обеспечить точность, имейте в виду, что автоматический перевод может содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется использовать профессиональный перевод, выполненный человеком. Мы не несем ответственности за любые недоразумения или неправильные толкования, возникшие в результате использования данного перевода.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T08:48:02+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "ru"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}