<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a8b2d4bb727c877ebf9edff8623d16b9",
  "translation_date": "2025-09-06T10:10:35+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "ru"
}
-->
[![Open Source Models](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.ru.png)](https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst)

## Введение

Мир открытых LLM-моделей захватывающий и постоянно развивается. Этот урок направлен на глубокое изучение открытых моделей. Если вы ищете информацию о сравнении проприетарных моделей с открытыми, перейдите к уроку ["Изучение и сравнение различных LLM"](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst). В этом уроке также будет рассмотрена тема тонкой настройки, но более подробное объяснение можно найти в уроке ["Тонкая настройка LLM"](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst).

## Цели обучения

- Понять, что такое открытые модели
- Осознать преимущества работы с открытыми моделями
- Изучить доступные открытые модели на Hugging Face и Azure AI Studio

## Что такое открытые модели?

Открытое программное обеспечение сыграло ключевую роль в развитии технологий в различных областях. Инициатива Open Source (OSI) определила [10 критериев для программного обеспечения](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst), чтобы оно считалось открытым. Исходный код должен быть открыт и распространяться под лицензией, одобренной OSI.

Хотя разработка LLM имеет схожие элементы с разработкой программного обеспечения, процесс не совсем идентичен. Это вызвало множество обсуждений в сообществе о том, как определить открытость в контексте LLM. Чтобы модель соответствовала традиционному определению открытого программного обеспечения, следующая информация должна быть доступна публично:

- Наборы данных, использованные для обучения модели.
- Полные веса модели как часть обучения.
- Код для оценки.
- Код для тонкой настройки.
- Полные веса модели и метрики обучения.

На данный момент существует лишь несколько моделей, соответствующих этим критериям. [Модель OLMo, созданная Институтом искусственного интеллекта Аллена (AllenAI)](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst), является одной из таких.

Для целей этого урока мы будем называть модели "открытыми моделями", так как они могут не соответствовать вышеуказанным критериям на момент написания.

## Преимущества открытых моделей

**Высокая настраиваемость** - Поскольку открытые модели публикуются с подробной информацией об обучении, исследователи и разработчики могут изменять внутреннюю структуру модели. Это позволяет создавать высокоспециализированные модели, настроенные для выполнения конкретных задач или изучения определенных областей. Примеры включают генерацию кода, математические операции и биологию.

**Стоимость** - Стоимость за токен при использовании и развертывании этих моделей ниже, чем у проприетарных моделей. При создании приложений на основе генеративного ИИ важно учитывать соотношение производительности и цены для вашего случая использования.

![Model Cost](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.ru.png)  
Источник: Artificial Analysis

**Гибкость** - Работа с открытыми моделями позволяет быть гибким в использовании различных моделей или их комбинировании. Примером является [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst), где пользователь может выбрать модель прямо в интерфейсе:

![Choose Model](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.ru.png)

## Изучение различных открытых моделей

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), разработанная Meta, является открытой моделью, оптимизированной для приложений на основе чата. Это связано с методом тонкой настройки, который включал большое количество диалогов и обратной связи от людей. Благодаря этому методу модель генерирует результаты, которые лучше соответствуют ожиданиям пользователей, обеспечивая более качественный опыт.

Примеры тонко настроенных версий Llama включают [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst), которая специализируется на японском языке, и [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), улучшенную версию базовой модели.

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) — это открытая модель, ориентированная на высокую производительность и эффективность. Она использует подход Mixture-of-Experts, который объединяет группу специализированных экспертных моделей в одну систему, где в зависимости от входных данных выбираются определенные модели. Это делает вычисления более эффективными, так как модели обрабатывают только те входные данные, в которых они специализируются.

Примеры тонко настроенных версий Mistral включают [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst), ориентированную на медицинскую область, и [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), которая выполняет математические вычисления.

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) — это LLM, созданная Институтом технологических инноваций (**TII**). Falcon-40B была обучена на 40 миллиардах параметров, что показало ее превосходство над GPT-3 при меньшем вычислительном бюджете. Это стало возможным благодаря использованию алгоритма FlashAttention и многозапросного внимания, которые позволяют сократить требования к памяти во время вывода. Благодаря сокращенному времени вывода Falcon-40B подходит для приложений на основе чата.

Примеры тонко настроенных версий Falcon включают [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst), помощник, построенный на открытых моделях, и [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), который обеспечивает более высокую производительность, чем базовая модель.

## Как выбрать

Нет единого ответа на вопрос, как выбрать открытую модель. Хорошим началом может быть использование функции фильтрации по задачам в Azure AI Studio. Это поможет вам понять, для каких типов задач модель была обучена. Hugging Face также поддерживает рейтинг LLM, который показывает лучшие модели по определенным метрикам.

Если вы хотите сравнить LLM по различным типам, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) — еще один отличный ресурс:

![Model Quality](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.ru.png)  
Источник: Artificial Analysis

Если вы работаете над конкретным случаем использования, поиск тонко настроенных версий, ориентированных на ту же область, может быть эффективным. Экспериментирование с несколькими открытыми моделями, чтобы увидеть, как они соответствуют вашим ожиданиям и ожиданиям ваших пользователей, — это также хорошая практика.

## Следующие шаги

Лучшее в открытых моделях — это то, что вы можете начать работать с ними довольно быстро. Ознакомьтесь с [каталогом моделей Azure AI Foundry](https://ai.azure.com?WT.mc_id=academic-105485-koreyst), который включает специальную коллекцию Hugging Face с обсуждаемыми здесь моделями.

## Обучение не заканчивается здесь, продолжайте путь

После завершения этого урока ознакомьтесь с нашей [коллекцией обучения генеративному ИИ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), чтобы продолжить углублять свои знания в области генеративного ИИ!

---

**Отказ от ответственности**:  
Этот документ был переведен с помощью сервиса автоматического перевода [Co-op Translator](https://github.com/Azure/co-op-translator). Хотя мы стремимся к точности, пожалуйста, учитывайте, что автоматические переводы могут содержать ошибки или неточности. Оригинальный документ на его исходном языке следует считать авторитетным источником. Для получения критически важной информации рекомендуется профессиональный перевод человеком. Мы не несем ответственности за любые недоразумения или неправильные интерпретации, возникающие в результате использования данного перевода.