{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bab 7: Membangun Aplikasi Chat\n",
    "## Github Models API Quickstart\n",
    "\n",
    "Notebook ini diadaptasi dari [Repositori Sampel Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) yang berisi notebook untuk mengakses layanan [Azure OpenAI](notebook-azure-openai.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Gambaran Umum  \n",
    "\"Model bahasa besar adalah fungsi yang memetakan teks ke teks. Diberikan sebuah input berupa string teks, model bahasa besar akan mencoba memprediksi teks apa yang akan muncul berikutnya\"(1). Notebook \"quickstart\" ini akan memperkenalkan konsep LLM tingkat tinggi, persyaratan inti paket untuk memulai dengan AML, pengenalan ringan tentang desain prompt, serta beberapa contoh singkat dari berbagai kasus penggunaan.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Daftar Isi  \n",
    "\n",
    "[Gambaran Umum](../../../../07-building-chat-applications/python)  \n",
    "[Cara menggunakan OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[1. Membuat OpenAI Service Anda](../../../../07-building-chat-applications/python)  \n",
    "[2. Instalasi](../../../../07-building-chat-applications/python)    \n",
    "[3. Kredensial](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Contoh Penggunaan](../../../../07-building-chat-applications/python)    \n",
    "[1. Merangkum Teks](../../../../07-building-chat-applications/python)  \n",
    "[2. Mengklasifikasikan Teks](../../../../07-building-chat-applications/python)  \n",
    "[3. Membuat Nama Produk Baru](../../../../07-building-chat-applications/python)  \n",
    "[4. Melakukan Fine Tune pada Klasifier](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Referensi](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Bangun prompt pertamamu  \n",
    "Latihan singkat ini akan memberikan pengenalan dasar untuk mengirimkan prompt ke model di Github Models untuk tugas sederhana \"merangkum\".\n",
    "\n",
    "**Langkah-langkah**:  \n",
    "1. Instal library `azure-ai-inference` di lingkungan python kamu, jika belum.  \n",
    "2. Muat library pembantu standar dan atur kredensial Github Models.  \n",
    "3. Pilih model untuk tugasmu  \n",
    "4. Buat prompt sederhana untuk model  \n",
    "5. Kirim permintaanmu ke API model!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Instal `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Menemukan model yang tepat  \n",
    "Model GPT-3.5-turbo atau GPT-4 dapat memahami dan menghasilkan bahasa alami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Desain Prompt  \n",
    "\n",
    "\"Keajaiban dari model bahasa besar adalah dengan dilatih untuk meminimalkan kesalahan prediksi ini pada sejumlah besar teks, model akhirnya mempelajari konsep-konsep yang berguna untuk prediksi tersebut. Misalnya, mereka mempelajari konsep seperti\"(1):\n",
    "\n",
    "* cara mengeja\n",
    "* cara kerja tata bahasa\n",
    "* cara memparafrasekan\n",
    "* cara menjawab pertanyaan\n",
    "* cara melakukan percakapan\n",
    "* cara menulis dalam banyak bahasa\n",
    "* cara membuat kode\n",
    "* dan lain-lain\n",
    "\n",
    "#### Cara mengendalikan model bahasa besar  \n",
    "\"Dari semua masukan ke model bahasa besar, yang paling berpengaruh adalah prompt teks(1).\n",
    "\n",
    "Model bahasa besar dapat diprompt untuk menghasilkan output dengan beberapa cara:\n",
    "\n",
    "Instruksi: Beritahu model apa yang kamu inginkan  \n",
    "Penyelesaian: Buat model melanjutkan awal dari apa yang kamu inginkan  \n",
    "Demonstrasi: Tunjukkan pada model apa yang kamu inginkan, dengan:  \n",
    "Beberapa contoh di dalam prompt  \n",
    "Ratusan atau ribuan contoh dalam dataset pelatihan fine-tuning\"\n",
    "\n",
    "\n",
    "\n",
    "#### Ada tiga pedoman dasar dalam membuat prompt:\n",
    "\n",
    "**Tunjukkan dan jelaskan**. Buat jelas apa yang kamu inginkan, baik melalui instruksi, contoh, atau kombinasi keduanya. Jika kamu ingin model mengurutkan daftar item secara alfabetis atau mengklasifikasikan paragraf berdasarkan sentimen, tunjukkan bahwa itulah yang kamu inginkan.\n",
    "\n",
    "**Berikan data yang berkualitas**. Jika kamu ingin membangun sebuah pengklasifikasi atau membuat model mengikuti pola tertentu, pastikan ada cukup contoh. Pastikan juga untuk memeriksa kembali contoh-contohmu — model biasanya cukup pintar untuk memahami kesalahan ejaan dasar dan tetap memberikan respons, tapi model juga bisa menganggap itu disengaja dan hal ini bisa memengaruhi responsnya.\n",
    "\n",
    "**Periksa pengaturanmu.** Pengaturan temperature dan top_p mengontrol seberapa deterministik model dalam menghasilkan respons. Jika kamu meminta respons yang hanya punya satu jawaban benar, sebaiknya atur nilai ini lebih rendah. Jika kamu ingin respons yang lebih beragam, kamu bisa menaikkannya. Kesalahan paling umum yang dilakukan orang dengan pengaturan ini adalah menganggapnya sebagai pengatur \"kepintaran\" atau \"kreativitas\" model.\n",
    "\n",
    "\n",
    "Sumber: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Merangkum Teks  \n",
    "#### Tantangan  \n",
    "Rangkum teks dengan menambahkan 'tl;dr:' di akhir sebuah paragraf. Perhatikan bagaimana model memahami cara melakukan berbagai tugas tanpa instruksi tambahan. Kamu bisa bereksperimen dengan prompt yang lebih deskriptif daripada tl;dr untuk mengubah perilaku model dan menyesuaikan ringkasan yang kamu terima(3).  \n",
    "\n",
    "Penelitian terbaru menunjukkan peningkatan signifikan pada banyak tugas dan tolok ukur NLP dengan melakukan pre-training pada korpus teks besar, lalu fine-tuning pada tugas tertentu. Meskipun arsitekturnya biasanya tidak bergantung pada tugas, metode ini tetap membutuhkan dataset fine-tuning khusus tugas yang berisi ribuan hingga puluhan ribu contoh. Sebaliknya, manusia umumnya bisa melakukan tugas bahasa baru hanya dari beberapa contoh atau instruksi sederhana—sesuatu yang masih sulit dicapai oleh sistem NLP saat ini. Di sini kami menunjukkan bahwa memperbesar skala model bahasa secara signifikan meningkatkan performa few-shot yang tidak bergantung pada tugas, bahkan kadang bisa menyaingi pendekatan fine-tuning terbaik sebelumnya.\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Latihan untuk beberapa kasus penggunaan  \n",
    "1. Merangkum Teks  \n",
    "2. Mengklasifikasikan Teks  \n",
    "3. Membuat Nama Produk Baru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klasifikasikan Teks  \n",
    "#### Tantangan  \n",
    "Klasifikasikan item ke dalam kategori yang diberikan saat inferensi. Pada contoh berikut, kita memberikan baik kategori maupun teks yang akan diklasifikasikan di prompt (*playground_reference).\n",
    "\n",
    "Pertanyaan Pelanggan: Halo, salah satu tombol di keyboard laptop saya baru saja rusak dan saya butuh pengganti:\n",
    "\n",
    "Kategori yang diklasifikasikan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Buat Nama Produk Baru\n",
    "#### Tantangan\n",
    "Buat nama produk dari kata-kata contoh. Di sini kami sertakan informasi tentang produk yang akan dibuatkan namanya dalam prompt. Kami juga memberikan contoh serupa untuk menunjukkan pola yang diinginkan. Nilai temperatur juga dibuat tinggi agar hasilnya lebih acak dan inovatif.\n",
    "\n",
    "Deskripsi produk: Mesin pembuat milkshake rumahan\n",
    "Kata kunci: cepat, sehat, ringkas.\n",
    "Nama produk: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Deskripsi produk: Sepasang sepatu yang bisa muat di semua ukuran kaki.\n",
    "Kata kunci: adaptif, pas, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Referensi  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Contoh OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Praktik terbaik untuk fine-tuning GPT-3 dalam mengklasifikasikan teks](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Untuk Bantuan Lebih Lanjut  \n",
    "[Tim Komersialisasi OpenAI](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Kontributor\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan terjemahan yang akurat, harap diketahui bahwa terjemahan otomatis dapat mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang berwenang. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang timbul akibat penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:44:14+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}