{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bab 7: Membangun Aplikasi Chat\n",
    "## OpenAI API Quickstart\n",
    "\n",
    "Notebook ini diadaptasi dari [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) yang berisi notebook untuk mengakses layanan [Azure OpenAI](notebook-azure-openai.ipynb).\n",
    "\n",
    "API OpenAI Python juga dapat digunakan dengan Model Azure OpenAI, dengan beberapa penyesuaian. Pelajari lebih lanjut tentang perbedaannya di sini: [Cara beralih antara endpoint OpenAI dan Azure OpenAI dengan Python](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Gambaran Umum  \n",
    "\"Model bahasa besar adalah fungsi yang memetakan teks ke teks. Diberikan sebuah input berupa string teks, model bahasa besar akan mencoba memprediksi teks apa yang akan muncul berikutnya\"(1). Notebook \"quickstart\" ini akan memperkenalkan konsep LLM tingkat tinggi, persyaratan inti paket untuk memulai dengan AML, pengenalan ringan tentang desain prompt, serta beberapa contoh singkat dari berbagai kasus penggunaan.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Daftar Isi  \n",
    "\n",
    "[Gambaran Umum](../../../../07-building-chat-applications/python)  \n",
    "[Cara Menggunakan Layanan OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[1. Membuat Layanan OpenAI Anda](../../../../07-building-chat-applications/python)  \n",
    "[2. Instalasi](../../../../07-building-chat-applications/python)    \n",
    "[3. Kredensial](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Studi Kasus](../../../../07-building-chat-applications/python)    \n",
    "[1. Merangkum Teks](../../../../07-building-chat-applications/python)  \n",
    "[2. Mengklasifikasikan Teks](../../../../07-building-chat-applications/python)  \n",
    "[3. Membuat Nama Produk Baru](../../../../07-building-chat-applications/python)  \n",
    "[4. Melatih Ulang Klasifikasi](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Referensi](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Bangun prompt pertamamu  \n",
    "Latihan singkat ini akan memberikan pengenalan dasar tentang cara mengirimkan prompt ke model OpenAI untuk tugas sederhana \"merangkum\".\n",
    "\n",
    "**Langkah-langkah**:  \n",
    "1. Instal library OpenAI di lingkungan python-mu  \n",
    "2. Muat library pembantu standar dan atur kredensial keamanan OpenAI yang biasa kamu gunakan untuk OpenAI Service yang sudah kamu buat  \n",
    "3. Pilih model untuk tugasmu  \n",
    "4. Buat prompt sederhana untuk model  \n",
    "5. Kirim permintaanmu ke API model!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Menemukan model yang tepat  \n",
    "Model GPT-3.5-turbo atau GPT-4 dapat memahami dan menghasilkan bahasa alami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Desain Prompt  \n",
    "\n",
    "\"Keajaiban dari model bahasa besar adalah dengan dilatih untuk meminimalkan kesalahan prediksi pada sejumlah besar teks, model akhirnya mempelajari konsep-konsep yang berguna untuk prediksi tersebut. Misalnya, mereka mempelajari konsep seperti\"(1):\n",
    "\n",
    "* cara mengeja\n",
    "* cara kerja tata bahasa\n",
    "* cara memparafrasekan\n",
    "* cara menjawab pertanyaan\n",
    "* cara melakukan percakapan\n",
    "* cara menulis dalam banyak bahasa\n",
    "* cara membuat kode\n",
    "* dan lain-lain\n",
    "\n",
    "#### Cara mengendalikan model bahasa besar  \n",
    "\"Dari semua masukan ke model bahasa besar, yang paling berpengaruh adalah prompt teks(1).\n",
    "\n",
    "Model bahasa besar dapat diprompt untuk menghasilkan output dengan beberapa cara:\n",
    "\n",
    "Instruksi: Beritahu model apa yang kamu inginkan  \n",
    "Penyelesaian: Buat model melanjutkan awal dari apa yang kamu inginkan  \n",
    "Demonstrasi: Tunjukkan pada model apa yang kamu inginkan, dengan:  \n",
    "Beberapa contoh di dalam prompt  \n",
    "Ratusan atau ribuan contoh dalam dataset pelatihan fine-tuning\"\n",
    "\n",
    "\n",
    "\n",
    "#### Ada tiga pedoman dasar dalam membuat prompt:\n",
    "\n",
    "**Tunjukkan dan jelaskan**. Buat jelas apa yang kamu inginkan, baik melalui instruksi, contoh, atau kombinasi keduanya. Jika kamu ingin model mengurutkan daftar item secara alfabetis atau mengklasifikasikan paragraf berdasarkan sentimen, tunjukkan bahwa itulah yang kamu inginkan.\n",
    "\n",
    "**Berikan data yang berkualitas**. Jika kamu ingin membangun sebuah pengklasifikasi atau membuat model mengikuti pola tertentu, pastikan ada cukup contoh. Pastikan juga untuk memeriksa kembali contoh-contohmu — model biasanya cukup pintar untuk memahami kesalahan ejaan dasar dan tetap memberikan respons, tapi model juga bisa menganggap itu disengaja dan hal ini bisa memengaruhi responsnya.\n",
    "\n",
    "**Periksa pengaturanmu.** Pengaturan temperature dan top_p mengontrol seberapa deterministik model dalam menghasilkan respons. Jika kamu meminta respons yang hanya punya satu jawaban benar, sebaiknya atur nilai ini lebih rendah. Jika kamu ingin respons yang lebih beragam, kamu bisa menaikkannya. Kesalahan paling umum yang dilakukan orang dengan pengaturan ini adalah menganggapnya sebagai pengatur \"kepintaran\" atau \"kreativitas\".\n",
    "\n",
    "\n",
    "Sumber: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Merangkum Teks  \n",
    "#### Tantangan  \n",
    "Rangkum teks dengan menambahkan 'tl;dr:' di akhir sebuah paragraf. Perhatikan bagaimana model dapat melakukan berbagai tugas tanpa instruksi tambahan. Kamu bisa bereksperimen dengan prompt yang lebih deskriptif daripada tl;dr untuk mengubah perilaku model dan menyesuaikan ringkasan yang kamu terima(3).  \n",
    "\n",
    "Penelitian terbaru menunjukkan peningkatan signifikan pada banyak tugas dan tolok ukur NLP dengan melakukan pre-training pada korpus teks besar, lalu fine-tuning pada tugas tertentu. Meskipun arsitekturnya biasanya tidak bergantung pada tugas, metode ini tetap membutuhkan dataset fine-tuning khusus tugas yang terdiri dari ribuan hingga puluhan ribu contoh. Sebaliknya, manusia umumnya bisa melakukan tugas bahasa baru hanya dari beberapa contoh atau instruksi sederhana—sesuatu yang masih sulit dicapai oleh sistem NLP saat ini. Di sini kami menunjukkan bahwa memperbesar skala model bahasa secara signifikan meningkatkan performa few-shot yang tidak bergantung pada tugas, bahkan kadang bisa menyaingi pendekatan fine-tuning terbaik sebelumnya.\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Latihan untuk beberapa kasus penggunaan  \n",
    "1. Merangkum Teks  \n",
    "2. Mengklasifikasikan Teks  \n",
    "3. Membuat Nama Produk Baru\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klasifikasikan Teks  \n",
    "#### Tantangan  \n",
    "Klasifikasikan item ke dalam kategori yang diberikan saat inferensi. Pada contoh berikut, kita memberikan baik kategori maupun teks yang akan diklasifikasikan di prompt (*playground_reference).\n",
    "\n",
    "Pertanyaan Pelanggan: Halo, salah satu tombol di keyboard laptop saya baru saja rusak dan saya butuh pengganti:\n",
    "\n",
    "Kategori yang diklasifikasikan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Buat Nama Produk Baru\n",
    "#### Tantangan\n",
    "Buat nama produk dari kata-kata contoh. Di sini kami sertakan informasi tentang produk yang akan dibuatkan namanya dalam prompt. Kami juga memberikan contoh serupa untuk menunjukkan pola yang diinginkan. Nilai temperatur juga kami atur tinggi agar hasilnya lebih acak dan inovatif.\n",
    "\n",
    "Deskripsi produk: Mesin pembuat milkshake rumahan\n",
    "Kata kunci: cepat, sehat, ringkas.\n",
    "Nama produk: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Deskripsi produk: Sepasang sepatu yang bisa muat di semua ukuran kaki.\n",
    "Kata kunci: adaptif, pas, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Referensi  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Contoh OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Praktik terbaik untuk fine-tuning GPT-3 dalam mengklasifikasikan teks](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Untuk Bantuan Lebih Lanjut  \n",
    "[Tim Komersialisasi OpenAI](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Kontributor\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan terjemahan yang akurat, harap diketahui bahwa terjemahan otomatis dapat mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang berwenang. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa penerjemah profesional. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang timbul akibat penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:23:34+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}