{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendahuluan\n",
    "\n",
    "Pelajaran ini akan membahas:\n",
    "- Apa itu pemanggilan fungsi dan kasus penggunaannya\n",
    "- Cara membuat pemanggilan fungsi menggunakan Azure OpenAI\n",
    "- Cara mengintegrasikan pemanggilan fungsi ke dalam aplikasi\n",
    "\n",
    "## Tujuan Pembelajaran\n",
    "\n",
    "Setelah menyelesaikan pelajaran ini, Anda akan mengetahui cara dan memahami:\n",
    "\n",
    "- Tujuan penggunaan pemanggilan fungsi\n",
    "- Menyiapkan Function Call menggunakan Azure Open AI Service\n",
    "- Merancang pemanggilan fungsi yang efektif untuk kasus penggunaan aplikasi Anda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memahami Pemanggilan Fungsi\n",
    "\n",
    "Untuk pelajaran ini, kita ingin membangun sebuah fitur untuk startup pendidikan kita yang memungkinkan pengguna menggunakan chatbot untuk mencari kursus teknis. Kami akan merekomendasikan kursus yang sesuai dengan tingkat keahlian, peran saat ini, dan teknologi yang diminati pengguna.\n",
    "\n",
    "Untuk menyelesaikan ini, kita akan menggunakan kombinasi dari:\n",
    " - `Azure Open AI` untuk menciptakan pengalaman chat bagi pengguna\n",
    " - `Microsoft Learn Catalog API` untuk membantu pengguna menemukan kursus berdasarkan permintaan mereka\n",
    " - `Function Calling` untuk mengambil pertanyaan pengguna dan mengirimkannya ke sebuah fungsi agar dapat melakukan permintaan API.\n",
    "\n",
    "Untuk memulai, mari kita lihat mengapa kita ingin menggunakan pemanggilan fungsi sejak awal:\n",
    "\n",
    "print(\"Pesan pada permintaan berikutnya:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # dapatkan respons baru dari GPT di mana ia bisa melihat respons fungsi\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengapa Menggunakan Function Calling\n",
    "\n",
    "Jika kamu sudah menyelesaikan pelajaran lain di kursus ini, kamu mungkin sudah paham betapa hebatnya menggunakan Large Language Models (LLMs). Semoga kamu juga bisa melihat beberapa keterbatasannya.\n",
    "\n",
    "Function Calling adalah fitur dari Azure Open AI Service yang dirancang untuk mengatasi keterbatasan berikut:\n",
    "1) Format respons yang konsisten\n",
    "2) Kemampuan menggunakan data dari sumber lain dalam aplikasi pada konteks chat\n",
    "\n",
    "Sebelum ada function calling, respons dari LLM biasanya tidak terstruktur dan tidak konsisten. Pengembang harus menulis kode validasi yang rumit agar bisa menangani setiap variasi respons.\n",
    "\n",
    "Pengguna tidak bisa mendapatkan jawaban seperti \"Bagaimana cuaca saat ini di Stockholm?\". Ini karena model hanya terbatas pada data yang digunakan saat pelatihan.\n",
    "\n",
    "Mari kita lihat contoh di bawah ini yang menggambarkan masalah ini:\n",
    "\n",
    "Misalkan kita ingin membuat database data siswa agar bisa merekomendasikan kursus yang tepat untuk mereka. Di bawah ini ada dua deskripsi siswa yang sangat mirip dalam data yang mereka miliki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin mengirimkan ini ke LLM untuk memproses data. Nantinya, ini bisa digunakan dalam aplikasi kami untuk dikirim ke API atau disimpan di database.\n",
    "\n",
    "Mari kita buat dua prompt identik yang akan kita gunakan untuk menginstruksikan LLM tentang informasi apa saja yang ingin kami ambil:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin mengirimkan ini ke LLM untuk menganalisis bagian-bagian yang penting bagi produk kami. Jadi kami dapat membuat dua prompt identik untuk menginstruksikan LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah membuat dua prompt ini, kita akan mengirimkannya ke LLM dengan menggunakan `openai.ChatCompletion`. Kita menyimpan prompt tersebut dalam variabel `messages` dan menetapkan peran sebagai `user`. Ini dilakukan untuk meniru pesan dari pengguna yang ditulis ke chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meskipun prompt-nya sama dan deskripsinya mirip, kita bisa mendapatkan format yang berbeda untuk properti `Grades`.\n",
    "\n",
    "Jika kamu menjalankan sel di atas beberapa kali, formatnya bisa saja `3.7` atau `3.7 GPA`.\n",
    "\n",
    "Ini terjadi karena LLM menerima data tidak terstruktur dalam bentuk prompt tertulis dan juga mengembalikan data yang tidak terstruktur. Kita perlu memiliki format yang terstruktur agar kita tahu apa yang diharapkan saat menyimpan atau menggunakan data ini.\n",
    "\n",
    "Dengan menggunakan functional calling, kita bisa memastikan bahwa kita menerima data yang terstruktur. Saat menggunakan function calling, LLM sebenarnya tidak memanggil atau menjalankan fungsi apa pun. Sebagai gantinya, kita membuat sebuah struktur yang harus diikuti LLM untuk responsnya. Kemudian kita menggunakan respons yang terstruktur tersebut untuk mengetahui fungsi apa yang harus dijalankan di aplikasi kita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram Alur Pemanggilan Fungsi](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.id.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kasus Penggunaan untuk pemanggilan fungsi\n",
    "\n",
    "**Memanggil Alat Eksternal**\n",
    "Chatbot sangat baik dalam memberikan jawaban atas pertanyaan dari pengguna. Dengan menggunakan pemanggilan fungsi, chatbot bisa memanfaatkan pesan dari pengguna untuk menyelesaikan tugas tertentu. Misalnya, seorang siswa bisa meminta chatbot untuk \"Kirim email ke dosen saya bahwa saya butuh bantuan lebih lanjut dengan mata kuliah ini\". Ini bisa memanggil fungsi `send_email(to: string, body: string)`\n",
    "\n",
    "**Membuat Query API atau Database**\n",
    "Pengguna bisa mencari informasi menggunakan bahasa alami yang kemudian diubah menjadi query atau permintaan API yang terformat. Contohnya, seorang guru meminta \"Siapa saja siswa yang sudah menyelesaikan tugas terakhir\" yang bisa memanggil fungsi bernama `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Membuat Data Terstruktur**\n",
    "Pengguna bisa mengambil sebuah blok teks atau CSV dan menggunakan LLM untuk mengekstrak informasi penting dari sana. Misalnya, seorang siswa bisa mengubah artikel Wikipedia tentang perjanjian damai untuk membuat kartu kilat AI. Ini bisa dilakukan dengan menggunakan fungsi bernama `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membuat Panggilan Fungsi Pertama Anda\n",
    "\n",
    "Proses membuat panggilan fungsi terdiri dari 3 langkah utama:\n",
    "1. Memanggil Chat Completions API dengan daftar fungsi Anda dan pesan dari pengguna\n",
    "2. Membaca respons model untuk melakukan sebuah aksi, misalnya menjalankan fungsi atau memanggil API\n",
    "3. Melakukan panggilan lagi ke Chat Completions API dengan respons dari fungsi Anda untuk menggunakan informasi tersebut dalam membuat respons kepada pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alur Pemanggilan Fungsi](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.id.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemen-elemen dari pemanggilan fungsi\n",
    "\n",
    "#### Input Pengguna\n",
    "\n",
    "Langkah pertama adalah membuat pesan dari pengguna. Ini bisa diisi secara dinamis dengan mengambil nilai dari input teks atau Anda bisa menetapkan nilainya di sini. Jika ini adalah pertama kalinya Anda bekerja dengan Chat Completions API, kita perlu mendefinisikan `role` dan `content` dari pesan tersebut.\n",
    "\n",
    "`role` bisa berupa `system` (membuat aturan), `assistant` (model), atau `user` (pengguna akhir). Untuk pemanggilan fungsi, kita akan menetapkannya sebagai `user` dan memberikan contoh pertanyaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat fungsi.\n",
    "\n",
    "Selanjutnya kita akan mendefinisikan sebuah fungsi beserta parameter-parameternya. Di sini kita hanya akan menggunakan satu fungsi bernama `search_courses`, namun kamu bisa membuat beberapa fungsi.\n",
    "\n",
    "**Penting**: Fungsi-fungsi akan dimasukkan ke dalam pesan sistem ke LLM dan akan dihitung dalam jumlah token yang tersedia untuk kamu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definisi**\n",
    "\n",
    "`name` - Nama fungsi yang ingin kita panggil.\n",
    "\n",
    "`description` - Ini adalah deskripsi tentang cara kerja fungsi tersebut. Di sini penting untuk menjelaskan secara spesifik dan jelas.\n",
    "\n",
    "`parameters` - Daftar nilai dan format yang ingin Anda minta model hasilkan dalam responsnya.\n",
    "\n",
    "`type` - Tipe data dari properti yang akan disimpan.\n",
    "\n",
    "`properties` - Daftar nilai spesifik yang akan digunakan model untuk responsnya.\n",
    "\n",
    "`name` - Nama properti yang akan digunakan model dalam respons yang sudah diformat.\n",
    "\n",
    "`type` - Tipe data dari properti ini.\n",
    "\n",
    "`description` - Deskripsi dari properti tertentu.\n",
    "\n",
    "**Opsional**\n",
    "\n",
    "`required` - Properti yang wajib diisi agar pemanggilan fungsi dapat diselesaikan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memanggil fungsi\n",
    "Setelah mendefinisikan sebuah fungsi, sekarang kita perlu memasukkannya dalam pemanggilan ke Chat Completion API. Kita melakukan ini dengan menambahkan `functions` ke permintaan. Dalam hal ini `functions=functions`.\n",
    "\n",
    "Ada juga opsi untuk mengatur `function_call` ke `auto`. Ini berarti kita membiarkan LLM yang memutuskan fungsi mana yang sebaiknya dipanggil berdasarkan pesan pengguna, bukan kita yang menentukannya sendiri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang mari kita lihat responsnya dan bagaimana formatnya:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Kamu bisa melihat bahwa nama fungsi dipanggil dan dari pesan pengguna, LLM dapat menemukan data yang sesuai untuk mengisi argumen fungsi tersebut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mengintegrasikan Pemanggilan Fungsi ke dalam Aplikasi.\n",
    "\n",
    "Setelah kita menguji respons yang diformat dari LLM, sekarang kita bisa mengintegrasikannya ke dalam aplikasi.\n",
    "\n",
    "### Mengelola alur\n",
    "\n",
    "Untuk mengintegrasikan ini ke dalam aplikasi kita, mari lakukan langkah-langkah berikut:\n",
    "\n",
    "Pertama, lakukan pemanggilan ke layanan Open AI dan simpan pesan tersebut dalam variabel bernama `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita akan mendefinisikan fungsi yang akan memanggil Microsoft Learn API untuk mendapatkan daftar kursus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai praktik terbaik, kita akan melihat apakah model ingin memanggil sebuah fungsi. Setelah itu, kita akan membuat salah satu fungsi yang tersedia dan mencocokkannya dengan fungsi yang sedang dipanggil. \n",
    "Kemudian, kita akan mengambil argumen dari fungsi tersebut dan memetakannya ke argumen dari LLM.\n",
    "\n",
    "Terakhir, kita akan menambahkan pesan pemanggilan fungsi dan nilai-nilai yang dikembalikan oleh pesan `search_courses`. Ini memberikan semua informasi yang dibutuhkan LLM\n",
    "untuk merespons pengguna menggunakan bahasa alami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tantangan Kode\n",
    "\n",
    "Kerja bagus! Untuk melanjutkan pembelajaran Anda tentang Azure Open AI Function Calling, Anda bisa membangun: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Tambahkan lebih banyak parameter pada fungsi yang bisa membantu pembelajar menemukan lebih banyak kursus. Anda bisa menemukan parameter API yang tersedia di sini:\n",
    " - Buat pemanggilan fungsi lain yang mengambil informasi tambahan dari pembelajar seperti bahasa asli mereka\n",
    " - Buat penanganan error ketika pemanggilan fungsi dan/atau pemanggilan API tidak mengembalikan kursus yang sesuai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan terjemahan yang akurat, harap diketahui bahwa terjemahan otomatis dapat mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang berwenang. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa penerjemah profesional. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang timbul akibat penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:23:50+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}