{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction \n",
    "\n",
    "Pelajaran ini akan membahas: \n",
    "- Apa itu pemanggilan fungsi dan kasus penggunaannya \n",
    "- Cara membuat pemanggilan fungsi menggunakan OpenAI \n",
    "- Cara mengintegrasikan pemanggilan fungsi ke dalam aplikasi \n",
    "\n",
    "## Learning Goals \n",
    "\n",
    "Setelah menyelesaikan pelajaran ini Anda akan mengetahui cara dan memahami: \n",
    "\n",
    "- Tujuan menggunakan pemanggilan fungsi \n",
    "- Menyiapkan Pemanggilan Fungsi menggunakan Layanan OpenAI \n",
    "- Merancang pemanggilan fungsi yang efektif untuk kasus penggunaan aplikasi Anda \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memahami Panggilan Fungsi\n",
    "\n",
    "Untuk pelajaran ini, kami ingin membangun fitur untuk startup pendidikan kami yang memungkinkan pengguna menggunakan chatbot untuk menemukan kursus teknis. Kami akan merekomendasikan kursus yang sesuai dengan tingkat keterampilan mereka, peran saat ini, dan teknologi yang diminati.\n",
    "\n",
    "Untuk menyelesaikan ini, kami akan menggunakan kombinasi:\n",
    " - `OpenAI` untuk membuat pengalaman chat bagi pengguna\n",
    " - `Microsoft Learn Catalog API` untuk membantu pengguna menemukan kursus berdasarkan permintaan pengguna\n",
    " - `Function Calling` untuk mengambil kueri pengguna dan mengirimkannya ke fungsi untuk membuat permintaan API.\n",
    "\n",
    "Untuk memulai, mari kita lihat mengapa kita ingin menggunakan function calling sejak awal:\n",
    "\n",
    "print(\"Pesan dalam permintaan berikutnya:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # dapatkan respons baru dari GPT di mana ia dapat melihat respons fungsi\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengapa Pemanggilan Fungsi\n",
    "\n",
    "Jika Anda telah menyelesaikan pelajaran lain dalam kursus ini, Anda mungkin sudah memahami kekuatan menggunakan Large Language Models (LLM). Semoga Anda juga dapat melihat beberapa keterbatasan mereka.\n",
    "\n",
    "Pemanggilan Fungsi adalah fitur dari Layanan OpenAI yang dirancang untuk mengatasi tantangan berikut:\n",
    "\n",
    "Format Respons yang Tidak Konsisten:\n",
    "- Sebelum pemanggilan fungsi, respons dari model bahasa besar tidak terstruktur dan tidak konsisten. Pengembang harus menulis kode validasi yang kompleks untuk menangani setiap variasi dalam output.\n",
    "\n",
    "Integrasi Terbatas dengan Data Eksternal:\n",
    "- Sebelum fitur ini, sulit untuk menggabungkan data dari bagian lain aplikasi ke dalam konteks obrolan.\n",
    "\n",
    "Dengan menstandarisasi format respons dan memungkinkan integrasi mulus dengan data eksternal, pemanggilan fungsi menyederhanakan pengembangan dan mengurangi kebutuhan logika validasi tambahan.\n",
    "\n",
    "Pengguna tidak bisa mendapatkan jawaban seperti \"Bagaimana cuaca saat ini di Stockholm?\". Ini karena model terbatas pada waktu data dilatih.\n",
    "\n",
    "Mari kita lihat contoh di bawah yang menggambarkan masalah ini:\n",
    "\n",
    "Misalkan kita ingin membuat basis data data siswa agar kita dapat menyarankan kursus yang tepat untuk mereka. Di bawah ini kita memiliki dua deskripsi siswa yang sangat mirip dalam data yang mereka miliki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin mengirim ini ke LLM untuk mengurai data. Ini nantinya dapat digunakan dalam aplikasi kami untuk mengirim ini ke API atau menyimpannya dalam basis data.\n",
    "\n",
    "Mari buat dua prompt identik yang kami instruksikan kepada LLM tentang informasi apa yang kami minati:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin mengirim ini ke LLM untuk menguraikan bagian-bagian yang penting bagi produk kami. Jadi kami dapat membuat dua prompt identik untuk menginstruksikan LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah membuat dua prompt ini, kita akan mengirimkannya ke LLM dengan menggunakan `openai.ChatCompletion`. Kita menyimpan prompt tersebut dalam variabel `messages` dan menetapkan peran sebagai `user`. Ini untuk meniru pesan dari pengguna yang ditulis ke chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita dapat mengirim kedua permintaan ke LLM dan memeriksa respons yang kita terima.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meskipun prompt-nya sama dan deskripsinya mirip, kita bisa mendapatkan format properti `Grades` yang berbeda.\n",
    "\n",
    "Jika Anda menjalankan sel di atas beberapa kali, formatnya bisa berupa `3.7` atau `3.7 GPA`.\n",
    "\n",
    "Ini karena LLM mengambil data tidak terstruktur dalam bentuk prompt tertulis dan juga mengembalikan data tidak terstruktur. Kita perlu memiliki format terstruktur agar kita tahu apa yang diharapkan saat menyimpan atau menggunakan data ini.\n",
    "\n",
    "Dengan menggunakan pemanggilan fungsi, kita dapat memastikan bahwa kita menerima data terstruktur kembali. Saat menggunakan pemanggilan fungsi, LLM sebenarnya tidak memanggil atau menjalankan fungsi apa pun. Sebaliknya, kita membuat struktur untuk diikuti LLM dalam responsnya. Kemudian kita menggunakan respons terstruktur tersebut untuk mengetahui fungsi apa yang harus dijalankan dalam aplikasi kita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram Alur Pemanggilan Fungsi](../../../../translated_images/id/Function-Flow.083875364af4f4bb.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kita kemudian dapat mengambil apa yang dikembalikan dari fungsi tersebut dan mengirimkannya kembali ke LLM. LLM kemudian akan merespons menggunakan bahasa alami untuk menjawab pertanyaan pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kasus Penggunaan untuk menggunakan pemanggilan fungsi\n",
    "\n",
    "**Memanggil Alat Eksternal**  \n",
    "Chatbot sangat baik dalam memberikan jawaban atas pertanyaan dari pengguna. Dengan menggunakan pemanggilan fungsi, chatbot dapat menggunakan pesan dari pengguna untuk menyelesaikan tugas tertentu. Misalnya, seorang siswa dapat meminta chatbot untuk \"Kirim email ke instruktur saya mengatakan saya membutuhkan bantuan lebih dengan mata pelajaran ini\". Ini dapat membuat panggilan fungsi ke `send_email(to: string, body: string)`\n",
    "\n",
    "**Membuat Query API atau Database**  \n",
    "Pengguna dapat menemukan informasi menggunakan bahasa alami yang diubah menjadi query atau permintaan API yang terformat. Contohnya bisa seorang guru yang meminta \"Siapa saja siswa yang menyelesaikan tugas terakhir\" yang dapat memanggil fungsi bernama `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Membuat Data Terstruktur**  \n",
    "Pengguna dapat mengambil blok teks atau CSV dan menggunakan LLM untuk mengekstrak informasi penting darinya. Misalnya, seorang siswa dapat mengubah artikel Wikipedia tentang perjanjian damai untuk membuat kartu flash AI. Ini dapat dilakukan dengan menggunakan fungsi yang disebut `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membuat Panggilan Fungsi Pertama Anda\n",
    "\n",
    "Proses membuat panggilan fungsi mencakup 3 langkah utama:\n",
    "1. Memanggil API Chat Completions dengan daftar fungsi Anda dan pesan pengguna\n",
    "2. Membaca respons model untuk melakukan tindakan yaitu menjalankan fungsi atau Panggilan API\n",
    "3. Membuat panggilan lain ke API Chat Completions dengan respons dari fungsi Anda untuk menggunakan informasi tersebut dalam membuat respons kepada pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alur Panggilan Fungsi](../../../../translated_images/id/LLM-Flow.3285ed8caf4796d7.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemen dari sebuah panggilan fungsi\n",
    "\n",
    "#### Input Pengguna\n",
    "\n",
    "Langkah pertama adalah membuat pesan pengguna. Ini dapat ditetapkan secara dinamis dengan mengambil nilai dari input teks atau Anda dapat menetapkan nilai di sini. Jika ini adalah pertama kalinya Anda bekerja dengan Chat Completions API, kita perlu mendefinisikan `role` dan `content` dari pesan tersebut.\n",
    "\n",
    "`role` dapat berupa `system` (membuat aturan), `assistant` (model) atau `user` (pengguna akhir). Untuk pemanggilan fungsi, kita akan menetapkannya sebagai `user` dan sebuah contoh pertanyaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat fungsi.\n",
    "\n",
    "Selanjutnya kita akan mendefinisikan sebuah fungsi dan parameter dari fungsi tersebut. Kita akan menggunakan hanya satu fungsi di sini yang disebut `search_courses` tetapi Anda dapat membuat beberapa fungsi.\n",
    "\n",
    "**Penting** : Fungsi-fungsi disertakan dalam pesan sistem ke LLM dan akan termasuk dalam jumlah token yang tersedia yang Anda miliki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definisi** \n",
    "\n",
    "Struktur definisi fungsi memiliki beberapa tingkat, masing-masing dengan properti sendiri. Berikut adalah rincian struktur bersarangnya:\n",
    "\n",
    "**Properti Fungsi Tingkat Atas:**\n",
    "\n",
    "`name` - Nama fungsi yang ingin kita panggil. \n",
    "\n",
    "`description` - Ini adalah deskripsi tentang bagaimana fungsi bekerja. Di sini penting untuk spesifik dan jelas \n",
    "\n",
    "`parameters` - Daftar nilai dan format yang ingin Anda model hasilkan dalam responsnya \n",
    "\n",
    "**Properti Objek Parameter:**\n",
    "\n",
    "`type` - Tipe data dari objek parameter (biasanya \"object\")\n",
    "\n",
    "`properties` - Daftar nilai spesifik yang akan digunakan model untuk responsnya \n",
    "\n",
    "**Properti Parameter Individu:**\n",
    "\n",
    "`name` - Didefinisikan secara implisit oleh kunci properti (misalnya, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Tipe data dari parameter spesifik ini (misalnya, \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Deskripsi dari parameter spesifik tersebut \n",
    "\n",
    "**Properti Opsional:**\n",
    "\n",
    "`required` - Array yang mencantumkan parameter mana yang diperlukan agar pemanggilan fungsi dapat diselesaikan \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat panggilan fungsi  \n",
    "Setelah mendefinisikan sebuah fungsi, sekarang kita perlu memasukkannya dalam panggilan ke API Chat Completion. Kita melakukan ini dengan menambahkan `functions` ke permintaan. Dalam kasus ini `functions=functions`.  \n",
    "\n",
    "Ada juga opsi untuk mengatur `function_call` ke `auto`. Ini berarti kita akan membiarkan LLM memutuskan fungsi mana yang harus dipanggil berdasarkan pesan pengguna daripada menetapkannya sendiri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang mari kita lihat responsnya dan bagaimana formatnya:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Anda dapat melihat bahwa nama fungsi dipanggil dan dari pesan pengguna, LLM dapat menemukan data yang sesuai dengan argumen fungsi tersebut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Mengintegrasikan Panggilan Fungsi ke dalam Aplikasi. \n",
    "\n",
    "\n",
    "Setelah kita menguji respons yang diformat dari LLM, sekarang kita dapat mengintegrasikannya ke dalam sebuah aplikasi. \n",
    "\n",
    "### Mengelola alur \n",
    "\n",
    "Untuk mengintegrasikan ini ke dalam aplikasi kita, mari ambil langkah-langkah berikut: \n",
    "\n",
    "Pertama, mari buat panggilan ke layanan OpenAI dan simpan pesan dalam variabel yang disebut `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita akan mendefinisikan fungsi yang akan memanggil API Microsoft Learn untuk mendapatkan daftar kursus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai praktik terbaik, kita kemudian akan melihat apakah model ingin memanggil sebuah fungsi. Setelah itu, kita akan membuat salah satu fungsi yang tersedia dan mencocokkannya dengan fungsi yang sedang dipanggil.  \n",
    "Kita kemudian akan mengambil argumen dari fungsi tersebut dan memetakan mereka ke argumen dari LLM.\n",
    "\n",
    "Terakhir, kita akan menambahkan pesan panggilan fungsi dan nilai-nilai yang dikembalikan oleh pesan `search_courses`. Ini memberikan LLM semua informasi yang dibutuhkan untuk  \n",
    "menanggapi pengguna menggunakan bahasa alami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kami akan mengirim pesan yang diperbarui ke LLM sehingga kami dapat menerima respons dalam bahasa alami, bukan respons yang diformat JSON API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tantangan Kode\n",
    "\n",
    "Kerja bagus! Untuk melanjutkan pembelajaran Anda tentang OpenAI Function Calling, Anda dapat membangun: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Lebih banyak parameter dari fungsi yang mungkin membantu pembelajar menemukan lebih banyak kursus. Anda dapat menemukan parameter API yang tersedia di sini:  \n",
    " - Buat panggilan fungsi lain yang mengambil lebih banyak informasi dari pembelajar seperti bahasa asli mereka  \n",
    " - Buat penanganan kesalahan ketika panggilan fungsi dan/atau panggilan API tidak mengembalikan kursus yang sesuai  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berusaha untuk akurasi, harap diingat bahwa terjemahan otomatis mungkin mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sahih. Untuk informasi penting, disarankan menggunakan terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau salah tafsir yang timbul dari penggunaan terjemahan ini.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T11:00:41+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}