{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pendahuluan\n",
    "\n",
    "Pelajaran ini akan membahas:\n",
    "- Apa itu pemanggilan fungsi dan contoh penggunaannya\n",
    "- Cara membuat pemanggilan fungsi menggunakan OpenAI\n",
    "- Cara mengintegrasikan pemanggilan fungsi ke dalam aplikasi\n",
    "\n",
    "## Tujuan Pembelajaran\n",
    "\n",
    "Setelah menyelesaikan pelajaran ini, Anda akan tahu dan memahami:\n",
    "\n",
    "- Tujuan menggunakan pemanggilan fungsi\n",
    "- Menyiapkan Pemanggilan Fungsi menggunakan Layanan OpenAI\n",
    "- Merancang pemanggilan fungsi yang efektif untuk kebutuhan aplikasi Anda\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memahami Pemanggilan Fungsi\n",
    "\n",
    "Untuk pelajaran ini, kita ingin membangun sebuah fitur untuk startup pendidikan kita yang memungkinkan pengguna menggunakan chatbot untuk mencari kursus teknis. Kami akan merekomendasikan kursus yang sesuai dengan tingkat keahlian, peran saat ini, dan teknologi yang diminati pengguna.\n",
    "\n",
    "Untuk menyelesaikan ini, kita akan menggunakan kombinasi dari:\n",
    " - `OpenAI` untuk menciptakan pengalaman chat bagi pengguna\n",
    " - `Microsoft Learn Catalog API` untuk membantu pengguna menemukan kursus berdasarkan permintaan mereka\n",
    " - `Function Calling` untuk mengambil pertanyaan pengguna dan mengirimkannya ke sebuah fungsi untuk melakukan permintaan API.\n",
    "\n",
    "Untuk memulai, mari kita lihat mengapa kita ingin menggunakan pemanggilan fungsi sejak awal:\n",
    "\n",
    "print(\"Pesan pada permintaan berikutnya:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # dapatkan respons baru dari GPT di mana ia bisa melihat respons fungsi\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mengapa Menggunakan Function Calling\n",
    "\n",
    "Jika kamu sudah menyelesaikan pelajaran lain di kursus ini, kamu mungkin sudah memahami kekuatan menggunakan Large Language Models (LLMs). Semoga kamu juga bisa melihat beberapa keterbatasannya.\n",
    "\n",
    "Function Calling adalah fitur dari OpenAI Service yang dirancang untuk mengatasi tantangan berikut:\n",
    "\n",
    "Format Respons yang Tidak Konsisten:\n",
    "- Sebelum adanya function calling, respons dari large language model tidak terstruktur dan seringkali tidak konsisten. Developer harus menulis kode validasi yang rumit untuk menangani setiap variasi output.\n",
    "\n",
    "Integrasi Terbatas dengan Data Eksternal:\n",
    "- Sebelum fitur ini ada, sulit untuk memasukkan data dari bagian lain aplikasi ke dalam konteks chat.\n",
    "\n",
    "Dengan menstandarkan format respons dan memungkinkan integrasi yang mulus dengan data eksternal, function calling memudahkan pengembangan dan mengurangi kebutuhan akan logika validasi tambahan.\n",
    "\n",
    "Pengguna tidak bisa mendapatkan jawaban seperti \"Bagaimana cuaca saat ini di Stockholm?\". Ini karena model hanya terbatas pada waktu data dilatih.\n",
    "\n",
    "Mari kita lihat contoh di bawah ini yang menggambarkan masalah ini:\n",
    "\n",
    "Misalkan kita ingin membuat database data siswa agar bisa merekomendasikan kursus yang tepat untuk mereka. Di bawah ini ada dua deskripsi siswa yang sangat mirip dalam data yang mereka miliki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin mengirimkan ini ke LLM untuk memproses data. Ini nantinya bisa digunakan dalam aplikasi kami untuk dikirim ke API atau disimpan di database.\n",
    "\n",
    "Mari kita buat dua prompt identik yang akan kita instruksikan ke LLM mengenai informasi apa saja yang ingin kita ambil:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kami ingin mengirimkan ini ke LLM untuk menganalisis bagian-bagian yang penting bagi produk kami. Jadi kami dapat membuat dua prompt identik untuk menginstruksikan LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setelah membuat dua prompt ini, kita akan mengirimkannya ke LLM dengan menggunakan `openai.ChatCompletion`. Kita menyimpan prompt tersebut dalam variabel `messages` dan menetapkan peran sebagai `user`. Ini dilakukan untuk meniru pesan dari pengguna yang ditulis ke chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meskipun prompt-nya sama dan deskripsinya mirip, kita bisa mendapatkan format properti `Grades` yang berbeda.\n",
    "\n",
    "Jika kamu menjalankan sel di atas beberapa kali, formatnya bisa saja `3.7` atau `3.7 GPA`.\n",
    "\n",
    "Ini terjadi karena LLM menerima data tidak terstruktur dalam bentuk prompt tertulis dan juga mengembalikan data yang tidak terstruktur. Kita perlu memiliki format yang terstruktur agar kita tahu apa yang diharapkan saat menyimpan atau menggunakan data ini.\n",
    "\n",
    "Dengan menggunakan functional calling, kita bisa memastikan bahwa kita menerima data yang terstruktur. Saat menggunakan function calling, LLM sebenarnya tidak memanggil atau menjalankan fungsi apa pun. Sebaliknya, kita membuat sebuah struktur yang harus diikuti LLM untuk responsnya. Kemudian kita menggunakan respons terstruktur tersebut untuk mengetahui fungsi apa yang harus dijalankan di aplikasi kita.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram Alur Pemanggilan Fungsi](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.id.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kasus Penggunaan untuk pemanggilan fungsi\n",
    "\n",
    "**Memanggil Alat Eksternal**\n",
    "Chatbot sangat membantu dalam memberikan jawaban atas pertanyaan dari pengguna. Dengan menggunakan pemanggilan fungsi, chatbot bisa memanfaatkan pesan dari pengguna untuk menyelesaikan tugas tertentu. Misalnya, seorang siswa bisa meminta chatbot untuk \"Kirim email ke dosen saya bahwa saya butuh bantuan lebih untuk mata pelajaran ini\". Ini bisa memanggil fungsi `send_email(to: string, body: string)`\n",
    "\n",
    "**Membuat Query API atau Database**\n",
    "Pengguna dapat mencari informasi menggunakan bahasa alami yang kemudian diubah menjadi query atau permintaan API yang terformat. Contohnya, seorang guru meminta \"Siapa saja siswa yang sudah menyelesaikan tugas terakhir\" yang bisa memanggil fungsi bernama `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Membuat Data Terstruktur**\n",
    "Pengguna dapat mengambil sebuah blok teks atau CSV dan menggunakan LLM untuk mengekstrak informasi penting dari sana. Misalnya, seorang siswa bisa mengubah artikel Wikipedia tentang perjanjian damai untuk membuat kartu kilat AI. Ini bisa dilakukan dengan menggunakan fungsi bernama `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Membuat Panggilan Fungsi Pertama Anda\n",
    "\n",
    "Proses membuat panggilan fungsi terdiri dari 3 langkah utama:\n",
    "1. Memanggil Chat Completions API dengan daftar fungsi Anda dan pesan dari pengguna\n",
    "2. Membaca respons model untuk melakukan sebuah aksi, misalnya menjalankan fungsi atau memanggil API\n",
    "3. Melakukan panggilan lagi ke Chat Completions API dengan respons dari fungsi Anda untuk menggunakan informasi tersebut dalam membuat respons kepada pengguna.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Alur Pemanggilan Fungsi](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.id.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemen-elemen dari pemanggilan fungsi\n",
    "\n",
    "#### Input Pengguna\n",
    "\n",
    "Langkah pertama adalah membuat pesan dari pengguna. Ini bisa diisi secara dinamis dengan mengambil nilai dari input teks atau Anda bisa menetapkan nilainya di sini. Jika ini adalah pertama kalinya Anda bekerja dengan Chat Completions API, kita perlu mendefinisikan `role` dan `content` dari pesan tersebut.\n",
    "\n",
    "`role` bisa berupa `system` (membuat aturan), `assistant` (model), atau `user` (pengguna akhir). Untuk pemanggilan fungsi, kita akan menetapkannya sebagai `user` dan memberikan contoh pertanyaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Membuat fungsi.\n",
    "\n",
    "Selanjutnya kita akan mendefinisikan sebuah fungsi beserta parameter-parameternya. Di sini kita hanya akan menggunakan satu fungsi yang disebut `search_courses`, namun kamu bisa membuat beberapa fungsi.\n",
    "\n",
    "**Penting** : Fungsi-fungsi akan dimasukkan ke dalam pesan sistem untuk LLM dan akan mempengaruhi jumlah token yang tersedia untuk kamu gunakan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definisi**\n",
    "\n",
    "Struktur definisi fungsi memiliki beberapa tingkat, masing-masing dengan propertinya sendiri. Berikut adalah penjelasan tentang struktur bertingkat tersebut:\n",
    "\n",
    "**Properti Fungsi Tingkat Atas:**\n",
    "\n",
    "`name` - Nama fungsi yang ingin kita panggil.\n",
    "\n",
    "`description` - Ini adalah deskripsi tentang cara kerja fungsi tersebut. Di sini penting untuk spesifik dan jelas.\n",
    "\n",
    "`parameters` - Daftar nilai dan format yang ingin Anda hasilkan dalam respons model.\n",
    "\n",
    "**Properti Objek Parameters:**\n",
    "\n",
    "`type` - Tipe data dari objek parameters (biasanya \"object\")\n",
    "\n",
    "`properties` - Daftar nilai spesifik yang akan digunakan model untuk responsnya\n",
    "\n",
    "**Properti Parameter Individual:**\n",
    "\n",
    "`name` - Didefinisikan secara implisit oleh kunci properti (misalnya, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Tipe data dari parameter spesifik ini (misalnya, \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Deskripsi dari parameter spesifik tersebut\n",
    "\n",
    "**Properti Opsional:**\n",
    "\n",
    "`required` - Sebuah array yang mencantumkan parameter mana saja yang wajib diisi agar pemanggilan fungsi dapat diselesaikan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memanggil fungsi\n",
    "Setelah mendefinisikan sebuah fungsi, sekarang kita perlu memasukkannya dalam pemanggilan ke Chat Completion API. Kita melakukan ini dengan menambahkan `functions` ke permintaan. Dalam hal ini `functions=functions`.\n",
    "\n",
    "Ada juga opsi untuk mengatur `function_call` ke `auto`. Ini berarti kita membiarkan LLM yang memutuskan fungsi mana yang sebaiknya dipanggil berdasarkan pesan pengguna, bukan kita yang menentukannya sendiri.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang mari kita lihat responsnya dan bagaimana formatnya:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Kamu bisa melihat bahwa nama fungsi dipanggil dan dari pesan pengguna, LLM dapat menemukan data yang sesuai untuk mengisi argumen fungsi tersebut.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mengintegrasikan Pemanggilan Fungsi ke dalam Aplikasi.\n",
    "\n",
    "Setelah kita menguji respons yang diformat dari LLM, sekarang kita bisa mengintegrasikannya ke dalam aplikasi.\n",
    "\n",
    "### Mengelola alur\n",
    "\n",
    "Untuk mengintegrasikan ini ke dalam aplikasi kita, mari lakukan langkah-langkah berikut:\n",
    "\n",
    "Pertama, lakukan pemanggilan ke layanan OpenAI dan simpan pesan tersebut dalam variabel bernama `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sekarang kita akan mendefinisikan fungsi yang akan memanggil Microsoft Learn API untuk mendapatkan daftar kursus:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebagai praktik terbaik, kita akan melihat apakah model ingin memanggil sebuah fungsi. Setelah itu, kita akan membuat salah satu fungsi yang tersedia dan mencocokkannya dengan fungsi yang sedang dipanggil. \n",
    "Selanjutnya, kita akan mengambil argumen dari fungsi tersebut dan memetakannya ke argumen dari LLM.\n",
    "\n",
    "Terakhir, kita akan menambahkan pesan pemanggilan fungsi dan nilai-nilai yang dikembalikan oleh pesan `search_courses`. Ini memberikan semua informasi yang dibutuhkan LLM\n",
    "untuk merespons pengguna menggunakan bahasa alami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tantangan Kode\n",
    "\n",
    "Kerja bagus! Untuk melanjutkan pembelajaran tentang OpenAI Function Calling, kamu bisa membangun: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Tambahkan lebih banyak parameter pada fungsi yang bisa membantu pembelajar menemukan lebih banyak kursus. Kamu bisa menemukan parameter API yang tersedia di sini:\n",
    " - Buat pemanggilan fungsi lain yang mengambil informasi tambahan dari pembelajar seperti bahasa asli mereka\n",
    " - Buat penanganan error ketika pemanggilan fungsi dan/atau API tidak mengembalikan kursus yang sesuai\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan terjemahan yang akurat, harap diketahui bahwa terjemahan otomatis dapat mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang sah. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang timbul akibat penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:12:42+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}