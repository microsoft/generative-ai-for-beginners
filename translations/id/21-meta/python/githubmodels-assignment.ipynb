{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Membangun dengan Model Keluarga Meta\n",
    "\n",
    "## Pendahuluan\n",
    "\n",
    "Pelajaran ini akan membahas:\n",
    "\n",
    "- Mengenal dua model utama dari keluarga Meta - Llama 3.1 dan Llama 3.2\n",
    "- Memahami kasus penggunaan dan skenario untuk masing-masing model\n",
    "- Contoh kode untuk menunjukkan fitur unik dari setiap model\n",
    "\n",
    "## Keluarga Model Meta\n",
    "\n",
    "Dalam pelajaran ini, kita akan membahas 2 model dari keluarga Meta atau \"Llama Herd\" - Llama 3.1 dan Llama 3.2\n",
    "\n",
    "Model-model ini tersedia dalam beberapa varian dan bisa ditemukan di marketplace Model Github. Berikut informasi lebih lanjut tentang cara menggunakan Github Models untuk [prototyping dengan model AI](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "Varian Model:\n",
    "- Llama 3.1 - 70B Instruct\n",
    "- Llama 3.1 - 405B Instruct\n",
    "- Llama 3.2 - 11B Vision Instruct\n",
    "- Llama 3.2 - 90B Vision Instruct\n",
    "\n",
    "*Catatan: Llama 3 juga tersedia di Github Models namun tidak akan dibahas dalam pelajaran ini*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "Dengan 405 Miliar Parameter, Llama 3.1 masuk ke dalam kategori LLM open source.\n",
    "\n",
    "Model ini merupakan peningkatan dari Llama 3 sebelumnya dengan menawarkan:\n",
    "\n",
    "- Jendela konteks yang lebih besar - 128k token dibandingkan 8k token\n",
    "- Maksimal Output Token yang lebih besar - 4096 dibandingkan 2048\n",
    "- Dukungan Multibahasa yang lebih baik - karena peningkatan jumlah token pelatihan\n",
    "\n",
    "Hal-hal ini memungkinkan Llama 3.1 menangani kasus penggunaan yang lebih kompleks saat membangun aplikasi GenAI, termasuk:\n",
    "- Native Function Calling - kemampuan untuk memanggil alat dan fungsi eksternal di luar alur kerja LLM\n",
    "- Performa RAG yang lebih baik - berkat jendela konteks yang lebih besar\n",
    "- Pembuatan Data Sintetis - kemampuan untuk membuat data yang efektif untuk tugas seperti fine-tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Native Function Calling\n",
    "\n",
    "Llama 3.1 telah disesuaikan agar lebih efektif dalam melakukan pemanggilan fungsi atau alat. Model ini juga memiliki dua alat bawaan yang bisa dikenali dan digunakan sesuai permintaan dari pengguna. Alat-alat tersebut adalah:\n",
    "\n",
    "- **Brave Search** - Dapat digunakan untuk mendapatkan informasi terbaru seperti cuaca dengan melakukan pencarian web\n",
    "- **Wolfram Alpha** - Dapat digunakan untuk perhitungan matematika yang lebih kompleks sehingga Anda tidak perlu menulis fungsi sendiri.\n",
    "\n",
    "Anda juga bisa membuat alat kustom sendiri yang dapat dipanggil oleh LLM.\n",
    "\n",
    "Pada contoh kode di bawah ini:\n",
    "\n",
    "- Kita mendefinisikan alat yang tersedia (brave_search, wolfram_alpha) di prompt sistem.\n",
    "- Mengirim prompt pengguna yang menanyakan tentang cuaca di sebuah kota tertentu.\n",
    "- LLM akan merespons dengan memanggil alat Brave Search yang akan terlihat seperti ini `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`\n",
    "\n",
    "*Catatan: Contoh ini hanya melakukan pemanggilan alat, jika Anda ingin mendapatkan hasilnya, Anda perlu membuat akun gratis di halaman API Brave dan mendefinisikan fungsi tersebut sendiri*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2\n",
    "\n",
    "Meskipun merupakan sebuah LLM, salah satu keterbatasan yang dimiliki Llama 3.1 adalah multimodalitas. Artinya, kemampuan untuk menggunakan berbagai jenis input seperti gambar sebagai prompt dan memberikan respons. Kemampuan ini menjadi salah satu fitur utama dari Llama 3.2. Fitur-fitur tersebut juga mencakup:\n",
    "\n",
    "- Multimodalitas - memiliki kemampuan untuk mengevaluasi prompt berupa teks maupun gambar\n",
    "- Varian ukuran Kecil hingga Menengah (11B dan 90B) - memberikan opsi penerapan yang fleksibel,\n",
    "- Varian khusus teks (1B dan 3B) - memungkinkan model dijalankan di perangkat edge / mobile dan memberikan latensi rendah\n",
    "\n",
    "Dukungan multimodal ini merupakan langkah besar di dunia model open source. Contoh kode di bawah ini menggunakan gambar dan prompt teks untuk mendapatkan analisis gambar dari Llama 3.2 90B.\n",
    "\n",
    "### Dukungan Multimodal dengan Llama 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Belajar tidak berhenti di sini, lanjutkan Perjalananmu\n",
    "\n",
    "Setelah menyelesaikan pelajaran ini, lihat [Koleksi Pembelajaran AI Generatif](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kami untuk terus meningkatkan pengetahuanmu tentang AI Generatif!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Penafian**:  \nDokumen ini telah diterjemahkan menggunakan layanan terjemahan AI [Co-op Translator](https://github.com/Azure/co-op-translator). Meskipun kami berupaya untuk memberikan terjemahan yang akurat, harap diketahui bahwa terjemahan otomatis dapat mengandung kesalahan atau ketidakakuratan. Dokumen asli dalam bahasa aslinya harus dianggap sebagai sumber yang berwenang. Untuk informasi yang bersifat kritis, disarankan menggunakan jasa terjemahan profesional oleh manusia. Kami tidak bertanggung jawab atas kesalahpahaman atau penafsiran yang timbul akibat penggunaan terjemahan ini.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:46:20+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "id"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}