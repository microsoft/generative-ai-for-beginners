{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## പരിചയം \n",
    "\n",
    "ഈ പാഠം ഉൾക്കൊള്ളുന്നതാണ്: \n",
    "- ഫംഗ്ഷൻ കോൾ ചെയ്യുന്നത് എന്താണെന്നും അതിന്റെ ഉപയോഗ കേസുകൾ \n",
    "- OpenAI ഉപയോഗിച്ച് ഫംഗ്ഷൻ കോൾ എങ്ങനെ സൃഷ്ടിക്കാമെന്ന് \n",
    "- ഒരു ആപ്ലിക്കേഷനിൽ ഫംഗ്ഷൻ കോൾ എങ്ങനെ സംയോജിപ്പിക്കാമെന്ന് \n",
    "\n",
    "## പഠന ലക്ഷ്യങ്ങൾ \n",
    "\n",
    "ഈ പാഠം പൂർത്തിയാക്കിയശേഷം നിങ്ങൾ അറിയുകയും മനസിലാക്കുകയും ചെയ്യുക: \n",
    "\n",
    "- ഫംഗ്ഷൻ കോൾ ഉപയോഗിക്കുന്നതിന്റെ ഉദ്ദേശ്യം \n",
    "- OpenAI സർവീസ് ഉപയോഗിച്ച് ഫംഗ്ഷൻ കോൾ സജ്ജമാക്കൽ \n",
    "- നിങ്ങളുടെ ആപ്ലിക്കേഷന്റെ ഉപയോഗ കേസിനായി ഫംഗ്ഷൻ കോൾ ഫലപ്രദമായി രൂപകൽപ്പന ചെയ്യുക\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ഫംഗ്ഷൻ കോൾസ് മനസ്സിലാക്കൽ\n",
    "\n",
    "ഈ പാഠത്തിനായി, ഞങ്ങൾ ഒരു എഡ്യൂക്കേഷൻ സ്റ്റാർട്ടപ്പിനായി ഒരു ഫീച്ചർ നിർമ്മിക്കാൻ ആഗ്രഹിക്കുന്നു, ഇത് ഉപയോക്താക്കൾക്ക് ടെക്നിക്കൽ കോഴ്സുകൾ കണ്ടെത്താൻ ഒരു ചാറ്റ്ബോട്ട് ഉപയോഗിക്കാൻ അനുവദിക്കും. അവരുടെ കഴിവ് നില, നിലവിലെ റോളും താൽപ്പര്യമുള്ള സാങ്കേതികവിദ്യയും അനുസരിച്ച് കോഴ്സുകൾ ഞങ്ങൾ ശിപാർശ ചെയ്യും.\n",
    "\n",
    "ഇത് പൂർത്തിയാക്കാൻ ഞങ്ങൾ ഉപയോഗിക്കുന്ന സംയോജനം:\n",
    " - ഉപയോക്താവിന് ഒരു ചാറ്റ് അനുഭവം സൃഷ്ടിക്കാൻ `OpenAI`\n",
    " - ഉപയോക്താവിന്റെ അഭ്യർത്ഥനയുടെ അടിസ്ഥാനത്തിൽ കോഴ്സുകൾ കണ്ടെത്താൻ സഹായിക്കുന്ന `Microsoft Learn Catalog API`\n",
    " - ഉപയോക്താവിന്റെ ചോദ്യം എടുത്ത് API അഭ്യർത്ഥന നടത്താൻ ഒരു ഫംഗ്ഷനിലേക്ക് അയയ്ക്കാൻ `Function Calling`\n",
    "\n",
    "ആരംഭിക്കാൻ, ആദ്യം ഫംഗ്ഷൻ കോൾ ഉപയോഗിക്കേണ്ടത് എന്തുകൊണ്ടാണെന്ന് നോക്കാം:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # ഫംഗ്ഷൻ പ്രതികരണം കാണാൻ GPT-യിൽ നിന്ന് പുതിയ പ്രതികരണം നേടുക\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഫംഗ്ഷൻ കോൾ ചെയ്യാനുള്ള കാരണം\n",
    "\n",
    "നിങ്ങൾ ഈ കോഴ്സിലെ മറ്റേതെങ്കിലും പാഠം പൂർത്തിയാക്കിയിട്ടുണ്ടെങ്കിൽ, വലിയ ഭാഷാ മോഡലുകൾ (LLMs) ഉപയോഗിക്കുന്നതിന്റെ ശക്തി നിങ്ങൾക്ക് മനസ്സിലായിരിക്കാം. അതുപോലെ തന്നെ അവയുടെ ചില പരിമിതികളും നിങ്ങൾക്ക് കാണാനാകാം.\n",
    "\n",
    "ഫംഗ്ഷൻ കോൾ ചെയ്യൽ OpenAI സർവീസിന്റെ ഒരു സവിശേഷതയാണ്, താഴെപ്പറയുന്ന വെല്ലുവിളികളെ നേരിടാൻ രൂപകൽപ്പന ചെയ്തിരിക്കുന്നത്:\n",
    "\n",
    "അസമതുല്യമായ പ്രതികരണ ഫോർമാറ്റിംഗ്:\n",
    "- ഫംഗ്ഷൻ കോൾ ചെയ്യുന്നതിന് മുമ്പ്, വലിയ ഭാഷാ മോഡലിൽ നിന്നുള്ള പ്രതികരണങ്ങൾ ഘടനരഹിതവും അസമതുല്യവുമായിരുന്നു. ഡെവലപ്പർമാർ ഓരോ വ്യത്യാസവും കൈകാര്യം ചെയ്യാൻ സങ്കീർണ്ണമായ പരിശോധന കോഡ് എഴുതേണ്ടിവന്നു.\n",
    "\n",
    "ബാഹ്യ ഡാറ്റയുമായി പരിമിതമായ സംയോജനം:\n",
    "- ഈ സവിശേഷതയ്ക്ക് മുമ്പ്, ഒരു ചാറ്റ് കോൺടെക്സ്റ്റിൽ ആപ്ലിക്കേഷന്റെ മറ്റ് ഭാഗങ്ങളിൽ നിന്നുള്ള ഡാറ്റ ഉൾപ്പെടുത്തുന്നത് ബുദ്ധിമുട്ടായിരുന്നു.\n",
    "\n",
    "പ്രതികരണ ഫോർമാറ്റുകൾ സ്റ്റാൻഡേർഡൈസ് ചെയ്ത് ബാഹ്യ ഡാറ്റയുമായി സുതാര്യമായ സംയോജനം സാധ്യമാക്കുന്നതിലൂടെ, ഫംഗ്ഷൻ കോൾ ചെയ്യൽ ഡെവലപ്പ്മെന്റ് ലളിതമാക്കുകയും അധിക പരിശോധന ലജിക് ആവശ്യം കുറയ്ക്കുകയും ചെയ്യുന്നു.\n",
    "\n",
    "ഉപയോക്താക്കൾക്ക് \"സ്റ്റോക്ക്ഹോംയിലെ നിലവിലെ കാലാവസ്ഥ എന്താണ്?\" പോലുള്ള ചോദ്യങ്ങൾക്ക് ഉത്തരം ലഭിക്കാനായിരുന്നില്ല. കാരണം മോഡലുകൾ പരിശീലിപ്പിച്ച ഡാറ്റയുടെ സമയത്തേക്ക് മാത്രമേ പരിമിതമായിരുന്നുള്ളൂ.\n",
    "\n",
    "ഈ പ്രശ്നം വിശദീകരിക്കുന്ന താഴെ കാണുന്ന ഉദാഹരണം നോക്കാം:\n",
    "\n",
    "നമുക്ക് വിദ്യാർത്ഥികളുടെ ഡാറ്റാബേസ് സൃഷ്ടിച്ച് അവർക്കു ശരിയായ കോഴ്സ് നിർദ്ദേശിക്കാൻ ആഗ്രഹിക്കാം. താഴെ രണ്ട് വിദ്യാർത്ഥികളുടെ വിവരങ്ങൾ കാണാം, അവ തമ്മിൽ ഡാറ്റയിൽ വളരെ സമാനമാണ്.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "നാം ഈ ഡാറ്റ പാഴ്‌സ് ചെയ്യാൻ ഒരു LLM-ന് അയയ്ക്കാൻ ആഗ്രഹിക്കുന്നു. ഇത് പിന്നീട് നമ്മുടെ ആപ്ലിക്കേഷനിൽ API-യിലേക്ക് അയയ്ക്കാനോ ഡാറ്റാബേസിൽ സൂക്ഷിക്കാനോ ഉപയോഗിക്കാം.\n",
    "\n",
    "നാം LLM-ന് ഞങ്ങൾ താൽപര്യമുള്ള വിവരങ്ങൾ എന്തെല്ലാമാണെന്ന് നിർദ്ദേശിക്കുന്ന രണ്ട് സമാനമായ പ്രോംപ്റ്റുകൾ സൃഷ്ടിക്കാം:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "നാം ഇത് ഒരു LLM-ന് അയച്ച് നമ്മുടെ ഉൽപ്പന്നത്തിന് പ്രധാനപ്പെട്ട ഭാഗങ്ങൾ പാഴ്‌സ് ചെയ്യാൻ ആഗ്രഹിക്കുന്നു. അതിനാൽ LLM-നെ നിർദ്ദേശിക്കാൻ രണ്ട് സമാനമായ പ്രോംപ്റ്റുകൾ സൃഷ്ടിക്കാം:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ഈ രണ്ട് പ്രോംപ്റ്റുകളും സൃഷ്ടിച്ചതിന് ശേഷം, അവയെ `openai.ChatCompletion` ഉപയോഗിച്ച് LLM-ലേക്ക് അയയ്ക്കും. പ്രോംപ്റ്റ് `messages` എന്ന വേരിയബിളിൽ സൂക്ഷിക്കുകയും റോളായി `user` നിശ്ചയിക്കുകയും ചെയ്യുന്നു. ഇത് ഒരു ഉപയോക്താവിന്റെ സന്ദേശം ചാറ്റ്ബോട്ടിലേക്ക് എഴുതുന്നതിനെ അനുകരിക്കാൻ ആണ്.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ഇപ്പോൾ നാം രണ്ട് അഭ്യർത്ഥനകളും LLM-ലേക്ക് അയച്ച് ലഭിക്കുന്ന പ്രതികരണം പരിശോധിക്കാം.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "പ്രോംപ്റ്റുകൾ ഒരേതും വിവരണങ്ങൾ സമാനവുമാണെങ്കിലും, `Grades` പ്രോപ്പർട്ടിയുടെ വ്യത്യസ്ത ഫോർമാറ്റുകൾ ലഭിക്കാം.\n",
    "\n",
    "മുകളിൽ കൊടുത്ത സെൽ പലതവണ ഓടിച്ചാൽ, ഫോർമാറ്റ് `3.7` അല്ലെങ്കിൽ `3.7 GPA` ആകാം.\n",
    "\n",
    "ഇത് കാരണം LLM എഴുതിയ പ്രോംപ്റ്റിന്റെ രൂപത്തിൽ അനിയന്ത്രിത ഡാറ്റ സ്വീകരിച്ച് അനിയന്ത്രിത ഡാറ്റ തന്നെ തിരികെ നൽകുന്നു. നമുക്ക് ഒരു ഘടനാപരമായ ഫോർമാറ്റ് വേണം, അതിലൂടെ ഈ ഡാറ്റ സംഭരിക്കുമ്പോഴും ഉപയോഗിക്കുമ്പോഴും എന്ത് പ്രതീക്ഷിക്കാമെന്ന് അറിയാം.\n",
    "\n",
    "ഫംഗ്ഷണൽ കോളിംഗ് ഉപയോഗിച്ച്, നമുക്ക് ഘടനാപരമായ ഡാറ്റ തിരികെ ലഭിക്കുന്നതായി ഉറപ്പാക്കാം. ഫംഗ്ഷൻ കോളിംഗ് ഉപയോഗിക്കുമ്പോൾ, LLM യഥാർത്ഥത്തിൽ ഫംഗ്ഷനുകൾ വിളിക്കുകയോ ഓടിക്കുകയോ ചെയ്യാറില്ല. പകരം, LLM അതിന്റെ പ്രതികരണങ്ങൾക്ക് പിന്തുടരാനുള്ള ഒരു ഘടന നാം സൃഷ്ടിക്കുന്നു. പിന്നീട് ആ ഘടനാപരമായ പ്രതികരണങ്ങൾ ഉപയോഗിച്ച് നമുക്ക് നമ്മുടെ ആപ്ലിക്കേഷനുകളിൽ ഏത് ഫംഗ്ഷൻ ഓടിക്കണമെന്ന് അറിയാം.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ഫംഗ്ഷൻ കോളിംഗ് ഫ്ലോ ഡയഗ്രാം](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ml.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "അപ്പോൾ നാം ഫംഗ്ഷനിൽ നിന്നു ലഭിക്കുന്നതെടുത്ത് LLM-ലേക്ക് തിരിച്ച് അയക്കാം. LLM പിന്നീട് സ്വാഭാവിക ഭാഷ ഉപയോഗിച്ച് ഉപയോക്താവിന്റെ ചോദ്യം മറുപടി നൽകും.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഫംഗ്ഷൻ കോൾസ് ഉപയോഗിക്കുന്നതിന് ഉപയോഗകേസുകൾ\n",
    "\n",
    "**ബാഹ്യ ടൂളുകൾ കോൾ ചെയ്യൽ**  \n",
    "ചാറ്റ്ബോട്ടുകൾ ഉപയോക്താക്കളിൽ നിന്നുള്ള ചോദ്യങ്ങൾക്ക് ഉത്തരം നൽകുന്നതിൽ മികച്ചവയാണ്. ഫംഗ്ഷൻ കോൾ ഉപയോഗിച്ച്, ചാറ്റ്ബോട്ടുകൾ ഉപയോക്താക്കളുടെ സന്ദേശങ്ങൾ ഉപയോഗിച്ച് ചില പ്രവർത്തനങ്ങൾ പൂർത്തിയാക്കാൻ കഴിയും. ഉദാഹരണത്തിന്, ഒരു വിദ്യാർത്ഥി ചാറ്റ്ബോട്ടിനോട് \"ഈ വിഷയത്തിൽ കൂടുതൽ സഹായം വേണമെന്ന് എന്റെ അധ്യാപകനെ ഇമെയിൽ അയയ്ക്കുക\" എന്ന് ചോദിക്കാം. ഇത് `send_email(to: string, body: string)` എന്ന ഫംഗ്ഷൻ കോൾ ചെയ്യാൻ കഴിയും.\n",
    "\n",
    "**API അല്ലെങ്കിൽ ഡാറ്റാബേസ് ക്വെറികൾ സൃഷ്ടിക്കൽ**  \n",
    "ഉപയോക്താക്കൾ സ്വാഭാവിക ഭാഷ ഉപയോഗിച്ച് വിവരങ്ങൾ കണ്ടെത്താം, അത് ഫോർമാറ്റ് ചെയ്ത ക്വെറി അല്ലെങ്കിൽ API അഭ്യർത്ഥനയാക്കി മാറ്റപ്പെടുന്നു. ഉദാഹരണത്തിന്, ഒരു അധ്യാപകൻ \"അവസാന അസൈൻമെന്റ് പൂർത്തിയാക്കിയ വിദ്യാർത്ഥികൾ ആരെല്ലാം?\" എന്ന് ചോദിക്കുമ്പോൾ, `get_completed(student_name: string, assignment: int, current_status: string)` എന്ന ഫംഗ്ഷൻ കോൾ ചെയ്യാം.\n",
    "\n",
    "**സംഘടിത ഡാറ്റ സൃഷ്ടിക്കൽ**  \n",
    "ഉപയോക്താക്കൾ ഒരു ടെക്സ്റ്റ് ബ്ലോക്ക് അല്ലെങ്കിൽ CSV എടുത്ത് അതിൽ നിന്നുള്ള പ്രധാന വിവരങ്ങൾ LLM ഉപയോഗിച്ച് എടുക്കാം. ഉദാഹരണത്തിന്, ഒരു വിദ്യാർത്ഥി സമാധാന കരാറുകളെക്കുറിച്ചുള്ള വിക്കിപീഡിയ ലേഖനം എഐ ഫ്ലാഷ് കാർഡുകൾ സൃഷ്ടിക്കാൻ മാറ്റാം. ഇത് `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` എന്ന ഫംഗ്ഷൻ ഉപയോഗിച്ച് ചെയ്യാം.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. നിങ്ങളുടെ ആദ്യ ഫംഗ്ഷൻ കോൾ സൃഷ്ടിക്കൽ\n",
    "\n",
    "ഒരു ഫംഗ്ഷൻ കോൾ സൃഷ്ടിക്കുന്ന പ്രക്രിയയിൽ 3 പ്രധാന ഘട്ടങ്ങൾ ഉൾപ്പെടുന്നു:  \n",
    "1. നിങ്ങളുടെ ഫംഗ്ഷനുകളുടെ പട്ടികയും ഒരു ഉപയോക്തൃ സന്ദേശവും ഉപയോഗിച്ച് Chat Completions API കോൾ ചെയ്യുക  \n",
    "2. ഒരു പ്രവർത്തനം നടത്താൻ മോഡലിന്റെ പ്രതികരണം വായിക്കുക, ഉദാ: ഒരു ഫംഗ്ഷൻ അല്ലെങ്കിൽ API കോൾ നിർവഹിക്കുക  \n",
    "3. നിങ്ങളുടെ ഫംഗ്ഷനിൽ നിന്നുള്ള പ്രതികരണം ഉപയോഗിച്ച് ഉപയോക്താവിന് മറുപടി സൃഷ്ടിക്കാൻ Chat Completions API വീണ്ടും കോൾ ചെയ്യുക.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ഫംഗ്ഷൻ കോൾ ഫ്ലോ](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ml.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഫംഗ്ഷൻ കോൾ എലമെന്റുകൾ\n",
    "\n",
    "#### ഉപയോക്തൃ ഇൻപുട്ട്\n",
    "\n",
    "ആദ്യ ഘട്ടം ഒരു ഉപയോക്തൃ സന്ദേശം സൃഷ്ടിക്കുകയാണ്. ഇത് ഒരു ടെക്സ്റ്റ് ഇൻപുട്ടിന്റെ മൂല്യം എടുത്ത് ഡൈനാമിക്കായി നിയോഗിക്കാമോ അല്ലെങ്കിൽ നിങ്ങൾക്ക് ഇവിടെ ഒരു മൂല്യം നിയോഗിക്കാമോ. ഇത് Chat Completions API ഉപയോഗിച്ച് ആദ്യമായാണ് നിങ്ങൾ പ്രവർത്തിക്കുന്നത് എങ്കിൽ, സന്ദേശത്തിന്റെ `role`യും `content`ഉം നിർവചിക്കേണ്ടതുണ്ട്.\n",
    "\n",
    "`role` ആയിരിക്കാം `system` (നിയമങ്ങൾ സൃഷ്ടിക്കുന്നത്), `assistant` (മോഡൽ) അല്ലെങ്കിൽ `user` (അവസാന ഉപയോക്താവ്). ഫംഗ്ഷൻ കോൾ ചെയ്യുന്നതിനായി, ഇത് `user` ആയി നിയോഗിക്കുകയും ഒരു ഉദാഹരണ ചോദ്യവും നൽകുകയും ചെയ്യും.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഫംഗ്ഷനുകൾ സൃഷ്ടിക്കൽ. \n",
    "\n",
    "അടുത്തതായി നാം ഒരു ഫംഗ്ഷനും ആ ഫംഗ്ഷന്റെ പാരാമീറ്ററുകളും നിർവചിക്കും. ഇവിടെ നാം `search_courses` എന്ന ഒരു ഫംഗ്ഷൻ മാത്രം ഉപയോഗിക്കും, പക്ഷേ നിങ്ങൾക്ക് നിരവധി ഫംഗ്ഷനുകൾ സൃഷ്ടിക്കാം.\n",
    "\n",
    "**പ്രധാനമായത്** : ഫംഗ്ഷനുകൾ LLM-ന് സിസ്റ്റം സന്ദേശത്തിൽ ഉൾപ്പെടുകയും നിങ്ങൾക്ക് ലഭ്യമായ ടോക്കണുകളുടെ അളവിൽ ഉൾപ്പെടുകയും ചെയ്യും.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**നിർവചനങ്ങൾ** \n",
    "\n",
    "ഫംഗ്ഷൻ നിർവചന ഘടനയ്ക്ക് പല തലങ്ങളുണ്ട്, ഓരോതിലും അതിന്റെ സ്വന്തം ഗുണങ്ങളുണ്ട്. ഇവിടെ നസ്റ്റഡ് ഘടനയുടെ ഒരു വിഭജനം കൊടുക്കുന്നു:\n",
    "\n",
    "**മുകളിൽ തലത്തിലുള്ള ഫംഗ്ഷൻ ഗുണങ്ങൾ:**\n",
    "\n",
    "`name` - വിളിക്കേണ്ട ഫംഗ്ഷന്റെ പേര്. \n",
    "\n",
    "`description` - ഫംഗ്ഷൻ എങ്ങനെ പ്രവർത്തിക്കുന്നു എന്നതിന്റെ വിവരണം. ഇവിടെ വ്യക്തവും വ്യക്തമുമായിരിക്കണം. \n",
    "\n",
    "`parameters` - മോഡൽ അതിന്റെ പ്രതികരണത്തിൽ ഉത്പാദിപ്പിക്കേണ്ട മൂല്യങ്ങളും ഫോർമാറ്റും ഉള്ള ഒരു പട്ടിക. \n",
    "\n",
    "**പാരാമീറ്ററുകളുടെ ഒബ്ജക്റ്റ് ഗുണങ്ങൾ:**\n",
    "\n",
    "`type` - പാരാമീറ്ററുകളുടെ ഒബ്ജക്റ്റിന്റെ ഡാറ്റാ തരം (സാധാരണയായി \"object\")\n",
    "\n",
    "`properties` - മോഡൽ അതിന്റെ പ്രതികരണത്തിനായി ഉപയോഗിക്കുന്ന പ്രത്യേക മൂല്യങ്ങളുടെ പട്ടിക. \n",
    "\n",
    "**വ്യക്തിഗത പാരാമീറ്റർ ഗുണങ്ങൾ:**\n",
    "\n",
    "`name` - പ്രോപ്പർട്ടി കീ ഉപയോഗിച്ച് നിഷ്കർഷിതമായി നിർവചിക്കപ്പെടുന്നു (ഉദാ: \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - ഈ പ്രത്യേക പാരാമീറ്ററിന്റെ ഡാറ്റാ തരം (ഉദാ: \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - പ്രത്യേക പാരാമീറ്ററിന്റെ വിവരണം. \n",
    "\n",
    "**ഐച്ഛിക ഗുണങ്ങൾ:**\n",
    "\n",
    "`required` - ഫംഗ്ഷൻ കോൾ പൂർത്തിയാക്കാൻ ആവശ്യമായ പാരാമീറ്ററുകളുടെ പട്ടിക.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഫംഗ്ഷൻ കോൾ ചെയ്യൽ  \n",
    "ഒരു ഫംഗ്ഷൻ നിർവചിച്ചതിന് ശേഷം, ഇപ്പോൾ അത് Chat Completion API-യിലേക്ക് കോൾ ചെയ്യുന്നതിൽ ഉൾപ്പെടുത്തേണ്ടതുണ്ട്. ഇത് ചെയ്യാൻ, അഭ്യർത്ഥനയിൽ `functions` ചേർക്കുന്നു. ഈ കേസിൽ `functions=functions` ആണ്.  \n",
    "\n",
    "`function_call` നെ `auto` ആയി സജ്ജീകരിക്കുന്ന ഒരു ഓപ്ഷനും ഉണ്ട്. ഇതിന്റെ അർത്ഥം, ഉപയോക്തൃ സന്ദേശത്തിന്റെ അടിസ്ഥാനത്തിൽ ഏത് ഫംഗ്ഷൻ കോൾ ചെയ്യണമെന്ന് LLM-ന് തീരുമാനിക്കാൻ അനുവദിക്കുന്നതാണ്, ഞങ്ങൾ തന്നെ അത് നിശ്ചയിക്കാതെ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ഇപ്പോൾ നമുക്ക് പ്രതികരണം നോക്കാം, അത് എങ്ങനെ ഫോർമാറ്റ് ചെയ്തിട്ടുള്ളതാണെന്ന് കാണാം:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "നിങ്ങൾക്ക് കാണാം, ഫംഗ്ഷന്റെ പേര് വിളിക്കപ്പെട്ടിട്ടുണ്ട്, കൂടാതെ ഉപയോക്തൃ സന്ദേശത്തിൽ നിന്നുള്ള ഡാറ്റ ഫംഗ്ഷന്റെ arguments-നു അനുയോജ്യമായി കണ്ടെത്താൻ LLM കഴിഞ്ഞു.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ഒരു അപ്ലിക്കേഷനിൽ ഫംഗ്ഷൻ കോൾസ് സംയോജിപ്പിക്കൽ. \n",
    "\n",
    "\n",
    "LLM-ൽ നിന്നുള്ള ഫോർമാറ്റ് ചെയ്ത പ്രതികരണം ഞങ്ങൾ പരിശോധിച്ചതിന് ശേഷം, ഇപ്പോൾ ഇത് ഒരു അപ്ലിക്കേഷനിൽ സംയോജിപ്പിക്കാം. \n",
    "\n",
    "### പ്രവാഹം നിയന്ത്രിക്കൽ \n",
    "\n",
    "ഇത് നമ്മുടെ അപ്ലിക്കേഷനിൽ സംയോജിപ്പിക്കാൻ, താഴെ പറയുന്ന ഘട്ടങ്ങൾ സ്വീകരിക്കാം: \n",
    "\n",
    "ആദ്യം, OpenAI സേവനങ്ങളിലേക്ക് കോൾ ചെയ്യുകയും സന്ദേശം `response_message` എന്ന വേരിയബിളിൽ സൂക്ഷിക്കുകയും ചെയ്യാം. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ഇപ്പോൾ നാം കോഴ്സുകളുടെ പട്ടിക ലഭിക്കാൻ Microsoft Learn API വിളിക്കുന്ന ഫംഗ്ഷൻ നിർവചിക്കും:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ഒരു മികച്ച പ്രാക്ടീസായി, മോഡൽ ഒരു ഫംഗ്ഷൻ വിളിക്കണമെന്ന് ആഗ്രഹിക്കുന്നുണ്ടോ എന്ന് നാം പിന്നീട് കാണും. അതിനുശേഷം, ലഭ്യമായ ഫംഗ്ഷനുകളിൽ ഒന്നിനെ നാം സൃഷ്ടിച്ച് വിളിക്കപ്പെടുന്ന ഫംഗ്ഷനുമായി പൊരുത്തപ്പെടുത്തും.  \n",
    "അതിനുശേഷം, ഫംഗ്ഷന്റെ arguments എടുത്ത് അവ LLM-ലെ arguments-നോട് മാപ്പ് ചെയ്യും.\n",
    "\n",
    "അവസാനമായി, ഫംഗ്ഷൻ കോൾ സന്ദേശവും `search_courses` സന്ദേശം വഴി തിരികെ ലഭിച്ച മൂല്യങ്ങളും നാം ചേർക്കും. ഇത് LLM-ന് ഉപയോക്താവിനോട് സ്വാഭാവിക ഭാഷ ഉപയോഗിച്ച് പ്രതികരിക്കാൻ ആവശ്യമായ എല്ലാ വിവരങ്ങളും നൽകുന്നു.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ഇപ്പോൾ നാം അപ്ഡേറ്റ് ചെയ്ത സന്ദേശം LLM-ലേക്ക് അയയ്ക്കും, അതിലൂടെ API JSON ഫോർമാറ്റിലുള്ള മറുപടിയുടെ പകരം സ്വാഭാവിക ഭാഷാ മറുപടി ലഭിക്കും.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## കോഡ് ചലഞ്ച്\n",
    "\n",
    "ശ്രേഷ്ഠമായ ജോലി! OpenAI ഫംഗ്ഷൻ കോളിംഗ് പഠനം തുടരാൻ നിങ്ങൾക്ക് നിർമ്മിക്കാം: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - പഠനാർത്ഥികൾക്ക് കൂടുതൽ കോഴ്സുകൾ കണ്ടെത്താൻ സഹായിക്കുന്ന ഫംഗ്ഷന്റെ കൂടുതൽ പാരാമീറ്ററുകൾ. ലഭ്യമായ API പാരാമീറ്ററുകൾ ഇവിടെ കണ്ടെത്താം:  \n",
    " - പഠനാർത്ഥിയുടെ മാതൃഭാഷ പോലുള്ള കൂടുതൽ വിവരങ്ങൾ സ്വീകരിക്കുന്ന മറ്റൊരു ഫംഗ്ഷൻ കോളും സൃഷ്ടിക്കുക  \n",
    " - ഫംഗ്ഷൻ കോളും/അഥവാ API കോളും യോജിച്ച കോഴ്സുകൾ തിരികെ നൽകാത്തപ്പോൾ പിശക് കൈകാര്യം ചെയ്യൽ സൃഷ്ടിക്കുക\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**അസൂയാ**:  \nഈ രേഖ AI വിവർത്തന സേവനം [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. നാം കൃത്യതയ്ക്ക് ശ്രമിച്ചിട്ടുണ്ടെങ്കിലും, സ്വയം പ്രവർത്തിക്കുന്ന വിവർത്തനങ്ങളിൽ പിശകുകൾ അല്ലെങ്കിൽ തെറ്റുകൾ ഉണ്ടാകാമെന്ന് ദയവായി ശ്രദ്ധിക്കുക. അതിന്റെ മാതൃഭാഷയിലുള്ള യഥാർത്ഥ രേഖയാണ് പ്രാമാണികമായ ഉറവിടം എന്ന് പരിഗണിക്കേണ്ടതാണ്. നിർണായകമായ വിവരങ്ങൾക്ക്, പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ശുപാർശ ചെയ്യപ്പെടുന്നു. ഈ വിവർത്തനം ഉപയോഗിക്കുന്നതിൽ നിന്നുണ്ടാകുന്ന ഏതെങ്കിലും തെറ്റിദ്ധാരണകൾക്കോ തെറ്റായ വ്യാഖ്യാനങ്ങൾക്കോ ഞങ്ങൾ ഉത്തരവാദികളല്ല.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T21:16:26+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}