{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ഓപ്പൺ എഐ മോഡലുകൾ ഫൈൻ ട്യൂണിംഗ്\n",
    "\n",
    "ഈ നോട്ട്‌ബുക്ക് ഓപ്പൺ എഐയുടെ [ഫൈൻ ട്യൂണിംഗ്](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) ഡോക്യുമെന്റേഷനിൽ നൽകിയ നിലവിലെ മാർഗ്ഗനിർദ്ദേശങ്ങളുടെ അടിസ്ഥാനത്തിലാണ്.\n",
    "\n",
    "ഫൈൻ-ട്യൂണിംഗ് നിങ്ങളുടെ ആപ്ലിക്കേഷനിനായി ഫൗണ്ടേഷൻ മോഡലുകളുടെ പ്രകടനം മെച്ചപ്പെടുത്തുന്നു, അതിനെ പ്രത്യേക ഉപയോഗകേസ് അല്ലെങ്കിൽ സാഹചര്യവുമായി ബന്ധപ്പെട്ട അധിക ഡാറ്റയും കോൺടെക്സ്റ്റും ഉപയോഗിച്ച് വീണ്ടും പരിശീലിപ്പിച്ച്. _ഫ്യൂ ഷോട്ട് ലേണിംഗ്_ , _റിട്രീവൽ ഓഗ്മെന്റഡ് ജനറേഷൻ_ പോലുള്ള പ്രോംപ്റ്റ് എഞ്ചിനീയറിംഗ് സാങ്കേതികവിദ്യകൾ നിലവിലുള്ള പ്രോംപ്റ്റ് ബന്ധപ്പെട്ട ഡാറ്റയോടെ മെച്ചപ്പെടുത്താൻ അനുവദിക്കുന്നുവെന്ന് ശ്രദ്ധിക്കുക. എന്നാൽ, ഈ സമീപനങ്ങൾ ലക്ഷ്യമിട്ട ഫൗണ്ടേഷൻ മോഡലിന്റെ പരമാവധി ടോക്കൺ വിൻഡോ വലുപ്പം കൊണ്ട് പരിമിതമാണ്.\n",
    "\n",
    "ഫൈൻ-ട്യൂണിംഗിലൂടെ, ആവശ്യമായ ഡാറ്റ ഉപയോഗിച്ച് മോഡലിനെ തന്നെ ഫലപ്രദമായി വീണ്ടും പരിശീലിപ്പിക്കുന്നു (പരമാവധി ടോക്കൺ വിൻഡോയിൽ ഉൾപ്പെടുത്താൻ കഴിയുന്നതിൽനിന്ന് വളരെ കൂടുതൽ ഉദാഹരണങ്ങൾ ഉപയോഗിക്കാൻ സാധിക്കുന്നു) - കൂടാതെ ഇൻഫറൻസ് സമയത്ത് ഉദാഹരണങ്ങൾ നൽകേണ്ടതില്ലാത്ത _കസ്റ്റം_ മോഡൽ പതിപ്പ് വിന്യസിക്കുന്നു. ഇത് നമ്മുടെ പ്രോംപ്റ്റ് ഡിസൈന്റെ ഫലപ്രദത മെച്ചപ്പെടുത്തുന്നതിന് മാത്രമല്ല (ടോക്കൺ വിൻഡോ മറ്റുള്ള കാര്യങ്ങൾക്ക് ഉപയോഗിക്കാൻ കൂടുതൽ സ്വാതന്ത്ര്യം ലഭിക്കുന്നു), ഇൻഫറൻസ് സമയത്ത് മോഡലിലേക്ക് അയയ്ക്കേണ്ട ടോക്കണുകളുടെ എണ്ണം കുറയ്ക്കുന്നതിലൂടെ ചിലവുകളും കുറയ്ക്കാൻ സഹായിക്കുന്നു.\n",
    "\n",
    "ഫൈൻ ട്യൂണിംഗിന് 4 ഘട്ടങ്ങളുണ്ട്:\n",
    "1. പരിശീലന ഡാറ്റ തയ്യാറാക്കി അപ്‌ലോഡ് ചെയ്യുക.\n",
    "1. ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ ലഭിക്കാൻ പരിശീലന ജോബ് നടത്തുക.\n",
    "1. ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ വിലയിരുത്തി ഗുണമേന്മയ്ക്ക് ആവർത്തിക്കുക.\n",
    "1. തൃപ്തികരമായാൽ ഇൻഫറൻസിനായി ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ വിന്യസിക്കുക.\n",
    "\n",
    "എല്ലാ ഫൗണ്ടേഷൻ മോഡലുകളും ഫൈൻ-ട്യൂണിംഗ് പിന്തുണയ്ക്കുന്നില്ലെന്ന് ശ്രദ്ധിക്കുക - ഏറ്റവും പുതിയ വിവരങ്ങൾക്ക് [ഓപ്പൺഎഐ ഡോക്യുമെന്റേഷൻ](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) പരിശോധിക്കുക. മുമ്പ് ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡലും വീണ്ടും ഫൈൻ-ട്യൂൺ ചെയ്യാം. ഈ ട്യൂട്ടോറിയലിൽ, ഫൈൻ-ട്യൂണിംഗിനായി ഞങ്ങൾ `gpt-35-turbo` എന്ന ലക്ഷ്യമിട്ട ഫൗണ്ടേഷൻ മോഡൽ ഉപയോഗിക്കും.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഘട്ടം 1.1: നിങ്ങളുടെ ഡാറ്റാസെറ്റ് തയ്യാറാക്കുക\n",
    "\n",
    "ഒരു ഘടകത്തെക്കുറിച്ചുള്ള ചോദ്യങ്ങൾക്ക് ലിമെറിക്ക് ഉപയോഗിച്ച് മറുപടി നൽകിക്കൊണ്ട് ഘടകങ്ങളുടെ പീരിയഡിക് ടേബിൾ നിങ്ങൾക്ക് മനസ്സിലാക്കാൻ സഹായിക്കുന്ന ഒരു ചാറ്റ്ബോട്ട് നിർമ്മിക്കാം. _ഈ_ ലളിതമായ ട്യൂട്ടോറിയലിൽ, ഡാറ്റയുടെ പ്രതീക്ഷിച്ച ഫോർമാറ്റ് കാണിക്കുന്ന ചില സാമ്പിൾ മറുപടികളോടുകൂടി മോഡൽ പരിശീലിപ്പിക്കാൻ ഒരു ഡാറ്റാസെറ്റ് മാത്രമേ സൃഷ്ടിക്കൂ. യഥാർത്ഥ ലോക ഉപയോഗത്തിൽ, നിങ്ങൾക്ക് വളരെ കൂടുതൽ ഉദാഹരണങ്ങളുള്ള ഒരു ഡാറ്റാസെറ്റ് സൃഷ്ടിക്കേണ്ടതുണ്ട്. നിങ്ങളുടെ അപേക്ഷാ മേഖലയ്ക്ക് അനുയോജ്യമായ ഒരു തുറന്ന ഡാറ്റാസെറ്റ് (open dataset) ഉണ്ടെങ്കിൽ അത് ഉപയോഗിച്ച് ഫൈൻ-ട്യൂണിംഗിനായി പുനഃരൂപീകരിക്കാനും കഴിയും.\n",
    "\n",
    "നാം `gpt-35-turbo`-യെ കേന്ദ്രീകരിച്ച് ഒറ്റ-ടേൺ മറുപടി (ചാറ്റ് പൂർത്തീകരണം) അന്വേഷിക്കുന്നതിനാൽ, OpenAI ചാറ്റ് പൂർത്തീകരണ ആവശ്യകതകൾ പ്രതിഫലിപ്പിക്കുന്ന [ഈ നിർദ്ദേശിച്ച ഫോർമാറ്റ്](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) ഉപയോഗിച്ച് ഉദാഹരണങ്ങൾ സൃഷ്ടിക്കാം. നിങ്ങൾക്ക് ബഹു-ടേൺ സംഭാഷണ ഉള്ളടക്കം പ്രതീക്ഷിക്കുന്നുവെങ്കിൽ, ഫൈൻ-ട്യൂണിംഗ് പ്രക്രിയയിൽ ഏത് സന്ദേശങ്ങൾ ഉപയോഗിക്കണമെന്ന് (അല്ലെങ്കിൽ ഉപയോഗിക്കരുതെന്ന്) സൂചിപ്പിക്കുന്ന `weight` പാരാമീറ്റർ ഉൾക്കൊള്ളുന്ന [ബഹു-ടേൺ ഉദാഹരണ ഫോർമാറ്റ്](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) ഉപയോഗിക്കേണ്ടതാണ്.\n",
    "\n",
    "നമ്മുടെ ട്യൂട്ടോറിയലിനായി ഇവിടെ ലളിതമായ ഒറ്റ-ടേൺ ഫോർമാറ്റ് ഉപയോഗിക്കാം. ഡാറ്റ [jsonl ഫോർമാറ്റിലാണ്](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst), ഓരോ വരിയിലും 1 റെക്കോർഡ്, ഓരോത് JSON-ഫോർമാറ്റിലുള്ള ഒബ്ജക്റ്റായി പ്രതിനിധീകരിച്ചിരിക്കുന്നു. താഴെയുള്ള സ്നിപ്പെറ്റ് 2 റെക്കോർഡുകൾ സാമ്പിളായി കാണിക്കുന്നു - മുഴുവൻ സാമ്പിൾ സെറ്റ് (10 ഉദാഹരണങ്ങൾ) കാണാൻ [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) കാണുക, ഇത് നാം ഫൈൻ-ട്യൂണിംഗ് ട്യൂട്ടോറിയലിനായി ഉപയോഗിക്കും. **കുറിപ്പ്:** ഓരോ റെക്കോർഡും _ഒറ്റ വരിയിലായിരിക്കണം_ (ഫോർമാറ്റ് ചെയ്ത JSON ഫയലിൽ സാധാരണയായി വരികളായി വിഭജിക്കാറുള്ളതുപോലെ അല്ല).\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "യഥാർത്ഥ ലോക ഉപയോഗത്തിൽ നല്ല ഫലങ്ങൾക്കായി വളരെ വലിയ ഉദാഹരണങ്ങൾ ഉള്ള സെറ്റ് ആവശ്യമാണ് - മറുപടികളുടെ ഗുണനിലവാരവും ഫൈൻ-ട്യൂണിംഗിനുള്ള സമയം/ചെലവും തമ്മിലുള്ള തർക്കമാണ് ഇത്. പ്രക്രിയ വിശദീകരിക്കാൻ നാം ചെറിയ സെറ്റ് ഉപയോഗിച്ച് ഫൈൻ-ട്യൂണിംഗ് വേഗത്തിൽ പൂർത്തിയാക്കാൻ ശ്രമിക്കുന്നു. കൂടുതൽ സങ്കീർണ്ണമായ ഫൈൻ-ട്യൂണിംഗ് ട്യൂട്ടോറിയലിനായി [ഈ OpenAI കുക്ക്ബുക്ക് ഉദാഹരണം](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) കാണുക.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ഘട്ടം 1.2 നിങ്ങളുടെ ഡാറ്റാസെറ്റ് അപ്‌ലോഡ് ചെയ്യുക\n",
    "\n",
    "ഫയൽസ് API ഉപയോഗിച്ച് ഡാറ്റ അപ്‌ലോഡ് ചെയ്യുക [ഇവിടെ വിവരിച്ചിരിക്കുന്നതുപോലെ](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). ഈ കോഡ് പ്രവർത്തിപ്പിക്കാൻ, നിങ്ങൾക്ക് താഴെ പറയുന്ന ഘട്ടങ്ങൾ ആദ്യം പൂർത്തിയാക്കിയിരിക്കണം:\n",
    " - `openai` പൈത്തൺ പാക്കേജ് ഇൻസ്റ്റാൾ ചെയ്തിരിക്കണം (പുതിയ ഫീച്ചറുകൾക്കായി >=0.28.0 വേർഷൻ ഉപയോഗിക്കുന്നതായിരിക്കണം)\n",
    " - `OPENAI_API_KEY` എൻവയോൺമെന്റ് വേരിയബിൾ നിങ്ങളുടെ OpenAI API കീ ആയി സജ്ജമാക്കിയിരിക്കണം\n",
    "കൂടുതൽ അറിയാൻ, കോഴ്സിനായി നൽകിയ [സജ്ജീകരണ ഗൈഡ്](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) കാണുക.\n",
    "\n",
    "ഇപ്പോൾ, നിങ്ങളുടെ ലോക്കൽ JSONL ഫയലിൽ നിന്ന് അപ്‌ലോഡിനായി ഒരു ഫയൽ സൃഷ്ടിക്കാൻ കോഡ് പ്രവർത്തിപ്പിക്കുക.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ഘട്ടം 2.1: SDK ഉപയോഗിച്ച് ഫൈൻ-ട്യൂണിംഗ് ജോബ് സൃഷ്ടിക്കുക\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ഘട്ടം 2.2: ജോബിന്റെ നില പരിശോധിക്കുക\n",
    "\n",
    "`client.fine_tuning.jobs` API ഉപയോഗിച്ച് നിങ്ങൾ ചെയ്യാൻ കഴിയുന്ന ചില കാര്യങ്ങൾ ഇവയാണ്:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - അവസാന n ഫൈൻ-ട്യൂണിംഗ് ജോലികൾ പട്ടികപ്പെടുത്തുക\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - ഒരു പ്രത്യേക ഫൈൻ-ട്യൂണിംഗ് ജോബിന്റെ വിശദാംശങ്ങൾ നേടുക\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - ഒരു ഫൈൻ-ട്യൂണിംഗ് ജോബ് റദ്ദാക്കുക\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - ജോലിയിൽ നിന്നുള്ള n വരെ ഇവന്റുകൾ പട്ടികപ്പെടുത്തുക\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "പ്രക്രിയയുടെ ആദ്യ ഘട്ടം _ട്രെയിനിംഗ് ഫയൽ സാധുവാണെന്ന് പരിശോധിക്കുക_ എന്നതാണ്, ഡാറ്റ ശരിയായ ഫോർമാറ്റിൽ ഉണ്ടെന്ന് ഉറപ്പാക്കാൻ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ഘട്ടം 2.3: പുരോഗതി നിരീക്ഷിക്കാൻ ഇവന്റുകൾ ട്രാക്ക് ചെയ്യുക\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ഘട്ടം 2.4: OpenAI ഡാഷ്ബോർഡിൽ നില കാണുക\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "നിങ്ങൾ OpenAI വെബ്സൈറ്റ് സന്ദർശിച്ച് പ്ലാറ്റ്ഫോമിന്റെ _Fine-tuning_ വിഭാഗം പരിശോധിച്ച് സ്റ്റാറ്റസ് കാണാനും കഴിയും. ഇത് നിലവിലെ ജോബിന്റെ സ്റ്റാറ്റസ് കാണിക്കും, കൂടാതെ മുൻ ജോബ് എക്സിക്യൂഷൻ റൺസിന്റെ ചരിത്രം ട്രാക്ക് ചെയ്യാനും അനുവദിക്കും. ഈ സ്ക്രീൻഷോട്ടിൽ, മുൻ എക്സിക്യൂഷൻ പരാജയപ്പെട്ടതും രണ്ടാം റൺ വിജയിച്ചതും നിങ്ങൾക്ക് കാണാം. പശ്ചാത്തലത്തിന്, ഇത് ആദ്യ റൺ തെറ്റായി ഫോർമാറ്റ് ചെയ്ത JSON ഫയൽ ഉപയോഗിച്ചപ്പോൾ സംഭവിച്ചു - ശരിയാക്കിയ ശേഷം, രണ്ടാം റൺ വിജയകരമായി പൂർത്തിയാക്കി മോഡൽ ഉപയോഗത്തിനായി ലഭ്യമാക്കി.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba.ml.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "നിങ്ങൾക്ക് താഴേക്ക് സ്‌ക്രോൾ ചെയ്ത് ദൃശ്യ ഡാഷ്ബോർഡിൽ സ്റ്റാറ്റസ് സന്ദേശങ്ങളും മെട്രിക്കുകളും കാണാനാകും, താഴെ കാണിച്ചിരിക്കുന്നതുപോലെ:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b.ml.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a65229.ml.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ഘട്ടം 3.1: ഐഡി വീണ്ടെടുക്കുക & കോഡിൽ ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ പരീക്ഷിക്കുക\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### ഘട്ടം 3.2: ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ പ്ലേഗ്രൗണ്ടിൽ ലോഡ് ചെയ്ത് പരീക്ഷിക്കുക\n",
    "\n",
    "ഇപ്പോൾ നിങ്ങൾക്ക് ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ രണ്ട് രീതികളിൽ പരീക്ഷിക്കാം. ആദ്യം, നിങ്ങൾക്ക് പ്ലേഗ്രൗണ്ടിൽ പോയി മോഡലുകൾ ഡ്രോപ്പ്-ഡൗൺ ഉപയോഗിച്ച് നിങ്ങളുടെ പുതിയ ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ ഓപ്ഷനുകളിൽ നിന്ന് തിരഞ്ഞെടുക്കാം. മറ്റൊരു ഓപ്ഷൻ ഫൈൻ-ട്യൂണിംഗ് പാനലിൽ കാണുന്ന \"Playground\" ഓപ്ഷൻ ഉപയോഗിക്കുകയാണ് (മുകളിൽ സ്ക്രീൻഷോട്ട് കാണുക) ഇത് താഴെ കാണുന്ന _തുലനാത്മക_ കാഴ്ച തുറക്കും, ഇത് ഫൗണ്ടേഷൻ മോഡലും ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡലും പക്കൽ-പക്കൽ വച്ച് വേഗത്തിൽ വിലയിരുത്താൻ സഹായിക്കുന്നു.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016.ml.png)\n",
    "\n",
    "നിങ്ങളുടെ പരിശീലന ഡാറ്റയിൽ ഉപയോഗിച്ച സിസ്റ്റം കോൺടെക്സ്റ്റ് പൂരിപ്പിച്ച് നിങ്ങളുടെ പരീക്ഷണ ചോദ്യവും നൽകുക. ഇരുവശവും സമാനമായ കോൺടെക്സ്റ്റും ചോദ്യവും അപ്ഡേറ്റ് ചെയ്യപ്പെടുന്നത് നിങ്ങൾ ശ്രദ്ധിക്കും. താരതമ്യം നടത്തുക, അവയുടെ ഔട്ട്പുട്ടുകളിൽ ഉള്ള വ്യത്യാസം നിങ്ങൾ കാണും. _ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ നിങ്ങൾ നൽകിയ ഉദാഹരണങ്ങളിൽ നൽകിയ ഫോർമാറ്റിൽ പ്രതികരണം നൽകുന്നത് എങ്ങനെ കാണാം, അതേസമയം ഫൗണ്ടേഷൻ മോഡൽ സിസ്റ്റം പ്രോംപ്റ്റ് അനുസരിച്ച് മാത്രമേ പ്രവർത്തിക്കൂ എന്നതും ശ്രദ്ധിക്കുക_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350.ml.png)\n",
    "\n",
    "താരതമ്യത്തിൽ ഓരോ മോഡലിനും ടോക്കൺ എണ്ണവും ഇൻഫറൻസ് നടത്താൻ എടുത്ത സമയവും കാണിക്കുന്നതും നിങ്ങൾ ശ്രദ്ധിക്കും. **ഈ പ്രത്യേക ഉദാഹരണം പ്രക്രിയ കാണിക്കാൻ മാത്രമുള്ള ലളിതമായതാണ്, യഥാർത്ഥ ലോക ഡാറ്റാസെറ്റ് അല്ലെങ്കിൽ സാഹചര്യത്തെ പ്രതിഫലിപ്പിക്കുന്നതല്ല**. ഇരുവശവും സമാനമായ ടോക്കൺ എണ്ണം കാണിക്കും (സിസ്റ്റം കോൺടെക്സ്റ്റും ഉപയോക്തൃ പ്രോംപ്റ്റും സമാനമാണ്) എന്നാൽ ഫൈൻ-ട്യൂൺ ചെയ്ത മോഡൽ ഇൻഫറൻസിന് കൂടുതൽ സമയം എടുക്കും (കസ്റ്റം മോഡൽ).\n",
    "\n",
    "യഥാർത്ഥ ലോക സാഹചര്യങ്ങളിൽ, നിങ്ങൾ ഇത്തരമൊരു ലളിതമായ ഉദാഹരണം ഉപയോഗിക്കുകയില്ല, പക്ഷേ യഥാർത്ഥ ഡാറ്റ (ഉദാ: ഉപഭോക്തൃ സേവനത്തിനുള്ള ഉൽപ്പന്ന കാറ്റലോഗ്) അടിസ്ഥാനമാക്കി ഫൈൻ-ട്യൂണിംഗ് ചെയ്യും, അവിടെ പ്രതികരണത്തിന്റെ ഗുണമേന്മ കൂടുതൽ വ്യക്തമായിരിക്കും. _അത്തരം സാഹചര്യത്തിൽ, ഫൗണ്ടേഷൻ മോഡലിൽ സമാനമായ പ്രതികരണ ഗുണമേന്മ നേടാൻ കൂടുതൽ കസ്റ്റം പ്രോംപ്റ്റ് എഞ്ചിനീയറിംഗ് ആവശ്യമായിരിക്കും, ഇത് ടോക്കൺ ഉപയോഗവും ഇൻഫറൻസ് പ്രോസസ്സിംഗ് സമയവും വർദ്ധിപ്പിക്കും_. _ഇത് പരീക്ഷിക്കാൻ, OpenAI കുക്ക്ബുക്കിലെ ഫൈൻ-ട്യൂണിംഗ് ഉദാഹരണങ്ങൾ പരിശോധിക്കുക_.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**അസൂയാപത്രം**:  \nഈ രേഖ AI വിവർത്തന സേവനം [Co-op Translator](https://github.com/Azure/co-op-translator) ഉപയോഗിച്ച് വിവർത്തനം ചെയ്തതാണ്. നാം കൃത്യതയ്ക്ക് ശ്രമിച്ചിട്ടുണ്ടെങ്കിലും, യന്ത്രം ചെയ്ത വിവർത്തനങ്ങളിൽ പിശകുകൾ അല്ലെങ്കിൽ തെറ്റുകൾ ഉണ്ടാകാമെന്ന് ദയവായി ശ്രദ്ധിക്കുക. അതിന്റെ മാതൃഭാഷയിലുള്ള യഥാർത്ഥ രേഖ അധികാരപരമായ ഉറവിടമായി കണക്കാക്കപ്പെടണം. നിർണായകമായ വിവരങ്ങൾക്ക്, പ്രൊഫഷണൽ മനുഷ്യ വിവർത്തനം ശുപാർശ ചെയ്യപ്പെടുന്നു. ഈ വിവർത്തനം ഉപയോഗിക്കുന്നതിൽ നിന്നുണ്ടാകുന്ന ഏതെങ്കിലും തെറ്റിദ്ധാരണകൾക്കോ തെറ്റായ വ്യാഖ്യാനങ്ങൾക്കോ ഞങ്ങൾ ഉത്തരവാദികളല്ല.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T21:33:28+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "ml"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}