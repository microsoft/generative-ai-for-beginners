{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Kapitel 7: Bygga chattapplikationer\n",
    "## OpenAI API Snabbstart\n",
    "\n",
    "Denna notebook är anpassad från [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) som innehåller notebooks som använder [Azure OpenAI](notebook-azure-openai.ipynb)-tjänster.\n",
    "\n",
    "Python OpenAI API fungerar även med Azure OpenAI-modeller, med några få justeringar. Läs mer om skillnaderna här: [Hur du växlar mellan OpenAI och Azure OpenAI endpoints med Python](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Översikt  \n",
    "\"Stora språkmodeller är funktioner som omvandlar text till text. Givet en inmatad textsträng försöker en stor språkmodell förutsäga vilken text som kommer härnäst\"(1). Denna \"snabbstartsguide\" kommer att introducera användare till grundläggande LLM-koncept, centrala paketkrav för att komma igång med AML, en mjuk introduktion till promptdesign samt flera korta exempel på olika användningsområden.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Innehållsförteckning  \n",
    "\n",
    "[Översikt](../../../../07-building-chat-applications/python)  \n",
    "[Hur du använder OpenAI-tjänsten](../../../../07-building-chat-applications/python)  \n",
    "[1. Skapa din OpenAI-tjänst](../../../../07-building-chat-applications/python)  \n",
    "[2. Installation](../../../../07-building-chat-applications/python)    \n",
    "[3. Autentiseringsuppgifter](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Användningsområden](../../../../07-building-chat-applications/python)    \n",
    "[1. Sammanfatta text](../../../../07-building-chat-applications/python)  \n",
    "[2. Klassificera text](../../../../07-building-chat-applications/python)  \n",
    "[3. Generera nya produktnamn](../../../../07-building-chat-applications/python)  \n",
    "[4. Finjustera en klassificerare](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Referenser](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Skapa din första prompt  \n",
    "Den här korta övningen ger en grundläggande introduktion till hur du skickar prompts till en OpenAI-modell för en enkel uppgift: \"sammanfattning\".\n",
    "\n",
    "\n",
    "**Steg**:  \n",
    "1. Installera OpenAI-biblioteket i din python-miljö  \n",
    "2. Ladda in vanliga hjälpbibliotek och ange dina vanliga OpenAI-säkerhetsuppgifter för den OpenAI-tjänst du har skapat  \n",
    "3. Välj en modell för din uppgift  \n",
    "4. Skapa en enkel prompt till modellen  \n",
    "5. Skicka din förfrågan till modellens API!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Installera OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Hitta rätt modell  \n",
    "GPT-3.5-turbo eller GPT-4-modellerna kan förstå och generera naturligt språk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Utformning av promptar  \n",
    "\n",
    "\"Magin med stora språkmodeller är att de, genom att tränas på att minimera detta prediktionsfel över enorma mängder text, till slut lär sig begrepp som är användbara för dessa förutsägelser. Till exempel lär de sig begrepp som\"(1):\n",
    "\n",
    "* hur man stavar\n",
    "* hur grammatik fungerar\n",
    "* hur man omformulerar\n",
    "* hur man besvarar frågor\n",
    "* hur man för en konversation\n",
    "* hur man skriver på många språk\n",
    "* hur man programmerar\n",
    "* osv.\n",
    "\n",
    "#### Hur man styr en stor språkmodell  \n",
    "\"Av alla indata till en stor språkmodell är textprompten utan tvekan den mest inflytelserika(1).\n",
    "\n",
    "Stora språkmodeller kan uppmanas att generera utdata på några olika sätt:\n",
    "\n",
    "Instruktion: Tala om för modellen vad du vill ha\n",
    "Komplettering: Få modellen att slutföra början på det du vill ha\n",
    "Demonstration: Visa modellen vad du vill ha, antingen med:\n",
    "Några exempel i prompten\n",
    "Många hundra eller tusentals exempel i en finjusterings-datamängd\"\n",
    "\n",
    "\n",
    "\n",
    "#### Det finns tre grundläggande riktlinjer för att skapa promptar:\n",
    "\n",
    "**Visa och berätta**. Gör det tydligt vad du vill ha, antingen genom instruktioner, exempel eller en kombination av båda. Om du vill att modellen ska rangordna en lista med objekt i alfabetisk ordning eller klassificera ett stycke efter känsla, visa att det är det du vill ha.\n",
    "\n",
    "**Ge kvalitetsdata**. Om du försöker bygga en klassificerare eller få modellen att följa ett mönster, se till att det finns tillräckligt med exempel. Korrekturläs dina exempel — modellen är oftast tillräckligt smart för att se igenom enkla stavfel och ge dig ett svar, men den kan också anta att det är avsiktligt och det kan påverka svaret.\n",
    "\n",
    "**Kontrollera dina inställningar.** Temperatur- och top_p-inställningarna styr hur deterministisk modellen är när den genererar ett svar. Om du ber om ett svar där det bara finns ett rätt svar, vill du sätta dessa lägre. Om du vill ha mer varierade svar kan du sätta dem högre. Det vanligaste misstaget folk gör med dessa inställningar är att tro att de styr \"smarthet\" eller \"kreativitet\".\n",
    "\n",
    "\n",
    "Källa: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sammanfatta text  \n",
    "#### Utmaning  \n",
    "Sammanfatta text genom att lägga till ett 'tl;dr:' i slutet av en textpassage. Lägg märke till hur modellen förstår att utföra flera uppgifter utan extra instruktioner. Du kan experimentera med mer beskrivande uppmaningar än tl;dr för att ändra modellens beteende och anpassa den sammanfattning du får(3).  \n",
    "\n",
    "Nyligen har forskning visat betydande framsteg inom många NLP-uppgifter och benchmarktester genom att förträna på en stor textkorpus och sedan finjustera på en specifik uppgift. Även om denna metod vanligtvis är uppgiftsoberoende i sin arkitektur, kräver den ändå uppgiftsspecifika finjusteringsdatamängder med tusentals eller tiotusentals exempel. Människor kan däremot oftast utföra en ny språkuppgift med bara några få exempel eller enkla instruktioner – något som nuvarande NLP-system fortfarande har svårt med. Här visar vi att större språkmodeller kraftigt förbättrar uppgiftsoberoende, få-exempel-prestanda, ibland till och med i nivå med tidigare toppmoderna finjusteringsmetoder.  \n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Övningar för flera användningsområden  \n",
    "1. Sammanfatta text  \n",
    "2. Kategorisera text  \n",
    "3. Skapa nya produktnamn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klassificera text  \n",
    "#### Utmaning  \n",
    "Klassificera objekt i kategorier som anges vid inferenstillfället. I följande exempel anger vi både kategorierna och texten som ska klassificeras i prompten (*playground_reference).\n",
    "\n",
    "Kundförfrågan: Hej, en av tangenterna på mitt laptop-tangentbord gick sönder nyligen och jag behöver en ersättning:\n",
    "\n",
    "Klassificerad kategori:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Skapa nya produktnamn\n",
    "#### Utmaning\n",
    "Skapa produktnamn utifrån exempelord. Här inkluderar vi information om produkten vi ska generera namn för i prompten. Vi ger också ett liknande exempel för att visa det mönster vi vill ha. Vi har dessutom ställt in temperaturvärdet högt för att öka slumpmässigheten och få mer innovativa svar.\n",
    "\n",
    "Produktbeskrivning: En milkshakemaskin för hemmet  \n",
    "Fröord: snabb, hälsosam, kompakt.  \n",
    "Produktnamn: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Produktbeskrivning: Ett par skor som passar alla fotstorlekar.  \n",
    "Fröord: anpassningsbar, passform, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Referenser  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Exempel](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Bästa praxis för finjustering av GPT-3 för att klassificera text](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# För mer hjälp  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bidragsgivare\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfriskrivning**:  \nDetta dokument har översatts med hjälp av AI-översättningstjänsten [Co-op Translator](https://github.com/Azure/co-op-translator). Vi strävar efter noggrannhet, men var medveten om att automatiska översättningar kan innehålla fel eller brister. Det ursprungliga dokumentet på dess originalspråk ska betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell mänsklig översättning. Vi tar inget ansvar för eventuella missförstånd eller feltolkningar som uppstår vid användning av denna översättning.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:18:28+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "sv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}