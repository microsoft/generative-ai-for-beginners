<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T15:40:01+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "sv"
}
-->
# Grunderna i Prompt Engineering

## Introduktion
Detta modul t√§cker viktiga koncept och tekniker f√∂r att skapa effektiva prompts i generativa AI-modeller. Hur du skriver din prompt till en LLM spelar ocks√• roll. En noggrant utformad prompt kan ge en b√§ttre svarskvalitet. Men vad betyder egentligen termer som _prompt_ och _prompt engineering_? Och hur f√∂rb√§ttrar jag promptens _inmatning_ som jag skickar till LLM? Dessa √§r de fr√•gor vi kommer att f√∂rs√∂ka besvara i detta kapitel och det n√§sta.

_Generativ AI_ kan skapa nytt inneh√•ll (t.ex. text, bilder, ljud, kod etc.) som svar p√• anv√§ndarf√∂rfr√•gningar. Den uppn√•r detta genom _Large Language Models_ som OpenAI:s GPT ("Generative Pre-trained Transformer")-serie som √§r tr√§nade f√∂r att anv√§nda naturligt spr√•k och kod.

Anv√§ndare kan nu interagera med dessa modeller genom bekanta paradigmer som chatt, utan att beh√∂va teknisk expertis eller utbildning. Modellerna √§r _prompt-baserade_ - anv√§ndare skickar en textinmatning (prompt) och f√•r tillbaka AI-svaret (komplettering). De kan sedan "chatta med AI" iterativt, i fleromg√•ngskonversationer, och f√∂rfina sin prompt tills svaret matchar deras f√∂rv√§ntningar.

"Prompts" blir nu det prim√§ra _programmeringsgr√§nssnittet_ f√∂r generativa AI-appar, som ber√§ttar f√∂r modellerna vad de ska g√∂ra och p√•verkar kvaliteten p√• de returnerade svaren. "Prompt Engineering" √§r ett snabbt v√§xande studieomr√•de som fokuserar p√• _design och optimering_ av prompts f√∂r att leverera konsekventa och kvalitativa svar i stor skala.

## L√§randem√•l

I denna lektion l√§r vi oss vad Prompt Engineering √§r, varf√∂r det √§r viktigt och hur vi kan skapa mer effektiva prompts f√∂r en given modell och applikationsm√•l. Vi kommer att f√∂rst√• k√§rnkoncept och b√§sta praxis f√∂r prompt engineering - och l√§ra oss om en interaktiv Jupyter Notebooks "sandbox"-milj√∂ d√§r vi kan se dessa koncept till√§mpade p√• verkliga exempel.

I slutet av denna lektion kommer vi att kunna:

1. F√∂rklara vad prompt engineering √§r och varf√∂r det √§r viktigt.
2. Beskriva komponenterna i en prompt och hur de anv√§nds.
3. L√§ra oss b√§sta praxis och tekniker f√∂r prompt engineering.
4. Till√§mpa inl√§rda tekniker p√• verkliga exempel, med hj√§lp av en OpenAI-endpoint.

## Nyckeltermer

Prompt Engineering: Praktiken att designa och f√∂rfina inmatningar f√∂r att styra AI-modeller mot att producera √∂nskade utg√•ngar.
Tokenisering: Processen att konvertera text till mindre enheter, kallade tokens, som en modell kan f√∂rst√• och bearbeta.
Instruktionsanpassade LLMs: Stora spr√•kmodeller (LLMs) som har finjusterats med specifika instruktioner f√∂r att f√∂rb√§ttra deras svarsnoggrannhet och relevans.

## L√§randesandbox

Prompt engineering √§r f√∂r n√§rvarande mer konst √§n vetenskap. Det b√§sta s√§ttet att f√∂rb√§ttra v√•r intuition f√∂r det √§r att _√∂va mer_ och anta en trial-and-error-ansats som kombinerar expertis inom applikationsdom√§nen med rekommenderade tekniker och modellspecifika optimeringar.

Jupyter Notebook som f√∂ljer med denna lektion ger en _sandbox_-milj√∂ d√§r du kan prova vad du l√§r dig - medan du g√•r eller som en del av kodutmaningen i slutet. F√∂r att utf√∂ra √∂vningarna beh√∂ver du:

1. **En Azure OpenAI API-nyckel** - tj√§nstens slutpunkt f√∂r en distribuerad LLM.
2. **En Python Runtime** - d√§r Notebook kan k√∂ras.
3. **Lokala milj√∂variabler** - _slutf√∂r [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) stegen nu f√∂r att f√∂rbereda dig_.

Noteboken kommer med _start_-√∂vningar - men du uppmuntras att l√§gga till dina egna _Markdown_ (beskrivning) och _Code_ (promptf√∂rfr√•gningar) sektioner f√∂r att prova fler exempel eller id√©er - och bygga din intuition f√∂r promptdesign.

## Illustrerad Guide

Vill du f√• en helhetsbild av vad denna lektion t√§cker innan du dyker in? Kolla in denna illustrerade guide, som ger dig en k√§nsla av de huvudsakliga √§mnena som t√§cks och de viktigaste insikterna f√∂r dig att t√§nka p√• i varje avsnitt. Lektionens v√§gkarta tar dig fr√•n att f√∂rst√• k√§rnkoncepten och utmaningarna till att adressera dem med relevanta prompt engineering-tekniker och b√§sta praxis. Observera att avsnittet "Avancerade tekniker" i denna guide h√§nvisar till inneh√•ll som t√§cks i _n√§sta_ kapitel av denna l√§roplan.

## V√•rt Startup

L√•t oss nu prata om hur _detta √§mne_ relaterar till v√•rt startup-uppdrag att [f√∂ra AI-innovation till utbildning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi vill bygga AI-drivna applikationer f√∂r _personlig inl√§rning_ - s√• l√•t oss t√§nka p√• hur olika anv√§ndare av v√•r applikation kan "designa" prompts:

- **Administrat√∂rer** kan be AI att _analysera l√§roplansdata f√∂r att identifiera luckor i t√§ckningen_. AI kan sammanfatta resultat eller visualisera dem med kod.
- **L√§rare** kan be AI att _generera en lektionsplan f√∂r en m√•lgrupp och √§mne_. AI kan bygga den personliga planen i ett specificerat format.
- **Studenter** kan be AI att _handleda dem i ett sv√•rt √§mne_. AI kan nu guida studenter med lektioner, ledtr√•dar och exempel anpassade till deras niv√•.

Det √§r bara toppen av isberget. Kolla in [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - ett √∂ppen k√§llkod-promptsbibliotek kuraterat av utbildningsexperter - f√∂r att f√• en bredare k√§nsla av m√∂jligheterna! _F√∂rs√∂k att k√∂ra n√•gra av dessa prompts i sandboxen eller anv√§nd OpenAI Playground f√∂r att se vad som h√§nder!_

## Vad √§r Prompt Engineering?

Vi b√∂rjade denna lektion med att definiera **Prompt Engineering** som processen att _designa och optimera_ textinmatningar (prompts) f√∂r att leverera konsekventa och kvalitativa svar (kompletteringar) f√∂r ett givet applikationsm√•l och modell. Vi kan t√§nka p√• detta som en 2-stegsprocess:

- _designa_ den initiala prompten f√∂r en given modell och m√•l
- _f√∂rfina_ prompten iterativt f√∂r att f√∂rb√§ttra kvaliteten p√• svaret

Detta √§r n√∂dv√§ndigtvis en trial-and-error-process som kr√§ver anv√§ndarens intuition och anstr√§ngning f√∂r att f√• optimala resultat. S√• varf√∂r √§r det viktigt? F√∂r att svara p√• den fr√•gan beh√∂ver vi f√∂rst f√∂rst√• tre koncept:

- _Tokenisering_ = hur modellen "ser" prompten
- _Bas LLMs_ = hur grundmodellen "bearbetar" en prompt
- _Instruktionsanpassade LLMs_ = hur modellen nu kan se "uppgifter"

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ d√§r olika modeller (eller versioner av en modell) kan tokenisera samma prompt p√• olika s√§tt. Eftersom LLMs √§r tr√§nade p√• tokens (och inte p√• r√•text), har s√§ttet som prompts tokeniseras en direkt p√•verkan p√• kvaliteten p√• det genererade svaret.

F√∂r att f√• en intuition f√∂r hur tokenisering fungerar, prova verktyg som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) som visas nedan. Kopiera in din prompt - och se hur den omvandlas till tokens, och notera hur blanksteg och skiljetecken hanteras. Observera att detta exempel visar en √§ldre LLM (GPT-3) - s√• att prova detta med en nyare modell kan ge ett annat resultat.

### Koncept: Grundmodeller

N√§r en prompt √§r tokeniserad √§r huvudfunktionen f√∂r ["Bas LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller Grundmodell) att f√∂ruts√§ga token i den sekvensen. Eftersom LLMs √§r tr√§nade p√• massiva textdatam√§ngder, har de en god k√§nsla f√∂r de statistiska relationerna mellan tokens och kan g√∂ra den f√∂ruts√§gelsen med viss s√§kerhet. Observera att de inte f√∂rst√•r _meningen_ med orden i prompten eller token; de ser bara ett m√∂nster de kan "komplettera" med sin n√§sta f√∂ruts√§gelse. De kan forts√§tta f√∂ruts√§ga sekvensen tills den avslutas av anv√§ndarens ingripande eller n√•gon f√∂rutbest√§md villkor.

Vill du se hur prompt-baserad komplettering fungerar? Skriv in ovanst√•ende prompt i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinst√§llningarna. Systemet √§r konfigurerat f√∂r att behandla prompts som f√∂rfr√•gningar om information - s√• du b√∂r se en komplettering som uppfyller detta sammanhang.

Men vad h√§nder om anv√§ndaren ville se n√•got specifikt som uppfyllde n√•gra kriterier eller uppgiftsm√•l? Det √§r h√§r _instruktionsanpassade_ LLMs kommer in i bilden.

### Koncept: Instruktionsanpassade LLMs

En [Instruktionsanpassad LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) b√∂rjar med grundmodellen och finjusterar den med exempel eller inmatnings-/utg√•ngspar (t.ex. fleromg√•ngs-"meddelanden") som kan inneh√•lla tydliga instruktioner - och svaret fr√•n AI f√∂rs√∂ker f√∂lja den instruktionen.

Detta anv√§nder tekniker som Reinforcement Learning with Human Feedback (RLHF) som kan tr√§na modellen att _f√∂lja instruktioner_ och _l√§ra sig av feedback_ s√• att den producerar svar som √§r b√§ttre l√§mpade f√∂r praktiska till√§mpningar och mer relevanta f√∂r anv√§ndarens m√•l.

L√•t oss prova det - g√• tillbaka till prompten ovan, men √§ndra nu _systemmeddelandet_ f√∂r att ge f√∂ljande instruktion som sammanhang:

> _Sammanfatta inneh√•llet du f√•r f√∂r en andraklassare. H√•ll resultatet till ett stycke med 3-5 punkter._

Ser du hur resultatet nu √§r anpassat f√∂r att √•terspegla det √∂nskade m√•let och formatet? En l√§rare kan nu direkt anv√§nda detta svar i sina bilder f√∂r den klassen.

## Varf√∂r beh√∂ver vi Prompt Engineering?

Nu n√§r vi vet hur prompts bearbetas av LLMs, l√•t oss prata om _varf√∂r_ vi beh√∂ver prompt engineering. Svaret ligger i det faktum att nuvarande LLMs st√§ller ett antal utmaningar som g√∂r _tillf√∂rlitliga och konsekventa kompletteringar_ sv√•rare att uppn√• utan att l√§gga ner anstr√§ngning p√• promptkonstruktion och optimering. Till exempel:

1. **Modellsvar √§r stokastiska.** Samma prompt kommer sannolikt att producera olika svar med olika modeller eller modellversioner. Och det kan till och med producera olika resultat med _samma modell_ vid olika tidpunkter. _Prompt engineering-tekniker kan hj√§lpa oss att minimera dessa variationer genom att tillhandah√•lla b√§ttre skyddsr√§cken_.

2. **Modeller kan fabricera svar.** Modeller √§r f√∂rtr√§nade med _stora men begr√§nsade_ datam√§ngder, vilket inneb√§r att de saknar kunskap om koncept utanf√∂r det tr√§ningsomr√•det. Som ett resultat kan de producera kompletteringar som √§r felaktiga, imagin√§ra eller direkt mots√§gande till k√§nda fakta. _Prompt engineering-tekniker hj√§lper anv√§ndare att identifiera och mildra s√•dana fabrikationer, t.ex. genom att be AI om citat eller resonemang_.

3. **Modellers kapabiliteter varierar.** Nyare modeller eller modellgenerationer kommer att ha rikare kapabiliteter men ocks√• medf√∂ra unika egenheter och avv√§gningar i kostnad och komplexitet. _Prompt engineering kan hj√§lpa oss att utveckla b√§sta praxis och arbetsfl√∂den som abstraherar bort skillnader och anpassar sig till modellspecifika krav p√• skalbara, s√∂ml√∂sa s√§tt_.

L√•t oss se detta i aktion i OpenAI eller Azure OpenAI Playground:

- Anv√§nd samma prompt med olika LLM-distributioner (t.ex. OpenAI, Azure OpenAI, Hugging Face) - s√•g du variationerna?
- Anv√§nd samma prompt upprepade g√•nger med _samma_ LLM-distribution (t.ex. Azure OpenAI playground) - hur skiljde sig dessa variationer?

### Exempel p√• fabrikationer

I denna kurs anv√§nder vi termen **"fabrikation"** f√∂r att referera till fenomenet d√§r LLMs ibland genererar faktuellt felaktig information p√• grund av begr√§nsningar i deras tr√§ning eller andra begr√§nsningar. Du kanske ocks√• har h√∂rt detta kallas _"hallucinationer"_ i popul√§ra artiklar eller forskningsrapporter. Men vi rekommenderar starkt att anv√§nda _"fabrikation"_ som termen s√• att vi inte av misstag tillskriver m√§nskliga egenskaper till en maskindriven utg√•ng. Detta f√∂rst√§rker ocks√• [Riktlinjer f√∂r Ansvarsfull AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fr√•n ett terminologiskt perspektiv, och tar bort termer som ocks√• kan betraktas som st√∂tande eller icke-inkluderande i vissa sammanhang.

Vill du f√• en k√§nsla av hur fabrikationer fungerar? T√§nk p√• en prompt som instruerar AI att generera inneh√•ll f√∂r ett icke-existerande √§mne (f√∂r att s√§kerst√§lla att det inte finns i tr√§ningsdatam√§ngden). Till exempel - jag provade denna prompt:

> **Prompt:** generera en lektionsplan om Marskriget 2076.

En webbs√∂kning visade mig att det fanns fiktiva ber√§ttelser (t.ex. tv-serier eller b√∂cker) om Marskrig - men inga √•r 2076. Sunt f√∂rnuft s√§ger ocks√• att 2076 √§r _i framtiden_ och d√§rf√∂r inte kan associeras med en verklig h√§ndelse.

S√• vad h√§nder n√§r vi k√∂r denna prompt med olika LLM-leverant√∂rer?

Som f√∂rv√§ntat producerar varje modell (eller modellversion) n√•got olika svar tack vare stokastiskt beteende och modellkapabilitetsvariationer. Till exempel riktar sig en modell till en √•ttondeklassare medan den andra antar en gymnasieelev. Men alla tre modeller genererade svar som kunde √∂vertyga en oinformerad anv√§ndare om att h√§ndelsen var verklig.

Prompt engineering-tekniker som _metaprompting_ och _temperaturkonfiguration_ kan minska modellers fabrikationer till viss del. Nya prompt engineering-_arkitekturer_ integrerar ocks√• nya verktyg och tekniker s√∂ml√∂st i promptfl√∂det, f√∂r att mildra eller minska n√•gra av dessa effekter.

## Fallstudie: GitHub Copilot

L√•t oss avsluta detta avsnitt genom att f√• en k√§nsla av hur prompt engineering anv√§nds i verkliga l√∂sningar genom att titta p√• en fallstudie: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot √§r din "AI Pair Programmer" - den konverterar textprompts till kodkompletteringar och √§r integrerad i din utvecklingsmilj√∂ (t.ex. Visual Studio Code) f√∂r en s√∂ml√∂s anv√§ndarupplevelse. Som dokumenterat i serien av bloggar nedan, var den tidigaste versionen baserad p√• OpenAI Codex-modellen - med ingenj√∂rer som snabbt ins√•g behovet av att finjustera modellen och utveckla b√§ttre prompt engineering-tekniker, f√∂r att f√∂rb√§ttra kodkvaliteten. I juli [debuterade de en f√∂rb√§ttrad AI-modell som g√•r bortom Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) f√∂r √§nnu snabbare f√∂rslag.

L√§s inl√§ggen i ordning, f√∂r att f√∂lja deras inl√§rningsresa.

Du kan ocks√• bl√§ddra i deras [Engineering blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) f√∂r fler inl√§gg som [detta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som visar hur dessa modeller och tekniker _till√§mpas_ f√∂r att driva verkliga applikationer.

## Promptkonstruktion

Vi har sett varf√∂r prompt engineering √§r viktigt - nu l√•t oss f√∂rst√• hur prompts _konstrueras_ s√• vi kan utv√§rdera olika tekniker f√∂r mer effektiv promptdesign.

### Grundl√§ggande Prompt

L√•t oss b√∂rja med den grundl√§ggande prompten: en textinmatning som skickas till modellen utan n√•gon annan kontext. H√§r √§r ett exempel - n√§r vi skickar de f√∂rsta orden i USA:s nationals√•ng till OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) kompletterar den omedelbart svaret med de n√§sta raderna, vilket illustrerar det grundl√§ggande f√∂ruts√§gbara beteendet.

### Komplex Prompt

Nu l√•t oss l√§gga till kontext och instruktioner till den grundl√§ggande prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to
Det verkliga v√§rdet av mallar ligger i f√∂rm√•gan att skapa och publicera _prompt-bibliotek_ f√∂r vertikala applikationsdom√§ner - d√§r promptmallen nu √§r _optimerad_ f√∂r att √•terspegla applikationsspecifik kontext eller exempel som g√∂r svaren mer relevanta och korrekta f√∂r den avsedda anv√§ndargruppen. Repositoriet [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √§r ett utm√§rkt exempel p√• detta tillv√§gag√•ngss√§tt, d√§r man samlar ett bibliotek av prompts f√∂r utbildningsdom√§nen med fokus p√• nyckelm√•l som lektionsplanering, kursplanedesign, studenthandledning etc.

## St√∂djande inneh√•ll

Om vi t√§nker p√• promptkonstruktion som att ha en instruktion (uppgift) och ett m√•l (prim√§rt inneh√•ll), d√• √§r _sekund√§rt inneh√•ll_ som ytterligare kontext vi tillhandah√•ller f√∂r att **p√•verka resultatet p√• n√•got s√§tt**. Det kan vara justeringsparametrar, formateringsinstruktioner, √§mnestaxonomier etc. som kan hj√§lpa modellen att _anpassa_ sitt svar f√∂r att passa de √∂nskade anv√§ndarm√•len eller f√∂rv√§ntningarna.

Till exempel: Givet en kurskatalog med omfattande metadata (namn, beskrivning, niv√•, metadatataggar, instrukt√∂r etc.) om alla tillg√§ngliga kurser i kursplanen:

- vi kan definiera en instruktion f√∂r att "sammanfatta kurskatalogen f√∂r h√∂sten 2023"
- vi kan anv√§nda det prim√§ra inneh√•llet f√∂r att ge n√•gra exempel p√• det √∂nskade resultatet
- vi kan anv√§nda det sekund√§ra inneh√•llet f√∂r att identifiera de fem fr√§msta "taggarna" av intresse.

Nu kan modellen ge en sammanfattning i det format som visas av de f√• exemplen - men om ett resultat har flera taggar, kan den prioritera de fem taggar som identifierats i det sekund√§ra inneh√•llet.

---

<!--
LEKTIONSMALL:
Denna enhet b√∂r t√§cka k√§rnkoncept #1.
F√∂rst√§rk konceptet med exempel och referenser.

KONCEPT #3:
Prompttekniker.
Vilka √§r n√•gra grundl√§ggande tekniker f√∂r promptteknik?
Illustrera det med n√•gra √∂vningar.
-->

## B√§sta praxis f√∂r prompt

Nu n√§r vi vet hur prompts kan _konstrueras_, kan vi b√∂rja t√§nka p√• hur man _designar_ dem f√∂r att √•terspegla b√§sta praxis. Vi kan t√§nka p√• detta i tv√• delar - att ha r√§tt _mentalitet_ och att till√§mpa r√§tt _tekniker_.

### Mentalitet f√∂r promptteknik

Promptteknik √§r en process av f√∂rs√∂k och misstag, s√• h√•ll tre breda v√§gledande faktorer i √•tanke:

1. **Dom√§nf√∂rst√•else √§r viktigt.** Svarens noggrannhet och relevans √§r en funktion av _dom√§nen_ d√§r applikationen eller anv√§ndaren verkar. Anv√§nd din intuition och dom√§nexpertis f√∂r att **anpassa tekniker** ytterligare. Till exempel, definiera _dom√§nspecifika personligheter_ i dina systemprompts, eller anv√§nd _dom√§nspecifika mallar_ i dina anv√§ndarprompts. Tillhandah√•ll sekund√§rt inneh√•ll som √•terspeglar dom√§nspecifika kontexter, eller anv√§nd _dom√§nspecifika ledtr√•dar och exempel_ f√∂r att v√§gleda modellen mot v√§lbekanta anv√§ndningsm√∂nster.

2. **Modellf√∂rst√•else √§r viktigt.** Vi vet att modeller √§r stokastiska till sin natur. Men modellimplementationer kan ocks√• variera n√§r det g√§ller tr√§ningsdatasetet de anv√§nder (f√∂rtr√§nad kunskap), de funktioner de tillhandah√•ller (t.ex. via API eller SDK) och typen av inneh√•ll de √§r optimerade f√∂r (t.ex. kod vs. bilder vs. text). F√∂rst√• styrkorna och begr√§nsningarna hos den modell du anv√§nder, och anv√§nd den kunskapen f√∂r att _prioritera uppgifter_ eller bygga _anpassade mallar_ som √§r optimerade f√∂r modellens kapabiliteter.

3. **Iteration och validering √§r viktigt.** Modeller utvecklas snabbt, och det g√∂r ocks√• teknikerna f√∂r promptteknik. Som dom√§nexpert kan du ha annan kontext eller kriterier f√∂r _din_ specifika applikation, som kanske inte g√§ller f√∂r den bredare gemenskapen. Anv√§nd verktyg och tekniker f√∂r promptteknik f√∂r att "komma ig√•ng" med promptkonstruktion, iterera sedan och validera resultaten med din egen intuition och dom√§nexpertis. Dokumentera dina insikter och skapa en **kunskapsbas** (t.ex. promptbibliotek) som kan anv√§ndas som en ny utg√•ngspunkt av andra, f√∂r snabbare iterationer i framtiden.

## B√§sta praxis

L√•t oss nu titta p√• vanliga b√§sta praxis som rekommenderas av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) och [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) praktiker.

| Vad                                | Varf√∂r                                                                                                                                                                                                                                               |
| :--------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Utv√§rdera de senaste modellerna.   | Nya modellgenerationer har sannolikt f√∂rb√§ttrade funktioner och kvalitet - men kan ocks√• inneb√§ra h√∂gre kostnader. Utv√§rdera dem f√∂r p√•verkan och fatta sedan migrationsbeslut.                                                                     |
| Separera instruktioner och kontext | Kontrollera om din modell/leverant√∂r definierar _avgr√§nsare_ f√∂r att tydligare skilja instruktioner, prim√§rt och sekund√§rt inneh√•ll. Detta kan hj√§lpa modeller att tilldela vikter mer exakt till tokens.                                              |
| Var specifik och tydlig            | Ge mer detaljer om den √∂nskade kontexten, resultatet, l√§ngden, formatet, stilen etc. Detta kommer att f√∂rb√§ttra b√•de kvaliteten och konsistensen i svaren. F√•nga recept i √•teranv√§ndbara mallar.                                                       |
| Var beskrivande, anv√§nd exempel    | Modeller kan svara b√§ttre p√• ett "visa och ber√§tta"-tillv√§gag√•ngss√§tt. B√∂rja med ett `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an ‚Äúout‚Äù           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` v√§rden. √Öterkom till [Learning Sandbox avsnittet](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) f√∂r att l√§ra dig hur.

### N√§sta steg, √∂ppna Jupyter Notebook

- V√§lj runtime-k√§rnan. Om du anv√§nder alternativ 1 eller 2, v√§lj helt enkelt den f√∂rvalda Python 3.10.x k√§rnan som tillhandah√•lls av utvecklingscontainern.

Du √§r redo att k√∂ra √∂vningarna. Observera att det inte finns n√•gra _r√§tt och fel_ svar h√§r - bara att utforska alternativ genom f√∂rs√∂k och misstag och bygga intuition f√∂r vad som fungerar f√∂r en given modell och applikationsdom√§n.

_Av denna anledning finns det inga Kodl√∂sningssegment i denna lektion. Ist√§llet kommer Notebooken att ha Markdown-celler med titeln "Min l√∂sning:" som visar ett exempel p√• resultat f√∂r referens._

 <!--
LEKTIONSMALL:
Avsluta avsnittet med en sammanfattning och resurser f√∂r sj√§lvstyrt l√§rande.
-->

## Kunskapskontroll

Vilket av f√∂ljande √§r en bra prompt som f√∂ljer n√•gra rimliga b√§sta praxis?

1. Visa mig en bild av en r√∂d bil
2. Visa mig en bild av en r√∂d bil av m√§rket Volvo och modellen XC90 parkerad vid en klippa med solnedg√•ngen
3. Visa mig en bild av en r√∂d bil av m√§rket Volvo och modellen XC90

A: 2, det √§r den b√§sta prompten eftersom den ger detaljer om "vad" och g√•r in p√• specifika detaljer (inte bara vilken bil som helst utan ett specifikt m√§rke och modell) och den beskriver ocks√• den √∂vergripande milj√∂n. 3 √§r n√§sta b√§sta eftersom den ocks√• inneh√•ller mycket beskrivning.

## üöÄ Utmaning

Se om du kan anv√§nda "ledtr√•dstekniken" med prompten: Fyll i meningen "Visa mig en bild av en r√∂d bil av m√§rket Volvo och ". Vad svarar den med, och hur skulle du f√∂rb√§ttra det?

## Bra jobbat! Forts√§tt ditt l√§rande

Vill du l√§ra dig mer om olika koncept inom Prompt Engineering? G√• till [sidan f√∂r fortsatt l√§rande](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att hitta andra bra resurser om detta √§mne.

G√• vidare till Lektion 5 d√§r vi kommer att titta p√• [avancerade promptingtekniker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, var medveten om att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller misstolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.