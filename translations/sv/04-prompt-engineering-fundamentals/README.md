<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-07-09T10:21:45+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "sv"
}
-->
# Grundl√§ggande om Prompt Engineering

[![Prompt Engineering Fundamentals](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.sv.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduktion  
Den h√§r modulen t√§cker viktiga begrepp och tekniker f√∂r att skapa effektiva prompts i generativa AI-modeller. Hur du formulerar din prompt till en LLM spelar ocks√• roll. En noggrant utformad prompt kan ge b√§ttre svarskvalitet. Men vad betyder egentligen termer som _prompt_ och _prompt engineering_? Och hur f√∂rb√§ttrar jag prompt-_inputen_ som jag skickar till LLM? Det √§r de fr√•gor vi ska f√∂rs√∂ka besvara i detta kapitel och n√§sta.

_Generativ AI_ kan skapa nytt inneh√•ll (t.ex. text, bilder, ljud, kod osv.) som svar p√• anv√§ndarf√∂rfr√•gningar. Det g√∂rs med hj√§lp av _Large Language Models_ som OpenAI:s GPT ("Generative Pre-trained Transformer")-serie, som √§r tr√§nade f√∂r att anv√§nda naturligt spr√•k och kod.

Anv√§ndare kan nu interagera med dessa modeller via v√§lbekanta gr√§nssnitt som chatt, utan att beh√∂va teknisk expertis eller utbildning. Modellerna √§r _prompt-baserade_ ‚Äì anv√§ndare skickar in en textinput (prompt) och f√•r tillbaka AI:s svar (completion). De kan sedan "chatta med AI:n" iterativt, i flerstegs-konversationer, och f√∂rfina sin prompt tills svaret motsvarar deras f√∂rv√§ntningar.

"Prompts" blir nu det prim√§ra _programmeringsgr√§nssnittet_ f√∂r generativa AI-appar, som talar om f√∂r modellerna vad de ska g√∂ra och p√•verkar kvaliteten p√• de svar som returneras. "Prompt Engineering" √§r ett snabbt v√§xande forskningsomr√•de som fokuserar p√• _design och optimering_ av prompts f√∂r att leverera konsekventa och kvalitativa svar i stor skala.

## L√§randem√•l

I denna lektion l√§r vi oss vad Prompt Engineering √§r, varf√∂r det √§r viktigt och hur vi kan skapa mer effektiva prompts f√∂r en given modell och applikationsm√•l. Vi kommer att f√∂rst√• k√§rnbegrepp och b√§sta praxis f√∂r prompt engineering ‚Äì och l√§ra oss om en interaktiv Jupyter Notebook-"sandbox" d√§r vi kan se dessa koncept till√§mpas p√• verkliga exempel.

I slutet av lektionen ska vi kunna:

1. F√∂rklara vad prompt engineering √§r och varf√∂r det √§r viktigt.  
2. Beskriva komponenterna i en prompt och hur de anv√§nds.  
3. L√§ra oss b√§sta praxis och tekniker f√∂r prompt engineering.  
4. Till√§mpa inl√§rda tekniker p√• verkliga exempel, med hj√§lp av en OpenAI-endpoint.

## Nyckelbegrepp

Prompt Engineering: Praktiken att designa och f√∂rfina input f√∂r att styra AI-modeller mot att producera √∂nskade resultat.  
Tokenisering: Processen att omvandla text till mindre enheter, kallade tokens, som en modell kan f√∂rst√• och bearbeta.  
Instruction-Tuned LLMs: Stora spr√•kmodeller (LLMs) som finjusterats med specifika instruktioner f√∂r att f√∂rb√§ttra svarens noggrannhet och relevans.

## L√§rande Sandbox

Prompt engineering √§r f√∂r n√§rvarande mer en konst √§n en exakt vetenskap. Det b√§sta s√§ttet att f√∂rb√§ttra v√•r intuition √§r att _√∂vning ger f√§rdighet_ och att anv√§nda en trial-and-error-metod som kombinerar dom√§nkunskap med rekommenderade tekniker och modell-specifika optimeringar.

Jupyter Notebook som f√∂ljer med denna lektion erbjuder en _sandbox_-milj√∂ d√§r du kan prova det du l√§r dig ‚Äì l√∂pande eller som en del av kodutmaningen i slutet. F√∂r att k√∂ra √∂vningarna beh√∂ver du:

1. **En Azure OpenAI API-nyckel** ‚Äì tj√§nstens endpoint f√∂r en distribuerad LLM.  
2. **En Python-runtime** ‚Äì d√§r Notebook kan k√∂ras.  
3. **Lokala milj√∂variabler** ‚Äì _slutf√∂r [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) stegen nu f√∂r att vara redo_.

Notebooken inneh√•ller _start√∂vningar_ ‚Äì men du uppmuntras att l√§gga till egna _Markdown_- (beskrivning) och _Code_- (promptf√∂rfr√•gningar) sektioner f√∂r att testa fler exempel eller id√©er ‚Äì och bygga din intuition f√∂r promptdesign.

## Illustrerad guide

Vill du f√• en √∂verblick √∂ver vad denna lektion handlar om innan du dyker in? Kolla in denna illustrerade guide som ger dig en k√§nsla f√∂r huvud√§mnena och viktiga insikter att fundera p√• i varje del. Lektionens f√§rdplan tar dig fr√•n att f√∂rst√• k√§rnbegrepp och utmaningar till att hantera dem med relevanta prompt engineering-tekniker och b√§sta praxis. Observera att avsnittet "Avancerade tekniker" i denna guide h√§nvisar till inneh√•ll som t√§cks i _n√§sta_ kapitel i denna kurs.

![Illustrerad guide till Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.sv.png)

## V√•rt startup

Nu ska vi prata om hur _detta √§mne_ relaterar till v√•r startup-mission att [f√∂ra AI-innovation till utbildning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi vill bygga AI-drivna applikationer f√∂r _personanpassat l√§rande_ ‚Äì s√• l√•t oss fundera p√• hur olika anv√§ndare av v√•r applikation kan "designa" prompts:

- **Administrat√∂rer** kan be AI:n att _analysera l√§roplansdata f√∂r att identifiera luckor i t√§ckningen_. AI:n kan sammanfatta resultaten eller visualisera dem med kod.  
- **L√§rare** kan be AI:n att _generera en lektionsplan f√∂r en m√•lgrupp och ett √§mne_. AI:n kan skapa den personliga planen i ett angivet format.  
- **Studenter** kan be AI:n att _handleda dem i ett sv√•rt √§mne_. AI:n kan nu guida studenter med lektioner, tips och exempel anpassade efter deras niv√•.

Det √§r bara toppen av isberget. Kolla in [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì ett open source-bibliotek med prompts sammanst√§llt av utbildningsexperter ‚Äì f√∂r att f√• en bredare bild av m√∂jligheterna! _Testa att k√∂ra n√•gra av dessa prompts i sandboxen eller i OpenAI Playground f√∂r att se vad som h√§nder!_

<!--  
LESSON TEMPLATE:  
This unit should cover core concept #1.  
Reinforce the concept with examples and references.  

CONCEPT #1:  
Prompt Engineering.  
Define it and explain why it is needed.  
-->

## Vad √§r Prompt Engineering?

Vi b√∂rjade denna lektion med att definiera **Prompt Engineering** som processen att _designa och optimera_ textinput (prompts) f√∂r att leverera konsekventa och kvalitativa svar (completions) f√∂r ett givet applikationsm√•l och modell. Vi kan se detta som en tv√•stegsprocess:

- _designa_ den initiala prompten f√∂r en given modell och m√•l  
- _f√∂rfina_ prompten iterativt f√∂r att f√∂rb√§ttra svarskvaliteten

Detta √§r n√∂dv√§ndigtvis en trial-and-error-process som kr√§ver anv√§ndarens intuition och anstr√§ngning f√∂r att n√• optimala resultat. S√• varf√∂r √§r det viktigt? F√∂r att svara p√• det beh√∂ver vi f√∂rst f√∂rst√• tre begrepp:

- _Tokenisering_ = hur modellen "ser" prompten  
- _Bas-LLMs_ = hur grundmodellen "bearbetar" en prompt  
- _Instruction-Tuned LLMs_ = hur modellen nu kan tolka "uppgifter"

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ d√§r olika modeller (eller versioner av en modell) kan tokenisera samma prompt p√• olika s√§tt. Eftersom LLMs tr√§nas p√• tokens (och inte r√•text) p√•verkar hur prompten tokeniseras direkt kvaliteten p√• det genererade svaret.

F√∂r att f√• en k√§nsla f√∂r hur tokenisering fungerar, prova verktyg som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) som visas nedan. Klistra in din prompt ‚Äì och se hur den omvandlas till tokens, med fokus p√• hur mellanslag och skiljetecken hanteras. Observera att detta exempel visar en √§ldre LLM (GPT-3) ‚Äì s√• att testa med en nyare modell kan ge ett annat resultat.

![Tokenisering](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.sv.png)

### Begrepp: Grundmodeller

N√§r en prompt √§r tokeniserad √§r huvudfunktionen f√∂r ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grundmodellen) att f√∂ruts√§ga n√§sta token i sekvensen. Eftersom LLMs tr√§nas p√• enorma textdatam√§ngder har de god f√∂rst√•else f√∂r statistiska samband mellan tokens och kan g√∂ra denna f√∂ruts√§gelse med viss s√§kerhet. Observera att de inte f√∂rst√•r _inneb√∂rden_ av orden i prompten eller token; de ser bara ett m√∂nster som de kan "komplettera" med sin n√§sta f√∂ruts√§gelse. De kan forts√§tta f√∂ruts√§ga sekvensen tills anv√§ndaren avbryter eller n√•gon f√∂rutbest√§md villkor uppfylls.

Vill du se hur prompt-baserad completion fungerar? Skriv in prompten ovan i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinst√§llningarna. Systemet √§r konfigurerat att behandla prompts som informationsf√∂rfr√•gningar ‚Äì s√• du b√∂r se ett svar som passar detta sammanhang.

Men vad h√§nder om anv√§ndaren vill ha n√•got specifikt som uppfyller vissa kriterier eller m√•l? H√§r kommer _instruction-tuned_ LLMs in i bilden.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.sv.png)

### Begrepp: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) bygger p√• grundmodellen och finjusteras med exempel eller input/output-par (t.ex. flerstegs-"meddelanden") som kan inneh√•lla tydliga instruktioner ‚Äì och AI:s svar f√∂rs√∂ker f√∂lja dessa instruktioner.

Detta anv√§nder tekniker som Reinforcement Learning with Human Feedback (RLHF) som kan tr√§na modellen att _f√∂lja instruktioner_ och _l√§ra sig av feedback_ s√• att den producerar svar som √§r b√§ttre anpassade f√∂r praktiska till√§mpningar och mer relevanta f√∂r anv√§ndarens m√•l.

L√•t oss prova ‚Äì g√• tillbaka till prompten ovan, men √§ndra nu _systemmeddelandet_ f√∂r att ge f√∂ljande instruktion som kontext:

> _Sammanfatta inneh√•llet du f√•r f√∂r en elev i √•rskurs 2. H√•ll resultatet till ett stycke med 3-5 punkter._

Ser du hur resultatet nu √§r anpassat f√∂r att spegla det √∂nskade m√•let och formatet? En l√§rare kan nu direkt anv√§nda detta svar i sina presentationer f√∂r den klassen.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.sv.png)

## Varf√∂r beh√∂ver vi Prompt Engineering?

Nu n√§r vi vet hur prompts bearbetas av LLMs, l√•t oss prata om _varf√∂r_ vi beh√∂ver prompt engineering. Svaret ligger i att dagens LLMs har flera utmaningar som g√∂r det sv√•rare att uppn√• _p√•litliga och konsekventa svar_ utan att l√§gga ner arbete p√• promptkonstruktion och optimering. Till exempel:

1. **Modellens svar √§r stokastiska.** _Samma prompt_ kan ge olika svar med olika modeller eller modellversioner. Och det kan till och med ge olika resultat med _samma modell_ vid olika tillf√§llen. _Prompt engineering-tekniker kan hj√§lpa oss att minimera dessa variationer genom att ge b√§ttre styrning_.

1. **Modeller kan hitta p√• svar.** Modeller √§r f√∂rtr√§nade p√• _stora men begr√§nsade_ dataset, vilket inneb√§r att de saknar kunskap om koncept utanf√∂r tr√§ningsmaterialet. Som en f√∂ljd kan de generera svar som √§r felaktiga, p√•hittade eller direkt mots√§ger k√§nda fakta. _Prompt engineering hj√§lper anv√§ndare att identifiera och minska s√•dana p√•hitt, t.ex. genom att be AI:n om k√§llh√§nvisningar eller resonemang_.

1. **Modellernas kapacitet varierar.** Nyare modeller eller modellgenerationer har rikare kapaciteter men medf√∂r ocks√• unika egenheter och kompromisser i kostnad och komplexitet. _Prompt engineering kan hj√§lpa oss att utveckla b√§sta praxis och arbetsfl√∂den som d√∂ljer skillnader och anpassar sig till modell-specifika krav p√• ett skalbart och smidigt s√§tt_.

L√•t oss se detta i praktiken i OpenAI eller Azure OpenAI Playground:

- Anv√§nd samma prompt med olika LLM-distributioner (t.ex. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√•g du variationerna?  
- Anv√§nd samma prompt upprepade g√•nger med _samma_ LLM-distribution (t.ex. Azure OpenAI playground) ‚Äì hur skiljde sig dessa variationer?

### Exempel p√• p√•hittade svar

I denna kurs anv√§nder vi termen **"fabrication"** f√∂r att beskriva fenomenet d√§r LLMs ibland genererar faktam√§ssigt felaktig information p√• grund av begr√§nsningar i deras tr√§ning eller andra faktorer. Du har kanske ocks√• h√∂rt detta kallat _"hallucinationer"_ i popul√§ra artiklar eller forskningsrapporter. Vi rekommenderar dock starkt att anv√§nda _"fabrication"_ som term f√∂r att undvika att antropomorfisera beteendet genom att tillskriva en m√§nsklig egenskap till ett maskindrivet resultat. Detta st√§rker ocks√• [Responsible AI-riktlinjer](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) ur ett terminologiskt perspektiv, genom att ta bort termer som kan uppfattas som st√∂tande eller icke-inkluderande i vissa sammanhang.

Vill du f√• en k√§nsla f√∂r hur fabrications fungerar? T√§nk p√• en prompt som instruerar AI:n att generera inneh√•ll f√∂r ett icke-existerande √§mne (f√∂r att s√§kerst√§lla att det inte finns i tr√§ningsdata). Till exempel ‚Äì jag testade denna prompt:
# Lektionplan: Marskriget 2076

## √ñversikt
I denna lektion kommer vi att utforska Marskriget som √§gde rum √•r 2076. Vi kommer att unders√∂ka orsakerna till konflikten, de viktigaste h√§ndelserna under kriget, samt dess konsekvenser f√∂r m√§nskligheten och rymdforskningen.

## M√•l
- F√∂rst√• bakgrunden till Marskriget 2076
- Identifiera de viktigaste akt√∂rerna och h√§ndelserna
- Analysera krigets p√•verkan p√• samh√§llet och teknologin
- Diskutera l√§rdomar fr√•n konflikten

## Material
- Textdokument om Marskriget 2076
- Kartor √∂ver Mars och jordens kolonier
- Videoklipp med intervjuer fr√•n √∂verlevande och experter
- Diskussionfr√•gor

## Lektionens g√•ng

### 1. Introduktion (10 minuter)
- Kort presentation av Marskriget 2076
- Visa en tidslinje √∂ver viktiga h√§ndelser
- Diskutera varf√∂r konflikten uppstod

### 2. Bakgrund och orsaker (15 minuter)
- G√• igenom de politiska och ekonomiska faktorerna
- Beskriv de olika grupperna och deras m√•l
- Analysera resursbrist och territoriella tvister

### 3. Viktiga h√§ndelser under kriget (20 minuter)
- Beskriv de st√∂rsta slagen och strategierna
- Diskutera teknologiska innovationer som anv√§ndes
- Visa kartor f√∂r att illustrera r√∂relser och kontrollomr√•den

### 4. Konsekvenser och efterspel (15 minuter)
- Analysera krigets p√•verkan p√• Mars och jorden
- Diskutera f√∂r√§ndringar i internationell politik och rymdlagstiftning
- Reflektera √∂ver hur kriget p√•verkade framtida rymdexpeditioner

### 5. Diskussion och reflektion (10 minuter)
- St√§ll fr√•gor till eleverna om vad de l√§rt sig
- Diskutera m√∂jliga alternativa utfall
- Uppmuntra eleverna att t√§nka p√• hur konflikter kan undvikas i framtiden

## Uppgifter
- Skriv en kort uppsats om en viktig h√§ndelse under Marskriget 2076
- Skapa en presentation om en av de teknologier som utvecklades under kriget
- Delta i en debatt om krigets r√§ttf√§rdigande och konsekvenser

## Bed√∂mning
- Aktivt deltagande i diskussioner
- Kvalitet p√• skriftliga uppgifter och presentationer
- F√∂rm√•ga att analysera och reflektera √∂ver historiska h√§ndelser

## Kommentarer
- Anpassa materialet efter elevernas f√∂rkunskaper
- Anv√§nd visuella hj√§lpmedel f√∂r att √∂ka f√∂rst√•elsen
- Uppmuntra kritiskt t√§nkande och k√§llkritik under hela lektionen
En webbs√∂kning visade att det fanns fiktiva ber√§ttelser (t.ex. TV-serier eller b√∂cker) om marskrig ‚Äì men inga fr√•n 2076. Sunt f√∂rnuft s√§ger ocks√• att 2076 √§r _i framtiden_ och d√§rf√∂r inte kan kopplas till en verklig h√§ndelse.

S√• vad h√§nder n√§r vi k√∂r denna prompt med olika LLM-leverant√∂rer?

> **Svar 1**: OpenAI Playground (GPT-35)

![Svar 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.sv.png)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Svar 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.sv.png)

> **Svar 3**: : Hugging Face Chat Playground (LLama-2)

![Svar 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.sv.png)

Som v√§ntat ger varje modell (eller modellversion) n√•got olika svar tack vare stokastiskt beteende och variationer i modellens kapacitet. Till exempel riktar sig en modell till en √•ttondeklassare medan en annan antar att anv√§ndaren √§r gymnasieelev. Men alla tre modeller genererade svar som skulle kunna √∂vertyga en oinformerad anv√§ndare om att h√§ndelsen var verklig.

Prompttekniker som _metaprompting_ och _temperaturinst√§llning_ kan till viss del minska modellens fabriceringar. Nya prompttekniska _arkitekturer_ integrerar ocks√• nya verktyg och metoder s√∂ml√∂st i promptfl√∂det f√∂r att mildra eller minska n√•gra av dessa effekter.

## Fallstudie: GitHub Copilot

L√•t oss avsluta detta avsnitt med att f√• en k√§nsla f√∂r hur promptteknik anv√§nds i verkliga l√∂sningar genom att titta p√• en fallstudie: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot √§r din "AI-parprogrammerare" ‚Äì den omvandlar textpromptar till kodkompletteringar och √§r integrerad i din utvecklingsmilj√∂ (t.ex. Visual Studio Code) f√∂r en s√∂ml√∂s anv√§ndarupplevelse. Som dokumenterat i bloggsserien nedan baserades den tidigaste versionen p√• OpenAI Codex-modellen ‚Äì d√§r ingenj√∂rer snabbt ins√•g behovet av att finjustera modellen och utveckla b√§ttre prompttekniker f√∂r att f√∂rb√§ttra kodkvaliteten. I juli [lanserade de en f√∂rb√§ttrad AI-modell som g√•r bortom Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) f√∂r √§nnu snabbare f√∂rslag.

L√§s inl√§ggen i ordning f√∂r att f√∂lja deras l√§randeresa.

- **Maj 2023** | [GitHub Copilot blir b√§ttre p√• att f√∂rst√• din kod](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inside GitHub: Att arbeta med LLM:erna bakom GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jun 2023** | [Hur man skriver b√§ttre prompts f√∂r GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [.. GitHub Copilot g√•r bortom Codex med f√∂rb√§ttrad AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En utvecklares guide till promptteknik och LLM:er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hur man bygger en f√∂retags-LLM-app: L√§rdomar fr√•n GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ocks√• bl√§ddra i deras [Engineering blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) f√∂r fler inl√§gg som [det h√§r](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som visar hur dessa modeller och tekniker _till√§mpas_ f√∂r att driva verkliga applikationer.

---

<!--
LESSON TEMPLATE:
Denna enhet b√∂r t√§cka k√§rnkoncept #2.
F√∂rst√§rk konceptet med exempel och referenser.

KONCEPT #2:
Promptdesign.
Illustrerat med exempel.
-->

## Promptkonstruktion

Vi har sett varf√∂r promptteknik √§r viktigt ‚Äì nu ska vi f√∂rst√• hur prompts _konstrueras_ s√• att vi kan utv√§rdera olika tekniker f√∂r mer effektiv promptdesign.

### Grundl√§ggande prompt

L√•t oss b√∂rja med den grundl√§ggande prompten: en textinmatning som skickas till modellen utan annan kontext. H√§r √§r ett exempel ‚Äì n√§r vi skickar de f√∂rsta orden i USA:s nationals√•ng till OpenAI:s [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) fullbordar den omedelbart svaret med de f√∂ljande raderna, vilket illustrerar det grundl√§ggande prediktionsbeteendet.

| Prompt (Inmatning)     | Komplettering (Utmatning)                                                                                                                        |
| :--------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see      | Det l√•ter som att du b√∂rjar med texten till "The Star-Spangled Banner", USA:s nationals√•ng. Den fullst√§ndiga texten √§r ...                      |

### Komplex prompt

Nu l√§gger vi till kontext och instruktioner till den grundl√§ggande prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) l√•ter oss bygga en komplex prompt som en samling _meddelanden_ med:

- Inmatning/utmatningspar som speglar _anv√§ndarens_ input och _assistentens_ svar.
- Systemmeddelande som s√§tter kontext f√∂r assistentens beteende eller personlighet.

F√∂rfr√•gan ser nu ut som nedan, d√§r _tokeniseringen_ effektivt f√•ngar relevant information fr√•n kontext och konversation. Att √§ndra systemkontexten kan nu p√•verka kvaliteten p√• kompletteringarna lika mycket som anv√§ndarens inmatningar.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I exemplen ovan var anv√§ndarprompten en enkel textfr√•ga som kan tolkas som en informationsf√∂rfr√•gan. Med _instruktionsprompter_ kan vi anv√§nda texten f√∂r att specificera en uppgift mer detaljerat och ge AI:n b√§ttre v√§gledning. H√§r √§r ett exempel:

| Prompt (Inmatning)                                                                                                                                                                                                                         | Komplettering (Utmatning)                                                                                                        | Instruktionstyp     |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Write a description of the Civil War                                                                                                                                                                                                   | _returnerade ett enkelt stycke_                                                                                                 | Enkel              |
| Write a description of the Civil War. Provide key dates and events and describe their significance                                                                                                                                     | _returnerade ett stycke f√∂ljt av en lista med viktiga datum och beskrivningar_                                                  | Komplex            |
| Write a description of the Civil War in 1 paragraph. Provide 3 bullet points with key dates and their significance. Provide 3 more bullet points with key historical figures and their contributions. Return the output as a JSON file | _returnerar mer omfattande detaljer i en textruta, formaterad som JSON som du kan kopiera och klistra in i en fil och validera vid behov_ | Komplex. Formaterad.|

## Prim√§rt inneh√•ll

I exemplen ovan var prompten fortfarande ganska √∂ppen, vilket till√§t LLM att avg√∂ra vilken del av dess f√∂rtr√§nade dataset som var relevant. Med designm√∂nstret _prim√§rt inneh√•ll_ delas inmatningstexten upp i tv√• delar:

- en instruktion (√•tg√§rd)
- relevant inneh√•ll (som p√•verkar √•tg√§rden)

H√§r √§r ett exempel d√§r instruktionen √§r att "sammanfatta detta i 2 meningar".

| Prompt (Inmatning)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Komplettering (Utmatning)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger massan av alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r forntida civilisationer sedan innan historien skrevs. Den √§r uppkallad efter den romerska guden Jupiter.[19] N√§r man ser Jupiter fr√•n jorden kan den vara tillr√§ckligt ljus f√∂r att dess reflekterade ljus ska kasta synliga skuggor,[20] och √§r i genomsnitt det tredje ljusaste naturliga objektet p√• natthimlen efter m√•nen och Venus. <br/> **Sammanfatta detta i 2 korta meningar** | Jupiter, den femte planeten fr√•n solen, √§r den st√∂rsta i solsystemet och √§r k√§nd f√∂r att vara ett av de ljusaste objekten p√• natthimlen. Uppkallad efter den romerska guden Jupiter, √§r det en gasj√§tte vars massa √§r tv√• och en halv g√•nger massan av alla andra planeter i solsystemet tillsammans. |

Segmentet med prim√§rt inneh√•ll kan anv√§ndas p√• olika s√§tt f√∂r att driva mer effektiva instruktioner:

- **Exempel** ‚Äì ist√§llet f√∂r att tala om f√∂r modellen vad den ska g√∂ra med en explicit instruktion, ge den exempel p√• vad som ska g√∂ras och l√•t den dra slutsatser om m√∂nstret.
- **Ledtr√•dar** ‚Äì f√∂lj instruktionen med en "ledtr√•d" som f√∂rbereder kompletteringen och styr modellen mot mer relevanta svar.
- **Mall** ‚Äì detta √§r upprepbara 'recept' f√∂r prompts med platsh√•llare (variabler) som kan anpassas med data f√∂r specifika anv√§ndningsfall.

L√•t oss utforska dessa i praktiken.

### Anv√§nda exempel

Detta √§r en metod d√§r du anv√§nder det prim√§ra inneh√•llet f√∂r att "mata modellen" med exempel p√• √∂nskat resultat f√∂r en given instruktion och l√•ter den dra slutsatser om m√∂nstret f√∂r √∂nskat resultat. Beroende p√• antalet exempel kan vi ha zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r nu av tre komponenter:

- En uppgiftsbeskrivning
- N√•gra exempel p√• √∂nskat resultat
- B√∂rjan p√• ett nytt exempel (som blir en implicit uppgiftsbeskrivning)

| Inl√§rningstyp | Prompt (Inmatning)                                                                                                                                        | Komplettering (Utmatning)         |
| :------------ | :-------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------- |
| Zero-shot     | "The Sun is Shining". Translate to Spanish                                                                                                              | "El Sol est√° brillando".          |
| One-shot      | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                   | "Es un d√≠a fr√≠o y ventoso".       |
| Few-shot      | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>       | Basketball                       |
|               |                                                                                                                                                           |                                 |

Notera hur vi beh√∂vde ge en explicit instruktion ("Translate to Spanish") i zero-shot prompting, men den h√§rleds i one-shot-exemplet. Few-shot-exemplet visar hur fler exempel g√∂r att modeller kan g√∂ra mer exakta slutsatser utan extra instruktioner.

### Promptledtr√•dar

En annan teknik f√∂r att anv√§nda prim√§rt inneh√•ll √§r att ge _ledtr√•dar_ ist√§llet f√∂r exempel. I detta fall ger vi modellen en knuff i r√§tt riktning genom att _starta den_ med ett utdrag som speglar √∂nskat svarformat. Modellen "tar ledtr√•den" och forts√§tter i samma stil.

| Antal ledtr√•dar | Prompt (Inmatning)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Komplettering (Utmatning)                                                                                                                                                                                                                                                                                       |
| :-------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0               | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger massan av alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen, och har varit k√§nt f√∂r forntida civilisationer sedan innan historien skrevs.

**Sammanfatta detta**                                       | Jupiter √§r den st√∂rsta planeten i v√•rt solsystem och den femte fr√•n solen. Det √§r en gasj√§tte med en massa som √§r 1/1000 av solens, men den √§r tyngre √§n alla andra planeter tillsammans. Forntida civilisationer har k√§nt till Jupiter l√§nge, och den √§r l√§tt synlig p√• natthimlen. |
| 1              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger tyngre √§n alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r forntida civilisationer l√•ngt innan historien skrevs ned. <br/>**Sammanfatta detta** <br/> Det vi l√§rde oss √§r att Jupiter | √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger tyngre √§n alla andra planeter tillsammans. Den √§r l√§tt synlig f√∂r blotta √∂gat och har varit k√§nd sedan urminnes tider.                        |
| 2              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger tyngre √§n alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r forntida civilisationer l√•ngt innan historien skrevs ned. <br/>**Sammanfatta detta** <br/> Topp 3 fakta vi l√§rde oss:         | 1. Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. <br/> 2. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens...<br/> 3. Jupiter har varit synlig f√∂r blotta √∂gat sedan urminnes tider ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Promptmallar

En promptmall √§r ett _f√∂rdefinierat recept f√∂r en prompt_ som kan sparas och √•teranv√§ndas vid behov f√∂r att skapa mer konsekventa anv√§ndarupplevelser i stor skala. I sin enklaste form √§r det helt enkelt en samling promptexempel som [det h√§r fr√•n OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som inneh√•ller b√•de de interaktiva promptkomponenterna (anv√§ndar- och systemmeddelanden) och API-drivna f√∂rfr√•gningsformatet ‚Äì f√∂r att st√∂dja √•teranv√§ndning.

I en mer komplex form som [det h√§r exemplet fr√•n LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) inneh√•ller den _platsh√•llare_ som kan ers√§ttas med data fr√•n olika k√§llor (anv√§ndarinmatning, systemkontext, externa datak√§llor etc.) f√∂r att generera en prompt dynamiskt. Detta g√∂r att vi kan skapa ett bibliotek av √•teranv√§ndbara prompts som kan anv√§ndas f√∂r att programm√§ssigt driva konsekventa anv√§ndarupplevelser i stor skala.

Slutligen ligger det verkliga v√§rdet i mallar i m√∂jligheten att skapa och publicera _promptbibliotek_ f√∂r vertikala applikationsdom√§ner ‚Äì d√§r promptmallen nu √§r _optimerad_ f√∂r att spegla applikationsspecifik kontext eller exempel som g√∂r svaren mer relevanta och korrekta f√∂r den riktade anv√§ndargruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst)-arkivet √§r ett utm√§rkt exempel p√• detta tillv√§gag√•ngss√§tt, d√§r man samlar ett bibliotek av prompts f√∂r utbildningsomr√•det med fokus p√• viktiga m√•l som lektionsplanering, l√§roplansdesign, handledning av studenter med mera.

## St√∂djande inneh√•ll

Om vi ser p√• promptkonstruktion som att ha en instruktion (uppgift) och ett m√•l (prim√§rt inneh√•ll), s√• √§r _sekund√§rt inneh√•ll_ som ytterligare kontext vi tillhandah√•ller f√∂r att **p√•verka resultatet p√• n√•got s√§tt**. Det kan vara justeringsparametrar, formateringsinstruktioner, √§mnestaxonomier etc. som hj√§lper modellen att _anpassa_ sitt svar f√∂r att passa √∂nskade anv√§ndarm√•l eller f√∂rv√§ntningar.

Till exempel: Givet en kurskatalog med omfattande metadata (namn, beskrivning, niv√•, metadatataggar, instrukt√∂r etc.) f√∂r alla tillg√§ngliga kurser i l√§roplanen:

- kan vi definiera en instruktion f√∂r att "sammanfatta kurskatalogen f√∂r h√∂sten 2023"
- vi kan anv√§nda det prim√§ra inneh√•llet f√∂r att ge n√•gra exempel p√• √∂nskat resultat
- vi kan anv√§nda det sekund√§ra inneh√•llet f√∂r att identifiera de 5 viktigaste "taggarna" av intresse.

Nu kan modellen ge en sammanfattning i det format som visas av de f√• exemplen ‚Äì men om ett resultat har flera taggar kan den prioritera de 5 taggar som identifierats i det sekund√§ra inneh√•llet.

---

<!--
LEKTIONSMALL:
Denna enhet b√∂r t√§cka k√§rnkoncept #1.
F√∂rst√§rk konceptet med exempel och referenser.

KONCEPT #3:
Prompt Engineering-tekniker.
Vilka √§r n√•gra grundl√§ggande tekniker f√∂r prompt engineering?
Illustrera med n√•gra √∂vningar.
-->

## B√§sta praxis f√∂r prompting

Nu n√§r vi vet hur prompts kan _konstrueras_ kan vi b√∂rja fundera p√• hur vi _designar_ dem f√∂r att f√∂lja b√§sta praxis. Vi kan se detta i tv√• delar ‚Äì att ha r√§tt _inst√§llning_ och att anv√§nda r√§tt _tekniker_.

### Inst√§llning f√∂r prompt engineering

Prompt Engineering √§r en process med f√∂rs√∂k och misstag, s√• h√•ll tre breda v√§gledande faktorer i √•tanke:

1. **Dom√§nf√∂rst√•else √§r viktigt.** Svarens noggrannhet och relevans beror p√• den _dom√§n_ d√§r applikationen eller anv√§ndaren verkar. Anv√§nd din intuition och dom√§nkunskap f√∂r att **anpassa teknikerna** ytterligare. Definiera till exempel _dom√§nspecifika personligheter_ i dina systemprompter, eller anv√§nd _dom√§nspecifika mallar_ i dina anv√§ndarprompter. Ge sekund√§rt inneh√•ll som speglar dom√§nspecifika kontexter, eller anv√§nd _dom√§nspecifika ledtr√•dar och exempel_ f√∂r att styra modellen mot bekanta anv√§ndningsm√∂nster.

2. **Modellf√∂rst√•else √§r viktigt.** Vi vet att modeller √§r stokastiska till sin natur. Men modellimplementationer kan ocks√• skilja sig √•t vad g√§ller tr√§ningsdata (f√∂rtr√§nad kunskap), vilka funktioner de erbjuder (t.ex. via API eller SDK) och vilken typ av inneh√•ll de √§r optimerade f√∂r (t.ex. kod vs. bilder vs. text). F√∂rst√• styrkor och begr√§nsningar hos den modell du anv√§nder och anv√§nd den kunskapen f√∂r att _prioritera uppgifter_ eller bygga _anpassade mallar_ som √§r optimerade f√∂r modellens kapacitet.

3. **Iteration och validering √§r viktigt.** Modeller utvecklas snabbt, och det g√∂r √§ven teknikerna f√∂r prompt engineering. Som dom√§nexpert kan du ha annan kontext eller kriterier f√∂r _din_ specifika applikation som kanske inte g√§ller f√∂r den bredare gemenskapen. Anv√§nd verktyg och tekniker f√∂r prompt engineering f√∂r att "komma ig√•ng" med promptkonstruktion, iterera sedan och validera resultaten med din egen intuition och dom√§nkunskap. Dokumentera dina insikter och skapa en **kunskapsbas** (t.ex. promptbibliotek) som kan anv√§ndas som ny baslinje av andra f√∂r snabbare iterationer i framtiden.

## B√§sta praxis

L√•t oss nu titta p√• vanliga b√§sta praxis som rekommenderas av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) och [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) experter.

| Vad                              | Varf√∂r                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Utv√§rdera de senaste modellerna. | Nya modellgenerationer har sannolikt f√∂rb√§ttrade funktioner och kvalitet ‚Äì men kan ocks√• inneb√§ra h√∂gre kostnader. Utv√§rdera deras p√•verkan och fatta sedan beslut om migrering.                                                                     |
| Separera instruktioner och kontext | Kontrollera om din modell/leverant√∂r definierar _avgr√§nsare_ f√∂r att tydligare skilja instruktioner, prim√§rt och sekund√§rt inneh√•ll. Detta kan hj√§lpa modeller att tilldela vikt mer exakt till tokens.                                            |
| Var specifik och tydlig           | Ge mer detaljer om √∂nskad kontext, resultat, l√§ngd, format, stil etc. Detta f√∂rb√§ttrar b√•de kvalitet och konsekvens i svaren. Spara recept i √•teranv√§ndbara mallar.                                                                                 |
| Var beskrivande, anv√§nd exempel   | Modeller kan svara b√§ttre p√• en "visa och ber√§tta"-metod. B√∂rja med en `zero-shot`-metod d√§r du ger en instruktion (men inga exempel) och prova sedan `few-shot` som f√∂rfining, d√§r du ger n√•gra exempel p√• √∂nskat resultat. Anv√§nd analogier.         |
| Anv√§nd ledtr√•dar f√∂r att starta svar | Styr modellen mot √∂nskat resultat genom att ge n√•gra inledande ord eller fraser som den kan anv√§nda som startpunkt f√∂r svaret.                                                                                                                   |
| Upprepa vid behov                 | Ibland kan du beh√∂va upprepa dig f√∂r modellen. Ge instruktioner f√∂re och efter ditt prim√§ra inneh√•ll, anv√§nd en instruktion och en ledtr√•d etc. Iterera och validera f√∂r att se vad som fungerar.                                                    |
| Ordningen spelar roll             | I vilken ordning du presenterar information f√∂r modellen kan p√•verka resultatet, √§ven i inl√§rningsexemplen, p√• grund av nyhetsbias. Prova olika alternativ f√∂r att se vad som fungerar b√§st.                                                        |
| Ge modellen en ‚Äúutv√§g‚Äù            | Ge modellen ett _fallback_-svar som den kan anv√§nda om den av n√•gon anledning inte kan slutf√∂ra uppgiften. Detta kan minska risken f√∂r att modellen genererar falska eller p√•hittade svar.                                                            |
|                                 |                                                                                                                                                                                                                                                   |

Som med all b√§sta praxis, kom ih√•g att _dina erfarenheter kan variera_ beroende p√• modell, uppgift och dom√§n. Anv√§nd dessa som en utg√•ngspunkt och iterera f√∂r att hitta vad som fungerar b√§st f√∂r dig. Utv√§rdera kontinuerligt din prompt engineering-process n√§r nya modeller och verktyg blir tillg√§ngliga, med fokus p√• skalbarhet och svarskvalitet.

<!--
LEKTIONSMALL:
Denna enhet b√∂r inneh√•lla en kodutmaning om till√§mpligt

UTMANING:
L√§nk till en Jupyter Notebook med endast kodkommentarer i instruktionerna (kodavsnitten √§r tomma).

L√ñSNING:
L√§nk till en kopia av den Notebook med ifyllda prompts och k√∂rd, som visar ett exempel p√• resultat.
-->

## Uppgift

Grattis! Du har n√•tt slutet av lektionen! Det √§r dags att testa n√•gra av de koncept och tekniker vi g√•tt igenom med riktiga exempel!

F√∂r v√•r uppgift kommer vi att anv√§nda en Jupyter Notebook med √∂vningar som du kan g√∂ra interaktivt. Du kan ocks√• ut√∂ka Notebooken med egna Markdown- och kodceller f√∂r att utforska id√©er och tekniker p√• egen hand.

### F√∂r att komma ig√•ng, fork:a repot och sedan

- (Rekommenderat) Starta GitHub Codespaces
- (Alternativt) Klona repot till din lokala enhet och anv√§nd det med Docker Desktop
- (Alternativt) √ñppna Notebooken i din f√∂redragna Notebook-milj√∂.

### N√§sta steg, konfigurera dina milj√∂variabler

- Kopiera filen `.env.copy` i repots rotmapp till `.env` och fyll i v√§rdena f√∂r `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` och `AZURE_OPENAI_DEPLOYMENT`. G√• tillbaka till [Learning Sandbox-sektionen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) f√∂r att l√§ra dig hur.

### N√§sta, √∂ppna Jupyter Notebook

- V√§lj runtime-k√§rnan. Om du anv√§nder alternativ 1 eller 2, v√§lj helt enkelt standard Python 3.10.x-k√§rnan som tillhandah√•lls av utvecklingscontainern.

Du √§r redo att k√∂ra √∂vningarna. Observera att det inte finns n√•gra _r√§tt eller fel_ svar h√§r ‚Äì det handlar om att utforska alternativ genom f√∂rs√∂k och misstag och bygga intuition f√∂r vad som fungerar f√∂r en viss modell och applikationsdom√§n.

_F√∂r denna anledning finns inga kodl√∂sningsavsnitt i denna lektion. Ist√§llet kommer Notebooken att ha Markdown-celler med titeln "Min l√∂sning:" som visar ett exempel p√• output f√∂r referens._

<!--
LEKTIONSMALL:
Avsluta avsnittet med en sammanfattning och resurser f√∂r sj√§lvstudier.
-->

## Kunskapskontroll

Vilken av f√∂ljande √§r en bra prompt som f√∂ljer rimliga b√§sta praxis?

1. Visa mig en bild p√• en r√∂d bil  
2. Visa mig en bild p√• en r√∂d bil av m√§rket Volvo och modellen XC90 parkerad vid en klippa med solen som g√•r ner  
3. Visa mig en bild p√• en r√∂d bil av m√§rket Volvo och modellen XC90

Svar: 2, det √§r den b√§sta prompten eftersom den ger detaljer om "vad" och g√•r in p√• specifika detaljer (inte bara vilken bil som helst utan ett specifikt m√§rke och modell) och den beskriver √§ven den √∂vergripande milj√∂n. 3 √§r n√§st b√§st eftersom den ocks√• inneh√•ller mycket beskrivning.

## üöÄ Utmaning

Se om du kan anv√§nda "ledtr√•ds"-tekniken med prompten: Fyll i meningen "Visa mig en bild p√• en r√∂d bil av m√§rket Volvo och ". Vad svarar den med, och hur skulle du f√∂rb√§ttra det?

## Bra jobbat! Forts√§tt din l√§rande

Vill du l√§ra dig mer om olika koncept inom Prompt Engineering? G√• till [sidan f√∂r fortsatt l√§rande](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att hitta fler bra resurser om detta √§mne.

G√• vidare till Lektion 5 d√§r vi tittar p√• [avancerade prompting-tekniker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, v√§nligen observera att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.