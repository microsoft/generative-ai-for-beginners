# Grundl√§ggande om Prompt Engineering

[![Grundl√§ggande om Prompt Engineering](../../../translated_images/sv/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introduktion
Denna modul t√§cker viktiga begrepp och tekniker f√∂r att skapa effektiva prompts i generativa AI-modeller. Hur du skriver din prompt till en LLM spelar ocks√• roll. En noggrant utformad prompt kan uppn√• b√§ttre kvalitet p√• svaret. Men vad inneb√§r egentligen begrepp som _prompt_ och _prompt engineering_? Och hur f√∂rb√§ttrar jag prompt-_input_ som jag skickar till LLM? Dessa √§r fr√•gor vi ska f√∂rs√∂ka svara p√• inom detta och n√§sta kapitel.

_Generativ AI_ kan skapa nytt inneh√•ll (t.ex. text, bilder, ljud, kod etc.) som svar p√• anv√§ndarens f√∂rfr√•gningar. Den g√∂r detta med hj√§lp av _Large Language Models_ som OpenAI:s GPT ("Generative Pre-trained Transformer")-serie som √§r tr√§nade f√∂r att anv√§nda naturligt spr√•k och kod.

Anv√§ndare kan nu interagera med dessa modeller med v√§lk√§nda paradigm som chatt, utan teknisk expertis eller utbildning. Modellerna √§r _prompt-baserade_ ‚Äì anv√§ndare skickar in en textinput (prompt) och f√•r tillbaka AI:s svar (komplettering). De kan sedan "chatta med AI:n" iterativt, i flerstegs-konversationer, och f√∂rfina sin prompt tills svaret matchar deras f√∂rv√§ntningar.

"Prompter" blir nu det prim√§ra _programmeringsgr√§nssnittet_ f√∂r generativa AI-appar och talar om f√∂r modellerna vad de ska g√∂ra samt p√•verkar kvaliteten p√• de svar som returneras. "Prompt Engineering" √§r ett snabbt v√§xande forskningsomr√•de som fokuserar p√• _design och optimering_ av promtps f√∂r att leverera konsekventa och kvalitativa svar i skala.

## L√§randem√•l

I denna lektion l√§r vi oss vad Prompt Engineering √§r, varf√∂r det √§r viktigt och hur vi kan skapa mer effektiva prompts f√∂r en viss modell och applikationssyfte. Vi kommer f√∂rst√• k√§rnbegrepp och b√§sta praxis f√∂r prompt engineering ‚Äì och l√§ra oss om en interaktiv Jupyter Notebooks-"sandbox"-milj√∂ d√§r vi kan se dessa begrepp till√§mpade med riktiga exempel.

I slutet av lektionen ska vi kunna:

1. F√∂rklara vad prompt engineering √§r och varf√∂r det √§r viktigt.
2. Beskriva komponenterna i en prompt och hur de anv√§nds.
3. L√§ra oss b√§sta praxis och tekniker f√∂r prompt engineering.
4. Till√§mpa inl√§rda tekniker p√• riktiga exempel, med en OpenAI-endpoint.

## Viktiga Begrepp

Prompt Engineering: Praktiken att designa och f√∂rfina input f√∂r att leda AI-modeller mot att producera √∂nskade utdata.  
Tokenisering: Processen att omvandla text till mindre enheter, kallade tokens, som en modell kan f√∂rst√• och bearbeta.  
Instruction-Tuned LLMs: Stora spr√•kmodeller som har finjusterats med specifika instruktioner f√∂r att f√∂rb√§ttra deras svarens noggrannhet och relevans.

## L√§rande Sandbox

Prompt engineering √§r idag mer en konst √§n vetenskap. Det b√§sta s√§ttet att f√∂rb√§ttra v√•r intuition f√∂r det √§r att _√∂vning ger f√§rdighet_ och att anta en trial-and-error-ansats som kombinerar kunskap om dom√§nen med rekommenderade tekniker och modelspecifika optimeringar.

Jupyter Notebook som f√∂ljer med denna lektion erbjuder en _sandbox_-milj√∂ d√§r du kan prova det du l√§r dig, antingen under tiden eller som en del av kodutmaningen i slutet. F√∂r att kunna utf√∂ra √∂vningarna beh√∂ver du:

1. **En Azure OpenAI API-nyckel** ‚Äì tj√§nstens endpoint f√∂r en distribuerad LLM.  
2. **En Python-runtime** ‚Äì d√§r Notebooks kan k√∂ras.  
3. **Lokala milj√∂variabler** ‚Äì _slutf√∂r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) stegen nu f√∂r att vara redo_.

Notebooken kommer med _start√∂vningar_ ‚Äì men du uppmuntras att l√§gga till egna _Markdown_ (beskrivningar) och _Code_ (prompt-f√∂rfr√•gningar) sektioner f√∂r att testa fler exempel eller id√©er ‚Äì och bygga din intuition f√∂r promptdesign.

## Illustrerad Guide

Vill du f√• en helhetsbild √∂ver vad denna lektion handlar om innan du dyker in? Kolla in denna illustrerade guide som ger dig en √∂versikt √∂ver huvud√§mnen och nyckelpunkter att t√§nka p√• i varje del. Lektionens f√§rdplan leder dig fr√•n grundl√§ggande koncept och utmaningar till att hantera dem med relevanta prompt engineering-tekniker och b√§sta praxis. Observera att avsnittet "Avancerade tekniker" i guiden avser inneh√•ll som tas upp i _n√§sta_ kapitel i denna kursplan.

![Illustrerad Guide till Prompt Engineering](../../../translated_images/sv/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## V√•rt Startup

Nu ska vi prata om hur _detta √§mne_ relaterar till v√•r startup-mission att [bringa AI-innovation till utbildning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi vill bygga AI-drivna applikationer f√∂r _personanpassat l√§rande_ ‚Äì s√• l√•t oss fundera p√• hur olika anv√§ndare av v√•r applikation kan "designa" prompts:

- **Administrat√∂rer** kan be AI:n att _analysera l√§roplansdata f√∂r att identifiera luckor i t√§ckningen_. AI kan sammanfatta resultaten eller visualisera dem med kod.  
- **Pedagoger** kan be AI:n att _generera en lektionsplan f√∂r en m√•lgrupp och ett √§mne_. AI kan bygga den personliga planen i ett specificerat format.  
- **Studenter** kan be AI:n att _handleda dem i ett sv√•rt √§mne_. AI kan nu guida studenter med lektioner, ledtr√•dar & exempel anpassade till deras niv√•.

Det √§r bara toppen av isberget. Kolla in [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì ett open-source prompts-bibliotek kuraterat av utbildningsexperter ‚Äì f√∂r att f√• en bredare bild av m√∂jligheterna! _Testa att k√∂ra n√•gra av dessa prompts i sandl√•dan eller i OpenAI Playground f√∂r att se vad som h√§nder!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Vad √§r Prompt Engineering?

Vi b√∂rjade denna lektion med att definiera **Prompt Engineering** som processen att _designa och optimera_ textinput (prompter) f√∂r att leverera konsekventa och kvalitativa svar (kompletteringar) f√∂r ett givet applikationsm√•l och modell. Vi kan se detta som en tv√•stegsprocess:

- _designa_ den initiala prompten f√∂r en given modell och m√•l  
- _f√∂rfina_ prompten iterativt f√∂r att f√∂rb√§ttra svarskvaliteten

Detta √§r n√∂dv√§ndigtvis en trial-and-error-process som kr√§ver anv√§ndarintuition och anstr√§ngning f√∂r att n√• optimala resultat. Men varf√∂r √§r det viktigt? F√∂r att svara p√• den fr√•gan beh√∂ver vi f√∂rst f√∂rst√• tre begrepp:

- _Tokenisering_ = hur modellen "ser" prompten  
- _Bas-LLMs_ = hur grundmodellen "bearbetar" en prompt  
- _Instruction-Tuned LLMs_ = hur modellen nu kan se "uppgifter"

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ d√§r olika modeller (eller versioner av samma modell) kan tokenisera samma prompt olika. Eftersom LLM:er tr√§nas p√• tokens (inte r√• text) har s√§ttet prompten tokeniseras en direkt p√•verkan p√• kvaliteten p√• det genererade svaret.

F√∂r att f√• en intuition om hur tokenisering fungerar, prova verktyg som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) som visas nedan. Kopiera in din prompt ‚Äì och se hur den konverteras till tokens, med uppm√§rksamhet p√• hur blanksteg och skiljetecken behandlas. Observera att exemplet visar en √§ldre LLM (GPT-3) ‚Äì s√• att testa med en nyare modell kan ge ett annat resultat.

![Tokenisering](../../../translated_images/sv/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Begrepp: Foundation Models

N√§r en prompt tokeniserats √§r den prim√§ra funktionen f√∂r ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grundmodellen) att f√∂rutsp√• n√§sta token i sekvensen. Eftersom LLMs tr√§nas p√• enorma textdatam√§ngder har de god f√∂rst√•else f√∂r statistiska samband mellan tokens och kan g√∂ra den f√∂ruts√§gelsen med viss s√§kerhet. Observera att de inte f√∂rst√•r _inneb√∂rden_ av orden i prompten eller token; de ser bara ett m√∂nster som de kan "komplettera" med n√§sta f√∂ruts√§gelse. De kan forts√§tta f√∂ruts√§ga sekvensen tills anv√§ndaren avbryter eller ett f√∂rinst√§llt villkor uppfylls.

Vill du se hur prompt-baserad komplettering fungerar? Ange prompten ovan i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinst√§llningarna. Systemet √§r konfigurerat f√∂r att behandla prompten som informationsf√∂rfr√•gningar ‚Äì s√• du b√∂r se en komplettering som st√§mmer √∂verens med den kontexten.

Men vad h√§nder om anv√§ndaren vill se n√•got som uppfyller vissa kriterier eller m√•l? H√§r kommer _instruction-tunade_ LLMs in i bilden.

![Bas-LLM Chat Completion](../../../translated_images/sv/04-playground-chat-base.65b76fcfde0caa67.webp)

### Begrepp: Instruction Tunade LLMs

En [Instruction Tunad LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) bygger p√• grundmodellen och finjusterar den med exempel eller input/output-par (t.ex. flerstegs-"meddelanden") som kan inneh√•lla tydliga instruktioner ‚Äì och AI:s svar f√∂rs√∂ker f√∂lja dessa instruktioner.

Detta anv√§nder tekniker som Reinforcement Learning with Human Feedback (RLHF) som kan l√§ra modellen att _f√∂lja instruktioner_ och _l√§ra av feedback_ s√• att den producerar svar som √§r b√§ttre anpassade f√∂r praktisk anv√§ndning och mer relevanta f√∂r anv√§ndarens m√•l.

L√•t oss prova ‚Äì √•terg√• till prompten ovan, men √§ndra nu _systemmeddelandet_ f√∂r att ge f√∂ljande instruktion som kontext:

> _Sammanfatta inneh√•llet du f√•r f√∂r en andraklassare. H√•ll resultatet till ett stycke med 3-5 punkter._

Ser du hur svaret nu √§r anpassat efter det √∂nskade m√•let och formatet? En pedagog kan direkt anv√§nda detta svar i sina presentationer f√∂r den klassen.

![Instruction Tunad LLM Chat Completion](../../../translated_images/sv/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## Varf√∂r beh√∂ver vi Prompt Engineering?

Nu n√§r vi vet hur prompts bearbetas av LLMs, l√•t oss tala om _varf√∂r_ vi beh√∂ver prompt engineering. Svaret ligger i att dagens LLMs har flera utmaningar som g√∂r att _p√•litliga och konsekventa kompletteringar_ blir sv√•rare att uppn√• utan att l√§gga ner anstr√§ngning p√• promptbyggande och optimering. Till exempel:

1. **Modellernas svar √§r stokastiska.** Samma prompt kan sannolikt ge olika svar med olika modeller eller modellversioner. Och det kan till och med ge olika resultat med samma modell vid olika tillf√§llen. _Prompt engineering-tekniker kan hj√§lpa oss att minska dessa variationer genom att ge b√§ttre styrinstrument_.

2. **Modeller kan hitta p√• svar.** Modeller √§r f√∂rtr√§nade med _stora men √§ndliga_ dataset, vilket inneb√§r att de saknar kunskap om begrepp utanf√∂r tr√§ningsomr√•det. D√§rf√∂r kan de ge kompletteringar som √§r felaktiga, p√•hittade eller direkt mots√§gelsefulla till k√§nda fakta. _Prompt engineering hj√§lper anv√§ndare att identifiera och motverka s√•dana p√•hitt, t.ex. genom att be AI:n om referenser eller motivering_.

3. **Modellernas kapacitet varierar.** Nyare modeller eller generationer har rikare f√∂rm√•gor men har ocks√• unika egenskaper och avv√§gningar i kostnad och komplexitet. _Prompt engineering hj√§lper oss att utveckla b√§sta praxis och arbetsfl√∂den som abstraherar skillnader och anpassar sig till modelspecifika krav p√• ett skalbart, s√∂ml√∂st s√§tt_.

L√•t oss se detta i praktiken i OpenAI eller Azure OpenAI Playground:

- Anv√§nd samma prompt med olika LLM-distributioner (t.ex. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√•g du variationerna?  
- Anv√§nd samma prompt upprepade g√•nger med _samma_ LLM-distribution (t.ex. Azure OpenAI Playground) ‚Äì hur skilde sig dessa variationer?

### Exempel p√• P√•hittade Svar

I denna kurs anv√§nder vi termen **"fabrication"** (p√•hitt) f√∂r att referera till fenomenet d√§r LLMs ibland genererar faktam√§ssigt felaktig information p√• grund av begr√§nsningar i deras tr√§ning eller andra faktorer. Du har kanske ocks√• h√∂rt detta refererat till som _"hallucinationer"_ i popul√§ra artiklar eller forskningspapper. Vi rekommenderar starkt att anv√§nda _"fabrication"_ som term f√∂r att undvika att antropomorfisera beteendet genom att tillskriva en m√§nsklig egenskap till ett maskindrivet resultat. Detta st√§rker ocks√• [Ansvarsfull AI riktlinjer](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) ur ett terminologiperspektiv och tar bort termer som kan uppfattas som st√∂tande eller icke-inkluderande i vissa sammanhang.

Vill du f√• en k√§nsla f√∂r hur fabrications fungerar? T√§nk p√• en prompt som instruerar AI:n att generera inneh√•ll f√∂r ett icke-existerande √§mne (f√∂r att s√§kerst√§lla att det inte finns med i tr√§ningsdata). Till exempel ‚Äì jag testade denna prompt:

> **Prompt:** generera en lektionsplan om Marskriget 2076.
En webbs√∂kning visade mig att det fanns fiktiva ber√§ttelser (t.ex. TV-serier eller b√∂cker) om marskrig - men inga √•r 2076. Sunt f√∂rnuft s√§ger oss ocks√• att 2076 √§r _i framtiden_ och d√§rmed inte kan kopplas till en verklig h√§ndelse.

S√• vad h√§nder n√§r vi k√∂r denna prompt med olika LLM-leverant√∂rer?

> **Svar 1**: OpenAI Playground (GPT-35)

![Response 1](../../../translated_images/sv/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../../translated_images/sv/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Svar 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../../translated_images/sv/04-fabrication-huggingchat.faf82a0a51278956.webp)

Som f√∂rv√§ntat ger varje modell (eller modellversion) n√•got olika svar tack vare stokastiskt beteende och variationer i modellkapacitet. Till exempel riktar sig en modell till en publik p√• √•rskurs 8 medan den andra antar en gymnasieelev. Men alla tre modeller genererade svar som skulle kunna √∂vertyga en oinformerad anv√§ndare om att h√§ndelsen var verklig.

Prompttekniker som _metaprompting_ och _temperaturkonfiguration_ kan minska modellens fabriceringar till viss del. Nya promptteknik _arkitekturer_ integrerar ocks√• s√∂ml√∂st nya verktyg och tekniker i promptfl√∂det f√∂r att mildra eller minska n√•gra av dessa effekter.

## Fallstudie: GitHub Copilot

L√•t oss avrunda denna sektion genom att f√• en k√§nsla f√∂r hur promptteknik anv√§nds i verkliga l√∂sningar genom att titta p√• en Fallstudie: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot √§r din "AI-parprogrammerare" ‚Äì den omvandlar textpromptar till kodkompletteringar och √§r integrerad i din utvecklingsmilj√∂ (t.ex. Visual Studio Code) f√∂r en s√∂ml√∂s anv√§ndarupplevelse. Som dokumenterat i serien av blogginl√§gg nedan var den tidigaste versionen baserad p√• OpenAI Codex-modellen ‚Äì d√§r ingenj√∂rer snabbt ins√•g behovet av att finjustera modellen och utveckla b√§ttre prompttekniker f√∂r att f√∂rb√§ttra kodkvaliteten. I juli [lanserade de en f√∂rb√§ttrad AI-modell som g√•r bortom Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) f√∂r √§nnu snabbare f√∂rslag.

L√§s inl√§ggen i ordning f√∂r att f√∂lja deras l√§randeresa.

- **Maj 2023** | [GitHub Copilot blir b√§ttre p√• att f√∂rst√• din kod](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inuti GitHub: Arbeta med LLM:erna bakom GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jun 2023** | [Hur man skriver b√§ttre promptar f√∂r GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [.. GitHub Copilot g√•r bortom Codex med f√∂rb√§ttrad AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En utvecklares guide till promptteknik och LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hur man bygger en f√∂retags-LLM-app: L√§rdomar fr√•n GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ocks√• bl√§ddra i deras [Engineering-blogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) f√∂r fler inl√§gg som [det h√§r](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som visar hur dessa modeller och tekniker _till√§mpas_ f√∂r att driva verkliga applikationer.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Promptkonstruktion

Vi har sett varf√∂r promptteknik √§r viktigt ‚Äì nu ska vi f√∂rst√• hur promptar _konstrueras_ s√• att vi kan utv√§rdera olika tekniker f√∂r mer effektiv promptdesign.

### Grundl√§ggande prompt

L√•t oss b√∂rja med den grundl√§ggande prompten: en textinmatning som skickas till modellen utan annan kontext. H√§r √§r ett exempel ‚Äì n√§r vi skickar de f√∂rsta orden i USA:s nationals√•ng till OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) s√• _fyller_ den genast i de f√∂ljande raderna, vilket illustrerar grundl√§ggande f√∂ruts√§gelsebeteende.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det l√•ter som att du b√∂rjar med texten till "The Star-Spangled Banner," USA:s nationals√•ng. Den fullst√§ndiga texten √§r ... |

### Komplex prompt

Nu l√§gger vi till kontext och instruktioner till den grundl√§ggande prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) l√•ter oss konstruera en komplex prompt som en samling _meddelanden_ med:

- In- och utdatapar som speglar _anv√§ndarens_ input och _assistents_ svar.
- Systemmeddelande som s√§tter kontext f√∂r assistentens beteende eller personlighet.

Beg√§ran √§r nu i formen nedan d√§r _tokenisering_ effektivt f√•ngar relevant information fr√•n kontext och konversation. Att √§ndra systemkontexten kan vara lika avg√∂rande f√∂r kvaliteten p√• svar som vilka anv√§ndaring√•ngar som ges.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I exemplen ovan var anv√§ndarprompten en enkel textfr√•ga som kan tolkas som en beg√§ran om information. Med _instruktions_ promptar kan vi anv√§nda den texten f√∂r att specificera en uppgift mer detaljerat, vilket ger AI b√§ttre v√§gledning. H√§r √§r ett exempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruktionstyp    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivning av inb√∂rdeskriget                                                                                                                                                                                                   | _returnerade ett enkelt stycke_                                                                                              | Enkel              |
| Skriv en beskrivning av inb√∂rdeskriget. Ange viktiga datum och h√§ndelser och beskriv deras betydelse                                                                                                                                     | _returnerade ett stycke f√∂ljt av en lista med viktiga h√§ndelsedatum och beskrivningar_                                             | Komplext             |
| Skriv en beskrivning av inb√∂rdeskriget i 1 stycke. Ge 3 punkter med viktiga datum och deras betydelse. Ge 3 punkter till med viktiga historiska personer och deras insatser. Returnera resultatet som en JSON-fil | _returnerar mer detaljerad information i en textruta, formaterad som JSON som du kan kopiera och validera efter behov_ | Komplext. Formaterat. |

## Prim√§rt inneh√•ll

I ovanst√•ende exempel var prompten fortfarande ganska √∂ppen, vilket till√§t LLM att sj√§lv avg√∂ra vilken del av dess f√∂rtr√§nade dataset som var relevant. Med designm√∂nstret _prim√§rt inneh√•ll_ delas inmatningstexten upp i tv√• delar:

- en instruktion (√•tg√§rd)
- relevant inneh√•ll (som p√•verkar √•tg√§rden)

H√§r √§r ett exempel d√§r instruktionen √§r att "sammanfatta detta i 2 meningar".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•ng s√• stor som summan av alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r forntida civilisationer sedan f√∂re skriftlig historia. Den √§r uppkallad efter den romerska guden Jupiter.[19] N√§r man betraktar Jupiter fr√•n jorden kan den vara tillr√§ckligt ljusstark f√∂r att dess reflekterade ljus ska kasta synliga skuggor,[20] och √§r i genomsnitt det tredje ljusstarkaste naturliga objektet p√• natthimlen efter m√•nen och Venus.<br/> **Sammanfatta detta i 2 korta meningar** | Jupiter, den femte planeten fr√•n solen, √§r den st√∂rsta i solsystemet och k√§nd f√∂r att vara ett av de ljusstarkaste objekten p√• natthimlen. Den √§r uppkallad efter den romerska guden Jupiter och √§r en gasj√§tte med en massa som √§r tv√• och en halv g√•ng s√• stor som alla andra planeter tillsammans. |

Den prim√§ra inneh√•llssektionen kan anv√§ndas p√• olika s√§tt f√∂r att driva mer effektiva instruktioner:

- **Exempel** ‚Äì ist√§llet f√∂r att tala om f√∂r modellen vad den ska g√∂ra med en explicit instruktion, ge den exempel p√• vad den ska g√∂ra och l√•t den dra slutsatsen om m√∂nstret.
- **Ledtr√•dar** ‚Äì f√∂lj instruktionen med en "ledtr√•d" som f√∂rbereder svaret och v√§gleder modellen mot mer relevanta svar.
- **Mall** ‚Äì dessa √§r upprepningsbara ‚Äùrecept‚Äù f√∂r promptar med platsh√•llare (variabler) som kan anpassas med data f√∂r specifika anv√§ndningsfall.

L√•t oss utforska dessa i praktiken.

### Anv√§nda exempel

Detta √§r en metod d√§r du anv√§nder det prim√§ra inneh√•llet f√∂r att "mata modellen" med exempel p√• √∂nskat resultat f√∂r en given instruktion, och l√•ter den dra slutsatsen om m√∂nstret f√∂r det √∂nskade resultatet. Beroende p√• antalet exempel kan vi ha zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r nu av tre komponenter:

- En uppgiftsbeskrivning
- N√•gra exempel p√• √∂nskat resultat
- B√∂rjan p√• ett nytt exempel (som blir en implicit uppgiftsbeskrivning)

| Inl√§rningstyp | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot     | "The Sun is Shining". √ñvers√§tt till spanska                                                                                                            | "El Sol est√° brillando".    |
| One-shot      | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot      | Spelaren sprang baserna => Baseboll <br/> Spelaren gjorde en ace => Tennis <br/> Spelaren slog en sexa => Cricket <br/> Spelaren gjorde en slam-dunk => | Basket                      |
|               |                                                                                                                                                       |                             |

Notera hur vi beh√∂vde ge explicit instruktion ("√ñvers√§tt till spanska") i zero-shot prompting, men att den tolkas implicit i one-shot-exemplet. Few-shot-exemplet visar hur fler exempel m√∂jligg√∂r mer precisa slutsatser utan till√§ggsinstruktioner.

### Prompt-ledtr√•dar

En annan teknik f√∂r att anv√§nda prim√§rt inneh√•ll √§r att tillhandah√•lla _ledtr√•dar_ i st√§llet f√∂r exempel. H√§r ger vi modellen en puff i r√§tt riktning genom att _starta den_ med ett stycke som speglar √∂nskat svarsformat. Modellen "tar d√• ledtr√•den" att forts√§tta i samma stil.

| Antal ledtr√•dar | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•ng s√• stor som summan av alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten synliga f√∂r blotta √∂gat p√• natthimlen, och har varit k√§nt f√∂r forntida civilisationer sedan f√∂re skriftlig historia. <br/>**Sammanfatta detta**                                       | Jupiter √§r den st√∂rsta planeten i v√•rt solsystem och den femte fr√•n solen. Den √§r en gasj√§tte med en massa som √§r 1/1000 av solens, men tyngre √§n alla andra planeter tillsammans. Forntida civilisationer har k√§nt till Jupiter l√§nge, och den √§r l√§tt synlig p√• natthimlen.. |
| 1              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger s√• stor som alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r forntida civilisationer sedan f√∂re den nedtecknade historien. <br/>**Sammanfatta detta** <br/> Vad vi l√§rt oss √§r att Jupiter | √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger s√• stor som alla andra planeter tillsammans. Den √§r l√§tt synlig f√∂r blotta √∂gat och har varit k√§nd sedan urminnes tider.                       |
| 2              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger s√• stor som alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r forntida civilisationer sedan f√∂re den nedtecknade historien. <br/>**Sammanfatta detta** <br/> Topp 3 fakta vi l√§rt oss:         | 1. Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. <br/> 2. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens...<br/> 3. Jupiter har varit synlig f√∂r blotta √∂gat sedan urminnes tider ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Promptmallar

En promptmall √§r ett _f√∂rdefinierat recept f√∂r en prompt_ som kan sparas och √•teranv√§ndas vid behov f√∂r att skapa mer konsekventa anv√§ndarupplevelser i stor skala. I sin enklaste form √§r det helt enkelt en samling promptexempel som [det h√§r fr√•n OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som tillhandah√•ller b√•de de interaktiva promptkomponenterna (anv√§ndar- och systemmeddelanden) och API-drivna f√∂rfr√•gningsformat ‚Äì f√∂r att st√∂dja √•teranv√§ndning.

I en mer komplex form, som [det h√§r exemplet fr√•n LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), inneh√•ller den _platsh√•llare_ som kan ers√§ttas med data fr√•n olika k√§llor (anv√§ndarinmatning, systemkontext, externa datak√§llor etc.) f√∂r att dynamiskt generera en prompt. Detta g√∂r att vi kan skapa ett bibliotek med √•teranv√§ndbara prompts som kan anv√§ndas f√∂r att driva konsekventa anv√§ndarupplevelser **programmerbart** i stor skala.

Slutligen ligger det verkliga v√§rdet i mallar i f√∂rm√•gan att skapa och publicera _promptbibliotek_ f√∂r vertikala applikationsdom√§ner ‚Äì d√§r promptmallen nu √§r _optimerad_ f√∂r att spegla applikationsspecifik kontext eller exempel som g√∂r svaren mer relevanta och tr√§ffs√§kra f√∂r den specifika anv√§ndargruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √§r ett utm√§rkt exempel p√• detta tillv√§gag√•ngss√§tt och sammanst√§ller ett bibliotek med prompts f√∂r utbildningsomr√•det med tonvikt p√• nyckelm√•l som lektionsplanering, l√§roplansdesign, studenthandledning etc.

## St√∂djande inneh√•ll

Om vi t√§nker p√• promptkonstruktion som att ha en instruktion (uppgift) och ett m√•l (prim√§rt inneh√•ll), √§r _sekund√§rt inneh√•ll_ som ytterligare kontext vi tillhandah√•ller f√∂r att **p√•verka resultatet p√• n√•got s√§tt**. Det kan vara finjusteringsparametrar, formateringsinstruktioner, √§mnestaxonomier osv. som hj√§lper modellen att _anpassa_ sitt svar f√∂r att passa √∂nskade anv√§ndarm√•l eller f√∂rv√§ntningar.

Till exempel: Givet en kurskatalog med omfattande metadata (namn, beskrivning, niv√•, metadatataggar, l√§rare etc.) f√∂r alla tillg√§ngliga kurser i l√§roplanen:

- kan vi definiera en instruktion att "sammanfatta kurskatalogen f√∂r h√∂sten 2023"
- vi kan anv√§nda det prim√§ra inneh√•llet f√∂r att ge n√•gra exempel p√• det √∂nskade resultatet
- vi kan anv√§nda det sekund√§ra inneh√•llet f√∂r att identifiera de 5 viktigaste "taggarna"

Nu kan modellen tillhandah√•lla en sammanfattning i det format som visas av de f√• exemplen ‚Äì men om ett resultat har flera taggar kan den prioritera de 5 taggar som identifieras i det sekund√§ra inneh√•llet.

---

<!--
LEKTIONSMALL:
Denna enhet b√∂r t√§cka k√§rnkoncept #1.
F√∂rst√§rk konceptet med exempel och referenser.

KONCEPT #3:
Prompt Engineering-tekniker.
Vilka √§r n√•gra grundl√§ggande tekniker f√∂r prompt engineering?
Illustrera det med n√•gra √∂vningar.
-->

## B√§sta metoder f√∂r prompting

Nu n√§r vi vet hur prompts kan _konstrueras_, kan vi b√∂rja t√§nka p√• hur vi _designar_ dem f√∂r att spegla b√§sta praxis. Vi kan t√§nka p√• detta i tv√• delar ‚Äì att ha r√§tt _tankes√§tt_ och att till√§mpa r√§tt _tekniker_.

### Tankes√§tt f√∂r prompt engineering

Prompt engineering √§r en process av f√∂rs√∂k och misstag, s√• h√•ll tre breda v√§gledande faktorer i √•tanke:

1. **Dom√§nf√∂rst√•else √§r viktigt.** Svarens noggrannhet och relevans beror p√• den _dom√§n_ d√§r applikationen eller anv√§ndaren verkar. Anv√§nd din intuition och dom√§nkunskap f√∂r att **anpassa tekniker** ytterligare. Till exempel, definiera _dom√§nspecifika personligheter_ i dina systemprompts, eller anv√§nd _dom√§nspecifika mallar_ i dina anv√§ndarprompts. Ge sekund√§rt inneh√•ll som speglar dom√§nspecifik kontext, eller anv√§nd _dom√§nspecifika signaler och exempel_ f√∂r att styra modellen mot v√§lbekanta anv√§ndningsm√∂nster.

2. **Modellf√∂rst√•else √§r viktigt.** Vi vet att modeller √§r stokastiska till sin natur. Men modellimplementationer kan ocks√• variera i fr√•ga om tr√§ningsdatasetet de anv√§nder (f√∂rtr√§nad kunskap), de kapaciteter de tillhandah√•ller (t.ex. via API eller SDK) och vilken sorts inneh√•ll de √§r optimerade f√∂r (t.ex. kod vs. bilder vs. text). F√∂rst√• styrkor och begr√§nsningar hos den modell du anv√§nder och anv√§nd denna kunskap f√∂r att _prioritera uppgifter_ eller bygga _anpassade mallar_ som √§r optimerade f√∂r modellens kapaciteter.

3. **Iteration och validering √§r viktigt.** Modeller utvecklas snabbt, liksom teknikerna f√∂r prompt engineering. Som dom√§nexpert kan du ha annan kontext eller kriterier f√∂r _din_ specifika applikation, som kanske inte g√§ller f√∂r den bredare gemenskapen. Anv√§nd verktyg och tekniker f√∂r prompt engineering f√∂r att "kickstarta" promptkonstruktionen, iterera sedan och validera resultaten med hj√§lp av din egen intuition och dom√§nkunskap. Dokumentera dina insikter och skapa en **kunskapsbas** (t.ex. promptbibliotek) som andra kan anv√§nda som ny baslinje f√∂r snabbare iterationer i framtiden.

## B√§sta metoder

L√•t oss nu titta p√• vanliga rekommenderade b√§sta metoder fr√•n [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) och [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Vad                              | Varf√∂r                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Utv√§rdera de senaste modellerna. | Nya generationer av modeller har troligtvis f√∂rb√§ttrade funktioner och kvalitet ‚Äì men kan ocks√• inneb√§ra h√∂gre kostnader. Utv√§rdera deras p√•verkan och fatta sedan beslut om migration.                                                            |
| Separera instruktioner och kontext | Kontrollera om din modell/leverant√∂r definierar _avgr√§nsare_ f√∂r att tydligare skilja instruktioner, prim√§rt och sekund√§rt inneh√•ll. Detta hj√§lper modeller att tilldela vikter mer exakt till tokens.                                            |
| Var specifik och tydlig           | Ge fler detaljer om √∂nskad kontext, resultat, l√§ngd, format, stil osv. Detta f√∂rb√§ttrar b√•de kvalitet och konsekvens i svaren. F√•nga recept i √•teranv√§ndbara mallar.                                                                           |
| Var beskrivande, anv√§nd exempel   | Modeller svarar ofta b√§ttre p√• en ‚Äùshow and tell‚Äù-metod. B√∂rja med en `zero-shot`-approach d√§r du ger instruktion men inga exempel, prova sedan `few-shot` som f√∂rfining med n√•gra exempel p√• √∂nskat resultat. Anv√§nd analogier.                      |
| Anv√§nd signaler f√∂r att p√•b√∂rja generering | Styr modellen mot √∂nskat resultat genom att ge ledande ord eller uttryck som den kan anv√§nda som startpunkt f√∂r svaret.                                                                                                                |
| Upprepa vid behov                  | Ibland beh√∂ver modellen instruktioner upprepas. Ge instruktioner f√∂re och efter ditt prim√§ra inneh√•ll, anv√§nd b√•de instruktion och signal, etc. Iterera och validera f√∂r att se vad som fungerar.                                         |
| Ordningen √§r viktig                | Ordningen du presenterar informationen f√∂r modellen kan p√•verka resultatet, √§ven i inl√§rningsexempel, p√• grund av nylighetsbias. Prova olika alternativ f√∂r att se vad som funkar b√§st.                                                               |
| Ge modellen en "utv√§g"             | Ge modellen ett _fallback_-svar att anv√§nda om den inte kan slutf√∂ra uppgiften av n√•gon anledning. Detta kan minska risken f√∂r felaktiga eller p√•hittade svar.                                                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Som med alla b√§sta metoder, kom ih√•g att _din erfarenhet kan variera_ beroende p√• modell, uppgift och dom√§n. Anv√§nd dessa som en utg√•ngspunkt och iterera f√∂r att hitta vad som fungerar b√§st f√∂r dig. Omtolkar st√§ndigt din process f√∂r prompt engineering n√§r nya modeller och verktyg blir tillg√§ngliga, med fokus p√• processens skalbarhet och svarskvalitet.

<!--
LEKTIONSMALL:
Denna enhet b√∂r inneh√•lla en kodutmaning om till√§mpligt

UTMANING:
L√§nk till en Jupyter Notebook med endast kodkommentarer i instruktionerna (kodavsnitt √§r tomma).

L√ñSNING:
L√§nk till en kopia av den Notebook med ifyllda prompts och k√∂rd, som visar ett exempel p√• utdata.
-->

## Uppgift

Grattis! Du har n√•tt slutet av lektionen! Det √§r dags att testa n√•gra av de koncept och tekniker vi g√•tt igenom med verkliga exempel!

F√∂r v√•r uppgift kommer vi att anv√§nda en Jupyter Notebook med √∂vningar du kan utf√∂ra interaktivt. Du kan ocks√• ut√∂ka Notebooken med egna Markdown- och kodceller f√∂r att utforska id√©er och tekniker p√• egen hand.

### F√∂r att komma ig√•ng, f√∂rgrena repo:n, och sedan

- (Rekommenderat) Starta GitHub Codespaces
- (Alternativt) Klona repo:n till din lokala enhet och anv√§nd den med Docker Desktop
- (Alternativt) √ñppna Notebooken i den milj√∂ f√∂r Notebooks du f√∂redrar.

### N√§sta steg, konfigurera dina milj√∂variabler

- Kopiera filen `.env.copy` i repo-roten till `.env` och fyll i v√§rdena f√∂r `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` och `AZURE_OPENAI_DEPLOYMENT`. Kom tillbaka till avsnittet [Learning Sandbox](../../../04-prompt-engineering-fundamentals) f√∂r att l√§ra dig hur.

### Sedan, √∂ppna Jupyter Notebook

- V√§lj runtime-k√§rnan. Om du anv√§nder alternativ 1 eller 2, v√§lj bara den f√∂rvalda Python 3.10.x-k√§rnan som tillhandah√•lls av utvecklingscontainern.

Du √§r redo att k√∂ra √∂vningarna. Observera att det h√§r inte finns n√•gra _r√§tta eller felaktiga_ svar ‚Äì utan att utforska alternativ med f√∂rs√∂k och misstag och bygga intuition f√∂r vad som fungerar f√∂r en given modell och applikationsdom√§n.

_F√∂r denna anledning finns det inga Kodl√∂snings-segment i denna lektion. Ist√§llet kommer Notebooken ha Markdown-celler med titeln "Min l√∂sning:" som visar ett exempel p√• ett utdata f√∂r referens._

 <!--
LEKTIONSMALL:
Avsluta avsnittet med en sammanfattning och resurser f√∂r sj√§lvstyrt l√§rande.
-->

## Kunskapskontroll

Vilket av f√∂ljande √§r en bra prompt enligt n√•gra rimliga b√§sta praxis?

1. Visa mig en bild av en r√∂d bil
2. Visa mig en bild av en r√∂d bil av m√§rket Volvo och modellen XC90 parkerad vid en klippa med solnedg√•ng
3. Visa mig en bild av en r√∂d bil av m√§rket Volvo och modellen XC90

Svar: 2, det √§r den b√§sta prompten eftersom den ger detaljer om "vad" och g√•r in p√• specifika detaljer (inte bara vilken bil som helst utan ett specifikt m√§rke och modell) och den beskriver ocks√• helhetsmilj√∂n. 3 √§r n√§st b√§st eftersom den ocks√• inneh√•ller mycket beskrivning.

## üöÄ Utmaning

Se om du kan anv√§nda "signal"-tekniken med prompten: Fyll i meningen "Visa mig en bild av en r√∂d bil av m√§rket Volvo och ". Vad svarar den med och hur skulle du f√∂rb√§ttra det?

## Bra jobbat! Forts√§tt ditt l√§rande

Vill du l√§ra dig mer om olika koncept inom Prompt Engineering? G√• till [sidan f√∂r fortsatt l√§rande](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att hitta andra utm√§rkta resurser om detta √§mne.

G√• vidare till Lektion 5 d√§r vi tittar p√• [avancerade prompting-tekniker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfriskrivning**:
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet b√∂r du vara medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r viktig information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->