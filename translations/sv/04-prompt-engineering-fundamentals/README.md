<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0135e6c271f3ece8699050d4debbce88",
  "translation_date": "2025-10-17T19:04:55+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "sv"
}
-->
# Grundl칛ggande om Prompt Engineering

[![Grundl칛ggande om Prompt Engineering](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.sv.png)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introduktion
Det h칛r kapitlet t칛cker viktiga koncept och tekniker f칬r att skapa effektiva prompts i generativa AI-modeller. Hur du skriver din prompt till en LLM spelar ocks친 roll. En noggrant utformad prompt kan ge b칛ttre kvalitet p친 svaret. Men vad betyder egentligen termer som _prompt_ och _prompt engineering_? Och hur kan jag f칬rb칛ttra prompt _input_ som jag skickar till LLM? Det 칛r fr친gor vi kommer att f칬rs칬ka besvara i detta kapitel och n칛sta.

_Generativ AI_ kan skapa nytt inneh친ll (t.ex. text, bilder, ljud, kod etc.) som svar p친 anv칛ndarf칬rfr친gningar. Den g칬r detta med hj칛lp av _Large Language Models_ som OpenAI:s GPT ("Generative Pre-trained Transformer")-serie, som 칛r tr칛nade f칬r att anv칛nda naturligt spr친k och kod.

Anv칛ndare kan nu interagera med dessa modeller genom v칛lbekanta paradigmer som chatt, utan att beh칬va teknisk expertis eller utbildning. Modellerna 칛r _prompt-baserade_ - anv칛ndare skickar en textinput (prompt) och f친r tillbaka AI:s svar (completion). De kan sedan "chatta med AI" iterativt, i samtal med flera turer, och f칬rfina sin prompt tills svaret matchar deras f칬rv칛ntningar.

"Prompts" blir nu det prim칛ra _programmeringsgr칛nssnittet_ f칬r generativa AI-appar, som talar om f칬r modellerna vad de ska g칬ra och p친verkar kvaliteten p친 de svar som returneras. "Prompt Engineering" 칛r ett snabbt v칛xande forskningsomr친de som fokuserar p친 _design och optimering_ av prompts f칬r att leverera konsekventa och kvalitativa svar i stor skala.

## L칛randem친l

I denna lektion l칛r vi oss vad Prompt Engineering 칛r, varf칬r det 칛r viktigt och hur vi kan skapa mer effektiva prompts f칬r en given modell och applikationsm친l. Vi kommer att f칬rst친 k칛rnkoncept och b칛sta praxis f칬r prompt engineering - och l칛ra oss om en interaktiv Jupyter Notebooks "sandbox"-milj칬 d칛r vi kan se dessa koncept till칛mpas p친 verkliga exempel.

I slutet av denna lektion kommer vi att kunna:

1. F칬rklara vad prompt engineering 칛r och varf칬r det 칛r viktigt.
2. Beskriva komponenterna i en prompt och hur de anv칛nds.
3. L칛ra oss b칛sta praxis och tekniker f칬r prompt engineering.
4. Till칛mpa l칛rda tekniker p친 verkliga exempel, med hj칛lp av en OpenAI-endpoint.

## Nyckeltermer

Prompt Engineering: Praktiken att designa och f칬rfina inputs f칬r att styra AI-modeller mot att producera 칬nskade outputs.  
Tokenisering: Processen att konvertera text till mindre enheter, kallade tokens, som en modell kan f칬rst친 och bearbeta.  
Instruktionsanpassade LLM: Stora spr친kmodeller (LLMs) som har finjusterats med specifika instruktioner f칬r att f칬rb칛ttra deras svarsnoggrannhet och relevans.

## L칛rande Sandbox

Prompt engineering 칛r f칬r n칛rvarande mer konst 칛n vetenskap. Det b칛sta s칛ttet att f칬rb칛ttra v친r intuition f칬r det 칛r att _칬va mer_ och anta en trial-and-error-approach som kombinerar applikationsdom칛nexpertis med rekommenderade tekniker och modell-specifika optimeringar.

Jupyter Notebook som f칬ljer med denna lektion erbjuder en _sandbox_-milj칬 d칛r du kan testa det du l칛r dig - under tiden eller som en del av kodutmaningen i slutet. F칬r att k칬ra 칬vningarna beh칬ver du:

1. **En Azure OpenAI API-nyckel** - tj칛nstens endpoint f칬r en distribuerad LLM.  
2. **En Python Runtime** - d칛r Notebook kan k칬ras.  
3. **Lokala milj칬variabler** - _slutf칬r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst)-stegen nu f칬r att bli redo_.  

Notebooken kommer med _start칬vningar_ - men du uppmuntras att l칛gga till egna _Markdown_- (beskrivning) och _Code_- (promptf칬rfr친gningar) sektioner f칬r att testa fler exempel eller id칠er - och bygga din intuition f칬r promptdesign.

## Illustrerad guide

Vill du f친 en 칬verblick 칬ver vad denna lektion t칛cker innan du dyker in? Kolla in denna illustrerade guide, som ger dig en k칛nsla f칬r de viktigaste 칛mnena som behandlas och de viktigaste insikterna att t칛nka p친 i varje avsnitt. Lektionens v칛gkarta tar dig fr친n att f칬rst친 k칛rnkoncept och utmaningar till att hantera dem med relevanta tekniker och b칛sta praxis f칬r prompt engineering. Observera att avsnittet "Avancerade tekniker" i denna guide h칛nvisar till inneh친ll som behandlas i _n칛sta_ kapitel av denna kursplan.

![Illustrerad guide till Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.sv.png)

## V친rt startup

Nu ska vi prata om hur _detta 칛mne_ relaterar till v친rt startup-uppdrag att [f칬ra AI-innovation till utbildning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi vill bygga AI-drivna applikationer f칬r _personligt l칛rande_ - s친 l친t oss fundera p친 hur olika anv칛ndare av v친r applikation kan "designa" prompts:

- **Administrat칬rer** kan be AI att _analysera kursplanedata f칬r att identifiera luckor i t칛ckningen_. AI kan sammanfatta resultaten eller visualisera dem med kod.  
- **L칛rare** kan be AI att _skapa en lektionsplan f칬r en m친lgrupp och ett 칛mne_. AI kan bygga den personliga planen i ett specificerat format.  
- **Studenter** kan be AI att _l칛ra dem ett sv친rt 칛mne_. AI kan nu v칛gleda studenter med lektioner, tips och exempel anpassade till deras niv친.  

Det 칛r bara toppen av isberget. Kolla in [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - ett 칬ppet bibliotek med prompts som har kuraterats av utbildningsexperter - f칬r att f친 en bredare k칛nsla av m칬jligheterna! _Testa att k칬ra n친gra av dessa prompts i sandboxen eller med OpenAI Playground f칬r att se vad som h칛nder!_

<!--
LEKTIONSMALL:
Denna enhet b칬r t칛cka k칛rnkoncept #1.
St칛rk konceptet med exempel och referenser.

KONCEPT #1:
Prompt Engineering.
Definiera det och f칬rklara varf칬r det beh칬vs.
-->

## Vad 칛r Prompt Engineering?

Vi b칬rjade denna lektion med att definiera **Prompt Engineering** som processen att _designa och optimera_ textinputs (prompts) f칬r att leverera konsekventa och kvalitativa svar (completions) f칬r ett givet applikationsm친l och modell. Vi kan t칛nka p친 detta som en tv친stegsprocess:

- _designa_ den initiala prompten f칬r en given modell och m친l  
- _f칬rfina_ prompten iterativt f칬r att f칬rb칛ttra kvaliteten p친 svaret  

Detta 칛r n칬dv칛ndigtvis en trial-and-error-process som kr칛ver anv칛ndarens intuition och anstr칛ngning f칬r att f친 optimala resultat. S친 varf칬r 칛r det viktigt? F칬r att besvara den fr친gan m친ste vi f칬rst f칬rst친 tre koncept:

- _Tokenisering_ = hur modellen "ser" prompten  
- _Bas-LLMs_ = hur grundmodellen "bearbetar" en prompt  
- _Instruktionsanpassade LLMs_ = hur modellen nu kan se "uppgifter"  

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ d칛r olika modeller (eller versioner av en modell) kan tokenisera samma prompt p친 olika s칛tt. Eftersom LLMs 칛r tr칛nade p친 tokens (och inte p친 r친text), har s칛ttet som prompts tokeniseras en direkt p친verkan p친 kvaliteten p친 det genererade svaret.

F칬r att f친 en intuition f칬r hur tokenisering fungerar, testa verktyg som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) som visas nedan. Kopiera in din prompt - och se hur den konverteras till tokens, och var uppm칛rksam p친 hur blanksteg och skiljetecken hanteras. Observera att detta exempel visar en 칛ldre LLM (GPT-3) - s친 att testa detta med en nyare modell kan ge ett annat resultat.

![Tokenisering](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.sv.png)

### Koncept: Grundmodeller

N칛r en prompt har tokeniserats 칛r den prim칛ra funktionen f칬r ["Bas-LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grundmodellen) att f칬ruts칛ga n칛sta token i den sekvensen. Eftersom LLMs 칛r tr칛nade p친 massiva textdatam칛ngder har de en god k칛nsla f칬r de statistiska relationerna mellan tokens och kan g칬ra den f칬ruts칛gelsen med viss s칛kerhet. Observera att de inte f칬rst친r _betydelsen_ av orden i prompten eller token; de ser bara ett m칬nster som de kan "komplettera" med sin n칛sta f칬ruts칛gelse. De kan forts칛tta att f칬ruts칛ga sekvensen tills anv칛ndaren avbryter eller n친gon f칬rutbest칛md villkor uppfylls.

Vill du se hur prompt-baserad completion fungerar? Ange prompten ovan i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinst칛llningarna. Systemet 칛r konfigurerat f칬r att behandla prompts som informationsf칬rfr친gningar - s친 du b칬r se en completion som uppfyller detta sammanhang.

Men vad h칛nder om anv칛ndaren ville se n친got specifikt som uppfyller vissa kriterier eller m친l? Det 칛r h칛r _instruktionsanpassade_ LLMs kommer in i bilden.

![Bas-LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.sv.png)

### Koncept: Instruktionsanpassade LLMs

En [Instruktionsanpassad LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) b칬rjar med grundmodellen och finjusterar den med exempel eller input/output-par (t.ex. meddelanden i flera turer) som kan inneh친lla tydliga instruktioner - och svaret fr친n AI f칬rs칬ker f칬lja den instruktionen.

Detta anv칛nder tekniker som f칬rst칛rkningsinl칛rning med m칛nsklig feedback (RLHF) som kan tr칛na modellen att _f칬lja instruktioner_ och _l칛ra sig av feedback_ s친 att den producerar svar som 칛r b칛ttre anpassade till praktiska till칛mpningar och mer relevanta f칬r anv칛ndarens m친l.

L친t oss testa det - g친 tillbaka till prompten ovan, men 칛ndra nu _systemmeddelandet_ f칬r att ge f칬ljande instruktion som kontext:

> _Sammanfatta inneh친llet du f친r f칬r en andra klassens elev. H친ll resultatet till ett stycke med 3-5 punkter._

Se hur resultatet nu 칛r anpassat f칬r att 친terspegla det 칬nskade m친let och formatet? En l칛rare kan nu direkt anv칛nda detta svar i sina presentationer f칬r den klassen.

![Instruktionsanpassad LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.sv.png)

## Varf칬r beh칬ver vi Prompt Engineering?

Nu n칛r vi vet hur prompts bearbetas av LLMs, l친t oss prata om _varf칬r_ vi beh칬ver prompt engineering. Svaret ligger i det faktum att nuvarande LLMs har ett antal utmaningar som g칬r _p친litliga och konsekventa completions_ sv친rare att uppn친 utan att l칛gga ner anstr칛ngning p친 promptkonstruktion och optimering. Till exempel:

1. **Modellsvar 칛r stokastiska.** _Samma prompt_ kommer sannolikt att producera olika svar med olika modeller eller modellversioner. Och det kan till och med producera olika resultat med _samma modell_ vid olika tillf칛llen. _Prompt engineering-tekniker kan hj칛lpa oss att minimera dessa variationer genom att ge b칛ttre riktlinjer_.  

1. **Modeller kan fabricera svar.** Modeller 칛r f칬rtr칛nade med _stora men begr칛nsade_ datam칛ngder, vilket inneb칛r att de saknar kunskap om koncept utanf칬r det tr칛ningsomr친det. Som ett resultat kan de producera completions som 칛r felaktiga, p친hittade eller direkt mots칛gande till k칛nda fakta. _Prompt engineering-tekniker hj칛lper anv칛ndare att identifiera och mildra s친dana fabriceringar, t.ex. genom att be AI om k칛llh칛nvisningar eller resonemang_.  

1. **Modellers kapacitet varierar.** Nyare modeller eller modellgenerationer kommer att ha rikare kapacitet men ocks친 medf칬ra unika egenheter och avv칛gningar i kostnad och komplexitet. _Prompt engineering kan hj칛lpa oss att utveckla b칛sta praxis och arbetsfl칬den som abstraherar bort skillnader och anpassar sig till modell-specifika krav p친 skalbara, s칬ml칬sa s칛tt_.  

L친t oss se detta i praktiken i OpenAI eller Azure OpenAI Playground:

- Anv칛nd samma prompt med olika LLM-distributioner (t.ex. OpenAI, Azure OpenAI, Hugging Face) - s친g du variationerna?  
- Anv칛nd samma prompt upprepade g친nger med _samma_ LLM-distribution (t.ex. Azure OpenAI Playground) - hur skiljde sig dessa variationer?  

### Exempel p친 fabriceringar

I denna kurs anv칛nder vi termen **"fabricering"** f칬r att h칛nvisa till fenomenet d칛r LLMs ibland genererar faktuellt felaktig information p친 grund av begr칛nsningar i deras tr칛ning eller andra faktorer. Du kanske ocks친 har h칬rt detta refereras till som _"hallucinationer"_ i popul칛ra artiklar eller forskningsrapporter. Vi rekommenderar dock starkt att anv칛nda termen _"fabricering"_ s친 att vi inte av misstag antropomorfiserar beteendet genom att tillskriva en m칛nsklig egenskap till ett maskindrivet resultat. Detta f칬rst칛rker ocks친 [Riktlinjer f칬r ansvarsfull AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) ur ett terminologiperspektiv, och tar bort termer som kan anses vara st칬tande eller icke-inkluderande i vissa sammanhang.

Vill du f친 en k칛nsla f칬r hur fabriceringar fungerar? T칛nk p친 en prompt som instruerar AI att generera inneh친ll f칬r ett icke-existerande 칛mne (f칬r att s칛kerst칛lla att det inte finns i tr칛ningsdatam칛ngden). Till exempel - jag testade denna prompt:

> **Prompt:** skapa en lektionsplan om det Marsianska kriget 친r 2076.
En webbs칬kning visade att det finns fiktiva ber칛ttelser (t.ex. tv-serier eller b칬cker) om krig p친 Mars - men inga fr친n 친r 2076. Sunt f칬rnuft s칛ger ocks친 att 2076 칛r _i framtiden_ och d칛rf칬r inte kan kopplas till en verklig h칛ndelse.

S친 vad h칛nder n칛r vi k칬r denna prompt med olika LLM-leverant칬rer?

> **Svar 1**: OpenAI Playground (GPT-35)

![Svar 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.sv.png)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Svar 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.sv.png)

> **Svar 3**: Hugging Face Chat Playground (LLama-2)

![Svar 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.sv.png)

Som f칬rv칛ntat producerar varje modell (eller modellversion) n친got olika svar tack vare stokastiskt beteende och variationer i modellens kapacitet. Till exempel riktar sig en modell till en 친ttondeklassare medan en annan antar att anv칛ndaren 칛r gymnasieelev. Men alla tre modeller genererade svar som skulle kunna 칬vertyga en oinformerad anv칛ndare om att h칛ndelsen var verklig.

Prompttekniker som _metaprompting_ och _temperaturkonfiguration_ kan minska modellens fabriceringar till viss del. Nya arkitekturer f칬r promptdesign integrerar ocks친 nya verktyg och tekniker smidigt i promptfl칬det f칬r att mildra eller minska dessa effekter.

## Fallstudie: GitHub Copilot

L친t oss avsluta denna sektion med att f친 en k칛nsla f칬r hur promptdesign anv칛nds i verkliga l칬sningar genom att titta p친 en fallstudie: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot 칛r din "AI-parprogrammerare" - den omvandlar textprompter till kodf칬rslag och 칛r integrerad i din utvecklingsmilj칬 (t.ex. Visual Studio Code) f칬r en smidig anv칛ndarupplevelse. Som dokumenterat i en serie bloggar nedan, baserades den tidigaste versionen p친 OpenAI Codex-modellen - med ingenj칬rer som snabbt ins친g behovet av att finjustera modellen och utveckla b칛ttre prompttekniker f칬r att f칬rb칛ttra kodkvaliteten. I juli [lanserade de en f칬rb칛ttrad AI-modell som g친r bortom Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) f칬r 칛nnu snabbare f칬rslag.

L칛s inl칛ggen i ordning f칬r att f칬lja deras l칛rande resa.

- **Maj 2023** | [GitHub Copilot blir b칛ttre p친 att f칬rst친 din kod](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inuti GitHub: Arbeta med LLM:erna bakom GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jun 2023** | [Hur man skriver b칛ttre prompter f칬r GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jul 2023** | [.. GitHub Copilot g친r bortom Codex med f칬rb칛ttrad AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En utvecklares guide till promptdesign och LLM:er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hur man bygger en f칬retagsapp med LLM:er: L칛rdomar fr친n GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ocks친 bl칛ddra i deras [Engineering-blogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) f칬r fler inl칛gg som [detta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som visar hur dessa modeller och tekniker _till칛mpas_ f칬r att driva verkliga applikationer.

---

## Konstruktion av prompter

Vi har sett varf칬r promptdesign 칛r viktig - nu ska vi f칬rst친 hur prompter _konstrueras_ s친 att vi kan utv칛rdera olika tekniker f칬r mer effektiv promptdesign.

### Grundl칛ggande prompt

L친t oss b칬rja med den grundl칛ggande prompten: en textinmatning som skickas till modellen utan n친gon annan kontext. H칛r 칛r ett exempel - n칛r vi skickar de f칬rsta orden i USA:s nationals친ng till OpenAI:s [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) kompletterar den omedelbart svaret med de f칬ljande raderna, vilket illustrerar det grundl칛ggande f칬ruts칛gelsebeteendet.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det verkar som att du b칬rjar med texten till "The Star-Spangled Banner", USA:s nationals친ng. Den fullst칛ndiga texten 칛r ...                |

### Komplex prompt

Nu ska vi l칛gga till kontext och instruktioner till den grundl칛ggande prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) l친ter oss konstruera en komplex prompt som en samling _meddelanden_ med:

- Inmatnings-/utmatningspar som reflekterar _anv칛ndarens_ inmatning och _assistentens_ svar.
- Systemmeddelande som s칛tter kontexten f칬r assistentens beteende eller personlighet.

Beg칛ran ser nu ut som nedan, d칛r _tokeniseringen_ effektivt f친ngar relevant information fr친n kontext och konversation. Att 칛ndra systemkontexten kan vara lika avg칬rande f칬r kvaliteten p친 svaren som de inmatningar som anv칛ndaren tillhandah친ller.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I ovanst친ende exempel var anv칛ndarens prompt en enkel textfr친ga som kan tolkas som en beg칛ran om information. Med _instruktionsprompter_ kan vi anv칛nda den texten f칬r att specificera en uppgift mer detaljerat och ge b칛ttre v칛gledning till AI:n. H칛r 칛r ett exempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Typ av instruktion  |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivning av inb칬rdeskriget                                                                                                                                                                                                 | _returnerade ett enkelt stycke_                                                                                            | Enkel               |
| Skriv en beskrivning av inb칬rdeskriget. Ange viktiga datum och h칛ndelser och beskriv deras betydelse                                                                                                                                   | _returnerade ett stycke f칬ljt av en lista med viktiga datum och deras betydelse_                                           | Komplex             |
| Skriv en beskrivning av inb칬rdeskriget i ett stycke. Ange 3 punkter med viktiga datum och deras betydelse. Ange 3 ytterligare punkter med viktiga historiska personer och deras bidrag. Returnera svaret som en JSON-fil.               | _returnerade mer omfattande detaljer i en textruta, formaterad som JSON som du kan kopiera och klistra in i en fil_        | Komplex. Formaterad |

## Prim칛rt inneh친ll

I ovanst친ende exempel var prompten fortfarande ganska 칬ppen, vilket till칛t LLM att avg칬ra vilken del av dess f칬rtr칛nade dataset som var relevant. Med designm칬nstret _prim칛rt inneh친ll_ delas inmatningstexten upp i tv친 delar:

- en instruktion (친tg칛rd)
- relevant inneh친ll (som p친verkar 친tg칛rden)

H칛r 칛r ett exempel d칛r instruktionen 칛r att "sammanfatta detta i 2 meningar".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter 칛r den femte planeten fr친n solen och den st칬rsta i solsystemet. Det 칛r en gasj칛tte med en massa som 칛r en tusendel av solens, men tv친 och en halv g친nger st칬rre 칛n alla andra planeter i solsystemet tillsammans. Jupiter 칛r en av de ljusaste objekten som 칛r synliga f칬r blotta 칬gat p친 natthimlen och har varit k칛nd f칬r antika civilisationer sedan f칬re den skrivna historien. Den 칛r uppkallad efter den romerska guden Jupiter.[19] N칛r den ses fr친n jorden kan Jupiter vara tillr칛ckligt ljus f칬r att dess reflekterade ljus ska kasta synliga skuggor,[20] och 칛r i genomsnitt det tredje ljusaste naturliga objektet p친 natthimlen efter m친nen och Venus. <br/> **Sammanfatta detta i 2 korta meningar** | Jupiter, den femte planeten fr친n solen, 칛r den st칬rsta i solsystemet och 칛r k칛nd f칬r att vara ett av de ljusaste objekten p친 natthimlen. Uppkallad efter den romerska guden Jupiter, 칛r det en gasj칛tte vars massa 칛r tv친 och en halv g친nger st칬rre 칛n alla andra planeter i solsystemet tillsammans. |

Segmentet med prim칛rt inneh친ll kan anv칛ndas p친 olika s칛tt f칬r att driva mer effektiva instruktioner:

- **Exempel** - ist칛llet f칬r att s칛ga till modellen vad den ska g칬ra med en explicit instruktion, ge den exempel p친 vad den ska g칬ra och l친t den dra slutsatser om m칬nstret.
- **Ledtr친dar** - f칬lj instruktionen med en "ledtr친d" som f칬rbereder modellen och guidar den mot mer relevanta svar.
- **Mallar** - dessa 칛r 친teranv칛ndbara "recept" f칬r prompter med platsh친llare (variabler) som kan anpassas med data f칬r specifika anv칛ndningsfall.

L친t oss utforska dessa i praktiken.

### Anv칛nda exempel

Detta 칛r en metod d칛r du anv칛nder det prim칛ra inneh친llet f칬r att "mata modellen" med n친gra exempel p친 칬nskad output f칬r en given instruktion och l친ter den dra slutsatser om m칬nstret f칬r den 칬nskade outputen. Beroende p친 antalet exempel som tillhandah친lls kan vi ha zero-shot prompting, one-shot prompting, few-shot prompting etc.

Prompten best친r nu av tre komponenter:

- En uppgiftsbeskrivning
- N친gra exempel p친 칬nskad output
- B칬rjan p친 ett nytt exempel (som blir en implicit uppgiftsbeskrivning)

| L칛rningstyp | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot   | "Solen skiner". 칐vers칛tt till spanska                                                                                                                | "El Sol est치 brillando".    |
| One-shot    | "Solen skiner" => ""El Sol est치 brillando". <br> "Det 칛r en kall och bl친sig dag" =>                                                                   | "Es un d칤a fr칤o y ventoso". |
| Few-shot    | Spelaren sprang runt baserna => Baseball <br/> Spelaren slog en serve => Tennis <br/> Spelaren slog en sexa => Cricket <br/> Spelaren gjorde en slam-dunk => | Basketboll                 |
|             |                                                                                                                                                       |                             |

Observera hur vi var tvungna att ge en explicit instruktion ("칐vers칛tt till spanska") i zero-shot prompting, men det blir implicit i one-shot prompting-exemplet. Few-shot-exemplet visar hur fler exempel g칬r att modeller kan dra mer exakta slutsatser utan ytterligare instruktioner.

### Ledtr친dar i prompten

En annan teknik f칬r att anv칛nda prim칛rt inneh친ll 칛r att ge _ledtr친dar_ ist칛llet f칬r exempel. I detta fall ger vi modellen en knuff i r칛tt riktning genom att _starta den_ med en snippet som reflekterar det 칬nskade svarformatet. Modellen "tar ledtr친den" och forts칛tter i samma stil.

| Antal ledtr친dar | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :-------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0               | Jupiter 칛r den femte planeten fr친n solen och den st칬rsta i solsystemet. Det 칛r en gasj칛tte med en massa som 칛r en tusendel av solens, men tv친 och en halv g친nger st칬rre 칛n alla andra planeter i solsystemet tillsammans. Jupiter 칛r en av de ljusaste objekten som 칛r synliga f칬r blotta 칬gat p친 natthimlen och har varit k칛nd f칬r antika civilisationer sedan f칬re den skrivna historien. <br/>**Sammanfatta Detta**                                       | Jupiter 칛r den st칬rsta planeten i v친rt solsystem och den femte fr친n solen. Det 칛r en gasj칛tte med en massa som 칛r 1/1000 av solens, men den 칛r tyngre 칛n alla andra planeter tillsammans. Antika civilisationer har k칛nt till Jupiter l칛nge, och den 칛r l칛tt synlig p친 natthimlen. |
| 1              | Jupiter 칛r den femte planeten fr친n solen och den st칬rsta i solsystemet. Det 칛r en gasj칛tte med en massa som 칛r en tusendel av solens, men tv친 och en halv g친nger st칬rre 칛n alla andra planeter i solsystemet tillsammans. Jupiter 칛r ett av de ljusstarkaste objekten som 칛r synliga f칬r blotta 칬gat p친 natthimlen och har varit k칛nt f칬r antika civilisationer sedan f칬re den skrivna historien. <br/>**Sammanfatta detta** <br/> Det vi l칛rde oss 칛r att Jupiter | 칛r den femte planeten fr친n solen och den st칬rsta i solsystemet. Det 칛r en gasj칛tte med en massa som 칛r en tusendel av solens, men tv친 och en halv g친nger st칬rre 칛n alla andra planeter tillsammans. Den 칛r l칛tt synlig f칬r blotta 칬gat och har varit k칛nd sedan antiken.                        |
| 2              | Jupiter 칛r den femte planeten fr친n solen och den st칬rsta i solsystemet. Det 칛r en gasj칛tte med en massa som 칛r en tusendel av solens, men tv친 och en halv g친nger st칬rre 칛n alla andra planeter i solsystemet tillsammans. Jupiter 칛r ett av de ljusstarkaste objekten som 칛r synliga f칬r blotta 칬gat p친 natthimlen och har varit k칛nt f칬r antika civilisationer sedan f칬re den skrivna historien. <br/>**Sammanfatta detta** <br/> Topp 3 fakta vi l칛rde oss:         | 1. Jupiter 칛r den femte planeten fr친n solen och den st칬rsta i solsystemet. <br/> 2. Det 칛r en gasj칛tte med en massa som 칛r en tusendel av solens...<br/> 3. Jupiter har varit synlig f칬r blotta 칬gat sedan antiken ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Promptmallar

En promptmall 칛r ett _f칬rdefinierat recept f칬r en prompt_ som kan sparas och 친teranv칛ndas vid behov f칬r att skapa mer konsekventa anv칛ndarupplevelser i stor skala. I sin enklaste form 칛r det helt enkelt en samling av exempel p친 prompts, som [detta fr친n OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), som inneh친ller b친de interaktiva promptkomponenter (anv칛ndar- och systemmeddelanden) och API-drivna beg칛randeformat - f칬r att st칬dja 친teranv칛ndning.

I sin mer komplexa form, som [detta exempel fr친n LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), inneh친ller den _platsh친llare_ som kan ers칛ttas med data fr친n olika k칛llor (anv칛ndarinmatning, systemkontext, externa datak칛llor etc.) f칬r att dynamiskt generera en prompt. Detta g칬r det m칬jligt att skapa ett bibliotek med 친teranv칛ndbara prompts som kan anv칛ndas f칬r att driva konsekventa anv칛ndarupplevelser **programmerbart** i stor skala.

Slutligen ligger det verkliga v칛rdet av mallar i m칬jligheten att skapa och publicera _promptbibliotek_ f칬r vertikala applikationsdom칛ner - d칛r promptmallen nu 칛r _optimerad_ f칬r att 친terspegla applikationsspecifik kontext eller exempel som g칬r svaren mer relevanta och korrekta f칬r den riktade anv칛ndargruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) 칛r ett utm칛rkt exempel p친 detta tillv칛gag친ngss칛tt, d칛r ett bibliotek med prompts f칬r utbildningsdom칛nen kurateras med fokus p친 viktiga m친l som lektionsplanering, l칛roplansdesign, handledning av studenter etc.

## St칬djande inneh친ll

Om vi t칛nker p친 promptkonstruktion som att ha en instruktion (uppgift) och ett m친l (prim칛rt inneh친ll), s친 칛r _sekund칛rt inneh친ll_ som ytterligare kontext vi tillhandah친ller f칬r att **p친verka resultatet p친 n친got s칛tt**. Det kan vara justeringsparametrar, formateringsinstruktioner, 칛mnestaxonomier etc. som kan hj칛lpa modellen att _anpassa_ sitt svar f칬r att passa de 칬nskade anv칛ndarm친len eller f칬rv칛ntningarna.

Till exempel: Givet en kurskatalog med omfattande metadata (namn, beskrivning, niv친, metadatataggar, instrukt칬r etc.) om alla tillg칛ngliga kurser i l칛roplanen:

- vi kan definiera en instruktion f칬r att "sammanfatta kurskatalogen f칬r h칬sten 2023"
- vi kan anv칛nda det prim칛ra inneh친llet f칬r att tillhandah친lla n친gra exempel p친 det 칬nskade resultatet
- vi kan anv칛nda det sekund칛ra inneh친llet f칬r att identifiera de 5 fr칛msta "taggarna" av intresse.

Nu kan modellen tillhandah친lla en sammanfattning i det format som visas av de f친 exemplen - men om ett resultat har flera taggar kan den prioritera de 5 taggar som identifierats i det sekund칛ra inneh친llet.

---

<!--
LEKTIONSMALL:
Denna enhet b칬r t칛cka k칛rnkoncept #1.
F칬rst칛rk konceptet med exempel och referenser.

KONCEPT #3:
Tekniker f칬r promptkonstruktion.
Vilka 칛r n친gra grundl칛ggande tekniker f칬r promptkonstruktion?
Illustrera med n친gra 칬vningar.
-->

## B칛sta praxis f칬r promptkonstruktion

Nu n칛r vi vet hur prompts kan _konstrueras_ kan vi b칬rja fundera p친 hur vi ska _designa_ dem f칬r att 친terspegla b칛sta praxis. Vi kan t칛nka p친 detta i tv친 delar - att ha r칛tt _inst칛llning_ och att till칛mpa r칛tt _tekniker_.

### Inst칛llning f칬r promptkonstruktion

Promptkonstruktion 칛r en process av f칬rs칬k och misstag, s친 h친ll tre breda v칛gledande faktorer i 친tanke:

1. **Dom칛nf칬rst친else 칛r viktigt.** Svarens noggrannhet och relevans 칛r en funktion av _dom칛nen_ d칛r applikationen eller anv칛ndaren verkar. Anv칛nd din intuition och dom칛nexpertis f칬r att **anpassa tekniker** ytterligare. Definiera till exempel _dom칛nspecifika personligheter_ i dina systemprompts, eller anv칛nd _dom칛nspecifika mallar_ i dina anv칛ndarprompts. Tillhandah친ll sekund칛rt inneh친ll som 친terspeglar dom칛nspecifika kontexter, eller anv칛nd _dom칛nspecifika ledtr친dar och exempel_ f칬r att v칛gleda modellen mot bekanta anv칛ndningsm칬nster.

2. **Modellf칬rst친else 칛r viktigt.** Vi vet att modeller 칛r stokastiska till sin natur. Men modellimplementeringar kan ocks친 variera n칛r det g칛ller tr칛ningsdatasetet de anv칛nder (f칬rtr칛nad kunskap), de funktioner de tillhandah친ller (t.ex. via API eller SDK) och typen av inneh친ll de 칛r optimerade f칬r (t.ex. kod vs. bilder vs. text). F칬rst친 styrkorna och begr칛nsningarna hos den modell du anv칛nder och anv칛nd den kunskapen f칬r att _prioritera uppgifter_ eller bygga _anpassade mallar_ som 칛r optimerade f칬r modellens kapabiliteter.

3. **Iteration och validering 칛r viktigt.** Modeller utvecklas snabbt, och det g칬r 칛ven teknikerna f칬r promptkonstruktion. Som dom칛nexpert kan du ha annan kontext eller kriterier f칬r _din_ specifika applikation, som kanske inte g칛ller f칬r den bredare gemenskapen. Anv칛nd verktyg och tekniker f칬r promptkonstruktion f칬r att "starta upp" promptkonstruktionen, iterera och validera resultaten med hj칛lp av din egen intuition och dom칛nexpertis. Dokumentera dina insikter och skapa en **kunskapsbas** (t.ex. promptbibliotek) som kan anv칛ndas som en ny baslinje av andra f칬r snabbare iterationer i framtiden.

## B칛sta praxis

L친t oss nu titta p친 vanliga b칛sta praxis som rekommenderas av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) och [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst)-praktiker.

| Vad                               | Varf칬r                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Utv칛rdera de senaste modellerna.  | Nya modellgenerationer har sannolikt f칬rb칛ttrade funktioner och kvalitet - men kan ocks친 medf칬ra h칬gre kostnader. Utv칛rdera dem f칬r p친verkan och fatta sedan migrationsbeslut.                                                                      |
| Separera instruktioner och kontext| Kontrollera om din modell/leverant칬r definierar _avgr칛nsare_ f칬r att tydligare skilja instruktioner, prim칛rt och sekund칛rt inneh친ll. Detta kan hj칛lpa modeller att tilldela vikter mer exakt till tokens.                                          |
| Var specifik och tydlig           | Ge fler detaljer om 칬nskad kontext, resultat, l칛ngd, format, stil etc. Detta kommer att f칬rb칛ttra b친de kvaliteten och konsistensen i svaren. F친nga recept i 친teranv칛ndbara mallar.                                                                  |
| Var beskrivande, anv칛nd exempel   | Modeller kan svara b칛ttre p친 en "visa och ber칛tta"-metod. B칬rja med en `zero-shot`-metod d칛r du ger en instruktion (men inga exempel) och prova sedan `few-shot` som en f칬rfining, genom att ge n친gra exempel p친 det 칬nskade resultatet. Anv칛nd analogier. |
| Anv칛nd ledtr친dar f칬r att starta svar| Ge en knuff mot ett 칬nskat resultat genom att ge n친gra inledande ord eller fraser som den kan anv칛nda som startpunkt f칬r svaret.                                                                                                               |
| Upprepa                           | Ibland kan du beh칬va upprepa dig f칬r modellen. Ge instruktioner f칬re och efter ditt prim칛ra inneh친ll, anv칛nd en instruktion och en ledtr친d etc. Iterera och validera f칬r att se vad som fungerar.                                                  |
| Ordning spelar roll               | Ordningen i vilken du presenterar information f칬r modellen kan p친verka resultatet, 칛ven i l칛randeexemplen, tack vare recency bias. Prova olika alternativ f칬r att se vad som fungerar b칛st.                                                        |
| Ge modellen en "utv칛g"            | Ge modellen ett _fallback_-svar som den kan ge om den inte kan slutf칬ra uppgiften av n친gon anledning. Detta kan minska risken f칬r att modeller genererar falska eller fabricerade svar.                                                          |
|                                   |                                                                                                                                                                                                                                                   |

Som med alla b칛sta praxis, kom ih친g att _din erfarenhet kan variera_ beroende p친 modell, uppgift och dom칛n. Anv칛nd dessa som en utg친ngspunkt och iterera f칬r att hitta vad som fungerar b칛st f칬r dig. Utv칛rdera st칛ndigt din process f칬r promptkonstruktion n칛r nya modeller och verktyg blir tillg칛ngliga, med fokus p친 processens skalbarhet och svarens kvalitet.

<!--
LEKTIONSMALL:
Denna enhet b칬r tillhandah친lla en kodutmaning om till칛mpligt

UTMANING:
L칛nka till en Jupyter Notebook med endast kodkommentarer i instruktionerna (kodsektionerna 칛r tomma).

L칐SNING:
L칛nka till en kopia av den Notebook med ifyllda och k칬rda prompts, som visar hur ett exempel kan se ut.
-->

## Uppgift

Grattis! Du har n친tt slutet av lektionen! Det 칛r dags att testa n친gra av dessa koncept och tekniker med riktiga exempel!

F칬r v친r uppgift kommer vi att anv칛nda en Jupyter Notebook med 칬vningar som du kan slutf칬ra interaktivt. Du kan ocks친 ut칬ka Notebook med dina egna Markdown- och kodceller f칬r att utforska id칠er och tekniker p친 egen hand.

### F칬r att komma ig친ng, fork:a repot, sedan

- (Rekommenderat) Starta GitHub Codespaces
- (Alternativt) Klona repot till din lokala enhet och anv칛nd det med Docker Desktop
- (Alternativt) 칐ppna Notebook med din f칬redragna Notebook-runtime-milj칬.

### N칛sta, konfigurera dina milj칬variabler

- Kopiera `.env.copy`-filen i repo-roten till `.env` och fyll i v칛rdena f칬r `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` och `AZURE_OPENAI_DEPLOYMENT`. G친 tillbaka till [Learning Sandbox-sektionen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) f칬r att l칛ra dig hur.

### N칛sta, 칬ppna Jupyter Notebook

- V칛lj runtime-k칛rnan. Om du anv칛nder alternativ 1 eller 2, v칛lj helt enkelt standardk칛rnan Python 3.10.x som tillhandah친lls av utvecklingscontainern.

Nu 칛r du redo att k칬ra 칬vningarna. Observera att det inte finns n친gra _r칛tt och fel_ svar h칛r - det handlar bara om att utforska alternativ genom f칬rs칬k och misstag och bygga intuition f칬r vad som fungerar f칬r en given modell och applikationsdom칛n.

_D칛rf칬r finns det inga kodl칬sningssegment i denna lektion. Ist칛llet kommer Notebook att ha Markdown-celler med titeln "Min l칬sning:" som visar ett exempel p친 resultat f칬r referens._

 <!--
LEKTIONSMALL:
Avsluta avsnittet med en sammanfattning och resurser f칬r sj칛lvstyrt l칛rande.
-->

## Kunskapskontroll

Vilket av f칬ljande 칛r en bra prompt som f칬ljer n친gra rimliga b칛sta praxis?

1. Visa mig en bild p친 en r칬d bil
2. Visa mig en bild p친 en r칬d bil av m칛rket Volvo och modell XC90 parkerad vid en klippa med solnedg친ng
3. Visa mig en bild p친 en r칬d bil av m칛rket Volvo och modell XC90

A: 2, det 칛r den b칛sta prompten eftersom den ger detaljer om "vad" och g친r in p친 specifika detaljer (inte bara vilken bil som helst utan en specifik modell och m칛rke) och beskriver ocks친 den 칬vergripande milj칬n. 3 칛r n칛st b칛st eftersom den ocks친 inneh친ller mycket beskrivning.

## 游 Utmaning

Se om du kan anv칛nda "ledtr친dstekniken" med prompten: Slutf칬r meningen "Visa mig en bild p친 en r칬d bil av m칛rket Volvo och ". Vad svarar den med, och hur skulle du f칬rb칛ttra det?

## Bra jobbat! Forts칛tt ditt l칛rande

Vill du l칛ra dig mer om olika koncept inom promptkonstruktion? G친 till [sidan f칬r fortsatt l칛rande](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f칬r att hitta andra bra resurser om detta 칛mne.

G친 vidare till Lektion 5 d칛r vi kommer att titta p친 [avancerade tekniker f칬r promptkonstruktion](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, b칬r det noteras att automatiserade 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess ursprungliga spr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.