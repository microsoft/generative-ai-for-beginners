<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b3cb38518cf4fe7714d2f5e74dfa3eb",
  "translation_date": "2025-10-03T09:35:04+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "sv"
}
-->
# Grundl√§ggande om Prompt Engineering

[![Grundl√§ggande om Prompt Engineering](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.sv.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduktion
Det h√§r kapitlet t√§cker viktiga koncept och tekniker f√∂r att skapa effektiva prompts i generativa AI-modeller. Hur du formulerar din prompt till en LLM spelar ocks√• roll. En noggrant utformad prompt kan ge b√§ttre kvalitet p√• svaren. Men vad betyder egentligen termer som _prompt_ och _prompt engineering_? Och hur kan jag f√∂rb√§ttra promptens _input_ som jag skickar till LLM? Det √§r fr√•gor vi ska f√∂rs√∂ka besvara i detta kapitel och det n√§sta.

_Generativ AI_ kan skapa nytt inneh√•ll (t.ex. text, bilder, ljud, kod etc.) som svar p√• anv√§ndarf√∂rfr√•gningar. Den g√∂r detta med hj√§lp av _Large Language Models_ som OpenAI:s GPT ("Generative Pre-trained Transformer")-serier, som √§r tr√§nade f√∂r att anv√§nda naturligt spr√•k och kod.

Anv√§ndare kan nu interagera med dessa modeller genom v√§lbekanta paradigmer som chatt, utan att beh√∂va teknisk expertis eller utbildning. Modellerna √§r _prompt-baserade_ ‚Äì anv√§ndare skickar en textinput (prompt) och f√•r tillbaka AI:s svar (completion). De kan sedan "chatta med AI:n" iterativt, i flerv√§ndiga konversationer, och f√∂rfina sin prompt tills svaret matchar deras f√∂rv√§ntningar.

"Prompts" blir nu det prim√§ra _programmeringsgr√§nssnittet_ f√∂r generativa AI-appar, som instruerar modellerna vad de ska g√∂ra och p√•verkar kvaliteten p√• de svar som returneras. "Prompt Engineering" √§r ett snabbt v√§xande forskningsomr√•de som fokuserar p√• _design och optimering_ av prompts f√∂r att leverera konsekventa och kvalitativa svar i stor skala.

## L√§randem√•l

I denna lektion l√§r vi oss vad Prompt Engineering √§r, varf√∂r det √§r viktigt och hur vi kan skapa mer effektiva prompts f√∂r en given modell och applikationsm√•l. Vi kommer att f√∂rst√• k√§rnkoncept och b√§sta praxis f√∂r prompt engineering ‚Äì och l√§ra oss om en interaktiv Jupyter Notebooks "sandbox"-milj√∂ d√§r vi kan se dessa koncept till√§mpas p√• verkliga exempel.

I slutet av denna lektion kommer vi att kunna:

1. F√∂rklara vad prompt engineering √§r och varf√∂r det √§r viktigt.
2. Beskriva komponenterna i en prompt och hur de anv√§nds.
3. L√§ra oss b√§sta praxis och tekniker f√∂r prompt engineering.
4. Till√§mpa l√§rda tekniker p√• verkliga exempel, med hj√§lp av en OpenAI-endpoint.

## Nyckeltermer

Prompt Engineering: Praktiken att designa och f√∂rfina inputs f√∂r att styra AI-modeller mot att producera √∂nskade outputs.  
Tokenisering: Processen att konvertera text till mindre enheter, kallade tokens, som en modell kan f√∂rst√• och bearbeta.  
Instruktionsanpassade LLM: Stora spr√•kmodeller (LLMs) som har finjusterats med specifika instruktioner f√∂r att f√∂rb√§ttra deras svarsnoggrannhet och relevans.

## L√§rande Sandbox

Prompt engineering √§r f√∂r n√§rvarande mer konst √§n vetenskap. Det b√§sta s√§ttet att f√∂rb√§ttra v√•r intuition f√∂r det √§r att _√∂va mer_ och anta en trial-and-error-approach som kombinerar applikationsdom√§nexpertis med rekommenderade tekniker och modell-specifika optimeringar.

Jupyter Notebook som f√∂ljer med denna lektion erbjuder en _sandbox_-milj√∂ d√§r du kan testa det du l√§r dig ‚Äì antingen under lektionen eller som en del av kodutmaningen i slutet. F√∂r att k√∂ra √∂vningarna beh√∂ver du:

1. **En Azure OpenAI API-nyckel** ‚Äì tj√§nstens endpoint f√∂r en distribuerad LLM.  
2. **En Python-runtime** ‚Äì d√§r Notebook kan k√∂ras.  
3. **Lokala milj√∂variabler** ‚Äì _slutf√∂r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst)-stegen nu f√∂r att bli redo_.  

Notebooken inneh√•ller _start√∂vningar_ ‚Äì men du uppmuntras att l√§gga till egna _Markdown_- (beskrivning) och _Code_- (promptf√∂rfr√•gningar) sektioner f√∂r att testa fler exempel eller id√©er ‚Äì och bygga din intuition f√∂r promptdesign.

## Illustrerad guide

Vill du f√• en √∂verblick √∂ver vad denna lektion t√§cker innan du dyker in? Kolla in denna illustrerade guide, som ger dig en k√§nsla av de viktigaste √§mnena som behandlas och de centrala insikterna att t√§nka p√• i varje del. Lektionens roadmap tar dig fr√•n att f√∂rst√• k√§rnkoncept och utmaningar till att hantera dem med relevanta tekniker och b√§sta praxis f√∂r prompt engineering. Observera att avsnittet "Avancerade tekniker" i denna guide h√§nvisar till inneh√•ll som behandlas i _n√§sta_ kapitel i denna kurs.

![Illustrerad guide till Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.sv.png)

## V√•rt startup

Nu ska vi prata om hur _detta √§mne_ relaterar till v√•rt startup-uppdrag att [f√∂ra AI-innovation till utbildning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi vill bygga AI-drivna applikationer f√∂r _personligt l√§rande_ ‚Äì s√• l√•t oss t√§nka p√• hur olika anv√§ndare av v√•r applikation kan "designa" prompts:

- **Administrat√∂rer** kan be AI att _analysera l√§roplansdata f√∂r att identifiera luckor i t√§ckningen_. AI kan sammanfatta resultaten eller visualisera dem med kod.  
- **L√§rare** kan be AI att _skapa en lektionsplan f√∂r en m√•lgrupp och ett √§mne_. AI kan bygga den personliga planen i ett specificerat format.  
- **Studenter** kan be AI att _l√§ra dem ett sv√•rt √§mne_. AI kan nu v√§gleda studenter med lektioner, tips och exempel anpassade till deras niv√•.  

Det √§r bara toppen av isberget. Kolla in [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì ett open-source promptbibliotek kuraterat av utbildningsexperter ‚Äì f√∂r att f√• en bredare k√§nsla av m√∂jligheterna! _Testa att k√∂ra n√•gra av dessa prompts i sandboxen eller med OpenAI Playground f√∂r att se vad som h√§nder!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Vad √§r Prompt Engineering?

Vi b√∂rjade denna lektion med att definiera **Prompt Engineering** som processen att _designa och optimera_ textinputs (prompts) f√∂r att leverera konsekventa och kvalitativa svar (completions) f√∂r ett givet applikationsm√•l och modell. Vi kan t√§nka p√• detta som en tv√•stegsprocess:

- _designa_ den initiala prompten f√∂r en given modell och m√•l  
- _f√∂rfina_ prompten iterativt f√∂r att f√∂rb√§ttra kvaliteten p√• svaret  

Detta √§r n√∂dv√§ndigtvis en trial-and-error-process som kr√§ver anv√§ndarens intuition och anstr√§ngning f√∂r att uppn√• optimala resultat. S√• varf√∂r √§r det viktigt? F√∂r att besvara den fr√•gan m√•ste vi f√∂rst f√∂rst√• tre koncept:

- _Tokenisering_ = hur modellen "ser" prompten  
- _Bas-LLMs_ = hur grundmodellen "bearbetar" en prompt  
- _Instruktionsanpassade LLMs_ = hur modellen nu kan se "uppgifter"  

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ d√§r olika modeller (eller versioner av en modell) kan tokenisera samma prompt p√• olika s√§tt. Eftersom LLMs √§r tr√§nade p√• tokens (och inte p√• r√•text), har s√§ttet som prompts tokeniseras en direkt p√•verkan p√• kvaliteten p√• det genererade svaret.

F√∂r att f√• en intuition f√∂r hur tokenisering fungerar, prova verktyg som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) som visas nedan. Kopiera in din prompt ‚Äì och se hur den konverteras till tokens, och uppm√§rksamma hur blanksteg och skiljetecken hanteras. Observera att detta exempel visar en √§ldre LLM (GPT-3) ‚Äì s√• att testa detta med en nyare modell kan ge ett annat resultat.

![Tokenisering](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.sv.png)

### Koncept: Grundmodeller

N√§r en prompt har tokeniserats √§r den prim√§ra funktionen hos ["Bas-LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grundmodell) att f√∂ruts√§ga n√§sta token i den sekvensen. Eftersom LLMs √§r tr√§nade p√• massiva textdatam√§ngder har de en god k√§nsla f√∂r de statistiska relationerna mellan tokens och kan g√∂ra den f√∂ruts√§gelsen med viss s√§kerhet. Observera att de inte f√∂rst√•r _betydelsen_ av orden i prompten eller token; de ser bara ett m√∂nster som de kan "slutf√∂ra" med sin n√§sta f√∂ruts√§gelse. De kan forts√§tta att f√∂ruts√§ga sekvensen tills anv√§ndaren avbryter eller n√•gon f√∂rutbest√§md villkor uppfylls.

Vill du se hur promptbaserad completion fungerar? Ange ovanst√•ende prompt i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinst√§llningarna. Systemet √§r konfigurerat f√∂r att behandla prompts som informationsf√∂rfr√•gningar ‚Äì s√• du b√∂r se en completion som uppfyller detta sammanhang.

Men vad h√§nder om anv√§ndaren ville se n√•got specifikt som uppfyller vissa kriterier eller m√•l f√∂r en uppgift? Det √§r h√§r _instruktionsanpassade_ LLMs kommer in i bilden.

![Bas-LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.sv.png)

### Koncept: Instruktionsanpassade LLMs

En [Instruktionsanpassad LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) b√∂rjar med grundmodellen och finjusterar den med exempel eller input/output-par (t.ex. flerv√§ndiga "meddelanden") som kan inneh√•lla tydliga instruktioner ‚Äì och svaret fr√•n AI f√∂rs√∂ker f√∂lja den instruktionen.

Detta anv√§nder tekniker som f√∂rst√§rkningsinl√§rning med m√§nsklig feedback (RLHF) som kan tr√§na modellen att _f√∂lja instruktioner_ och _l√§ra sig av feedback_ s√• att den producerar svar som √§r b√§ttre anpassade till praktiska applikationer och mer relevanta f√∂r anv√§ndarens m√•l.

L√•t oss testa det ‚Äì g√• tillbaka till prompten ovan, men √§ndra nu _systemmeddelandet_ f√∂r att ge f√∂ljande instruktion som kontext:

> _Sammanfatta inneh√•llet du f√•r f√∂r en andra klassens elev. Begr√§nsa resultatet till ett stycke med 3-5 punkter._

Se hur resultatet nu √§r anpassat f√∂r att √•terspegla det √∂nskade m√•let och formatet? En l√§rare kan nu direkt anv√§nda detta svar i sina presentationer f√∂r den klassen.

![Instruktionsanpassad LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.sv.png)

## Varf√∂r beh√∂ver vi Prompt Engineering?

Nu n√§r vi vet hur prompts bearbetas av LLMs, l√•t oss prata om _varf√∂r_ vi beh√∂ver prompt engineering. Svaret ligger i det faktum att nuvarande LLMs har ett antal utmaningar som g√∂r _p√•litliga och konsekventa completions_ sv√•rare att uppn√• utan att l√§gga ner anstr√§ngning p√• promptkonstruktion och optimering. Till exempel:

1. **Modellsvar √§r stokastiska.** _Samma prompt_ kommer sannolikt att producera olika svar med olika modeller eller modellversioner. Och det kan till och med producera olika resultat med _samma modell_ vid olika tidpunkter. _Prompt engineering-tekniker kan hj√§lpa oss att minimera dessa variationer genom att ge b√§ttre riktlinjer_.  

1. **Modeller kan fabricera svar.** Modeller √§r f√∂rtr√§nade med _stora men begr√§nsade_ datam√§ngder, vilket inneb√§r att de saknar kunskap om koncept utanf√∂r det tr√§ningsomr√•det. Som ett resultat kan de producera completions som √§r felaktiga, p√•hittade eller direkt mots√§gelsefulla mot k√§nda fakta. _Prompt engineering-tekniker hj√§lper anv√§ndare att identifiera och mildra s√•dana fabriceringar, t.ex. genom att be AI om k√§llh√§nvisningar eller resonemang_.  

1. **Modellers kapacitet varierar.** Nyare modeller eller modellgenerationer kommer att ha rikare kapaciteter men ocks√• medf√∂ra unika egenheter och avv√§gningar i kostnad och komplexitet. _Prompt engineering kan hj√§lpa oss att utveckla b√§sta praxis och arbetsfl√∂den som abstraherar bort skillnader och anpassar sig till modell-specifika krav p√• skalbara, s√∂ml√∂sa s√§tt_.  

L√•t oss se detta i praktiken i OpenAI eller Azure OpenAI Playground:

- Anv√§nd samma prompt med olika LLM-distributioner (t.ex. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√•g du variationerna?  
- Anv√§nd samma prompt upprepade g√•nger med _samma_ LLM-distribution (t.ex. Azure OpenAI Playground) ‚Äì hur skiljde sig dessa variationer?  

### Exempel p√• fabriceringar

I denna kurs anv√§nder vi termen **"fabricering"** f√∂r att h√§nvisa till fenomenet d√§r LLMs ibland genererar faktam√§ssigt felaktig information p√• grund av begr√§nsningar i deras tr√§ning eller andra faktorer. Du kanske ocks√• har h√∂rt detta refereras till som _"hallucinationer"_ i popul√§ra artiklar eller forskningsrapporter. Vi rekommenderar dock starkt att anv√§nda termen _"fabricering"_ s√• att vi inte av misstag tillskriver en m√§nsklig egenskap till ett maskindrivet resultat. Detta f√∂rst√§rker ocks√• [Riktlinjer f√∂r ansvarsfull AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) ur ett terminologiperspektiv, och tar bort termer som kan anses vara st√∂tande eller icke-inkluderande i vissa sammanhang.

Vill du f√• en k√§nsla f√∂r hur fabriceringar fungerar? T√§nk p√• en prompt som instruerar AI att generera inneh√•ll f√∂r ett icke-existerande √§mne (f√∂r att s√§kerst√§lla att det inte finns i tr√§ningsdatam√§ngden). Till exempel ‚Äì jag testade denna prompt:

> **Prompt:** skapa en lektionsplan om Marskriget 2076.
En webbs√∂kning visade att det finns fiktiva ber√§ttelser (t.ex. tv-serier eller b√∂cker) om krig p√• Mars ‚Äì men inga fr√•n √•r 2076. Sunt f√∂rnuft s√§ger ocks√• att 2076 √§r _i framtiden_ och d√§rf√∂r inte kan kopplas till en verklig h√§ndelse.

S√• vad h√§nder n√§r vi testar denna prompt med olika LLM-leverant√∂rer?

> **Svar 1**: OpenAI Playground (GPT-35)

![Svar 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.sv.png)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Svar 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.sv.png)

> **Svar 3**: Hugging Face Chat Playground (LLama-2)

![Svar 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.sv.png)

Som f√∂rv√§ntat genererar varje modell (eller modellversion) n√•got olika svar tack vare stokastiskt beteende och variationer i modellens kapacitet. Till exempel riktar sig en modell till en √•ttondeklassare medan en annan antar att anv√§ndaren √§r en gymnasieelev. Men alla tre modeller producerade svar som skulle kunna √∂vertyga en oinformerad anv√§ndare om att h√§ndelsen var verklig.

Prompttekniker som _metaprompting_ och _temperaturkonfiguration_ kan minska modellens fabriceringar till viss del. Nya arkitekturer f√∂r promptdesign integrerar ocks√• nya verktyg och tekniker smidigt i promptfl√∂det f√∂r att mildra eller minska dessa effekter.

## Fallstudie: GitHub Copilot

L√•t oss avsluta denna sektion med att f√• en k√§nsla f√∂r hur promptdesign anv√§nds i verkliga l√∂sningar genom att titta p√• en fallstudie: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot √§r din "AI-parprogrammerare" ‚Äì den omvandlar textprompter till kodf√∂rslag och √§r integrerad i din utvecklingsmilj√∂ (t.ex. Visual Studio Code) f√∂r en smidig anv√§ndarupplevelse. Som dokumenterat i en serie bloggar nedan, baserades den tidigaste versionen p√• OpenAI Codex-modellen ‚Äì med ingenj√∂rer som snabbt ins√•g behovet av att finjustera modellen och utveckla b√§ttre prompttekniker f√∂r att f√∂rb√§ttra kodkvaliteten. I juli [lanserade de en f√∂rb√§ttrad AI-modell som g√•r bortom Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) f√∂r √§nnu snabbare f√∂rslag.

L√§s blogginl√§ggen i ordning f√∂r att f√∂lja deras l√§randeresa.

- **Maj 2023** | [GitHub Copilot blir b√§ttre p√• att f√∂rst√• din kod](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Inuti GitHub: Arbeta med LLM:erna bakom GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jun 2023** | [Hur man skriver b√§ttre prompter f√∂r GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jul 2023** | [.. GitHub Copilot g√•r bortom Codex med f√∂rb√§ttrad AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [En utvecklares guide till promptdesign och LLM:er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hur man bygger en f√∂retags-LLM-app: L√§rdomar fr√•n GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ocks√• bl√§ddra i deras [ingenj√∂rsblogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) f√∂r fler inl√§gg som [detta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som visar hur dessa modeller och tekniker _till√§mpas_ f√∂r att driva verkliga applikationer.

---

## Promptkonstruktion

Vi har sett varf√∂r promptdesign √§r viktig ‚Äì nu ska vi f√∂rst√• hur prompter _konstrueras_ s√• att vi kan utv√§rdera olika tekniker f√∂r mer effektiv promptdesign.

### Grundl√§ggande prompt

L√•t oss b√∂rja med den grundl√§ggande prompten: en textinmatning som skickas till modellen utan n√•gon annan kontext. H√§r √§r ett exempel ‚Äì n√§r vi skickar de f√∂rsta orden i USA:s nationals√•ng till OpenAI:s [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) kompletterar den omedelbart svaret med de f√∂ljande raderna, vilket illustrerar det grundl√§ggande prediktionsbeteendet.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det verkar som att du b√∂rjar p√• texten till "The Star-Spangled Banner", USA:s nationals√•ng. Den fullst√§ndiga texten √§r ...                 |

### Komplex prompt

Nu l√§gger vi till kontext och instruktioner till den grundl√§ggande prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) l√•ter oss konstruera en komplex prompt som en samling _meddelanden_ med:

- Input/output-par som reflekterar _anv√§ndarens_ inmatning och _assistentens_ svar.
- Systemmeddelande som s√§tter kontexten f√∂r assistentens beteende eller personlighet.

Beg√§ran ser nu ut som nedan, d√§r _tokeniseringen_ effektivt f√•ngar relevant information fr√•n kontext och konversation. Att √§ndra systemkontexten kan vara lika avg√∂rande f√∂r kvaliteten p√• svaren som de anv√§ndarinmatningar som tillhandah√•lls.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruktionsprompt

I exemplen ovan var anv√§ndarens prompt en enkel textfr√•ga som kan tolkas som en beg√§ran om information. Med _instruktionsprompter_ kan vi anv√§nda texten f√∂r att specificera en uppgift mer detaljerat och ge b√§ttre v√§gledning till AI:n. H√§r √§r ett exempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruktionstyp     |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivning av amerikanska inb√∂rdeskriget                                                                                                                                                                                     | _returnerade ett enkelt stycke_                                                                                           | Enkel               |
| Skriv en beskrivning av amerikanska inb√∂rdeskriget. Ange viktiga datum och h√§ndelser och beskriv deras betydelse                                                                                                                       | _returnerade ett stycke f√∂ljt av en lista med viktiga datum och h√§ndelser med beskrivningar_                               | Komplex             |
| Skriv en beskrivning av amerikanska inb√∂rdeskriget i ett stycke. Ange 3 punkter med viktiga datum och deras betydelse. Ange 3 ytterligare punkter med viktiga historiska personer och deras bidrag. Returnera svaret som en JSON-fil. | _returnerade mer omfattande detaljer i en textbox, formaterad som JSON som du kan kopiera och klistra in i en fil_         | Komplex. Formaterad |

## Prim√§rt inneh√•ll

I exemplen ovan var prompten fortfarande ganska √∂ppen, vilket till√§t LLM att avg√∂ra vilken del av dess f√∂rtr√§nade dataset som var relevant. Med designm√∂nstret _prim√§rt inneh√•ll_ delas inmatningstexten upp i tv√• delar:

- en instruktion (handling)
- relevant inneh√•ll (som p√•verkar handlingen)

H√§r √§r ett exempel d√§r instruktionen √§r att "sammanfatta detta i 2 meningar".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Den √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger st√∂rre √§n alla andra planeter i solsystemet tillsammans. Jupiter √§r en av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nd f√∂r antika civilisationer sedan innan den skrivna historien. Den √§r uppkallad efter den romerska guden Jupiter. N√§r den ses fr√•n jorden kan Jupiter vara tillr√§ckligt ljusstark f√∂r att dess reflekterade ljus ska kasta synliga skuggor och √§r i genomsnitt det tredje ljusstarkaste naturliga objektet p√• natthimlen efter m√•nen och Venus. <br/> **Sammanfatta detta i 2 korta meningar** | Jupiter, den femte planeten fr√•n solen, √§r den st√∂rsta i solsystemet och √§r k√§nd f√∂r att vara ett av de ljusstarkaste objekten p√• natthimlen. Uppkallad efter den romerska guden Jupiter, √§r det en gasj√§tte vars massa √§r tv√• och en halv g√•nger st√∂rre √§n alla andra planeter i solsystemet tillsammans. |

Segmentet med prim√§rt inneh√•ll kan anv√§ndas p√• olika s√§tt f√∂r att driva mer effektiva instruktioner:

- **Exempel** ‚Äì ist√§llet f√∂r att ber√§tta f√∂r modellen vad den ska g√∂ra med en explicit instruktion, ge den exempel p√• vad den ska g√∂ra och l√•t den dra slutsatser om m√∂nstret.
- **Ledtr√•dar** ‚Äì f√∂lj instruktionen med en "ledtr√•d" som f√∂rbereder svaret och guidar modellen mot mer relevanta svar.
- **Mallar** ‚Äì dessa √§r upprepbara "recept" f√∂r prompter med platsh√•llare (variabler) som kan anpassas med data f√∂r specifika anv√§ndningsfall.

L√•t oss utforska dessa i praktiken.

### Anv√§nda exempel

Detta √§r en metod d√§r du anv√§nder det prim√§ra inneh√•llet f√∂r att "mata modellen" med n√•gra exempel p√• √∂nskat resultat f√∂r en given instruktion och l√•ter den dra slutsatser om m√∂nstret f√∂r det √∂nskade resultatet. Beroende p√• antalet exempel som tillhandah√•lls kan vi ha zero-shot-prompting, one-shot-prompting, few-shot-prompting etc.

Prompten best√•r nu av tre komponenter:

- En uppgiftsbeskrivning
- N√•gra exempel p√• √∂nskat resultat
- B√∂rjan p√• ett nytt exempel (som blir en implicit uppgiftsbeskrivning)

| L√§rande typ | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot   | "The Sun is Shining". √ñvers√§tt till spanska                                                                                                           | "El Sol est√° brillando".    |
| One-shot    | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot    | Spelaren sprang runt baserna => Baseball <br/> Spelaren slog en serve => Tennis <br/> Spelaren slog en sexa => Cricket <br/> Spelaren gjorde en slam-dunk => | Basketboll                  |
|             |                                                                                                                                                       |                             |

Notera hur vi var tvungna att ge en explicit instruktion ("√ñvers√§tt till spanska") i zero-shot-prompting, men det blir underf√∂rst√•tt i one-shot-prompting-exemplet. Few-shot-exemplet visar hur fler exempel g√∂r att modeller kan dra mer exakta slutsatser utan ytterligare instruktioner.

### Ledtr√•dar i prompten

En annan teknik f√∂r att anv√§nda prim√§rt inneh√•ll √§r att ge _ledtr√•dar_ ist√§llet f√∂r exempel. I detta fall ger vi modellen en knuff i r√§tt riktning genom att _b√∂rja med_ en snippet som reflekterar det √∂nskade svarformatet. Modellen "tar ledtr√•den" och forts√§tter i samma stil.

| Antal ledtr√•dar | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :-------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0               | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Den √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger st√∂rre √§n alla andra planeter i solsystemet tillsammans. Jupiter √§r en av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nd f√∂r antika civilisationer sedan innan den skrivna historien. <br/>**Sammanfatta detta**                                       | Jupiter √§r den st√∂rsta planeten i v√•rt solsystem och den femte fr√•n solen. Den √§r en gasj√§tte med en massa som √§r 1/1000 av solens, men tyngre √§n alla andra planeter tillsammans. Antika civilisationer har k√§nt till Jupiter l√§nge, och den √§r l√§tt synlig p√• natthimlen. |
| 1              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger st√∂rre √§n alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r antika civilisationer sedan f√∂re den skrivna historien. <br/>**Sammanfatta detta** <br/> Det vi l√§rde oss √§r att Jupiter | √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger st√∂rre √§n alla andra planeter tillsammans. Den √§r l√§tt synlig f√∂r blotta √∂gat och har varit k√§nd sedan antiken.                        |
| 2              | Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens, men tv√• och en halv g√•nger st√∂rre √§n alla andra planeter i solsystemet tillsammans. Jupiter √§r ett av de ljusstarkaste objekten som √§r synliga f√∂r blotta √∂gat p√• natthimlen och har varit k√§nt f√∂r antika civilisationer sedan f√∂re den skrivna historien. <br/>**Sammanfatta detta** <br/> Topp 3 fakta vi l√§rde oss:         | 1. Jupiter √§r den femte planeten fr√•n solen och den st√∂rsta i solsystemet. <br/> 2. Det √§r en gasj√§tte med en massa som √§r en tusendel av solens...<br/> 3. Jupiter har varit synlig f√∂r blotta √∂gat sedan antiken ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Promptmallar

En promptmall √§r ett _f√∂rdefinierat recept f√∂r en prompt_ som kan sparas och √•teranv√§ndas vid behov f√∂r att skapa mer konsekventa anv√§ndarupplevelser i stor skala. I sin enklaste form √§r det helt enkelt en samling av promptexempel som [detta fr√•n OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som inneh√•ller b√•de interaktiva promptkomponenter (anv√§ndar- och systemmeddelanden) och API-drivna beg√§randeformat - f√∂r att st√∂dja √•teranv√§ndning.

I sin mer komplexa form, som [detta exempel fr√•n LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), inneh√•ller den _platsh√•llare_ som kan ers√§ttas med data fr√•n olika k√§llor (anv√§ndarinmatning, systemkontext, externa datak√§llor etc.) f√∂r att dynamiskt generera en prompt. Detta g√∂r det m√∂jligt att skapa ett bibliotek av √•teranv√§ndbara prompts som kan anv√§ndas f√∂r att driva konsekventa anv√§ndarupplevelser **programmerbart** i stor skala.

Slutligen ligger det verkliga v√§rdet av mallar i m√∂jligheten att skapa och publicera _promptbibliotek_ f√∂r vertikala applikationsdom√§ner - d√§r promptmallen nu √§r _optimerad_ f√∂r att √•terspegla applikationsspecifik kontext eller exempel som g√∂r svaren mer relevanta och korrekta f√∂r den riktade anv√§ndargruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √§r ett utm√§rkt exempel p√• detta tillv√§gag√•ngss√§tt, d√§r ett bibliotek av prompts f√∂r utbildningsdom√§nen kurateras med fokus p√• viktiga m√•l som lektionsplanering, l√§roplansdesign, studenthandledning etc.

## St√∂djande inneh√•ll

Om vi t√§nker p√• promptkonstruktion som att ha en instruktion (uppgift) och ett m√•l (prim√§rt inneh√•ll), s√• √§r _sekund√§rt inneh√•ll_ som ytterligare kontext vi tillhandah√•ller f√∂r att **p√•verka resultatet p√• n√•got s√§tt**. Det kan vara justeringsparametrar, formateringsinstruktioner, √§mnestaxonomier etc. som kan hj√§lpa modellen att _anpassa_ sitt svar f√∂r att passa de √∂nskade anv√§ndarm√•len eller f√∂rv√§ntningarna.

Till exempel: Givet en kurskatalog med omfattande metadata (namn, beskrivning, niv√•, metadatataggar, instrukt√∂r etc.) om alla tillg√§ngliga kurser i l√§roplanen:

- vi kan definiera en instruktion f√∂r att "sammanfatta kurskatalogen f√∂r h√∂sten 2023"
- vi kan anv√§nda det prim√§ra inneh√•llet f√∂r att tillhandah√•lla n√•gra exempel p√• det √∂nskade resultatet
- vi kan anv√§nda det sekund√§ra inneh√•llet f√∂r att identifiera de 5 fr√§msta "taggarna" av intresse.

Nu kan modellen tillhandah√•lla en sammanfattning i det format som visas av de f√• exemplen - men om ett resultat har flera taggar kan den prioritera de 5 taggar som identifierats i det sekund√§ra inneh√•llet.

---

<!--
LEKTIONSMALL:
Denna enhet b√∂r t√§cka k√§rnkoncept #1.
F√∂rst√§rk konceptet med exempel och referenser.

KONCEPT #3:
Tekniker f√∂r promptdesign.
Vilka √§r n√•gra grundl√§ggande tekniker f√∂r promptdesign?
Illustrera med n√•gra √∂vningar.
-->

## B√§sta praxis f√∂r promptdesign

Nu n√§r vi vet hur prompts kan _konstrueras_, kan vi b√∂rja t√§nka p√• hur vi ska _designa_ dem f√∂r att √•terspegla b√§sta praxis. Vi kan t√§nka p√• detta i tv√• delar - att ha r√§tt _mentalitet_ och att till√§mpa r√§tt _tekniker_.

### Mentalitet f√∂r promptdesign

Promptdesign √§r en process av f√∂rs√∂k och misstag, s√• h√•ll tre breda v√§gledande faktorer i √•tanke:

1. **Dom√§nf√∂rst√•else √§r viktigt.** Svarens noggrannhet och relevans √§r en funktion av _dom√§nen_ d√§r applikationen eller anv√§ndaren verkar. Anv√§nd din intuition och dom√§nexpertis f√∂r att **anpassa tekniker** ytterligare. Till exempel, definiera _dom√§nspecifika personligheter_ i dina systemprompts, eller anv√§nd _dom√§nspecifika mallar_ i dina anv√§ndarprompts. Tillhandah√•ll sekund√§rt inneh√•ll som √•terspeglar dom√§nspecifika kontexter, eller anv√§nd _dom√§nspecifika ledtr√•dar och exempel_ f√∂r att v√§gleda modellen mot bekanta anv√§ndningsm√∂nster.

2. **Modellf√∂rst√•else √§r viktigt.** Vi vet att modeller √§r stokastiska till sin natur. Men modellimplementeringar kan ocks√• variera n√§r det g√§ller tr√§ningsdatasetet de anv√§nder (f√∂rtr√§nad kunskap), de funktioner de tillhandah√•ller (t.ex. via API eller SDK) och typen av inneh√•ll de √§r optimerade f√∂r (t.ex. kod vs. bilder vs. text). F√∂rst√• styrkorna och begr√§nsningarna hos den modell du anv√§nder och anv√§nd den kunskapen f√∂r att _prioritera uppgifter_ eller bygga _anpassade mallar_ som √§r optimerade f√∂r modellens kapabiliteter.

3. **Iteration och validering √§r viktigt.** Modeller utvecklas snabbt, och det g√∂r √§ven teknikerna f√∂r promptdesign. Som dom√§nexpert kan du ha annan kontext eller kriterier f√∂r _din_ specifika applikation, som kanske inte g√§ller f√∂r den bredare gemenskapen. Anv√§nd verktyg och tekniker f√∂r promptdesign f√∂r att "snabbstarta" promptkonstruktionen, iterera och validera resultaten med din egen intuition och dom√§nexpertis. Dokumentera dina insikter och skapa en **kunskapsbas** (t.ex. promptbibliotek) som kan anv√§ndas som en ny baslinje av andra f√∂r snabbare iterationer i framtiden.

## B√§sta praxis

L√•t oss nu titta p√• vanliga b√§sta praxis som rekommenderas av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) och [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) praktiker.

| Vad                               | Varf√∂r                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Utv√§rdera de senaste modellerna.  | Nya modellgenerationer har sannolikt f√∂rb√§ttrade funktioner och kvalitet - men kan ocks√• medf√∂ra h√∂gre kostnader. Utv√§rdera dem f√∂r p√•verkan och fatta sedan migrationsbeslut.                                                                        |
| Separera instruktioner och kontext | Kontrollera om din modell/leverant√∂r definierar _avgr√§nsare_ f√∂r att tydligare skilja instruktioner, prim√§rt och sekund√§rt inneh√•ll. Detta kan hj√§lpa modeller att tilldela vikter mer exakt till tokens.                                             |
| Var specifik och tydlig           | Ge fler detaljer om √∂nskad kontext, resultat, l√§ngd, format, stil etc. Detta kommer att f√∂rb√§ttra b√•de kvaliteten och konsistensen i svaren. F√•nga recept i √•teranv√§ndbara mallar.                                                                    |
| Var beskrivande, anv√§nd exempel   | Modeller kan svara b√§ttre p√• en "visa och ber√§tta"-metod. B√∂rja med en `zero-shot`-metod d√§r du ger en instruktion (men inga exempel) och prova sedan `few-shot` som en f√∂rfining, genom att ge n√•gra exempel p√• det √∂nskade resultatet. Anv√§nd analogier. |
| Anv√§nd ledtr√•dar f√∂r att starta svar | Ge modellen n√•gra inledande ord eller fraser som den kan anv√§nda som utg√•ngspunkt f√∂r svaret f√∂r att styra den mot ett √∂nskat resultat.                                                                                                               |
| Upprepa                           | Ibland kan du beh√∂va upprepa dig f√∂r modellen. Ge instruktioner f√∂re och efter ditt prim√§ra inneh√•ll, anv√§nd en instruktion och en ledtr√•d etc. Iterera och validera f√∂r att se vad som fungerar.                                                     |
| Ordning spelar roll               | Ordningen i vilken du presenterar information f√∂r modellen kan p√•verka resultatet, √§ven i l√§randeexemplen, tack vare recency bias. Prova olika alternativ f√∂r att se vad som fungerar b√§st.                                                           |
| Ge modellen en "utv√§g"            | Ge modellen ett _fallback_-svar som den kan ge om den inte kan slutf√∂ra uppgiften av n√•gon anledning. Detta kan minska risken f√∂r att modellen genererar falska eller fabricerade svar.                                                              |
|                                   |                                                                                                                                                                                                                                                   |

Som med alla b√§sta praxis, kom ih√•g att _din erfarenhet kan variera_ beroende p√• modell, uppgift och dom√§n. Anv√§nd dessa som en utg√•ngspunkt och iterera f√∂r att hitta vad som fungerar b√§st f√∂r dig. Utv√§rdera st√§ndigt din process f√∂r promptdesign n√§r nya modeller och verktyg blir tillg√§ngliga, med fokus p√• processskalbarhet och svarskvalitet.

<!--
LEKTIONSMALL:
Denna enhet b√∂r tillhandah√•lla en kodutmaning om till√§mpligt

UTMANING:
L√§nk till en Jupyter Notebook med endast kodkommentarer i instruktionerna (kodsektioner √§r tomma).

L√ñSNING:
L√§nk till en kopia av den Notebook med prompts ifyllda och k√∂rda, som visar vad ett exempel kan vara.
-->

## Uppgift

Grattis! Du har n√•tt slutet av lektionen! Det √§r dags att testa n√•gra av dessa koncept och tekniker med riktiga exempel!

F√∂r v√•r uppgift kommer vi att anv√§nda en Jupyter Notebook med √∂vningar som du kan slutf√∂ra interaktivt. Du kan ocks√• ut√∂ka Notebook med dina egna Markdown- och kodceller f√∂r att utforska id√©er och tekniker p√• egen hand.

### F√∂r att komma ig√•ng, fork:a repot och sedan

- (Rekommenderat) Starta GitHub Codespaces
- (Alternativt) Klona repot till din lokala enhet och anv√§nd det med Docker Desktop
- (Alternativt) √ñppna Notebook med din f√∂redragna Notebook-milj√∂.

### N√§sta, konfigurera dina milj√∂variabler

- Kopiera `.env.copy`-filen i repo-roten till `.env` och fyll i v√§rdena f√∂r `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` och `AZURE_OPENAI_DEPLOYMENT`. G√• tillbaka till [Learning Sandbox-sektionen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) f√∂r att l√§ra dig hur.

### N√§sta, √∂ppna Jupyter Notebook

- V√§lj runtime-k√§rnan. Om du anv√§nder alternativ 1 eller 2, v√§lj helt enkelt standardk√§rnan Python 3.10.x som tillhandah√•lls av utvecklingscontainern.

Du √§r redo att k√∂ra √∂vningarna. Observera att det inte finns n√•gra _r√§tt och fel_ svar h√§r - bara att utforska alternativ genom f√∂rs√∂k och misstag och bygga intuition f√∂r vad som fungerar f√∂r en given modell och applikationsdom√§n.

_F√∂r denna anledning finns det inga kodl√∂sningssegment i denna lektion. Ist√§llet kommer Notebook att ha Markdown-celler med titeln "Min l√∂sning:" som visar ett exempel p√• resultat f√∂r referens._

 <!--
LEKTIONSMALL:
Avsluta sektionen med en sammanfattning och resurser f√∂r sj√§lvstyrt l√§rande.
-->

## Kunskapskontroll

Vilken av f√∂ljande √§r en bra prompt som f√∂ljer n√•gra rimliga b√§sta praxis?

1. Visa mig en bild av en r√∂d bil
2. Visa mig en bild av en r√∂d bil av m√§rket Volvo och modellen XC90 parkerad vid en klippa med solnedg√•ngen
3. Visa mig en bild av en r√∂d bil av m√§rket Volvo och modellen XC90

A: 2, det √§r den b√§sta prompten eftersom den ger detaljer om "vad" och g√•r in p√• specifika detaljer (inte bara vilken bil som helst utan ett specifikt m√§rke och modell) och den beskriver ocks√• den √∂vergripande milj√∂n. 3 √§r n√§st b√§st eftersom den ocks√• inneh√•ller mycket beskrivning.

## üöÄ Utmaning

Se om du kan anv√§nda "ledtr√•dstekniken" med prompten: Slutf√∂r meningen "Visa mig en bild av en r√∂d bil av m√§rket Volvo och ". Vad svarar den med, och hur skulle du f√∂rb√§ttra det?

## Bra jobbat! Forts√§tt ditt l√§rande

Vill du l√§ra dig mer om olika koncept inom promptdesign? G√• till [sidan f√∂r fortsatt l√§rande](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att hitta andra bra resurser om detta √§mne.

G√• vidare till Lektion 5 d√§r vi kommer att titta p√• [avancerade tekniker f√∂r promptdesign](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r det noteras att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess originalspr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.