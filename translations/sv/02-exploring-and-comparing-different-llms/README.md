<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:04:32+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "sv"
}
-->
# Utforska och j√§mf√∂ra olika LLMs

> _Klicka p√• bilden ovan f√∂r att se videon av denna lektion_

I den tidigare lektionen s√•g vi hur Generativ AI f√∂r√§ndrar tekniklandskapet, hur Stora Spr√•kmodeller (LLMs) fungerar och hur ett f√∂retag - som v√•r startup - kan till√§mpa dem p√• sina anv√§ndningsomr√•den och v√§xa! I detta kapitel ska vi j√§mf√∂ra och kontrastera olika typer av stora spr√•kmodeller (LLMs) f√∂r att f√∂rst√• deras f√∂r- och nackdelar.

N√§sta steg i v√•r startups resa √§r att utforska det nuvarande landskapet av LLMs och f√∂rst√• vilka som √§r l√§mpliga f√∂r v√•rt anv√§ndningsomr√•de.

## Introduktion

Denna lektion kommer att t√§cka:

- Olika typer av LLMs i det nuvarande landskapet.
- Testa, iterera och j√§mf√∂ra olika modeller f√∂r ditt anv√§ndningsomr√•de i Azure.
- Hur man distribuerar en LLM.

## L√§randem√•l

Efter att ha slutf√∂rt denna lektion kommer du att kunna:

- V√§lja r√§tt modell f√∂r ditt anv√§ndningsomr√•de.
- F√∂rst√• hur man testar, itererar och f√∂rb√§ttrar prestandan hos din modell.
- Veta hur f√∂retag distribuerar modeller.

## F√∂rst√• olika typer av LLMs

LLMs kan ha flera kategoriseringar baserat p√• deras arkitektur, tr√§ningsdata och anv√§ndningsomr√•de. Att f√∂rst√• dessa skillnader kommer att hj√§lpa v√•r startup att v√§lja r√§tt modell f√∂r scenariot och f√∂rst√• hur man testar, itererar och f√∂rb√§ttrar prestandan.

Det finns m√•nga olika typer av LLM-modeller, ditt val av modell beror p√• vad du avser att anv√§nda dem f√∂r, din data, hur mycket du √§r beredd att betala och mer.

Beroende p√• om du avser att anv√§nda modellerna f√∂r text, ljud, video, bildgenerering och s√• vidare, kan du v√§lja en annan typ av modell.

- **Ljud- och taligenk√§nning**. F√∂r detta √§ndam√•l √§r Whisper-typmodeller ett utm√§rkt val eftersom de √§r allm√§nna och inriktade p√• taligenk√§nning. Den √§r tr√§nad p√• olika ljud och kan utf√∂ra flerspr√•kig taligenk√§nning. L√§s mer om [Whisper-typmodeller h√§r](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Bildgenerering**. F√∂r bildgenerering √§r DALL-E och Midjourney tv√• mycket v√§lk√§nda val. DALL-E erbjuds av Azure OpenAI. [L√§s mer om DALL-E h√§r](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) och √§ven i kapitel 9 av denna l√§roplan.

- **Textgenerering**. De flesta modeller √§r tr√§nade p√• textgenerering och du har ett stort urval av val fr√•n GPT-3.5 till GPT-4. De kommer till olika kostnader d√§r GPT-4 √§r den dyraste. Det √§r v√§rt att titta in i [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) f√∂r att utv√§rdera vilka modeller som b√§st passar dina behov i termer av kapacitet och kostnad.

- **Multimodalitet**. Om du vill hantera flera typer av data i in- och utmatning, kanske du vill titta p√• modeller som [gpt-4 turbo med vision eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - de senaste versionerna av OpenAI-modeller - som √§r kapabla att kombinera naturlig spr√•kbehandling med visuell f√∂rst√•else, vilket m√∂jligg√∂r interaktioner genom multimodala gr√§nssnitt.

Att v√§lja en modell inneb√§r att du f√•r n√•gra grundl√§ggande kapaciteter, som kanske inte r√§cker dock. Ofta har du f√∂retagsspecifik data som du p√• n√•got s√§tt beh√∂ver informera LLM om. Det finns n√•gra olika val p√• hur man n√§rmar sig det, mer om det i de kommande avsnitten.

### Grundmodeller kontra LLMs

Termen Grundmodell myntades av [Stanford-forskare](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) och definieras som en AI-modell som f√∂ljer vissa kriterier, s√•som:

- **De √§r tr√§nade med osuperviserat l√§rande eller sj√§lv√∂vervakat l√§rande**, vilket inneb√§r att de √§r tr√§nade p√• om√§rkt multimodal data och de kr√§ver inte m√§nsklig annotering eller m√§rkning av data f√∂r sin tr√§ningsprocess.
- **De √§r mycket stora modeller**, baserade p√• mycket djupa neurala n√§tverk tr√§nade p√• miljarder parametrar.
- **De √§r normalt avsedda att fungera som en 'grund' f√∂r andra modeller**, vilket inneb√§r att de kan anv√§ndas som en startpunkt f√∂r andra modeller att byggas p√•, vilket kan g√∂ras genom finjustering.

F√∂r att ytterligare klarg√∂ra denna distinktion, l√•t oss ta ChatGPT som ett exempel. F√∂r att bygga den f√∂rsta versionen av ChatGPT, tj√§nade en modell kallad GPT-3.5 som grundmodell. Detta inneb√§r att OpenAI anv√§nde viss chattspecifik data f√∂r att skapa en justerad version av GPT-3.5 som var specialiserad p√• att prestera bra i konversationsscenarier, som chatbots.

### √ñppen k√§llkod kontra Propriet√§ra modeller

Ett annat s√§tt att kategorisera LLMs √§r om de √§r √∂ppen k√§llkod eller propriet√§ra.

√ñppen k√§llkod-modeller √§r modeller som g√∂rs tillg√§ngliga f√∂r allm√§nheten och kan anv√§ndas av vem som helst. De g√∂rs ofta tillg√§ngliga av f√∂retaget som skapade dem eller av forskarsamh√§llet. Dessa modeller f√•r inspekteras, modifieras och anpassas f√∂r de olika anv√§ndningsfallen i LLMs. Dock √§r de inte alltid optimerade f√∂r produktionsanv√§ndning och kanske inte √§r lika presterande som propriet√§ra modeller. Dessutom kan finansiering f√∂r √∂ppen k√§llkod-modeller vara begr√§nsad och de kanske inte underh√•lls l√•ngsiktigt eller uppdateras med den senaste forskningen. Exempel p√• popul√§ra √∂ppen k√§llkod-modeller inkluderar [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) och [LLaMA](https://llama.meta.com).

Propriet√§ra modeller √§r modeller som √§gs av ett f√∂retag och inte g√∂rs tillg√§ngliga f√∂r allm√§nheten. Dessa modeller √§r ofta optimerade f√∂r produktionsanv√§ndning. Dock f√•r de inte inspekteras, modifieras eller anpassas f√∂r olika anv√§ndningsfall. Dessutom √§r de inte alltid tillg√§ngliga gratis och kan kr√§va en prenumeration eller betalning f√∂r att anv√§nda. Anv√§ndare har inte heller kontroll √∂ver den data som anv√§nds f√∂r att tr√§na modellen, vilket inneb√§r att de b√∂r lita p√• modell√§garen f√∂r att s√§kerst√§lla engagemang f√∂r datasekretess och ansvarsfull anv√§ndning av AI. Exempel p√• popul√§ra propriet√§ra modeller inkluderar [OpenAI-modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) eller [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Inb√§ddning kontra Bildgenerering kontra Text- och kodgenerering

LLMs kan ocks√• kategoriseras efter vilken output de genererar.

Inb√§ddningar √§r en upps√§ttning modeller som kan konvertera text till en numerisk form, kallad inb√§ddning, vilket √§r en numerisk representation av inputtexten. Inb√§ddningar g√∂r det l√§ttare f√∂r maskiner att f√∂rst√• relationerna mellan ord eller meningar och kan anv√§ndas som input av andra modeller, s√•som klassificeringsmodeller eller klustermodeller som har b√§ttre prestanda p√• numerisk data. Inb√§ddningsmodeller anv√§nds ofta f√∂r transferl√§rande, d√§r en modell byggs f√∂r en surrogatuppgift f√∂r vilken det finns en √∂verfl√∂d av data, och sedan √•teranv√§nds modellens vikter (inb√§ddningar) f√∂r andra nedstr√∂msuppgifter. Ett exempel p√• denna kategori √§r [OpenAI-inb√§ddningar](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

Bildgenereringsmodeller √§r modeller som genererar bilder. Dessa modeller anv√§nds ofta f√∂r bildredigering, bildsyntes och bild√∂vers√§ttning. Bildgenereringsmodeller tr√§nas ofta p√• stora dataset av bilder, s√•som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), och kan anv√§ndas f√∂r att generera nya bilder eller f√∂r att redigera befintliga bilder med inpainting, superuppl√∂sning och f√§rgl√§ggningstekniker. Exempel inkluderar [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) och [Stable Diffusion-modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

Text- och kodgenereringsmodeller √§r modeller som genererar text eller kod. Dessa modeller anv√§nds ofta f√∂r textsammanfattning, √∂vers√§ttning och fr√•gor och svar. Textgenereringsmodeller tr√§nas ofta p√• stora dataset av text, s√•som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), och kan anv√§ndas f√∂r att generera ny text eller f√∂r att svara p√• fr√•gor. Kodgenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), tr√§nas ofta p√• stora dataset av kod, s√•som GitHub, och kan anv√§ndas f√∂r att generera ny kod eller f√∂r att fixa buggar i befintlig kod.

### Encoder-Decoder kontra Endast Decoder

F√∂r att prata om de olika typerna av arkitekturer av LLMs, l√•t oss anv√§nda en analogi.

F√∂rest√§ll dig att din chef gav dig en uppgift att skriva ett quiz f√∂r studenterna. Du har tv√• kollegor; en ansvarar f√∂r att skapa inneh√•llet och den andra ansvarar f√∂r att granska dem.

Inneh√•llsskaparen √§r som en Endast Decoder-modell, de kan titta p√• √§mnet och se vad du redan har skrivit och sedan kan han skriva en kurs baserat p√• det. De √§r mycket bra p√• att skriva engagerande och informativt inneh√•ll, men de √§r inte s√§rskilt bra p√• att f√∂rst√• √§mnet och l√§randem√•len. N√•gra exempel p√• Decoder-modeller √§r GPT-familjemodeller, s√•som GPT-3.

Granskaren √§r som en Endast Encoder-modell, de tittar p√• den skrivna kursen och svaren, m√§rker relationen mellan dem och f√∂rst√•r sammanhanget, men de √§r inte bra p√• att generera inneh√•ll. Ett exempel p√• Endast Encoder-modell skulle vara BERT.

F√∂rest√§ll dig att vi ocks√• kan ha n√•gon som b√•de kan skapa och granska quizet, detta √§r en Encoder-Decoder-modell. N√•gra exempel skulle vara BART och T5.

### Tj√§nst kontra Modell

Nu, l√•t oss prata om skillnaden mellan en tj√§nst och en modell. En tj√§nst √§r en produkt som erbjuds av en molntj√§nstleverant√∂r och √§r ofta en kombination av modeller, data och andra komponenter. En modell √§r k√§rnkomponenten i en tj√§nst och √§r ofta en grundmodell, s√•som en LLM.

Tj√§nster √§r ofta optimerade f√∂r produktionsanv√§ndning och √§r ofta enklare att anv√§nda √§n modeller, via ett grafiskt anv√§ndargr√§nssnitt. Dock √§r tj√§nster inte alltid tillg√§ngliga gratis och kan kr√§va en prenumeration eller betalning f√∂r att anv√§nda, i utbyte mot att utnyttja tj√§nste√§garens utrustning och resurser, optimera kostnader och skala enkelt. Ett exempel p√• en tj√§nst √§r [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som erbjuder en betalning-per-anv√§ndning-prisplan, vilket inneb√§r att anv√§ndare debiteras proportionellt till hur mycket de anv√§nder tj√§nsten. Dessutom erbjuder Azure OpenAI Service s√§kerhet i f√∂retagsklass och ett ansvarsfullt AI-ramverk ovanp√• modellernas kapaciteter.

Modeller √§r bara det neurala n√§tverket, med parametrarna, vikterna och andra. Vilket g√∂r det m√∂jligt f√∂r f√∂retag att k√∂ra lokalt, men skulle beh√∂va k√∂pa utrustning, bygga en struktur f√∂r att skala och k√∂pa en licens eller anv√§nda en √∂ppen k√§llkod-modell. En modell som LLaMA √§r tillg√§nglig f√∂r att anv√§ndas, vilket kr√§ver datorkraft f√∂r att k√∂ra modellen.

## Hur man testar och itererar med olika modeller f√∂r att f√∂rst√• prestanda p√• Azure

N√§r v√•rt team har utforskat det nuvarande LLMs-landskapet och identifierat n√•gra bra kandidater f√∂r sina scenarier, √§r n√§sta steg att testa dem p√• deras data och p√• deras arbetsbelastning. Detta √§r en iterativ process, gjord genom experiment och m√§tningar.
De flesta av de modeller vi n√§mnde i tidigare stycken (OpenAI-modeller, √∂ppen k√§llkod-modeller som Llama2, och Hugging Face-transformers) √§r tillg√§ngliga i [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √§r en molnplattform designad f√∂r utvecklare att bygga generativa AI-applikationer och hantera hela utvecklingslivscykeln - fr√•n experiment till utv√§rdering - genom att kombinera alla Azure AI-tj√§nster i ett enda nav med ett praktiskt GUI. Modellkatalogen i Azure AI Studio g√∂r det m√∂jligt f√∂r anv√§ndaren att:

- Hitta den grundmodell av intresse i katalogen - antingen propriet√§r eller √∂ppen k√§llkod, filtrera efter uppgift, licens eller namn. F√∂r att f√∂rb√§ttra s√∂kbarheten √§r modellerna organiserade i samlingar, som Azure OpenAI-samling, Hugging Face-samling och mer.

- Granska modellkortet, inklusive en detaljerad beskrivning av avsett anv√§ndningsomr√•de och tr√§ningsdata, kodexempel och utv√§rderingsresultat p√• det interna utv√§rderingsbiblioteket.
- J√§mf√∂r benchmarks mellan modeller och datasets som finns tillg√§ngliga inom industrin f√∂r att bed√∂ma vilken som b√§st uppfyller aff√§rsscenariot, genom [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panelen.

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.sv.png)

- Finjustera modellen med anpassade tr√§ningsdata f√∂r att f√∂rb√§ttra modellens prestanda i en specifik arbetsbelastning, genom att utnyttja experimentering och sp√•rningsfunktionerna i Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.sv.png)

- Distribuera den ursprungliga f√∂rtr√§nade modellen eller den finjusterade versionen till en fj√§rrinference i realtid - hanterad ber√§kning - eller serverl√∂s api-endpunkt - [betala per anv√§ndning](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - f√∂r att g√∂ra det m√∂jligt f√∂r applikationer att konsumera den.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.sv.png)

> [!NOTE]
> Alla modeller i katalogen √§r f√∂r n√§rvarande inte tillg√§ngliga f√∂r finjustering och/eller betala per anv√§ndning-distribution. Kontrollera modellkortet f√∂r detaljer om modellens kapaciteter och begr√§nsningar.

## F√∂rb√§ttra LLM-resultat

Vi har utforskat med v√•rt startup-team olika typer av LLMs och en molnplattform (Azure Machine Learning) som g√∂r det m√∂jligt f√∂r oss att j√§mf√∂ra olika modeller, utv√§rdera dem p√• testdata, f√∂rb√§ttra prestanda och distribuera dem p√• inference-endpunkter.

Men n√§r ska de √∂verv√§ga att finjustera en modell ist√§llet f√∂r att anv√§nda en f√∂rtr√§nad? Finns det andra metoder f√∂r att f√∂rb√§ttra modellprestanda i specifika arbetsbelastningar?

Det finns flera metoder ett f√∂retag kan anv√§nda f√∂r att f√• de resultat de beh√∂ver fr√•n en LLM. Du kan v√§lja olika typer av modeller med olika grader av tr√§ning n√§r du distribuerar en LLM i produktion, med olika niv√•er av komplexitet, kostnad och kvalitet. H√§r √§r n√•gra olika metoder:

- **Prompt engineering med kontext**. Id√©n √§r att ge tillr√§ckligt med kontext n√§r du ger en prompt f√∂r att s√§kerst√§lla att du f√•r de svar du beh√∂ver.

- **Retrieval Augmented Generation, RAG**. Dina data kan finnas i en databas eller web-endpunkt, till exempel, f√∂r att s√§kerst√§lla att dessa data, eller en del av dem, inkluderas vid tidpunkten f√∂r prompten, kan du h√§mta relevant data och g√∂ra det till en del av anv√§ndarens prompt.

- **Finjusterad modell**. H√§r har du tr√§nat modellen ytterligare p√• dina egna data vilket ledde till att modellen blev mer exakt och responsiv till dina behov men kan vara kostsam.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.sv.png)

Bildk√§lla: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med Kontext

F√∂rtr√§nade LLMs fungerar mycket bra p√• generella naturliga spr√•kuppgifter, √§ven genom att kalla dem med en kort prompt, som en mening att slutf√∂ra eller en fr√•ga ‚Äì det s√• kallade "zero-shot" l√§randet.

Men ju mer anv√§ndaren kan formulera sin fr√•ga, med en detaljerad beg√§ran och exempel ‚Äì Kontexten ‚Äì desto mer exakt och n√§rmare anv√§ndarens f√∂rv√§ntningar kommer svaret att vara. I detta fall pratar vi om "one-shot" l√§rande om prompten inkluderar endast ett exempel och "few-shot learning" om det inkluderar flera exempel. Prompt engineering med kontext √§r det mest kostnadseffektiva s√§ttet att komma ig√•ng.

### Retrieval Augmented Generation (RAG)

LLMs har begr√§nsningen att de endast kan anv√§nda data som har anv√§nts under deras tr√§ning f√∂r att generera ett svar. Detta betyder att de inte vet n√•got om fakta som h√§nt efter deras tr√§ningsprocess, och de kan inte komma √•t icke-offentlig information (som f√∂retagsdata).
Detta kan √∂vervinnas genom RAG, en teknik som f√∂rst√§rker prompten med extern data i form av dokumentdelar, med h√§nsyn till promptl√§ngdsbegr√§nsningar. Detta st√∂ds av verktyg f√∂r vektordatabaser (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) som h√§mtar de anv√§ndbara delarna fr√•n olika f√∂rdefinierade datak√§llor och l√§gger till dem i promptkontexten.

Denna teknik √§r mycket hj√§lpsam n√§r ett f√∂retag inte har tillr√§ckligt med data, tid eller resurser f√∂r att finjustera en LLM, men √§nd√• √∂nskar f√∂rb√§ttra prestanda i en specifik arbetsbelastning och minska riskerna f√∂r fabriceringar, dvs. f√∂rvanskning av verkligheten eller skadligt inneh√•ll.

### Finjusterad modell

Finjustering √§r en process som utnyttjar transfer learning f√∂r att 'anpassa' modellen till en nedstr√∂msuppgift eller f√∂r att l√∂sa ett specifikt problem. Annorlunda √§n few-shot learning och RAG, resulterar det i en ny modell som genereras, med uppdaterade vikter och f√∂rdomar. Det kr√§ver en upps√§ttning tr√§nings exempel best√•ende av en enda input (prompten) och dess associerade output (slutf√∂randet).
Detta skulle vara den f√∂redragna metoden om:

- **Anv√§nda finjusterade modeller**. Ett f√∂retag skulle vilja anv√§nda finjusterade mindre kapabla modeller (som inb√§ddningsmodeller) snarare √§n h√∂gpresterande modeller, vilket resulterar i en mer kostnadseffektiv och snabb l√∂sning.

- **Beakta latens**. Latens √§r viktigt f√∂r ett specifikt anv√§ndningsfall, s√• det √§r inte m√∂jligt att anv√§nda mycket l√•nga prompts eller antalet exempel som modellen b√∂r l√§ra sig fr√•n passar inte med promptl√§ngdsbegr√§nsningen.

- **H√•lla sig uppdaterad**. Ett f√∂retag har mycket h√∂gkvalitativa data och grundl√§ggande sanningsetiketter och de resurser som kr√§vs f√∂r att h√•lla dessa data uppdaterade √∂ver tid.

### Tr√§nad modell

Att tr√§na en LLM fr√•n grunden √§r utan tvekan den sv√•raste och mest komplexa metoden att anta, vilket kr√§ver enorma m√§ngder data, skickliga resurser och l√§mplig datorkraft. Detta alternativ b√∂r endast √∂verv√§gas i ett scenario d√§r ett f√∂retag har ett dom√§nspecifikt anv√§ndningsfall och en stor m√§ngd dom√§ncentrerade data.

## Kunskapskontroll

Vad kan vara en bra metod f√∂r att f√∂rb√§ttra LLM-slutf√∂ringsresultat?

1. Prompt engineering med kontext
1. RAG
1. Finjusterad modell

A:3, om du har tid och resurser och h√∂gkvalitativa data, √§r finjustering det b√§ttre alternativet f√∂r att h√•lla sig uppdaterad. Men om du tittar p√• att f√∂rb√§ttra saker och saknar tid √§r det v√§rt att √∂verv√§ga RAG f√∂rst.

## üöÄ Utmaning

L√§s mer om hur du kan [anv√§nda RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) f√∂r ditt f√∂retag.

## Bra Jobbat, Forts√§tt Din Inl√§rning

Efter att ha avslutat denna lektion, kolla in v√•r [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att forts√§tta utveckla din kunskap om Generative AI!

G√• vidare till Lektion 3 d√§r vi kommer att titta p√• hur man [bygger med Generative AI Ansvarsfullt](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). Vi str√§var efter noggrannhet, men var medveten om att automatiska √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess ursprungliga spr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller misstolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.