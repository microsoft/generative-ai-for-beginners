<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T19:01:28+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "sv"
}
-->
# Utforska och j√§mf√∂r olika LLM:er

[![Utforska och j√§mf√∂r olika LLM:er](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.sv.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Klicka p√• bilden ovan f√∂r att se videon av denna lektion_

I den f√∂reg√•ende lektionen s√•g vi hur Generativ AI f√∂r√§ndrar tekniklandskapet, hur stora spr√•kmodeller (LLM:er) fungerar och hur ett f√∂retag - som v√•r startup - kan till√§mpa dem p√• sina anv√§ndningsomr√•den och v√§xa! I detta kapitel ska vi j√§mf√∂ra och kontrastera olika typer av stora spr√•kmodeller (LLM:er) f√∂r att f√∂rst√• deras f√∂r- och nackdelar.

N√§sta steg i v√•r startups resa √§r att utforska det aktuella landskapet f√∂r LLM:er och f√∂rst√• vilka som √§r l√§mpliga f√∂r v√•rt anv√§ndningsomr√•de.

## Introduktion

Denna lektion kommer att t√§cka:

- Olika typer av LLM:er i det aktuella landskapet.
- Testa, iterera och j√§mf√∂ra olika modeller f√∂r ditt anv√§ndningsomr√•de i Azure.
- Hur man distribuerar en LLM.

## L√§randem√•l

Efter att ha avslutat denna lektion kommer du att kunna:

- V√§lja r√§tt modell f√∂r ditt anv√§ndningsomr√•de.
- F√∂rst√• hur man testar, itererar och f√∂rb√§ttrar modellens prestanda.
- Veta hur f√∂retag distribuerar modeller.

## F√∂rst√• olika typer av LLM:er

LLM:er kan kategoriseras p√• olika s√§tt baserat p√• deras arkitektur, tr√§ningsdata och anv√§ndningsomr√•de. Att f√∂rst√• dessa skillnader hj√§lper v√•r startup att v√§lja r√§tt modell f√∂r scenariot och f√∂rst√• hur man testar, itererar och f√∂rb√§ttrar prestandan.

Det finns m√•nga olika typer av LLM-modeller, och ditt val av modell beror p√• vad du vill anv√§nda dem till, din data, hur mycket du √§r beredd att betala och mer.

Beroende p√• om du vill anv√§nda modellerna f√∂r text, ljud, video, bildgenerering och s√• vidare, kan du v√§lja en annan typ av modell.

- **Ljud- och taligenk√§nning**. F√∂r detta √§ndam√•l √§r modeller av typen Whisper ett utm√§rkt val eftersom de √§r allm√§nna och inriktade p√• taligenk√§nning. De √§r tr√§nade p√• varierande ljud och kan utf√∂ra flerspr√•kig taligenk√§nning. L√§s mer om [Whisper-modeller h√§r](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Bildgenerering**. F√∂r bildgenerering √§r DALL-E och Midjourney tv√• mycket v√§lk√§nda val. DALL-E erbjuds av Azure OpenAI. [L√§s mer om DALL-E h√§r](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) och √§ven i kapitel 9 av denna kurs.

- **Textgenerering**. De flesta modeller √§r tr√§nade f√∂r textgenerering och det finns ett stort urval fr√•n GPT-3.5 till GPT-4. De har olika kostnader, d√§r GPT-4 √§r den dyraste. Det √§r v√§rt att titta p√• [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) f√∂r att utv√§rdera vilka modeller som b√§st passar dina behov n√§r det g√§ller kapacitet och kostnad.

- **Multimodalitet**. Om du vill hantera flera typer av data i in- och utmatning kan du vilja titta p√• modeller som [gpt-4 turbo med vision eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - de senaste versionerna av OpenAI-modeller - som kan kombinera naturlig spr√•kbehandling med visuell f√∂rst√•else och m√∂jligg√∂ra interaktioner genom multimodala gr√§nssnitt.

Att v√§lja en modell inneb√§r att du f√•r vissa grundl√§ggande funktioner, men det kanske inte r√§cker. Ofta har du f√∂retagsspecifik data som du p√• n√•got s√§tt beh√∂ver informera LLM:en om. Det finns n√•gra olika s√§tt att n√§rma sig detta, mer om det i kommande avsnitt.

### Grundmodeller kontra LLM:er

Begreppet Grundmodell myntades av [forskare vid Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) och definieras som en AI-modell som uppfyller vissa kriterier, s√•som:

- **De tr√§nas med hj√§lp av osupervised learning eller sj√§lv√∂vervakad inl√§rning**, vilket inneb√§r att de tr√§nas p√• oetiketterad multimodal data och inte kr√§ver m√§nsklig annotering eller etikettering av data f√∂r sin tr√§ningsprocess.
- **De √§r mycket stora modeller**, baserade p√• mycket djupa neurala n√§tverk tr√§nade p√• miljarder parametrar.
- **De √§r normalt avsedda att fungera som en "grund" f√∂r andra modeller**, vilket inneb√§r att de kan anv√§ndas som utg√•ngspunkt f√∂r att bygga andra modeller ovanp√•, vilket kan g√∂ras genom finjustering.

![Grundmodeller kontra LLM:er](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.sv.png)

Bildk√§lla: [Essential Guide to Foundation Models and Large Language Models | av Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

F√∂r att ytterligare klarg√∂ra denna skillnad, l√•t oss ta ChatGPT som exempel. F√∂r att bygga den f√∂rsta versionen av ChatGPT anv√§ndes en modell som heter GPT-3.5 som grundmodell. Detta inneb√§r att OpenAI anv√§nde viss chatt-specifik data f√∂r att skapa en finjusterad version av GPT-3.5 som var specialiserad p√• att prestera bra i konversationsscenarier, s√•som chatbotar.

![Grundmodell](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.sv.png)

Bildk√§lla: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### √ñppen k√§llkod kontra Propriet√§ra modeller

Ett annat s√§tt att kategorisera LLM:er √§r om de √§r √∂ppen k√§llkod eller propriet√§ra.

Modeller med √∂ppen k√§llkod √§r modeller som g√∂rs tillg√§ngliga f√∂r allm√§nheten och kan anv√§ndas av vem som helst. De g√∂rs ofta tillg√§ngliga av f√∂retaget som skapade dem eller av forskarsamh√§llet. Dessa modeller f√•r inspekteras, modifieras och anpassas f√∂r olika anv√§ndningsomr√•den inom LLM:er. Dock √§r de inte alltid optimerade f√∂r produktionsanv√§ndning och kanske inte √§r lika presterande som propriet√§ra modeller. Dessutom kan finansiering f√∂r modeller med √∂ppen k√§llkod vara begr√§nsad, och de kanske inte underh√•lls l√•ngsiktigt eller uppdateras med den senaste forskningen. Exempel p√• popul√§ra modeller med √∂ppen k√§llkod inkluderar [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) och [LLaMA](https://llama.meta.com).

Propriet√§ra modeller √§r modeller som √§gs av ett f√∂retag och inte g√∂rs tillg√§ngliga f√∂r allm√§nheten. Dessa modeller √§r ofta optimerade f√∂r produktionsanv√§ndning. Dock f√•r de inte inspekteras, modifieras eller anpassas f√∂r olika anv√§ndningsomr√•den. Dessutom √§r de inte alltid tillg√§ngliga gratis och kan kr√§va en prenumeration eller betalning f√∂r att anv√§ndas. Anv√§ndare har heller inte kontroll √∂ver den data som anv√§nds f√∂r att tr√§na modellen, vilket inneb√§r att de m√•ste lita p√• att modell√§garen s√§kerst√§ller datasekretess och ansvarsfull anv√§ndning av AI. Exempel p√• popul√§ra propriet√§ra modeller inkluderar [OpenAI-modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) eller [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Inb√§ddning kontra Bildgenerering kontra Text- och kodgenerering

LLM:er kan ocks√• kategoriseras efter den output de genererar.

Inb√§ddningar √§r en upps√§ttning modeller som kan konvertera text till en numerisk form, kallad inb√§ddning, vilket √§r en numerisk representation av den inmatade texten. Inb√§ddningar g√∂r det enklare f√∂r maskiner att f√∂rst√• relationer mellan ord eller meningar och kan anv√§ndas som indata av andra modeller, s√•som klassificeringsmodeller eller klustermodeller som har b√§ttre prestanda p√• numerisk data. Inb√§ddningsmodeller anv√§nds ofta f√∂r transfer learning, d√§r en modell byggs f√∂r en surrogatuppgift f√∂r vilken det finns gott om data, och sedan √•teranv√§nds modellvikterna (inb√§ddningarna) f√∂r andra nedstr√∂msuppgifter. Ett exempel p√• denna kategori √§r [OpenAI inb√§ddningar](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Inb√§ddning](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.sv.png)

Bildgenereringsmodeller √§r modeller som genererar bilder. Dessa modeller anv√§nds ofta f√∂r bildredigering, bildsyntes och bild√∂vers√§ttning. Bildgenereringsmodeller tr√§nas ofta p√• stora dataset av bilder, s√•som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), och kan anv√§ndas f√∂r att generera nya bilder eller redigera befintliga bilder med tekniker som inpainting, superuppl√∂sning och f√§rgl√§ggning. Exempel inkluderar [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) och [Stable Diffusion-modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Bildgenerering](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.sv.png)

Text- och kodgenereringsmodeller √§r modeller som genererar text eller kod. Dessa modeller anv√§nds ofta f√∂r textsammanfattning, √∂vers√§ttning och fr√•gesvar. Textgenereringsmodeller tr√§nas ofta p√• stora dataset av text, s√•som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), och kan anv√§ndas f√∂r att generera ny text eller svara p√• fr√•gor. Kodgenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), tr√§nas ofta p√• stora dataset av kod, s√•som GitHub, och kan anv√§ndas f√∂r att generera ny kod eller fixa buggar i befintlig kod.

![Text- och kodgenerering](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.sv.png)

### Encoder-Decoder kontra Endast Decoder

F√∂r att prata om de olika typerna av arkitekturer f√∂r LLM:er, l√•t oss anv√§nda en analogi.

F√∂rest√§ll dig att din chef ger dig i uppdrag att skriva ett quiz f√∂r studenterna. Du har tv√• kollegor; en ansvarar f√∂r att skapa inneh√•llet och den andra f√∂r att granska det.

Inneh√•llsskaparen √§r som en modell med endast Decoder, de kan titta p√• √§mnet och se vad du redan har skrivit och sedan skriva en kurs baserat p√• det. De √§r mycket bra p√• att skriva engagerande och informativt inneh√•ll, men de √§r inte s√§rskilt bra p√• att f√∂rst√• √§mnet och l√§randem√•len. N√•gra exempel p√• Decoder-modeller √§r GPT-familjemodeller, s√•som GPT-3.

Granskaren √§r som en modell med endast Encoder, de tittar p√• den skrivna kursen och svaren, m√§rker relationen mellan dem och f√∂rst√•r sammanhanget, men de √§r inte bra p√• att generera inneh√•ll. Ett exempel p√• en modell med endast Encoder skulle vara BERT.

F√∂rest√§ll dig att vi ocks√• kan ha n√•gon som b√•de kan skapa och granska quizet, detta √§r en Encoder-Decoder-modell. N√•gra exempel skulle vara BART och T5.

### Tj√§nst kontra Modell

Nu ska vi prata om skillnaden mellan en tj√§nst och en modell. En tj√§nst √§r en produkt som erbjuds av en molntj√§nstleverant√∂r och √§r ofta en kombination av modeller, data och andra komponenter. En modell √§r k√§rnkomponenten i en tj√§nst och √§r ofta en grundmodell, s√•som en LLM.

Tj√§nster √§r ofta optimerade f√∂r produktionsanv√§ndning och √§r ofta enklare att anv√§nda √§n modeller, via ett grafiskt anv√§ndargr√§nssnitt. Dock √§r tj√§nster inte alltid tillg√§ngliga gratis och kan kr√§va en prenumeration eller betalning f√∂r att anv√§ndas, i utbyte mot att utnyttja tj√§nste√§garens utrustning och resurser, optimera kostnader och skala enkelt. Ett exempel p√• en tj√§nst √§r [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som erbjuder en betalningsplan baserad p√• anv√§ndning, vilket inneb√§r att anv√§ndare debiteras proportionellt till hur mycket de anv√§nder tj√§nsten. Dessutom erbjuder Azure OpenAI Service s√§kerhet p√• f√∂retagsniv√• och en ansvarsfull AI-ram ovanp√• modellernas kapacitet.

Modeller √§r bara det neurala n√§tverket, med parametrar, vikter och annat. Detta g√∂r det m√∂jligt f√∂r f√∂retag att k√∂ra lokalt, men skulle kr√§va att k√∂pa utrustning, bygga en struktur f√∂r att skala och k√∂pa en licens eller anv√§nda en modell med √∂ppen k√§llkod. En modell som LLaMA √§r tillg√§nglig att anv√§nda, vilket kr√§ver ber√§kningskraft f√∂r att k√∂ra modellen.

## Hur man testar och itererar med olika modeller f√∂r att f√∂rst√• prestanda i Azure

N√§r v√•rt team har utforskat det aktuella LLM-landskapet och identifierat n√•gra bra kandidater f√∂r sina scenarier, √§r n√§sta steg att testa dem p√• deras data och arbetsbelastning. Detta √§r en iterativ process som g√∂rs genom experiment och m√§tningar.
De flesta av modellerna vi n√§mnde i tidigare stycken (OpenAI-modeller, √∂ppna k√§llkodsmodeller som Llama2 och Hugging Face transformers) finns tillg√§ngliga i [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √§r en molnplattform utformad f√∂r utvecklare att bygga generativa AI-applikationer och hantera hela utvecklingslivscykeln - fr√•n experimentering till utv√§rdering - genom att kombinera alla Azure AI-tj√§nster i en enda hub med ett anv√§ndarv√§nligt gr√§nssnitt. Model Catalog i Azure AI Studio g√∂r det m√∂jligt f√∂r anv√§ndaren att:

- Hitta den Foundation Model som √§r av intresse i katalogen - antingen propriet√§r eller √∂ppen k√§llkod, filtrera efter uppgift, licens eller namn. F√∂r att f√∂rb√§ttra s√∂kbarheten √§r modellerna organiserade i samlingar, som Azure OpenAI-samlingen, Hugging Face-samlingen och fler.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.sv.png)

- Granska modellkortet, inklusive en detaljerad beskrivning av avsedd anv√§ndning och tr√§ningsdata, kodexempel och utv√§rderingsresultat fr√•n det interna utv√§rderingsbiblioteket.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.sv.png)

- J√§mf√∂ra benchmarks mellan modeller och dataset som finns tillg√§ngliga i branschen f√∂r att bed√∂ma vilken som b√§st uppfyller aff√§rsscenariot, via [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst)-panelen.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.sv.png)

- Finjustera modellen med anpassad tr√§ningsdata f√∂r att f√∂rb√§ttra modellens prestanda i en specifik arbetsbelastning, med hj√§lp av experimenterings- och sp√•rningsfunktionerna i Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.sv.png)

- Distribuera den ursprungliga f√∂rtr√§nade modellen eller den finjusterade versionen till en fj√§rrbaserad realtidsinferens - hanterad ber√§kning - eller serverl√∂s API-slutpunkt - [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - f√∂r att m√∂jligg√∂ra att applikationer kan anv√§nda den.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.sv.png)

> [!NOTE]
> Alla modeller i katalogen √§r f√∂r n√§rvarande inte tillg√§ngliga f√∂r finjustering och/eller pay-as-you-go-distribution. Kontrollera modellkortet f√∂r detaljer om modellens kapabiliteter och begr√§nsningar.

## F√∂rb√§ttra LLM-resultat

Vi har tillsammans med v√•rt startup-team utforskat olika typer av LLM:er och en molnplattform (Azure Machine Learning) som g√∂r det m√∂jligt f√∂r oss att j√§mf√∂ra olika modeller, utv√§rdera dem p√• testdata, f√∂rb√§ttra prestanda och distribuera dem p√• inferensslutpunkter.

Men n√§r b√∂r de √∂verv√§ga att finjustera en modell ist√§llet f√∂r att anv√§nda en f√∂rtr√§nad? Finns det andra metoder f√∂r att f√∂rb√§ttra modellens prestanda f√∂r specifika arbetsbelastningar?

Det finns flera metoder som ett f√∂retag kan anv√§nda f√∂r att f√• de resultat de beh√∂ver fr√•n en LLM. Du kan v√§lja olika typer av modeller med olika grader av tr√§ning n√§r du distribuerar en LLM i produktion, med olika niv√•er av komplexitet, kostnad och kvalitet. H√§r √§r n√•gra olika metoder:

- **Prompt engineering med kontext**. Id√©n √§r att ge tillr√§ckligt med kontext n√§r du st√§ller en fr√•ga f√∂r att s√§kerst√§lla att du f√•r de svar du beh√∂ver.

- **Retrieval Augmented Generation, RAG**. Din data kan finnas i en databas eller webbtj√§nst, till exempel, f√∂r att s√§kerst√§lla att denna data, eller en del av den, inkluderas vid tidpunkten f√∂r fr√•gan, kan du h√§mta relevant data och g√∂ra den till en del av anv√§ndarens fr√•ga.

- **Finjusterad modell**. H√§r tr√§nar du modellen vidare p√• din egen data vilket g√∂r att modellen blir mer exakt och anpassad till dina behov, men det kan vara kostsamt.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.sv.png)

Bildk√§lla: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med Kontext

F√∂rtr√§nade LLM:er fungerar mycket bra p√• generella naturliga spr√•kuppgifter, √§ven n√§r de anv√§nds med en kort fr√•ga, som en mening att komplettera eller en fr√•ga ‚Äì det s√• kallade "zero-shot"-l√§randet.

Men ju mer anv√§ndaren kan formulera sin fr√•ga, med en detaljerad beg√§ran och exempel ‚Äì Kontexten ‚Äì desto mer exakt och n√§rmare anv√§ndarens f√∂rv√§ntningar blir svaret. I detta fall talar vi om "one-shot"-l√§rande om fr√•gan inneh√•ller endast ett exempel och "few-shot"-l√§rande om den inneh√•ller flera exempel. Prompt engineering med kontext √§r det mest kostnadseffektiva s√§ttet att b√∂rja med.

### Retrieval Augmented Generation (RAG)

LLM:er har begr√§nsningen att de endast kan anv√§nda den data som har anv√§nts under deras tr√§ning f√∂r att generera ett svar. Detta inneb√§r att de inte vet n√•got om fakta som intr√§ffat efter deras tr√§ningsprocess, och de kan inte komma √•t icke-offentlig information (som f√∂retagsdata).
Detta kan √∂vervinnas genom RAG, en teknik som f√∂rst√§rker fr√•gan med extern data i form av dokumentfragment, med h√§nsyn till begr√§nsningar i fr√•gel√§ngd. Detta st√∂ds av verktyg f√∂r vektordatabaser (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) som h√§mtar anv√§ndbara fragment fr√•n olika f√∂rdefinierade datak√§llor och l√§gger till dem i fr√•gans kontext.

Denna teknik √§r mycket anv√§ndbar n√§r ett f√∂retag inte har tillr√§ckligt med data, tid eller resurser f√∂r att finjustera en LLM, men √§nd√• vill f√∂rb√§ttra prestanda f√∂r en specifik arbetsbelastning och minska risken f√∂r fabriceringar, dvs. f√∂rvr√§ngning av verkligheten eller skadligt inneh√•ll.

### Finjusterad modell

Finjustering √§r en process som utnyttjar transfer learning f√∂r att "anpassa" modellen till en nedstr√∂msuppgift eller f√∂r att l√∂sa ett specifikt problem. Till skillnad fr√•n few-shot-l√§rande och RAG resulterar det i en ny modell som genereras, med uppdaterade vikter och f√∂rskjutningar. Det kr√§ver en upps√§ttning tr√§ningsexempel best√•ende av en enda input (fr√•gan) och dess associerade output (slutf√∂randet).
Detta skulle vara den f√∂redragna metoden om:

- **Anv√§nda finjusterade modeller**. Ett f√∂retag vill anv√§nda finjusterade mindre kapabla modeller (som inb√§ddningsmodeller) ist√§llet f√∂r h√∂gpresterande modeller, vilket resulterar i en mer kostnadseffektiv och snabb l√∂sning.

- **Beakta latens**. Latens √§r viktigt f√∂r ett specifikt anv√§ndningsfall, s√• det √§r inte m√∂jligt att anv√§nda mycket l√•nga fr√•gor eller antalet exempel som modellen ska l√§ra sig fr√•n passar inte med fr√•gel√§ngdsbegr√§nsningen.

- **H√•lla sig uppdaterad**. Ett f√∂retag har mycket h√∂gkvalitativ data och sanningsenliga etiketter samt de resurser som kr√§vs f√∂r att h√•lla denna data uppdaterad √∂ver tid.

### Tr√§nad modell

Att tr√§na en LLM fr√•n grunden √§r utan tvekan det sv√•raste och mest komplexa tillv√§gag√•ngss√§ttet att anta, vilket kr√§ver enorma m√§ngder data, kvalificerade resurser och l√§mplig ber√§kningskraft. Detta alternativ b√∂r endast √∂verv√§gas i ett scenario d√§r ett f√∂retag har ett dom√§nspecifikt anv√§ndningsfall och en stor m√§ngd dom√§ncentrerad data.

## Kunskapskontroll

Vad kan vara ett bra tillv√§gag√•ngss√§tt f√∂r att f√∂rb√§ttra LLM-slutf√∂ringsresultat?

1. Prompt engineering med kontext  
1. RAG  
1. Finjusterad modell  

A:3, om du har tid och resurser samt h√∂gkvalitativ data, √§r finjustering det b√§ttre alternativet f√∂r att h√•lla sig uppdaterad. Men om du vill f√∂rb√§ttra saker och saknar tid √§r det v√§rt att √∂verv√§ga RAG f√∂rst.

## üöÄ Utmaning

L√§s mer om hur du kan [anv√§nda RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) f√∂r ditt f√∂retag.

## Bra jobbat, forts√§tt din inl√§rning

Efter att ha avslutat denna lektion, kolla in v√•r [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att forts√§tta utveckla din kunskap om generativ AI!

G√• vidare till Lektion 3 d√§r vi kommer att titta p√• hur man [bygger med Generativ AI p√• ett ansvarsfullt s√§tt](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, b√∂r det noteras att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller felaktigheter. Det ursprungliga dokumentet p√• dess ursprungliga spr√•k b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller feltolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.