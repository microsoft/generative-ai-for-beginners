<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:28:13+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "sv"
}
-->
# Utforska och j√§mf√∂ra olika LLMs

[![Utforska och j√§mf√∂ra olika LLMs](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.sv.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Klicka p√• bilden ovan f√∂r att se videon till denna lektion_

I f√∂reg√•ende lektion har vi sett hur Generativ AI f√∂r√§ndrar tekniklandskapet, hur Large Language Models (LLMs) fungerar och hur ett f√∂retag ‚Äì som v√•r startup ‚Äì kan anv√§nda dem f√∂r sina anv√§ndningsomr√•den och v√§xa! I detta kapitel ska vi j√§mf√∂ra och kontrastera olika typer av stora spr√•kmodeller (LLMs) f√∂r att f√∂rst√• deras f√∂r- och nackdelar.

N√§sta steg i v√•r startups resa √§r att utforska det nuvarande landskapet av LLMs och f√∂rst√• vilka som passar f√∂r v√•rt anv√§ndningsfall.

## Introduktion

Denna lektion kommer att t√§cka:

- Olika typer av LLMs i dagens landskap.
- Testa, iterera och j√§mf√∂ra olika modeller f√∂r ditt anv√§ndningsfall i Azure.
- Hur man distribuerar en LLM.

## L√§randem√•l

Efter att ha genomf√∂rt denna lektion kommer du att kunna:

- V√§lja r√§tt modell f√∂r ditt anv√§ndningsfall.
- F√∂rst√• hur man testar, itererar och f√∂rb√§ttrar modellens prestanda.
- Veta hur f√∂retag distribuerar modeller.

## F√∂rst√• olika typer av LLMs

LLMs kan kategoriseras p√• flera s√§tt baserat p√• deras arkitektur, tr√§ningsdata och anv√§ndningsomr√•de. Att f√∂rst√• dessa skillnader hj√§lper v√•r startup att v√§lja r√§tt modell f√∂r scenariot och f√∂rst√• hur man testar, itererar och f√∂rb√§ttrar prestandan.

Det finns m√•nga olika typer av LLM-modeller, och ditt val beror p√• vad du vill anv√§nda dem till, din data, hur mycket du √§r beredd att betala och mer.

Beroende p√• om du vill anv√§nda modellerna f√∂r text, ljud, video, bildgenerering och s√• vidare, kan du beh√∂va v√§lja en annan typ av modell.

- **Ljud- och taligenk√§nning**. F√∂r detta √§ndam√•l √§r Whisper-typ modeller ett utm√§rkt val eftersom de √§r allm√§nna och inriktade p√• taligenk√§nning. De √§r tr√§nade p√• varierande ljud och kan utf√∂ra flerspr√•kig taligenk√§nning. L√§s mer om [Whisper-typ modeller h√§r](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Bildgenerering**. F√∂r bildgenerering √§r DALL-E och Midjourney tv√• mycket v√§lk√§nda val. DALL-E erbjuds via Azure OpenAI. [L√§s mer om DALL-E h√§r](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) och √§ven i kapitel 9 i denna kursplan.

- **Textgenerering**. De flesta modeller √§r tr√§nade f√∂r textgenerering och du har ett stort urval fr√•n GPT-3.5 till GPT-4. De har olika kostnader d√§r GPT-4 √§r den dyraste. Det √§r v√§rt att titta p√• [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) f√∂r att utv√§rdera vilka modeller som b√§st passar dina behov vad g√§ller kapacitet och kostnad.

- **Multimodalitet**. Om du vill hantera flera typer av data i in- och utdata kan du vilja titta p√• modeller som [gpt-4 turbo med vision eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ‚Äì de senaste OpenAI-modellerna ‚Äì som kan kombinera naturlig spr√•kbehandling med visuell f√∂rst√•else, vilket m√∂jligg√∂r interaktioner via multimodala gr√§nssnitt.

Att v√§lja en modell inneb√§r att du f√•r vissa grundl√§ggande funktioner, men det r√§cker ofta inte. Ofta har du f√∂retagspecifik data som du p√• n√•got s√§tt beh√∂ver informera LLM om. Det finns n√•gra olika s√§tt att n√§rma sig detta, mer om det i kommande avsnitt.

### Foundation Models kontra LLMs

Begreppet Foundation Model myntades av forskare vid Stanford och definieras som en AI-modell som uppfyller vissa kriterier, s√•som:

- **De tr√§nas med o√∂vervakad eller sj√§lv√∂vervakad inl√§rning**, vilket inneb√§r att de tr√§nas p√• om√§rkt multimodal data och inte kr√§ver m√§nsklig annotering eller m√§rkning av data f√∂r tr√§ningsprocessen.
- **De √§r mycket stora modeller**, baserade p√• mycket djupa neurala n√§tverk tr√§nade p√• miljarder parametrar.
- **De √§r normalt avsedda att fungera som en ‚Äògrund‚Äô f√∂r andra modeller**, vilket betyder att de kan anv√§ndas som utg√•ngspunkt f√∂r att bygga andra modeller ovanp√•, vilket kan g√∂ras genom finjustering.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.sv.png)

Bildk√§lla: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

F√∂r att ytterligare f√∂rtydliga denna skillnad, l√•t oss ta ChatGPT som exempel. F√∂r att bygga den f√∂rsta versionen av ChatGPT anv√§ndes en modell som heter GPT-3.5 som foundation model. Det betyder att OpenAI anv√§nde viss chatt-specifik data f√∂r att skapa en finjusterad version av GPT-3.5 som var specialiserad p√• att prestera bra i konversationsscenarier, som chattbotar.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.sv.png)

Bildk√§lla: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source kontra Propriet√§ra modeller

Ett annat s√§tt att kategorisera LLMs √§r om de √§r open source eller propriet√§ra.

Open source-modeller √§r modeller som g√∂rs tillg√§ngliga f√∂r allm√§nheten och kan anv√§ndas av vem som helst. De g√∂rs ofta tillg√§ngliga av f√∂retaget som skapade dem eller av forskarsamh√§llet. Dessa modeller f√•r inspekteras, modifieras och anpassas f√∂r olika anv√§ndningsomr√•den inom LLMs. De √§r dock inte alltid optimerade f√∂r produktionsbruk och kanske inte √§r lika presterande som propriet√§ra modeller. Dessutom kan finansieringen f√∂r open source-modeller vara begr√§nsad, och de kanske inte underh√•lls l√•ngsiktigt eller uppdateras med den senaste forskningen. Exempel p√• popul√§ra open source-modeller √§r [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) och [LLaMA](https://llama.meta.com).

Propriet√§ra modeller √§r modeller som √§gs av ett f√∂retag och inte g√∂rs tillg√§ngliga f√∂r allm√§nheten. Dessa modeller √§r ofta optimerade f√∂r produktionsbruk. De f√•r dock inte inspekteras, modifieras eller anpassas f√∂r olika anv√§ndningsomr√•den. Dessutom √§r de inte alltid gratis och kan kr√§va prenumeration eller betalning f√∂r att anv√§ndas. Anv√§ndare har inte heller kontroll √∂ver den data som anv√§nds f√∂r att tr√§na modellen, vilket inneb√§r att de m√•ste lita p√• att modell√§garen s√§kerst√§ller engagemang f√∂r dataskydd och ansvarsfull AI-anv√§ndning. Exempel p√• popul√§ra propriet√§ra modeller √§r [OpenAI-modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) eller [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding kontra Bildgenerering kontra Text- och kodgenerering

LLMs kan ocks√• kategoriseras efter vilken typ av output de genererar.

Embeddings √§r en upps√§ttning modeller som kan omvandla text till en numerisk form, kallad embedding, vilket √§r en numerisk representation av inmatningstexten. Embeddings g√∂r det enklare f√∂r maskiner att f√∂rst√• relationerna mellan ord eller meningar och kan anv√§ndas som indata f√∂r andra modeller, s√•som klassificeringsmodeller eller klustringsmodeller som presterar b√§ttre p√• numerisk data. Embedding-modeller anv√§nds ofta f√∂r transfer learning, d√§r en modell byggs f√∂r en surrogatuppgift med mycket data, och sedan √•teranv√§nds modellvikterna (embeddings) f√∂r andra efterf√∂ljande uppgifter. Ett exempel p√• denna kategori √§r [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.sv.png)

Bildgenereringsmodeller √§r modeller som genererar bilder. Dessa modeller anv√§nds ofta f√∂r bildredigering, bildsyntes och bild√∂vers√§ttning. Bildgenereringsmodeller tr√§nas ofta p√• stora bilddatam√§ngder, som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), och kan anv√§ndas f√∂r att skapa nya bilder eller redigera befintliga bilder med tekniker som inpainting, superuppl√∂sning och f√§rgl√§ggning. Exempel inkluderar [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) och [Stable Diffusion-modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Bildgenerering](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.sv.png)

Text- och kodgenereringsmodeller √§r modeller som genererar text eller kod. Dessa modeller anv√§nds ofta f√∂r textsammanfattning, √∂vers√§ttning och fr√•gesvar. Textgenereringsmodeller tr√§nas ofta p√• stora textdatam√§ngder, som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), och kan anv√§ndas f√∂r att generera ny text eller svara p√• fr√•gor. Kodgenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), tr√§nas ofta p√• stora koddatam√§ngder, som GitHub, och kan anv√§ndas f√∂r att generera ny kod eller fixa buggar i befintlig kod.

![Text- och kodgenerering](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.sv.png)

### Encoder-Decoder kontra Decoder-only

F√∂r att prata om olika typer av arkitekturer f√∂r LLMs, l√•t oss anv√§nda en liknelse.

F√∂rest√§ll dig att din chef gav dig i uppdrag att skriva ett quiz f√∂r studenterna. Du har tv√• kollegor; en ansvarar f√∂r att skapa inneh√•llet och den andra f√∂r att granska det.

Inneh√•llsskaparen √§r som en Decoder-only modell, de kan titta p√• √§mnet och se vad du redan skrivit och sedan skriva en kurs baserat p√• det. De √§r mycket bra p√• att skriva engagerande och informativt inneh√•ll, men √§r inte s√• bra p√• att f√∂rst√• √§mnet och l√§randem√•len. N√•gra exempel p√• Decoder-modeller √§r GPT-familjen, som GPT-3.

Granskaren √§r som en Encoder-only modell, de tittar p√• den skrivna kursen och svaren, noterar relationen mellan dem och f√∂rst√•r kontexten, men √§r inte bra p√• att generera inneh√•ll. Ett exempel p√• en Encoder-only modell √§r BERT.

F√∂rest√§ll dig att vi kan ha n√•gon som b√•de kan skapa och granska quizet, detta √§r en Encoder-Decoder modell. N√•gra exempel √§r BART och T5.

### Tj√§nst kontra Modell

Nu ska vi prata om skillnaden mellan en tj√§nst och en modell. En tj√§nst √§r en produkt som erbjuds av en molntj√§nstleverant√∂r och √§r ofta en kombination av modeller, data och andra komponenter. En modell √§r k√§rnkomponenten i en tj√§nst och √§r ofta en foundation model, som en LLM.

Tj√§nster √§r ofta optimerade f√∂r produktionsbruk och √§r ofta enklare att anv√§nda √§n modeller, via ett grafiskt anv√§ndargr√§nssnitt. Tj√§nster √§r dock inte alltid gratis och kan kr√§va prenumeration eller betalning f√∂r att anv√§ndas, i utbyte mot att utnyttja tj√§nste√§garens utrustning och resurser, optimera kostnader och enkelt skala. Ett exempel p√• en tj√§nst √§r [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som erbjuder en betalningsmodell baserad p√• anv√§ndning, vilket inneb√§r att anv√§ndare debiteras proportionellt efter hur mycket de anv√§nder tj√§nsten. Dessutom erbjuder Azure OpenAI Service f√∂retagsklassad s√§kerhet och ett ramverk f√∂r ansvarsfull AI ovanp√• modellernas kapabiliteter.

Modeller √§r bara det neurala n√§tverket, med parametrar, vikter och annat. De kan k√∂ras lokalt av f√∂retag, men d√• beh√∂ver man k√∂pa utrustning, bygga en struktur f√∂r skalning och k√∂pa licens eller anv√§nda en open source-modell. En modell som LLaMA finns tillg√§nglig f√∂r anv√§ndning, men kr√§ver ber√§kningskraft f√∂r att k√∂ra modellen.

## Hur man testar och itererar med olika modeller f√∂r att f√∂rst√• prestanda i Azure

N√§r v√•rt team har utforskat det nuvarande LLM-landskapet och identifierat n√•gra bra kandidater f√∂r sina scenarier, √§r n√§sta steg att testa dem p√• deras data och arbetsbelastning. Detta √§r en iterativ process som g√∂rs genom experiment och m√§tningar.
De flesta av de modeller vi n√§mnde i tidigare avsnitt (OpenAI-modeller, open source-modeller som Llama2 och Hugging Face-transformers) finns tillg√§ngliga i [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √§r en molnplattform designad f√∂r utvecklare att bygga generativa AI-applikationer och hantera hela utvecklingscykeln ‚Äì fr√•n experiment till utv√§rdering ‚Äì genom att kombinera alla Azure AI-tj√§nster i en enda hubb med ett anv√§ndarv√§nligt GUI. Model Catalog i Azure AI Studio g√∂r det m√∂jligt f√∂r anv√§ndaren att:

- Hitta det Foundation Model som √§r intressant i katalogen ‚Äì antingen propriet√§rt eller open source, med filtrering efter uppgift, licens eller namn. F√∂r att f√∂rb√§ttra s√∂kbarheten √§r modellerna organiserade i samlingar, som Azure OpenAI-samlingen, Hugging Face-samlingen och fler.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.sv.png)

- Granska model card, inklusive en detaljerad beskrivning av avsedd anv√§ndning och tr√§ningsdata, kodexempel och utv√§rderingsresultat fr√•n det interna utv√§rderingsbiblioteket.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.sv.png)

- J√§mf√∂ra benchmarks mellan modeller och dataset som finns tillg√§ngliga i branschen f√∂r att bed√∂ma vilken som passar b√§st f√∂r aff√§rsscenariot, via [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst)-panelen.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.sv.png)

- Finjustera modellen p√• egen tr√§ningsdata f√∂r att f√∂rb√§ttra modellens prestanda i en specifik arbetsbelastning, med hj√§lp av experiment- och sp√•rningsfunktionerna i Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.sv.png)

- Distribuera den ursprungliga f√∂rtr√§nade modellen eller den finjusterade versionen till en fj√§rrstyrd realtidsinferenz ‚Äì hanterad ber√§kning ‚Äì eller serverl√∂s API-endpoint ‚Äì [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) ‚Äì f√∂r att m√∂jligg√∂ra att applikationer kan anv√§nda den.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.sv.png)


> [!NOTE]
> Alla modeller i katalogen √§r inte f√∂r n√§rvarande tillg√§ngliga f√∂r finjustering och/eller pay-as-you-go-distribution. Kontrollera model card f√∂r detaljer om modellens kapabiliteter och begr√§nsningar.

## F√∂rb√§ttra LLM-resultat

Vi har tillsammans med v√•rt startup-team utforskat olika typer av LLM:er och en molnplattform (Azure Machine Learning) som g√∂r det m√∂jligt f√∂r oss att j√§mf√∂ra olika modeller, utv√§rdera dem p√• testdata, f√∂rb√§ttra prestanda och distribuera dem p√• inferensendpoints.

Men n√§r b√∂r man √∂verv√§ga att finjustera en modell ist√§llet f√∂r att anv√§nda en f√∂rtr√§nad? Finns det andra metoder f√∂r att f√∂rb√§ttra modellens prestanda p√• specifika arbetsuppgifter?

Det finns flera tillv√§gag√•ngss√§tt som ett f√∂retag kan anv√§nda f√∂r att f√• de resultat de beh√∂ver fr√•n en LLM. Du kan v√§lja olika typer av modeller med olika grader av tr√§ning n√§r du distribuerar en LLM i produktion, med olika niv√•er av komplexitet, kostnad och kvalitet. H√§r √§r n√•gra olika metoder:

- **Prompt engineering med kontext**. Id√©n √§r att ge tillr√§ckligt med kontext n√§r du ger prompten f√∂r att s√§kerst√§lla att du f√•r de svar du beh√∂ver.

- **Retrieval Augmented Generation, RAG**. Din data kan till exempel finnas i en databas eller web-endpoint, och f√∂r att s√§kerst√§lla att denna data, eller en delm√§ngd av den, inkluderas vid promptning kan du h√§mta relevant data och g√∂ra den till en del av anv√§ndarens prompt.

- **Finjusterad modell**. H√§r tr√§nar du modellen vidare p√• din egen data vilket g√∂r att modellen blir mer exakt och anpassad efter dina behov, men det kan vara kostsamt.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.sv.png)

Bildk√§lla: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med Kontext

F√∂rtr√§nade LLM:er fungerar mycket bra p√• generella naturliga spr√•k-uppgifter, √§ven genom att bara anropa dem med en kort prompt, som en mening att slutf√∂ra eller en fr√•ga ‚Äì det s√• kallade ‚Äùzero-shot‚Äù-l√§randet.

Men ju mer anv√§ndaren kan rama in sin fr√•ga, med en detaljerad f√∂rfr√•gan och exempel ‚Äì Kontexten ‚Äì desto mer exakt och n√§ra anv√§ndarens f√∂rv√§ntningar blir svaret. I detta fall talar vi om ‚Äùone-shot‚Äù-l√§rande om prompten inneh√•ller endast ett exempel och ‚Äùfew-shot‚Äù-l√§rande om den inneh√•ller flera exempel. Prompt engineering med kontext √§r det mest kostnadseffektiva s√§ttet att komma ig√•ng p√•.

### Retrieval Augmented Generation (RAG)

LLM:er har begr√§nsningen att de bara kan anv√§nda den data som anv√§nts under deras tr√§ning f√∂r att generera ett svar. Det betyder att de inte k√§nner till fakta som intr√§ffat efter deras tr√§ningsprocess, och de kan inte komma √•t icke-offentlig information (som f√∂retagsdata).  
Detta kan √∂vervinnas med RAG, en teknik som f√∂rst√§rker prompten med extern data i form av dokumentbitar, med h√§nsyn till promptens l√§ngdbegr√§nsningar. Detta st√∂ds av vektordatabaser (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) som h√§mtar anv√§ndbara delar fr√•n olika f√∂rdefinierade datak√§llor och l√§gger till dem i promptens kontext.

Denna teknik √§r mycket anv√§ndbar n√§r ett f√∂retag inte har tillr√§ckligt med data, tid eller resurser f√∂r att finjustera en LLM, men √§nd√• vill f√∂rb√§ttra prestandan p√• en specifik arbetsuppgift och minska risken f√∂r fabriceringar, dvs. f√∂rvr√§ngning av verkligheten eller skadligt inneh√•ll.

### Finjusterad modell

Finjustering √§r en process som anv√§nder transfer learning f√∂r att ‚Äùanpassa‚Äù modellen till en specifik uppgift eller f√∂r att l√∂sa ett s√§rskilt problem. Till skillnad fr√•n few-shot-l√§rande och RAG resulterar det i att en ny modell skapas, med uppdaterade vikter och bias. Det kr√§ver en upps√§ttning tr√§ningsexempel best√•ende av en enda input (prompten) och dess tillh√∂rande output (kompletteringen).  
Detta √§r den f√∂redragna metoden om:

- **Anv√§nda finjusterade modeller**. Ett f√∂retag vill anv√§nda finjusterade, mindre kraftfulla modeller (som embedding-modeller) ist√§llet f√∂r h√∂gpresterande modeller, vilket ger en mer kostnadseffektiv och snabb l√∂sning.

- **T√§nka p√• latens**. Latens √§r viktigt f√∂r ett specifikt anv√§ndningsfall, s√• det √§r inte m√∂jligt att anv√§nda mycket l√•nga prompts eller antalet exempel som modellen ska l√§ra sig fr√•n passar inte in i promptens l√§ngdbegr√§nsning.

- **H√•lla sig uppdaterad**. Ett f√∂retag har mycket h√∂gkvalitativ data och sanna etiketter samt resurser f√∂r att h√•lla denna data uppdaterad √∂ver tid.

### Tr√§nad modell

Att tr√§na en LLM fr√•n grunden √§r utan tvekan det sv√•raste och mest komplexa tillv√§gag√•ngss√§ttet, som kr√§ver enorma m√§ngder data, skickliga resurser och l√§mplig ber√§kningskraft. Detta alternativ b√∂r endast √∂verv√§gas i ett scenario d√§r ett f√∂retag har ett dom√§nspecifikt anv√§ndningsfall och en stor m√§ngd dom√§ncentrerad data.

## Kunskapskontroll

Vad kan vara ett bra s√§tt att f√∂rb√§ttra LLM:s genererade resultat?

1. Prompt engineering med kontext  
1. RAG  
1. Finjusterad modell

Svar: 3, om du har tid, resurser och h√∂gkvalitativ data √§r finjustering det b√§sta alternativet f√∂r att h√•lla sig uppdaterad. Men om du vill f√∂rb√§ttra saker och saknar tid √§r det v√§rt att f√∂rst √∂verv√§ga RAG.

## üöÄ Utmaning

L√§s mer om hur du kan [anv√§nda RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) f√∂r ditt f√∂retag.

## Bra jobbat, forts√§tt l√§ra dig

Efter att ha slutf√∂rt denna lektion, kolla in v√•r [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att forts√§tta utveckla dina kunskaper inom Generativ AI!

G√• vidare till Lektion 3 d√§r vi tittar p√• hur man [bygger med Generativ AI p√• ett ansvarsfullt s√§tt](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, v√§nligen observera att automatiska √∂vers√§ttningar kan inneh√•lla fel eller brister. Det ursprungliga dokumentet p√• dess modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r n√•gra missf√∂rst√•nd eller feltolkningar som uppst√•r till f√∂ljd av anv√§ndningen av denna √∂vers√§ttning.