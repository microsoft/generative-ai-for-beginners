{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "För att kunna köra följande anteckningsböcker, om du inte redan har gjort det, behöver du ange openai-nyckeln i .env-filen som `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nästa steg är att ladda in Embedding Index i en Pandas Dataframe. Embedding Index är lagrat i en JSON-fil som heter `embedding_index_3m.json`. Embedding Index innehåller embeddingar för varje YouTube-transkript fram till slutet av oktober 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nästa steg är att skapa en funktion som heter `get_videos` som kommer att söka i Embedding Index efter frågan. Funktionen kommer att returnera de 5 bästa videorna som är mest lik frågan. Funktionen fungerar på följande sätt:\n",
    "\n",
    "1. Först skapas en kopia av Embedding Index.\n",
    "2. Därefter beräknas Embedding för frågan med hjälp av OpenAI Embedding API.\n",
    "3. Sedan skapas en ny kolumn i Embedding Index som heter `similarity`. Kolumnen `similarity` innehåller cosinuslikheten mellan frågans Embedding och Embedding för varje videosegment.\n",
    "4. Nästa steg är att filtrera Embedding Index efter kolumnen `similarity`. Embedding Index filtreras för att endast inkludera videor som har en cosinuslikhet större än eller lika med 0,75.\n",
    "5. Slutligen sorteras Embedding Index efter kolumnen `similarity` och de 5 bästa videorna returneras.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den här funktionen är mycket enkel, den skriver bara ut resultaten av sökfrågan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Först laddas Embedding Index in i en Pandas Dataframe.  \n",
    "2. Därefter uppmanas användaren att skriva in en fråga.  \n",
    "3. Sedan anropas funktionen `get_videos` för att söka i Embedding Index efter frågan.  \n",
    "4. Slutligen anropas funktionen `display_results` för att visa resultaten för användaren.  \n",
    "5. Användaren uppmanas sedan att skriva in en ny fråga. Denna process fortsätter tills användaren skriver `exit`.  \n",
    "\n",
    "![](../../../../translated_images/sv/notebook-search.1e320b9c7fcbb0bc.webp)  \n",
    "\n",
    "Du kommer att uppmanas att skriva in en fråga. Skriv in en fråga och tryck på enter. Applikationen kommer att returnera en lista med videor som är relevanta för frågan. Applikationen kommer också att returnera en länk till platsen i videon där svaret på frågan finns.  \n",
    "\n",
    "Här är några frågor att prova:  \n",
    "\n",
    "- Vad är Azure Machine Learning?  \n",
    "- Hur fungerar konvolutionella neurala nätverk?  \n",
    "- Vad är ett neuralt nätverk?  \n",
    "- Kan jag använda Jupyter Notebooks med Azure Machine Learning?  \n",
    "- Vad är ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Ansvarsfriskrivning**:\nDetta dokument har översatts med hjälp av AI-översättningstjänsten [Co-op Translator](https://github.com/Azure/co-op-translator). Även om vi strävar efter noggrannhet, vänligen observera att automatiska översättningar kan innehålla fel eller brister. Det ursprungliga dokumentet på dess modersmål bör betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell mänsklig översättning. Vi ansvarar inte för några missförstånd eller feltolkningar som uppstår till följd av användningen av denna översättning.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T10:27:50+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "sv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}