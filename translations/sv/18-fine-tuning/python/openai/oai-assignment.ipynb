{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finjustering av Open AI-modeller\n",
    "\n",
    "Denna anteckningsbok är baserad på den aktuella vägledningen som tillhandahålls i [Finjustering](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) dokumentationen från Open AI.\n",
    "\n",
    "Finjustering förbättrar prestandan hos grundmodeller för din applikation genom att träna om den med ytterligare data och kontext som är relevant för just det specifika användningsfallet eller scenariot. Observera att prompttekniker som _few shot learning_ och _retrieval augmented generation_ låter dig förbättra standardprompten med relevant data för att höja kvaliteten. Dessa metoder är dock begränsade av max token-fönstrets storlek för den riktade grundmodellen.\n",
    "\n",
    "Med finjustering tränar vi effektivt om modellen själv med den nödvändiga datan (vilket tillåter oss att använda många fler exempel än vad som får plats i max token-fönstret) - och distribuerar en _anpassad_ version av modellen som inte längre behöver få exempel vid inferenstid. Detta förbättrar inte bara effektiviteten i vår promptdesign (vi har mer flexibilitet att använda token-fönstret för andra saker) utan kan också potentiellt förbättra våra kostnader (genom att minska antalet tokens vi behöver skicka till modellen vid inferenstid).\n",
    "\n",
    "Finjustering har 4 steg:\n",
    "1. Förbered träningsdata och ladda upp den.\n",
    "1. Kör träningsjobbet för att få en finjusterad modell.\n",
    "1. Utvärdera den finjusterade modellen och iterera för kvalitet.\n",
    "1. Distribuera den finjusterade modellen för inferens när du är nöjd.\n",
    "\n",
    "Observera att inte alla grundmodeller stödjer finjustering - [kolla OpenAI-dokumentationen](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) för den senaste informationen. Du kan också finjustera en tidigare finjusterad modell. I denna handledning kommer vi att använda `gpt-35-turbo` som vår målgrundmodell för finjustering.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 1.1: Förbered din dataset\n",
    "\n",
    "Låt oss bygga en chatbot som hjälper dig att förstå det periodiska systemet genom att svara på frågor om ett grundämne med en limerick. I _denna_ enkla handledning kommer vi bara att skapa en dataset för att träna modellen med några exempel på svar som visar det förväntade formatet på datan. I ett verkligt användningsfall skulle du behöva skapa en dataset med många fler exempel. Du kan också eventuellt använda en öppen dataset (för ditt applikationsområde) om en sådan finns, och omformatera den för användning vid finjustering.\n",
    "\n",
    "Eftersom vi fokuserar på `gpt-35-turbo` och söker ett svar i en enda vändning (chat completion) kan vi skapa exempel med [detta föreslagna format](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) som speglar OpenAI:s krav för chat completion. Om du förväntar dig innehåll i flera vändningar skulle du använda [formatet för exempel med flera vändningar](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) som inkluderar en `weight`-parameter för att signalera vilka meddelanden som ska användas (eller inte) i finjusteringsprocessen.\n",
    "\n",
    "Vi kommer att använda det enklare formatet för en enda vändning för vår handledning här. Datan är i [jsonl-format](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) med 1 post per rad, där varje post representeras som ett JSON-formaterat objekt. Utdraget nedan visar 2 poster som exempel – se [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) för hela exempeluppsättningen (10 exempel) som vi använder för vår finjusteringshandledning. **Notera:** Varje post _måste_ definieras på en enda rad (inte uppdelad över flera rader som är vanligt i en formaterad JSON-fil)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "I ett verkligt användningsfall behöver du en mycket större uppsättning exempel för bra resultat – avvägningen kommer att vara mellan kvaliteten på svaren och tiden/kostnaderna för finjustering. Vi använder en liten uppsättning så att vi snabbt kan slutföra finjusteringen för att illustrera processen. Se [detta exempel från OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) för en mer komplex handledning i finjustering.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Steg 1.2 Ladda upp din dataset\n",
    "\n",
    "Ladda upp data med hjälp av Files API [som beskrivs här](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Observera att för att köra denna kod måste du först ha gjort följande steg:\n",
    " - Installerat Python-paketet `openai` (se till att du använder en version >=0.28.0 för de senaste funktionerna)\n",
    " - Satt miljövariabeln `OPENAI_API_KEY` till din OpenAI API-nyckel\n",
    "För att lära dig mer, se [Setup-guiden](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) som tillhandahålls för kursen.\n",
    "\n",
    "Kör nu koden för att skapa en fil för uppladdning från din lokala JSONL-fil.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Steg 2.1: Skapa finjusteringsjobbet med SDK:n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Steg 2.2: Kontrollera status för jobbet\n",
    "\n",
    "Här är några saker du kan göra med `client.fine_tuning.jobs` API:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Lista de senaste n finjusteringsjobben\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Hämta detaljer för ett specifikt finjusteringsjobb\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Avbryt ett finjusteringsjobb\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Lista upp till n händelser från jobbet\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Det första steget i processen är _att validera träningsfilen_ för att säkerställa att data är i rätt format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Steg 2.3: Spåra händelser för att övervaka framsteg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steg 2.4: Visa status i OpenAI-instrumentpanelen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kan också se statusen genom att besöka OpenAI:s webbplats och utforska avsnittet _Fine-tuning_ på plattformen. Detta visar statusen för det aktuella jobbet och låter dig även följa historiken för tidigare körningar av jobb. I denna skärmdump kan du se att den tidigare körningen misslyckades, och den andra körningen lyckades. För kontext hände detta när den första körningen använde en JSON-fil med felaktigt formaterade poster – när detta rättades till slutfördes den andra körningen framgångsrikt och gjorde modellen tillgänglig för användning.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/sv/fine-tuned-model-status.563271727bf7bfba.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Du kan också se statusmeddelanden och mätvärden genom att scrolla längre ner i den visuella instrumentpanelen som visas:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/sv/fine-tuned-messages-panel.4ed0c2da5ea1313b.png) |  ![Metrics](../../../../../translated_images/sv/fine-tuned-metrics-panel.700d7e4995a65229.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Steg 3.1: Hämta ID & Testa finjusterad modell i kod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Steg 3.2: Ladda och testa finjusterad modell i Playground\n",
    "\n",
    "Du kan nu testa den finjusterade modellen på två sätt. Först kan du besöka Playground och använda rullgardinsmenyn Models för att välja din nyfinjusterade modell från de listade alternativen. Det andra alternativet är att använda \"Playground\"-alternativet som visas i Fine-tuning-panelen (se skärmdump ovan) vilket startar följande _jämförande_ vy som visar grundmodellen och den finjusterade modellversionen sida vid sida för snabb utvärdering.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/sv/fine-tuned-playground-compare.56e06f0ad8922016.png)\n",
    "\n",
    "Fyll helt enkelt i systemkontexten som användes i din träningsdata och ange din testfråga. Du kommer att märka att båda sidor uppdateras med identisk kontext och fråga. Kör jämförelsen och du kommer att se skillnaden i svaren mellan dem. _Notera hur den finjusterade modellen återger svaret i det format du angav i dina exempel medan grundmodellen helt enkelt följer systemprompten_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/sv/fine-tuned-playground-launch.5a26495c983c6350.png)\n",
    "\n",
    "Du kommer att märka att jämförelsen också visar tokenräkningen för varje modell och den tid som tagits för inferensen. **Detta specifika exempel är ett förenklat sådant som är avsett att visa processen men speglar inte en verklig dataset eller scenario**. Du kan märka att båda exemplen visar samma antal tokens (systemkontext och användarprompt är identiska) med den finjusterade modellen som tar längre tid för inferens (anpassad modell).\n",
    "\n",
    "I verkliga scenarier kommer du inte att använda ett leksaksexempel som detta, utan finjustera mot verklig data (t.ex. produktkatalog för kundservice) där kvaliteten på svaret kommer att vara mycket tydligare. I _det_ sammanhanget kommer det att krävas mer anpassad promptteknik för att få motsvarande svarskvalitet med grundmodellen, vilket ökar tokenanvändningen och potentiellt den relaterade bearbetningstiden för inferens. _För att prova detta, kolla in finjusteringsexemplen i OpenAI Cookbook för att komma igång._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Ansvarsfriskrivning**:\nDetta dokument har översatts med hjälp av AI-översättningstjänsten [Co-op Translator](https://github.com/Azure/co-op-translator). Även om vi strävar efter noggrannhet, vänligen observera att automatiska översättningar kan innehålla fel eller brister. Det ursprungliga dokumentet på dess modersmål bör betraktas som den auktoritativa källan. För kritisk information rekommenderas professionell mänsklig översättning. Vi ansvarar inte för några missförstånd eller feltolkningar som uppstår till följd av användningen av denna översättning.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T10:30:48+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "sv"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}