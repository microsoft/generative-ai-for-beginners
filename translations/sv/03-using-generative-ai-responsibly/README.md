<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:41:16+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "sv"
}
-->
# Anv√§nda Generativ AI Ansvarsfullt

[![Anv√§nda Generativ AI Ansvarsfullt](../../../translated_images/03-lesson-banner.63a265562d8a9f9230f5c636ab303a0137d11420177528f475b0a05c5f6a9ff9.sv.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Klicka p√• bilden ovan f√∂r att se videon av denna lektion_

Det √§r l√§tt att fascineras av AI och generativ AI i synnerhet, men du beh√∂ver √∂verv√§ga hur du skulle anv√§nda det ansvarsfullt. Du beh√∂ver t√§nka p√• saker som hur du s√§kerst√§ller att output √§r r√§ttvis, icke-skadlig och mer. Detta kapitel syftar till att ge dig den n√§mnda kontexten, vad du b√∂r √∂verv√§ga och hur du kan ta aktiva steg f√∂r att f√∂rb√§ttra din AI-anv√§ndning.

## Introduktion

Denna lektion kommer att t√§cka:

- Varf√∂r du b√∂r prioritera Ansvarsfull AI n√§r du bygger Generativa AI-applikationer.
- Grundprinciper f√∂r Ansvarsfull AI och hur de relaterar till Generativ AI.
- Hur du oms√§tter dessa principer f√∂r Ansvarsfull AI i praktiken genom strategi och verktyg.

## Inl√§rningsm√•l

Efter att ha avslutat denna lektion kommer du att veta:

- Vikten av Ansvarsfull AI n√§r du bygger Generativa AI-applikationer.
- N√§r du ska t√§nka och till√§mpa de grundl√§ggande principerna f√∂r Ansvarsfull AI n√§r du bygger Generativa AI-applikationer.
- Vilka verktyg och strategier som finns tillg√§ngliga f√∂r att oms√§tta konceptet Ansvarsfull AI i praktiken.

## Principer f√∂r Ansvarsfull AI

Entusiasmen f√∂r Generativ AI har aldrig varit st√∂rre. Denna entusiasm har f√∂rt med sig m√•nga nya utvecklare, uppm√§rksamhet och finansiering till detta omr√•de. √Ñven om detta √§r mycket positivt f√∂r alla som vill bygga produkter och f√∂retag med Generativ AI, √§r det ocks√• viktigt att vi forts√§tter ansvarsfullt.

Under hela denna kurs fokuserar vi p√• att bygga v√•r startup och v√•r AI-utbildningsprodukt. Vi kommer att anv√§nda principerna f√∂r Ansvarsfull AI: R√§ttvisa, Inkluderande, P√•litlighet/S√§kerhet, S√§kerhet & Integritet, Transparens och Ansvarighet. Med dessa principer kommer vi att utforska hur de relaterar till v√•r anv√§ndning av Generativ AI i v√•ra produkter.

## Varf√∂r Ska Du Prioritera Ansvarsfull AI

N√§r du bygger en produkt, leder ett m√§nniskocentrerat f√∂rh√•llningss√§tt med anv√§ndarens b√§sta intresse i √•tanke till de b√§sta resultaten.

Det unika med Generativ AI √§r dess kraft att skapa hj√§lpsamma svar, information, v√§gledning och inneh√•ll f√∂r anv√§ndare. Detta kan g√∂ras utan m√•nga manuella steg vilket kan leda till mycket imponerande resultat. Utan ordentlig planering och strategier kan det tyv√§rr ocks√• leda till skadliga resultat f√∂r dina anv√§ndare, din produkt och samh√§llet som helhet.

L√•t oss titta p√• n√•gra (men inte alla) av dessa potentiellt skadliga resultat:

### Hallucinationer

Hallucinationer √§r en term som anv√§nds f√∂r att beskriva n√§r en LLM producerar inneh√•ll som antingen √§r helt nonsens eller n√•got vi vet √§r faktam√§ssigt felaktigt baserat p√• andra informationsk√§llor.

L√•t oss ta ett exempel d√§r vi bygger en funktion f√∂r v√•r startup som till√•ter studenter att st√§lla historiska fr√•gor till en modell. En student st√§ller fr√•gan `Who was the sole survivor of Titanic?`

Modellen ger ett svar som det nedan:

![Uppmaning som s√§ger "Vem var den enda √∂verlevande fr√•n Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(K√§lla: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Detta √§r ett mycket sj√§lvs√§kert och grundligt svar. Tyv√§rr √§r det felaktigt. √Ñven med en minimal m√§ngd forskning skulle man uppt√§cka att det fanns mer √§n en √∂verlevande fr√•n Titanic-katastrofen. F√∂r en student som just b√∂rjat forska i detta √§mne kan detta svar vara √∂vertygande nog att inte ifr√•gas√§ttas och behandlas som fakta. Konsekvenserna av detta kan leda till att AI-systemet blir op√•litligt och negativt p√•verkar v√•r startups rykte.

Med varje iteration av en given LLM har vi sett prestandaf√∂rb√§ttringar kring att minimera hallucinationer. √Ñven med denna f√∂rb√§ttring beh√∂ver vi som applikationsbyggare och anv√§ndare fortfarande vara medvetna om dessa begr√§nsningar.

### Skadligt Inneh√•ll

Vi t√§ckte i den tidigare sektionen n√§r en LLM producerar felaktiga eller nonsensiska svar. En annan risk vi beh√∂ver vara medvetna om √§r n√§r en modell svarar med skadligt inneh√•ll.

Skadligt inneh√•ll kan definieras som:

- Att ge instruktioner eller uppmuntra till sj√§lvskada eller skada mot vissa grupper.
- Hatiskt eller neds√§ttande inneh√•ll.
- Att v√§gleda planering av n√•gon typ av attack eller v√•ldsamma handlingar.
- Att ge instruktioner om hur man hittar olagligt inneh√•ll eller beg√•r olagliga handlingar.
- Att visa sexuellt explicit inneh√•ll.

F√∂r v√•r startup vill vi se till att vi har r√§tt verktyg och strategier p√• plats f√∂r att f√∂rhindra att denna typ av inneh√•ll ses av studenter.

### Brist p√• R√§ttvisa

R√§ttvisa definieras som ‚Äúatt s√§kerst√§lla att ett AI-system √§r fritt fr√•n bias och diskriminering och att det behandlar alla r√§ttvist och j√§mlikt.‚Äù I v√§rlden av Generativ AI vill vi s√§kerst√§lla att exkluderande v√§rldsbilder av marginaliserade grupper inte f√∂rst√§rks av modellens output.

Dessa typer av outputs √§r inte bara destruktiva f√∂r att bygga positiva produktupplevelser f√∂r v√•ra anv√§ndare, utan de orsakar ocks√• ytterligare samh√§llelig skada. Som applikationsbyggare b√∂r vi alltid h√•lla en bred och diversifierad anv√§ndarbas i √•tanke n√§r vi bygger l√∂sningar med Generativ AI.

## Hur Man Anv√§nder Generativ AI Ansvarsfullt

Nu n√§r vi har identifierat vikten av Ansvarsfull Generativ AI, l√•t oss titta p√• 4 steg vi kan ta f√∂r att bygga v√•ra AI-l√∂sningar ansvarsfullt:

![Minska Cykel](../../../translated_images/mitigate-cycle.f82610b2048bda5a84aaa3a3cb2cda8b35fe614a7269743fdc63cbc2cbb8f20f.sv.png)

### M√§ta Potentiella Skador

I mjukvarutestning testar vi de f√∂rv√§ntade handlingarna av en anv√§ndare p√• en applikation. P√• samma s√§tt √§r det bra att testa en diversifierad upps√§ttning uppmaningar som anv√§ndare mest troligt kommer att anv√§nda f√∂r att m√§ta potentiell skada.

Eftersom v√•r startup bygger en utbildningsprodukt skulle det vara bra att f√∂rbereda en lista √∂ver utbildningsrelaterade uppmaningar. Detta kan vara f√∂r att t√§cka ett visst √§mne, historiska fakta och uppmaningar om studentlivet.

### Minska Potentiella Skador

Det √§r nu dags att hitta s√§tt d√§r vi kan f√∂rhindra eller begr√§nsa den potentiella skada som orsakas av modellen och dess svar. Vi kan se p√• detta i 4 olika lager:

![Minskning Lager](../../../translated_images/mitigation-layers.db2d802e3affb2f49681cf8ae39e8f1a67ff1ce29c3f1099c96948a841d62037.sv.png)

- **Modell**. V√§lja r√§tt modell f√∂r r√§tt anv√§ndningsomr√•de. St√∂rre och mer komplexa modeller som GPT-4 kan orsaka mer risk f√∂r skadligt inneh√•ll n√§r de till√§mpas p√• mindre och mer specifika anv√§ndningsomr√•den. Att anv√§nda din tr√§ningsdata f√∂r att finjustera minskar ocks√• risken f√∂r skadligt inneh√•ll.

- **S√§kerhetssystem**. Ett s√§kerhetssystem √§r en upps√§ttning verktyg och konfigurationer p√• plattformen som serverar modellen som hj√§lper till att minska skada. Ett exempel p√• detta √§r inneh√•llsfiltreringssystemet p√• Azure OpenAI-tj√§nsten. System b√∂r ocks√• uppt√§cka jailbreak-attacker och o√∂nskad aktivitet som f√∂rfr√•gningar fr√•n bots.

- **Metaprompt**. Metaprompts och grundning √§r s√§tt vi kan styra eller begr√§nsa modellen baserat p√• vissa beteenden och information. Detta kan vara att anv√§nda systeminputs f√∂r att definiera vissa gr√§nser f√∂r modellen. Dessutom att tillhandah√•lla outputs som √§r mer relevanta f√∂r systemets omfattning eller dom√§n.

Det kan ocks√• vara att anv√§nda tekniker som Retrieval Augmented Generation (RAG) f√∂r att f√• modellen att endast h√§mta information fr√•n ett urval av betrodda k√§llor. Det finns en lektion senare i denna kurs f√∂r [att bygga s√∂kapplikationer](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Anv√§ndarupplevelse**. Det sista lagret √§r d√§r anv√§ndaren interagerar direkt med modellen genom v√•r applikationsgr√§nssnitt p√• n√•got s√§tt. P√• detta s√§tt kan vi designa UI/UX f√∂r att begr√§nsa anv√§ndaren p√• de typer av inputs de kan skicka till modellen samt text eller bilder som visas f√∂r anv√§ndaren. N√§r vi distribuerar AI-applikationen m√•ste vi ocks√• vara transparenta om vad v√•r Generativa AI-applikation kan och inte kan g√∂ra.

Vi har en hel lektion dedikerad till [Designa UX f√∂r AI-applikationer](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Utv√§rdera modell**. Att arbeta med LLMs kan vara utmanande eftersom vi inte alltid har kontroll √∂ver datan som modellen tr√§nades p√•. Oavsett b√∂r vi alltid utv√§rdera modellens prestanda och outputs. Det √§r fortfarande viktigt att m√§ta modellens noggrannhet, likhet, grundlighet och relevans av output. Detta hj√§lper till att ge transparens och f√∂rtroende till intressenter och anv√§ndare.

### Driva en Ansvarsfull Generativ AI-l√∂sning

Att bygga en operativ praxis kring dina AI-applikationer √§r det sista steget. Detta inkluderar att samarbeta med andra delar av v√•r startup som Juridik och S√§kerhet f√∂r att s√§kerst√§lla att vi f√∂ljer alla regulatoriska policyer. Innan lansering vill vi ocks√• bygga planer kring leverans, hantering av incidenter och √•terst√§llning f√∂r att f√∂rhindra n√•gon skada f√∂r v√•ra anv√§ndare fr√•n att v√§xa.

## Verktyg

√Ñven om arbetet med att utveckla Ansvarsfull AI-l√∂sningar kan verka mycket, √§r det arbete som √§r v√§l v√§rt anstr√§ngningen. N√§r omr√•det f√∂r Generativ AI v√§xer, kommer fler verktyg f√∂r att hj√§lpa utvecklare att effektivt integrera ansvar i sina arbetsfl√∂den att mogna. Till exempel kan [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hj√§lpa till att uppt√§cka skadligt inneh√•ll och bilder via en API-f√∂rfr√•gan.

## Kunskapskontroll

Vad √§r n√•gra saker du beh√∂ver bry dig om f√∂r att s√§kerst√§lla ansvarsfull AI-anv√§ndning?

1. Att svaret √§r korrekt.
1. Skadlig anv√§ndning, att AI inte anv√§nds f√∂r kriminella syften.
1. Att s√§kerst√§lla att AI √§r fri fr√•n bias och diskriminering.

A: 2 och 3 √§r korrekta. Ansvarsfull AI hj√§lper dig att √∂verv√§ga hur du kan minska skadliga effekter och bias och mer.

## üöÄ Utmaning

L√§s om [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) och se vad du kan anta f√∂r din anv√§ndning.

## Bra Jobbat, Forts√§tt Din Inl√§rning

Efter att ha avslutat denna lektion, kolla in v√•r [Generativ AI Inl√§rningssamling](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f√∂r att forts√§tta utveckla din Generativ AI-kunskap!

G√• vidare till Lektion 4 d√§r vi kommer att titta p√• [Grunderna i Prompt Engineering](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfriskrivning**:  
Detta dokument har √∂versatts med hj√§lp av AI-√∂vers√§ttningstj√§nsten [Co-op Translator](https://github.com/Azure/co-op-translator). √Ñven om vi str√§var efter noggrannhet, var medveten om att automatiserade √∂vers√§ttningar kan inneh√•lla fel eller oriktigheter. Det ursprungliga dokumentet p√• dess modersm√•l b√∂r betraktas som den auktoritativa k√§llan. F√∂r kritisk information rekommenderas professionell m√§nsklig √∂vers√§ttning. Vi ansvarar inte f√∂r eventuella missf√∂rst√•nd eller misstolkningar som uppst√•r vid anv√§ndning av denna √∂vers√§ttning.