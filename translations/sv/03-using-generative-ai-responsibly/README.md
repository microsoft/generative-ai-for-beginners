<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-17T19:00:21+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "sv"
}
-->
# Anv칛nda Generativ AI Ansvarsfullt

[![Anv칛nda Generativ AI Ansvarsfullt](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.sv.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _Klicka p친 bilden ovan f칬r att se videon f칬r denna lektion_

Det 칛r l칛tt att fascineras av AI och generativ AI i synnerhet, men det 칛r viktigt att fundera 칬ver hur man anv칛nder den p친 ett ansvarsfullt s칛tt. Du beh칬ver t칛nka p친 saker som hur du s칛kerst칛ller att resultaten 칛r r칛ttvisa, icke-skadliga och mer. Detta kapitel syftar till att ge dig den n칛mnda kontexten, vad du b칬r t칛nka p친 och hur du kan ta aktiva steg f칬r att f칬rb칛ttra din AI-anv칛ndning.

## Introduktion

Denna lektion kommer att t칛cka:

- Varf칬r du b칬r prioritera Ansvarsfull AI n칛r du bygger applikationer med Generativ AI.
- Grundprinciper f칬r Ansvarsfull AI och hur de relaterar till Generativ AI.
- Hur du kan oms칛tta dessa principer i praktiken genom strategier och verktyg.

## L칛randem친l

Efter att ha avslutat denna lektion kommer du att veta:

- Vikten av Ansvarsfull AI n칛r du bygger applikationer med Generativ AI.
- N칛r du ska t칛nka p친 och till칛mpa grundprinciperna f칬r Ansvarsfull AI n칛r du bygger applikationer med Generativ AI.
- Vilka verktyg och strategier som finns tillg칛ngliga f칬r att oms칛tta konceptet Ansvarsfull AI i praktiken.

## Principer f칬r Ansvarsfull AI

Intresset f칬r Generativ AI har aldrig varit st칬rre. Detta intresse har lockat m친nga nya utvecklare, uppm칛rksamhet och finansiering till detta omr친de. 츿ven om detta 칛r mycket positivt f칬r alla som vill bygga produkter och f칬retag med Generativ AI, 칛r det ocks친 viktigt att vi g친r fram친t p친 ett ansvarsfullt s칛tt.

Under hela denna kurs fokuserar vi p친 att bygga v친rt startup och v친r utbildningsprodukt med AI. Vi kommer att anv칛nda principerna f칬r Ansvarsfull AI: R칛ttvisa, Inkludering, Tillf칬rlitlighet/S칛kerhet, S칛kerhet & Integritet, Transparens och Ansvar. Med dessa principer kommer vi att utforska hur de relaterar till v친r anv칛ndning av Generativ AI i v친ra produkter.

## Varf칬r B칬r Du Prioritera Ansvarsfull AI

N칛r du bygger en produkt leder ett m칛nniskocentrerat tillv칛gag친ngss칛tt, d칛r du h친ller anv칛ndarens b칛sta intresse i 친tanke, till de b칛sta resultaten.

Det unika med Generativ AI 칛r dess f칬rm친ga att skapa hj칛lpsamma svar, information, v칛gledning och inneh친ll f칬r anv칛ndare. Detta kan g칬ras utan m친nga manuella steg, vilket kan leda till mycket imponerande resultat. Utan ordentlig planering och strategier kan det tyv칛rr ocks친 leda till skadliga resultat f칬r dina anv칛ndare, din produkt och samh칛llet som helhet.

L친t oss titta p친 n친gra (men inte alla) av dessa potentiellt skadliga resultat:

### Hallucinationer

Hallucinationer 칛r en term som anv칛nds f칬r att beskriva n칛r en LLM producerar inneh친ll som antingen 칛r helt nonsens eller n친got vi vet 칛r faktam칛ssigt fel baserat p친 andra informationsk칛llor.

L친t oss ta ett exempel d칛r vi bygger en funktion f칬r v친rt startup som till친ter studenter att st칛lla historiska fr친gor till en modell. En student st칛ller fr친gan `Vem var den enda 칬verlevande fr친n Titanic?`

Modellen producerar ett svar som det nedan:

![Prompt som s칛ger "Vem var den enda 칬verlevande fr친n Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(K칛lla: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Detta 칛r ett mycket sj칛lvs칛kert och detaljerat svar. Tyv칛rr 칛r det felaktigt. 츿ven med minimal forskning skulle man uppt칛cka att det fanns fler 칛n en 칬verlevande fr친n Titanic-katastrofen. F칬r en student som just b칬rjat forska om detta 칛mne kan detta svar vara tillr칛ckligt 칬vertygande f칬r att inte ifr친gas칛ttas och behandlas som fakta. Konsekvenserna av detta kan leda till att AI-systemet blir op친litligt och negativt p친verkar v친rt startups rykte.

Med varje iteration av en given LLM har vi sett f칬rb칛ttringar i prestanda n칛r det g칛ller att minimera hallucinationer. 츿ven med denna f칬rb칛ttring m친ste vi som applikationsbyggare och anv칛ndare fortfarande vara medvetna om dessa begr칛nsningar.

### Skadligt Inneh친ll

Vi har tidigare t칛ckt n칛r en LLM producerar felaktiga eller nonsenssvar. En annan risk vi m친ste vara medvetna om 칛r n칛r en modell svarar med skadligt inneh친ll.

Skadligt inneh친ll kan definieras som:

- Att ge instruktioner eller uppmuntra till sj칛lvskada eller skada mot vissa grupper.
- Hatiskt eller nedv칛rderande inneh친ll.
- V칛gledning f칬r att planera n친gon typ av attack eller v친ldsamma handlingar.
- Att ge instruktioner om hur man hittar olagligt inneh친ll eller beg친r olagliga handlingar.
- Att visa sexuellt explicit inneh친ll.

F칬r v친rt startup vill vi se till att vi har r칛tt verktyg och strategier p친 plats f칬r att f칬rhindra att denna typ av inneh친ll visas f칬r studenter.

### Brist p친 R칛ttvisa

R칛ttvisa definieras som "att s칛kerst칛lla att ett AI-system 칛r fritt fr친n partiskhet och diskriminering och att det behandlar alla r칛ttvist och lika." Inom Generativ AI vill vi s칛kerst칛lla att exkluderande v칛rldsuppfattningar om marginaliserade grupper inte f칬rst칛rks av modellens output.

Denna typ av output 칛r inte bara destruktiv f칬r att bygga positiva produktupplevelser f칬r v친ra anv칛ndare, utan orsakar ocks친 ytterligare samh칛llelig skada. Som applikationsbyggare b칬r vi alltid ha en bred och m친ngsidig anv칛ndarbas i 친tanke n칛r vi bygger l칬sningar med Generativ AI.

## Hur Man Anv칛nder Generativ AI Ansvarsfullt

Nu n칛r vi har identifierat vikten av Ansvarsfull Generativ AI, l친t oss titta p친 4 steg vi kan ta f칬r att bygga v친ra AI-l칬sningar ansvarsfullt:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.sv.png)

### M칛ta Potentiella Skador

Inom mjukvarutestning testar vi de f칬rv칛ntade handlingarna hos en anv칛ndare p친 en applikation. P친 samma s칛tt 칛r det en bra id칠 att testa en m친ngfald av prompts som anv칛ndare mest sannolikt kommer att anv칛nda f칬r att m칛ta potentiella skador.

Eftersom v친rt startup bygger en utbildningsprodukt skulle det vara bra att f칬rbereda en lista med utbildningsrelaterade prompts. Detta kan t칛cka ett visst 칛mne, historiska fakta och prompts om studentlivet.

### Begr칛nsa Potentiella Skador

Nu 칛r det dags att hitta s칛tt d칛r vi kan f칬rhindra eller begr칛nsa den potentiella skada som orsakas av modellen och dess svar. Vi kan titta p친 detta i 4 olika lager:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.sv.png)

- **Modell**. V칛lja r칛tt modell f칬r r칛tt anv칛ndningsomr친de. St칬rre och mer komplexa modeller som GPT-4 kan inneb칛ra st칬rre risk f칬r skadligt inneh친ll n칛r de anv칛nds f칬r mindre och mer specifika anv칛ndningsomr친den. Att anv칛nda din tr칛ningsdata f칬r att finjustera minskar ocks친 risken f칬r skadligt inneh친ll.

- **S칛kerhetssystem**. Ett s칛kerhetssystem 칛r en upps칛ttning verktyg och konfigurationer p친 plattformen som serverar modellen och hj칛lper till att begr칛nsa skador. Ett exempel p친 detta 칛r inneh친llsfiltreringssystemet p친 Azure OpenAI-tj칛nsten. System b칬r ocks친 uppt칛cka jailbreak-attacker och o칬nskad aktivitet som f칬rfr친gningar fr친n bots.

- **Metaprompt**. Metaprompts och grounding 칛r s칛tt vi kan styra eller begr칛nsa modellen baserat p친 vissa beteenden och information. Detta kan vara att anv칛nda systeminputs f칬r att definiera vissa gr칛nser f칬r modellen. Dessutom att tillhandah친lla outputs som 칛r mer relevanta f칬r systemets omfattning eller dom칛n.

Det kan ocks친 vara att anv칛nda tekniker som Retrieval Augmented Generation (RAG) f칬r att f친 modellen att endast h칛mta information fr친n ett urval av betrodda k칛llor. Det finns en lektion senare i denna kurs f칬r [att bygga s칬kapplikationer](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Anv칛ndarupplevelse**. Det sista lagret 칛r d칛r anv칛ndaren interagerar direkt med modellen genom v친r applikationsgr칛nssnitt p친 n친got s칛tt. P친 detta s칛tt kan vi designa UI/UX f칬r att begr칛nsa anv칛ndaren i vilka typer av inputs de kan skicka till modellen samt text eller bilder som visas f칬r anv칛ndaren. N칛r vi distribuerar AI-applikationen m친ste vi ocks친 vara transparenta om vad v친r Generativa AI-applikation kan och inte kan g칬ra.

Vi har en hel lektion dedikerad till [Designa UX f칬r AI-applikationer](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Utv칛rdera modellen**. Att arbeta med LLMs kan vara utmanande eftersom vi inte alltid har kontroll 칬ver datan modellen tr칛nades p친. Oavsett detta b칬r vi alltid utv칛rdera modellens prestanda och outputs. Det 칛r fortfarande viktigt att m칛ta modellens noggrannhet, likhet, grundning och relevans av output. Detta hj칛lper till att ge transparens och f칬rtroende till intressenter och anv칛ndare.

### Driva en Ansvarsfull Generativ AI-l칬sning

Att bygga en operativ praxis kring dina AI-applikationer 칛r det sista steget. Detta inkluderar att samarbeta med andra delar av v친rt startup som Juridik och S칛kerhet f칬r att s칛kerst칛lla att vi f칬ljer alla regler och policyer. Innan lansering vill vi ocks친 bygga planer kring leverans, hantering av incidenter och rollback f칬r att f칬rhindra att n친gon skada drabbar v친ra anv칛ndare.

## Verktyg

츿ven om arbetet med att utveckla Ansvarsfulla AI-l칬sningar kan verka omfattande, 칛r det arbete som 칛r v칛l v칛rt anstr칛ngningen. N칛r omr친det f칬r Generativ AI v칛xer kommer fler verktyg att mogna f칬r att hj칛lpa utvecklare att effektivt integrera ansvar i sina arbetsfl칬den. Till exempel kan [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hj칛lpa till att uppt칛cka skadligt inneh친ll och bilder via en API-f칬rfr친gan.

## Kunskapskontroll

Vad 칛r n친gra saker du beh칬ver bry dig om f칬r att s칛kerst칛lla ansvarsfull AI-anv칛ndning?

1. Att svaret 칛r korrekt.
1. Skadlig anv칛ndning, att AI inte anv칛nds f칬r kriminella 칛ndam친l.
1. S칛kerst칛lla att AI 칛r fri fr친n partiskhet och diskriminering.

A: 2 och 3 칛r korrekta. Ansvarsfull AI hj칛lper dig att 칬verv칛ga hur du kan begr칛nsa skadliga effekter och partiskhet och mer.

## 游 Utmaning

L칛s om [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) och se vad du kan anv칛nda f칬r dina behov.

## Bra Jobbat, Forts칛tt Din Inl칛rning

Efter att ha avslutat denna lektion, kolla in v친r [Generativ AI L칛randekollektion](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) f칬r att forts칛tta utveckla din kunskap om Generativ AI!

G친 vidare till Lektion 4 d칛r vi kommer att titta p친 [Grundl칛ggande om Prompt Engineering](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfriskrivning**:  
Detta dokument har 칬versatts med hj칛lp av AI-칬vers칛ttningstj칛nsten [Co-op Translator](https://github.com/Azure/co-op-translator). 츿ven om vi str칛var efter noggrannhet, b칬r du vara medveten om att automatiserade 칬vers칛ttningar kan inneh친lla fel eller felaktigheter. Det ursprungliga dokumentet p친 dess ursprungliga spr친k b칬r betraktas som den auktoritativa k칛llan. F칬r kritisk information rekommenderas professionell m칛nsklig 칬vers칛ttning. Vi ansvarar inte f칬r eventuella missf칬rst친nd eller feltolkningar som uppst친r vid anv칛ndning av denna 칬vers칛ttning.