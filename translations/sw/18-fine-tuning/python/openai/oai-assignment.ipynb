{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kuboresha Zaidi Mifano ya Open AI\n",
    "\n",
    "Daftari hili limejikita kwenye mwongozo wa sasa uliotolewa kwenye [Kuboresha Zaidi](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) kutoka Open AI.\n",
    "\n",
    "Kuboresha zaidi huongeza utendaji wa mifano ya msingi kwa programu yako kwa kuifundisha tena kwa kutumia data na muktadha wa ziada unaohusiana na matumizi hayo maalum au hali fulani. Kumbuka kwamba mbinu za uhandisi wa msukumo kama _few shot learning_ na _retrieval augmented generation_ zinakuruhusu kuboresha msukumo wa awali kwa kuongeza data husika ili kuboresha ubora. Hata hivyo, njia hizi zina mipaka kutokana na ukubwa wa juu wa tokeni ambao mfano wa msingi unaruhusu.\n",
    "\n",
    "Kwa kuboresha zaidi, tunafundisha tena mfano wenyewe kwa kutumia data inayohitajika (hii inatupa nafasi ya kutumia mifano mingi zaidi kuliko ile inayoweza kutoshea kwenye dirisha la tokeni) - na tunazindua toleo _maalum_ la mfano ambalo halihitaji tena mifano kutolewa wakati wa utabiri. Hii haiboresha tu ufanisi wa muundo wa msukumo wetu (tunapata uhuru zaidi wa kutumia dirisha la tokeni kwa mambo mengine) bali pia inaweza kupunguza gharama zetu (kwa kupunguza idadi ya tokeni tunazotuma kwa mfano wakati wa utabiri).\n",
    "\n",
    "Kuboresha zaidi kuna hatua 4:\n",
    "1. Andaa data ya mafunzo na uipakie.\n",
    "1. Endesha kazi ya mafunzo ili kupata mfano ulioboreshwa.\n",
    "1. Pima mfano ulioboreshwa na uboreshe ubora wake.\n",
    "1. Zindua mfano ulioboreshwa kwa utabiri ukiridhika.\n",
    "\n",
    "Kumbuka si mifano yote ya msingi inayoauni kuboresha zaidi - [angalia nyaraka za OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) kwa taarifa za hivi karibuni. Unaweza pia kuboresha zaidi mfano ambao tayari umeboreshwa. Katika somo hili, tutatumia `gpt-35-turbo` kama mfano wetu wa msingi wa kuboresha zaidi. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 1.1: Andaa Seti Yako ya Data\n",
    "\n",
    "Tujenge roboti ya mazungumzo inayokusaidia kuelewa jedwali la vipengele kwa kujibu maswali kuhusu kipengele kwa kutumia limerick. Katika _mafunzo_ haya rahisi, tutaandaa tu seti ya data ya kufundishia mfano wetu kwa kutumia mifano michache ya majibu yanayoonyesha muundo unaotarajiwa wa data. Katika matumizi halisi, utahitaji kuandaa seti ya data yenye mifano mingi zaidi. Pia unaweza kutumia seti ya data iliyo wazi (kwa eneo lako la matumizi) kama ipo, na kuibadilisha ili itumike kwenye mafunzo ya ziada.\n",
    "\n",
    "Kwa kuwa tunalenga kutumia `gpt-35-turbo` na tunahitaji jibu la mzungumzo la mara moja (chat completion), tunaweza kuunda mifano tukitumia [muundo huu unaopendekezwa](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) unaoendana na mahitaji ya OpenAI ya chat completion. Kama unatarajia mazungumzo ya mfululizo (multi-turn), utatumia [muundo wa mifano ya mazungumzo ya mfululizo](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) ambao unajumuisha kipengele cha `weight` kuonyesha ni ujumbe upi utumike (au usitumike) kwenye mchakato wa mafunzo ya ziada.\n",
    "\n",
    "Tutatumia muundo rahisi wa jibu la mara moja kwa ajili ya mafunzo haya. Data iko katika [muundo wa jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) ikiwa na rekodi 1 kwa kila mstari, kila moja ikiwa ni kitu kilichoandikwa kwa muundo wa JSON. Kipande hapa chini kinaonyesha rekodi 2 kama mfano - angalia [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) kwa seti kamili ya mifano (mifano 10) tutakayotumia kwenye mafunzo yetu ya ziada. **Kumbuka:** Kila rekodi _lazima_ iandikwe kwenye mstari mmoja (isigawanywe kwenye mistari kama ilivyo kawaida kwenye faili la JSON lililopangwa vizuri)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Katika matumizi halisi utahitaji seti kubwa zaidi ya mifano ili kupata matokeo mazuri - utalazimika kuchagua kati ya ubora wa majibu na muda/gahrama za mafunzo ya ziada. Tunatumia seti ndogo ili tuweze kukamilisha mafunzo ya ziada haraka na kuonyesha mchakato. Tazama [mfano huu wa OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) kwa mafunzo ya ziada yaliyo na mifano changamano zaidi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 1.2 Pakia Seti Yako ya Data\n",
    "\n",
    "Pakia data ukitumia Files API [kama ilivyoelezwa hapa](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Kumbuka kwamba ili kuendesha msimbo huu, lazima uwe umefanya hatua zifuatazo kwanza:\n",
    " - Umeweka kifurushi cha `openai` cha Python (hakikisha unatumia toleo >=0.28.0 kwa vipengele vipya zaidi)\n",
    " - Umeweka `OPENAI_API_KEY` kwenye mazingira yako kama ufunguo wa OpenAI API\n",
    "Ili kujifunza zaidi, angalia [Mwongozo wa Usanidi](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) uliotolewa kwa ajili ya kozi.\n",
    "\n",
    "Sasa, endesha msimbo ili kuunda faili la kupakia kutoka kwenye faili lako la JSONL la ndani.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 2.1: Tengeneza kazi ya Fine-tuning kwa kutumia SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 2.2: Angalia Hali ya kazi\n",
    "\n",
    "Hapa kuna mambo kadhaa unayoweza kufanya kwa kutumia API ya `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Orodhesha kazi za mwisho n za fine-tuning\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Pata maelezo ya kazi maalum ya fine-tuning\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Ghairi kazi ya fine-tuning\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Orodhesha hadi matukio n kutoka kwenye kazi\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Hatua ya kwanza ya mchakato huu ni _kuthibitisha faili la mafunzo_ ili kuhakikisha data iko katika muundo sahihi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 2.3: Fuatilia matukio ili kufuatilia maendeleo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 2.4: Angalia hali katika Dashibodi ya OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unaweza pia kuona hali kwa kutembelea tovuti ya OpenAI na kuchunguza sehemu ya _Fine-tuning_ kwenye jukwaa. Hii itakuonyesha hali ya kazi inayofanyika kwa sasa, na pia kukuwezesha kufuatilia historia ya utekelezaji wa kazi zilizopita. Katika picha hii ya skrini, unaweza kuona kwamba utekelezaji wa awali ulishindwa, na mzunguko wa pili ulifanikiwa. Kwa ufafanuzi, hili lilitokea wakati mzunguko wa kwanza ulitumia faili ya JSON yenye rekodi zilizopangwa vibaya - baada ya kurekebishwa, mzunguko wa pili ulikamilika vizuri na kufanya modeli ipatikane kwa matumizi.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.sw.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unaweza pia kuona ujumbe wa hali na vipimo kwa kusogeza chini zaidi kwenye dashibodi ya kuona kama inavyoonyeshwa:\n",
    "\n",
    "| Ujumbe | Vipimo |\n",
    "|:---|:---|\n",
    "| ![Ujumbe](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.sw.png) |  ![Vipimo](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.sw.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 3.1: Pata Kitambulisho & Jaribu Mfano Ulioboreshwa kwa Kutumia Msimbo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hatua ya 3.2: Pakia & Jaribu Modeli Iliyoboreshwa kwenye Playground\n",
    "\n",
    "Sasa unaweza kujaribu modeli uliyoiboresha kwa njia mbili. Kwanza, unaweza kutembelea Playground na kutumia menyu kunjuzi ya Models kuchagua modeli yako mpya iliyoboreshwa kutoka kwenye chaguo zilizoorodheshwa. Njia nyingine ni kutumia chaguo la \"Playground\" linaloonekana kwenye paneli ya Fine-tuning (tazama picha hapo juu) ambayo inafungua mwonekano wa _ulinganisho_ unaoonyesha toleo la msingi na lile lililoboreshwa upande kwa upande ili uweze kulinganisha haraka.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.sw.png)\n",
    "\n",
    "Jaza tu muktadha wa mfumo uliotumia kwenye data yako ya mafunzo na uweke swali lako la majaribio. Utagundua kuwa pande zote mbili zinasasishwa na muktadha na swali sawa. Endesha ulinganisho na utaona tofauti ya majibu kati yao. _Angalia jinsi modeli iliyoboreshwa inavyotoa jibu kwa muundo ulioutoa kwenye mifano yako ilhali modeli ya msingi inafuata tu agizo la mfumo_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.sw.png)\n",
    "\n",
    "Utagundua pia kuwa ulinganisho huu unaonyesha idadi ya tokeni kwa kila modeli, na muda uliotumika kutoa jibu. **Mfano huu maalum ni rahisi na umetolewa ili kuonyesha mchakato, lakini hauwakilishi seti halisi ya data au hali ya maisha halisi**. Unaweza kuona kuwa sampuli zote mbili zinaonyesha idadi sawa ya tokeni (muktadha wa mfumo na agizo la mtumiaji ni sawa) huku modeli iliyoboreshwa ikichukua muda zaidi kutoa jibu (modeli maalum).\n",
    "\n",
    "Katika hali halisi, hutatumia mfano rahisi kama huu, bali utakuwa unafanya fine-tuning kwa data halisi (kwa mfano, orodha ya bidhaa kwa huduma kwa wateja) ambapo ubora wa majibu utaonekana zaidi. Katika _muktadha_ huo, kupata ubora sawa wa majibu kwa kutumia modeli ya msingi kutahitaji uhandisi zaidi wa maelekezo maalum, jambo ambalo litaongeza matumizi ya tokeni na huenda likaongeza muda wa kuchakata majibu. _Ili kujaribu hili, angalia mifano ya fine-tuning kwenye OpenAI Cookbook uanze._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Kanusho**:  \nHati hii imetafsiriwa kwa kutumia huduma ya kutafsiri ya AI [Co-op Translator](https://github.com/Azure/co-op-translator). Ingawa tunajitahidi kwa usahihi, tafadhali fahamu kwamba tafsiri za kiotomatiki zinaweza kuwa na makosa au kutokuwa sahihi. Hati asili katika lugha yake ya asili inapaswa kuchukuliwa kama chanzo cha mamlaka. Kwa taarifa muhimu, inashauriwa kutumia mtafsiri wa kibinadamu mwenye ujuzi. Hatutawajibika kwa kutoelewana au tafsiri potofu zitakazotokana na matumizi ya tafsiri hii.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:52:25+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "sw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}