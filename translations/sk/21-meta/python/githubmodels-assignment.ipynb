{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Práca s modelmi rodiny Meta\n",
    "\n",
    "## Úvod\n",
    "\n",
    "V tejto lekcii sa budeme venovať:\n",
    "\n",
    "- Preskúmaniu dvoch hlavných modelov rodiny Meta – Llama 3.1 a Llama 3.2\n",
    "- Pochopeniu prípadov použitia a scenárov pre každý model\n",
    "- Ukážke kódu, ktorá predstaví jedinečné vlastnosti každého modelu\n",
    "\n",
    "## Modely rodiny Meta\n",
    "\n",
    "V tejto lekcii sa pozrieme na 2 modely z rodiny Meta alebo „Llama Herd“ – Llama 3.1 a Llama 3.2\n",
    "\n",
    "Tieto modely existujú v rôznych variantoch a sú dostupné na trhu modelov Github. Viac informácií o používaní Github Models na [prototypovanie s AI modelmi](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst) nájdete na tomto odkaze.\n",
    "\n",
    "Varianty modelov:\n",
    "- Llama 3.1 – 70B Instruct\n",
    "- Llama 3.1 – 405B Instruct\n",
    "- Llama 3.2 – 11B Vision Instruct\n",
    "- Llama 3.2 – 90B Vision Instruct\n",
    "\n",
    "*Poznámka: Llama 3 je tiež dostupná na Github Models, ale v tejto lekcii sa jej venovať nebudeme*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "S 405 miliardami parametrov patrí Llama 3.1 medzi open source LLM modely.\n",
    "\n",
    "Tento model je vylepšením predchádzajúcej verzie Llama 3 a prináša:\n",
    "\n",
    "- Väčšie kontextové okno – 128k tokenov oproti 8k tokenom\n",
    "- Väčší maximálny počet výstupných tokenov – 4096 oproti 2048\n",
    "- Lepšiu podporu viacerých jazykov – vďaka zvýšenému počtu trénovacích tokenov\n",
    "\n",
    "Vďaka týmto vylepšeniam dokáže Llama 3.1 zvládnuť zložitejšie prípady použitia pri tvorbe GenAI aplikácií, vrátane:\n",
    "- Natívneho volania funkcií – možnosť volať externé nástroje a funkcie mimo workflow LLM\n",
    "- Lepšieho výkonu pri RAG – vďaka väčšiemu kontextovému oknu\n",
    "- Generovania syntetických dát – možnosť vytvárať efektívne dáta pre úlohy ako doladenie modelu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natívne volanie funkcií\n",
    "\n",
    "Llama 3.1 bola doladená tak, aby bola efektívnejšia pri volaní funkcií alebo nástrojov. Má tiež dva vstavané nástroje, ktoré model dokáže rozpoznať ako potrebné použiť na základe zadania od používateľa. Tieto nástroje sú:\n",
    "\n",
    "- **Brave Search** – Dá sa použiť na získanie aktuálnych informácií, napríklad o počasí, prostredníctvom webového vyhľadávania\n",
    "- **Wolfram Alpha** – Dá sa využiť na zložitejšie matematické výpočty, takže nie je potrebné písať vlastné funkcie.\n",
    "\n",
    "Môžete si tiež vytvoriť vlastné nástroje, ktoré môže LLM volať.\n",
    "\n",
    "V nasledujúcom príklade kódu:\n",
    "\n",
    "- V systémovom zadaní definujeme dostupné nástroje (brave_search, wolfram_alpha).\n",
    "- Pošleme používateľský dopyt, ktorý sa pýta na počasie v konkrétnom meste.\n",
    "- LLM odpovie volaním nástroja Brave Search, ktoré bude vyzerať takto: `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`\n",
    "\n",
    "*Poznámka: Tento príklad iba vykoná volanie nástroja. Ak chcete získať výsledky, musíte si vytvoriť bezplatný účet na stránke Brave API a definovať samotnú funkciu.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2\n",
    "\n",
    "Napriek tomu, že Llama 3.1 je veľký jazykový model, jedným z jej obmedzení je multimodalita. To znamená, že nedokáže pracovať s rôznymi typmi vstupov, ako sú napríklad obrázky, a poskytovať na ne odpovede. Táto schopnosť patrí medzi hlavné novinky Llama 3.2. Medzi tieto vlastnosti patria aj:\n",
    "\n",
    "- Multimodalita – dokáže spracovať textové aj obrazové vstupy\n",
    "- Varianty v malých až stredných veľkostiach (11B a 90B) – umožňujú flexibilné možnosti nasadenia,\n",
    "- Iba textové varianty (1B a 3B) – umožňujú nasadenie modelu na okrajových zariadeniach alebo mobiloch a poskytujú nízku latenciu\n",
    "\n",
    "Podpora multimodality predstavuje veľký krok v oblasti open source modelov. Nasledujúci príklad kódu prijíma ako vstup obrázok aj textový prompt, aby získal analýzu obrázka z Llama 3.2 90B.\n",
    "\n",
    "### Multimodálna podpora s Llama 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Učenie sa tu nekončí, pokračujte v ceste\n",
    "\n",
    "Po dokončení tejto lekcie si pozrite našu [kolekciu o generatívnej AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) a pokračujte v rozširovaní svojich vedomostí o generatívnej umelej inteligencii!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Vyhlásenie o vylúčení zodpovednosti**:  \nTento dokument bol preložený pomocou AI prekladateľskej služby [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa snažíme o presnosť, upozorňujeme, že automatizované preklady môžu obsahovať chyby alebo nepresnosti. Za autoritatívny zdroj by sa mal považovať pôvodný dokument v jeho natívnom jazyku. Pre kritické informácie odporúčame profesionálny ľudský preklad. Nezodpovedáme za žiadne nedorozumenia alebo nesprávne interpretácie vyplývajúce z použitia tohto prekladu.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:48:22+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "sk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}