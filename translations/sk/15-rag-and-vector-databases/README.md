<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-05-20T01:41:06+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "sk"
}
-->
# Gener치cia roz코칤ren치 o vyh쬬d치vanie (RAG) a vektorov칠 datab치zy

V lekcii o aplik치ci치ch na vyh쬬d치vanie sme sa stru캜ne nau캜ili, ako integrova콘 vlastn칠 d치ta do ve쬶칳ch jazykov칳ch modelov (LLM). V tejto lekcii sa hlb코ie ponor칤me do konceptov zakotvenia va코ich d치t vo va코ej LLM aplik치cii, mechaniky procesu a met칩d na ukladanie d치t, vr치tane embeddings a textu.

> **Video pr칤de 캜oskoro**

## 칔vod

V tejto lekcii sa budeme zaobera콘 nasleduj칰cim:

- 칔vod do RAG, 캜o to je a pre캜o sa pou쮂셨a v AI (umelej inteligencii).

- Pochopenie toho, 캜o s칰 vektorov칠 datab치zy a vytvorenie jednej pre na코u aplik치ciu.

- Praktick칳 pr칤klad, ako integrova콘 RAG do aplik치cie.

## Ciele u캜enia

Po absolvovan칤 tejto lekcie budete schopn칤:

- Vysvetli콘 v칳znam RAG pri vyh쬬d치van칤 a spracovan칤 d치t.

- Nastavi콘 RAG aplik치ciu a zakotvi콘 va코e d치ta do LLM

- Efekt칤vna integr치cia RAG a vektorov칳ch datab치z do LLM aplik치ci칤.

## N치코 scen치r: vylep코enie na코ich LLM vlastn칳mi d치tami

Pre t칰to lekciu chceme prida콘 na코e vlastn칠 pozn치mky do vzdel치vacieho startupu, 캜o umo쬹칤 chatbotu z칤ska콘 viac inform치ci칤 o r칪znych predmetoch. Pomocou pozn치mok, ktor칠 m치me, bud칰 코tudenti schopn칤 lep코ie 코tudova콘 a pochopi콘 r칪zne t칠my, 캜o im u쬬h캜칤 pr칤pravu na sk칰코ky. Na vytvorenie n치코ho scen치ra pou쬴jeme:

- `Azure OpenAI:` LLM, ktor칳 pou쬴jeme na vytvorenie n치코ho chatbota

- `AI for beginners' lesson on Neural Networks`: toto bud칰 d치ta, na ktor칳ch zakotv칤me n치코 LLM

- `Azure AI Search` a `Azure Cosmos DB:` vektorov치 datab치za na ukladanie na코ich d치t a vytvorenie indexu vyh쬬d치vania

Pou쮂셨atelia bud칰 m칪c콘 vytv치ra콘 cvi캜n칠 testy zo svojich pozn치mok, karti캜ky na opakovanie a zhrn칰콘 ich do stru캜n칳ch preh쬬dov. Aby sme za캜ali, pozrime sa na to, 캜o je RAG a ako funguje:

## Gener치cia roz코칤ren치 o vyh쬬d치vanie (RAG)

Chatbot poh치켿an칳 LLM spracov치va pou쮂셨ate쬽k칠 v칳zvy na generovanie odpoved칤. Je navrhnut칳 tak, aby bol interakt칤vny a zap치ja sa do 코irokej 코k치ly t칠m. Av코ak jeho odpovede s칰 obmedzen칠 na kontext, ktor칳 je poskytnut칳 a na jeho z치kladn칠 tr칠ningov칠 d치ta. Napr칤klad, GPT-4 m치 obmedzenie znalost칤 na september 2021, 캜o znamen치, 쬰 nem치 znalosti o udalostiach, ktor칠 sa udiali po tomto obdob칤. Okrem toho, d치ta pou쬴t칠 na tr칠ning LLM vylu캜uj칰 d칪vern칠 inform치cie, ako osobn칠 pozn치mky alebo manu치l produktu spolo캜nosti.

### Ako funguj칰 RAG (Gener치cia roz코칤ren치 o vyh쬬d치vanie)

Predpokladajme, 쬰 chcete nasadi콘 chatbota, ktor칳 vytv치ra testy z va코ich pozn치mok, budete potrebova콘 pripojenie k znalostnej b치ze. Tu prich치dza na pomoc RAG. RAG funguje nasledovne:

- **Znalostn치 b치za:** Pred vyh쬬d치van칤m musia by콘 tieto dokumenty spracovan칠 a predspracovan칠, typicky rozdelen칤m ve쬶칳ch dokumentov na men코ie 캜asti, transform치ciou na textov칠 embeddings a ich ulo쬰n칤m do datab치zy.

- **Dotaz pou쮂셨ate쬬:** pou쮂셨ate polo쮂 ot치zku

- **Vyh쬬d치vanie:** Ke캞 pou쮂셨ate polo쮂 ot치zku, embedding model vyh쬬d치 relevantn칠 inform치cie z na코ej znalostnej b치zy, aby poskytol viac kontextu, ktor칳 bude za캜lenen칳 do v칳zvy.

- **Roz코칤ren치 gener치cia:** LLM vylep코uje svoju odpove캞 na z치klade z칤skan칳ch d치t. Umo쮄갓je, aby odpove캞 generovan치 nebola zalo쬰n치 len na predtr칠novan칳ch d치tach, ale aj na relevantn칳ch inform치ci치ch z pridan칠ho kontextu. Z칤skan칠 d치ta sa pou쮂셨aj칰 na roz코칤renie odpoved칤 LLM. LLM potom vr치ti odpove캞 na ot치zku pou쮂셨ate쬬.

Architekt칰ra pre RAG je implementovan치 pomocou transform치torov pozost치vaj칰cich z dvoch 캜ast칤: k칩dova캜a a dek칩dova캜a. Napr칤klad, ke캞 pou쮂셨ate polo쮂 ot치zku, vstupn칳 text je 'zak칩dovan칳' do vektorov, ktor칠 zachyt치vaj칰 v칳znam slov a vektory s칰 'dek칩dovan칠' do n치코ho dokumentov칠ho indexu a generuj칰 nov칳 text na z치klade dotazu pou쮂셨ate쬬. LLM pou쮂셨a model k칩dova캜-dek칩dova캜 na generovanie v칳stupu.

Dva pr칤stupy pri implement치cii RAG pod쬬 navrhovan칠ho 캜l치nku: [Gener치cia roz코칤ren치 o vyh쬬d치vanie pre 칰lohy NLP (softv칠r na spracovanie prirodzen칠ho jazyka) n치ro캜n칠 na znalosti](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) s칰:

- **_RAG-Sequence_** pou쮂셨aj칰ci z칤skan칠 dokumenty na predpovedanie najlep코ej mo쬹ej odpovede na dotaz pou쮂셨ate쬬

- **RAG-Token** pou쮂셨aj칰ci dokumenty na generovanie 캞al코ieho tokenu, potom ich z칤skava na odpove캞 na dotaz pou쮂셨ate쬬

### Pre캜o by ste pou쮂셨ali RAG?

- **Bohatstvo inform치ci칤:** zais콘uje, 쬰 textov칠 odpovede s칰 aktu치lne a aktu치lne. Preto zlep코uje v칳kon pri 칰loh치ch 코pecifick칳ch pre dom칠nu pr칤stupom k intern칳m znalostiam.

- Zni쬿je fabrika캜n칠 chyby vyu쬴t칤m **overite쬹칳ch d치t** v znalostnej b치ze na poskytnutie kontextu k dotazom pou쮂셨ate쬺v.

- Je **n치kladovo efekt칤vny**, preto쬰 s칰 ekonomickej코ie v porovnan칤 s jemn칳m doladen칤m LLM.

## Vytvorenie znalostnej b치zy

Na코a aplik치cia je zalo쬰n치 na na코ich osobn칳ch d치tach, tj. lekcia o neur칩nov칳ch sie콘ach v u캜ebnom pl치ne AI pre za캜iato캜n칤kov.

### Vektorov칠 datab치zy

Vektorov치 datab치za, na rozdiel od tradi캜n칳ch datab치z, je 코pecializovan치 datab치za navrhnut치 na ukladanie, spr치vu a vyh쬬d치vanie embedded vektorov. Uklad치 캜칤seln칠 reprezent치cie dokumentov. Rozdelenie d치t na 캜칤seln칠 embeddings u쬬h캜uje n치코mu AI syst칠mu pochopi콘 a spracova콘 d치ta.

Uklad치me na코e embeddings vo vektorov칳ch datab치zach, preto쬰 LLM maj칰 obmedzenie po캜tu tokenov, ktor칠 akceptuj칰 ako vstup. Ke캞쬰 nem칪쬰te prenies콘 cel칠 embeddings do LLM, budeme ich musie콘 rozdeli콘 na 캜asti a ke캞 pou쮂셨ate polo쮂 ot치zku, embeddings najviac podobn칠 ot치zke bud칰 vr치ten칠 spolu s v칳zvou. Rozdelenie tie zni쬿je n치klady na po캜et tokenov prenesen칳ch cez LLM.

Niektor칠 popul치rne vektorov칠 datab치zy zah콋켿aj칰 Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant a DeepLake. M칪쬰te vytvori콘 model Azure Cosmos DB pomocou Azure CLI s nasleduj칰cim pr칤kazom:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Od textu k embeddings

Predt칳m, ako ulo쮂셠e na코e d치ta, budeme ich musie콘 previes콘 na vektorov칠 embeddings predt칳m, ako bud칰 ulo쬰n칠 v datab치ze. Ak pracujete s ve쬶칳mi dokumentmi alebo dlh칳mi textami, m칪쬰te ich rozdeli콘 na z치klade dotazov, ktor칠 o캜ak치vate. Rozdelenie m칪쬰 by콘 vykonan칠 na 칰rovni vety alebo na 칰rovni odstavca. Ke캞쬰 rozdelenie odv치dza v칳znamy z okolit칳ch slov, m칪쬰te prida콘 nejak칳 캞al코칤 kontext do 캜asti, napr칤klad pridan칤m n치zvu dokumentu alebo zahrnut칤m textu pred alebo po 캜asti. D치ta m칪쬰te rozdeli콘 nasledovne:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Ke캞 s칰 rozdelen칠, m칪쬰me potom embedova콘 n치코 text pomocou r칪znych embedding modelov. Niektor칠 modely, ktor칠 m칪쬰te pou쬴콘, zah콋켿aj칰: word2vec, ada-002 od OpenAI, Azure Computer Vision a mnoho 캞al코칤ch. V칳ber modelu na pou쬴tie bude z치visie콘 od jazykov, ktor칠 pou쮂셨ate, typu k칩dovan칠ho obsahu (text/obr치zky/audio), ve쬶osti vstupu, ktor칳 m칪쬰 k칩dova콘 a d컄쬶y v칳stupu embeddingu.

Pr칤klad embedded textu pomocou modelu `text-embedding-ada-002` od OpenAI je:
![embedding slova ma캜ka](../../../translated_images/cat.3db013cbca4fd5d90438ea7b312ad0364f7686cf79931ab15cd5922151aea53e.sk.png)

## Vyh쬬d치vanie a vektorov칠 vyh쬬d치vanie

Ke캞 pou쮂셨ate polo쮂 ot치zku, retriever ju transformuje na vektor pomocou k칩dova캜a dotazu, potom preh쬬d치va n치코 dokumentov칳 index vyh쬬d치vania pre relevantn칠 vektory v dokumente, ktor칠 s칰visia s vstupom. Ke캞 je hotovo, konvertuje vstupn칳 vektor aj vektory dokumentu na text a prech치dza cez LLM.

### Vyh쬬d치vanie

Vyh쬬d치vanie sa uskuto캜켿uje, ke캞 syst칠m sa sna쮂 r칳chlo n치js콘 dokumenty z indexu, ktor칠 sp컄켿aj칰 krit칠ri치 vyh쬬d치vania. Cie쬺m retrievera je z칤ska콘 dokumenty, ktor칠 bud칰 pou쬴t칠 na poskytnutie kontextu a zakotvenie LLM na va코ich d치tach.

Existuje nieko쬶o sp칪sobov, ako vykon치va콘 vyh쬬d치vanie v na코ej datab치ze, ako napr칤klad:

- **Vyh쬬d치vanie pod쬬 k쮂줷꼂v칳ch slov** - pou쮂셨an칠 pre textov칠 vyh쬬d치vania

- **Semantick칠 vyh쬬d치vanie** - pou쮂셨a semantick칳 v칳znam slov

- **Vektorov칠 vyh쬬d치vanie** - konvertuje dokumenty z textu na vektorov칠 reprezent치cie pomocou embedding modelov. Vyh쬬d치vanie bude vykonan칠 dotazovan칤m dokumentov, ktor칳ch vektorov칠 reprezent치cie s칰 najbli쮄멸e k ot치zke pou쮂셨ate쬬.

- **Hybridn칠** - kombin치cia vyh쬬d치vania pod쬬 k쮂줷꼂v칳ch slov a vektorov칠ho vyh쬬d치vania.

V칳zva pri vyh쬬d치van칤 nast치va, ke캞 v datab치ze nie je podobn치 odpove캞 na dotaz, syst칠m potom vr치ti najlep코ie inform치cie, ktor칠 m칪쬰 z칤ska콘, av코ak m칪쬰te pou쬴콘 taktiky, ako nastavenie maxim치lnej vzdialenosti pre relevanciu alebo pou쬴tie hybridn칠ho vyh쬬d치vania, ktor칠 kombinuje k쮂줷꼂v칠 slov치 a vektorov칠 vyh쬬d치vanie. V tejto lekcii pou쬴jeme hybridn칠 vyh쬬d치vanie, kombin치ciu vektorov칠ho a vyh쬬d치vania pod쬬 k쮂줷꼂v칳ch slov. Na코e d치ta ulo쮂셠e do d치tov칠ho r치mca so st컄pcami obsahuj칰cimi 캜asti a embeddings.

### Vektorov치 podobnos콘

Retriever preh쬬d치 znalostn칰 datab치zu pre embeddings, ktor칠 s칰 bl칤zko seba, najbli쮄멸eho suseda, preto쬰 s칰 texty, ktor칠 s칰 podobn칠. V pr칤pade, 쬰 pou쮂셨ate polo쮂 dotaz, je najprv embedovan칳 a potom porovnan칳 s podobn칳mi embeddings. Be쬹칠 meranie, ktor칠 sa pou쮂셨a na zistenie, ako podobn칠 s칰 r칪zne vektory, je kos칤nov치 podobnos콘, ktor치 je zalo쬰n치 na uhle medzi dvoma vektormi.

M칪쬰me mera콘 podobnos콘 pomocou in칳ch alternat칤v, ktor칠 m칪쬰me pou쬴콘, ako je Euklidovsk치 vzdialenos콘, ktor치 je priamou 캜iarou medzi koncov칳mi bodmi vektorov a skal치rny s칰캜in, ktor칳 meria s칰캜et s칰캜inov zodpovedaj칰cich prvkov dvoch vektorov.

### Index vyh쬬d치vania

Pri vykon치van칤 vyh쬬d치vania budeme potrebova콘 vytvori콘 index vyh쬬d치vania pre na코u znalostn칰 b치zu predt칳m, ako vykon치me vyh쬬d치vanie. Index bude uklada콘 na코e embeddings a m칪쬰 r칳chlo vyh쬬da콘 najpodobnej코ie 캜asti aj vo ve쬶ej datab치ze. M칪쬰me vytvori콘 n치코 index lok치lne pomocou:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Pre-rankovanie

Ke캞 dotazujete datab치zu, mo쬹o budete potrebova콘 zoradi콘 v칳sledky od najrelevantnej코칤ch. Pre-rankovac칤 LLM vyu쮂셨a strojov칠 u캜enie na zlep코enie relevancie v칳sledkov vyh쬬d치vania ich zoraden칤m od najrelevantnej코칤ch. Pomocou Azure AI Search sa pre-rankovanie vykon치va automaticky pomocou semantick칠ho pre-rankeru. Pr칤klad, ako funguje pre-rankovanie pomocou najbli쮄뫆셖h susedov:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Spojenie v코etk칠ho dohromady

Posledn칳m krokom je prida콘 n치코 LLM do mixu, aby sme mohli z칤ska콘 odpovede, ktor칠 s칰 zakotven칠 na na코ich d치tach. M칪쬰me to implementova콘 nasledovne:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Hodnotenie na코ej aplik치cie

### Hodnotiace metriky

- Kvalita poskytnut칳ch odpoved칤, zabezpe캜enie, 쬰 znie prirodzene, plynulo a 쬿dsky

- Zakotvenie d치t: hodnotenie, 캜i odpove캞 poch치dza z poskytnut칳ch dokumentov

- Relevancia: hodnotenie, 캜i odpove캞 zodpoved치 a s칰vis칤 s polo쬰nou ot치zkou

- Plynulos콘 - 캜i odpove캞 d치va zmysel gramaticky

## Pou쬴tie RAG (Gener치cia roz코칤ren치 o vyh쬬d치vanie) a vektorov칳ch datab치z

Existuje mnoho r칪znych pou쬴t칤, kde volania funkci칤 m칪쬿 zlep코i콘 va코u aplik치ciu, ako napr칤klad:

- Ot치zky a odpovede: zakotvenie va코ich firemn칳ch d치t do chatu, ktor칳 m칪쬿 pou쮂셨a콘 zamestnanci na kladenie ot치zok.

- Syst칠my odpor칰캜ania: kde m칪쬰te vytvori콘 syst칠m, ktor칳 zodpoved치 najpodobnej코ie hodnoty, napr. filmy, re코taur치cie a mnoho 캞al코칤ch.

- Slu쬭y chatbotov: m칪쬰te uklada콘 hist칩riu chatov a personalizova콘 konverz치ciu na z치klade d치t pou쮂셨ate쬬.

- Vyh쬬d치vanie obr치zkov na z치klade vektorov칳ch embeddings, u쬴to캜n칠 pri rozpozn치van칤 obr치zkov a detekcii anom치li칤.

## Zhrnutie

Pokryli sme z치kladn칠 oblasti RAG od pridania na코ich d치t do aplik치cie, dotazu pou쮂셨ate쬬 a v칳stupu. Na zjednodu코enie tvorby RAG m칪쬰te pou쬴콘 r치mce ako Semanti Kernel, Langchain alebo Autogen.

## Zadanie

Aby ste pokra캜ovali vo va코om u캜en칤 o Gener치cii roz코칤renej o vyh쬬d치vanie (RAG), m칪쬰te vytvori콘:

- Vytvorte front-end pre aplik치ciu pomocou r치mca pod쬬 v치코ho v칳beru

- Vyu쬴te r치mec, bu캞 LangChain alebo Semantic Kernel, a znovu vytvorte svoju aplik치ciu.

Gratulujeme k dokon캜eniu lekcie 游녪.

## U캜enie sa tu nekon캜칤, pokra캜ujte v ceste

Po dokon캜en칤 tejto lekcie si pozrite na코u [kolekciu u캜enia Generat칤vnej AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby ste pokra캜ovali v zvy코ovan칤 va코ich znalost칤 o Generat칤vnej AI!

**Zrieknutie sa zodpovednosti**:  
Tento dokument bol prelo쬰n칳 pomocou slu쬭y AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Aj ke캞 sa sna쮂셠e o presnos콘, pros칤m uvedomte si, 쬰 automatizovan칠 preklady m칪쬿 obsahova콘 chyby alebo nepresnosti. P칪vodn칳 dokument v jeho rodnom jazyku by mal by콘 pova쬺van칳 za autoritat칤vny zdroj. Pre kritick칠 inform치cie sa odpor칰캜a profesion치lny 쬿dsk칳 preklad. Nie sme zodpovedn칤 za ak칠ko쭀ek nedorozumenia alebo nespr치vne interpret치cie vypl칳vaj칰ce z pou쬴tia tohto prekladu.