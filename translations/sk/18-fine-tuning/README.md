<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T21:59:00+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "sk"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.sk.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Jemn√© doladenie v√°≈°ho LLM

Pou≈æ√≠vanie veƒæk√Ωch jazykov√Ωch modelov na vytv√°ranie aplik√°ci√≠ generat√≠vnej AI prin√°≈°a nov√© v√Ωzvy. Kƒæ√∫ƒçov√Ωm probl√©mom je zabezpeƒçenie kvality odpoved√≠ (presnos≈• a relevantnos≈•) v obsahu generovanom modelom na z√°klade po≈æiadavky pou≈æ√≠vateƒæa. V predch√°dzaj√∫cich lekci√°ch sme diskutovali o technik√°ch, ako je n√°vrh v√Ωzvy (prompt engineering) a generovanie s roz≈°√≠ren√Ωm vyhƒæad√°van√≠m, ktor√© sa sna≈æia vyrie≈°i≈• probl√©m _√∫pravou vstupu v√Ωzvy_ existuj√∫ceho modelu.

V dne≈°nej lekcii sa zaober√°me tre≈•ou technikou, **jemn√Ωm doladen√≠m**, ktor√° sa sna≈æ√≠ rie≈°i≈• v√Ωzvu _pretr√©novan√≠m samotn√©ho modelu_ s dodatoƒçn√Ωmi √∫dajmi. Poƒème sa pozrie≈• na detaily.

## Ciele uƒçenia

T√°to lekcia predstavuje koncept jemn√©ho doladenia pre predtr√©novan√© jazykov√© modely, sk√∫ma v√Ωhody a v√Ωzvy tohto pr√≠stupu a poskytuje usmernenia, kedy a ako pou≈æi≈• jemn√© doladenie na zlep≈°enie v√Ωkonu va≈°ich generat√≠vnych AI modelov.

Na konci tejto lekcie by ste mali vedie≈• odpoveda≈• na nasleduj√∫ce ot√°zky:

- ƒåo je jemn√© doladenie jazykov√Ωch modelov?
- Kedy a preƒço je jemn√© doladenie u≈æitoƒçn√©?
- Ako m√¥≈æem jemne doladi≈• predtr√©novan√Ω model?
- Ak√© s√∫ obmedzenia jemn√©ho doladenia?

Pripraven√≠? Poƒème na to.

## Ilustrovan√Ω sprievodca

Chcete si urobi≈• prehƒæad o tom, ƒço budeme prebera≈•, e≈°te predt√Ωm, ne≈æ sa do toho pust√≠me? Pozrite si tento ilustrovan√Ω sprievodca, ktor√Ω popisuje uƒçebn√∫ cestu tejto lekcie - od uƒçenia sa z√°kladn√Ωch konceptov a motiv√°cie pre jemn√© doladenie a≈æ po pochopenie procesu a najlep≈°√≠ch postupov pri vykon√°van√≠ √∫lohy jemn√©ho doladenia. Je to fascinuj√∫ca t√©ma na presk√∫manie, tak≈æe nezabudnite nav≈°t√≠vi≈• str√°nku [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pre ƒèal≈°ie odkazy na podporu va≈°ej samostatnej uƒçebnej cesty!

![Ilustrovan√Ω sprievodca jemn√Ωm doladen√≠m jazykov√Ωch modelov](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.sk.png)

## ƒåo je jemn√© doladenie jazykov√Ωch modelov?

Podƒæa defin√≠cie s√∫ veƒæk√© jazykov√© modely _predtr√©novan√©_ na veƒæk√Ωch mno≈æstv√°ch textu z√≠skan√©ho z r√¥znych zdrojov vr√°tane internetu. Ako sme sa nauƒçili v predch√°dzaj√∫cich lekci√°ch, na zlep≈°enie kvality odpoved√≠ modelu na ot√°zky pou≈æ√≠vateƒæa ("v√Ωzvy") potrebujeme techniky ako _n√°vrh v√Ωzvy_ a _generovanie s roz≈°√≠ren√Ωm vyhƒæad√°van√≠m_.

Popul√°rna technika n√°vrhu v√Ωzvy zah≈ï≈àa poskytnutie modelu v√§ƒç≈°ieho mno≈æstva pokynov o tom, ƒço sa oƒçak√°va v odpovedi, buƒè poskytnut√≠m _in≈°trukci√≠_ (explicitn√© usmernenie), alebo _poskytnut√≠m niekoƒæk√Ωch pr√≠kladov_ (implicitn√© usmernenie). Toto sa naz√Ωva _few-shot learning_, ale m√° dve obmedzenia:

- Limity tokenov modelu m√¥≈æu obmedzi≈• poƒçet pr√≠kladov, ktor√© m√¥≈æete poskytn√∫≈•, a t√Ωm zn√≠≈æi≈• efektivitu.
- N√°klady na tokeny modelu m√¥≈æu by≈• drah√© pri prid√°van√≠ pr√≠kladov ku ka≈ædej v√Ωzve, ƒço obmedzuje flexibilitu.

Jemn√© doladenie je be≈æn√° prax v syst√©moch strojov√©ho uƒçenia, kde vezmeme predtr√©novan√Ω model a pretr√©nujeme ho s nov√Ωmi √∫dajmi, aby sme zlep≈°ili jeho v√Ωkon na konkr√©tnej √∫lohe. V kontexte jazykov√Ωch modelov m√¥≈æeme jemne doladi≈• predtr√©novan√Ω model _s kur√°torskou sadou pr√≠kladov pre dan√∫ √∫lohu alebo aplikaƒçn√∫ oblas≈•_, aby sme vytvorili **vlastn√Ω model**, ktor√Ω m√¥≈æe by≈• presnej≈°√≠ a relevantnej≈°√≠ pre t√∫to konkr√©tnu √∫lohu alebo oblas≈•. Vedƒæaj≈°√≠m pr√≠nosom jemn√©ho doladenia je, ≈æe m√¥≈æe tie≈æ zn√≠≈æi≈• poƒçet potrebn√Ωch pr√≠kladov pre few-shot learning - ƒç√≠m sa zni≈æuje pou≈æ√≠vanie tokenov a s√∫visiace n√°klady.

## Kedy a preƒço by sme mali jemne doladi≈• modely?

V _tomto_ kontexte, keƒè hovor√≠me o jemnom doladen√≠, m√°me na mysli **superv√≠zovan√©** jemn√© doladenie, kde sa pretr√©novanie vykon√°va **pridan√≠m nov√Ωch √∫dajov**, ktor√© neboli s√∫ƒças≈•ou p√¥vodn√©ho tr√©ningov√©ho datasetu. To sa l√≠≈°i od nesuperv√≠zovan√©ho jemn√©ho doladenia, kde sa model pretr√©nuje na p√¥vodn√Ωch √∫dajoch, ale s r√¥znymi hyperparametrami.

Kƒæ√∫ƒçov√° vec, ktor√∫ si treba zapam√§ta≈•, je, ≈æe jemn√© doladenie je pokroƒçil√° technika, ktor√° si vy≈æaduje urƒçit√∫ √∫rove≈à odbornosti na dosiahnutie po≈æadovan√Ωch v√Ωsledkov. Ak sa vykon√° nespr√°vne, nemus√≠ prinies≈• oƒçak√°van√© zlep≈°enia a m√¥≈æe dokonca zhor≈°i≈• v√Ωkon modelu pre v√°≈° cieƒæov√Ω dom√©nov√Ω priestor.

Tak≈æe predt√Ωm, ne≈æ sa nauƒç√≠te "ako" jemne doladi≈• jazykov√© modely, mus√≠te vedie≈• "preƒço" by ste mali zvoli≈• t√∫to cestu a "kedy" zaƒça≈• proces jemn√©ho doladenia. Zaƒçnite t√Ωm, ≈æe si polo≈æ√≠te tieto ot√°zky:

- **Pou≈æitie**: Ak√Ω je v√°≈° _pr√≠pad pou≈æitia_ pre jemn√© doladenie? Ak√Ω aspekt aktu√°lneho predtr√©novan√©ho modelu chcete zlep≈°i≈•?
- **Alternat√≠vy**: Sk√∫sili ste _in√© techniky_ na dosiahnutie po≈æadovan√Ωch v√Ωsledkov? Pou≈æite ich na vytvorenie z√°kladnej l√≠nie pre porovnanie.
  - N√°vrh v√Ωzvy: Sk√∫ste techniky ako few-shot prompting s pr√≠kladmi relevantn√Ωch odpoved√≠ na v√Ωzvy. Vyhodno≈•te kvalitu odpoved√≠.
  - Generovanie s roz≈°√≠ren√Ωm vyhƒæad√°van√≠m: Sk√∫ste roz≈°√≠ri≈• v√Ωzvy v√Ωsledkami vyhƒæad√°vania vo va≈°ich √∫dajoch. Vyhodno≈•te kvalitu odpoved√≠.
- **N√°klady**: Identifikovali ste n√°klady na jemn√© doladenie?
  - Mo≈ænos≈• doladenia - je predtr√©novan√Ω model dostupn√Ω na jemn√© doladenie?
  - √ösilie - na pr√≠pravu tr√©ningov√Ωch √∫dajov, hodnotenie a doladenie modelu.
  - V√Ωpoƒçtov√° kapacita - na spustenie √∫loh jemn√©ho doladenia a nasadenie jemne doladen√©ho modelu.
  - √ödaje - pr√≠stup k dostatoƒçn√©mu mno≈æstvu kvalitn√Ωch pr√≠kladov na dosiahnutie vplyvu jemn√©ho doladenia.
- **V√Ωhody**: Potvrdili ste v√Ωhody jemn√©ho doladenia?
  - Kvalita - prekonal jemne doladen√Ω model z√°kladn√∫ l√≠niu?
  - N√°klady - zni≈æuje pou≈æ√≠vanie tokenov zjednodu≈°en√≠m v√Ωziev?
  - Roz≈°√≠riteƒænos≈• - m√¥≈æete z√°kladn√Ω model prisp√¥sobi≈• nov√Ωm dom√©nam?

Odpoveƒèou na tieto ot√°zky by ste mali by≈• schopn√≠ rozhodn√∫≈•, ƒçi je jemn√© doladenie spr√°vnym pr√≠stupom pre v√°≈° pr√≠pad pou≈æitia. Ide√°lne je, ak pr√≠stup plat√≠ iba vtedy, ak v√Ωhody preva≈æuj√∫ nad n√°kladmi. Keƒè sa rozhodnete pokraƒçova≈•, je ƒças prem√Ω≈°ƒæa≈• o _tom, ako_ m√¥≈æete jemne doladi≈• predtr√©novan√Ω model.

Chcete z√≠ska≈• viac inform√°ci√≠ o rozhodovacom procese? Pozrite si [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Ako m√¥≈æeme jemne doladi≈• predtr√©novan√Ω model?

Na jemn√© doladenie predtr√©novan√©ho modelu potrebujete:

- predtr√©novan√Ω model na jemn√© doladenie
- dataset na pou≈æitie pri jemnom doladen√≠
- tr√©ningov√© prostredie na spustenie √∫lohy jemn√©ho doladenia
- hostingov√© prostredie na nasadenie jemne doladen√©ho modelu

## Jemn√© doladenie v praxi

Nasleduj√∫ce zdroje poskytuj√∫ podrobn√© n√°vody, ktor√© v√°s preved√∫ skutoƒçn√Ωm pr√≠kladom pou≈æitia vybran√©ho modelu s kur√°torsk√Ωm datasetom. Na pr√°cu s t√Ωmito n√°vodmi potrebujete √∫ƒçet u konkr√©tneho poskytovateƒæa spolu s pr√≠stupom k relevantn√©mu modelu a datasetom.

| Poskytovateƒæ | N√°vod                                                                                                                                                                       | Popis                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Ako jemne doladi≈• chatovacie modely](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)       | Nauƒçte sa jemne doladi≈• `gpt-35-turbo` pre konkr√©tnu dom√©nu ("asistent receptov") pr√≠pravou tr√©ningov√Ωch √∫dajov, spusten√≠m √∫lohy jemn√©ho doladenia a pou≈æit√≠m jemne doladen√©ho modelu na inferenciu.                                                                                                                                                                                                                              |
| Azure OpenAI | [N√°vod na jemn√© doladenie GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Nauƒçte sa jemne doladi≈• model `gpt-35-turbo-0613` **na Azure** vykonan√≠m krokov na vytvorenie a nahranie tr√©ningov√Ωch √∫dajov, spustenie √∫lohy jemn√©ho doladenia. Nasadenie a pou≈æitie nov√©ho modelu.                                                                                                                                                                                                                             |
| Hugging Face | [Jemn√© doladenie LLMs s Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                           | Tento blogov√Ω pr√≠spevok v√°s prevedie jemn√Ωm doladen√≠m _otvoren√©ho LLM_ (napr. `CodeLlama 7B`) pomocou kni≈ænice [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) s otvoren√Ωmi [datasetmi](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Jemn√© doladenie LLMs s AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                     | AutoTrain (alebo AutoTrain Advanced) je python kni≈ænica vyvinut√° spoloƒçnos≈•ou Hugging Face, ktor√° umo≈æ≈àuje jemn√© doladenie pre mnoho r√¥znych √∫loh vr√°tane jemn√©ho doladenia LLM. AutoTrain je rie≈°enie bez potreby k√≥du a jemn√© doladenie je mo≈æn√© vykona≈• vo va≈°om vlastnom cloude, na Hugging Face Spaces alebo lok√°lne. Podporuje webov√© GUI, CLI a tr√©ning prostredn√≠ctvom yaml konfiguraƒçn√Ωch s√∫borov.                                           |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Zadanie

Vyberte si jeden z vy≈°≈°ie uveden√Ωch n√°vodov a prejdite si ho. _M√¥≈æeme replikova≈• verziu t√Ωchto n√°vodov v Jupyter Notebooks v tomto repozit√°ri len na referenciu. Pros√≠m, pou≈æite priamo p√¥vodn√© zdroje na z√≠skanie najnov≈°√≠ch verzi√≠_.

## Skvel√° pr√°ca! Pokraƒçujte vo svojom uƒçen√≠.

Po dokonƒçen√≠ tejto lekcie si pozrite na≈°u [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby ste pokraƒçovali v roz≈°irovan√≠ svojich znalost√≠ o generat√≠vnej AI!

Gratulujeme!! Dokonƒçili ste posledn√∫ lekciu zo s√©rie v2 tohto kurzu! Nezastavujte sa v uƒçen√≠ a budovan√≠. \*\*Pozrite si str√°nku [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pre zoznam ƒèal≈°√≠ch n√°vrhov pr√°ve na t√∫to t√©mu.

Na≈°a s√©ria lekci√≠ v1 bola tie≈æ aktualizovan√° s viacer√Ωmi zadaniami a konceptmi. Tak≈æe si n√°jdite chv√≠ƒæu na osvie≈æenie svojich vedomost√≠ - a pros√≠m [zdieƒæajte svoje ot√°zky a sp√§tn√∫ v√§zbu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), aby ste n√°m pomohli zlep≈°i≈• tieto lekcie pre komunitu.

---

**Zrieknutie sa zodpovednosti**:  
Tento dokument bol prelo≈æen√Ω pomocou slu≈æby AI prekladu [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho rodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nenesieme zodpovednos≈• za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.