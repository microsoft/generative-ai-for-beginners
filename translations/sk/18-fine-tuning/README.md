<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:49:08+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "sk"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.sk.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Doladenie v√°≈°ho LLM

Pou≈æ√≠vanie veƒæk√Ωch jazykov√Ωch modelov na tvorbu generat√≠vnych AI aplik√°ci√≠ prin√°≈°a nov√© v√Ωzvy. Kƒæ√∫ƒçov√Ωm probl√©mom je zabezpeƒçi≈• kvalitu odpoved√≠ (presnos≈• a relevantnos≈•) v obsahu generovanom modelom na z√°klade po≈æiadavky pou≈æ√≠vateƒæa. V predch√°dzaj√∫cich lekci√°ch sme diskutovali techniky ako prompt engineering a retrieval-augmented generation, ktor√© sa sna≈æia vyrie≈°i≈• tento probl√©m _√∫pravou vstupn√©ho promptu_ pre existuj√∫ci model.

V dne≈°nej lekcii sa pozrieme na tretiu techniku, **doladenie (fine-tuning)**, ktor√° sa sna≈æ√≠ vyrie≈°i≈• t√∫to v√Ωzvu _pre≈°kolen√≠m samotn√©ho modelu_ s pou≈æit√≠m dodatoƒçn√Ωch d√°t. Poƒème sa pozrie≈• na detaily.

## Ciele uƒçenia

T√°to lekcia predstavuje koncept doladenia predtr√©novan√Ωch jazykov√Ωch modelov, sk√∫ma v√Ωhody a v√Ωzvy tohto pr√≠stupu a poskytuje usmernenie, kedy a ako pou≈æi≈• doladenie na zlep≈°enie v√Ωkonu va≈°ich generat√≠vnych AI modelov.

Na konci tejto lekcie by ste mali vedie≈• odpoveda≈• na tieto ot√°zky:

- ƒåo je doladenie jazykov√Ωch modelov?
- Kedy a preƒço je doladenie u≈æitoƒçn√©?
- Ako m√¥≈æem doladi≈• predtr√©novan√Ω model?
- Ak√© s√∫ obmedzenia doladenia?

Pripraven√≠? Poƒème na to.

## Ilustrovan√Ω sprievodca

Chcete z√≠ska≈• celkov√Ω prehƒæad o tom, ƒço budeme prebera≈•, e≈°te predt√Ωm, ne≈æ sa do toho pust√≠me? Pozrite si tento ilustrovan√Ω sprievodca, ktor√Ω popisuje vzdel√°vaciu cestu pre t√∫to lekciu ‚Äì od pochopenia z√°kladn√Ωch konceptov a motiv√°cie pre doladenie a≈æ po pochopenie procesu a najlep≈°√≠ch prakt√≠k pri vykon√°van√≠ doladenia. Je to fascinuj√∫ca t√©ma na presk√∫manie, tak nezabudnite nav≈°t√≠vi≈• str√°nku [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pre ƒèal≈°ie odkazy, ktor√© podporia va≈°e samostatn√© ≈°t√∫dium!

![Ilustrovan√Ω sprievodca doladen√≠m jazykov√Ωch modelov](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.sk.png)

## ƒåo je doladenie jazykov√Ωch modelov?

Veƒæk√© jazykov√© modely s√∫ podƒæa defin√≠cie _predtr√©novan√©_ na veƒæk√Ωch mno≈æstv√°ch textu z√≠skan√©ho z r√¥znych zdrojov vr√°tane internetu. Ako sme sa nauƒçili v predch√°dzaj√∫cich lekci√°ch, potrebujeme techniky ako _prompt engineering_ a _retrieval-augmented generation_, aby sme zlep≈°ili kvalitu odpoved√≠ modelu na ot√°zky pou≈æ√≠vateƒæa (‚Äûprompty‚Äú).

Popul√°rna technika prompt engineeringu spoƒç√≠va v tom, ≈æe modelu poskytneme viac usmernen√≠, ƒço sa oƒçak√°va v odpovedi, buƒè prostredn√≠ctvom _in≈°trukci√≠_ (explicitn√© usmernenie) alebo _poskytnut√≠m niekoƒæk√Ωch pr√≠kladov_ (implicitn√© usmernenie). Toto sa naz√Ωva _few-shot learning_, ale m√° dve obmedzenia:

- Limit tokenov modelu m√¥≈æe obmedzi≈• poƒçet pr√≠kladov, ktor√© m√¥≈æete poskytn√∫≈•, a t√Ωm aj efektivitu.
- N√°klady na tokeny m√¥≈æu sp√¥sobi≈•, ≈æe prid√°vanie pr√≠kladov ku ka≈æd√©mu promptu bude drah√© a obmedz√≠ flexibilitu.

Doladenie je be≈æn√° prax v syst√©moch strojov√©ho uƒçenia, kde vezmeme predtr√©novan√Ω model a pre≈°kol√≠me ho s nov√Ωmi d√°tami, aby sme zlep≈°ili jeho v√Ωkon na konkr√©tnu √∫lohu. V kontexte jazykov√Ωch modelov m√¥≈æeme doladi≈• predtr√©novan√Ω model _s vybranou sadou pr√≠kladov pre dan√∫ √∫lohu alebo aplikaƒçn√∫ dom√©nu_, aby sme vytvorili **vlastn√Ω model**, ktor√Ω m√¥≈æe by≈• presnej≈°√≠ a relevantnej≈°√≠ pre t√∫to konkr√©tnu √∫lohu alebo dom√©nu. Vedƒæaj≈°ou v√Ωhodou doladenia je, ≈æe m√¥≈æe tie≈æ zn√≠≈æi≈• poƒçet pr√≠kladov potrebn√Ωch pre few-shot learning ‚Äì ƒç√≠m sa zn√≠≈æi spotreba tokenov a s√∫visiace n√°klady.

## Kedy a preƒço by sme mali doladi≈• modely?

V _tomto_ kontexte, keƒè hovor√≠me o doladen√≠, m√°me na mysli **supervidovan√©** doladenie, kde sa pre≈°kolenie vykon√°va **pridan√≠m nov√Ωch d√°t**, ktor√© neboli s√∫ƒças≈•ou p√¥vodn√©ho tr√©ningov√©ho datasetu. To sa l√≠≈°i od nesupervidovan√©ho doladenia, kde sa model pre≈°kol√≠ na p√¥vodn√Ωch d√°tach, ale s in√Ωmi hyperparametrami.

D√¥le≈æit√© je si uvedomi≈•, ≈æe doladenie je pokroƒçil√° technika, ktor√° vy≈æaduje urƒçit√∫ √∫rove≈à odbornosti, aby priniesla ≈æelan√© v√Ωsledky. Ak sa vykon√° nespr√°vne, nemus√≠ prinies≈• oƒçak√°van√© zlep≈°enia a m√¥≈æe dokonca zhor≈°i≈• v√Ωkon modelu pre va≈°u cieƒæov√∫ dom√©nu.

Predt√Ωm, ne≈æ sa nauƒç√≠te ‚Äûako‚Äú doladi≈• jazykov√© modely, mus√≠te vedie≈• ‚Äûpreƒço‚Äú by ste mali √≠s≈• touto cestou a ‚Äûkedy‚Äú zaƒça≈• proces doladenia. Zaƒçnite t√Ωm, ≈æe si polo≈æ√≠te tieto ot√°zky:

- **Pou≈æitie**: Ak√Ω je v√°≈° _pr√≠pad pou≈æitia_ pre doladenie? Ktor√Ω aspekt s√∫ƒçasn√©ho predtr√©novan√©ho modelu chcete zlep≈°i≈•?
- **Alternat√≠vy**: Sk√∫sili ste _in√© techniky_ na dosiahnutie po≈æadovan√Ωch v√Ωsledkov? Pou≈æite ich na vytvorenie z√°kladnej l√≠nie pre porovnanie.
  - Prompt engineering: Vysk√∫≈°ajte techniky ako few-shot prompting s pr√≠kladmi relevantn√Ωch odpoved√≠. Vyhodno≈•te kvalitu odpoved√≠.
  - Retrieval Augmented Generation: Vysk√∫≈°ajte doplni≈• prompty v√Ωsledkami vyhƒæad√°vania vo va≈°ich d√°tach. Vyhodno≈•te kvalitu odpoved√≠.
- **N√°klady**: Identifikovali ste n√°klady spojen√© s doladen√≠m?
  - Mo≈ænos≈• doladenia ‚Äì je predtr√©novan√Ω model dostupn√Ω na doladenie?
  - N√°maha ‚Äì pr√≠prava tr√©ningov√Ωch d√°t, hodnotenie a dolaƒèovanie modelu.
  - V√Ωpoƒçtov√© zdroje ‚Äì na spustenie doladiacich √∫loh a nasadenie doladen√©ho modelu.
  - D√°ta ‚Äì pr√≠stup k dostatoƒçne kvalitn√Ωm pr√≠kladom na dosiahnutie efektu doladenia.
- **V√Ωhody**: Potvrdili ste si v√Ωhody doladenia?
  - Kvalita ‚Äì prekonal doladen√Ω model z√°kladn√∫ l√≠niu?
  - N√°klady ‚Äì zni≈æuje spotrebu tokenov zjednodu≈°en√≠m promptov?
  - Roz≈°√≠riteƒænos≈• ‚Äì m√¥≈æete z√°kladn√Ω model pou≈æi≈• pre nov√© dom√©ny?

Odpoveƒèami na tieto ot√°zky by ste mali vedie≈• rozhodn√∫≈•, ƒçi je doladenie spr√°vnym pr√≠stupom pre v√°≈° pr√≠pad pou≈æitia. Ide√°lne je, ak s√∫ v√Ωhody vy≈°≈°ie ako n√°klady. Ak sa rozhodnete pokraƒçova≈•, je ƒças prem√Ω≈°ƒæa≈• o tom, _ako_ m√¥≈æete doladi≈• predtr√©novan√Ω model.

Chcete z√≠ska≈• viac inform√°ci√≠ o rozhodovacom procese? Pozrite si [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Ako m√¥≈æeme doladi≈• predtr√©novan√Ω model?

Na doladenie predtr√©novan√©ho modelu potrebujete:

- predtr√©novan√Ω model na doladenie
- dataset na doladenie
- tr√©ningov√© prostredie na spustenie doladiacej √∫lohy
- hostingov√© prostredie na nasadenie doladen√©ho modelu

## Doladenie v praxi

Nasleduj√∫ce zdroje poskytuj√∫ krok za krokom n√°vody, ktor√© v√°s preved√∫ re√°lnym pr√≠kladom s vybran√Ωm modelom a vybran√Ωm datasetom. Na pr√°cu s t√Ωmito tutori√°lmi potrebujete √∫ƒçet u konkr√©tneho poskytovateƒæa, ako aj pr√≠stup k relevantn√©mu modelu a datasetom.

| Poskytovateƒæ | Tutori√°l                                                                                                                                                                      | Popis                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)               | Nauƒçte sa doladi≈• `gpt-35-turbo` pre konkr√©tnu dom√©nu (‚Äûasistent na recepty‚Äú) pr√≠pravou tr√©ningov√Ωch d√°t, spusten√≠m doladiacej √∫lohy a pou≈æit√≠m doladen√©ho modelu na inferenciu.                                                                                                                                                                                                                                                  |
| Azure OpenAI | [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Nauƒçte sa doladi≈• model `gpt-35-turbo-0613` **na Azure** krok za krokom ‚Äì vytvorenie a nahranie tr√©ningov√Ωch d√°t, spustenie doladiacej √∫lohy, nasadenie a pou≈æitie nov√©ho modelu.                                                                                                                                                                                                                                                |
| Hugging Face | [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | Tento blogov√Ω pr√≠spevok v√°s prevedie doladen√≠m _otvoren√©ho LLM_ (napr. `CodeLlama 7B`) pomocou kni≈ænice [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) s otvoren√Ωmi [datasetmi](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| ü§ó AutoTrain | [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                        | AutoTrain (alebo AutoTrain Advanced) je python kni≈ænica vyvinut√° Hugging Face, ktor√° umo≈æ≈àuje doladenie pre r√¥zne √∫lohy vr√°tane doladenia LLM. AutoTrain je rie≈°enie bez k√≥du a doladenie m√¥≈æete vykona≈• vo vlastnom cloude, na Hugging Face Spaces alebo lok√°lne. Podporuje webov√© GUI, CLI a tr√©ning cez yaml konfiguraƒçn√© s√∫bory.                                                                                                   |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                   |

## Zadanie

Vyberte si jeden z vy≈°≈°ie uveden√Ωch tutori√°lov a prejdite si ho. _M√¥≈æeme vytvori≈• verziu t√Ωchto tutori√°lov v Jupyter Notebooks v tomto repozit√°ri len na referenciu. Pre najnov≈°ie verzie v≈°ak pou≈æ√≠vajte priamo p√¥vodn√© zdroje_.

## V√Ωborn√° pr√°ca! Pokraƒçujte v uƒçen√≠.

Po dokonƒçen√≠ tejto lekcie si pozrite na≈°u [kolekciu Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby ste naƒèalej rozv√≠jali svoje znalosti o generat√≠vnej AI!

Gratulujeme!! Dokonƒçili ste posledn√∫ lekciu z verzie v2 tohto kurzu! Nezastavujte sa v uƒçen√≠ a tvorbe. \*\*Pozrite si str√°nku [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pre zoznam ƒèal≈°√≠ch odpor√∫ƒçan√≠ pr√°ve k tejto t√©me.

Na≈°a s√©ria lekci√≠ v1 bola tie≈æ aktualizovan√° o viac zadania a konceptov. Tak si dajte chv√≠ƒæu na osvie≈æenie vedomost√≠ ‚Äì a pros√≠m, [zdieƒæajte svoje ot√°zky a sp√§tn√∫ v√§zbu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), aby sme mohli tieto lekcie pre komunitu e≈°te vylep≈°i≈•.

**Vyhl√°senie o zodpovednosti**:  
Tento dokument bol prelo≈æen√Ω pomocou AI prekladateƒæskej slu≈æby [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, majte na pam√§ti, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. Origin√°lny dokument v jeho p√¥vodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nie sme zodpovedn√≠ za ak√©koƒævek nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.