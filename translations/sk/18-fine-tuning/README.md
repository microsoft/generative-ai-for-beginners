<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-05-20T07:57:44+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "sk"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.8487555c3e3225eefc1dc84e72c8e00bce1ee76db867a080628fb0fbb04aa0d2.sk.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Doladenie v√°≈°ho LLM

Pou≈æ√≠vanie veƒæk√Ωch jazykov√Ωch modelov na vytv√°ranie aplik√°ci√≠ generat√≠vnej AI prin√°≈°a nov√© v√Ωzvy. Kƒæ√∫ƒçov√Ωm probl√©mom je zabezpeƒçenie kvality odpoved√≠ (presnos≈• a relevantnos≈•) v obsahu generovanom modelom pre dan√∫ po≈æiadavku pou≈æ√≠vateƒæa. V predch√°dzaj√∫cich lekci√°ch sme diskutovali o technik√°ch, ako je prompt engineering a retrieval-augmented generation, ktor√© sa sna≈æia vyrie≈°i≈• probl√©m _√∫pravou vstupu promptu_ do existuj√∫ceho modelu.

V dne≈°nej lekcii sa venujeme tretej technike, **doladeniu**, ktor√° sa sna≈æ√≠ rie≈°i≈• v√Ωzvu _pretr√©novan√≠m samotn√©ho modelu_ s ƒèal≈°√≠mi d√°tami. Poƒème sa ponori≈• do detailov.

## Ciele uƒçenia

T√°to lekcia predstavuje koncept doladenia pre predtr√©novan√© jazykov√© modely, sk√∫ma v√Ωhody a v√Ωzvy tohto pr√≠stupu a poskytuje rady, kedy a ako pou≈æi≈• doladenie na zlep≈°enie v√Ωkonu va≈°ich generat√≠vnych AI modelov.

Na konci tejto lekcie by ste mali by≈• schopn√≠ odpoveda≈• na nasleduj√∫ce ot√°zky:

- ƒåo je doladenie pre jazykov√© modely?
- Kedy a preƒço je doladenie u≈æitoƒçn√©?
- Ako m√¥≈æem doladi≈• predtr√©novan√Ω model?
- Ak√© s√∫ obmedzenia doladenia?

Pripraven√≠? Poƒème zaƒça≈•.

## Ilustrovan√Ω sprievodca

Chcete z√≠ska≈• celkov√Ω obraz o tom, ƒço budeme pokr√Ωva≈•, ne≈æ sa ponor√≠me do detailov? Pozrite si tento ilustrovan√Ω sprievodca, ktor√Ω popisuje cestu uƒçenia sa pre t√∫to lekciu - od uƒçenia sa z√°kladn√Ωch konceptov a motiv√°cie pre doladenie, po pochopenie procesu a najlep≈°√≠ch prakt√≠k pre vykonanie √∫lohy doladenia. Toto je fascinuj√∫ca t√©ma na presk√∫manie, tak≈æe nezabudnite si pozrie≈• str√°nku [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pre ƒèal≈°ie odkazy na podporu va≈°ej samostatnej cesty uƒçenia!

![Ilustrovan√Ω sprievodca doladen√≠m jazykov√Ωch modelov](../../../translated_images/18-fine-tuning-sketchnote.92733966235199dd260184b1aae3a84b877c7496bc872d8e63ad6fa2dd96bafc.sk.png)

## ƒåo je doladenie pre jazykov√© modely?

Podƒæa defin√≠cie s√∫ veƒæk√© jazykov√© modely _predtr√©novan√©_ na veƒækom mno≈æstve textov z√≠skan√Ωch z r√¥znych zdrojov vr√°tane internetu. Ako sme sa nauƒçili v predch√°dzaj√∫cich lekci√°ch, potrebujeme techniky ako _prompt engineering_ a _retrieval-augmented generation_, aby sme zlep≈°ili kvalitu odpoved√≠ modelu na ot√°zky pou≈æ√≠vateƒæa ("prompty").

Popul√°rna technika prompt engineeringu zah≈ï≈àa poskytnutie modelu viac pokynov o tom, ƒço sa oƒçak√°va v odpovedi, buƒè poskytnut√≠m _in≈°trukci√≠_ (explicitn√© vedenie) alebo _poskytnut√≠m niekoƒæk√Ωch pr√≠kladov_ (implicitn√© vedenie). Toto sa naz√Ωva _few-shot learning_, ale m√° dve obmedzenia:

- Limity tokenov modelu m√¥≈æu obmedzi≈• poƒçet pr√≠kladov, ktor√© m√¥≈æete poskytn√∫≈•, a obmedzi≈• √∫ƒçinnos≈•.
- N√°klady na tokeny modelu m√¥≈æu by≈• drah√©, ak prid√°vate pr√≠klady ku ka≈æd√©mu promptu, a obmedzuj√∫ flexibilitu.

Doladenie je be≈ænou praxou v syst√©moch strojov√©ho uƒçenia, kde vezmeme predtr√©novan√Ω model a pretr√©nujeme ho s nov√Ωmi d√°tami, aby sme zlep≈°ili jeho v√Ωkon na konkr√©tnu √∫lohu. V kontexte jazykov√Ωch modelov m√¥≈æeme doladi≈• predtr√©novan√Ω model _s kur√°torskou sadou pr√≠kladov pre dan√∫ √∫lohu alebo aplikaƒçn√∫ dom√©nu_, aby sme vytvorili **vlastn√Ω model**, ktor√Ω m√¥≈æe by≈• presnej≈°√≠ a relevantnej≈°√≠ pre t√∫to konkr√©tnu √∫lohu alebo dom√©nu. Vedƒæaj≈°√≠m pr√≠nosom doladenia je, ≈æe m√¥≈æe tie≈æ zn√≠≈æi≈• poƒçet potrebn√Ωch pr√≠kladov pre few-shot learning - ƒç√≠m sa zni≈æuje pou≈æitie tokenov a s√∫visiace n√°klady.

## Kedy a preƒço by sme mali doladi≈• modely?

V _tomto_ kontexte, keƒè hovor√≠me o doladen√≠, m√°me na mysli **superv√≠zovan√©** doladenie, kde sa pretr√©novanie vykon√°va **pridan√≠m nov√Ωch d√°t**, ktor√© neboli s√∫ƒças≈•ou p√¥vodn√©ho tr√©ningov√©ho datasetu. To sa l√≠≈°i od nesuperv√≠zovan√©ho doladenia, kde je model pretr√©novan√Ω na p√¥vodn√Ωch d√°tach, ale s r√¥znymi hyperparametrami.

Kƒæ√∫ƒçov√° vec, ktor√∫ si treba pam√§ta≈•, je, ≈æe doladenie je pokroƒçil√° technika, ktor√° vy≈æaduje urƒçit√∫ √∫rove≈à odbornosti na dosiahnutie po≈æadovan√Ωch v√Ωsledkov. Ak je vykonan√© nespr√°vne, nemus√≠ poskytn√∫≈• oƒçak√°van√© zlep≈°enia a m√¥≈æe dokonca zhor≈°i≈• v√Ωkon modelu pre va≈°u cieƒæov√∫ dom√©nu.

Tak≈æe predt√Ωm, ne≈æ sa nauƒç√≠te "ako" doladi≈• jazykov√© modely, mus√≠te vedie≈• "preƒço" by ste mali √≠s≈• touto cestou a "kedy" zaƒça≈• proces doladenia. Zaƒçnite t√Ωm, ≈æe si polo≈æ√≠te tieto ot√°zky:

- **Pou≈æitie**: Ak√© je va≈°e _pou≈æitie_ pre doladenie? Ak√Ω aspekt s√∫ƒçasn√©ho predtr√©novan√©ho modelu chcete zlep≈°i≈•?
- **Alternat√≠vy**: Sk√∫≈°ali ste _in√© techniky_, aby ste dosiahli po≈æadovan√© v√Ωsledky? Pou≈æite ich na vytvorenie z√°kladn√©ho porovnania.
  - Prompt engineering: Sk√∫ste techniky ako few-shot prompting s pr√≠kladmi relevantn√Ωch odpoved√≠ na prompt. Vyhodno≈•te kvalitu odpoved√≠.
  - Retrieval Augmented Generation: Sk√∫ste augmentova≈• prompty s v√Ωsledkami dotazov z√≠skan√Ωmi vyhƒæad√°van√≠m va≈°ich d√°t. Vyhodno≈•te kvalitu odpoved√≠.
- **N√°klady**: Identifikovali ste n√°klady na doladenie?
  - Doladiteƒænos≈• - je predtr√©novan√Ω model dostupn√Ω na doladenie?
  - √ösilie - na pr√≠pravu tr√©ningov√Ωch d√°t, hodnotenie a doladenie modelu.
  - V√Ωpoƒçtov√° kapacita - na spustenie √∫loh doladenia a nasadenie doladen√©ho modelu
  - D√°ta - pr√≠stup k dostatoƒçn√©mu mno≈æstvu kvalitn√Ωch pr√≠kladov na ovplyvnenie doladenia
- **V√Ωhody**: Potvrdili ste v√Ωhody doladenia?
  - Kvalita - prekonal doladen√Ω model z√°kladn√© porovnanie?
  - N√°klady - zni≈æuje to pou≈æitie tokenov zjednodu≈°en√≠m promptov?
  - Roz≈°√≠riteƒænos≈• - m√¥≈æete op√§tovne pou≈æi≈• z√°kladn√Ω model pre nov√© dom√©ny?

Zodpovedan√≠m t√Ωchto ot√°zok by ste mali by≈• schopn√≠ rozhodn√∫≈•, ƒçi je doladenie spr√°vnym pr√≠stupom pre v√°≈° pr√≠pad pou≈æitia. Ide√°lne je, ≈æe pr√≠stup je platn√Ω len vtedy, ak v√Ωhody preva≈æuj√∫ nad n√°kladmi. Keƒè sa rozhodnete pokraƒçova≈•, je ƒças prem√Ω≈°ƒæa≈• o _tom, ako_ m√¥≈æete doladi≈• predtr√©novan√Ω model.

Chcete z√≠ska≈• viac inform√°ci√≠ o procese rozhodovania? Sledujte [Doladi≈• alebo nedoladi≈•](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Ako m√¥≈æeme doladi≈• predtr√©novan√Ω model?

Na doladenie predtr√©novan√©ho modelu potrebujete:

- predtr√©novan√Ω model na doladenie
- dataset na pou≈æitie pri doladen√≠
- tr√©ningov√© prostredie na spustenie √∫lohy doladenia
- hostingov√© prostredie na nasadenie doladen√©ho modelu

## Doladenie v praxi

Nasleduj√∫ce zdroje poskytuj√∫ podrobn√© tutori√°ly, ktor√© v√°s preved√∫ skutoƒçn√Ωm pr√≠kladom pomocou vybran√©ho modelu s kur√°torsk√Ωm datasetom. Aby ste mohli prejs≈• t√Ωmito tutori√°lmi, potrebujete √∫ƒçet u konkr√©tneho poskytovateƒæa spolu s pr√≠stupom k relevantn√Ωm modelom a datasetom.

| Poskytovateƒæ | Tutori√°l                                                                                                                                                                       | Popis                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Ako doladi≈• chatovacie modely](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Nauƒçte sa doladi≈• `gpt-35-turbo` pre konkr√©tnu dom√©nu ("asistent receptov") pr√≠pravou tr√©ningov√Ωch d√°t, spusten√≠m √∫lohy doladenia a pou≈æit√≠m doladen√©ho modelu na inferenciu.                                                                                                                                                                                                                                              |
| Azure OpenAI | [GPT 3.5 Turbo doladenie tutori√°l](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Nauƒçte sa doladi≈• `gpt-35-turbo-0613` model **na Azure** vykonan√≠m krokov na vytvorenie a nahranie tr√©ningov√Ωch d√°t, spustenie √∫lohy doladenia. Nasadenie a pou≈æitie nov√©ho modelu.                                                                                                                                                                                                                                                                 |
| Hugging Face | [Doladenie LLMs s Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Tento blogov√Ω pr√≠spevok v√°s prevedie doladen√≠m _open LLM_ (napr. `CodeLlama 7B`) pomocou kni≈ænice [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) s otvoren√Ωmi [datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Doladenie LLMs s AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (alebo AutoTrain Advanced) je python kni≈ænica vyvinut√° Hugging Face, ktor√° umo≈æ≈àuje doladenie pre mnoho r√¥znych √∫loh vr√°tane doladenia LLM. AutoTrain je rie≈°enie bez k√≥du a doladenie m√¥≈æe by≈• vykonan√© vo va≈°om vlastnom cloude, na Hugging Face Spaces alebo lok√°lne. Podporuje webov√© rozhranie, CLI a tr√©ning pomocou yaml konfiguraƒçn√Ωch s√∫borov.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Zadanie

Vyberte jeden z vy≈°≈°ie uveden√Ωch tutori√°lov a prejdite ho. _M√¥≈æeme replikova≈• verziu t√Ωchto tutori√°lov v Jupyter Notebooks v tomto repozit√°ri len na referenciu. Pou≈æite p√¥vodn√© zdroje priamo na z√≠skanie najnov≈°√≠ch verzi√≠_.

## Skvel√° pr√°ca! Pokraƒçujte vo svojom uƒçen√≠.

Po dokonƒçen√≠ tejto lekcie si pozrite na≈°u [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby ste pokraƒçovali v zvy≈°ovan√≠ svojich znalost√≠ o Generat√≠vnej AI!

Gratulujeme!! Dokonƒçili ste posledn√∫ lekciu z v2 s√©rie pre tento kurz! Neprest√°vajte sa uƒçi≈• a budova≈•. \*\*Pozrite si str√°nku [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pre zoznam ƒèal≈°√≠ch n√°vrhov pr√°ve pre t√∫to t√©mu.

Na≈°a v1 s√©ria lekci√≠ bola tie≈æ aktualizovan√° s viacer√Ωmi √∫lohami a konceptmi. Tak≈æe si chv√≠ƒæu osvie≈æte svoje vedomosti - a pros√≠m [podeƒæte sa o svoje ot√°zky a sp√§tn√∫ v√§zbu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), aby sme mohli zlep≈°i≈• tieto lekcie pre komunitu.

**Upozornenie**:  
Tento dokument bol prelo≈æen√Ω pomocou AI prekladateƒæskej slu≈æby [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa sna≈æ√≠me o presnos≈•, pros√≠m, berte na vedomie, ≈æe automatizovan√© preklady m√¥≈æu obsahova≈• chyby alebo nepresnosti. P√¥vodn√Ω dokument v jeho rodnom jazyku by mal by≈• pova≈æovan√Ω za autoritat√≠vny zdroj. Pre kritick√© inform√°cie sa odpor√∫ƒça profesion√°lny ƒæudsk√Ω preklad. Nie sme zodpovedn√≠ za ≈æiadne nedorozumenia alebo nespr√°vne interpret√°cie vypl√Ωvaj√∫ce z pou≈æitia tohto prekladu.