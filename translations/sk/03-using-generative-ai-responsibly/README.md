<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:49:37+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "sk"
}
-->
# ZodpovednÃ© pouÅ¾Ã­vanie generatÃ­vnej AI

[![ZodpovednÃ© pouÅ¾Ã­vanie generatÃ­vnej AI](../../../translated_images/03-lesson-banner.63a265562d8a9f9230f5c636ab303a0137d11420177528f475b0a05c5f6a9ff9.sk.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite na obrÃ¡zok vyÅ¡Å¡ie a pozrite si video tejto lekcie_

Je Ä¾ahkÃ© byÅ¥ fascinovanÃ½ AI, obzvlÃ¡Å¡Å¥ generatÃ­vnou AI, ale je potrebnÃ© zvÃ¡Å¾iÅ¥, ako ju pouÅ¾Ã­vaÅ¥ zodpovedne. Je potrebnÃ© zvÃ¡Å¾iÅ¥ veci ako zabezpeÄenie spravodlivÃ©ho a neÅ¡kodnÃ©ho vÃ½stupu a ÄalÅ¡ie. TÃ¡to kapitola sa snaÅ¾Ã­ poskytnÃºÅ¥ vÃ¡m uvedenÃ½ kontext, Äo zvÃ¡Å¾iÅ¥ a ako podniknÃºÅ¥ aktÃ­vne kroky na zlepÅ¡enie pouÅ¾Ã­vania AI.

## Ãšvod

TÃ¡to lekcia pokryje:

- PreÄo by ste mali uprednostniÅ¥ zodpovednÃº AI pri budovanÃ­ aplikÃ¡ciÃ­ generatÃ­vnej AI.
- ZÃ¡kladnÃ© princÃ­py zodpovednej AI a ako sa vzÅ¥ahujÃº na generatÃ­vnu AI.
- Ako uplatniÅ¥ tieto princÃ­py zodpovednej AI v praxi prostrednÃ­ctvom stratÃ©gie a nÃ¡strojov.

## Ciele uÄenia

Po dokonÄenÃ­ tejto lekcie budete vedieÅ¥:

- DÃ´leÅ¾itosÅ¥ zodpovednej AI pri budovanÃ­ aplikÃ¡ciÃ­ generatÃ­vnej AI.
- Kedy premÃ½Å¡Ä¾aÅ¥ a uplatniÅ¥ zÃ¡kladnÃ© princÃ­py zodpovednej AI pri budovanÃ­ aplikÃ¡ciÃ­ generatÃ­vnej AI.
- AkÃ© nÃ¡stroje a stratÃ©gie sÃº dostupnÃ©, aby ste koncept zodpovednej AI uviedli do praxe.

## PrincÃ­py zodpovednej AI

NadÅ¡enie z generatÃ­vnej AI nikdy nebolo vyÅ¡Å¡ie. Toto nadÅ¡enie prinieslo do tejto oblasti mnoÅ¾stvo novÃ½ch vÃ½vojÃ¡rov, pozornosÅ¥ a financovanie. Aj keÄ je to veÄ¾mi pozitÃ­vne pre kaÅ¾dÃ©ho, kto chce budovaÅ¥ produkty a spoloÄnosti pomocou generatÃ­vnej AI, je tieÅ¾ dÃ´leÅ¾itÃ© pokraÄovaÅ¥ zodpovedne.

PoÄas tohto kurzu sa zameriavame na budovanie nÃ¡Å¡ho startupu a nÃ¡Å¡ho vzdelÃ¡vacieho produktu AI. PouÅ¾ijeme princÃ­py zodpovednej AI: SpravodlivosÅ¥, InkluzÃ­vnosÅ¥, SpoÄ¾ahlivosÅ¥/BezpeÄnosÅ¥, ZabezpeÄenie a SÃºkromie, TransparentnosÅ¥ a ZodpovednosÅ¥. S tÃ½mito princÃ­pmi preskÃºmame, ako sa vzÅ¥ahujÃº na naÅ¡e pouÅ¾Ã­vanie generatÃ­vnej AI v naÅ¡ich produktoch.

## PreÄo by ste mali uprednostniÅ¥ zodpovednÃº AI

Pri budovanÃ­ produktu, zaujatie prÃ­stupu zameranÃ©ho na Äloveka tÃ½m, Å¾e mÃ¡te na pamÃ¤ti najlepÅ¡Ã­ zÃ¡ujem vaÅ¡ich pouÅ¾Ã­vateÄ¾ov, vedie k najlepÅ¡Ã­m vÃ½sledkom.

UnikÃ¡tnosÅ¥ generatÃ­vnej AI je jej schopnosÅ¥ vytvÃ¡raÅ¥ uÅ¾itoÄnÃ© odpovede, informÃ¡cie, rady a obsah pre pouÅ¾Ã­vateÄ¾ov. To sa dÃ¡ urobiÅ¥ bez mnohÃ½ch manuÃ¡lnych krokov, Äo mÃ´Å¾e viesÅ¥ k veÄ¾mi pÃ´sobivÃ½m vÃ½sledkom. Bez sprÃ¡vneho plÃ¡novania a stratÃ©giÃ­ to mÃ´Å¾e bohuÅ¾iaÄ¾ tieÅ¾ viesÅ¥ k Å¡kodlivÃ½m vÃ½sledkom pre vaÅ¡ich pouÅ¾Ã­vateÄ¾ov, vÃ¡Å¡ produkt a spoloÄnosÅ¥ ako celok.

Pozrime sa na niektorÃ© (ale nie vÅ¡etky) z tÃ½chto potenciÃ¡lne Å¡kodlivÃ½ch vÃ½sledkov:

### HalucinÃ¡cie

HalucinÃ¡cie sÃº termÃ­n pouÅ¾Ã­vanÃ½ na popis, keÄ LLM produkuje obsah, ktorÃ½ je buÄ Ãºplne nezmyselnÃ½, alebo nieÄo, o Äom vieme, Å¾e je fakticky nesprÃ¡vne na zÃ¡klade inÃ½ch zdrojov informÃ¡ciÃ­.

Predstavme si, Å¾e vytvorÃ­me funkciu pre nÃ¡Å¡ startup, ktorÃ¡ umoÅ¾nÃ­ Å¡tudentom klÃ¡sÅ¥ historickÃ© otÃ¡zky modelu. Å tudent sa pÃ½ta otÃ¡zku `Who was the sole survivor of Titanic?`

Model produkuje odpoveÄ, ako je tÃ¡ niÅ¾Å¡ie:

![VÃ½zva s textom "Kto bol jedinÃ½m preÅ¾ivÅ¡Ã­m z Titanicu"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Zdroj: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Toto je veÄ¾mi sebavedomÃ¡ a dÃ´kladnÃ¡ odpoveÄ. BohuÅ¾iaÄ¾, je nesprÃ¡vna. Aj s minimÃ¡lnym mnoÅ¾stvom vÃ½skumu by sa zistilo, Å¾e z katastrofy Titanicu preÅ¾ilo viac ako jedna osoba. Pre Å¡tudenta, ktorÃ½ prÃ¡ve zaÄÃ­na skÃºmaÅ¥ tÃºto tÃ©mu, mÃ´Å¾e byÅ¥ tÃ¡to odpoveÄ presvedÄivÃ¡ natoÄ¾ko, Å¾e ju nebude spochybÅˆovaÅ¥ a bude ju povaÅ¾ovaÅ¥ za fakt. DÃ´sledky tohto mÃ´Å¾u viesÅ¥ k tomu, Å¾e AI systÃ©m bude nespoÄ¾ahlivÃ½ a negatÃ­vne ovplyvnÃ­ reputÃ¡ciu nÃ¡Å¡ho startupu.

Pri kaÅ¾dej iterÃ¡cii danÃ©ho LLM sme zaznamenali zlepÅ¡enie vÃ½konu pri minimalizovanÃ­ halucinÃ¡ciÃ­. Aj pri tomto zlepÅ¡enÃ­, my ako tvorcovia aplikÃ¡ciÃ­ a pouÅ¾Ã­vatelia stÃ¡le musÃ­me byÅ¥ si vedomÃ­ tÃ½chto obmedzenÃ­.

### Å kodlivÃ½ obsah

V predchÃ¡dzajÃºcej Äasti sme sa venovali tomu, keÄ LLM produkuje nesprÃ¡vne alebo nezmyselnÃ© odpovede. ÄalÅ¡Ã­m rizikom, ktorÃ© musÃ­me maÅ¥ na pamÃ¤ti, je, keÄ model odpovedÃ¡ Å¡kodlivÃ½m obsahom.

Å kodlivÃ½ obsah mÃ´Å¾e byÅ¥ definovanÃ½ ako:

- Poskytovanie pokynov alebo podpora sebapoÅ¡kodzovania alebo poÅ¡kodzovania urÄitÃ½ch skupÃ­n.
- NenÃ¡vistnÃ½ alebo poniÅ¾ujÃºci obsah.
- NÃ¡vody na plÃ¡novanie akÃ©hokoÄ¾vek typu Ãºtoku alebo nÃ¡silnÃ½ch Äinov.
- Poskytovanie pokynov na nÃ¡jdenie nelegÃ¡lneho obsahu alebo spÃ¡chanie nelegÃ¡lnych Äinov.
- Zobrazovanie sexuÃ¡lne explicitnÃ©ho obsahu.

Pre nÃ¡Å¡ startup chceme zabezpeÄiÅ¥, Å¾e mÃ¡me sprÃ¡vne nÃ¡stroje a stratÃ©gie na zabrÃ¡nenie tomu, aby sa tento typ obsahu dostal k Å¡tudentom.

### Nedostatok spravodlivosti

SpravodlivosÅ¥ je definovanÃ¡ ako â€zabezpeÄenie, Å¾e AI systÃ©m je bez predsudkov a diskriminÃ¡cie a Å¾e zaobchÃ¡dza so vÅ¡etkÃ½mi spravodlivo a rovnakoâ€œ. Vo svete generatÃ­vnej AI chceme zabezpeÄiÅ¥, Å¾e vyluÄujÃºce svetonÃ¡zory marginalizovanÃ½ch skupÃ­n nie sÃº posilnenÃ© vÃ½stupom modelu.

Tieto typy vÃ½stupov sÃº nielen deÅ¡truktÃ­vne pre budovanie pozitÃ­vnych produktovÃ½ch zÃ¡Å¾itkov pre naÅ¡ich pouÅ¾Ã­vateÄ¾ov, ale tieÅ¾ spÃ´sobujÃº ÄalÅ¡ie spoloÄenskÃ© Å¡kody. Ako tvorcovia aplikÃ¡ciÃ­ by sme mali vÅ¾dy maÅ¥ na pamÃ¤ti Å¡irokÃº a rozmanitÃº zÃ¡kladÅˆu pouÅ¾Ã­vateÄ¾ov pri budovanÃ­ rieÅ¡enÃ­ s generatÃ­vnou AI.

## Ako pouÅ¾Ã­vaÅ¥ generatÃ­vnu AI zodpovedne

Teraz, keÄ sme identifikovali dÃ´leÅ¾itosÅ¥ zodpovednej generatÃ­vnej AI, pozrime sa na 4 kroky, ktorÃ© mÃ´Å¾eme podniknÃºÅ¥, aby sme zodpovedne budovali naÅ¡e AI rieÅ¡enia:

![Cyklus zmierÅˆovania](../../../translated_images/mitigate-cycle.f82610b2048bda5a84aaa3a3cb2cda8b35fe614a7269743fdc63cbc2cbb8f20f.sk.png)

### Meranie potenciÃ¡lnych Å¡kÃ´d

V softvÃ©rovom testovanÃ­ testujeme oÄakÃ¡vanÃ© akcie pouÅ¾Ã­vateÄ¾a na aplikÃ¡cii. Podobne, testovanie rÃ´znorodÃ©ho sÃºboru vÃ½ziev, ktorÃ© pouÅ¾Ã­vatelia pravdepodobne pouÅ¾ijÃº, je dobrÃ½ spÃ´sob, ako meraÅ¥ potenciÃ¡lnu Å¡kodu.

KeÄÅ¾e nÃ¡Å¡ startup buduje vzdelÃ¡vacÃ­ produkt, bolo by dobrÃ© pripraviÅ¥ zoznam vÃ½ziev sÃºvisiacich so vzdelÃ¡vanÃ­m. To by mohlo pokrÃ½vaÅ¥ urÄitÃ½ predmet, historickÃ© fakty a vÃ½zvy tÃ½kajÃºce sa Å¾ivota Å¡tudentov.

### Zmiernenie potenciÃ¡lnych Å¡kÃ´d

Teraz je Äas nÃ¡jsÅ¥ spÃ´soby, ako mÃ´Å¾eme zabrÃ¡niÅ¥ alebo obmedziÅ¥ potenciÃ¡lnu Å¡kodu spÃ´sobenÃº modelom a jeho odpoveÄami. MÃ´Å¾eme sa na to pozrieÅ¥ v 4 rÃ´znych vrstvÃ¡ch:

![Vrstvy zmierÅˆovania](../../../translated_images/mitigation-layers.db2d802e3affb2f49681cf8ae39e8f1a67ff1ce29c3f1099c96948a841d62037.sk.png)

- **Model**. VÃ½ber sprÃ¡vneho modelu pre sprÃ¡vny prÃ­pad pouÅ¾itia. VÃ¤ÄÅ¡ie a zloÅ¾itejÅ¡ie modely ako GPT-4 mÃ´Å¾u spÃ´sobiÅ¥ vÃ¤ÄÅ¡ie riziko Å¡kodlivÃ©ho obsahu, keÄ sÃº aplikovanÃ© na menÅ¡ie a Å¡pecifickÃ© prÃ­pady pouÅ¾itia. PouÅ¾itie vaÅ¡ich trÃ©ningovÃ½ch dÃ¡t na jemnÃ© doladenie tieÅ¾ zniÅ¾uje riziko Å¡kodlivÃ©ho obsahu.

- **BezpeÄnostnÃ½ systÃ©m**. BezpeÄnostnÃ½ systÃ©m je sÃºbor nÃ¡strojov a konfigurÃ¡ciÃ­ na platforme, ktorÃ¡ poskytuje model, ktorÃ© pomÃ¡hajÃº zmierniÅ¥ Å¡kodu. PrÃ­kladom je systÃ©m filtrovania obsahu na sluÅ¾be Azure OpenAI. SystÃ©my by tieÅ¾ mali detekovaÅ¥ Ãºtoky typu jailbreak a neÅ¾iaducu aktivitu, ako sÃº poÅ¾iadavky od botov.

- **Metaprompt**. Metaprompt a ukotvenie sÃº spÃ´soby, ako mÃ´Å¾eme usmerniÅ¥ alebo obmedziÅ¥ model na zÃ¡klade urÄitÃ½ch sprÃ¡vanÃ­ a informÃ¡ciÃ­. To by mohlo byÅ¥ pouÅ¾itie systÃ©movÃ½ch vstupov na definovanie urÄitÃ½ch limitov modelu. Okrem toho poskytovanie vÃ½stupov, ktorÃ© sÃº relevantnejÅ¡ie pre rozsah alebo domÃ©nu systÃ©mu.

MÃ´Å¾e to byÅ¥ tieÅ¾ pouÅ¾itie technÃ­k ako Retrieval Augmented Generation (RAG), aby model Äerpal informÃ¡cie iba z vÃ½beru dÃ´veryhodnÃ½ch zdrojov. V tejto lekcii je neskÃ´r lekcia pre [budovanie vyhÄ¾adÃ¡vacÃ­ch aplikÃ¡ciÃ­](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **PouÅ¾Ã­vateÄ¾skÃ¡ skÃºsenosÅ¥**. PoslednÃ¡ vrstva je miesto, kde pouÅ¾Ã­vateÄ¾ interaguje priamo s modelom prostrednÃ­ctvom rozhrania naÅ¡ej aplikÃ¡cie urÄitÃ½m spÃ´sobom. TÃ½mto spÃ´sobom mÃ´Å¾eme navrhnÃºÅ¥ UI/UX tak, aby sme obmedzili pouÅ¾Ã­vateÄ¾a na typy vstupov, ktorÃ© mÃ´Å¾e posielaÅ¥ modelu, ako aj text alebo obrÃ¡zky zobrazovanÃ© pouÅ¾Ã­vateÄ¾ovi. Pri nasadzovanÃ­ AI aplikÃ¡cie musÃ­me tieÅ¾ byÅ¥ transparentnÃ­ ohÄ¾adom toho, Äo naÅ¡a generatÃ­vna AI aplikÃ¡cia mÃ´Å¾e a nemÃ´Å¾e robiÅ¥.

MÃ¡me celÃº lekciu venovanÃº [navrhovaniu UX pre AI aplikÃ¡cie](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Vyhodnotenie modelu**. PrÃ¡ca s LLM mÃ´Å¾e byÅ¥ nÃ¡roÄnÃ¡, pretoÅ¾e nemÃ¡me vÅ¾dy kontrolu nad dÃ¡tami, na ktorÃ½ch bol model trÃ©novanÃ½. Bez ohÄ¾adu na to, by sme mali vÅ¾dy vyhodnotiÅ¥ vÃ½kon a vÃ½stupy modelu. Je stÃ¡le dÃ´leÅ¾itÃ© meraÅ¥ presnosÅ¥, podobnosÅ¥, ukotvenie a relevantnosÅ¥ vÃ½stupu modelu. To pomÃ¡ha poskytovaÅ¥ transparentnosÅ¥ a dÃ´veru pre zainteresovanÃ© strany a pouÅ¾Ã­vateÄ¾ov.

### PrevÃ¡dzkovanie zodpovednÃ©ho rieÅ¡enia generatÃ­vnej AI

Budovanie operaÄnej praxe okolo vaÅ¡ich AI aplikÃ¡ciÃ­ je poslednÃ¡ fÃ¡za. To zahÅ•Åˆa partnerstvo s inÃ½mi ÄasÅ¥ami nÃ¡Å¡ho startupu, ako sÃº PrÃ¡vne a BezpeÄnosÅ¥, aby sme zabezpeÄili, Å¾e sme v sÃºlade so vÅ¡etkÃ½mi regulaÄnÃ½mi politikami. Pred uvedenÃ­m na trh tieÅ¾ chceme budovaÅ¥ plÃ¡ny okolo doruÄovania, rieÅ¡enia incidentov a rollbacku, aby sme zabrÃ¡nili akÃ©mukoÄ¾vek poÅ¡kodeniu naÅ¡ich pouÅ¾Ã­vateÄ¾ov.

## NÃ¡stroje

Aj keÄ sa prÃ¡ca na vÃ½voji zodpovednÃ½ch AI rieÅ¡enÃ­ mÃ´Å¾e zdaÅ¥ veÄ¾a, je to prÃ¡ca, ktorÃ¡ stojÃ­ za to. Ako sa oblasÅ¥ generatÃ­vnej AI rozrastÃ¡, viac nÃ¡strojov na pomoc vÃ½vojÃ¡rom efektÃ­vne integrovaÅ¥ zodpovednosÅ¥ do ich pracovnÃ½ch tokov bude dozrievaÅ¥. NaprÃ­klad, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) mÃ´Å¾e pomÃ´cÅ¥ detekovaÅ¥ Å¡kodlivÃ½ obsah a obrÃ¡zky prostrednÃ­ctvom API poÅ¾iadavky.

## Kontrola vedomostÃ­

Na Äo je potrebnÃ© dbaÅ¥, aby sa zabezpeÄilo zodpovednÃ© pouÅ¾Ã­vanie AI?

1. Å½e odpoveÄ je sprÃ¡vna.
1. Å kodlivÃ© pouÅ¾itie, aby AI nebola pouÅ¾itÃ¡ na kriminÃ¡lne ÃºÄely.
1. ZabezpeÄenie, Å¾e AI je bez predsudkov a diskriminÃ¡cie.

A: 2 a 3 sÃº sprÃ¡vne. ZodpovednÃ¡ AI vÃ¡m pomÃ¡ha zvÃ¡Å¾iÅ¥, ako zmierniÅ¥ Å¡kodlivÃ© ÃºÄinky a predsudky a viac.

## ğŸš€ VÃ½zva

PreÄÃ­tajte si o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) a zistite, Äo mÃ´Å¾ete prijaÅ¥ pre svoje pouÅ¾itie.

## SkvelÃ¡ prÃ¡ca, pokraÄujte vo svojom uÄenÃ­

Po dokonÄenÃ­ tejto lekcie si pozrite naÅ¡u [kolekciu uÄenia o generatÃ­vnej AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby ste pokraÄovali v rozÅ¡irovanÃ­ svojich vedomostÃ­ o generatÃ­vnej AI!

Prejdite na lekciu 4, kde sa pozrieme na [ZÃ¡klady inÅ¾inierstva vÃ½ziev](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Upozornenie**:  
Tento dokument bol preloÅ¾enÃ½ pomocou AI prekladovej sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). Hoci sa snaÅ¾Ã­me o presnosÅ¥, prosÃ­m uvedomte si, Å¾e automatizovanÃ© preklady mÃ´Å¾u obsahovaÅ¥ chyby alebo nepresnosti. PÃ´vodnÃ½ dokument v jeho rodnom jazyku by mal byÅ¥ povaÅ¾ovanÃ½ za autoritatÃ­vny zdroj. Pre kritickÃ© informÃ¡cie sa odporÃºÄa profesionÃ¡lny Ä¾udskÃ½ preklad. Nie sme zodpovednÃ­ za Å¾iadne nedorozumenia alebo nesprÃ¡vne interpretÃ¡cie vyplÃ½vajÃºce z pouÅ¾itia tohto prekladu.