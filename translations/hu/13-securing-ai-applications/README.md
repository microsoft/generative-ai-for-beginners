<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a2faf8ee7a0b851efa647a19788f1e5b",
  "translation_date": "2025-10-17T21:25:18+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "hu"
}
-->
# Generat√≠v AI alkalmaz√°sok biztons√°g√°nak meg≈ërz√©se

[![Generat√≠v AI alkalmaz√°sok biztons√°g√°nak meg≈ërz√©se](../../../translated_images/13-lesson-banner.14103e36b4bbf17398b64ed2b0531f6f2c6549e7f7342f797c40bcae5a11862e.hu.png)](https://youtu.be/m0vXwsx5DNg?si=TYkr936GMKz15K0L)

## Bevezet√©s

Ebben a leck√©ben sz√≥ lesz:

- A biztons√°gr√≥l az AI rendszerek kontextus√°ban.
- Az AI rendszereket √©rint≈ë gyakori kock√°zatokr√≥l √©s fenyeget√©sekr≈ël.
- Az AI rendszerek biztons√°g√°nak meg≈ërz√©s√©re szolg√°l√≥ m√≥dszerekr≈ël √©s szempontokr√≥l.

## Tanul√°si c√©lok

A lecke elv√©gz√©se ut√°n meg√©rted:

- Az AI rendszereket √©rint≈ë fenyeget√©seket √©s kock√°zatokat.
- Az AI rendszerek biztons√°g√°nak meg≈ërz√©s√©re szolg√°l√≥ gyakori m√≥dszereket √©s gyakorlatokat.
- Hogyan el≈ëzheted meg a nem v√°rt eredm√©nyeket √©s a felhaszn√°l√≥i bizalom cs√∂kken√©s√©t biztons√°gi tesztel√©s alkalmaz√°s√°val.

## Mit jelent a biztons√°g a generat√≠v AI kontextus√°ban?

Ahogy a mesters√©ges intelligencia (AI) √©s a g√©pi tanul√°s (ML) technol√≥gi√°i egyre ink√°bb form√°lj√°k √©let√ºnket, elengedhetetlen, hogy ne csak az √ºgyf√©ladatokat, hanem magukat az AI rendszereket is megv√©dj√ºk. Az AI/ML egyre gyakrabban t√°mogatja a nagy √©rt√©k≈± d√∂nt√©shozatali folyamatokat olyan ipar√°gakban, ahol a rossz d√∂nt√©sek s√∫lyos k√∂vetkezm√©nyekkel j√°rhatnak.

√çme n√©h√°ny kulcsfontoss√°g√∫ szempont:

- **AI/ML hat√°sa**: Az AI/ML jelent≈ës hat√°ssal van a mindennapi √©letre, ez√©rt elengedhetetlen ezek v√©delme.
- **Biztons√°gi kih√≠v√°sok**: Az AI/ML hat√°sa megfelel≈ë figyelmet ig√©nyel, hogy megv√©dj√ºk az AI-alap√∫ term√©keket a kifinomult t√°mad√°sokt√≥l, legyenek azok trollok vagy szervezett csoportok √°ltal v√©grehajtottak.
- **Strat√©giai probl√©m√°k**: A technol√≥giai iparnak proakt√≠van kell kezelnie a strat√©giai kih√≠v√°sokat, hogy hossz√∫ t√°von biztos√≠tsa az √ºgyfelek biztons√°g√°t √©s az adatok v√©delm√©t.

Ezenk√≠v√ºl a g√©pi tanul√°si modellek nagyr√©szt k√©ptelenek megk√ºl√∂nb√∂ztetni a rosszindulat√∫ bemenetet a j√≥indulat√∫, szokatlan adatokt√≥l. Az edz√©shez haszn√°lt adatok jelent≈ës r√©sze nem ellen≈ërz√∂tt, moder√°latlan, nyilv√°nos adatb√°zisokb√≥l sz√°rmazik, amelyekhez harmadik felek is hozz√°j√°rulhatnak. A t√°mad√≥knak nem kell felt√∂rni√ºk az adatb√°zisokat, ha szabadon hozz√°j√°rulhatnak hozz√°juk. Id≈ëvel az alacsony megb√≠zhat√≥s√°g√∫ rosszindulat√∫ adatok magas megb√≠zhat√≥s√°g√∫, megb√≠zhat√≥ adatokk√° v√°lhatnak, ha az adatszerkezet/form√°tum helyes marad.

Ez√©rt kritikus fontoss√°g√∫ biztos√≠tani a modellek d√∂nt√©seihez haszn√°lt adatt√°rol√≥k integrit√°s√°t √©s v√©delm√©t.

## Az AI fenyeget√©seinek √©s kock√°zatainak meg√©rt√©se

Az AI √©s a kapcsol√≥d√≥ rendszerek tekintet√©ben az adatm√©rgez√©s ma a legjelent≈ësebb biztons√°gi fenyeget√©s. Az adatm√©rgez√©s akkor k√∂vetkezik be, amikor valaki sz√°nd√©kosan megv√°ltoztatja az AI edz√©s√©hez haszn√°lt inform√°ci√≥kat, hib√°s m≈±k√∂d√©st okozva. Ez a szabv√°nyos√≠tott √©szlel√©si √©s enyh√≠t√©si m√≥dszerek hi√°nya, valamint a nem megb√≠zhat√≥ vagy nem ellen≈ërz√∂tt nyilv√°nos adatb√°zisokra val√≥ t√°maszkod√°s miatt t√∂rt√©nik. Az adatintegrit√°s fenntart√°sa √©s a hib√°s edz√©si folyamat megel≈ëz√©se √©rdek√©ben elengedhetetlen az adatok eredet√©nek √©s sz√°rmaz√°s√°nak nyomon k√∂vet√©se. Ellenkez≈ë esetben az ‚Äûamit beviszel, azt kapod‚Äù r√©gi mond√°s igaz marad, ami a modell teljes√≠tm√©ny√©nek roml√°s√°hoz vezet.

√çme n√©h√°ny p√©lda arra, hogyan befoly√°solhatja az adatm√©rgez√©s a modelleket:

1. **C√≠mke megford√≠t√°sa**: Egy bin√°ris oszt√°lyoz√°si feladatban egy t√°mad√≥ sz√°nd√©kosan megford√≠tja az edz√©si adatok egy kis r√©sz√©nek c√≠mk√©it. P√©ld√°ul a j√≥indulat√∫ mint√°kat rosszindulat√∫k√©nt c√≠mk√©zik, ami miatt a modell helytelen t√°rs√≠t√°sokat tanul.\
   **P√©lda**: Egy spam sz≈±r≈ë, amely manipul√°lt c√≠mk√©k miatt t√©vesen oszt√°lyozza a legitim e-maileket spamk√©nt.
2. **Jellemz≈ë m√©rgez√©s**: Egy t√°mad√≥ finoman m√≥dos√≠tja az edz√©si adatok jellemz≈ëit, hogy elfogults√°got vezessen be vagy f√©lrevezesse a modellt.\
   **P√©lda**: Jelent√©ktelen kulcsszavak hozz√°ad√°sa term√©kle√≠r√°sokhoz, hogy manipul√°lj√°k az aj√°nl√≥rendszereket.
3. **Adat injekci√≥**: Rosszindulat√∫ adatok bejuttat√°sa az edz√©si k√©szletbe, hogy befoly√°solj√°k a modell viselked√©s√©t.\
   **P√©lda**: Hamis felhaszn√°l√≥i v√©lem√©nyek bevezet√©se, hogy torz√≠ts√°k az √©rzelemelemz√©s eredm√©nyeit.
4. **H√°ts√≥ ajt√≥s t√°mad√°sok**: Egy t√°mad√≥ rejtett mint√°t (h√°ts√≥ ajt√≥t) helyez el az edz√©si adatokban. A modell megtanulja felismerni ezt a mint√°t, √©s rosszindulat√∫an viselkedik, amikor aktiv√°lj√°k.\
   **P√©lda**: Egy arcfelismer≈ë rendszer, amely h√°ts√≥ ajt√≥s k√©pekkel edzett, √©s egy adott szem√©lyt t√©vesen azonos√≠t.

A MITRE Corporation l√©trehozta az [ATLAS-t (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), amely egy tud√°sb√°zis az AI rendszerek elleni val√≥s t√°mad√°sok sor√°n alkalmazott taktik√°kr√≥l √©s technik√°kr√≥l.

> Az AI-alap√∫ rendszerekben egyre t√∂bb sebezhet≈ës√©g jelenik meg, mivel az AI be√©p√≠t√©se n√∂veli a megl√©v≈ë rendszerek t√°mad√°si fel√ºlet√©t a hagyom√°nyos kibert√°mad√°sokon t√∫l. Az ATLAS-t az√©rt fejlesztett√ºk ki, hogy felh√≠vjuk a figyelmet ezekre az egyedi √©s folyamatosan fejl≈ëd≈ë sebezhet≈ës√©gekre, mivel a glob√°lis k√∂z√∂ss√©g egyre ink√°bb be√©p√≠ti az AI-t k√ºl√∂nb√∂z≈ë rendszerekbe. Az ATLAS a MITRE ATT&CK¬Æ keretrendszer mint√°j√°ra k√©sz√ºlt, √©s taktik√°i, technik√°i, valamint elj√°r√°sai (TTP-k) kieg√©sz√≠tik az ATT&CK-ban tal√°lhat√≥kat.

Hasonl√≥an a MITRE ATT&CK¬Æ keretrendszerhez, amelyet sz√©les k√∂rben haszn√°lnak a hagyom√°nyos kiberbiztons√°gban fejlett fenyeget√©s-emul√°ci√≥s forgat√≥k√∂nyvek tervez√©s√©re, az ATLAS k√∂nnyen kereshet≈ë TTP-ket k√≠n√°l, amelyek seg√≠tenek jobban meg√©rteni √©s felk√©sz√ºlni a felt√∂rekv≈ë t√°mad√°sok elleni v√©dekez√©sre.

Ezenk√≠v√ºl az Open Web Application Security Project (OWASP) l√©trehozott egy "[Top 10 list√°t](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" a LLM-eket haszn√°l√≥ alkalmaz√°sokban tal√°lhat√≥ legkritikusabb sebezhet≈ës√©gekr≈ël. A lista kiemeli az olyan fenyeget√©sek kock√°zatait, mint az eml√≠tett adatm√©rgez√©s, valamint m√°sokat, p√©ld√°ul:

- **Prompt Injection**: egy technika, amelyben a t√°mad√≥k gondosan megfogalmazott bemenetekkel manipul√°lj√°k a Nagy Nyelvi Modelleket (LLM), hogy azok a sz√°nd√©kolt viselked√©sen k√≠v√ºl m≈±k√∂djenek.
- **Ell√°t√°si l√°nc sebezhet≈ës√©gek**: Az LLM-eket haszn√°l√≥ alkalmaz√°sok √∂sszetev≈ëi √©s szoftverei, p√©ld√°ul Python modulok vagy k√ºls≈ë adatb√°zisok, maguk is kompromitt√°l√≥dhatnak, ami v√°ratlan eredm√©nyeket, bevezetett elfogults√°gokat √©s ak√°r az alapvet≈ë infrastrukt√∫r√°ban l√©v≈ë sebezhet≈ës√©geket is okozhat.
- **T√∫lzott t√°maszkod√°s**: Az LLM-ek hib√°sak lehetnek, √©s hajlamosak ‚Äûhallucin√°lni‚Äù, pontatlan vagy nem biztons√°gos eredm√©nyeket adva. Sz√°mos dokument√°lt esetben az emberek az eredm√©nyeket k√©szp√©nznek vett√©k, ami nem sz√°nd√©kolt negat√≠v k√∂vetkezm√©nyekhez vezetett a val√≥ vil√°gban.

A Microsoft Cloud Advocate Rod Trent √≠rt egy ingyenes e-k√∂nyvet, [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst), amely m√©lyen belemer√ºl ezekbe √©s m√°s felt√∂rekv≈ë AI fenyeget√©sekbe, √©s √°tfog√≥ √∫tmutat√°st ny√∫jt arr√≥l, hogyan lehet a legjobban kezelni ezeket a helyzeteket.

## Biztons√°gi tesztel√©s AI rendszerek √©s LLM-ek sz√°m√°ra

A mesters√©ges intelligencia (AI) sz√°mos ter√ºletet √©s ipar√°gat √°talak√≠t, √∫j lehet≈ës√©geket √©s el≈ëny√∂ket k√≠n√°lva a t√°rsadalom sz√°m√°ra. Azonban az AI jelent≈ës kih√≠v√°sokat √©s kock√°zatokat is jelent, mint p√©ld√°ul az adatv√©delem, az elfogults√°g, a magyar√°zhat√≥s√°g hi√°nya √©s a potenci√°lis vissza√©l√©s. Ez√©rt elengedhetetlen, hogy az AI rendszerek biztons√°gosak √©s felel≈ëss√©gteljesek legyenek, azaz megfeleljenek az etikai √©s jogi norm√°knak, √©s megb√≠zhat√≥ak legyenek a felhaszn√°l√≥k √©s √©rintettek sz√°m√°ra.

A biztons√°gi tesztel√©s az AI rendszer vagy LLM biztons√°g√°nak √©rt√©kel√©s√©nek folyamata, amely sor√°n azonos√≠tj√°k √©s kihaszn√°lj√°k azok sebezhet≈ës√©geit. Ezt a fejleszt≈ëk, felhaszn√°l√≥k vagy harmadik f√©l √°ltal megb√≠zott auditorok v√©gezhetik, a tesztel√©s c√©lj√°t√≥l √©s terjedelm√©t≈ël f√ºgg≈ëen. Az AI rendszerek √©s LLM-ek leggyakoribb biztons√°gi tesztel√©si m√≥dszerei a k√∂vetkez≈ëk:

- **Adattiszt√≠t√°s**: Ez az √©rz√©keny vagy szem√©lyes inform√°ci√≥k elt√°vol√≠t√°s√°nak vagy anonimiz√°l√°s√°nak folyamata az AI rendszer vagy LLM edz√©si adataib√≥l vagy bemenet√©b≈ël. Az adattiszt√≠t√°s seg√≠thet megel≈ëzni az adatveszt√©st √©s a rosszindulat√∫ manipul√°ci√≥t az√°ltal, hogy cs√∂kkenti a bizalmas vagy szem√©lyes adatok kitetts√©g√©t.
- **Adverz√°rius tesztel√©s**: Ez az adverz√°rius p√©ld√°k gener√°l√°s√°nak √©s alkalmaz√°s√°nak folyamata az AI rendszer vagy LLM bemenet√©re vagy kimenet√©re, hogy √©rt√©kelj√©k annak robusztuss√°g√°t √©s ellen√°ll√≥k√©pess√©g√©t az adverz√°rius t√°mad√°sokkal szemben. Az adverz√°rius tesztel√©s seg√≠thet az AI rendszer vagy LLM sebezhet≈ës√©geinek √©s gyenges√©geinek azonos√≠t√°s√°ban √©s enyh√≠t√©s√©ben, amelyeket a t√°mad√≥k kihaszn√°lhatnak.
- **Modell ellen≈ërz√©s**: Ez az AI rendszer vagy LLM modellparam√©tereinek vagy architekt√∫r√°j√°nak helyess√©g√©nek √©s teljess√©g√©nek ellen≈ërz√©si folyamata. A modell ellen≈ërz√©s seg√≠thet a modell lop√°s√°nak √©szlel√©s√©ben √©s megel≈ëz√©s√©ben az√°ltal, hogy biztos√≠tja a modell v√©delm√©t √©s hiteles√≠t√©s√©t.
- **Kimenet ellen≈ërz√©s**: Ez az AI rendszer vagy LLM kimenet√©nek min≈ës√©g√©nek √©s megb√≠zhat√≥s√°g√°nak ellen≈ërz√©si folyamata. A kimenet ellen≈ërz√©s seg√≠thet a rosszindulat√∫ manipul√°ci√≥ √©szlel√©s√©ben √©s kijav√≠t√°s√°ban az√°ltal, hogy biztos√≠tja a kimenet k√∂vetkezetess√©g√©t √©s pontoss√°g√°t.

Az OpenAI, az AI rendszerek egyik vezet≈ëje, egy sor _biztons√°gi √©rt√©kel√©st_ √°ll√≠tott fel a red teaming h√°l√≥zati kezdem√©nyez√©s r√©szek√©nt, amelynek c√©lja az AI rendszerek kimenet√©nek tesztel√©se, hogy hozz√°j√°ruljon az AI biztons√°g√°hoz.

> Az √©rt√©kel√©sek egyszer≈± k√©rdezz-felelek tesztekt≈ël √∂sszetettebb szimul√°ci√≥kig terjedhetnek. Konkr√©t p√©ldak√©nt itt vannak az OpenAI √°ltal kidolgozott mintavizsg√°latok, amelyek az AI viselked√©s√©t t√∂bb szempontb√≥l √©rt√©kelik:

#### Meggy≈ëz√©s

- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): Mennyire j√≥l tud egy AI rendszer r√°venni egy m√°sik AI rendszert, hogy kimondjon egy titkos sz√≥t?
- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): Mennyire j√≥l tud egy AI rendszer meggy≈ëzni egy m√°sik AI rendszert, hogy p√©nzt adom√°nyozzon?
- [Ballot Proposal](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): Mennyire j√≥l tud egy AI rendszer befoly√°solni egy m√°sik AI rendszer t√°mogat√°s√°t egy politikai javaslat ir√°nt?

#### Steganogr√°fia (rejtett √ºzenetk√ºld√©s)

- [Steganography](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): Mennyire j√≥l tud egy AI rendszer titkos √ºzeneteket √°tadni an√©lk√ºl, hogy egy m√°sik AI rendszer √©szrevenn√©?
- [Text Compression](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): Mennyire j√≥l tud egy AI rendszer √ºzeneteket t√∂m√∂r√≠teni √©s visszafejteni, hogy lehet≈ëv√© tegye titkos √ºzenetek rejt√©s√©t?
- [Schelling Point](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): Mennyire j√≥l tud egy AI rendszer koordin√°lni egy m√°sik AI rendszerrel k√∂zvetlen kommunik√°ci√≥ n√©lk√ºl?

### AI Biztons√°g

Elengedhetetlen, hogy megv√©dj√ºk az AI rendszereket a rosszindulat√∫ t√°mad√°sokt√≥l, vissza√©l√©sekt≈ël vagy nem sz√°nd√©kolt k√∂vetkezm√©nyekt≈ël. Ez mag√°ban foglalja az AI rendszerek biztons√°g√°nak, megb√≠zhat√≥s√°g√°nak √©s hiteless√©g√©nek biztos√≠t√°s√°t, p√©ld√°ul:

- Az AI modellek edz√©s√©hez √©s futtat√°s√°hoz haszn√°lt adatok √©s algoritmusok v√©delme
- Az AI rendszerek jogosulatlan hozz√°f√©r√©s√©nek, manipul√°ci√≥j√°nak vagy szabot√°zs√°nak megel≈ëz√©se
- Az AI rendszerekben l√©v≈ë elfogults√°g, diszkrimin√°ci√≥ vagy etikai probl√©m√°k √©szlel√©se √©s enyh√≠t√©se
- Az AI d√∂nt√©sek √©s cselekv√©sek elsz√°moltathat√≥s√°g√°nak, √°tl√°that√≥s√°g√°nak √©s magyar√°zhat√≥s√°g√°nak biztos√≠t√°sa
- Az AI rendszerek c√©ljainak √©s √©rt√©keinek √∂sszehangol√°sa az emberek √©s a t√°rsadalom c√©ljaival √©s √©rt√©keivel

Az AI biztons√°g fontos az AI rendszerek √©s adatok integrit√°s√°nak, el√©rhet≈ës√©g√©nek √©s titkoss√°g√°nak biztos√≠t√°sa √©rdek√©ben. Az AI biztons√°g√°nak kih√≠v√°sai √©s lehet≈ës√©gei k√∂z√© tartozik:

- Lehet≈ës√©g: Az AI be√©p√≠t√©se a kiberbiztons√°gi strat√©gi√°kba, mivel kulcsszerepet j√°tszhat a fenyeget√©sek azonos√≠t√°s√°ban √©s a v√°laszid≈ëk jav√≠t√°s√°ban. Az AI seg√≠thet automatiz√°lni √©s kieg√©sz√≠teni a kibert√°mad√°sok, p√©ld√°ul adathal√°szat, rosszindulat√∫ programok vagy zsarol√≥programok √©szlel√©s√©t √©s enyh√≠t√©s√©t.
- Kih√≠v√°s: Az AI-t az ellenfelek is haszn√°lhatj√°k kifinomult t√°mad√°sok ind√≠t√°s√°ra, p√©ld√°ul hamis vagy f√©lrevezet≈ë tartalom gener√°l√°s√°ra
A val√≥s fenyeget√©sek szimul√°l√°sa ma m√°r standard gyakorlatnak sz√°m√≠t az ellen√°ll√≥k√©pes mesters√©ges intelligencia rendszerek √©p√≠t√©s√©ben, amely sor√°n hasonl√≥ eszk√∂z√∂ket, taktik√°kat √©s elj√°r√°sokat alkalmaznak a rendszerek kock√°zatainak azonos√≠t√°s√°ra √©s a v√©d≈ëk reakci√≥inak tesztel√©s√©re.

> Az AI red teaming gyakorlata kib≈ëv√ºlt, √©s m√°r nemcsak a biztons√°gi sebezhet≈ës√©gek felt√°r√°s√°t foglalja mag√°ban, hanem m√°s rendszerhib√°k vizsg√°lat√°t is, p√©ld√°ul potenci√°lisan k√°ros tartalmak gener√°l√°s√°t. Az AI rendszerek √∫j kock√°zatokkal j√°rnak, √©s a red teaming kulcsfontoss√°g√∫ ezeknek az √∫j kock√°zatoknak a meg√©rt√©s√©ben, mint p√©ld√°ul a prompt injection √©s a megalapozatlan tartalmak el≈ë√°ll√≠t√°sa. - [Microsoft AI Red Team building future of safer AI](https://www.microsoft.com/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-105485-koreyst)

[![√ötmutat√≥ √©s forr√°sok a red teaminghez](../../../translated_images/13-AI-red-team.642ed54689d7e8a4d83bdf0635768c4fd8aa41ea539d8e3ffe17514aec4b4824.hu.png)]()

Az al√°bbiakban bemutatjuk azokat a kulcsfontoss√°g√∫ felismer√©seket, amelyek form√°lt√°k a Microsoft AI Red Team programj√°t.

1. **Az AI Red Teaming kiterjesztett hat√≥k√∂re:**
   Az AI red teaming most m√°r mag√°ban foglalja mind a biztons√°gi, mind a Felel≈ës AI (RAI) eredm√©nyeket. Hagyom√°nyosan a red teaming a biztons√°gi aspektusokra √∂sszpontos√≠tott, a modellt vektork√©nt kezelve (pl. az alapmodell ellop√°sa). Az AI rendszerek azonban √∫j biztons√°gi sebezhet≈ës√©geket vezetnek be (pl. prompt injection, m√©rgez√©s), amelyek k√ºl√∂n√∂s figyelmet ig√©nyelnek. A biztons√°gon t√∫l az AI red teaming a m√©lt√°nyoss√°gi k√©rd√©seket (pl. sztereotipiz√°l√°s) √©s a k√°ros tartalmakat (pl. er≈ëszak dics≈ë√≠t√©se) is vizsg√°lja. Ezeknek a probl√©m√°knak a korai azonos√≠t√°sa lehet≈ëv√© teszi a v√©delmi beruh√°z√°sok priorit√°s√°nak meghat√°roz√°s√°t.
2. **Rosszindulat√∫ √©s j√≥indulat√∫ hib√°k:**
   Az AI red teaming a hib√°kat mind rosszindulat√∫, mind j√≥indulat√∫ szempontb√≥l vizsg√°lja. P√©ld√°ul, amikor a Bing √∫j verzi√≥j√°t tesztelj√ºk, nemcsak azt vizsg√°ljuk, hogyan tudj√°k rosszindulat√∫ t√°mad√≥k al√°√°sni a rendszert, hanem azt is, hogyan tal√°lkozhatnak h√©tk√∂znapi felhaszn√°l√≥k probl√©m√°s vagy k√°ros tartalommal. A hagyom√°nyos biztons√°gi red teaming f≈ëk√©nt rosszindulat√∫ szerepl≈ëkre √∂sszpontos√≠t, m√≠g az AI red teaming sz√©lesebb k√∂r≈± szem√©lyis√©geket √©s potenci√°lis hib√°kat vesz figyelembe.
3. **Az AI rendszerek dinamikus term√©szete:**
   Az AI alkalmaz√°sok folyamatosan fejl≈ëdnek. A nagy nyelvi modell alkalmaz√°sok eset√©ben a fejleszt≈ëk alkalmazkodnak a v√°ltoz√≥ k√∂vetelm√©nyekhez. A folyamatos red teaming biztos√≠tja az √°lland√≥ √©bers√©get √©s az alkalmazkod√°st az √∫jonnan felmer√ºl≈ë kock√°zatokhoz.

Az AI red teaming nem mindenre kiterjed≈ë megold√°s, √©s kieg√©sz√≠t≈ë mozg√°sk√©nt kell tekinteni m√°s kontrollok mellett, mint p√©ld√°ul a [szerepk√∂r-alap√∫ hozz√°f√©r√©s-vez√©rl√©s (RBAC)](https://learn.microsoft.com/azure/ai-services/openai/how-to/role-based-access-control?WT.mc_id=academic-105485-koreyst) √©s √°tfog√≥ adatkezel√©si megold√°sok. C√©lja, hogy kieg√©sz√≠tse egy olyan biztons√°gi strat√©gi√°t, amely a biztons√°gos √©s felel≈ës AI megold√°sok alkalmaz√°s√°ra √∂sszpontos√≠t, figyelembe v√©ve a mag√°n√©let √©s a biztons√°g szempontjait, mik√∂zben t√∂rekszik minimaliz√°lni az elfogults√°gokat, k√°ros tartalmakat √©s f√©lret√°j√©koztat√°st, amelyek al√°√°shatj√°k a felhaszn√°l√≥i bizalmat.

√çme n√©h√°ny tov√°bbi olvasnival√≥, amely seg√≠thet jobban meg√©rteni, hogyan seg√≠thet a red teaming az AI rendszerek kock√°zatainak azonos√≠t√°s√°ban √©s enyh√≠t√©s√©ben:

- [Red teaming tervez√©se nagy nyelvi modellek (LLM-ek) √©s alkalmaz√°saik sz√°m√°ra](https://learn.microsoft.com/azure/ai-services/openai/concepts/red-teaming?WT.mc_id=academic-105485-koreyst)
- [Mi az OpenAI Red Teaming Network?](https://openai.com/blog/red-teaming-network?WT.mc_id=academic-105485-koreyst)
- [AI Red Teaming - Kulcsfontoss√°g√∫ gyakorlat a biztons√°gosabb √©s felel≈ësebb AI megold√°sok √©p√≠t√©s√©hez](https://rodtrent.substack.com/p/ai-red-teaming?WT.mc_id=academic-105485-koreyst)
- MITRE [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), egy tud√°sb√°zis a mesters√©ges intelligencia rendszerek elleni val√≥s t√°mad√°sok sor√°n alkalmazott taktik√°kr√≥l √©s technik√°kr√≥l.

## Tud√°sellen≈ërz√©s

Mi lehet egy j√≥ megk√∂zel√≠t√©s az adatintegrit√°s fenntart√°s√°ra √©s a vissza√©l√©sek megel≈ëz√©s√©re?

1. Er≈ës szerepk√∂r-alap√∫ kontrollok alkalmaz√°sa az adathozz√°f√©r√©s √©s adatkezel√©s ter√©n  
1. Az adatok c√≠mk√©z√©s√©nek megval√≥s√≠t√°sa √©s audit√°l√°sa az adatok f√©lre√©rtelmez√©s√©nek vagy vissza√©l√©s√©nek megel≈ëz√©se √©rdek√©ben  
1. Biztos√≠tsa, hogy AI infrastrukt√∫r√°ja t√°mogatja a tartalomsz≈±r√©st  

A:1, B√°r mindh√°rom nagyszer≈± aj√°nl√°s, azzal, hogy biztos√≠tja a megfelel≈ë adathozz√°f√©r√©si jogosults√°gok kioszt√°s√°t a felhaszn√°l√≥knak, nagyban hozz√°j√°rulhat az LLM-ek √°ltal haszn√°lt adatok manipul√°ci√≥j√°nak √©s f√©lre√©rtelmez√©s√©nek megel≈ëz√©s√©hez.

## üöÄ Kih√≠v√°s

Olvasson t√∂bbet arr√≥l, hogyan [korm√°nyozhatja √©s v√©dheti az √©rz√©keny inform√°ci√≥kat](https://learn.microsoft.com/training/paths/purview-protect-govern-ai/?WT.mc_id=academic-105485-koreyst) az AI kor√°ban.

## Nagyszer≈± munka, folytassa a tanul√°st

A lecke befejez√©se ut√°n tekintse meg [Generat√≠v AI tanul√°si gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejlessze generat√≠v AI ismereteit!

L√©pjen tov√°bb a 14. leck√©re, ahol [a Generat√≠v AI alkalmaz√°s √©letciklus√°t](../14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst) fogjuk megvizsg√°lni!

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.