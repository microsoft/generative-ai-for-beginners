<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:37:10+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "hu"
}
-->
# K√ºl√∂nb√∂z≈ë LLM-ek felfedez√©se √©s √∂sszehasonl√≠t√°sa

[![K√ºl√∂nb√∂z≈ë LLM-ek felfedez√©se √©s √∂sszehasonl√≠t√°sa](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.hu.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Kattints a fenti k√©pre a lecke vide√≥j√°nak megtekint√©s√©hez_

Az el≈ëz≈ë leck√©ben l√°ttuk, hogyan alak√≠tja √°t a Generat√≠v AI a technol√≥giai k√∂rnyezetet, hogyan m≈±k√∂dnek a Nagy Nyelvi Modellek (LLM-ek), √©s hogyan alkalmazhatja egy v√°llalkoz√°s ‚Äì p√©ld√°ul a mi startupunk ‚Äì ezeket az eseteihez, hogy n√∂vekedjen! Ebben a fejezetben k√ºl√∂nb√∂z≈ë t√≠pus√∫ nagy nyelvi modelleket hasonl√≠tunk √∂ssze, hogy meg√©rts√ºk az el≈ënyeiket √©s h√°tr√°nyaikat.

A k√∂vetkez≈ë l√©p√©s a startupunk √∫tj√°n az LLM-ek jelenlegi k√≠n√°lat√°nak felt√©rk√©pez√©se, √©s annak meg√©rt√©se, hogy melyek alkalmasak a mi felhaszn√°l√°si eset√ºnkh√∂z.

## Bevezet√©s

Ebben a leck√©ben a k√∂vetkez≈ëkr≈ël lesz sz√≥:

- Az LLM-ek k√ºl√∂nb√∂z≈ë t√≠pusai a jelenlegi piacon.
- K√ºl√∂nb√∂z≈ë modellek tesztel√©se, iter√°l√°sa √©s √∂sszehasonl√≠t√°sa az Azure k√∂rnyezet√©ben a saj√°t felhaszn√°l√°si esethez.
- Hogyan lehet egy LLM-et telep√≠teni.

## Tanul√°si c√©lok

A lecke elv√©gz√©se ut√°n k√©pes leszel:

- Kiv√°lasztani a megfelel≈ë modellt a saj√°t felhaszn√°l√°si esetedhez.
- Meg√©rteni, hogyan kell tesztelni, iter√°lni √©s jav√≠tani a modell teljes√≠tm√©ny√©t.
- Tudni, hogyan telep√≠tenek modelleket a v√°llalkoz√°sok.

## K√ºl√∂nb√∂z≈ë LLM t√≠pusok meg√©rt√©se

Az LLM-ek t√∂bbf√©lek√©ppen kategoriz√°lhat√≥k az architekt√∫r√°juk, a tan√≠t√≥ adatok √©s a felhaszn√°l√°si eset alapj√°n. Ezeknek a k√ºl√∂nbs√©geknek az ismerete seg√≠t a startupunknak a megfelel≈ë modell kiv√°laszt√°s√°ban, valamint abban, hogy hogyan tesztelj√ºk, iter√°ljuk √©s jav√≠tsuk a teljes√≠tm√©nyt.

Sz√°mos k√ºl√∂nb√∂z≈ë LLM modell l√©tezik, a v√°laszt√°s att√≥l f√ºgg, mire szeretn√©d haszn√°lni ≈ëket, milyen adataid vannak, mennyit vagy hajland√≥ fizetni, √©s m√©g sok m√°s t√©nyez≈ët≈ël.

Att√≥l f√ºgg≈ëen, hogy sz√∂veg, hang, vide√≥, k√©p gener√°l√°s√°ra vagy m√°sra szeretn√©d haszn√°lni a modelleket, m√°s-m√°s t√≠pus√∫ modellt v√°laszthatsz.

- **Hang- √©s besz√©dfelismer√©s**. Ehhez a c√©lra a Whisper t√≠pus√∫ modellek kiv√°l√≥ak, mivel √°ltal√°nos c√©l√∫ak √©s besz√©dfelismer√©sre vannak optimaliz√°lva. Sokf√©le hanganyagon tan√≠tott√°k ≈ëket, √©s t√∂bbnyelv≈± besz√©dfelismer√©sre k√©pesek. Tudj meg t√∂bbet a [Whisper t√≠pus√∫ modellekr≈ël itt](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **K√©palkot√°s**. K√©palkot√°sra a DALL-E √©s a Midjourney a legismertebb v√°laszt√°sok. A DALL-E az Azure OpenAI szolg√°ltat√°s r√©sze. [Olvass t√∂bbet a DALL-E-r≈ël itt](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst), valamint a tananyag 9. fejezet√©ben.

- **Sz√∂veg gener√°l√°s**. A legt√∂bb modell sz√∂veg gener√°l√°sra van tan√≠tva, √©s sz√©les v√°laszt√©k √°ll rendelkez√©sre a GPT-3.5-t≈ël a GPT-4-ig. Ezek k√ºl√∂nb√∂z≈ë √°rkateg√≥ri√°kban √©rhet≈ëk el, a GPT-4 a legdr√°g√°bb. √ârdemes megn√©zni az [Azure OpenAI playgroundot](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), hogy felm√©rd, mely modellek felelnek meg legink√°bb a k√©pess√©geidnek √©s k√∂lts√©gvet√©sednek.

- **T√∂bbmodalit√°s**. Ha t√∂bbf√©le adatot szeretn√©l kezelni bemenetk√©nt √©s kimenetk√©nt is, √©rdemes megn√©zni olyan modelleket, mint a [gpt-4 turbo visionnal vagy gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ‚Äì ezek az OpenAI leg√∫jabb modelljei ‚Äì, amelyek k√©pesek a term√©szetes nyelv feldolgoz√°s√°t vizu√°lis meg√©rt√©ssel kombin√°lni, lehet≈ëv√© t√©ve a t√∂bbmodalit√°s√∫ fel√ºleteken val√≥ interakci√≥t.

Egy modell kiv√°laszt√°sa alapvet≈ë k√©pess√©geket ad, de ez nem mindig el√©g. Gyakran vannak c√©ges specifikus adatok, amelyeket valahogy be kell t√°pl√°lni az LLM-be. T√∂bbf√©le megk√∂zel√≠t√©s l√©tezik erre, err≈ël a k√∂vetkez≈ë szakaszokban lesz sz√≥.

### Foundation Model-ek √©s LLM-ek

A Foundation Model kifejez√©st [Stanford kutat√≥k alkott√°k meg](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst), √©s olyan AI modellt jel√∂l, amely megfelel bizonyos krit√©riumoknak, p√©ld√°ul:

- **√ñnfel√ºgyelt vagy √∂n√°ll√≥ tanul√°ssal tan√≠tj√°k**, azaz c√≠mk√©zetlen, t√∂bbmodalit√°s√∫ adatokon tanulnak, emberi annot√°ci√≥ vagy c√≠mk√©z√©s n√©lk√ºl.
- **Nagyon nagy modellek**, m√©ly neur√°lis h√°l√≥zatokon alapulnak, amelyeket milli√°rdnyi param√©teren tan√≠tottak.
- **√Åltal√°ban m√°s modellek ‚Äûalapjak√©nt‚Äù szolg√°lnak**, vagyis kiindul√≥pontk√©nt haszn√°lhat√≥k tov√°bbi modellek √©p√≠t√©s√©hez, finomhangol√°ssal.

![Foundation Model-ek √©s LLM-ek](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.hu.png)

K√©p forr√°sa: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

A k√ºl√∂nbs√©g tov√°bbi tiszt√°z√°s√°hoz vegy√ºk p√©ldak√©nt a ChatGPT-t. A ChatGPT els≈ë verzi√≥j√°nak megalkot√°s√°hoz a GPT-3.5 modellt haszn√°lt√°k alapmodellk√©nt. Ez azt jelenti, hogy az OpenAI chat-specifikus adatokkal finomhangolta a GPT-3.5-√∂t, hogy az j√≥l teljes√≠tsen besz√©lget≈ës helyzetekben, p√©ld√°ul chatbotokn√°l.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.hu.png)

K√©p forr√°sa: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Ny√≠lt forr√°sk√≥d√∫ √©s z√°rt modellek

Az LLM-ek m√°sik kategoriz√°l√°si m√≥dja, hogy ny√≠lt forr√°sk√≥d√∫ak vagy z√°rtak-e.

A ny√≠lt forr√°sk√≥d√∫ modellek nyilv√°nosan el√©rhet≈ëk, b√°rki haszn√°lhatja ≈ëket. Ezeket gyakran a fejleszt≈ë c√©g vagy a kutat√≥k√∂z√∂ss√©g teszi el√©rhet≈ëv√©. Ezek a modellek megtekinthet≈ëk, m√≥dos√≠that√≥k √©s testreszabhat√≥k k√ºl√∂nb√∂z≈ë felhaszn√°l√°si esetekhez. Ugyanakkor nem mindig optimaliz√°ltak √©les haszn√°latra, √©s nem biztos, hogy olyan teljes√≠tm√©nyt ny√∫jtanak, mint a z√°rt modellek. A ny√≠lt forr√°sk√≥d√∫ modellek finansz√≠roz√°sa korl√°tozott lehet, √©s el≈ëfordulhat, hogy nem tartj√°k ≈ëket hossz√∫ t√°von karban, vagy nem friss√≠tik ≈ëket a leg√∫jabb kutat√°sokkal. N√©pszer≈± ny√≠lt forr√°sk√≥d√∫ modellek p√©ld√°ul az [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) √©s a [LLaMA](https://llama.meta.com).

A z√°rt modellek egy c√©g tulajdon√°ban vannak, √©s nem nyilv√°nosak. Ezeket gyakran √©les haszn√°latra optimaliz√°lj√°k. Nem enged√©lyezett a megtekint√©s√ºk, m√≥dos√≠t√°suk vagy testreszab√°suk k√ºl√∂nb√∂z≈ë esetekhez. Nem mindig ingyenesek, el≈ëfizet√©s vagy fizet√©s sz√ºks√©ges a haszn√°latukhoz. A felhaszn√°l√≥k nem rendelkeznek kontrollal a modell tan√≠t√°s√°hoz haszn√°lt adatok felett, ez√©rt a modell tulajdonos√°ra kell b√≠zni az adatv√©delem √©s a felel≈ës AI haszn√°lat biztos√≠t√°s√°t. N√©pszer≈± z√°rt modellek p√©ld√°ul az [OpenAI modellek](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), a [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) vagy a [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding, k√©palkot√°s, sz√∂veg- √©s k√≥dgener√°l√°s

Az LLM-eket a kimenet√ºk alapj√°n is csoportos√≠thatjuk.

Az embedding modellek olyan modellek, amelyek sz√∂veget alak√≠tanak √°t numerikus form√°ba, az √∫gynevezett embeddingbe, ami a bemeneti sz√∂veg numerikus reprezent√°ci√≥ja. Az embeddingek megk√∂nny√≠tik a g√©pek sz√°m√°ra a szavak vagy mondatok k√∂z√∂tti kapcsolatok meg√©rt√©s√©t, √©s m√°s modellek bemenetek√©nt haszn√°lhat√≥k, p√©ld√°ul oszt√°lyoz√≥ vagy klaszterez≈ë modellekhez, amelyek jobban teljes√≠tenek numerikus adatokon. Az embedding modelleket gyakran haszn√°lj√°k transfer learninghez, amikor egy modellt egy helyettes√≠t≈ë feladatra tan√≠tanak, amelyhez sok adat √°ll rendelkez√©sre, majd a modell s√∫lyait (embeddingeket) √∫jrafelhaszn√°lj√°k m√°s, k√©s≈ëbbi feladatokhoz. Ennek a kateg√≥ri√°nak p√©ld√°ja az [OpenAI embeddingek](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.hu.png)

A k√©palkot√≥ modellek k√©peket gener√°lnak. Ezeket gyakran haszn√°lj√°k k√©pszerkeszt√©sre, k√©pszint√©zisre √©s k√©p√°talak√≠t√°sra. Ezeket a modelleket nagy k√©padatb√°zisokon, p√©ld√°ul a [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst) tan√≠tott√°k, √©s √∫j k√©pek gener√°l√°s√°ra vagy megl√©v≈ë k√©pek szerkeszt√©s√©re haszn√°lhat√≥k, p√©ld√°ul inpainting, szuperfelbont√°s vagy sz√≠nez√©s technik√°kkal. P√©ld√°k: [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) √©s a [Stable Diffusion modellek](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![K√©palkot√°s](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.hu.png)

A sz√∂veg- √©s k√≥dgener√°l√≥ modellek sz√∂veget vagy k√≥dot hoznak l√©tre. Ezeket gyakran haszn√°lj√°k sz√∂veg√∂sszefoglal√°sra, ford√≠t√°sra √©s k√©rd√©s-v√°lasz feladatokra. A sz√∂veg gener√°l√≥ modelleket nagy sz√∂veges adatb√°zisokon, p√©ld√°ul a [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst) tan√≠tott√°k, √©s √∫j sz√∂vegek gener√°l√°s√°ra vagy k√©rd√©sek megv√°laszol√°s√°ra haszn√°lhat√≥k. A k√≥dgener√°l√≥ modelleket, mint p√©ld√°ul a [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), nagy k√≥dadatb√°zisokon, p√©ld√°ul a GitHubon tan√≠tott√°k, √©s √∫j k√≥d gener√°l√°s√°ra vagy megl√©v≈ë k√≥d hib√°inak jav√≠t√°s√°ra haszn√°lhat√≥k.

![Sz√∂veg- √©s k√≥dgener√°l√°s](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.hu.png)

### Encoder-Decoder √©s csak Decoder architekt√∫r√°k

Az LLM-ek k√ºl√∂nb√∂z≈ë architekt√∫r√°ir√≥l egy anal√≥gi√°val besz√©lj√ºnk.

K√©pzeld el, hogy a vezet≈ëd feladatul adta, hogy √≠rj egy kv√≠zt a di√°koknak. K√©t koll√©g√°d van; az egyik a tartalom l√©trehoz√°s√°√©rt felel, a m√°sik a tartalom √°tn√©z√©s√©√©rt.

A tartalomk√©sz√≠t≈ë olyan, mint egy csak Decoder modell: megn√©zi a t√©m√°t √©s azt, amit m√°r √≠rt√°l, majd ennek alapj√°n √≠r egy leck√©t. Nagyon j√≥k abban, hogy √©rdekes √©s informat√≠v tartalmat √≠rjanak, de nem annyira j√≥k a t√©ma √©s a tanul√°si c√©lok meg√©rt√©s√©ben. P√©ld√°k a csak Decoder modellekre a GPT csal√°d tagjai, p√©ld√°ul a GPT-3.

Az √°tn√©z≈ë olyan, mint egy csak Encoder modell: megn√©zi a meg√≠rt leck√©t √©s a v√°laszokat, √©szleli a k√∂zt√ºk l√©v≈ë kapcsolatot, meg√©rti a kontextust, de nem j√≥ tartalom gener√°l√°s√°ban. P√©lda az csak Encoder modellre a BERT.

K√©pzeld el, hogy lenne valaki, aki egyszerre tudna l√©trehozni √©s √°tn√©zni is egy kv√≠zt ‚Äì ez az Encoder-Decoder modell. P√©ld√°k erre a BART √©s a T5.

### Szolg√°ltat√°s √©s modell k√∂z√∂tti k√ºl√∂nbs√©g

Most besz√©lj√ºnk a szolg√°ltat√°s √©s a modell k√∂z√∂tti k√ºl√∂nbs√©gr≈ël. A szolg√°ltat√°s egy term√©k, amelyet egy felh≈ëszolg√°ltat√≥ k√≠n√°l, √©s gyakran modellek, adatok √©s egy√©b √∂sszetev≈ëk kombin√°ci√≥ja. A modell a szolg√°ltat√°s magja, gyakran egy alapmodell, p√©ld√°ul egy LLM.

A szolg√°ltat√°sokat gyakran √©les haszn√°latra optimaliz√°lj√°k, √©s √°ltal√°ban k√∂nnyebben haszn√°lhat√≥k, p√©ld√°ul grafikus fel√ºleten kereszt√ºl. Ugyanakkor nem mindig ingyenesek, el≈ëfizet√©s vagy fizet√©s sz√ºks√©ges a haszn√°latukhoz, cser√©be a szolg√°ltat√°s tulajdonos√°nak eszk√∂zeit √©s er≈ëforr√°sait haszn√°lhatod, optimaliz√°lva a k√∂lts√©geket √©s k√∂nnyen sk√°l√°zva. P√©lda egy szolg√°ltat√°sra az [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), amely fogyaszt√°s alap√∫ d√≠jszab√°st k√≠n√°l, vagyis a felhaszn√°l√≥k ar√°nyosan fizetnek a szolg√°ltat√°s haszn√°lat√°√©rt. Az Azure OpenAI Service v√°llalati szint≈± biztons√°got √©s felel≈ës AI keretrendszert is biztos√≠t a modellek k√©pess√©gei mellett.

A modellek csak a neur√°lis h√°l√≥zatok, param√©terekkel, s√∫lyokkal √©s egyebekkel. A c√©gek helyben is futtathatj√°k ≈ëket, de ehhez eszk√∂z√∂ket kell v√°s√°rolniuk, infrastrukt√∫r√°t √©p√≠teni√ºk a sk√°l√°z√°shoz, √©s licencet kell venni√ºk, vagy ny√≠lt forr√°sk√≥d√∫ modellt haszn√°lniuk. P√©ld√°ul a LLaMA modell el√©rhet≈ë haszn√°latra, de futtat√°s√°hoz sz√°m√≠t√°si kapacit√°s sz√ºks√©ges.

## Hogyan tesztelj√ºnk √©s iter√°ljunk k√ºl√∂nb√∂z≈ë modellekkel az Azure-on a teljes√≠tm√©ny meg√©rt√©s√©hez

Miut√°n a csapat felt√©rk√©pezte az LLM-ek jelenlegi k√≠n√°lat√°t √©s kiv√°lasztott n√©h√°ny √≠g√©retes modellt a saj√°t eseteikhez, a k√∂vetkez≈ë l√©p√©s, hogy tesztelj√©k ≈ëket a saj√°t adataikon √©s munkaterhel√©s√ºk√∂n. Ez egy iterat√≠v folyamat, amely k√≠s√©rletez√©ssel √©s m√©r√©si eredm√©nyekkel zajlik.
A legt√∂bb, az el≈ëz≈ë bekezd√©sekben eml√≠tett modell (OpenAI modellek, ny√≠lt forr√°sk√≥d√∫ modellek, mint a Llama2, √©s a Hugging Face transzformerek) el√©rhet≈ë a [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) alatt az [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst) platformon.

Az [Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) egy felh≈ëalap√∫ platform, amely fejleszt≈ëk sz√°m√°ra k√©sz√ºlt generat√≠v AI alkalmaz√°sok √©p√≠t√©s√©re √©s a teljes fejleszt√©si √©letciklus kezel√©s√©re ‚Äì a k√≠s√©rletez√©st≈ël az √©rt√©kel√©sig ‚Äì, az √∂sszes Azure AI szolg√°ltat√°s egyetlen k√∂zpontba integr√°l√°s√°val, k√©nyelmes grafikus fel√ºlettel. Az Azure AI Studio Model Catalog lehet≈ëv√© teszi a felhaszn√°l√≥ sz√°m√°ra, hogy:

- Megtal√°lja az √©rdekl≈ëd√©s√©nek megfelel≈ë Foundation Modelt a katal√≥gusban ‚Äì ak√°r saj√°t fejleszt√©s≈±, ak√°r ny√≠lt forr√°sk√≥d√∫, sz≈±rve feladat, licenc vagy n√©v szerint. A jobb kereshet≈ës√©g √©rdek√©ben a modelleket gy≈±jtem√©nyekbe szervezt√©k, mint p√©ld√°ul az Azure OpenAI gy≈±jtem√©ny, Hugging Face gy≈±jtem√©ny √©s m√°sok.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.hu.png)

- √Åttekintheti a modellk√°rty√°t, amely tartalmazza a r√©szletes le√≠r√°st a tervezett felhaszn√°l√°sr√≥l √©s a tan√≠t√≥ adathalmazr√≥l, k√≥dr√©szleteket √©s √©rt√©kel√©si eredm√©nyeket az bels≈ë √©rt√©kel√©si k√∂nyvt√°rb√≥l.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.hu.png)

- √ñsszehasonl√≠thatja az ipar√°gban el√©rhet≈ë modellek √©s adathalmazok benchmark eredm√©nyeit, hogy felm√©rje, melyik felel meg legink√°bb az √ºzleti forgat√≥k√∂nyvnek, a [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panel seg√≠ts√©g√©vel.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.hu.png)

- Finomhangolhatja a modellt egyedi tan√≠t√≥ adatokon, hogy jav√≠tsa a modell teljes√≠tm√©ny√©t egy adott feladatra, kihaszn√°lva az Azure AI Studio k√≠s√©rletez√©si √©s nyomonk√∂vet√©si k√©pess√©geit.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.hu.png)

- Telep√≠theti az eredeti el≈ëre betan√≠tott modellt vagy a finomhangolt verzi√≥t t√°voli val√≥s idej≈± lek√©rdez√©sre ‚Äì menedzselt sz√°m√≠t√°si k√∂rnyezetbe ‚Äì vagy szerver n√©lk√ºli API v√©gpontra ‚Äì [fizess a haszn√°lat alapj√°n](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) ‚Äì, hogy az alkalmaz√°sok k√©pesek legyenek haszn√°lni azt.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.hu.png)


> [!NOTE]
> Nem minden modell √©rhet≈ë el jelenleg finomhangol√°sra √©s/vagy fizess a haszn√°lat alapj√°n t√∂rt√©n≈ë telep√≠t√©sre. A modellk√°rty√°n ellen≈ërizze a modell k√©pess√©geit √©s korl√°tait.

## LLM eredm√©nyek jav√≠t√°sa

Startup csapatunkkal k√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-eket √©s egy felh≈ëplatformot (Azure Machine Learning) vizsg√°ltunk, amely lehet≈ëv√© teszi sz√°munkra, hogy √∂sszehasonl√≠tsuk a modelleket, tesztadatokon √©rt√©kelj√ºk ≈ëket, jav√≠tsuk a teljes√≠tm√©nyt, √©s telep√≠ts√ºk ≈ëket lek√©rdez√©si v√©gpontokra.

De mikor √©rdemes ink√°bb finomhangolni egy modellt, mint el≈ëre betan√≠tottat haszn√°lni? Vannak m√°s m√≥dszerek is a modell teljes√≠tm√©ny√©nek jav√≠t√°s√°ra adott feladatokon?

Sz√°mos megk√∂zel√≠t√©s l√©tezik, amelyeket egy v√°llalkoz√°s alkalmazhat, hogy megkapja a k√≠v√°nt eredm√©nyeket egy LLM-t≈ël. K√ºl√∂nb√∂z≈ë t√≠pus√∫ modelleket v√°laszthatunk, k√ºl√∂nb√∂z≈ë m√©rt√©k≈± tan√≠t√°ssal, amikor egy LLM-et √©les k√∂rnyezetbe telep√≠t√ºnk, elt√©r≈ë komplexit√°ssal, k√∂lts√©ggel √©s min≈ës√©ggel. √çme n√©h√°ny megk√∂zel√≠t√©s:

- **Prompt tervez√©s kontextussal**. Az √∂tlet az, hogy elegend≈ë kontextust adjunk a promptban, hogy biztosan megkapjuk a sz√ºks√©ges v√°laszokat.

- **Retrieval Augmented Generation, RAG**. Az adatok p√©ld√°ul adatb√°zisban vagy webes v√©gponton lehetnek t√°rolva, √©s hogy ezek az adatok vagy azok egy r√©sze be√©p√ºlj√∂n a promptba, lek√©rhetj√ºk a relev√°ns adatokat, √©s beilleszthetj√ºk a felhaszn√°l√≥ promptj√°ba.

- **Finomhangolt modell**. Itt a modellt tov√°bb tan√≠tottuk a saj√°t adatainkon, ami pontosabb√° √©s jobban reag√°l√≥v√° tette a modellt az ig√©nyeinkre, de ez k√∂lts√©ges lehet.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.hu.png)

K√©p forr√°sa: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt tervez√©s kontextussal

Az el≈ëre betan√≠tott LLM-ek nagyon j√≥l m≈±k√∂dnek √°ltal√°nos term√©szetes nyelvi feladatokon, m√©g akkor is, ha csak egy r√∂vid prompttal h√≠vjuk meg ≈ëket, p√©ld√°ul egy befejezend≈ë mondattal vagy k√©rd√©ssel ‚Äì ezt h√≠vjuk ‚Äûzero-shot‚Äù tanul√°snak.

Azonban min√©l jobban k√©pes a felhaszn√°l√≥ megfogalmazni a k√©r√©s√©t r√©szletesen, p√©ld√°kkal ‚Äì vagyis a Kontextussal ‚Äì, ann√°l pontosabb √©s a felhaszn√°l√≥ elv√°r√°saihoz k√∂zelebb √°ll√≥ lesz a v√°lasz. Ebben az esetben ‚Äûone-shot‚Äù tanul√°sr√≥l besz√©l√ºnk, ha a prompt csak egy p√©ld√°t tartalmaz, √©s ‚Äûfew-shot‚Äù tanul√°sr√≥l, ha t√∂bb p√©ld√°t is tartalmaz.
A prompt tervez√©s kontextussal a legk√∂lts√©ghat√©konyabb megk√∂zel√≠t√©s a kezd√©shez.

### Retrieval Augmented Generation (RAG)

Az LLM-ek korl√°tja, hogy csak azokat az adatokat haszn√°lhatj√°k fel v√°lasz gener√°l√°s√°ra, amelyek a tan√≠t√°suk sor√°n rendelkez√©sre √°lltak. Ez azt jelenti, hogy nem tudnak semmit a tan√≠t√°suk ut√°n t√∂rt√©nt esem√©nyekr≈ël, √©s nem f√©rnek hozz√° nem nyilv√°nos inform√°ci√≥khoz (p√©ld√°ul v√°llalati adatokhoz).
Ezt a probl√©m√°t oldja meg a RAG, amely egy technika, amely k√ºls≈ë adatokat illeszt be a promptba dokumentumdarabok form√°j√°ban, figyelembe v√©ve a prompt hossz√°nak korl√°tait. Ezt t√°mogatj√°k a vektor adatb√°zis eszk√∂z√∂k (p√©ld√°ul az [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), amelyek el≈ëre meghat√°rozott adatforr√°sokb√≥l kinyerik a relev√°ns darabokat, √©s hozz√°adj√°k azokat a prompt Kontextus√°hoz.

Ez a technika k√ºl√∂n√∂sen hasznos, ha egy v√°llalkoz√°snak nincs elegend≈ë adata, ideje vagy er≈ëforr√°sa egy LLM finomhangol√°s√°ra, de m√©gis szeretn√© jav√≠tani a teljes√≠tm√©nyt egy adott feladaton, √©s cs√∂kkenteni a t√©ves inform√°ci√≥k vagy k√°ros tartalom kock√°zat√°t.

### Finomhangolt modell

A finomhangol√°s egy olyan folyamat, amely a transfer learninget haszn√°lja arra, hogy a modellt egy adott feladathoz vagy probl√©m√°hoz ‚Äûigaz√≠tsa‚Äù. A few-shot tanul√°st√≥l √©s a RAG-t√≥l elt√©r≈ëen ez egy √∫j modellt eredm√©nyez, friss√≠tett s√∫lyokkal √©s torz√≠t√°sokkal. Ehhez egy tan√≠t√≥ p√©ldak√©szlet sz√ºks√©ges, amely egy bemenetb≈ël (a promptb√≥l) √©s a hozz√° tartoz√≥ kimenetb≈ël (a befejez√©sb≈ël) √°ll.
Ez a megk√∂zel√≠t√©s el≈ëny√∂s, ha:

- **Finomhangolt modelleket haszn√°lnak**. Egy v√°llalkoz√°s ink√°bb finomhangolt, kev√©sb√© er≈ëforr√°s-ig√©nyes modelleket (p√©ld√°ul embedding modelleket) szeretne haszn√°lni a nagy teljes√≠tm√©ny≈± modellek helyett, ami k√∂lts√©ghat√©konyabb √©s gyorsabb megold√°st eredm√©nyez.

- **Fontos a k√©sleltet√©s**. Egy adott felhaszn√°l√°si esetben a k√©sleltet√©s kritikus, ez√©rt nem lehet nagyon hossz√∫ promptokat haszn√°lni, vagy a tanuland√≥ p√©ld√°k sz√°ma nem f√©r bele a prompt hosszkorl√°tj√°ba.

- **Friss adatokkal dolgoznak**. Egy v√°llalkoz√°snak sok magas min≈ës√©g≈± adata √©s val√≥s c√≠mk√©je van, valamint megvannak az er≈ëforr√°sai ezeknek az adatoknak a folyamatos friss√≠t√©s√©re.

### Betan√≠tott modell

Egy LLM-et a null√°r√≥l betan√≠tani k√©ts√©gtelen√ºl a legnehezebb √©s leg√∂sszetettebb megk√∂zel√≠t√©s, amely hatalmas mennyis√©g≈± adatot, k√©pzett szakembereket √©s megfelel≈ë sz√°m√≠t√°si kapacit√°st ig√©nyel. Ezt a lehet≈ës√©get csak akkor √©rdemes megfontolni, ha egy v√°llalkoz√°snak speci√°lis, adott szakter√ºletre f√≥kusz√°l√≥ esete van, √©s nagy mennyis√©g≈±, szakter√ºlet-specifikus adata √°ll rendelkez√©sre.

## Tud√°sellen≈ërz√©s

Mi lehet egy j√≥ megk√∂zel√≠t√©s az LLM befejez√©si eredm√©nyek jav√≠t√°s√°ra?

1. Prompt tervez√©s kontextussal  
1. RAG  
1. Finomhangolt modell

V√°lasz: 3, ha van id≈ëd, er≈ëforr√°sod √©s magas min≈ës√©g≈± adatod, a finomhangol√°s a jobb v√°laszt√°s a naprak√©szs√©g fenntart√°s√°hoz. Azonban, ha gyors jav√≠t√°sra van sz√ºks√©g √©s kev√©s az id≈ë, √©rdemes el≈ësz√∂r a RAG-et megfontolni.

## üöÄ Kih√≠v√°s

Olvass ut√°na, hogyan haszn√°lhatod a [RAG-et](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) a v√°llalkoz√°sodban.

## Sz√©p munka, folytasd a tanul√°st!

A lecke elv√©gz√©se ut√°n n√©zd meg a [Generative AI Learning gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejleszd generat√≠v AI ismereteidet!

L√©pj tov√°bb a 3. leck√©be, ahol megn√©zz√ºk, hogyan lehet [felel≈ëss√©gteljesen √©p√≠teni generat√≠v AI-val](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Jogi nyilatkozat**:  
Ez a dokumentum az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel k√©sz√ºlt. B√°r a pontoss√°gra t√∂reksz√ºnk, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n professzion√°lis emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.