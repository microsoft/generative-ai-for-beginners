<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T21:27:32+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "hu"
}
-->
# K√ºl√∂nb√∂z≈ë LLM-ek felfedez√©se √©s √∂sszehasonl√≠t√°sa

[![K√ºl√∂nb√∂z≈ë LLM-ek felfedez√©se √©s √∂sszehasonl√≠t√°sa](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.hu.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Kattints a fenti k√©pre, hogy megn√©zd a leck√©r≈ël sz√≥l√≥ vide√≥t_

Az el≈ëz≈ë leck√©ben l√°thattuk, hogyan v√°ltoztatja meg a generat√≠v mesters√©ges intelligencia a technol√≥giai k√∂rnyezetet, hogyan m≈±k√∂dnek a nagy nyelvi modellek (LLM-ek), √©s hogyan alkalmazhatja egy v√°llalkoz√°s - p√©ld√°ul a mi startupunk - ezeket a saj√°t eseteiben, hogy n√∂vekedjen! Ebben a fejezetben k√ºl√∂nb√∂z≈ë t√≠pus√∫ nagy nyelvi modelleket (LLM-eket) fogunk √∂sszehasonl√≠tani, hogy meg√©rts√ºk azok el≈ënyeit √©s h√°tr√°nyait.

Startupunk k√∂vetkez≈ë l√©p√©se az LLM-ek jelenlegi k√∂rnyezet√©nek felt√©rk√©pez√©se √©s annak meg√©rt√©se, hogy melyek alkalmasak a mi felhaszn√°l√°si eset√ºnkre.

## Bevezet√©s

Ez a lecke az al√°bbiakat fogja t√°rgyalni:

- Az LLM-ek k√ºl√∂nb√∂z≈ë t√≠pusai a jelenlegi k√∂rnyezetben.
- K√ºl√∂nb√∂z≈ë modellek tesztel√©se, iter√°l√°sa √©s √∂sszehasonl√≠t√°sa az Azure-ban t√∂rt√©n≈ë felhaszn√°l√°sra.
- Hogyan telep√≠ts√ºnk egy LLM-et.

## Tanul√°si c√©lok

A lecke elv√©gz√©se ut√°n k√©pes leszel:

- Kiv√°lasztani a megfelel≈ë modellt a saj√°t felhaszn√°l√°si esethez.
- Meg√©rteni, hogyan kell tesztelni, iter√°lni √©s jav√≠tani a modell teljes√≠tm√©ny√©t.
- Tudni, hogyan telep√≠tik a v√°llalkoz√°sok a modelleket.

## K√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-ek meg√©rt√©se

Az LLM-eket t√∂bbf√©lek√©ppen lehet kategoriz√°lni az architekt√∫r√°juk, a tan√≠t√°si adataik √©s a felhaszn√°l√°si eset√ºk alapj√°n. Ezeknek a k√ºl√∂nbs√©geknek a meg√©rt√©se seg√≠t a startupunknak kiv√°lasztani a megfelel≈ë modellt az adott helyzethez, valamint meg√©rteni, hogyan kell tesztelni, iter√°lni √©s jav√≠tani a teljes√≠tm√©nyt.

Sz√°mos k√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-modell l√©tezik, √©s a v√°laszt√°sod att√≥l f√ºgg, hogy mire szeretn√©d haszn√°lni ≈ëket, milyen adataid vannak, mennyit vagy hajland√≥ fizetni, √©s m√©g sok m√°s t√©nyez≈ët≈ël.

Att√≥l f√ºgg≈ëen, hogy a modelleket sz√∂veg-, hang-, vide√≥-, k√©pgener√°l√°sra stb. szeretn√©d haszn√°lni, elt√©r≈ë t√≠pus√∫ modellt v√°laszthatsz.

- **Hang- √©s besz√©dfelismer√©s**. Erre a c√©lra a Whisper t√≠pus√∫ modellek kiv√°l√≥ v√°laszt√°snak bizonyulnak, mivel √°ltal√°nos c√©l√∫ak √©s besz√©dfelismer√©sre ir√°nyulnak. Sokf√©le hanganyagon tan√≠tott√°k ≈ëket, √©s k√©pesek t√∂bbnyelv≈± besz√©dfelismer√©sre. Tov√°bbi inform√°ci√≥ a [Whisper t√≠pus√∫ modellekr≈ël itt](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **K√©pgener√°l√°s**. A k√©pgener√°l√°shoz a DALL-E √©s a Midjourney k√©t nagyon ismert v√°laszt√°s. A DALL-E-t az Azure OpenAI k√≠n√°lja. [Tov√°bbi inform√°ci√≥ a DALL-E-r≈ël itt](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst), valamint a tananyag 9. fejezet√©ben.

- **Sz√∂veggener√°l√°s**. A legt√∂bb modellt sz√∂veggener√°l√°sra tan√≠tott√°k, √©s sz√°mos v√°laszt√°si lehet≈ës√©g √°ll rendelkez√©sre, p√©ld√°ul GPT-3.5-t≈ël GPT-4-ig. Ezek k√ºl√∂nb√∂z≈ë k√∂lts√©gekkel j√°rnak, a GPT-4 a legdr√°g√°bb. √ârdemes megn√©zni az [Azure OpenAI j√°tsz√≥teret](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), hogy √©rt√©kelni tudjuk, mely modellek felelnek meg legjobban az ig√©nyeinknek k√©pess√©gek √©s k√∂lts√©gek szempontj√°b√≥l.

- **Multimodalit√°s**. Ha t√∂bbf√©le adatot szeretn√©l kezelni bemenetk√©nt √©s kimenetk√©nt, √©rdemes lehet olyan modelleket megvizsg√°lni, mint p√©ld√°ul a [gpt-4 turbo vizu√°lis funkci√≥val vagy gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - az OpenAI modellek leg√∫jabb kiad√°sai -, amelyek k√©pesek kombin√°lni a term√©szetes nyelvi feldolgoz√°st a vizu√°lis meg√©rt√©ssel, lehet≈ëv√© t√©ve a multimod√°lis interf√©szeken kereszt√ºli interakci√≥kat.

Egy modell kiv√°laszt√°sa alapvet≈ë k√©pess√©geket biztos√≠t, amelyek azonban nem mindig elegend≈ëek. Gyakran el≈ëfordul, hogy a v√°llalatnak specifikus adatai vannak, amelyeket valahogyan k√∂z√∂lni kell az LLM-mel. Erre t√∂bbf√©le megk√∂zel√≠t√©s l√©tezik, amelyeket a k√∂vetkez≈ë szakaszokban t√°rgyalunk.

### Alapmodellek √©s LLM-ek

Az Alapmodell kifejez√©st [Stanford kutat√≥k alkott√°k meg](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst), √©s olyan AI modellk√©nt defini√°lt√°k, amely megfelel bizonyos krit√©riumoknak, p√©ld√°ul:

- **Nem fel√ºgyelt tanul√°ssal vagy √∂nfel√ºgyelt tanul√°ssal tan√≠tj√°k ≈ëket**, ami azt jelenti, hogy c√≠mk√©zetlen multimod√°lis adatokon tan√≠tj√°k ≈ëket, √©s nem ig√©nyelnek emberi annot√°ci√≥t vagy adatc√≠mk√©z√©st a tan√≠t√°si folyamathoz.
- **Nagyon nagy modellek**, amelyek nagyon m√©ly neur√°lis h√°l√≥zatokon alapulnak, √©s milli√°rdnyi param√©terrel vannak tan√≠tva.
- **√Åltal√°ban m√°s modellek ‚Äûalapjak√©nt‚Äù szolg√°lnak**, ami azt jelenti, hogy kiindul√≥pontk√©nt haszn√°lhat√≥k m√°s modellek √©p√≠t√©s√©hez, amit finomhangol√°ssal lehet el√©rni.

![Alapmodellek √©s LLM-ek](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.hu.png)

K√©p forr√°sa: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

A k√ºl√∂nbs√©g tov√°bbi tiszt√°z√°sa √©rdek√©ben vegy√ºk p√©ld√°nak a ChatGPT-t. A ChatGPT els≈ë verzi√≥j√°nak l√©trehoz√°s√°hoz egy GPT-3.5 nev≈± modell szolg√°lt alapmodellk√©nt. Ez azt jelenti, hogy az OpenAI n√©h√°ny chat-specifikus adatot haszn√°lt fel egy finomhangolt GPT-3.5 verzi√≥ l√©trehoz√°s√°hoz, amelyet kifejezetten arra specializ√°ltak, hogy j√≥l teljes√≠tsen besz√©lget√©si helyzetekben, p√©ld√°ul chatbotok eset√©ben.

![Alapmodell](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.hu.png)

K√©p forr√°sa: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Ny√≠lt forr√°sk√≥d√∫ √©s z√°rt modellek

Az LLM-eket aszerint is lehet kategoriz√°lni, hogy ny√≠lt forr√°sk√≥d√∫ak vagy z√°rtak.

A ny√≠lt forr√°sk√≥d√∫ modellek olyan modellek, amelyeket a nyilv√°noss√°g sz√°m√°ra el√©rhet≈ëv√© tesznek, √©s b√°rki haszn√°lhatja ≈ëket. Gyakran az ≈ëket l√©trehoz√≥ v√°llalat vagy a kutat√≥i k√∂z√∂ss√©g teszi el√©rhet≈ëv√© ≈ëket. Ezeket a modelleket lehet ellen≈ërizni, m√≥dos√≠tani √©s testre szabni az LLM-ek k√ºl√∂nb√∂z≈ë felhaszn√°l√°si eseteihez. Azonban nem mindig optimaliz√°ltak a termel√©si haszn√°latra, √©s nem biztos, hogy olyan teljes√≠tm√©nyesek, mint a z√°rt modellek. R√°ad√°sul a ny√≠lt forr√°sk√≥d√∫ modellek finansz√≠roz√°sa korl√°tozott lehet, √©s nem biztos, hogy hossz√∫ t√°von karbantartj√°k ≈ëket, vagy friss√≠tik a leg√∫jabb kutat√°sokkal. N√©pszer≈± ny√≠lt forr√°sk√≥d√∫ modellek p√©ld√°ul [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) √©s [LLaMA](https://llama.meta.com).

A z√°rt modellek olyan modellek, amelyeket egy v√°llalat birtokol, √©s nem tesznek nyilv√°nosan el√©rhet≈ëv√©. Ezeket a modelleket gyakran optimaliz√°lj√°k termel√©si haszn√°latra. Azonban nem lehet ≈ëket ellen≈ërizni, m√≥dos√≠tani vagy testre szabni k√ºl√∂nb√∂z≈ë felhaszn√°l√°si esetekhez. R√°ad√°sul nem mindig ingyenesek, √©s el≈ëfizet√©st vagy fizet√©st ig√©nyelhetnek a haszn√°lathoz. Tov√°bb√° a felhaszn√°l√≥k nem rendelkeznek kontrollal a modell tan√≠t√°s√°hoz haszn√°lt adatok felett, ami azt jelenti, hogy a modell tulajdonos√°nak kell megb√≠zhat√≥an biztos√≠tania az adatv√©delem √©s az AI felel≈ës haszn√°lat√°nak betart√°s√°t. N√©pszer≈± z√°rt modellek p√©ld√°ul [OpenAI modellek](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) vagy [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Be√°gyaz√°s, k√©pgener√°l√°s, sz√∂veg- √©s k√≥dgener√°l√°s

Az LLM-eket az √°ltaluk gener√°lt kimenet alapj√°n is kategoriz√°lhatjuk.

A be√°gyaz√°sok olyan modellek, amelyek k√©pesek a sz√∂veget numerikus form√°v√°, √∫gynevezett be√°gyaz√°ss√° alak√≠tani, amely az input sz√∂veg numerikus reprezent√°ci√≥ja. A be√°gyaz√°sok megk√∂nny√≠tik a g√©pek sz√°m√°ra a szavak vagy mondatok k√∂z√∂tti kapcsolatok meg√©rt√©s√©t, √©s m√°s modellek, p√©ld√°ul oszt√°lyoz√°si vagy klaszterez√©si modellek bemenetek√©nt is felhaszn√°lhat√≥k, amelyek jobban teljes√≠tenek numerikus adatokkal. A be√°gyaz√°si modelleket gyakran haszn√°lj√°k transzfer tanul√°sra, ahol egy modellt egy helyettes√≠t≈ë feladatra √©p√≠tenek, amelyhez b≈ës√©ges adat √°ll rendelkez√©sre, majd a modell s√∫lyait (be√°gyaz√°sokat) √∫jra felhaszn√°lj√°k m√°s downstream feladatokhoz. P√©lda erre a kateg√≥ri√°ra: [OpenAI be√°gyaz√°sok](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Be√°gyaz√°s](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.hu.png)

A k√©pgener√°l√°si modellek olyan modellek, amelyek k√©peket gener√°lnak. Ezeket a modelleket gyakran haszn√°lj√°k k√©p szerkeszt√©s√©re, k√©p szint√©zis√©re √©s k√©p √°talak√≠t√°s√°ra. A k√©pgener√°l√°si modelleket gyakran nagy k√©padatb√°zisokon tan√≠tj√°k, p√©ld√°ul [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), √©s √∫j k√©pek gener√°l√°s√°ra vagy megl√©v≈ë k√©pek szerkeszt√©s√©re haszn√°lhat√≥k, p√©ld√°ul inpainting, szuperfelbont√°s √©s sz√≠nez√©si technik√°k seg√≠ts√©g√©vel. P√©ld√°k: [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) √©s [Stable Diffusion modellek](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![K√©pgener√°l√°s](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.hu.png)

A sz√∂veg- √©s k√≥dgener√°l√°si modellek olyan modellek, amelyek sz√∂veget vagy k√≥dot gener√°lnak. Ezeket a modelleket gyakran haszn√°lj√°k sz√∂veg√∂sszefoglal√°sra, ford√≠t√°sra √©s k√©rd√©sek megv√°laszol√°s√°ra. A sz√∂veggener√°l√°si modelleket gyakran nagy sz√∂vegadatb√°zisokon tan√≠tj√°k, p√©ld√°ul [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), √©s √∫j sz√∂vegek gener√°l√°s√°ra vagy k√©rd√©sek megv√°laszol√°s√°ra haszn√°lhat√≥k. A k√≥dgener√°l√°si modelleket, mint p√©ld√°ul [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), gyakran nagy k√≥dadatb√°zisokon tan√≠tj√°k, p√©ld√°ul GitHubon, √©s √∫j k√≥d gener√°l√°s√°ra vagy megl√©v≈ë k√≥d hib√°inak jav√≠t√°s√°ra haszn√°lhat√≥k.

![Sz√∂veg- √©s k√≥dgener√°l√°s](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.hu.png)

### K√≥dol√≥-dek√≥dol√≥ vs. Csak dek√≥dol√≥

Az LLM-ek k√ºl√∂nb√∂z≈ë architekt√∫r√°inak meg√©rt√©s√©hez haszn√°ljunk egy hasonlatot.

K√©pzeld el, hogy a vezet≈ëd adott neked egy feladatot, hogy √≠rj egy kv√≠zt a di√°kok sz√°m√°ra. K√©t koll√©g√°d van; az egyik a tartalom l√©trehoz√°s√°√©rt, a m√°sik pedig annak ellen≈ërz√©s√©√©rt felel.

A tartalomk√©sz√≠t≈ë olyan, mint egy csak dek√≥dol√≥ modell, amely k√©pes megn√©zni a t√©m√°t √©s azt, amit m√°r le√≠rt√°l, majd ennek alapj√°n meg√≠rni egy tananyagot. Nagyon j√≥ az √©rdekes √©s informat√≠v tartalom √≠r√°s√°ban, de nem t√∫l j√≥ a t√©ma √©s a tanul√°si c√©lok meg√©rt√©s√©ben. N√©h√°ny p√©lda a dek√≥dol√≥ modellekre: a GPT csal√°d modelljei, p√©ld√°ul a GPT-3.

Az ellen≈ërz≈ë olyan, mint egy csak k√≥dol√≥ modell, amely megn√©zi az elk√©sz√ºlt tananyagot √©s a v√°laszokat, √©szreveszi a kapcsolatokat √©s meg√©rti a kontextust, de nem j√≥ a tartalom gener√°l√°s√°ban. P√©lda a csak k√≥dol√≥ modellre: BERT.

K√©pzeld el, hogy lehetne valaki, aki egyszerre tudna kv√≠zt k√©sz√≠teni √©s ellen≈ërizni, ez egy k√≥dol√≥-dek√≥dol√≥ modell. N√©h√°ny p√©lda: BART √©s T5.

### Szolg√°ltat√°s vs. Modell

Most besz√©lj√ºnk a k√ºl√∂nbs√©gr≈ël egy szolg√°ltat√°s √©s egy modell k√∂z√∂tt. A szolg√°ltat√°s egy term√©k, amelyet egy felh≈ëszolg√°ltat√≥ k√≠n√°l, √©s gyakran modellek, adatok √©s m√°s √∂sszetev≈ëk kombin√°ci√≥ja. A modell egy szolg√°ltat√°s alapvet≈ë √∂sszetev≈ëje, √©s gyakran egy alapmodell, p√©ld√°ul egy LLM.

A szolg√°ltat√°sok gyakran optimaliz√°ltak termel√©si haszn√°latra, √©s gyakran k√∂nnyebben haszn√°lhat√≥k, p√©ld√°ul grafikus felhaszn√°l√≥i fel√ºleten kereszt√ºl. Azonban a szolg√°ltat√°sok nem mindig ingyenesek, √©s el≈ëfizet√©st vagy fizet√©st ig√©nyelhetnek a haszn√°lathoz, cser√©be a szolg√°ltat√°s tulajdonos√°nak berendez√©sei √©s er≈ëforr√°sai haszn√°lat√°√©rt, a k√∂lts√©gek optimaliz√°l√°s√°√©rt √©s az egyszer≈± sk√°l√°z√°s√©rt. P√©lda egy szolg√°ltat√°sra: [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), amely pay-as-you-go d√≠jcsomagot k√≠n√°l, ami azt jelenti, hogy a felhaszn√°l√≥kat ar√°nyosan terhelik a szolg√°ltat√°s haszn√°lat√°nak m√©rt√©k√©vel. Az Azure OpenAI Service emellett v√°llalati szint≈± biztons√°got √©s felel≈ës AI keretrendszert k√≠n√°l a modellek k√©pess√©gei mellett.

A modellek csak a neur√°lis h√°l√≥zatot jelentik, a param√©terekkel, s√∫lyokkal √©s m√°sokkal. Lehet≈ëv√© teszik a v√°llalatok sz√°m√°ra, hogy helyben futtass√°k ≈ëket, azonban ehhez berendez√©seket kell v√°s√°rolni, strukt√∫r√°t kell √©p√≠teni a sk√°l√°z√°shoz, √©s licencet kell v√°s√°rolni vagy ny√≠lt forr√°sk√≥d√∫ modellt kell haszn√°lni. Egy modell, mint p√©ld√°ul LLaMA, el√©rhet≈ë a haszn√°latra, de sz√°m√≠t√°si kapacit√°s sz√ºks√©ges a
A legt√∂bb modell, amelyet az el≈ëz≈ë bekezd√©sekben eml√≠tett√ºnk (OpenAI modellek, ny√≠lt forr√°sk√≥d√∫ modellek, mint p√©ld√°ul a Llama2, √©s Hugging Face transformerek), el√©rhet≈ë a [Modellek katal√≥gus√°ban](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) az [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst) platformon.

Az [Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) egy felh≈ëalap√∫ platform, amelyet fejleszt≈ëk sz√°m√°ra terveztek generat√≠v AI alkalmaz√°sok l√©trehoz√°s√°ra √©s a teljes fejleszt√©si √©letciklus kezel√©s√©re - a k√≠s√©rletez√©st≈ël az √©rt√©kel√©sig -, az√°ltal, hogy az √∂sszes Azure AI szolg√°ltat√°st egyetlen k√∂zpontba integr√°lja, egy praktikus grafikus fel√ºlettel. Az Azure AI Studio Modellek katal√≥gusa lehet≈ëv√© teszi a felhaszn√°l√≥k sz√°m√°ra, hogy:

- Megtal√°lj√°k az √©rdekl≈ëd√©s√ºknek megfelel≈ë alapmodellt a katal√≥gusban - ak√°r saj√°t fejleszt√©s≈±, ak√°r ny√≠lt forr√°sk√≥d√∫ -, feladat, licenc vagy n√©v alapj√°n sz≈±rve. A kereshet≈ës√©g jav√≠t√°sa √©rdek√©ben a modellek gy≈±jtem√©nyekbe vannak rendezve, mint p√©ld√°ul az Azure OpenAI gy≈±jtem√©ny, Hugging Face gy≈±jtem√©ny √©s m√°sok.

![Modellek katal√≥gusa](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.hu.png)

- √Åttekints√©k a modellk√°rty√°t, amely r√©szletes le√≠r√°st tartalmaz a tervezett felhaszn√°l√°sr√≥l √©s a k√©pz√©si adatokkal kapcsolatos inform√°ci√≥kr√≥l, k√≥dp√©ld√°kat √©s √©rt√©kel√©si eredm√©nyeket az Azure bels≈ë √©rt√©kel√©si k√∂nyvt√°r√°ban.

![Modellk√°rtya](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.hu.png)

- √ñsszehasonl√≠ts√°k az ipar√°gban el√©rhet≈ë modellek √©s adathalmazok benchmarkjait, hogy felm√©rj√©k, melyik felel meg legjobban az √ºzleti ig√©nyeknek, a [Modellek benchmarkjai](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panelen kereszt√ºl.

![Modellek benchmarkjai](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.hu.png)

- Finomhangolj√°k a modellt egyedi k√©pz√©si adatokkal, hogy jav√≠ts√°k a modell teljes√≠tm√©ny√©t egy adott munkaterhel√©sben, kihaszn√°lva az Azure AI Studio k√≠s√©rletez√©si √©s nyomonk√∂vet√©si k√©pess√©geit.

![Modell finomhangol√°sa](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.hu.png)

- Telep√≠ts√©k az eredeti el≈ëre betan√≠tott modellt vagy a finomhangolt verzi√≥t t√°voli val√≥s idej≈± k√∂vetkeztet√©sre - kezelt sz√°m√≠t√°si k√∂rnyezetre - vagy szerver n√©lk√ºli API v√©gpontra - [fizet√©s haszn√°lat alapj√°n](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) -, hogy lehet≈ëv√© tegy√©k az alkalmaz√°sok sz√°m√°ra a modell haszn√°lat√°t.

![Modell telep√≠t√©se](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.hu.png)

> [!NOTE]
> Nem minden modell √©rhet≈ë el jelenleg finomhangol√°sra √©s/vagy fizet√©s haszn√°lat alapj√°n t√∂rt√©n≈ë telep√≠t√©sre a katal√≥gusban. Ellen≈ërizze a modellk√°rty√°t a modell k√©pess√©geir≈ël √©s korl√°tair√≥l sz√≥l√≥ r√©szletek√©rt.

## LLM eredm√©nyek jav√≠t√°sa

Startup csapatunkkal k√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-eket √©s egy felh≈ëalap√∫ platformot (Azure Machine Learning) vizsg√°ltunk meg, amely lehet≈ëv√© teszi sz√°munkra, hogy √∂sszehasonl√≠tsuk a k√ºl√∂nb√∂z≈ë modelleket, tesztadatokon √©rt√©kelj√ºk ≈ëket, jav√≠tsuk a teljes√≠tm√©nyt √©s telep√≠ts√ºk ≈ëket k√∂vetkeztet√©si v√©gpontokra.

De mikor √©rdemes finomhangolni egy modellt az el≈ëre betan√≠tott helyett? Vannak m√°s megk√∂zel√≠t√©sek is, amelyek jav√≠thatj√°k a modell teljes√≠tm√©ny√©t egy adott munkaterhel√©sben?

Sz√°mos megk√∂zel√≠t√©s l√©tezik, amelyet egy v√°llalkoz√°s alkalmazhat, hogy el√©rje a k√≠v√°nt eredm√©nyeket egy LLM-t≈ël. K√ºl√∂nb√∂z≈ë t√≠pus√∫ modelleket v√°laszthat, amelyek elt√©r≈ë m√©rt√©k≈± k√©pz√©st kaptak, amikor egy LLM-et telep√≠t a gy√°rt√°sba, k√ºl√∂nb√∂z≈ë szint≈± komplexit√°ssal, k√∂lts√©ggel √©s min≈ës√©ggel. √çme n√©h√°ny megk√∂zel√≠t√©s:

- **Prompt tervez√©s kontextussal**. Az √∂tlet az, hogy elegend≈ë kontextust biztos√≠tsunk a promptban, hogy biztos√≠tsuk a sz√ºks√©ges v√°laszokat.

- **Retrieval Augmented Generation, RAG**. Az adatok p√©ld√°ul egy adatb√°zisban vagy webes v√©gponton l√©tezhetnek, √©s annak √©rdek√©ben, hogy ezek az adatok vagy azok egy r√©sze beker√ºlj√∂n a promptba, a relev√°ns adatokat lek√©rhetj√ºk, √©s a felhaszn√°l√≥ promptj√°nak r√©sz√©v√© tehetj√ºk.

- **Finomhangolt modell**. Itt a modellt tov√°bb k√©pezt√©k saj√°t adatokon, ami pontosabb√° √©s az ig√©nyekre √©rz√©kenyebb√© tette, b√°r k√∂lts√©ges lehet.

![LLM-ek telep√≠t√©se](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.hu.png)

K√©p forr√°sa: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt tervez√©s kontextussal

Az el≈ëre betan√≠tott LLM-ek nagyon j√≥l m≈±k√∂dnek √°ltal√°nos term√©szetes nyelvi feladatokban, m√©g akkor is, ha csak egy r√∂vid promptot kapnak, p√©ld√°ul egy befejezend≈ë mondatot vagy egy k√©rd√©st ‚Äì az √∫gynevezett ‚Äûzero-shot‚Äù tanul√°s.

Azonban min√©l r√©szletesebben tudja a felhaszn√°l√≥ megfogalmazni a k√©rd√©s√©t, egy r√©szletes k√©r√©ssel √©s p√©ld√°kkal ‚Äì a kontextussal ‚Äì, ann√°l pontosabb √©s k√∂zelebb √°ll a v√°lasz a felhaszn√°l√≥ elv√°r√°saihoz. Ebben az esetben ‚Äûone-shot‚Äù tanul√°sr√≥l besz√©l√ºnk, ha a prompt csak egy p√©ld√°t tartalmaz, √©s ‚Äûfew-shot‚Äù tanul√°sr√≥l, ha t√∂bb p√©ld√°t tartalmaz.
A prompt tervez√©s kontextussal a legk√∂lts√©ghat√©konyabb megk√∂zel√≠t√©s a kezd√©shez.

### Retrieval Augmented Generation (RAG)

Az LLM-ek korl√°toz√°sa, hogy csak azokat az adatokat tudj√°k haszn√°lni, amelyeket a k√©pz√©s√ºk sor√°n haszn√°ltak fel v√°lasz gener√°l√°s√°hoz. Ez azt jelenti, hogy nem tudnak semmit a k√©pz√©si folyamatuk ut√°n t√∂rt√©nt esem√©nyekr≈ël, √©s nem f√©rnek hozz√° nem nyilv√°nos inform√°ci√≥khoz (p√©ld√°ul v√°llalati adatokhoz).
Ez lek√ºzdhet≈ë a RAG seg√≠ts√©g√©vel, egy olyan technik√°val, amely k√ºls≈ë adatokat ad hozz√° a prompthoz dokumentumdarabok form√°j√°ban, figyelembe v√©ve a prompt hossz√°nak korl√°tait. Ezt t√°mogatj√°k a vektoralap√∫ adatb√°zis eszk√∂z√∂k (p√©ld√°ul [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), amelyek hasznos darabokat keresnek el≈ëre meghat√°rozott adatforr√°sokb√≥l, √©s hozz√°adj√°k ≈ëket a prompt kontextus√°hoz.

Ez a technika nagyon hasznos, ha egy v√°llalkoz√°snak nincs elegend≈ë adata, ideje vagy er≈ëforr√°sa egy LLM finomhangol√°s√°hoz, de m√©gis szeretn√© jav√≠tani a teljes√≠tm√©nyt egy adott munkaterhel√©sben, √©s cs√∂kkenteni a t√©ves inform√°ci√≥k, azaz a val√≥s√°g elferd√≠t√©s√©nek vagy k√°ros tartalom kock√°zat√°t.

### Finomhangolt modell

A finomhangol√°s egy olyan folyamat, amely a transzfer tanul√°st haszn√°lja fel arra, hogy a modellt egy adott feladathoz vagy probl√©m√°hoz ‚Äûadapt√°lja‚Äù. A few-shot tanul√°st√≥l √©s a RAG-t√≥l elt√©r≈ëen ez egy √∫j modell l√©trehoz√°s√°t eredm√©nyezi, friss√≠tett s√∫lyokkal √©s torz√≠t√°sokkal. Ehhez egy k√©pz√©si p√©ld√°kb√≥l √°ll√≥ k√©szlet sz√ºks√©ges, amely egyetlen bemenetet (a promptot) √©s a hozz√° tartoz√≥ kimenetet (a befejez√©st) tartalmazza.
Ez lenne az el≈ënyben r√©szes√≠tett megk√∂zel√≠t√©s, ha:

- **Finomhangolt modellek haszn√°lata**. Egy v√°llalkoz√°s ink√°bb kev√©sb√© teljes√≠tm√©nyorient√°lt finomhangolt modelleket (p√©ld√°ul be√°gyaz√°si modelleket) haszn√°lna, mint nagy teljes√≠tm√©ny≈± modelleket, ami k√∂lts√©ghat√©konyabb √©s gyorsabb megold√°st eredm√©nyez.

- **K√©sleltet√©s figyelembev√©tele**. A k√©sleltet√©s fontos egy adott felhaszn√°l√°si esetben, √≠gy nem lehets√©ges nagyon hossz√∫ promptokat haszn√°lni, vagy a p√©ld√°k sz√°ma, amelyeket a modellnek meg kell tanulnia, nem f√©r bele a prompt hossz√°nak korl√°tj√°ba.

- **Naprak√©szs√©g fenntart√°sa**. Egy v√°llalkoz√°snak sok kiv√°l√≥ min≈ës√©g≈± adata √©s val√≥s c√≠mk√©je van, valamint megvannak az er≈ëforr√°sai, hogy ezeket az adatokat id≈ëvel naprak√©szen tartsa.

### K√©pzett modell

Egy LLM null√°r√≥l t√∂rt√©n≈ë k√©pz√©se k√©ts√©gtelen√ºl a legnehezebb √©s leg√∂sszetettebb megk√∂zel√≠t√©s, amely hatalmas mennyis√©g≈± adatot, k√©pzett er≈ëforr√°sokat √©s megfelel≈ë sz√°m√≠t√°si kapacit√°st ig√©nyel. Ezt az opci√≥t csak akkor √©rdemes fontol√≥ra venni, ha egy v√°llalkoz√°snak van egy speci√°lis ter√ºletre vonatkoz√≥ felhaszn√°l√°si esete √©s nagy mennyis√©g≈±, ter√ºlet-specifikus adata.

## Tud√°sellen≈ërz√©s

Mi lehet egy j√≥ megk√∂zel√≠t√©s az LLM befejez√©si eredm√©nyek jav√≠t√°s√°ra?

1. Prompt tervez√©s kontextussal
1. RAG
1. Finomhangolt modell

A: 3, ha van el√©g id≈ë, er≈ëforr√°s √©s kiv√°l√≥ min≈ës√©g≈± adatok, a finomhangol√°s a jobb opci√≥ a naprak√©szs√©g fenntart√°s√°hoz. Azonban, ha az id≈ë sz≈±k√∂s, √©rdemes el≈ësz√∂r a RAG-ot fontol√≥ra venni.

## üöÄ Kih√≠v√°s

Olvasson t√∂bbet arr√≥l, hogyan haszn√°lhatja a [RAG-ot](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) v√°llalkoz√°sa sz√°m√°ra.

## Nagyszer≈± munka, folytassa a tanul√°st

A lecke befejez√©se ut√°n tekintse meg [Generat√≠v AI tanul√°si gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejlessze generat√≠v AI ismereteit!

L√©pjen tov√°bb a 3. leck√©re, ahol megvizsg√°ljuk, hogyan lehet [felel≈ëss√©gteljesen √©p√≠teni generat√≠v AI-val](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.