<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:18:24+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "hu"
}
-->
# Felfedez√©s √©s √∂sszehasonl√≠t√°s k√ºl√∂nb√∂z≈ë LLM-ekkel

[![Felfedez√©s √©s √∂sszehasonl√≠t√°s k√ºl√∂nb√∂z≈ë LLM-ekkel](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.hu.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Kattintson a fenti k√©pre, hogy megn√©zze a leck√©r≈ël k√©sz√ºlt vide√≥t_

Az el≈ëz≈ë leck√©ben l√°ttuk, hogyan v√°ltoztatja meg a generat√≠v AI a technol√≥giai k√∂rnyezetet, hogyan m≈±k√∂dnek a nagy nyelvi modellek (LLM-ek), √©s hogyan alkalmazhatja egy v√°llalkoz√°s - p√©ld√°ul a startupunk - azokat a saj√°t eseteikben √©s n√∂vekedhet! Ebben a fejezetben k√ºl√∂nb√∂z≈ë t√≠pus√∫ nagy nyelvi modelleket (LLM-eket) hasonl√≠tunk √∂ssze, hogy meg√©rts√ºk azok el≈ënyeit √©s h√°tr√°nyait.

Startupunk k√∂vetkez≈ë l√©p√©se az LLM-ek jelenlegi k√∂rnyezet√©nek felt√©rk√©pez√©se √©s annak meg√©rt√©se, hogy melyek alkalmasak a mi felhaszn√°l√°si eset√ºnkre.

## Bevezet√©s

Ez a lecke kiterjed:

- K√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-ekre a jelenlegi k√∂rnyezetben.
- Modellek tesztel√©s√©re, iter√°l√°s√°ra √©s √∂sszehasonl√≠t√°s√°ra az Azure-ban.
- Hogyan telep√≠ts√ºnk egy LLM-et.

## Tanul√°si c√©lok

A lecke befejez√©se ut√°n k√©pes leszel:

- Kiv√°lasztani a megfelel≈ë modellt a felhaszn√°l√°si esetedhez.
- Meg√©rteni, hogyan tesztelheted, iter√°lhatod √©s jav√≠thatod a modelled teljes√≠tm√©ny√©t.
- Tudni, hogyan telep√≠tenek modelleket a v√°llalkoz√°sok.

## K√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-ek meg√©rt√©se

Az LLM-eket t√∂bbf√©lek√©ppen kategoriz√°lhatjuk az architekt√∫r√°juk, a k√©pz√©si adataik √©s a felhaszn√°l√°si eset√ºk alapj√°n. Ezeknek a k√ºl√∂nbs√©geknek a meg√©rt√©se seg√≠t startupunknak kiv√°lasztani a megfelel≈ë modellt az adott helyzethez, √©s meg√©rteni, hogyan tesztelhetj√ºk, iter√°lhatjuk √©s jav√≠thatjuk a teljes√≠tm√©nyt.

Sokf√©le LLM modell l√©tezik, a modell kiv√°laszt√°sa att√≥l f√ºgg, hogy mire szeretn√©d haszn√°lni ≈ëket, milyen adatokat haszn√°lsz, mennyit vagy hajland√≥ fizetni √©s m√©g sok m√°s t√©nyez≈ët≈ël.

Att√≥l f√ºgg≈ëen, hogy a modelleket sz√∂veg, hang, vide√≥, k√©p gener√°l√°s√°ra √©s √≠gy tov√°bb szeretn√©d haszn√°lni, v√°laszthatsz k√ºl√∂nb√∂z≈ë t√≠pus√∫ modellt.

- **Hang- √©s besz√©dfelismer√©s**. Erre a c√©lra a Whisper t√≠pus√∫ modellek kiv√°l√≥ v√°laszt√°s, mivel √°ltal√°nos c√©l√∫ak √©s a besz√©dfelismer√©sre ir√°nyulnak. K√ºl√∂nb√∂z≈ë hangokon k√©pzett √©s k√©pes t√∂bbnyelv≈± besz√©dfelismer√©sre. Tudj meg t√∂bbet a [Whisper t√≠pus√∫ modellekr≈ël itt](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **K√©p gener√°l√°s**. K√©p gener√°l√°sra a DALL-E √©s a Midjourney k√©t nagyon ismert v√°laszt√°s. A DALL-E az Azure OpenAI √°ltal k√≠n√°lt. [Olvass t√∂bbet a DALL-E-r≈ël itt](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) √©s a tananyag 9. fejezet√©ben.

- **Sz√∂veg gener√°l√°s**. A legt√∂bb modell sz√∂veg gener√°l√°sra van kik√©pezve, √©s nagy v√°laszt√©kot k√≠n√°l a GPT-3.5-t≈ël a GPT-4-ig. K√ºl√∂nb√∂z≈ë k√∂lts√©gekkel j√°rnak, a GPT-4 a legdr√°g√°bb. √ârdemes megn√©zni az [Azure OpenAI j√°tsz√≥teret](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), hogy ki√©rt√©keld, mely modellek illeszkednek legjobban a sz√ºks√©gleteidhez k√©pess√©g √©s k√∂lts√©g szempontj√°b√≥l.

- **Multi-modalit√°s**. Ha t√∂bbf√©le adatot szeretn√©l kezelni bemenetk√©nt √©s kimenetk√©nt, √©rdemes megfontolni modelleket, mint p√©ld√°ul [gpt-4 turbo with vision vagy gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - az OpenAI modellek leg√∫jabb kiad√°sai - amelyek k√©pesek kombin√°lni a term√©szetes nyelv feldolgoz√°st a vizu√°lis meg√©rt√©ssel, lehet≈ëv√© t√©ve a multi-mod√°lis interf√©szekkel val√≥ interakci√≥kat.

A modell kiv√°laszt√°sa azt jelenti, hogy kapsz n√©h√°ny alapvet≈ë k√©pess√©get, amelyek azonban lehet, hogy nem elegend≈ëek. Gyakran van c√©gspecifikus adat, amelyet valahogy el kell mondanod az LLM-nek. Sz√°mos k√ºl√∂nb√∂z≈ë lehet≈ës√©g van arra, hogyan k√∂zel√≠tsd meg ezt, err≈ël t√∂bbet az elk√∂vetkez≈ë szakaszokban.

### Alapmodellek versus LLM-ek

Az Alapmodell kifejez√©st [a Stanford kutat√≥i alkott√°k](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst), √©s √∫gy defini√°lt√°k, mint egy AI modellt, amely bizonyos krit√©riumokat k√∂vet, mint p√©ld√°ul:

- **Nem fel√ºgyelt tanul√°ssal vagy √∂nfel√ºgyelt tanul√°ssal vannak kik√©pezve**, ami azt jelenti, hogy c√≠mk√©zetlen multi-mod√°lis adatokon vannak kik√©pezve, √©s nem ig√©nyelnek emberi annot√°ci√≥t vagy adatc√≠mk√©z√©st a k√©pz√©si folyamatukhoz.
- **Nagyon nagy modellek**, amelyek nagyon m√©ly neur√°lis h√°l√≥zatokon alapulnak, milli√°rd param√©terekkel k√©pzett.
- **√Åltal√°ban m√°s modellek 'alapjak√©nt' szolg√°lnak**, ami azt jelenti, hogy kiindul√≥pontk√©nt haszn√°lhat√≥k m√°s modellek √©p√≠t√©s√©re, amit finomhangol√°ssal lehet el√©rni.

![Alapmodellek versus LLM-ek](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.hu.png)

K√©p forr√°sa: [Alapvet≈ë √∫tmutat√≥ az Alapmodellekhez √©s Nagy Nyelvi Modellekhez | Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

A megk√ºl√∂nb√∂ztet√©s tov√°bbi tiszt√°z√°sa √©rdek√©ben vegy√ºk p√©ld√°nak a ChatGPT-t. Az els≈ë verzi√≥j√°nak fel√©p√≠t√©s√©hez egy GPT-3.5 nev≈± modell szolg√°lt alapmodellk√©nt. Ez azt jelenti, hogy az OpenAI haszn√°lt n√©h√°ny chat-specifikus adatot, hogy l√©trehozzon egy hangolt verzi√≥t a GPT-3.5-b≈ël, amely specializ√°l√≥dott a besz√©lget√©si helyzetekben, mint p√©ld√°ul a chatbotok, val√≥ j√≥ teljes√≠tm√©nyre.

![Alapmodell](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.hu.png)

K√©p forr√°sa: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Ny√≠lt forr√°sk√≥d√∫ versus Tulajdonosi modellek

Az LLM-ek m√°sik m√≥dja, hogy ny√≠lt forr√°sk√≥d√∫ak vagy tulajdonosiak.

A ny√≠lt forr√°sk√≥d√∫ modellek olyan modellek, amelyeket nyilv√°noss√°gra hoznak, √©s b√°rki haszn√°lhatja ≈ëket. Gyakran a l√©trehoz√≥ v√°llalat vagy a kutat√≥i k√∂z√∂ss√©g teszi ≈ëket el√©rhet≈ëv√©. Ezek a modellek lehet≈ëv√© teszik az ellen≈ërz√©st, m√≥dos√≠t√°st √©s testreszab√°st a k√ºl√∂nb√∂z≈ë LLM felhaszn√°l√°si esetekhez. Azonban nem mindig optimaliz√°ltak termel√©si haszn√°latra, √©s lehet, hogy nem olyan teljes√≠tm√©nyesek, mint a tulajdonosi modellek. Tov√°bb√°, a ny√≠lt forr√°sk√≥d√∫ modellek finansz√≠roz√°sa korl√°tozott lehet, √©s lehet, hogy nem tartj√°k fenn hossz√∫ t√°von, vagy nem friss√≠tik a leg√∫jabb kutat√°sokkal. N√©pszer≈± ny√≠lt forr√°sk√≥d√∫ modellek p√©ld√°i k√∂z√© tartozik [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) √©s [LLaMA](https://llama.meta.com).

A tulajdonosi modellek olyan modellek, amelyeket egy v√°llalat birtokol, √©s nem teszik ≈ëket el√©rhet≈ëv√© a nyilv√°noss√°g sz√°m√°ra. Ezek a modellek gyakran optimaliz√°ltak termel√©si haszn√°latra. Azonban nem enged√©lyezett az ellen≈ërz√©s, m√≥dos√≠t√°s vagy testreszab√°s k√ºl√∂nb√∂z≈ë felhaszn√°l√°si esetekhez. Tov√°bb√°, nem mindig el√©rhet≈ëk ingyen, √©s el≈ëfizet√©st vagy fizet√©st ig√©nyelhetnek a haszn√°latukhoz. Tov√°bb√°, a felhaszn√°l√≥k nem rendelkeznek az adatok felett, amelyeket a modell k√©pz√©s√©hez haszn√°lnak, ami azt jelenti, hogy a modell tulajdonos√°nak kell b√≠zniuk az adatok adatv√©delm√©nek √©s az AI felel≈ës haszn√°lat√°nak biztos√≠t√°s√°ban. N√©pszer≈± tulajdonosi modellek p√©ld√°i k√∂z√© tartozik [OpenAI modellek](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) vagy [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Be√°gyaz√°s versus K√©p gener√°l√°s versus Sz√∂veg √©s K√≥d gener√°l√°s

Az LLM-eket az √°ltaluk gener√°lt kimenet alapj√°n is kategoriz√°lhatjuk.

A be√°gyaz√°sok olyan modellek, amelyek k√©pesek sz√∂veget numerikus form√°ba, √∫gynevezett be√°gyaz√°sba konvert√°lni, amely a bemeneti sz√∂veg numerikus reprezent√°ci√≥ja. A be√°gyaz√°sok megk√∂nny√≠tik a g√©pek sz√°m√°ra a szavak vagy mondatok k√∂z√∂tti kapcsolatok meg√©rt√©s√©t, √©s m√°s modellek, mint p√©ld√°ul oszt√°lyoz√°si modellek vagy csoportos√≠t√°si modellek, amelyek jobban teljes√≠tenek numerikus adatokon, bemenetk√©nt fogyaszthat√≥k. A be√°gyaz√°si modelleket gyakran haszn√°lj√°k √°tvitel tanul√°sra, ahol egy modellt egy helyettes√≠t≈ë feladatra √©p√≠tenek, amelyhez b≈ës√©ges adat √°ll rendelkez√©sre, majd a modell s√∫lyait (be√°gyaz√°sokat) √∫jra felhaszn√°lj√°k m√°s lefel√© ir√°nyul√≥ feladatokra. Ennek a kateg√≥ri√°nak egy p√©ld√°ja az [OpenAI be√°gyaz√°sok](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Be√°gyaz√°s](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.hu.png)

A k√©p gener√°l√°si modellek olyan modellek, amelyek k√©peket gener√°lnak. Ezeket a modelleket gyakran haszn√°lj√°k k√©p szerkeszt√©sre, k√©p szint√©zisre √©s k√©p ford√≠t√°sra. A k√©p gener√°l√°si modellek gyakran nagy k√©padatk√©szleteken, p√©ld√°ul [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst) k√©pzett, √©s √∫j k√©pek gener√°l√°s√°ra vagy megl√©v≈ë k√©pek szerkeszt√©s√©re haszn√°lhat√≥k fest√©s, szuperfelbont√°s √©s sz√≠nez√©si technik√°k seg√≠ts√©g√©vel. P√©ld√°k k√∂z√© tartozik a [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) √©s a [Stable Diffusion modellek](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![K√©p gener√°l√°s](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.hu.png)

A sz√∂veg √©s k√≥d gener√°l√°si modellek olyan modellek, amelyek sz√∂veget vagy k√≥dot gener√°lnak. Ezeket a modelleket gyakran haszn√°lj√°k sz√∂veg √∂sszefoglal√°sra, ford√≠t√°sra √©s k√©rd√©s megv√°laszol√°sra. A sz√∂veg gener√°l√°si modellek gyakran nagy sz√∂vegadatk√©szleteken, p√©ld√°ul [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst) k√©pzett, √©s √∫j sz√∂veg gener√°l√°s√°ra vagy k√©rd√©sek megv√°laszol√°s√°ra haszn√°lhat√≥k. A k√≥d gener√°l√°si modellek, mint p√©ld√°ul [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), gyakran nagy k√≥dadatk√©szleteken, p√©ld√°ul GitHub k√©pzett, √©s √∫j k√≥d gener√°l√°s√°ra vagy megl√©v≈ë k√≥d hib√°inak jav√≠t√°s√°ra haszn√°lhat√≥k.

![Sz√∂veg √©s k√≥d gener√°l√°s](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.hu.png)

### K√≥dol√≥-Dek√≥dol√≥ versus Csak dek√≥dol√≥

Az LLM-ek k√ºl√∂nb√∂z≈ë architekt√∫r√°inak megvitat√°s√°hoz haszn√°ljunk egy anal√≥gi√°t.

K√©pzeld el, hogy a vezet≈ëd adott neked egy feladatot, hogy √≠rj egy kv√≠zt a di√°kok sz√°m√°ra. K√©t koll√©g√°d van; az egyik a tartalom l√©trehoz√°s√°√©rt felel≈ës, a m√°sik a fel√ºlvizsg√°lat√©rt.

A tartalom l√©trehoz√≥ olyan, mint egy Csak dek√≥dol√≥ modell, megn√©zheti a t√©m√°t √©s azt, amit m√°r √≠rt√°l, majd az alapj√°n √≠rhat egy kurzust. Nagyon j√≥k az √©rdekes √©s informat√≠v tartalom √≠r√°s√°ban, de nem nagyon j√≥k a t√©ma √©s a tanul√°si c√©lok meg√©rt√©s√©ben. A dek√≥dol√≥ modellek p√©ld√°i a GPT csal√°d modellek, p√©ld√°ul a GPT-3.

A fel√ºlvizsg√°l√≥ olyan, mint egy Csak k√≥dol√≥ modell, megn√©zi az √≠rt kurzust √©s a v√°laszokat, √©szreveszi a kapcsolatot k√∂z√∂tt√ºk √©s meg√©rti a kontextust, de nem j√≥ a tartalom gener√°l√°s√°ban. A k√≥dol√≥ modellek p√©ld√°ja a BERT.

K√©pzeld el, hogy lehetne valaki, aki l√©trehozhatja √©s fel√ºlvizsg√°lhatja a kv√≠zt, ez egy K√≥dol√≥-Dek√≥dol√≥ modell. N√©h√°ny p√©lda lenne a BART √©s a T5.

### Szolg√°ltat√°s versus Modell

Most besz√©lj√ºnk a szolg√°ltat√°s √©s a modell k√∂z√∂tti k√ºl√∂nbs√©gr≈ël. A szolg√°ltat√°s egy term√©k, amelyet egy Felh≈ë Szolg√°ltat√≥ k√≠n√°l, √©s gyakran modellek, adatok √©s m√°s √∂sszetev≈ëk kombin√°ci√≥ja. A modell a szolg√°ltat√°s k√∂zponti eleme, √©s gyakran alapmodell, mint p√©ld√°ul egy LLM.

A szolg√°ltat√°sok gyakran optimaliz√°ltak termel√©si haszn√°latra, √©s gyakran k√∂nnyebben haszn√°lhat√≥k, mint a modellek, grafikus felhaszn√°l√≥i fel√ºleten kereszt√ºl. Azonban a szolg√°ltat√°sok nem mindig el√©rhet≈ëk ingyen, √©s el≈ëfizet√©st vagy fizet√©st ig√©nyelhetnek a haszn√°latuk√©rt, cser√©be a szolg√°ltat√°s tulajdonos√°nak felszerel√©se √©s er≈ëforr√°sai, k√∂lts√©gek optimaliz√°l√°sa √©s k√∂nny≈± sk√°l√°z√°s. P√©lda egy szolg√°ltat√°sra az [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), amely pay-as-you-go d√≠jtervet k√≠n√°l, ami azt jelenti, hogy a felhaszn√°l√≥kat ar√°nyosan terhelik azzal, hogy mennyit haszn√°lj√°k a szolg√°ltat√°st. Tov√°bb√°, az Azure OpenAI Service v√°llalati szint≈± biztons√°got √©s felel≈ës AI keretrendszert k√≠n√°l a modellek k√©pess√©gein fel√ºl.

A modellek csak a Neur√°lis H√°l√≥zat, a param√©terekkel, s√∫lyokkal √©s m√°sokkal. Lehet≈ëv√© teszi a v√°llalatoknak, hogy helyileg futtass√°k, azonban sz√ºks√©g lenne felszerel√©s v√°s√°rl√°s√°ra, strukt√∫ra √©p√≠t√©s√©re a sk√°l√°z√°shoz √©s licenc v√°s√°rl√°s√°ra vagy ny√≠lt forr√°sk√≥d√∫ modell haszn√°lat√°ra. Egy modell, mint a LLaMA, el√©rhet≈ë a haszn√°latra, sz√°m√≠t√°si teljes√≠tm√©nyt ig√©nyelve a modell futtat√°s√°hoz.

## Hogyan tesztelj√ºk √©s iter√°ljuk k√ºl√∂nb√∂z≈ë modellekkel a teljes√≠tm√©ny meg√©rt√©s
- Hasonl√≠tsa √∂ssze az ipar√°gban el√©rhet≈ë modellek √©s adathalmazok benchmarkjait, hogy felm√©rje, melyik felel meg az √ºzleti forgat√≥k√∂nyvnek, a [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panelen kereszt√ºl.

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.hu.png)

- Finomhangolja a modellt egyedi k√©pz√©si adatokon, hogy jav√≠tsa a modell teljes√≠tm√©ny√©t egy adott munkaterhel√©sben, az Azure AI Studio k√≠s√©rletez√©si √©s nyomon k√∂vet√©si k√©pess√©geit kihaszn√°lva.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.hu.png)

- Telep√≠tse az eredeti el≈ëre betan√≠tott modellt vagy a finomhangolt verzi√≥t t√°voli val√≥s idej≈± k√∂vetkeztet√©shez - kezelt sz√°m√≠t√°si kapacit√°s - vagy szerver n√©lk√ºli API v√©gpontra - [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - hogy az alkalmaz√°sok felhaszn√°lhass√°k azt.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.hu.png)

> [!NOTE]
> Nem minden modell el√©rhet≈ë jelenleg a katal√≥gusban finomhangol√°sra √©s/vagy pay-as-you-go telep√≠t√©sre. Ellen≈ërizze a modell k√°rty√°j√°t a modell k√©pess√©geir≈ël √©s korl√°tair√≥l.

## LLM eredm√©nyek jav√≠t√°sa

Startup csapatunkkal k√ºl√∂nb√∂z≈ë t√≠pus√∫ LLM-eket √©s egy felh≈ëplatformot (Azure Machine Learning) vizsg√°ltunk, amely lehet≈ëv√© teszi sz√°munkra, hogy √∂sszehasonl√≠tsunk k√ºl√∂nb√∂z≈ë modelleket, tesztadatokon √©rt√©kelj√ºk ≈ëket, jav√≠tsuk a teljes√≠tm√©nyt √©s telep√≠ts√ºk ≈ëket k√∂vetkeztet√©si v√©gpontokra.

De mikor √©rdemes ink√°bb finomhangolni egy modellt, mint egy el≈ëre betan√≠tottat haszn√°lni? Vannak m√°s megk√∂zel√≠t√©sek is a modell teljes√≠tm√©ny√©nek jav√≠t√°s√°ra konkr√©t munkaterhel√©sek eset√©n?

Sz√°mos megk√∂zel√≠t√©st alkalmazhat egy v√°llalkoz√°s, hogy el√©rje a k√≠v√°nt eredm√©nyeket egy LLM seg√≠ts√©g√©vel. K√ºl√∂nb√∂z≈ë t√≠pus√∫ modelleket v√°laszthat, k√ºl√∂nb√∂z≈ë k√©pz√©si fokozatokkal, amikor egy LLM-et telep√≠t a termel√©sbe, k√ºl√∂nb√∂z≈ë komplexit√°si, k√∂lts√©g- √©s min≈ës√©gi szintekkel. √çme n√©h√°ny k√ºl√∂nb√∂z≈ë megk√∂zel√≠t√©s:

- **Prompt tervez√©s kontextussal**. Az √∂tlet az, hogy elegend≈ë kontextust biztos√≠tunk a promptn√°l, hogy biztos√≠tsuk a sz√ºks√©ges v√°laszok el√©r√©s√©t.

- **Retrieval Augmented Generation, RAG**. Az adatai p√©ld√°ul egy adatb√°zisban vagy webes v√©gponton l√©tezhetnek, hogy biztos√≠ts√°k ezen adatok vagy azok r√©szhalmaz√°nak bevon√°s√°t a prompt id≈ëpontj√°ban, lek√©rheti a relev√°ns adatokat, √©s a felhaszn√°l√≥i prompt r√©sz√©v√© teheti.

- **Finomhangolt modell**. Itt tov√°bb k√©pezte a modellt saj√°t adataival, ami pontosabb√° √©s reag√°l√≥bb√° tette a modell az ig√©nyeire, de k√∂lts√©ges lehet.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.hu.png)

K√©p forr√°sa: [N√©gy m√≥d, ahogyan a v√°llalatok telep√≠tik az LLM-eket | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt tervez√©s kontextussal

Az el≈ëre betan√≠tott LLM-ek nagyon j√≥l m≈±k√∂dnek √°ltal√°nos√≠tott term√©szetes nyelvi feladatokban, m√©g akkor is, ha r√∂vid prompttal h√≠vj√°k meg ≈ëket, mint p√©ld√°ul egy befejezend≈ë mondat vagy k√©rd√©s ‚Äì az √∫gynevezett ‚Äûzero-shot‚Äù tanul√°s.

Azonban min√©l ink√°bb k√©pes a felhaszn√°l√≥ megfogalmazni k√©rd√©s√©t, r√©szletes k√©r√©ssel √©s p√©ld√°kkal ‚Äì a kontextussal ‚Äì, ann√°l pontosabb √©s a felhaszn√°l√≥ elv√°r√°saihoz legk√∂zelebb √°ll√≥ lesz a v√°lasz. Ebben az esetben ‚Äûone-shot‚Äù tanul√°sr√≥l besz√©l√ºnk, ha a prompt csak egy p√©ld√°t tartalmaz, √©s ‚Äûfew-shot‚Äù tanul√°sr√≥l, ha t√∂bb p√©ld√°t tartalmaz. A prompt tervez√©s kontextussal a legk√∂lts√©ghat√©konyabb megk√∂zel√≠t√©s a kezd√©shez.

### Retrieval Augmented Generation (RAG)

Az LLM-eknek az a korl√°tja, hogy csak azokat az adatokat tudj√°k felhaszn√°lni, amelyek a k√©pz√©s√ºk sor√°n rendelkez√©sre √°lltak a v√°lasz gener√°l√°s√°hoz. Ez azt jelenti, hogy nem tudnak semmit azokr√≥l a t√©nyekr≈ël, amelyek a k√©pz√©si folyamatuk ut√°n t√∂rt√©ntek, √©s nem f√©rnek hozz√° nem nyilv√°nos inform√°ci√≥khoz (p√©ld√°ul v√°llalati adatok).
Ezt a RAG seg√≠ts√©g√©vel lehet √°thidalni, egy olyan technik√°val, amely k√ºls≈ë adatokkal eg√©sz√≠ti ki a promptot dokumentumok darabjaival, figyelembe v√©ve a prompt hossz√∫s√°gi korl√°tait. Ezt a vektor adatb√°zis eszk√∂z√∂k t√°mogatj√°k (mint p√©ld√°ul [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), amelyek hasznos darabokat keresnek vissza k√ºl√∂nb√∂z≈ë el≈ëre meghat√°rozott adatforr√°sokb√≥l, √©s hozz√°adj√°k ≈ëket a prompt kontextus√°hoz.

Ez a technika nagyon hasznos, amikor egy v√°llalkoz√°snak nincs elegend≈ë adata, elegend≈ë ideje vagy er≈ëforr√°sa egy LLM finomhangol√°s√°ra, de m√©g mindig szeretn√© jav√≠tani a teljes√≠tm√©nyt egy adott munkaterhel√©sben, √©s cs√∂kkenteni a kital√°l√°sok, azaz a val√≥s√°g elferd√≠t√©s√©nek vagy k√°ros tartalom kock√°zat√°t.

### Finomhangolt modell

A finomhangol√°s egy olyan folyamat, amely a transzfer tanul√°st kihaszn√°lva ‚Äûalkalmazza‚Äù a modellt egy lefel√© ir√°nyul√≥ feladatra vagy egy adott probl√©ma megold√°s√°ra. Ellent√©tben a few-shot tanul√°ssal √©s a RAG-gal, √∫j modell j√∂n l√©tre, friss√≠tett s√∫lyokkal √©s torz√≠t√°sokkal. Sz√ºks√©ge van egy k√©pz√©si p√©ld√°k halmaz√°ra, amely egyetlen bemenetb≈ël (a promptb√≥l) √©s a hozz√° kapcsol√≥d√≥ kimenetb≈ël (a befejez√©sb≈ël) √°ll.
Ez lenne a prefer√°lt megk√∂zel√≠t√©s, ha:

- **Finomhangolt modellek haszn√°lata**. Egy v√°llalkoz√°s ink√°bb kev√©sb√© k√©pes finomhangolt modelleket (mint p√©ld√°ul be√°gyaz√°si modellek) szeretne haszn√°lni, mint magas teljes√≠tm√©ny≈± modelleket, ami k√∂lts√©ghat√©konyabb √©s gyorsabb megold√°st eredm√©nyez.

- **K√©sleltet√©s figyelembev√©tele**. A k√©sleltet√©s fontos egy adott felhaszn√°l√°si esetben, ez√©rt nem lehets√©ges nagyon hossz√∫ promptokat haszn√°lni, vagy a p√©ld√°k sz√°ma, amelyeket a modellnek meg kell tanulnia, nem illeszkedik a prompt hossz√∫s√°gi korl√°tj√°hoz.

- **Naprak√©sz marad√°s**. Egy v√°llalkoz√°snak sok kiv√°l√≥ min≈ës√©g≈± adata √©s val√≥s√°gbeli c√≠mk√©je van, valamint az er≈ëforr√°sok, amelyek sz√ºks√©gesek ezeknek az adatoknak a folyamatos naprak√©szen tart√°s√°hoz.

### Betan√≠tott modell

Egy LLM-et a semmib≈ël betan√≠tani k√©ts√©gtelen√ºl a legnehezebb √©s leg√∂sszetettebb megk√∂zel√≠t√©s, amely hatalmas mennyis√©g≈± adatot, k√©pzett er≈ëforr√°sokat √©s megfelel≈ë sz√°m√≠t√°si kapacit√°st ig√©nyel. Ezt az opci√≥t csak akkor √©rdemes fontol√≥ra venni, ha egy v√°llalkoz√°snak van egy ter√ºlet-specifikus felhaszn√°l√°si esete √©s nagy mennyis√©g≈± ter√ºletk√∂zpont√∫ adata.

## Tud√°s ellen≈ërz√©se

Mi lehet egy j√≥ megk√∂zel√≠t√©s az LLM befejez√©si eredm√©nyek jav√≠t√°s√°ra?

1. Prompt tervez√©s kontextussal
1. RAG
1. Finomhangolt modell

A:3, ha van ideje √©s er≈ëforr√°sai, valamint kiv√°l√≥ min≈ës√©g≈± adatai, a finomhangol√°s a jobb opci√≥, hogy naprak√©sz maradjon. Azonban, ha a dolgok jav√≠t√°s√°ra t√∂rekszik, √©s nincs el√©g ideje, √©rdemes el≈ësz√∂r a RAG-ot fontol√≥ra venni.

## üöÄ Kih√≠v√°s

Olvasson t√∂bbet arr√≥l, hogyan tudja [haszn√°lni a RAG-ot](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) v√°llalkoz√°s√°ban.

## Remek munka, folytassa a tanul√°st

A lecke befejez√©se ut√°n tekintse meg [Generative AI Learning gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb n√∂velje a Generative AI tud√°s√°t!

L√©pjen tov√°bb a 3. leck√©re, ahol megn√©zz√ºk, hogyan lehet [felel≈ëss√©gteljesen √©p√≠teni Generative AI-vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Jogi nyilatkozat**:  
Ez a dokumentum az AI ford√≠t√°si szolg√°ltat√°s [Co-op Translator](https://github.com/Azure/co-op-translator) haszn√°lat√°val k√©sz√ºlt. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum a saj√°t nyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n javasolt a professzion√°lis emberi ford√≠t√°s ig√©nybev√©tele. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy f√©lremagyar√°z√°sok√©rt.