{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A következő jegyzetfüzetet a GitHub Copilot Chat automatikusan generálta, és kizárólag kezdeti beállításra szolgál.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bevezetés a prompt engineeringbe\n",
    "A prompt engineering a természetes nyelvfeldolgozási feladatokhoz használt utasítások megtervezésének és optimalizálásának folyamata. Ez magában foglalja a megfelelő promptok kiválasztását, azok paramétereinek finomhangolását, valamint a teljesítményük értékelését. A prompt engineering kulcsfontosságú a magas pontosság és hatékonyság eléréséhez az NLP modellekben. Ebben a részben áttekintjük a prompt engineering alapjait, az OpenAI modellek segítségével bemutatva a lehetőségeket.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gyakorlat 1: Tokenizálás\n",
    "Ismerkedj meg a tokenizálással a tiktoken segítségével, amely az OpenAI nyílt forráskódú, gyors tokenizálója.\n",
    "További példákat találsz az [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) oldalán.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. gyakorlat: Az OpenAI API-kulcs beállításának ellenőrzése\n",
    "\n",
    "Futtasd le az alábbi kódot, hogy megbizonyosodj róla, helyesen állítottad be az OpenAI végpontot. A kód egy egyszerű alap promptot próbál ki, és ellenőrzi a választ. Az `oh say can you see` bemenetre a válasznak valami olyasmit kellene tartalmaznia, mint például `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\"\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]       \n",
    "    response = client.chat.completions.create(   \n",
    "        model=deployment,                                         \n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. gyakorlat: Kitalációk\n",
    "Vizsgáld meg, mi történik, ha arra kéred az LLM-et, hogy adjon választ egy olyan témára, ami lehet, hogy nem is létezik, vagy olyan témákról, amelyeket nem ismerhet, mert kívül esnek az előzetes tanítási adathalmazán (például frissebb témák). Figyeld meg, hogyan változik a válasz, ha másik promptot vagy másik modellt próbálsz ki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feladat 4: Utasítás alapú\n",
    "Használd a \"text\" változót az elsődleges tartalom beállításához,\n",
    "és a \"prompt\" változót arra, hogy egy utasítást adj az elsődleges tartalomhoz kapcsolódóan.\n",
    "\n",
    "Itt arra kérjük a modellt, hogy foglalja össze a szöveget egy második osztályos tanuló számára.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. gyakorlat: Összetett prompt\n",
    "Próbálj ki egy olyan kérést, amelyben van rendszer-, felhasználói és asszisztens üzenet is\n",
    "A rendszer beállítja az asszisztens kontextusát\n",
    "A felhasználó és az asszisztens üzenetei többfordulós beszélgetési kontextust adnak\n",
    "\n",
    "Figyeld meg, hogy az asszisztens személyisége \"szarkasztikusra\" van állítva a rendszer kontextusában.\n",
    "Próbáld ki más személyiség kontextussal is. Vagy próbálj ki más sorozatú be- és kimeneti üzeneteket\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gyakorlat: Fedezd fel az intuíciódat\n",
    "A fenti példák olyan mintákat mutatnak, amelyeket felhasználhatsz új promptok (egyszerű, összetett, utasítás stb.) létrehozásához – próbálj meg további gyakorlatokat készíteni, hogy felfedezd a többi, korábban említett ötletet, például példákat, jelzéseket és még sok mást.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Jogi nyilatkozat**:  \nEz a dokumentum az AI-alapú [Co-op Translator](https://github.com/Azure/co-op-translator) fordítószolgáltatás segítségével készült. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti, eredeti nyelvű dokumentum tekintendő hiteles forrásnak. Kritikus információk esetén javasoljuk a professzionális, emberi fordítást. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy téves értelmezésekért.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "coopTranslator": {
   "original_hash": "ec9eedd4f3981f097d4bd34c849cb8b6",
   "translation_date": "2025-08-25T13:48:10+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/oai-assignment.ipynb",
   "language_code": "hu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}