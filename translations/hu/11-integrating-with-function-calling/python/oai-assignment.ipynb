{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bevezetés\n",
    "\n",
    "Ebben a leckében szó lesz arról, hogy:\n",
    "- Mi az a függvényhívás, és mire használható\n",
    "- Hogyan lehet függvényhívást létrehozni az OpenAI segítségével\n",
    "- Hogyan lehet egy alkalmazásba integrálni a függvényhívást\n",
    "\n",
    "## Tanulási célok\n",
    "\n",
    "A lecke elvégzése után tudni fogod és megérted:\n",
    "\n",
    "- Miért érdemes függvényhívást használni\n",
    "- Hogyan állítsd be a Function Call-t az OpenAI szolgáltatással\n",
    "- Hogyan tervezz hatékony függvényhívásokat az alkalmazásod igényeihez\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A függvényhívások megértése\n",
    "\n",
    "Ebben a leckében egy olyan funkciót szeretnénk fejleszteni oktatási startupunk számára, amely lehetővé teszi, hogy a felhasználók egy chatbot segítségével technikai kurzusokat találjanak. Olyan tanfolyamokat fogunk ajánlani, amelyek megfelelnek a felhasználó tudásszintjének, jelenlegi szerepkörének és az őt érdeklő technológiának.\n",
    "\n",
    "Ehhez a következőket fogjuk használni:\n",
    " - `OpenAI` a felhasználói chat élmény megteremtéséhez\n",
    " - `Microsoft Learn Catalog API`, hogy a felhasználó igényei alapján segíthessünk kurzusokat találni\n",
    " - `Function Calling`, amellyel a felhasználó lekérdezését egy függvényhez továbbítjuk, hogy API-kérést indítsunk\n",
    "\n",
    "Kezdésként nézzük meg, miért érdemes egyáltalán függvényhívást használni:\n",
    "\n",
    "print(\"Üzenetek a következő kérésben:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # új választ kérünk a GPT-től, ahol már látja a függvény válaszát\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miért hasznos a Function Calling\n",
    "\n",
    "Ha már elvégeztél bármelyik másik leckét ebben a kurzusban, valószínűleg már érted, milyen erősek a Nagy Nyelvi Modellek (LLM-ek). Remélhetőleg az is feltűnt, hogy vannak korlátaik.\n",
    "\n",
    "A Function Calling az OpenAI Service egyik funkciója, amely a következő problémákra kínál megoldást:\n",
    "\n",
    "Válaszok formázásának következetlensége:\n",
    "- A function calling előtt a nagy nyelvi modellek válaszai rendezetlenek és következetlenek voltak. A fejlesztőknek bonyolult ellenőrző kódokat kellett írniuk, hogy minden lehetséges válaszvariációt kezelni tudjanak.\n",
    "\n",
    "Korlátozott integráció külső adatokkal:\n",
    "- E funkció bevezetése előtt nehéz volt más alkalmazásrészekből származó adatokat beemelni a chat-környezetbe.\n",
    "\n",
    "A válaszformátumok egységesítésével és a külső adatok egyszerű integrálásával a function calling megkönnyíti a fejlesztést, és csökkenti a plusz ellenőrző logika szükségességét.\n",
    "\n",
    "A felhasználók például nem kaphattak olyan válaszokat, mint „Milyen most az időjárás Stockholmban?”. Ennek oka, hogy a modellek csak a tanításuk idején elérhető adatokra támaszkodtak.\n",
    "\n",
    "Nézzük meg az alábbi példát, amely jól szemlélteti ezt a problémát:\n",
    "\n",
    "Tegyük fel, hogy szeretnénk létrehozni egy adatbázist a diákokról, hogy a számukra legmegfelelőbb kurzust tudjuk ajánlani. Az alábbiakban két diák leírását látjuk, amelyek nagyon hasonló adatokat tartalmaznak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezt el szeretnénk küldeni egy LLM-nek, hogy feldolgozza az adatokat. Később ezt felhasználhatjuk arra, hogy elküldjük egy API-nak vagy eltároljuk egy adatbázisban.\n",
    "\n",
    "Készítsünk két teljesen azonos promptot, amelyekben utasítjuk a LLM-et, hogy milyen információkra vagyunk kíváncsiak:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ezt el szeretnénk küldeni egy LLM-nek, hogy feldolgozza a termékünk szempontjából fontos részeket. Így két azonos promptot tudunk létrehozni, hogy utasítsuk az LLM-et:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Miután létrehoztuk ezt a két promptot, elküldjük őket az LLM-nek az `openai.ChatCompletion` használatával. A promptot a `messages` változóban tároljuk, és a szerepet `user`-re állítjuk. Ez azért van, hogy egy felhasználó üzenetét utánozzuk, amelyet egy chatbotnak írnak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annak ellenére, hogy a promptok ugyanazok és a leírások is hasonlóak, a `Grades` tulajdonság különböző formátumokban jelenhet meg.\n",
    "\n",
    "Ha többször futtatod a fenti cellát, a formátum lehet `3.7` vagy `3.7 GPA` is.\n",
    "\n",
    "Ez azért van, mert az LLM a szöveges prompt formájában kapja meg a strukturálatlan adatokat, és ugyanígy strukturálatlan adatokat is ad vissza. Szükségünk van egy strukturált formátumra, hogy tudjuk, mire számíthatunk, amikor tároljuk vagy felhasználjuk ezeket az adatokat.\n",
    "\n",
    "A funkcióhívás használatával biztosíthatjuk, hogy strukturált adatokat kapjunk vissza. A funkcióhívás során az LLM valójában nem hív meg vagy futtat le semmilyen függvényt. Ehelyett létrehozunk egy struktúrát, amit az LLM-nek követnie kell a válaszaiban. Ezeket a strukturált válaszokat aztán arra használjuk, hogy eldöntsük, melyik függvényt futtassuk az alkalmazásainkban.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Függvényhívási folyamatábra](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.hu.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funkcióhívások felhasználási esetei\n",
    "\n",
    "**Külső eszközök meghívása**\n",
    "A chatbotok kiválóan alkalmasak arra, hogy válaszokat adjanak a felhasználók kérdéseire. Funkcióhívások segítségével a chatbotok a felhasználók üzeneteit felhasználva bizonyos feladatokat is el tudnak végezni. Például egy diák megkérheti a chatbotot: „Küldj e-mailt az oktatómnak, hogy több segítségre van szükségem ebben a témában.” Ilyenkor a chatbot meghívhatja a `send_email(to: string, body: string)` nevű függvényt.\n",
    "\n",
    "**API vagy adatbázis lekérdezések létrehozása**\n",
    "A felhasználók természetes nyelven kereshetnek információkat, amelyeket a rendszer formázott lekérdezéssé vagy API-kéréssé alakít. Például egy tanár megkérdezheti: „Kik azok a diákok, akik teljesítették az utolsó feladatot?”, ami meghívhatja a `get_completed(student_name: string, assignment: int, current_status: string)` nevű függvényt.\n",
    "\n",
    "**Strukturált adatok létrehozása**\n",
    "A felhasználók egy szövegrészletből vagy CSV-ből a LLM segítségével kiemelhetik a legfontosabb információkat. Például egy diák egy békemegállapodásról szóló Wikipédia-cikket átalakíthat AI tanulókártyákká. Ehhez használható a `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` nevű függvény.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Első függvényhívás létrehozása\n",
    "\n",
    "A függvényhívás létrehozása három fő lépésből áll:\n",
    "1. Meghívod a Chat Completions API-t a függvényeid listájával és egy felhasználói üzenettel\n",
    "2. Elolvasod a modell válaszát, hogy végrehajts egy műveletet, például egy függvény vagy API hívását\n",
    "3. Újabb hívást indítasz a Chat Completions API-hoz a függvényed válaszával, hogy ezt az információt felhasználd a felhasználónak szóló válasz létrehozásához\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Egy függvényhívás folyamata](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.hu.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Egy függvényhívás elemei\n",
    "\n",
    "#### Felhasználói bemenet\n",
    "\n",
    "Az első lépés egy felhasználói üzenet létrehozása. Ezt dinamikusan is megadhatjuk egy szövegbevitel értékének felhasználásával, vagy itt is megadhatunk egy értéket. Ha most dolgozol először a Chat Completions API-val, meg kell határoznunk az üzenet `role` (szerep) és `content` (tartalom) mezőit.\n",
    "\n",
    "A `role` lehet `system` (szabályok létrehozása), `assistant` (a modell) vagy `user` (a végfelhasználó). Függvényhívás esetén ezt `user`-re állítjuk, és megadunk egy példakérdést.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Függvények létrehozása.\n",
    "\n",
    "Most definiálunk egy függvényt és annak paramétereit. Itt csak egyetlen függvényt fogunk használni, amelynek neve `search_courses`, de természetesen több függvényt is létrehozhatsz.\n",
    "\n",
    "**Fontos**: A függvények bekerülnek a rendszerüzenetbe az LLM számára, és beleszámítanak az elérhető tokenek mennyiségébe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definíciók**\n",
    "\n",
    "A függvénydefiníció szerkezete több szintből áll, mindegyiknek megvannak a saját tulajdonságai. Íme a beágyazott szerkezet áttekintése:\n",
    "\n",
    "**Legfelső szintű függvénytulajdonságok:**\n",
    "\n",
    "`name` – Annak a függvénynek a neve, amelyet meg szeretnénk hívni.\n",
    "\n",
    "`description` – Ez írja le, hogyan működik a függvény. Itt fontos, hogy pontosak és egyértelműek legyünk.\n",
    "\n",
    "`parameters` – Azoknak az értékeknek és formátumnak a listája, amelyeket szeretnénk, hogy a modell válaszként előállítson.\n",
    "\n",
    "**Paraméter objektum tulajdonságai:**\n",
    "\n",
    "`type` – A paraméter objektum adattípusa (általában \"object\")\n",
    "\n",
    "`properties` – Azoknak a konkrét értékeknek a listája, amelyeket a modell a válaszához használni fog\n",
    "\n",
    "**Egyedi paraméter tulajdonságai:**\n",
    "\n",
    "`name` – Implicit módon a tulajdonság kulcsa határozza meg (pl. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` – Ennek a konkrét paraméternek az adattípusa (pl. \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` – Az adott paraméter leírása\n",
    "\n",
    "**Opcionális tulajdonságok:**\n",
    "\n",
    "`required` – Egy tömb, amely felsorolja, hogy mely paraméterek szükségesek a függvényhívás végrehajtásához\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A függvény meghívása\n",
    "Miután definiáltuk a függvényt, most be kell illesztenünk azt a Chat Completion API hívásába. Ezt úgy tesszük meg, hogy hozzáadjuk a `functions` paramétert a kéréshez. Ebben az esetben `functions=functions`.\n",
    "\n",
    "Lehetőség van arra is, hogy a `function_call` értékét `auto`-ra állítsuk. Ez azt jelenti, hogy az LLM-re bízzuk, melyik függvényt hívja meg a felhasználói üzenet alapján, ahelyett, hogy mi magunk választanánk ki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most nézzük meg a választ, és nézzük meg, hogyan van formázva:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Láthatod, hogy a függvény neve meg van hívva, és a felhasználói üzenet alapján a LLM képes volt megtalálni az adatokat, hogy kitöltse a függvény argumentumait.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funkcióhívások integrálása egy alkalmazásba.\n",
    "\n",
    "Miután leteszteltük az LLM által formázott választ, most már beépíthetjük ezt az alkalmazásunkba.\n",
    "\n",
    "### A folyamat kezelése\n",
    "\n",
    "Ahhoz, hogy ezt beépítsük az alkalmazásunkba, kövessük az alábbi lépéseket:\n",
    "\n",
    "Először hívjuk meg az OpenAI szolgáltatásait, és tároljuk az üzenetet egy `response_message` nevű változóban.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most definiáljuk azt a függvényt, amely meghívja a Microsoft Learn API-t, hogy lekérje a tanfolyamok listáját:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legjobb gyakorlatként először megnézzük, hogy a modell szeretne-e meghívni egy függvényt. Ezután létrehozunk egy elérhető függvényt, és hozzárendeljük ahhoz, amelyiket a modell hívni szeretné.\n",
    "\n",
    "Ezután a függvény argumentumait hozzárendeljük a LLM-től kapott argumentumokhoz.\n",
    "\n",
    "Végül hozzáfűzzük a függvényhívás üzenetét és azokat az értékeket, amelyeket a `search_courses` üzenet visszaadott. Ez minden szükséges információt megad a LLM-nek ahhoz, hogy természetes nyelven válaszoljon a felhasználónak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kód kihívás\n",
    "\n",
    "Szép munka! Ha szeretnéd tovább bővíteni az OpenAI Function Calling ismereteidet, próbáld ki ezt: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Adj hozzá több paramétert a függvényhez, amelyek segíthetnek a tanulóknak még több tanfolyamot találni. Az elérhető API paramétereket itt találod:  \n",
    " - Hozz létre egy másik függvényhívást, amely több információt kér be a tanulótól, például az anyanyelvét  \n",
    " - Készíts hibakezelést arra az esetre, ha a függvényhívás és/vagy az API hívás nem ad vissza megfelelő tanfolyamokat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Jogi nyilatkozat**:  \nEz a dokumentum az AI-alapú [Co-op Translator](https://github.com/Azure/co-op-translator) fordítószolgáltatás segítségével készült. Bár törekszünk a pontosságra, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti, eredeti nyelvű dokumentum tekintendő hiteles forrásnak. Kritikus információk esetén javasoljuk a professzionális, emberi fordítást. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy téves értelmezésekért.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:16:49+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "hu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}