# Lek√©rdez√©s-gyors√≠tott gener√°l√°s (RAG) √©s vektor adatb√°zisok

[![Lek√©rdez√©s-gyors√≠tott gener√°l√°s (RAG) √©s vektor adatb√°zisok](../../../translated_images/hu/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

A keres√©si alkalmaz√°sok leck√©ben r√∂viden megismert√ºk, hogyan lehet integr√°lni a saj√°t adatainkat a nagym√©ret≈± nyelvi modellekbe (LLM-ekbe). Ebben a leck√©ben m√©lyebben bepillant√°st nyer√ºnk az adatok alapoz√°s√°nak fogalmaiba az LLM alkalmaz√°saidban, a folyamat mechanik√°j√°ba √©s az adatt√°rol√°si m√≥dszerekbe, bele√©rtve a be√°gyaz√°sokat √©s a sz√∂veget is.

> **Vide√≥ hamarosan el√©rhet≈ë**

## Bevezet√©s

Ebben a leck√©ben a k√∂vetkez≈ëkr≈ël lesz sz√≥:

- Bevezet√©s a RAG-be, mi is az √©s mi√©rt haszn√°ljuk mesters√©ges intelligenci√°ban (AI).

- Meg√©rtj√ºk, mik azok a vektor adatb√°zisok, √©s hogyan hozhatunk l√©tre egyet az alkalmaz√°sunkhoz.

- Gyakorlati p√©lda arra, hogyan integr√°ljuk a RAG-et egy alkalmaz√°sba.

## Tanul√°si c√©lok

A lecke elv√©gz√©se ut√°n k√©pes leszel:

- Megmagyar√°zni a RAG jelent≈ës√©g√©t az adatok lek√©rdez√©s√©ben √©s feldolgoz√°s√°ban.

- Be√°ll√≠tani a RAG alkalmaz√°st √©s az adatokat √∂sszek√∂tni egy LLM-mel.

- Hat√©konyan integr√°lni a RAG-et √©s a vektor adatb√°zisokat LLM alkalmaz√°sokban.

## A forgat√≥k√∂nyv√ºnk: az LLM-jeink b≈ëv√≠t√©se saj√°t adatainkkal

Ebben a leck√©ben saj√°t jegyzeteinket szeretn√©nk hozz√°adni az oktat√°si startuphoz, amely lehet≈ëv√© teszi, hogy a chatbot t√∂bb inform√°ci√≥val rendelkezzen a k√ºl√∂nb√∂z≈ë tant√°rgyakr√≥l. A jegyzeteink seg√≠ts√©g√©vel a tanul√≥k jobban tanulhatnak √©s meg√©rthetik a k√ºl√∂nf√©le t√©m√°kat, megk√∂nny√≠tve a vizsg√°ra val√≥ k√©sz√ºl√©st. Forgat√≥k√∂nyv√ºnk elk√©sz√≠t√©s√©hez a k√∂vetkez≈ëket haszn√°ljuk:

- `Azure OpenAI:` az LLM, amelyet chatbot l√©trehoz√°s√°ra haszn√°lunk

- `AI az kezd≈ëknek lecke a neur√°lis h√°l√≥zatokr√≥l`: ez lesz az adat, amelyhez az LLM-et alapozzuk

- `Azure AI Search` √©s `Azure Cosmos DB:` vektor adatb√°zis az adataink t√°rol√°s√°ra √©s keres√©si index l√©trehoz√°s√°ra

A felhaszn√°l√≥k gyakorol√≥ kv√≠zeket hozhatnak l√©tre a jegyzeteikb≈ël, k√©sz√≠thetnek ism√©tl≈ë k√°rty√°kat √©s √∂sszefoglal√≥kat. Kezdj√ºk azzal, hogy mi az a RAG √©s hogyan m≈±k√∂dik:

## Lek√©rdez√©s-gyors√≠tott gener√°l√°s (RAG)

Egy LLM-alap√∫ chatbot felhaszn√°l√≥i utas√≠t√°sokat dolgoz fel v√°laszok gener√°l√°s√°ra. Interakt√≠v kialak√≠t√°s√∫, √©s sokf√©le t√©m√°ban kommunik√°l a felhaszn√°l√≥kkal. V√°laszai azonban a rendelkez√©sre √°ll√≥ kontextusra √©s az alapk√©pz√©s adataira korl√°toz√≥dnak. P√©ld√°ul a GPT-4 tud√°sv√°g√°si d√°tuma 2021 szeptember, vagyis nem ismeri az az√≥ta t√∂rt√©nt esem√©nyeket. Tov√°bb√°, az LLM-ek kik√©pz√©s√©hez haszn√°lt adatok nem tartalmaznak bizalmas inform√°ci√≥kat, mint p√©ld√°ul szem√©lyes jegyzeteket vagy egy c√©g term√©kk√©zik√∂nyv√©t.

### Hogyan m≈±k√∂dnek a RAG-ek (Lek√©rdez√©s-gyors√≠tott gener√°l√°s)

![rajz a RAG m≈±k√∂d√©s√©r≈ël](../../../translated_images/hu/how-rag-works.f5d0ff63942bd3a6.webp)

Tegy√ºk fel, hogy egy chatbotot szeretn√©l √ºzemeltetni, amely a jegyzeteidb≈ël hoz l√©tre kv√≠zeket, ehhez kapcsol√≥dni kell a tud√°sb√°zishoz. Itt j√∂n a k√©pbe a RAG. A RAG-ek √≠gy m≈±k√∂dnek:

- **Tud√°sb√°zis:** A lek√©rdez√©s el≈ëtt ezeket a dokumentumokat be kell olvasni √©s el≈ë kell feldolgozni, √°ltal√°ban nagy dokumentumokat kisebb r√©szekre bontva, √°talak√≠tva ≈ëket sz√∂veges be√°gyaz√°ss√°, majd t√°rolva az adatb√°zisban.

- **Felhaszn√°l√≥i lek√©rdez√©s:** a felhaszn√°l√≥ k√©rd√©st tesz fel

- **Lek√©rdez√©s:** Amikor a felhaszn√°l√≥ k√©rdez, a be√°gyaz√°s modell relev√°ns inform√°ci√≥kat keres a tud√°sb√°zisban, hogy t√∂bb kontextust adjon a prompthoz.

- **Kiterjesztett gener√°l√°s:** az LLM a lek√©rt adatok alapj√°n jav√≠tja v√°lasz√°t. Ez lehet≈ëv√© teszi, hogy a v√°lasz ne csak a tanult adatokon alapuljon, hanem a hozz√°adott relev√°ns kontextusb√≥l is. A lek√©rt adatokat az LLM v√°laszainak b≈ëv√≠t√©s√©re haszn√°lj√°k. Az LLM ezut√°n visszaadja a v√°laszt a felhaszn√°l√≥ k√©rd√©s√©re.

![rajz a RAG architekt√∫r√°j√°r√≥l](../../../translated_images/hu/encoder-decode.f2658c25d0eadee2.webp)

A RAG architekt√∫r√°ja transformer modell alapj√°n m≈±k√∂dik, amely k√©t r√©szb≈ël √°ll: egy k√≥dol√≥b√≥l √©s egy dek√≥dol√≥b√≥l. P√©ld√°ul, amikor a felhaszn√°l√≥ k√©rdez, a bemeneti sz√∂veget ‚Äûk√≥dolj√°k‚Äù vektorokk√°, amelyek a szavak jelent√©s√©t r√∂gz√≠tik, majd ezeket a vektorokat ‚Äûdek√≥dolj√°k‚Äù a dokumentum index√ºnkbe, √©s √∫j sz√∂veget gener√°lnak a k√©rd√©s alapj√°n. Az LLM mind a k√≥dol√≥-dek√≥dol√≥ modellt haszn√°lja a kimenet l√©trehoz√°s√°ra.

A javasolt tanulm√°ny [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) szerint a RAG implement√°l√°snak k√©t megk√∂zel√≠t√©se van:

- **_RAG-Sequence_**: a lek√©rt dokumentumokat haszn√°lja a felhaszn√°l√≥i k√©rd√©s legjobb v√°lasz√°nak el≈ërejelz√©s√©re

- **RAG-Token**: a dokumentumokat haszn√°lva gener√°lja a k√∂vetkez≈ë tokent, majd √∫jra lek√©ri ≈ëket a v√°laszhoz

### Mi√©rt haszn√°ln√°l RAG-et?

- **Inform√°ci√≥ gazdags√°g:** biztos√≠tja, hogy a sz√∂veges v√°laszok naprak√©szek √©s aktu√°lisak legyenek. Ez√°ltal jav√≠tja az adott szakter√ºleti feladatok teljes√≠tm√©ny√©t az√°ltal, hogy hozz√°f√©r az bels≈ë tud√°sb√°zishoz.

- Cs√∂kkenti a kital√°l√°st azzal, hogy **ellen≈ërizhet≈ë adatokat** haszn√°l a tud√°sb√°zisban a felhaszn√°l√≥i k√©rd√©sek kontextus√°hoz.

- **K√∂lts√©ghat√©kony**, mivel gazdas√°gosabb, mint egy LLM finomhangol√°sa.

## Tud√°sb√°zis l√©trehoz√°sa

Az alkalmaz√°sunk saj√°t adatainkra √©p√ºl, azaz az AI kezd≈ëknek oktat√°si anyag√°nak Neur√°lis H√°l√≥zatok leck√©j√©re.

### Vektor adatb√°zisok

A vektor adatb√°zis egy speci√°lis adatb√°zis, amely be√°gyazott vektorok t√°rol√°s√°ra, kezel√©s√©re √©s keres√©s√©re szolg√°l, szemben a hagyom√°nyos adatb√°zisokkal. A dokumentumok numerikus reprezent√°ci√≥it t√°rolja. Az adatok numerikus be√°gyaz√°ss√° bont√°sa megk√∂nny√≠ti az MI rendszer sz√°m√°ra az adatok meg√©rt√©s√©t √©s feldolgoz√°s√°t.

A be√°gyaz√°sainkat vektor adatb√°zisban t√°roljuk, mivel az LLM-eknek van bemeneti token korl√°tjuk. Mivel nem lehet az √∂sszes be√°gyaz√°st egyszerre √°tadni az LLM-nek, darabokra kell ≈ëket bontani, √©s amikor a felhaszn√°l√≥ k√©rdez, a k√©rd√©shez legink√°bb illeszked≈ë be√°gyaz√°sokat visszaadjuk a prompttal egy√ºtt. A darabol√°s cs√∂kkenti az LLM-en √°tvitt tokenek sz√°m√°t, √≠gy k√∂lts√©ghat√©konyabb.

N√©h√°ny n√©pszer≈± vektor adatb√°zis: Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant √©s DeepLake. Azure CLI seg√≠ts√©g√©vel p√©ld√°ul √≠gy hozhatsz l√©tre Azure Cosmos DB modellt:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Sz√∂vegb≈ël be√°gyaz√°s

Miel≈ëtt adatainkat t√°roln√°nk, vektor be√°gyaz√°sokk√° kell alak√≠tani ≈ëket. Ha nagy dokumentumokkal vagy hossz√∫ sz√∂vegekkel dolgozol, darabolhatod ≈ëket a v√°rhat√≥ lek√©rdez√©sek szerint. Darabol√°s t√∂rt√©nhet mondatszinten vagy bekezd√©sszinten. Mivel a darabok a k√∂rnyez≈ë szavakb√≥l nyernek jelent√©st, adhatunk nekik plusz kontextust, p√©ld√°ul a dokumentum c√≠m√©t vagy n√©mi sz√∂veget a darab el≈ëtt vagy ut√°n. A darabol√°s √≠gy t√∂rt√©nhet:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # Ha az utols√≥ darab nem √©rte el a minim√°lis hossz√∫s√°got, akkor is add hozz√°
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Miut√°n daraboltuk, k√ºl√∂nb√∂z≈ë be√°gyaz√≥ modellekkel alak√≠thatjuk be√°gyaz√°sokk√° a sz√∂veget. Haszn√°lhat√≥ modellek p√©ld√°ul: word2vec, OpenAI ada-002, Azure Computer Vision √©s sok m√°s. A modell v√°laszt√°sa a haszn√°lt nyelvekt≈ël, a tartalom t√≠pus√°t√≥l (sz√∂veg/k√©p/hang), az input m√©ret√©t≈ël √©s a be√°gyaz√°s hossz√°t√≥l f√ºgg.

P√©lda egy OpenAI `text-embedding-ada-002` modell √°ltal k√©sz√≠tett be√°gyaz√°sra:
![a cat sz√≥ be√°gyaz√°sa](../../../translated_images/hu/cat.74cbd7946bc9ca38.webp)

## Lek√©rdez√©s √©s vektor keres√©s

Amikor a felhaszn√°l√≥ k√©rdez, a keres≈ë lek√≥dolja a k√©rd√©st vektorr√°, azt√°n a dokumentum keres√©si index√ºnkben keres relev√°ns vektorokat a bemenethez kapcsol√≥d√≥ dokumentumok k√∂z√∂tt. Ezut√°n a bemeneti vektort √©s a dokumentum vektorokat sz√∂vegg√© alak√≠tva tov√°bb√≠tja az LLM-nek.

### Lek√©rdez√©s

A lek√©rdez√©s akkor t√∂rt√©nik, amikor a rendszer gyorsan megpr√≥b√°lja megtal√°lni azokat a dokumentumokat az indexb≈ël, amelyek megfelelnek a keres√©si felt√©teleknek. A lek√©rdez≈ë c√©lja, hogy olyan dokumentumokat biztos√≠tson, melyek kontextust adnak √©s alapozz√°k az LLM-et az adatokra.

T√∂bbf√©le keres√©si m√≥d l√©tezik az adatb√°zisban:

- **Kulcsszavas keres√©s** ‚Äì sz√∂veges keres√©sekhez

- **Vektor keres√©s** ‚Äì a dokumentumokat be√°gyaz√°s modellek seg√≠ts√©g√©vel alak√≠tja vektor reprezent√°ci√≥v√°, lehet≈ëv√© t√©ve a **szemantikus keres√©st**, amely a szavak jelent√©s√©n alapul. A lek√©rdez√©s a legk√∂zelebbi vektorok alapj√°n t√∂rt√©nik.

- **Hibrid** ‚Äì a kulcsszavas √©s vektor keres√©s kombin√°ci√≥ja.

A kih√≠v√°s akkor jelentkezik, ha nincs a k√©rd√©shez hasonl√≥ v√°lasz az adatb√°zisban, ilyenkor a rendszer a legjobb el√©rhet≈ë inform√°ci√≥t adja vissza. Erre vannak tr√ºkk√∂k, mint p√©ld√°ul relevancia maxim√°lis t√°vols√°g√°nak be√°ll√≠t√°sa vagy hibrid keres√©s alkalmaz√°sa, mely kulcsszavas √©s vektor keres√©st egyar√°nt haszn√°l. Ebben a leck√©ben hibrid keres√©st haszn√°lunk, adatainkat adatkeretben t√°rolva, oszlopokban a darabokkal √©s be√°gyaz√°sokkal.

### Vektor hasonl√≥s√°g

A keres≈ë a tud√°sb√°zisban az √∂sszevethet≈ë be√°gyaz√°sok k√∂z√∂tt keresi a legk√∂zelebbi szomsz√©dokat, mert ezek a legink√°bb hasonl√≥ sz√∂vegek. Ha a felhaszn√°l√≥ k√©rdez, azt el≈ësz√∂r be√°gyazzuk, majd a hasonl√≥ be√°gyaz√°sokkal illesztj√ºk √∂ssze. A leggyakrabban haszn√°lt m√©r≈ësz√°m a vektorok hasonl√≥s√°g√°ra a koszinusz hasonl√≥s√°g, amely a k√©t vektor k√∂z√∂tti sz√∂g alapj√°n m≈±k√∂dik.

M√°s alternat√≠v√°k a hasonl√≥s√°g m√©r√©s√©re az euklideszi t√°vols√°g (a k√©t vektor v√©gpontja k√∂z√∂tti egyenes vonal) vagy a skal√°ris szorzat (a k√©t vektor megfelel≈ë elemeinek szorzatainak √∂sszege).

### Keres√©si index

Lek√©rdez√©s el≈ëtt sz√ºks√©ges keres√©si indexet √©p√≠teni tud√°sb√°zisunkhoz. Az index t√°rolja a be√°gyaz√°sainkat, √©s gyorsan tudja visszaadni a legink√°bb hasonl√≥ darabokat m√©g nagy adatb√°zis eset√©n is. Indexet lok√°lisan √≠gy hozhatsz l√©tre:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Keres√©si index l√©trehoz√°sa
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# Az index lek√©rdez√©s√©hez haszn√°lhatja a kneighbors met√≥dust
distances, indices = nbrs.kneighbors(embeddings)
```

### √öjrarendez√©s

Miut√°n lek√©rdezted az adatb√°zist, sz√ºks√©g lehet az eredm√©nyek relevancia szerinti sorrendez√©s√©re. Egy √∫jrarendez≈ë LLM g√©pi tanul√°st haszn√°l a keres√©si eredm√©nyek relevanci√°j√°nak jav√≠t√°s√°ra √∫gy, hogy a legrelev√°nsabbat helyezi el≈ëre. Az Azure AI Search automatikusan v√©gzi az √∫jrarendez√©st szemantikus √∫jrarendez≈ëvel. √çme egy p√©lda arra, hogyan m≈±k√∂dik az √∫jrarendez√©s a legk√∂zelebbi szomsz√©dok alapj√°n:

```python
# Tal√°ld meg a legink√°bb hasonl√≥ dokumentumokat
distances, indices = nbrs.kneighbors([query_vector])

index = []
# √çrd ki a legink√°bb hasonl√≥ dokumentumokat
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## √ñsszeillesztve

Az utols√≥ l√©p√©s, hogy az LLM-et is bevonjuk a folyamatba, hogy az adatainkra alapozott v√°laszokat kapjunk. Az implement√°ci√≥ a k√∂vetkez≈ë l√©p√©sekb≈ël √°ll:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # A k√©rd√©s √°talak√≠t√°sa lek√©rdez√©si vektorr√°
    query_vector = create_embeddings(user_input)

    # A legink√°bb hasonl√≥ dokumentumok megtal√°l√°sa
    distances, indices = nbrs.kneighbors([query_vector])

    # dokumentumok hozz√°ad√°sa a lek√©rdez√©shez a kontextus biztos√≠t√°s√°hoz
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # az el≈ëzm√©ny √©s a felhaszn√°l√≥i bevitel egyes√≠t√©se
    history.append(user_input)

    # √ºzenetobjektum l√©trehoz√°sa
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # cseveg≈ë befejez√©st haszn√°lva v√°lasz gener√°l√°sa
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Az alkalmaz√°s ki√©rt√©kel√©se

### Ki√©rt√©kel√©si mutat√≥k

- A v√°laszok min≈ës√©ge, hogy term√©szetesnek, foly√©konyan √©s emberinek hangzanak-e

- Adat√°hoz√°s (groundedness): annak √©rt√©kel√©se, hogy a v√°lasz a megadott dokumentumokb√≥l sz√°rmazik-e

- Relevancia: hogy a v√°lasz megegyezik-e √©s kapcsol√≥dik-e a feltett k√©rd√©shez

- Foly√©konys√°g ‚Äì hogy a v√°lasz grammatikaileg √©rtelmes-e

## RAG (Lek√©rdez√©s-gyors√≠tott gener√°l√°s) √©s vektor adatb√°zisok alkalmaz√°si ter√ºletei

Sz√°mos alkalmaz√°si eset van, ahol a funkci√≥h√≠v√°sok jav√≠thatj√°k az alkalmaz√°sodat, p√©ld√°ul:

- K√©rd√©s-v√°lasz rendszerek: √∂sszekapcsolni a v√°llalati adatokat egy chattel, amit az alkalmazottak k√©rd√©sek megv√°laszol√°s√°ra haszn√°lhatnak.

- Aj√°nl√≥rendszerek: olyan rendszer l√©trehoz√°sa, amely a legink√°bb hasonl√≥ √©rt√©keket tal√°lja meg, pl. filmek, √©ttermek stb.

- Chatbot szolg√°ltat√°sok: t√°rolhatod a chat el≈ëzm√©nyeket, √©s szem√©lyre szabhatod a besz√©lget√©st a felhaszn√°l√≥i adatok alapj√°n.

- K√©pes keres√©s vektor be√°gyaz√°sok alapj√°n, hasznos k√©pfelismer√©sn√©l vagy anom√°lia kimutat√°sn√°l.

## √ñsszefoglal√≥

Megismert√ºk a RAG alapjait az adatok hozz√°ad√°s√°t√≥l az alkalmaz√°shoz, a felhaszn√°l√≥i k√©rd√©st≈ël a kimenetig. A RAG kialak√≠t√°s√°t megk√∂nny√≠theted olyan keretrendszerekkel, mint a Semantic Kernel, Langchain vagy Autogen.

## Feladat

A lek√©rdez√©s-gyors√≠tott gener√°l√°s (RAG) tanul√°s√°nak folytat√°s√°hoz √©p√≠tsd meg:

- Egy front-end-et az alkalmaz√°shoz a saj√°t v√°lasztott keretrendszereddel

- Haszn√°lj keretrendszert, p√©ld√°ul LangChain-et vagy Semantic Kernelet, √©s k√©sz√≠tsd √∫jra az alkalmaz√°sodat.

Gratul√°lunk a lecke elv√©gz√©s√©hez üëè.

## A tanul√°s itt nem √©r v√©get, folytasd az utat

A lecke elv√©gz√©se ut√°n n√©zd meg a [Generat√≠v AI tanul√°si gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejleszd a generat√≠v AI ismereteidet!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Jogi nyilatkozat**:
Ezt a dokumentumot az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel ford√≠tottuk le. B√°r igyeksz√ºnk pontoss√°got biztos√≠tani, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n szakmai emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get az ebb≈ël a ford√≠t√°sb√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy f√©lre√©rtelmez√©sek√©rt.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->