<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-07-09T16:18:31+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "hu"
}
-->
# Retrieval Augmented Generation (RAG) √©s vektoralap√∫ adatb√°zisok

[![Retrieval Augmented Generation (RAG) √©s vektoralap√∫ adatb√°zisok](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.hu.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

A keres√©si alkalmaz√°sok leck√©ben r√∂viden megismert√ºk, hogyan lehet saj√°t adatokat integr√°lni a Nagy Nyelvi Modellekbe (LLM-ekbe). Ebben a leck√©ben m√©lyebben belemer√ºl√ºnk abba, hogyan lehet az adatokat megalapozni az LLM alkalmaz√°sban, a folyamat m≈±k√∂d√©s√©be √©s az adatok t√°rol√°s√°nak m√≥dszereibe, bele√©rtve az embeddingeket √©s a sz√∂veget is.

> **Vide√≥ hamarosan el√©rhet≈ë**

## Bevezet√©s

Ebben a leck√©ben a k√∂vetkez≈ë t√©m√°kat t√°rgyaljuk:

- Bevezet√©s a RAG-be, mi az √©s mi√©rt haszn√°lj√°k a mesters√©ges intelligenci√°ban (AI).

- Meg√©rtj√ºk, mik azok a vektoralap√∫ adatb√°zisok, √©s l√©trehozunk egyet az alkalmaz√°sunkhoz.

- Egy gyakorlati p√©lda arra, hogyan integr√°ljuk a RAG-et egy alkalmaz√°sba.

## Tanul√°si c√©lok

A lecke elv√©gz√©se ut√°n k√©pes leszel:

- Elmagyar√°zni a RAG jelent≈ës√©g√©t az adatok lek√©r√©s√©ben √©s feldolgoz√°s√°ban.

- Be√°ll√≠tani egy RAG alkalmaz√°st √©s megalapozni az adataidat egy LLM-ben.

- Hat√©konyan integr√°lni a RAG-et √©s a vektoralap√∫ adatb√°zisokat LLM alkalmaz√°sokban.

## A mi eset√ºnk: LLM-jeink fejleszt√©se saj√°t adatokkal

Ebben a leck√©ben szeretn√©nk hozz√°adni saj√°t jegyzeteinket az oktat√°si startuphoz, hogy a chatbot t√∂bb inform√°ci√≥t kapjon a k√ºl√∂nb√∂z≈ë t√©m√°kr√≥l. A jegyzetek seg√≠ts√©g√©vel a tanul√≥k jobban tudnak tanulni √©s meg√©rteni a k√ºl√∂nb√∂z≈ë t√©mak√∂r√∂ket, √≠gy k√∂nnyebben tudnak k√©sz√ºlni a vizsg√°ikra. A forgat√≥k√∂nyv√ºnk l√©trehoz√°s√°hoz a k√∂vetkez≈ëket haszn√°ljuk:

- `Azure OpenAI:` az LLM, amellyel a chatbotot k√©sz√≠tj√ºk

- `AI for beginners' lesson on Neural Networks:` ez lesz az az adat, amire az LLM-et alapozzuk

- `Azure AI Search` √©s `Azure Cosmos DB:` vektoralap√∫ adatb√°zis az adataink t√°rol√°s√°ra √©s keres√©si index l√©trehoz√°s√°ra

A felhaszn√°l√≥k k√©pesek lesznek gyakorl√≥ kv√≠zeket k√©sz√≠teni a jegyzeteikb≈ël, ism√©tl≈ë k√°rty√°kat l√©trehozni, √©s √∂sszefoglal√≥kat k√©sz√≠teni. Kezdj√ºk azzal, hogy megn√©zz√ºk, mi az a RAG √©s hogyan m≈±k√∂dik:

## Retrieval Augmented Generation (RAG)

Egy LLM-alap√∫ chatbot a felhaszn√°l√≥i k√©rd√©sek feldolgoz√°s√°val v√°laszokat gener√°l. Interakt√≠v m√≥don m≈±k√∂dik, √©s sokf√©le t√©m√°ban k√©pes p√°rbesz√©det folytatni. V√°laszai azonban korl√°tozottak a rendelkez√©sre √°ll√≥ kontextusra √©s az alapul szolg√°l√≥ tan√≠t√≥ adatokra. P√©ld√°ul a GPT-4 tud√°sv√°g√°si pontja 2021 szeptember, vagyis nem ismeri az az√≥ta t√∂rt√©nt esem√©nyeket. Emellett az LLM-ek k√©pz√©s√©hez haszn√°lt adatok nem tartalmaznak bizalmas inform√°ci√≥kat, mint p√©ld√°ul szem√©lyes jegyzetek vagy egy c√©g term√©kk√©zik√∂nyve.

### Hogyan m≈±k√∂dnek a RAG-ek (Retrieval Augmented Generation)

![rajz, amely bemutatja, hogyan m≈±k√∂dnek a RAG-ek](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.hu.png)

Tegy√ºk fel, hogy egy olyan chatbotot szeretn√©l bevezetni, amely a jegyzeteidb≈ël kv√≠zeket k√©sz√≠t, ehhez sz√ºks√©ged lesz egy kapcsolatfelv√©telre a tud√°sb√°zissal. Itt j√∂n k√©pbe a RAG. A RAG-ek a k√∂vetkez≈ëk√©ppen m≈±k√∂dnek:

- **Tud√°sb√°zis:** A lek√©r√©s el≈ëtt ezeket a dokumentumokat be kell olvasni √©s el≈ë kell k√©sz√≠teni, √°ltal√°ban √∫gy, hogy a nagy dokumentumokat kisebb r√©szekre bontj√°k, √°talak√≠tj√°k sz√∂veges embeddingekk√©, majd elt√°rolj√°k egy adatb√°zisban.

- **Felhaszn√°l√≥i k√©rd√©s:** a felhaszn√°l√≥ k√©rd√©st tesz fel

- **Lek√©r√©s:** Amikor a felhaszn√°l√≥ k√©rdez, az embedding modell relev√°ns inform√°ci√≥kat keres a tud√°sb√°zisb√≥l, hogy t√∂bb kontextust adjon, amely be√©p√ºl a promptba.

- **Kiterjesztett gener√°l√°s:** az LLM a lek√©rt adatok alapj√°n jav√≠tja a v√°lasz√°t. Ez lehet≈ëv√© teszi, hogy a v√°lasz ne csak az el≈ëzetesen betan√≠tott adatokon alapuljon, hanem a hozz√°adott kontextusb√≥l sz√°rmaz√≥ relev√°ns inform√°ci√≥kat is felhaszn√°lja. Az LLM ezut√°n v√°laszol a felhaszn√°l√≥ k√©rd√©s√©re.

![rajz, amely bemutatja a RAG architekt√∫r√°j√°t](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.hu.png)

A RAG-ek architekt√∫r√°ja transformer alap√∫, k√©t r√©szb≈ël √°ll: egy encoderb≈ël √©s egy decoderb≈ël. P√©ld√°ul amikor a felhaszn√°l√≥ k√©rdez, a bemeneti sz√∂veget vektorokk√° "k√≥dolj√°k", amelyek a szavak jelent√©s√©t ragadj√°k meg, majd a vektorokat "dek√≥dolj√°k" a dokumentumindexbe, √©s √∫j sz√∂veget gener√°lnak a felhaszn√°l√≥i k√©rd√©s alapj√°n. Az LLM mindk√©t modellt haszn√°lja a kimenet el≈ë√°ll√≠t√°s√°hoz.

A javasolt tanulm√°ny szerint k√©t megk√∂zel√≠t√©s l√©tezik a RAG megval√≥s√≠t√°s√°ra: [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst):

- **_RAG-Sequence_**: a lek√©rt dokumentumokat haszn√°lja a legjobb v√°lasz el≈ërejelz√©s√©re a felhaszn√°l√≥i k√©rd√©sre

- **RAG-Token**: a dokumentumokat a k√∂vetkez≈ë token gener√°l√°s√°hoz haszn√°lja, majd lek√©ri ≈ëket a v√°laszhoz

### Mi√©rt √©rdemes RAG-et haszn√°lni?

- **Inform√°ci√≥gazdags√°g:** biztos√≠tja, hogy a sz√∂veges v√°laszok naprak√©szek √©s aktu√°lisak legyenek. Ez√°ltal jav√≠tja a teljes√≠tm√©nyt az adott szakter√ºleti feladatokban, mivel hozz√°f√©r a bels≈ë tud√°sb√°zishoz.

- Cs√∂kkenti a kital√°l√°sokat az√°ltal, hogy **ellen≈ërizhet≈ë adatokat** haszn√°l a tud√°sb√°zisb√≥l, hogy kontextust adjon a felhaszn√°l√≥i k√©rd√©sekhez.

- **K√∂lts√©ghat√©kony**, mivel gazdas√°gosabb, mint egy LLM finomhangol√°sa.

## Tud√°sb√°zis l√©trehoz√°sa

Az alkalmaz√°sunk szem√©lyes adatokon alapul, azaz az AI For Beginners tananyag√°nak Neur√°lis H√°l√≥zat leck√©j√©n.

### Vektoralap√∫ adatb√°zisok

A vektoralap√∫ adatb√°zis, ellent√©tben a hagyom√°nyos adatb√°zisokkal, egy speci√°lis adatb√°zis, amely be√°gyazott vektorok t√°rol√°s√°ra, kezel√©s√©re √©s keres√©s√©re szolg√°l. Sz√°m√©rt√©kes reprezent√°ci√≥kat t√°rol dokumentumokr√≥l. Az adatok numerikus embeddingekk√© bont√°sa megk√∂nny√≠ti az AI rendszer sz√°m√°ra az adatok meg√©rt√©s√©t √©s feldolgoz√°s√°t.

Az embeddingeket vektoralap√∫ adatb√°zisokban t√°roljuk, mivel az LLM-eknek korl√°tozott a bemeneti tokenek sz√°ma. Mivel nem lehet az eg√©sz embeddinget egyszerre √°tadni az LLM-nek, darabokra kell bontani, √©s amikor a felhaszn√°l√≥ k√©rdez, a k√©rd√©shez legink√°bb hasonl√≥ embeddingeket adjuk vissza a prompttal egy√ºtt. A darabol√°s cs√∂kkenti a tokenek sz√°m√°t, √≠gy a k√∂lts√©geket is.

N√©h√°ny n√©pszer≈± vektoralap√∫ adatb√°zis: Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant √©s DeepLake. Azure Cosmos DB modellt az Azure CLI seg√≠ts√©g√©vel hozhatsz l√©tre a k√∂vetkez≈ë paranccsal:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Sz√∂vegb≈ël embeddingekbe

Miel≈ëtt t√°roln√°nk az adatokat, vektorembeddingekk√© kell alak√≠tani ≈ëket. Ha nagy dokumentumokkal vagy hossz√∫ sz√∂vegekkel dolgozol, darabolhatod ≈ëket a v√°rhat√≥ lek√©rdez√©sek alapj√°n. A darabol√°s t√∂rt√©nhet mondatszinten vagy bekezd√©sszinten. Mivel a darabok jelent√©s√©t a k√∂rnyez≈ë szavak adj√°k, adhatsz hozz√°juk tov√°bbi kontextust, p√©ld√°ul a dokumentum c√≠m√©t vagy n√©h√°ny sz√∂veget a darab el≈ëtt vagy ut√°n. Az adatokat √≠gy darabolhatod:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

A darabol√°s ut√°n k√ºl√∂nb√∂z≈ë embedding modellekkel √°gyazhatod be a sz√∂veget. Haszn√°lhatsz p√©ld√°ul word2vec-et, OpenAI ada-002 modellj√©t, Azure Computer Vision-t √©s m√©g sok m√°st. A modell kiv√°laszt√°sa att√≥l f√ºgg, milyen nyelvet haszn√°lsz, milyen t√≠pus√∫ tartalmat k√≥dolsz (sz√∂veg/k√©p/hang), mekkora bemenetet k√©pes kezelni √©s milyen hossz√∫ embeddinget ad vissza.

Egy p√©lda az OpenAI `text-embedding-ada-002` modellj√©vel k√©sz√ºlt embeddingre:
![a "cat" sz√≥ embeddingje](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.hu.png)

## Lek√©r√©s √©s vektoros keres√©s

Amikor a felhaszn√°l√≥ k√©rdez, a lek√©r≈ë a k√©rd√©st vektorr√° alak√≠tja a lek√©rdez√©senk√≥der seg√≠ts√©g√©vel, majd √°tkutatja a dokumentumkeres≈ë index√ºnket a relev√°ns vektorok ut√°n, amelyek kapcsol√≥dnak a bemenethez. Ezut√°n a bemeneti √©s dokumentumvektorokat sz√∂vegg√© alak√≠tja, √©s √°tadja az LLM-nek.

### Lek√©r√©s

A lek√©r√©s akkor t√∂rt√©nik, amikor a rendszer gyorsan megpr√≥b√°lja megtal√°lni azokat a dokumentumokat az indexben, amelyek megfelelnek a keres√©si felt√©teleknek. A lek√©r≈ë c√©lja, hogy olyan dokumentumokat szerezzen, amelyek kontextust adnak √©s megalapozz√°k az LLM-et az adataiddal.

T√∂bbf√©le keres√©si m√≥d l√©tezik az adatb√°zisban, p√©ld√°ul:

- **Kulcsszavas keres√©s** ‚Äì sz√∂veges keres√©sekhez

- **Szemantikus keres√©s** ‚Äì a szavak jelent√©s√©t haszn√°lja

- **Vektoros keres√©s** ‚Äì a dokumentumokat embedding modellekkel vektorokk√° alak√≠tja. A lek√©r√©s azokat a dokumentumokat keresi, amelyek vektorai legink√°bb hasonl√≠tanak a felhaszn√°l√≥i k√©rd√©s vektor√°hoz.

- **Hibrid** ‚Äì a kulcsszavas √©s vektoros keres√©s kombin√°ci√≥ja.

A lek√©r√©s kih√≠v√°sa, ha nincs hasonl√≥ v√°lasz az adatb√°zisban, a rendszer a legjobb el√©rhet≈ë inform√°ci√≥t adja vissza. Ilyenkor be√°ll√≠that√≥ a relevancia maxim√°lis t√°vols√°ga, vagy haszn√°lhat√≥ hibrid keres√©s, amely a kulcsszavas √©s vektoros keres√©st √∂tv√∂zi. Ebben a leck√©ben hibrid keres√©st haszn√°lunk, azaz a vektoros √©s kulcsszavas keres√©s kombin√°ci√≥j√°t. Az adatokat egy dataframe-ben t√°roljuk, amely oszlopokban tartalmazza a darabokat √©s az embeddingeket.

### Vektoros hasonl√≥s√°g

A lek√©r≈ë a tud√°sb√°zisban olyan embeddingeket keres, amelyek k√∂zel vannak egym√°shoz, azaz a legk√∂zelebbi szomsz√©dokat, mert ezek hasonl√≥ sz√∂vegek. Ha a felhaszn√°l√≥ k√©rd√©st tesz fel, azt el≈ësz√∂r embeddingg√© alak√≠tjuk, majd √∂sszevetj√ºk a hasonl√≥ embeddingekkel. A leggyakrabban haszn√°lt m√©r≈ësz√°m a koszinusz hasonl√≥s√°g, amely a k√©t vektor k√∂z√∂tti sz√∂get m√©ri.

M√°s alternat√≠v√°k a hasonl√≥s√°g m√©r√©s√©re: az euklideszi t√°vols√°g, amely a vektorok v√©gpontjai k√∂z√∂tti egyenes t√°vols√°g, illetve a skal√°ris szorzat, amely a k√©t vektor megfelel≈ë elemeinek szorzatainak √∂sszeg√©t m√©ri.

### Keres√©si index

A lek√©r√©s el≈ëtt l√©tre kell hoznunk egy keres√©si indexet a tud√°sb√°zisunkhoz. Az index t√°rolja az embeddingeket, √©s gyorsan vissza tudja adni a legink√°bb hasonl√≥ darabokat m√©g nagy adatb√°zis eset√©n is. Az indexet helyben √≠gy hozhatjuk l√©tre:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### √öjrarendez√©s (re-ranking)

Miut√°n lek√©rdezt√ºk az adatb√°zist, sz√ºks√©g lehet az eredm√©nyek relevancia szerinti rendez√©s√©re. Egy √∫jrarendez≈ë LLM g√©pi tanul√°st haszn√°l, hogy jav√≠tsa a keres√©si eredm√©nyek relevanci√°j√°t, √©s a legrelev√°nsabbakat el≈ëre sorolja. Az Azure AI Search automatikusan elv√©gzi az √∫jrarendez√©st szemantikus √∫jrarendez≈ëvel. √çme egy p√©lda arra, hogyan m≈±k√∂dik az √∫jrarendez√©s a legk√∂zelebbi szomsz√©dok alapj√°n:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Mindezt √∂sszeillesztve

Az utols√≥ l√©p√©s, hogy az LLM-et is bevonjuk, hogy olyan v√°laszokat kapjunk, amelyek az adatainkon alapulnak. Ezt √≠gy val√≥s√≠thatjuk meg:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Az alkalmaz√°s √©rt√©kel√©se

### √ârt√©kel√©si mutat√≥k

- A v√°laszok min≈ës√©ge: term√©szetes, foly√©kony √©s emberi hangz√°s√∫ legyen

- Az adatok megalapozotts√°ga: √©rt√©kelni, hogy a v√°lasz a megadott dokumentumokb√≥l sz√°rmazik-e

- Relevancia: a v√°lasz illeszkedik-e √©s kapcsol√≥dik-e a feltett k√©rd√©shez

- Foly√©konys√°g: a v√°lasz nyelvtanilag √©rtelmes-e

## RAG (Retrieval Augmented Generation) √©s vektoralap√∫ adatb√°zisok haszn√°lati esetei

Sz√°mos k√ºl√∂nb√∂z≈ë esetben jav√≠thatj√°k az alkalmaz√°sodat a funkci√≥h√≠v√°sok, p√©ld√°ul:

- K√©rd√©s-v√°lasz rendszerek: a c√©ges adatokat alapozhatod egy chatre, amelyet az alkalmazottak k√©rd√©sek feltev√©s√©re haszn√°lhatnak.

- Aj√°nl√≥rendszerek: olyan rendszert hozhatsz l√©tre, amely a legink√°bb hasonl√≥ √©rt√©keket p√°ros√≠tja √∂ssze, pl. filmek, √©ttermek √©s m√©g sok m√°s.

- Chatbot szolg√°ltat√°sok: t√°rolhatod a besz√©lget√©si el≈ëzm√©nyeket, √©s szem√©lyre szabhatod a p√°rbesz√©det a felhaszn√°l√≥i adatok alapj√°n.

- K√©pkeres√©s vektorembeddingek alapj√°n, hasznos k√©pfelismer√©shez √©s anom√°lia√©szlel√©shez.

## √ñsszefoglal√°s

√Åttekintett√ºk a RAG alapvet≈ë ter√ºleteit, az adat hozz√°ad√°s√°t az alkalmaz√°shoz, a felhaszn√°l√≥i lek√©rdez√©st √©s a kimenetet. A RAG l√©trehoz√°s√°nak egyszer≈±s√≠t√©s√©re haszn√°lhatsz keretrendszereket, mint a Semantic Kernel, Langchain vagy Autogen.

## Feladat

A Retrieval Augmented Generation (RAG) tov√°bbi tanul√°s√°hoz √©p√≠tsd meg:

- Egy front-endet az alkalmaz√°shoz a v√°lasztott keretrendszerrel

- Haszn√°lj egy keretrendszert, p√©ld√°ul LangChain-et vagy Semantic Kernel-t, √©s √©p√≠tsd √∫jra az alkalmaz√°sodat.

Gratul√°lunk a lecke elv√©gz√©s√©hez üëè.

## A tanul√°s itt nem √©r v√©get, folytasd az utat

A lecke elv√©gz√©se ut√°n n√©zd meg a [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) gy≈±jtem√©ny√ºnket, hogy tov√°bb fejleszd generat√≠v AI ismereteidet!

**Jogi nyilatkozat**:  
Ez a dokumentum az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel k√©sz√ºlt. B√°r a pontoss√°gra t√∂reksz√ºnk, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n szakmai, emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.