{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI modellek finomhangolása\n",
    "\n",
    "Ez a jegyzetfüzet az Open AI [Finomhangolás](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) dokumentációjában található aktuális útmutatás alapján készült.\n",
    "\n",
    "A finomhangolás javítja az alapmodellek teljesítményét az alkalmazásod számára azáltal, hogy további, az adott felhasználási esetre vagy helyzetre releváns adatokkal és kontextussal újratanítjuk azt. Érdemes megjegyezni, hogy a prompt tervezési technikák, mint a _few shot learning_ és a _retrieval augmented generation_ lehetővé teszik az alapértelmezett prompt releváns adatokkal való kiegészítését a minőség javítása érdekében. Ezek a megközelítések azonban korlátozottak a célzott alapmodell maximális tokenablakának mérete által.\n",
    "\n",
    "A finomhangolással valójában magát a modellt tanítjuk újra a szükséges adatokkal (ami lehetővé teszi, hogy sokkal több példát használjunk, mint amennyi a maximális tokenablakba belefér) – és egy _egyedi_ verzióját telepítjük a modellnek, amelynek már nincs szüksége példákra az inferencia idején. Ez nemcsak a prompt tervezés hatékonyságát javítja (nagyobb rugalmasságot ad a tokenablak más célokra való használatában), hanem potenciálisan a költségeinket is csökkenti (azáltal, hogy kevesebb tokent kell elküldenünk a modellnek az inferencia során).\n",
    "\n",
    "A finomhangolás 4 lépésből áll:\n",
    "1. Készítsd elő a tanító adatokat és töltsd fel azokat.\n",
    "1. Futtasd a tanítási feladatot, hogy kapj egy finomhangolt modellt.\n",
    "1. Értékeld ki a finomhangolt modellt, és ismételd a minőség javítása érdekében.\n",
    "1. Telepítsd a finomhangolt modellt az inferencia céljára, ha elégedett vagy.\n",
    "\n",
    "Fontos megjegyezni, hogy nem minden alapmodell támogatja a finomhangolást – a legfrissebb információkért [ellenőrizd az OpenAI dokumentációját](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst). Korábban finomhangolt modellt is finomhangolhatsz. Ebben a bemutatóban a `gpt-35-turbo` modellt használjuk célmodellként a finomhangoláshoz.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 lépés: Készítse elő az adatkészletét\n",
    "\n",
    "Építsünk egy chatbotot, amely segít megérteni az elemek periódusos rendszerét azáltal, hogy egy limerikkel válaszol egy elemről feltett kérdésekre. Ebben az _egyszerű_ bemutatóban csak egy adatkészletet hozunk létre a modell betanításához néhány minta válasszal, amelyek bemutatják az adatok elvárt formátumát. Egy valós használati esetben sokkal több példát kell létrehozni az adatkészlethez. Lehet, hogy egy nyílt adatkészletet is használhat (az alkalmazási területének megfelelően), ha létezik ilyen, és átalakíthatja azt a finomhangoláshoz való használathoz.\n",
    "\n",
    "Mivel a `gpt-35-turbo`-ra koncentrálunk, és egyetlen körös választ (chat befejezést) keresünk, példákat hozhatunk létre [ebben a javasolt formátumban](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), amely tükrözi az OpenAI chat befejezési követelményeit. Ha többkörös beszélgetési tartalomra számít, akkor a [többkörös példa formátumot](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) használná, amely tartalmaz egy `weight` paramétert, hogy jelezze, mely üzeneteket kell (vagy nem kell) használni a finomhangolási folyamatban.\n",
    "\n",
    "Itt a bemutatóhoz az egyszerűbb, egykörös formátumot fogjuk használni. Az adatok [jsonl formátumban](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) vannak, egy rekord soronként, mindegyik JSON-formátumú objektumként ábrázolva. Az alábbi részlet 2 rekordot mutat mintaként – a teljes mintakészletért (10 példa) lásd a [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) fájlt, amelyet a finomhangolási bemutatóhoz használunk. **Megjegyzés:** Minden rekordot _egy sorban_ kell definiálni (nem szabad több sorra bontani, mint ahogy az egy formázott JSON fájlban szokásos).\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Egy valós használati esetben sokkal nagyobb példakészletre lesz szükség a jó eredményekhez – a kompromisszum a válaszok minősége és a finomhangolás ideje/költsége között lesz. Mi egy kis készletet használunk, hogy gyorsan befejezhessük a finomhangolást, és bemutathassuk a folyamatot. Lásd [ezt az OpenAI Cookbook példát](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) egy összetettebb finomhangolási bemutatóért.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 1.2 lépés Adatkészlet feltöltése\n",
    "\n",
    "Töltsd fel az adatokat a Files API segítségével [ahogyan itt le van írva](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Ne feledd, hogy a kód futtatásához először a következő lépéseket kell elvégezned:\n",
    " - Telepítetted az `openai` Python csomagot (győződj meg róla, hogy a verzió >=0.28.0 a legújabb funkciókhoz)\n",
    " - Beállítottad az `OPENAI_API_KEY` környezeti változót az OpenAI API kulcsodra\n",
    "További információért lásd a kurzushoz biztosított [Beállítási útmutatót](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "Most futtasd a kódot, hogy létrehozz egy feltöltésre alkalmas fájlt a helyi JSONL fájlodból.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.1 lépés: Hozza létre a finomhangolási feladatot az SDK-val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.2. lépés: A munka állapotának ellenőrzése\n",
    "\n",
    "Íme néhány dolog, amit a `client.fine_tuning.jobs` API-val tehetsz:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Az utolsó n finomhangolási munka listázása\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Egy adott finomhangolási munka részleteinek lekérése\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Egy finomhangolási munka megszakítása\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Legfeljebb n esemény listázása a munkából\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "A folyamat első lépése a _tanítófájl érvényesítése_, hogy megbizonyosodjunk arról, hogy az adatok megfelelő formátumban vannak.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 2.3 lépés: Események követése a haladás nyomon követéséhez\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 lépés: Állapot megtekintése az OpenAI irányítópulton\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A státuszt megtekintheti az OpenAI weboldalán is, a platform _Finomhangolás_ szekciójának felfedezésével. Ez megmutatja az aktuális feladat állapotát, és lehetővé teszi a korábbi feladatvégrehajtások történetének nyomon követését is. Ebben a képernyőképen látható, hogy az előző futás sikertelen volt, míg a második futás sikeresen lezajlott. Kontextusként, ez akkor történt, amikor az első futás egy hibásan formázott rekordokat tartalmazó JSON fájlt használt – miután ezt javították, a második futás sikeresen befejeződött, és a modellt használatra elérhetővé tette. \n",
    "\n",
    "![Finomhangolási feladat állapota](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.hu.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A státuszüzeneteket és a metrikákat is megtekintheti, ha tovább görget a vizuális irányítópulton, ahogy az alább látható:\n",
    "\n",
    "| Üzenetek | Metrikák |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.hu.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.hu.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.1 lépés: Azonosító lekérése és a finomhangolt modell tesztelése kódban\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3.2 lépés: Finomhangolt modell betöltése és tesztelése a Playgroundban\n",
    "\n",
    "Most kétféleképpen tesztelheti a finomhangolt modellt. Először is meglátogathatja a Playgroundot, és a Modellek legördülő menüből kiválaszthatja az újonnan finomhangolt modelljét a listából. A másik lehetőség a Finomhangolás panelen megjelenő „Playground” opció használata (lásd a fenti képernyőképet), amely elindítja a következő _összehasonlító_ nézetet, amely az alapmodellt és a finomhangolt modell verzióit egymás mellett mutatja a gyors értékeléshez.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.hu.png)\n",
    "\n",
    "Egyszerűen töltse ki a rendszerkörnyezetet, amelyet a tanító adatokban használt, és adja meg a tesztkérdését. Észre fogja venni, hogy mindkét oldalon frissül az azonos kontextus és kérdés. Futtassa le az összehasonlítást, és látni fogja a különbséget a kimenetek között. _Figyelje meg, hogy a finomhangolt modell hogyan jeleníti meg a választ az Ön példáiban megadott formátumban, míg az alapmodell egyszerűen követi a rendszerparancsot_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.hu.png)\n",
    "\n",
    "Észre fogja venni, hogy az összehasonlítás a tokenek számát is megadja mindkét modell esetében, valamint a lekérdezéshez szükséges időt. **Ez a konkrét példa egyszerűsített, hogy bemutassa a folyamatot, de nem tükröz valós adatokat vagy helyzetet**. Észreveheti, hogy mindkét minta ugyanannyi tokent mutat (a rendszerkörnyezet és a felhasználói kérés azonos), miközben a finomhangolt modell több időt vesz igénybe a lekérdezéshez (egyedi modell).\n",
    "\n",
    "Valós helyzetekben nem egy ilyen játékpéldát fog használni, hanem valós adatokon finomhangol (pl. termékkatalógus ügyfélszolgálathoz), ahol a válasz minősége sokkal nyilvánvalóbb lesz. _Ebben a_ kontextusban az alapmodelllel egyenértékű válaszminőség eléréséhez több egyedi prompttervezésre lesz szükség, ami növeli a tokenhasználatot és potenciálisan a lekérdezéshez szükséges feldolgozási időt. _Ha ki szeretné próbálni, nézze meg az OpenAI Cookbook finomhangolási példáit._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Jogi nyilatkozat**:\nEzt a dokumentumot az AI fordító szolgáltatás, a [Co-op Translator](https://github.com/Azure/co-op-translator) segítségével fordítottuk le. Bár a pontosságra törekszünk, kérjük, vegye figyelembe, hogy az automatikus fordítások hibákat vagy pontatlanságokat tartalmazhatnak. Az eredeti dokumentum az anyanyelvén tekintendő hiteles forrásnak. Fontos információk esetén szakmai, emberi fordítást javaslunk. Nem vállalunk felelősséget a fordítás használatából eredő félreértésekért vagy félreértelmezésekért.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:18:56+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "hu"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}