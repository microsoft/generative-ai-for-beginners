<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-05-20T07:56:09+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "hu"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.8487555c3e3225eefc1dc84e72c8e00bce1ee76db867a080628fb0fbb04aa0d2.hu.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Az LLM finomhangol√°sa

A generat√≠v AI alkalmaz√°sok l√©trehoz√°sa nagy nyelvi modellek seg√≠ts√©g√©vel √∫j kih√≠v√°sokat jelent. Az egyik f≈ë probl√©ma a v√°laszok min≈ës√©g√©nek (pontoss√°g √©s relevancia) biztos√≠t√°sa a modell √°ltal gener√°lt tartalom eset√©ben egy adott felhaszn√°l√≥i k√©r√©sre. Az el≈ëz≈ë leck√©kben olyan technik√°kat t√°rgyaltunk, mint a prompt m√©rn√∂ks√©g √©s a visszakeres√©ssel b≈ëv√≠tett gener√°ci√≥, amelyek a probl√©m√°t azzal pr√≥b√°lj√°k megoldani, hogy _m√≥dos√≠tj√°k a megl√©v≈ë modell bemeneti k√©r√©s√©t_.

A mai leck√©ben egy harmadik technik√°t, a **finomhangol√°st** t√°rgyaljuk, amely a kih√≠v√°st azzal pr√≥b√°lja megoldani, hogy _√∫jra betan√≠tja mag√°t a modellt_ tov√°bbi adatokkal. N√©zz√ºk meg a r√©szleteket.

## Tanul√°si c√©lok

Ez a lecke bevezeti a finomhangol√°s fogalm√°t az el≈ëre betan√≠tott nyelvi modellek eset√©ben, megvizsg√°lja ennek az elj√°r√°snak az el≈ënyeit √©s kih√≠v√°sait, valamint √∫tmutat√°st ad arra vonatkoz√≥an, hogy mikor √©s hogyan √©rdemes finomhangol√°st alkalmazni a generat√≠v AI modellek teljes√≠tm√©ny√©nek jav√≠t√°sa √©rdek√©ben.

A lecke v√©g√©re k√©pesnek kell lenned megv√°laszolni a k√∂vetkez≈ë k√©rd√©seket:

- Mi a finomhangol√°s a nyelvi modellek eset√©ben?
- Mikor √©s mi√©rt hasznos a finomhangol√°s?
- Hogyan tudom finomhangolni az el≈ëre betan√≠tott modellt?
- Mik a finomhangol√°s korl√°tai?

K√©szen √°llsz? Kezdj√ºk el.

## Illusztr√°lt √∫tmutat√≥

Szeretn√©l √°tfog√≥ k√©pet kapni arr√≥l, amit t√°rgyalni fogunk, miel≈ëtt belemer√ºl√ºnk a r√©szletekbe? N√©zd meg ezt az illusztr√°lt √∫tmutat√≥t, amely bemutatja a tanul√°si folyamatot ebben a leck√©ben - a finomhangol√°s alapvet≈ë fogalmainak √©s motiv√°ci√≥j√°nak megismer√©s√©t≈ël kezdve a folyamat √©s a legjobb gyakorlatok meg√©rt√©s√©ig a finomhangol√°si feladat v√©grehajt√°s√°hoz. Ez egy izgalmas t√©ma a felfedez√©shez, ez√©rt ne felejtsd el megn√©zni a [Forr√°sok](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt, ahol tov√°bbi linkeket tal√°lsz az √∂n√°ll√≥ tanul√°si utad t√°mogat√°s√°hoz!

![Illusztr√°lt √∫tmutat√≥ a nyelvi modellek finomhangol√°s√°hoz](../../../translated_images/18-fine-tuning-sketchnote.92733966235199dd260184b1aae3a84b877c7496bc872d8e63ad6fa2dd96bafc.hu.png)

## Mi a finomhangol√°s a nyelvi modellek eset√©ben?

Defin√≠ci√≥ szerint a nagy nyelvi modellek _el≈ëre betan√≠tottak_ nagy mennyis√©g≈±, k√ºl√∂nb√∂z≈ë forr√°sokb√≥l, k√∂zt√ºk az internetr≈ël sz√°rmaz√≥ sz√∂vegeken. Ahogy az el≈ëz≈ë leck√©kben megtanultuk, olyan technik√°kra van sz√ºks√©g√ºnk, mint a _prompt m√©rn√∂ks√©g_ √©s a _visszakeres√©ssel b≈ëv√≠tett gener√°ci√≥_, hogy jav√≠tsuk a modell v√°laszainak min≈ës√©g√©t a felhaszn√°l√≥i k√©rd√©sekre ("prompts").

Egy n√©pszer≈± prompt m√©rn√∂ks√©gi technika az, hogy a modellnek t√∂bb √∫tmutat√°st adunk arra vonatkoz√≥an, hogy mi v√°rhat√≥ a v√°laszban, ak√°r _utas√≠t√°sok_ (explicit √∫tmutat√°s) ad√°s√°val, ak√°r _n√©h√°ny p√©lda_ bemutat√°s√°val (implicit √∫tmutat√°s). Ezt _few-shot tanul√°snak_ nevezik, de k√©t korl√°tja van:

- A modell token korl√°tai korl√°tozhatj√°k a megadhat√≥ p√©ld√°k sz√°m√°t, √©s cs√∂kkenthetik a hat√©konys√°got.
- A modell token k√∂lts√©gei dr√°g√°v√° tehetik a p√©ld√°k hozz√°ad√°s√°t minden k√©r√©shez, √©s korl√°tozhatj√°k a rugalmass√°got.

A finomhangol√°s egy gyakori gyakorlat a g√©pi tanul√°si rendszerekben, amikor egy el≈ëre betan√≠tott modellt √∫j adatokkal √∫jra betan√≠tunk, hogy jav√≠tsuk a teljes√≠tm√©ny√©t egy adott feladaton. A nyelvi modellek kontextus√°ban a finomhangol√°s sor√°n a _kiv√°lasztott p√©ld√°k egy k√©szlet√©t haszn√°ljuk egy adott feladatra vagy alkalmaz√°si ter√ºletre_, hogy l√©trehozzunk egy **egyedi modellt**, amely pontosabb √©s relev√°nsabb lehet az adott feladathoz vagy ter√ºlethez. A finomhangol√°s egyik mell√©khat√°sa az is lehet, hogy cs√∂kkenti a sz√ºks√©ges p√©ld√°k sz√°m√°t a few-shot tanul√°shoz - cs√∂kkentve a token haszn√°latot √©s a kapcsol√≥d√≥ k√∂lts√©geket.

## Mikor √©s mi√©rt kell finomhangolni a modelleket?

Ebben a kontextusban, amikor a finomhangol√°sr√≥l besz√©l√ºnk, a **fel√ºgyelt** finomhangol√°sra utalunk, ahol az √∫jratan√≠t√°s **√∫j adatok hozz√°ad√°s√°val** t√∂rt√©nik, amelyek nem voltak r√©szei az eredeti tan√≠t√≥ adathalmaznak. Ez elt√©r az ellen≈ërizetlen finomhangol√°si megk√∂zel√≠t√©st≈ël, ahol a modellt az eredeti adatokon √∫jratan√≠tj√°k, de m√°s hiperparam√©terekkel.

A legfontosabb, amit meg kell jegyezni, hogy a finomhangol√°s egy fejlett technika, amely bizonyos szint≈± szak√©rtelmet ig√©nyel a k√≠v√°nt eredm√©nyek el√©r√©s√©hez. Ha nem megfelel≈ëen hajtj√°k v√©gre, akkor nem biztos, hogy a v√°rt javul√°sokat hozza, s≈ët, ak√°r ronthatja is a modell teljes√≠tm√©ny√©t a c√©lzott ter√ºleten.

Teh√°t miel≈ëtt megtanuln√°d, "hogyan" kell finomhangolni a nyelvi modelleket, tudnod kell, "mi√©rt" kell ezt az utat v√°lasztani, √©s "mikor" kell elkezdeni a finomhangol√°si folyamatot. Kezdd azzal, hogy felteszed magadnak ezeket a k√©rd√©seket:

- **Felhaszn√°l√°si eset**: Mi a _felhaszn√°l√°si eseted_ a finomhangol√°sra? Milyen szempontot szeretn√©l jav√≠tani a jelenlegi el≈ëre betan√≠tott modellen?
- **Alternat√≠v√°k**: Pr√≥b√°lt√°l m√°s technik√°kat a k√≠v√°nt eredm√©nyek el√©r√©s√©hez? Haszn√°ld ≈ëket √∂sszehasonl√≠t√°si alapk√©nt.
  - Prompt m√©rn√∂ks√©g: Pr√≥b√°lj ki technik√°kat, mint p√©ld√°ul a few-shot k√©rdez√©s relev√°ns v√°lasz p√©ld√°kkal. √ârt√©keld a v√°laszok min≈ës√©g√©t.
  - Visszakeres√©ssel b≈ëv√≠tett gener√°ci√≥: Pr√≥b√°ld meg kieg√©sz√≠teni a k√©rd√©seket a keres√©si adatok √°ltal visszakeresett eredm√©nyekkel. √ârt√©keld a v√°laszok min≈ës√©g√©t.
- **K√∂lts√©gek**: Azonos√≠tottad a finomhangol√°s k√∂lts√©geit?
  - Hangolhat√≥s√°g - el√©rhet≈ë-e az el≈ëre betan√≠tott modell finomhangol√°sra?
  - Er≈ëfesz√≠t√©s - a tan√≠t√≥ adatok el≈ëk√©sz√≠t√©s√©re, a modell √©rt√©kel√©s√©re √©s finom√≠t√°s√°ra.
  - Sz√°m√≠t√°s - a finomhangol√°si feladatok futtat√°s√°ra √©s a finomhangolt modell telep√≠t√©s√©re
  - Adatok - hozz√°f√©r√©s elegend≈ë min≈ës√©g≈± p√©ld√°khoz a finomhangol√°si hat√°s √©rdek√©ben
- **El≈ëny√∂k**: Meger≈ës√≠tetted a finomhangol√°s el≈ënyeit?
  - Min≈ës√©g - t√∫lsz√°rnyalta-e a finomhangolt modell az alapmodellt?
  - K√∂lts√©g - cs√∂kkenti-e a token haszn√°latot az egyszer≈±s√≠tett k√©rd√©sekkel?
  - Kiterjeszthet≈ës√©g - √∫jra felhaszn√°lhat√≥-e az alapmodell √∫j ter√ºletekre?

Ezekre a k√©rd√©sekre v√°laszolva el tudod d√∂nteni, hogy a finomhangol√°s megfelel≈ë megk√∂zel√≠t√©s-e a felhaszn√°l√°si esetedhez. Ide√°lis esetben a megk√∂zel√≠t√©s csak akkor √©rv√©nyes, ha az el≈ëny√∂k meghaladj√°k a k√∂lts√©geket. Miut√°n eld√∂nt√∂tted, hogy folytatod, itt az ideje, hogy gondolkodj azon, _hogyan_ tudod finomhangolni az el≈ëre betan√≠tott modellt.

Szeretn√©l t√∂bb betekint√©st kapni a d√∂nt√©shozatali folyamatba? N√©zd meg a [Finomhangolni vagy nem finomhangolni](https://www.youtube.com/watch?v=0Jo-z-MFxJs) c√≠m≈± vide√≥t.

## Hogyan tudjuk finomhangolni az el≈ëre betan√≠tott modellt?

Az el≈ëre betan√≠tott modell finomhangol√°s√°hoz sz√ºks√©ged lesz:

- egy el≈ëre betan√≠tott modellre, amelyet finomhangolhatsz
- egy adathalmazra, amelyet a finomhangol√°shoz haszn√°lhatsz
- egy k√©pz√©si k√∂rnyezetre a finomhangol√°si feladat futtat√°s√°hoz
- egy hosztol√≥ k√∂rnyezetre a finomhangolt modell telep√≠t√©s√©hez

## Finomhangol√°s akci√≥ban

Az al√°bbi forr√°sok l√©p√©sr≈ël-l√©p√©sre bemutatj√°k, hogyan v√©gezhetsz el egy val√≥s p√©ld√°t egy kiv√°lasztott modell √©s egy gondosan √∂ssze√°ll√≠tott adathalmaz seg√≠ts√©g√©vel. A bemutat√≥k v√©grehajt√°s√°hoz sz√ºks√©ged lesz egy fi√≥kra a konkr√©t szolg√°ltat√≥n√°l, valamint hozz√°f√©r√©sre a relev√°ns modellhez √©s adathalmazokhoz.

| Szolg√°ltat√≥  | Bemutat√≥                                                                                                                                                                       | Le√≠r√°s                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Hogyan finomhangoljuk a chat modelleket](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo` modellt egy adott ter√ºletre ("recept asszisztens") azzal, hogy el≈ëk√©sz√≠ted a tan√≠t√≥ adatokat, futtatod a finomhangol√°si feladatot, √©s haszn√°lod a finomhangolt modellt az el≈ërejelz√©shez.                                                                                                                                                                                                                                              |
| Azure OpenAI | [GPT 3.5 Turbo finomhangol√°si bemutat√≥](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo-0613` modellt **az Azure-on** azzal, hogy l√©p√©seket teszel a tan√≠t√≥ adatok l√©trehoz√°s√°ra √©s felt√∂lt√©s√©re, futtatod a finomhangol√°si feladatot. Telep√≠tsd √©s haszn√°ld az √∫j modellt.                                                                                                                                                                                                                                                                 |
| Hugging Face | [LLM-ek finomhangol√°sa a Hugging Face-szel](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Ez a blogbejegyz√©s bemutatja, hogyan finomhangolj egy _ny√≠lt LLM-et_ (p√©ld√°ul: `CodeLlama 7B`) a [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) k√∂nyvt√°r √©s a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) seg√≠ts√©g√©vel, ny√≠lt [adathalmazok](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) felhaszn√°l√°s√°val a Hugging Face-en. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [LLM-ek finomhangol√°sa az AutoTrain-nal](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | Az AutoTrain (vagy AutoTrain Advanced) egy Python k√∂nyvt√°r, amelyet a Hugging Face fejlesztett ki, √©s amely lehet≈ëv√© teszi a finomhangol√°st sokf√©le feladatra, bele√©rtve az LLM finomhangol√°st. Az AutoTrain egy k√≥dmentes megold√°s, √©s a finomhangol√°s elv√©gezhet≈ë saj√°t felh≈ëben, a Hugging Face Spaces-en vagy helyileg. T√°mogatja mind a webalap√∫ GUI-t, mind a CLI-t, valamint a yaml konfigur√°ci√≥s f√°jlokkal t√∂rt√©n≈ë k√©pz√©st.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Feladat

V√°lassz ki egyet a fenti bemutat√≥k k√∂z√ºl, √©s dolgozd v√©gig ≈ëket. _Lehet, hogy ezeknek a bemutat√≥knak egy v√°ltozat√°t Jupyter Notebookokban is megism√©telj√ºk ebben a rep√≥ban, csak hivatkoz√°si c√©lb√≥l. K√©rj√ºk, k√∂zvetlen√ºl az eredeti forr√°sokat haszn√°ld, hogy a legfrissebb verzi√≥kat kapd meg_.

## Remek munka! Folytasd a tanul√°st.

A lecke befejez√©se ut√°n n√©zd meg a [Generat√≠v AI Tanul√°si gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejleszd a Generat√≠v AI tud√°sodat!

Gratul√°lunk!! Befejezted a kurzus v2 sorozat√°nak utols√≥ leck√©j√©t! Ne hagyd abba a tanul√°st √©s az √©p√≠t√©st. **N√©zd meg a [FORR√ÅSOK](RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt, ahol tov√°bbi javaslatokat tal√°lsz erre a t√©m√°ra.

A v1 sorozat leck√©i is friss√ºltek t√∂bb feladattal √©s koncepci√≥val. Sz√°nj egy percet a tud√°sod felfriss√≠t√©s√©re - √©s k√©rj√ºk, [oszd meg k√©rd√©seidet √©s visszajelz√©seidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), hogy seg√≠ts nek√ºnk jav√≠tani ezeket a leck√©ket a k√∂z√∂ss√©g sz√°m√°ra.

**Jogi nyilatkozat**:  
Ezt a dokumentumot az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel ford√≠tottuk le. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hiteles forr√°snak. Kritikus inform√°ci√≥k eset√©n javasolt a professzion√°lis emberi ford√≠t√°s. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy f√©lre√©rtelmez√©sek√©rt.