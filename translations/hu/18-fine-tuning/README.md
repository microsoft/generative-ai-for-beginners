<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:48:16+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "hu"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.hu.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# LLM finomhangol√°sa

Nagy nyelvi modellek haszn√°lata generat√≠v AI alkalmaz√°sok √©p√≠t√©s√©hez √∫j kih√≠v√°sokat hoz mag√°val. Egy kulcsk√©rd√©s a v√°laszok min≈ës√©g√©nek (pontoss√°g √©s relevancia) biztos√≠t√°sa a modell √°ltal egy adott felhaszn√°l√≥i k√©r√©sre gener√°lt tartalomban. Kor√°bbi leck√©kben olyan technik√°kat t√°rgyaltunk, mint a prompt tervez√©s √©s a lek√©rdez√©s-alap√∫ gener√°l√°s, amelyek a probl√©m√°t azzal pr√≥b√°lj√°k megoldani, hogy _m√≥dos√≠tj√°k a prompt bemenet√©t_ a megl√©v≈ë modellen.

A mai leck√©ben egy harmadik technik√°t, a **finomhangol√°st** mutatjuk be, amely a kih√≠v√°st √∫gy pr√≥b√°lja kezelni, hogy _mag√°t a modellt √∫jra betan√≠tja_ tov√°bbi adatokkal. Mer√ºlj√ºnk el a r√©szletekben.

## Tanul√°si c√©lok

Ez a lecke bevezeti a finomhangol√°s fogalm√°t az el≈ëre betan√≠tott nyelvi modellekn√©l, felt√°rja ennek az elj√°r√°snak az el≈ënyeit √©s kih√≠v√°sait, valamint √∫tmutat√°st ad arra, mikor √©s hogyan √©rdemes finomhangol√°st alkalmazni generat√≠v AI modellek teljes√≠tm√©ny√©nek jav√≠t√°s√°ra.

A lecke v√©g√©re k√©pes leszel v√°laszolni az al√°bbi k√©rd√©sekre:

- Mi a finomhangol√°s nyelvi modellekn√©l?
- Mikor √©s mi√©rt hasznos a finomhangol√°s?
- Hogyan lehet finomhangolni egy el≈ëre betan√≠tott modellt?
- Milyen korl√°tai vannak a finomhangol√°snak?

K√©szen √°llsz? Kezdj√ºk!

## Illusztr√°lt √∫tmutat√≥

Szeretn√©d √°tl√°tni a leck√©ben t√°rgyaltakat, miel≈ëtt belev√°gn√°nk? N√©zd meg ezt az illusztr√°lt √∫tmutat√≥t, amely bemutatja a tanul√°si folyamatot ‚Äì a finomhangol√°s alapfogalmainak √©s motiv√°ci√≥j√°nak megismer√©s√©t≈ël a finomhangol√°si feladat v√©grehajt√°s√°nak folyamat√°n √©s legjobb gyakorlataikon √°t. Ez egy izgalmas t√©ma, ez√©rt ne felejtsd el megn√©zni a [Forr√°sok](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt tov√°bbi linkek√©rt, amelyek t√°mogatj√°k az √∂n√°ll√≥ tanul√°si utadat!

![Illusztr√°lt √∫tmutat√≥ a nyelvi modellek finomhangol√°s√°hoz](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.hu.png)

## Mi a finomhangol√°s nyelvi modellekn√©l?

Defin√≠ci√≥ szerint a nagy nyelvi modelleket _el≈ëre betan√≠tj√°k_ nagy mennyis√©g≈±, k√ºl√∂nb√∂z≈ë forr√°sb√≥l sz√°rmaz√≥ sz√∂vegen, bele√©rtve az internetet is. Ahogy kor√°bbi leck√©kben tanultuk, sz√ºks√©g√ºnk van olyan technik√°kra, mint a _prompt tervez√©s_ √©s a _lek√©rdez√©s-alap√∫ gener√°l√°s_, hogy jav√≠tsuk a modell v√°laszainak min≈ës√©g√©t a felhaszn√°l√≥i k√©rd√©sekre ("promptra").

Egy n√©pszer≈± prompt-tervez√©si technika, hogy a modellnek t√∂bb ir√°nymutat√°st adunk arr√≥l, mit v√°runk el a v√°laszban, ak√°r _utas√≠t√°sokkal_ (explicit ir√°nymutat√°s), ak√°r _n√©h√°ny p√©ld√°val_ (implicit ir√°nymutat√°s). Ezt h√≠vjuk _few-shot learningnek_, de ennek k√©t korl√°tja van:

- A modell token-korl√°tai megszabhatj√°k, h√°ny p√©ld√°t adhatsz meg, √©s ezzel a hat√©konys√°got is korl√°tozz√°k.
- A token-k√∂lts√©gek miatt dr√°ga lehet minden promptba p√©ld√°kat tenni, ami cs√∂kkenti a rugalmass√°got.

A finomhangol√°s egy gyakori gyakorlat a g√©pi tanul√°sban, amikor egy el≈ëre betan√≠tott modellt √∫j adatokkal √∫jratan√≠tunk, hogy jav√≠tsuk a teljes√≠tm√©ny√©t egy adott feladaton. Nyelvi modellek eset√©n finomhangolhatjuk az el≈ëre betan√≠tott modellt _egy gondosan √∂ssze√°ll√≠tott p√©ldak√©szlettel egy adott feladathoz vagy alkalmaz√°si ter√ºlethez_, √≠gy l√©trehozva egy **egyedi modellt**, amely pontosabb √©s relev√°nsabb lehet az adott feladatra vagy ter√ºletre. A finomhangol√°s mell√©khat√°sa, hogy cs√∂kkentheti a few-shot learninghez sz√ºks√©ges p√©ld√°k sz√°m√°t ‚Äì ez√°ltal kevesebb token haszn√°lat√°val √©s k√∂lts√©ggel j√°r.

## Mikor √©s mi√©rt √©rdemes finomhangolni a modelleket?

Ebben a kontextusban, amikor finomhangol√°sr√≥l besz√©l√ºnk, akkor **fel√ºgyelt** finomhangol√°sr√≥l van sz√≥, ahol az √∫jratan√≠t√°s √∫gy t√∂rt√©nik, hogy **√∫j adatokat adunk hozz√°**, amelyek nem voltak r√©szei az eredeti tan√≠t√≥ adathalmaznak. Ez elt√©r az √∂nfel√ºgyelt finomhangol√°st√≥l, ahol a modellt az eredeti adatokon √∫jratan√≠tj√°k, de m√°s hiperparam√©terekkel.

A legfontosabb, hogy a finomhangol√°s egy halad√≥ technika, amely bizonyos szint≈± szak√©rtelmet ig√©nyel a k√≠v√°nt eredm√©nyek el√©r√©s√©hez. Ha helytelen√ºl v√©gzik, nem biztos, hogy hozza a v√°rt javul√°st, s≈ët, ak√°r ronthatja is a modell teljes√≠tm√©ny√©t a c√©lzott ter√ºleten.

Ez√©rt miel≈ëtt megtanuln√°d, "hogyan" finomhangolj nyelvi modelleket, tudnod kell, "mi√©rt" √©rdemes ezt az utat v√°lasztani, √©s "mikor" kezd el a finomhangol√°si folyamatot. Tedd fel magadnak a k√∂vetkez≈ë k√©rd√©seket:

- **Haszn√°lati eset**: Mi a te _haszn√°lati eseted_ a finomhangol√°shoz? Melyik aspektus√°t szeretn√©d jav√≠tani a jelenlegi el≈ëre betan√≠tott modellnek?
- **Alternat√≠v√°k**: Pr√≥b√°lt√°l m√°r _m√°s technik√°kat_ a k√≠v√°nt eredm√©nyek el√©r√©s√©re? Haszn√°ld ezeket alapvonalnak az √∂sszehasonl√≠t√°shoz.
  - Prompt tervez√©s: Pr√≥b√°lj ki olyan technik√°kat, mint a few-shot promptol√°s relev√°ns p√©ld√°kkal. √ârt√©keld a v√°laszok min≈ës√©g√©t.
  - Lek√©rdez√©s-alap√∫ gener√°l√°s: Pr√≥b√°ld meg kieg√©sz√≠teni a promptokat a lek√©rdez√©sek eredm√©nyeivel, amelyeket az adataidban keresel. √ârt√©keld a v√°laszok min≈ës√©g√©t.
- **K√∂lts√©gek**: Azonos√≠tottad a finomhangol√°s k√∂lts√©geit?
  - Finomhangolhat√≥s√°g ‚Äì el√©rhet≈ë-e az el≈ëre betan√≠tott modell finomhangol√°sra?
  - Er≈ëforr√°s ‚Äì az oktat√≥ adatok el≈ëk√©sz√≠t√©se, a modell √©rt√©kel√©se √©s finom√≠t√°sa.
  - Sz√°m√≠t√°si kapacit√°s ‚Äì a finomhangol√°si feladatok futtat√°s√°hoz √©s a finomhangolt modell √ºzemeltet√©s√©hez.
  - Adat ‚Äì elegend≈ë min≈ës√©g≈± p√©lda el√©rhet≈ës√©ge a finomhangol√°s hat√°s√°hoz.
- **El≈ëny√∂k**: Meger≈ës√≠tetted a finomhangol√°s el≈ënyeit?
  - Min≈ës√©g ‚Äì a finomhangolt modell fel√ºlm√∫lta az alapmodellt?
  - K√∂lts√©g ‚Äì cs√∂kkenti a tokenhaszn√°latot az egyszer≈±s√≠tett promptokkal?
  - Kiterjeszthet≈ës√©g ‚Äì √∫j ter√ºletekre is √°t tudod alak√≠tani az alapmodellt?

Ezekre a k√©rd√©sekre v√°laszolva eld√∂ntheted, hogy a finomhangol√°s a megfelel≈ë megk√∂zel√≠t√©s-e az adott haszn√°lati esetedhez. Ide√°lis esetben csak akkor √©rdemes belev√°gni, ha az el≈ëny√∂k meghaladj√°k a k√∂lts√©geket. Ha eld√∂nt√∂tted, hogy folytatod, akkor gondolkodj el azon, _hogyan_ tudod finomhangolni az el≈ëre betan√≠tott modellt.

Szeretn√©l m√©lyebb betekint√©st a d√∂nt√©si folyamatba? N√©zd meg a [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs) vide√≥t.

## Hogyan finomhangolhatunk egy el≈ëre betan√≠tott modellt?

Egy el≈ëre betan√≠tott modell finomhangol√°s√°hoz sz√ºks√©ged van:

- egy el≈ëre betan√≠tott modellre, amit finomhangolhatsz
- egy adathalmazra, amit a finomhangol√°shoz haszn√°lsz
- egy k√∂rnyezetre, ahol lefuttathatod a finomhangol√°si feladatot
- egy k√∂rnyezetre, ahol √ºzemeltetheted a finomhangolt modellt

## Finomhangol√°s a gyakorlatban

Az al√°bbi forr√°sok l√©p√©sr≈ël l√©p√©sre vezetnek v√©gig egy val√≥s p√©ld√°n, ahol egy kiv√°lasztott modellt finomhangolunk egy gondosan √∂ssze√°ll√≠tott adathalmazon. Ezekhez a bemutat√≥khoz sz√ºks√©ged lesz egy fi√≥kra az adott szolg√°ltat√≥n√°l, valamint hozz√°f√©r√©sre a relev√°ns modellhez √©s adathalmazokhoz.

| Szolg√°ltat√≥ | Bemutat√≥                                                                                                                                                                       | Le√≠r√°s                                                                                                                                                                                                                                                                                                                                                                                                                           |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [Hogyan finomhangoljuk a chat modelleket](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)      | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo` modellt egy adott ter√ºletre ("recept asszisztens") az oktat√≥ adatok el≈ëk√©sz√≠t√©s√©vel, a finomhangol√°si feladat futtat√°s√°val, √©s a finomhangolt modell haszn√°lat√°val az inferenci√°hoz.                                                                                                                                                                                        |
| Azure OpenAI| [GPT 3.5 Turbo finomhangol√°si √∫tmutat√≥](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo-0613` modellt **Azure-on**, l√©p√©sr≈ël l√©p√©sre az oktat√≥ adatok l√©trehoz√°s√°val √©s felt√∂lt√©s√©vel, a finomhangol√°si feladat futtat√°s√°val, majd az √∫j modell telep√≠t√©s√©vel √©s haszn√°lat√°val.                                                                                                                                                                                           |
| Hugging Face| [LLM-ek finomhangol√°sa Hugging Face seg√≠ts√©g√©vel](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                  | Ez a blogbejegyz√©s v√©gigvezet egy _ny√≠lt LLM_ (pl. `CodeLlama 7B`) finomhangol√°s√°n a [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) k√∂nyvt√°r √©s a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) haszn√°lat√°val, ny√≠lt [adathalmazokon](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) a Hugging Face-en. |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ü§ó AutoTrain| [LLM-ek finomhangol√°sa AutoTrain-nel](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                     | Az AutoTrain (vagy AutoTrain Advanced) egy Hugging Face √°ltal fejlesztett Python k√∂nyvt√°r, amely sokf√©le feladathoz, k√∂zt√ºk LLM finomhangol√°shoz is lehet≈ës√©get ad. Az AutoTrain egy k√≥d n√©lk√ºli megold√°s, √©s a finomhangol√°s v√©gezhet≈ë a saj√°t felh≈ëdben, Hugging Face Spaces-en vagy helyileg. T√°mogatja a webes GUI-t, CLI-t √©s a yaml konfigur√°ci√≥s f√°jlokon kereszt√ºli tan√≠t√°st is.                                                                                 |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |

## Feladat

V√°lassz ki egy fenti bemutat√≥t, √©s dolgozd v√©gig. _Lehets√©ges, hogy ezekb≈ël a bemutat√≥kb√≥l k√©sz√≠t√ºnk egy verzi√≥t Jupyter Notebook form√°tumban ebben a rep√≥ban csak referenciak√©nt. K√©rj√ºk, az eredeti forr√°sokat haszn√°ld a legfrissebb verzi√≥k√©rt._

## Sz√©p munka! Folytasd a tanul√°st.

A lecke elv√©gz√©se ut√°n n√©zd meg a [Generat√≠v AI tanul√°si gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejleszd generat√≠v AI ismereteidet!

Gratul√°lunk!! Ezzel befejezted a kurzus v2-es sorozat√°nak utols√≥ leck√©j√©t! Ne hagyd abba a tanul√°st √©s az √©p√≠tkez√©st. \*\*N√©zd meg a [FORR√ÅSOK](RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt tov√°bbi javaslatok√©rt csak erre a t√©m√°ra.

A v1-es leckesorozatunkat is friss√≠tett√ºk t√∂bb feladattal √©s fogalommal. Sz√°nj egy percet a tud√°sod felfriss√≠t√©s√©re ‚Äì √©s k√©rj√ºk, [oszd meg k√©rd√©seidet √©s visszajelz√©seidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), hogy seg√≠tsd a k√∂z√∂ss√©g sz√°m√°ra ezeknek a leck√©knek a fejleszt√©s√©t.

**Jogi nyilatkozat**:  
Ez a dokumentum az AI ford√≠t√≥ szolg√°ltat√°s, a [Co-op Translator](https://github.com/Azure/co-op-translator) seg√≠ts√©g√©vel k√©sz√ºlt. B√°r a pontoss√°gra t√∂reksz√ºnk, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az anyanyelv√©n tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n szakmai, emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy t√©ves √©rtelmez√©sek√©rt.