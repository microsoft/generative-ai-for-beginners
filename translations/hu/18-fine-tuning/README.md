<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T18:52:51+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "hu"
}
-->
[![Open Source Models](../../../../../translated_images/hu/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# LLM finomhangol√°sa

A nagy nyelvi modellek alkalmaz√°sa generat√≠v MI alkalmaz√°sok √©p√≠t√©s√©hez √∫j kih√≠v√°sokkal j√°r. Egy kulcsk√©rd√©s a v√°laszok min≈ës√©g√©nek (pontoss√°g √©s relevancia) biztos√≠t√°sa a modell √°ltal egy adott felhaszn√°l√≥i k√©r√©sre gener√°lt tartalomban. Kor√°bbi leck√©kben olyan technik√°kat t√°rgyaltunk, mint a prompt m√©rn√∂ki munka √©s a visszakeres√©ssel b≈ëv√≠tett gener√°l√°s, amelyek a probl√©m√°t a _megl√©v≈ë modell prompt bemenet√©nek m√≥dos√≠t√°s√°val_ pr√≥b√°lj√°k megoldani.

A mai leck√©ben egy harmadik technik√°t, a **finomhangol√°st** t√°rgyaljuk, amely a kih√≠v√°st √∫gy pr√≥b√°lja megoldani, hogy _mag√°t a modellt √∫jradolgozza_ tov√°bbi adatokkal. Mer√ºlj√ºnk el a r√©szletekben.

## Tanul√°si c√©lok

Ez a lecke bevezeti a finomhangol√°s fogalm√°t az el≈ëre betan√≠tott nyelvi modellek eset√©n, felt√°rja ennek az elj√°r√°snak az el≈ënyeit √©s kih√≠v√°sait, valamint √∫tmutat√°st ad arra, mikor √©s hogyan √©rdemes finomhangol√°st alkalmazni generat√≠v MI modelljei teljes√≠tm√©ny√©nek jav√≠t√°s√°ra.

A lecke v√©g√©re k√©pesnek kell lenned az al√°bbi k√©rd√©sek megv√°laszol√°s√°ra:

- Mi a finomhangol√°s nyelvi modellekn√©l?
- Mikor √©s mi√©rt hasznos a finomhangol√°s?
- Hogyan lehet finomhangolni egy el≈ëre betan√≠tott modellt?
- Melyek a finomhangol√°s korl√°tai?

K√©szen √°llsz? Kezdj√ºnk hozz√°.

## Illusztr√°lt √∫tmutat√≥

Szeretn√©d l√°tni a teljes k√©p√©t annak, amit t√°rgyalni fogunk, miel≈ëtt belemer√ºln√©nk? N√©zd meg ezt az illusztr√°lt √∫tmutat√≥t, amely bemutatja a lecke tanul√°si √∫tj√°t ‚Äì a finomhangol√°s alapvet≈ë fogalm√°nak √©s motiv√°ci√≥j√°nak meg√©rt√©s√©t≈ël a finomhangol√°si folyamat √©s a legjobb gyakorlatok meg√©rt√©s√©ig. Ez egy leny≈±g√∂z≈ë t√©mak√∂r, ez√©rt ne feledd megn√©zni a [Forr√°sok](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt is, ahol tov√°bbi linkeket tal√°lsz az √∂n√°ll√≥ tanul√°shoz!

![Illusztr√°lt √∫tmutat√≥ a nyelvi modellek finomhangol√°s√°hoz](../../../../../translated_images/hu/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Mi a finomhangol√°s nyelvi modellekn√©l?

Defin√≠ci√≥ szerint a nagy nyelvi modellek _el≈ëre betan√≠tottak_ nagy mennyis√©g≈± sz√∂vegen, amelyek k√ºl√∂nb√∂z≈ë forr√°sokb√≥l, k√∂zt√ºk az internetr≈ël sz√°rmaznak. Ahogy kor√°bbi leck√©inkb≈ël megtanultuk, olyan technik√°kra van sz√ºks√©g√ºnk, mint a _prompt m√©rn√∂ki munka_ √©s a _visszakeres√©ssel b≈ëv√≠tett gener√°l√°s_, hogy jav√≠tsuk a modell v√°laszainak min≈ës√©g√©t a felhaszn√°l√≥i k√©rd√©sekre (‚Äûpromptokra‚Äù).

Egy n√©pszer≈± prompt-m√©rn√∂ki technika, hogy a modellt t√∂bb ir√°nymutat√°ssal l√°tjuk el a v√°lasz tekintet√©ben, ak√°r _utas√≠t√°sokkal_ (explicit ir√°nymutat√°s), ak√°r _n√©h√°ny p√©ld√°val_ (implicit ir√°nymutat√°s). Ezt nevezik _few-shot learningnek_, de ennek k√©t korl√°tja van:

- A modell token-korl√°tai korl√°tozhatj√°k az adhat√≥ p√©ld√°k sz√°m√°t, √©s cs√∂kkenthetik hat√©konys√°g√°t.
- A modell token k√∂lts√©gei megdr√°g√≠thatj√°k, ha minden promptba p√©ld√°kat tesz√ºnk, √©s korl√°tozz√°k a rugalmass√°got.

A finomhangol√°s egy sz√©les k√∂rben haszn√°lt elj√°r√°s g√©pi tanul√°si rendszerekben, ahol egy el≈ëre betan√≠tott modellt √∫j adatokkal √∫jra tan√≠tunk annak √©rdek√©ben, hogy jav√≠tsuk a teljes√≠tm√©ny√©t egy specifikus feladatban. A nyelvi modellek eset√©n az el≈ëre betan√≠tott modellt finomhangolhatjuk _egy szelekt√°lt p√©ldagy≈±jtem√©nnyel egy adott feladatra vagy alkalmaz√°si ter√ºletre_, hogy egy **egyedi modellt** hozzunk l√©tre, amely pontosabb √©s relev√°nsabb lehet az adott feladat vagy ter√ºlet sz√°m√°ra. A finomhangol√°s egyik mell√©khat√°sa az is, hogy cs√∂kkentheti a few-shot learninghez sz√ºks√©ges p√©ld√°k sz√°m√°t ‚Äì √≠gy kevesebb token haszn√°lat√°val √©s az azzal j√°r√≥ k√∂lts√©gek cs√∂kkent√©s√©vel j√°r.

## Mikor √©s mi√©rt √©rdemes finomhangolni a modelleket?

Ebben az √∂sszef√ºgg√©sben, amikor finomhangol√°sr√≥l besz√©l√ºnk, **fel√ºgyelt** finomhangol√°sr√≥l van sz√≥, ahol az √∫jratan√≠t√°s √∫gy t√∂rt√©nik, hogy **√∫j adatokat adunk hozz√°**, amelyek nem voltak r√©szei az eredeti tanul√≥ adatk√©szletnek. Ez k√ºl√∂nb√∂zik az unsupervised (fel√ºgyelet n√©lk√ºli) finomhangol√°st√≥l, ahol a modellt az eredeti adatokon tan√≠tj√°k √∫jra, de elt√©r≈ë hiperparam√©terekkel.

A legfontosabb, amit meg kell jegyezni: a finomhangol√°s egy fejlett technika, amely bizonyos fok√∫ szak√©rtelmet ig√©nyel a k√≠v√°nt eredm√©nyek el√©r√©s√©hez. Hib√°s alkalmaz√°s eset√©n nem hozhatja a v√°rt javul√°st, s≈ët ronthatja a modell teljes√≠tm√©ny√©t a c√©ltartom√°nyban.

Ez√©rt miel≈ëtt megtanuln√°d, "hogyan" kell finomhangolni a nyelvi modelleket, tudnod kell, "mi√©rt" √©rdemes ezt az utat v√°lasztani, √©s "mikor" kell elkezdeni a finomhangol√°si folyamatot. Tedd fel magadnak a k√∂vetkez≈ë k√©rd√©seket:

- **Haszn√°lati eset**: Mi az a _haszn√°lati eset_, amelyhez finomhangolni szeretn√©d? Mely aspektus√°t akarod jav√≠tani a jelenlegi el≈ëre betan√≠tott modellnek?
- **Alternat√≠v√°k**: Kipr√≥b√°lt√°l _m√°s technik√°kat_ a k√≠v√°nt eredm√©nyek el√©r√©s√©re? Haszn√°ld ≈ëket kiindul√°si alapnak az √∂sszehasonl√≠t√°shoz.
  - Prompt m√©rn√∂ki munka: Pr√≥b√°ld ki p√©ld√°ul a few-shot promptol√°st p√©ld√°kkal a relev√°ns v√°laszokr√≥l. √ârt√©keld a v√°laszok min≈ës√©g√©t.
  - Visszakeres√©s-alap√∫ gener√°l√°s: Pr√≥b√°ld meg b≈ëv√≠teni a promptokat lek√©rdez√©si eredm√©nyekkel, amelyeket a saj√°t adatb√°zisodb√≥l keresel ki. √ârt√©keld a v√°laszok min≈ës√©g√©t.
- **K√∂lts√©gek**: Felm√©rt√©l minden finomhangol√°ssal j√°r√≥ k√∂lts√©get?
  - Finomhangolhat√≥s√°g ‚Äì el√©rhet≈ë-e az el≈ëre betan√≠tott modell a finomhangol√°shoz?
  - Er≈ëfesz√≠t√©s ‚Äì az adatok el≈ëk√©sz√≠t√©se, a modell √©rt√©kel√©se √©s finom√≠t√°sa
  - Sz√°m√≠t√°stechnikai er≈ëforr√°sok ‚Äì a finomhangol√°si feladatok futtat√°s√°hoz √©s a finomhangolt modell telep√≠t√©s√©hez
  - Adatok ‚Äì elegend≈ë min≈ës√©g≈± p√©lda biztos√≠t√°sa a finomhangol√°s hat√°s√°hoz
- **El≈ëny√∂k**: Meger≈ës√≠tetted a finomhangol√°s el≈ënyeit?
  - Min≈ës√©g ‚Äì a finomhangolt modell jobb lett-e a kiindul√°si alapn√°l?
  - K√∂lts√©g ‚Äì cs√∂kkenti-e a tokenhaszn√°latot a promptok egyszer≈±s√≠t√©s√©vel?
  - Kiterjeszthet≈ës√©g ‚Äì √∫j tartom√°nyokra is √°talak√≠that√≥ az alapmodell?

E k√©rd√©sek megv√°laszol√°s√°val el tudod d√∂nteni, hogy a finomhangol√°s megfelel≈ë megk√∂zel√≠t√©s-e az adott haszn√°lati esethez. Ide√°lis esetben ezt a m√≥dszert csak akkor alkalmazd, ha az el≈ëny√∂k meghaladj√°k a k√∂lts√©geket. Ha √∫gy d√∂ntesz, hogy folytatod, itt az ideje √°tgondolni, _hogyan_ finomhangold az el≈ëre betan√≠tott modellt.

Szeretn√©l tov√°bbi betekint√©st nyerni a d√∂nt√©si folyamatba? N√©zd meg a [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs) vide√≥t.

## Hogyan lehet finomhangolni egy el≈ëre betan√≠tott modellt?

Ahhoz, hogy finomhangolj egy el≈ëre betan√≠tott modellt, sz√ºks√©ged van:

- egy el≈ëre betan√≠tott modellre finomhangol√°shoz
- egy adatk√©szletre a finomhangol√°shoz
- egy tr√©ning k√∂rnyezetre a finomhangol√≥ feladat futtat√°s√°hoz
- egy hoszting k√∂rnyezetre a finomhangolt modell telep√≠t√©s√©hez

## Finomhangol√°s a gyakorlatban

Az al√°bbi forr√°sok l√©p√©sr≈ël l√©p√©sre mutatnak be oktat√≥anyagokat, amelyek egy kiv√°lasztott modell √©s egy gondosan √∂ssze√°ll√≠tott adathalmaz felhaszn√°l√°s√°val vezetik v√©gig a finomhangol√°s folyamat√°t. Ezeknek az oktat√≥anyagoknak a v√©gigvitel√©hez rendelkezni kell fi√≥kkal az adott szolg√°ltat√≥n√°l, valamint hozz√°f√©r√©ssel a relev√°ns modellhez √©s adathalmazokhoz.

| Szolg√°ltat√≥  | Oktat√≥anyag                                                                                                                                                                   | Le√≠r√°s                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Chat modellek finomhangol√°sa](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)              | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo` modellt egy adott ter√ºletre (‚Äûrecept asszisztens‚Äù), az adatok el≈ëk√©sz√≠t√©s√©t≈ël a finomhangol√≥ feladat futtat√°s√°n √°t eg√©szen a finomhangolt modell haszn√°lat√°ig az inferenci√°hoz.                                                                                                                                                                                                |
| Azure OpenAI | [GPT 3.5 Turbo finomhangol√°si oktat√≥anyag](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo-0613` modellt **az Azure-on** az adatok el≈ëk√©sz√≠t√©s√©t≈ël √©s felt√∂lt√©s√©t≈ël, a finomhangol√≥ folyamat futtat√°s√°n kereszt√ºl a modell telep√≠t√©s√©ig √©s haszn√°lat√°ig.                                                                                                                                                                                                                    |
| Hugging Face | [LLM-ek finomhangol√°sa Hugging Face-szel](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                       | Ez a blogbejegyz√©s v√©gigvezet egy _ny√≠lt LLM_ (pl. `CodeLlama 7B`) finomhangol√°s√°n a [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) k√∂nyvt√°r √©s a [Transformer meger≈ës√≠t√©ses tanul√°s (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) haszn√°lat√°val, valamint ny√≠lt [adatk√©szleteken](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) a Hugging Face-en. |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| ü§ó AutoTrain | [LLM-ek finomhangol√°sa AutoTrain seg√≠ts√©g√©vel](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                         | Az AutoTrain (vagy AutoTrain Advanced) egy python k√∂nyvt√°r a Hugging Face-t≈ël, amely sokf√©le feladathoz teszi lehet≈ëv√© a finomhangol√°st, bele√©rtve az LLM finomhangol√°st is. Az AutoTrain egy k√≥d n√©lk√ºli megold√°s; a finomhangol√°s t√∂rt√©nhet a saj√°t felh≈ëdben, a Hugging Face Spaces-en vagy lok√°lisan. T√°mogat webes GUI-t, parancssori fel√ºletet (CLI) √©s yaml konfigur√°ci√≥s f√°jlokon alapul√≥ tr√©ninget.                                           |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                   |
| ü¶• Unsloth      | [LLM-ek finomhangol√°sa Unsloth seg√≠ts√©g√©vel](https://github.com/unslothai/unsloth)                                                                             | Az Unsloth egy ny√≠lt forr√°sk√≥d√∫ keretrendszer, amely t√°mogatja az LLM finomhangol√°st √©s meger≈ës√≠t√©ses tanul√°st (RL). Az Unsloth leegyszer≈±s√≠ti a helyi tr√©ninget, √©rt√©kel√©st √©s telep√≠t√©st k√©sz notebookok seg√≠ts√©g√©vel. Tov√°bb√° t√°mogatja a sz√∂veg-besz√©d konverzi√≥t (TTS), BERT √©s multimod√°lis modelleket is. Kezd√©shez olvasd el az √°ltaluk k√©sz√≠tett l√©p√©sr≈ël l√©p√©sre sz√≥l√≥ [Finomhangol√°s LLM-ekhez √∫tmutat√≥t](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                   |
## Feladat

V√°lassz ki egy fenti oktat√≥anyagot √©s dolgozd v√©gig. _Ezekb≈ël az oktat√≥anyagokb√≥l el≈ëfordulhat, hogy k√©sz√≠t√ºnk egy verzi√≥t Jupyter Notebook form√°tumban ebben a rep√≥ban csak t√°j√©koztat√°sul. Azonban a legfrissebb v√°ltozatok√©rt mindig az eredeti forr√°sokat haszn√°ld._

## Remek munka! Folytasd a tanul√°st.

A lecke elv√©gz√©se ut√°n n√©zd meg a [Generat√≠v MI tanul√°si gy≈±jtem√©nyt](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejleszd generat√≠v MI ismereteidet!

Gratul√°lunk!! Teljes√≠tetted a kurzus v2 sorozat√°nak utols√≥ leck√©j√©t! Ne hagyd abba a tanul√°st √©s az √©p√≠tkez√©st. \*\*N√©zd meg a [FORR√ÅSOK](RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt, ahol tov√°bbi aj√°nl√°sokat tal√°lsz kiz√°r√≥lag ehhez a t√©mak√∂rh√∂z.

A v1 sorozatunk is friss√ºlt t√∂bb feladattal √©s fogalommal. Sz√°nj egy percet, hogy felfriss√≠tsd a tud√°sod ‚Äì √©s k√©rj√ºk, [oszd meg k√©rd√©seidet √©s visszajelz√©seidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), hogy seg√≠ts fejl≈ëdni ezeket a leck√©ket a k√∂z√∂ss√©g sz√°m√°ra.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Nyilatkozat**:
Ezt a dokumentumot az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√≥szolg√°ltat√°s seg√≠ts√©g√©vel ford√≠tottuk. B√°r igyeksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti, anyanyelv≈± dokumentum tekintend≈ë a hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n professzion√°lis emberi ford√≠t√°st javaslunk. Nem v√°llalunk felel≈ëss√©get a ford√≠t√°s haszn√°lat√°b√≥l ered≈ë f√©lre√©rt√©sek√©rt vagy f√©lre√©rtelmez√©sek√©rt.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->