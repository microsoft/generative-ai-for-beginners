<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T21:30:19+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "hu"
}
-->
[![Ny√≠lt forr√°sk√≥d√∫ modellek](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.hu.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# LLM finomhangol√°sa

A nagy nyelvi modellek haszn√°lata generat√≠v AI alkalmaz√°sok √©p√≠t√©s√©hez √∫j kih√≠v√°sokkal j√°r. Az egyik kulcsfontoss√°g√∫ k√©rd√©s az, hogy biztos√≠tsuk a modell √°ltal gener√°lt tartalom v√°laszainak min≈ës√©g√©t (pontoss√°g √©s relevancia) egy adott felhaszn√°l√≥i k√©r√©sre. Az el≈ëz≈ë leck√©kben olyan technik√°kr√≥l besz√©lt√ºnk, mint a prompt engineering √©s a retrieval-augmented generation, amelyek a probl√©m√°t a megl√©v≈ë modell _prompt inputj√°nak m√≥dos√≠t√°s√°val_ pr√≥b√°lj√°k megoldani.

A mai leck√©ben egy harmadik technik√°r√≥l, a **finomhangol√°sr√≥l** besz√©l√ºnk, amely a kih√≠v√°st a modell _√∫jratan√≠t√°s√°val_ pr√≥b√°lja kezelni tov√°bbi adatokkal. Mer√ºlj√ºnk el a r√©szletekben.

## Tanul√°si c√©lok

Ez a lecke bemutatja a finomhangol√°s fogalm√°t az el≈ëre betan√≠tott nyelvi modellek eset√©ben, felt√°rja ennek az elj√°r√°snak az el≈ënyeit √©s kih√≠v√°sait, valamint √∫tmutat√°st ny√∫jt arra vonatkoz√≥an, hogy mikor √©s hogyan haszn√°ljuk a finomhangol√°st a generat√≠v AI modellek teljes√≠tm√©ny√©nek jav√≠t√°s√°ra.

A lecke v√©g√©re k√©pes leszel megv√°laszolni a k√∂vetkez≈ë k√©rd√©seket:

- Mi az a finomhangol√°s a nyelvi modellek eset√©ben?
- Mikor √©s mi√©rt hasznos a finomhangol√°s?
- Hogyan lehet finomhangolni egy el≈ëre betan√≠tott modellt?
- Milyen korl√°tai vannak a finomhangol√°snak?

K√©szen √°llsz? Kezdj√ºk el.

## Illusztr√°lt √∫tmutat√≥

Szeretn√©d √°tl√°tni, mir≈ël lesz sz√≥, miel≈ëtt belev√°gunk? N√©zd meg ezt az illusztr√°lt √∫tmutat√≥t, amely bemutatja a tanul√°si folyamatot ebben a leck√©ben ‚Äì az alapfogalmak √©s a finomhangol√°s motiv√°ci√≥j√°nak megismer√©s√©t≈ël kezdve a folyamat √©s a legjobb gyakorlatok meg√©rt√©s√©ig a finomhangol√°si feladat v√©grehajt√°s√°hoz. Ez egy izgalmas t√©ma a felfedez√©shez, ez√©rt ne felejtsd el megn√©zni a [Forr√°sok](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt tov√°bbi linkek√©rt, amelyek t√°mogatj√°k az √∂n√°ll√≥ tanul√°si utadat!

![Illusztr√°lt √∫tmutat√≥ a nyelvi modellek finomhangol√°s√°hoz](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.hu.png)

## Mi az a finomhangol√°s a nyelvi modellek eset√©ben?

Defin√≠ci√≥ szerint a nagy nyelvi modellek _el≈ëre betan√≠tottak_, √©s hatalmas mennyis√©g≈± sz√∂vegen alapulnak, amelyeket k√ºl√∂nb√∂z≈ë forr√°sokb√≥l, p√©ld√°ul az internetr≈ël gy≈±jt√∂ttek. Ahogy az el≈ëz≈ë leck√©kben tanultuk, olyan technik√°kra van sz√ºks√©g√ºnk, mint a _prompt engineering_ √©s a _retrieval-augmented generation_, hogy jav√≠tsuk a modell v√°laszainak min≈ës√©g√©t a felhaszn√°l√≥i k√©rd√©sekre ("prompts").

Egy n√©pszer≈± prompt engineering technika az, hogy a modellnek t√∂bb √∫tmutat√°st adunk arr√≥l, hogy mi v√°rhat√≥ el a v√°laszban, ak√°r _utas√≠t√°sok_ (egy√©rtelm≈± √∫tmutat√°s), ak√°r _n√©h√°ny p√©lda_ (k√∂zvetett √∫tmutat√°s) megad√°s√°val. Ezt _few-shot learningnek_ nevezz√ºk, de k√©t korl√°tja van:

- A modell tokenkorl√°tai korl√°tozhatj√°k a megadhat√≥ p√©ld√°k sz√°m√°t, √©s cs√∂kkenthetik a hat√©konys√°got.
- A modell tokenk√∂lts√©gei dr√°g√°v√° tehetik a p√©ld√°k hozz√°ad√°s√°t minden prompthoz, √©s cs√∂kkenthetik a rugalmass√°got.

A finomhangol√°s egy √°ltal√°nos gyakorlat a g√©pi tanul√°si rendszerekben, amely sor√°n egy el≈ëre betan√≠tott modellt √∫j adatokkal √∫jratan√≠tunk, hogy jav√≠tsuk a teljes√≠tm√©ny√©t egy adott feladaton. A nyelvi modellek kontextus√°ban a finomhangol√°s sor√°n az el≈ëre betan√≠tott modellt _egy adott feladathoz vagy alkalmaz√°si ter√ºlethez gondosan kiv√°lasztott p√©ld√°k halmaz√°val_ tan√≠tjuk √∫jra, hogy egy **egyedi modellt** hozzunk l√©tre, amely pontosabb √©s relev√°nsabb lehet az adott feladathoz vagy ter√ºlethez. A finomhangol√°s egyik mell√©khat√°sa, hogy cs√∂kkentheti a few-shot learninghez sz√ºks√©ges p√©ld√°k sz√°m√°t ‚Äì cs√∂kkentve a tokenhaszn√°latot √©s a kapcsol√≥d√≥ k√∂lts√©geket.

## Mikor √©s mi√©rt kell finomhangolni a modelleket?

Ebben a kontextusban, amikor finomhangol√°sr√≥l besz√©l√ºnk, a **fel√ºgyelt** finomhangol√°sra utalunk, ahol az √∫jratan√≠t√°s **√∫j adatok hozz√°ad√°s√°val** t√∂rt√©nik, amelyek nem voltak r√©szei az eredeti tan√≠t√°si adathalmaznak. Ez k√ºl√∂nb√∂zik a nem fel√ºgyelt finomhangol√°si megk√∂zel√≠t√©st≈ël, ahol a modellt az eredeti adatokon tan√≠tj√°k √∫jra, de elt√©r≈ë hiperparam√©terekkel.

A legfontosabb, hogy a finomhangol√°s egy halad√≥ technika, amely bizonyos szint≈± szak√©rtelmet ig√©nyel a k√≠v√°nt eredm√©nyek el√©r√©s√©hez. Ha helytelen√ºl v√©gezz√ºk, nem biztos, hogy a v√°rt javul√°sokat hozza, s≈ët, ak√°r ronthatja is a modell teljes√≠tm√©ny√©t a c√©lzott ter√ºleten.

Teh√°t miel≈ëtt megtanuln√°d, "hogyan" kell finomhangolni a nyelvi modelleket, tudnod kell, "mi√©rt" √©rdemes ezt az utat v√°lasztani, √©s "mikor" √©rdemes elkezdeni a finomhangol√°s folyamat√°t. Kezdd azzal, hogy felteszed magadnak ezeket a k√©rd√©seket:

- **Felhaszn√°l√°si eset**: Mi a _felhaszn√°l√°si eseted_ a finomhangol√°sra? Mit szeretn√©l jav√≠tani az aktu√°lis el≈ëre betan√≠tott modellen?
- **Alternat√≠v√°k**: Kipr√≥b√°lt√°l m√°r _m√°s technik√°kat_ a k√≠v√°nt eredm√©nyek el√©r√©s√©hez? Haszn√°ld ezeket √∂sszehasonl√≠t√°si alapk√©nt.
  - Prompt engineering: Pr√≥b√°lj ki olyan technik√°kat, mint a few-shot prompting relev√°ns promptv√°laszok p√©ld√°ival. √ârt√©keld a v√°laszok min≈ës√©g√©t.
  - Retrieval Augmented Generation: Pr√≥b√°ld meg kieg√©sz√≠teni a promtokat az adataid keres√©s√©vel nyert lek√©rdez√©si eredm√©nyekkel. √ârt√©keld a v√°laszok min≈ës√©g√©t.
- **K√∂lts√©gek**: Azonos√≠tottad a finomhangol√°s k√∂lts√©geit?
  - Finomhangolhat√≥s√°g ‚Äì el√©rhet≈ë-e az el≈ëre betan√≠tott modell finomhangol√°sra?
  - Er≈ëfesz√≠t√©s ‚Äì az adatok el≈ëk√©sz√≠t√©s√©re, a modell √©rt√©kel√©s√©re √©s finom√≠t√°s√°ra ford√≠tott munka.
  - Sz√°m√≠t√°si kapacit√°s ‚Äì a finomhangol√°si feladatok futtat√°s√°hoz √©s a finomhangolt modell telep√≠t√©s√©hez sz√ºks√©ges er≈ëforr√°sok.
  - Adatok ‚Äì elegend≈ë min≈ës√©gi p√©lda √°ll rendelkez√©sre a finomhangol√°s hat√°s√°hoz.
- **El≈ëny√∂k**: Meger≈ës√≠tetted a finomhangol√°s el≈ënyeit?
  - Min≈ës√©g ‚Äì a finomhangolt modell fel√ºlm√∫lta az alapmodellt?
  - K√∂lts√©g ‚Äì cs√∂kkenti a tokenhaszn√°latot az egyszer≈±s√≠tett promtok r√©v√©n?
  - Kiterjeszthet≈ës√©g ‚Äì √∫j ter√ºletekre is alkalmazhat√≥ az alapmodell?

Ezekre a k√©rd√©sekre v√°laszolva el tudod d√∂nteni, hogy a finomhangol√°s megfelel≈ë megk√∂zel√≠t√©s-e a felhaszn√°l√°si esetedhez. Ide√°lis esetben a megk√∂zel√≠t√©s csak akkor √©rv√©nyes, ha az el≈ëny√∂k meghaladj√°k a k√∂lts√©geket. Ha √∫gy d√∂ntesz, hogy folytatod, itt az ideje √°tgondolni, _hogyan_ finomhangolhatod az el≈ëre betan√≠tott modellt.

Szeretn√©l t√∂bbet megtudni a d√∂nt√©shozatali folyamatr√≥l? N√©zd meg: [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Hogyan finomhangolhatunk egy el≈ëre betan√≠tott modellt?

Egy el≈ëre betan√≠tott modell finomhangol√°s√°hoz sz√ºks√©ged lesz:

- egy el≈ëre betan√≠tott modellre, amelyet finomhangolhatsz
- egy adathalmazra a finomhangol√°shoz
- egy tan√≠t√°si k√∂rnyezetre a finomhangol√°si feladat futtat√°s√°hoz
- egy hosztol√≥ k√∂rnyezetre a finomhangolt modell telep√≠t√©s√©hez

## Finomhangol√°s a gyakorlatban

Az al√°bbi forr√°sok l√©p√©sr≈ël l√©p√©sre bemutatj√°k, hogyan v√©gezheted el a finomhangol√°st egy kiv√°lasztott modellen egy gondosan √∂ssze√°ll√≠tott adathalmazzal. Ezeknek a bemutat√≥knak az elv√©gz√©s√©hez sz√ºks√©ged lesz egy fi√≥kra az adott szolg√°ltat√≥n√°l, valamint hozz√°f√©r√©sre a relev√°ns modellhez √©s adathalmazokhoz.

| Szolg√°ltat√≥  | Bemutat√≥                                                                                                                                                                       | Le√≠r√°s                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Hogyan finomhangoljuk a chat modelleket](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)     | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo` modellt egy adott ter√ºletre ("recept asszisztens") az adatok el≈ëk√©sz√≠t√©s√©vel, a finomhangol√°si feladat futtat√°s√°val √©s a finomhangolt modell haszn√°lat√°val.                                                                                                                                                                                                                     |
| Azure OpenAI | [GPT 3.5 Turbo finomhangol√°si bemutat√≥](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Tanuld meg, hogyan finomhangolj egy `gpt-35-turbo-0613` modellt **az Azure-on** az adatok l√©trehoz√°s√°val √©s felt√∂lt√©s√©vel, a finomhangol√°si feladat futtat√°s√°val. Telep√≠tsd √©s haszn√°ld az √∫j modellt.                                                                                                                                                                                                                              |
| Hugging Face | [Nyelvi modellek finomhangol√°sa a Hugging Face seg√≠ts√©g√©vel](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                        | Ez a blogbejegyz√©s bemutatja, hogyan finomhangolj egy _ny√≠lt LLM_-et (pl.: `CodeLlama 7B`) a [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) k√∂nyvt√°r √©s a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) seg√≠ts√©g√©vel, ny√≠lt [adathalmazokkal](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) a Hugging Face-en. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Nyelvi modellek finomhangol√°sa az AutoTrain seg√≠ts√©g√©vel](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                 | Az AutoTrain (vagy AutoTrain Advanced) egy Python k√∂nyvt√°r, amelyet a Hugging Face fejlesztett ki, √©s amely lehet≈ëv√© teszi sz√°mos k√ºl√∂nb√∂z≈ë feladat, k√∂zt√ºk a nyelvi modellek finomhangol√°s√°t. Az AutoTrain egy k√≥dmentes megold√°s, √©s a finomhangol√°s elv√©gezhet≈ë saj√°t felh≈ëben, a Hugging Face Spaces-en vagy helyileg. T√°mogatja a webalap√∫ GUI-t, a CLI-t √©s a yaml konfigur√°ci√≥s f√°jlokon kereszt√ºli tan√≠t√°st. |

## Feladat

V√°lassz ki egyet a fenti bemutat√≥k k√∂z√ºl, √©s v√©gezd el. _El≈ëfordulhat, hogy ezeknek a bemutat√≥knak egy verzi√≥j√°t replik√°ljuk a Jupyter Notebookokban ebben a rep√≥ban csak referenciak√©nt. K√©rj√ºk, haszn√°ld k√∂zvetlen√ºl az eredeti forr√°sokat a legfrissebb verzi√≥k el√©r√©s√©hez_.

## Sz√©p munka! Folytasd a tanul√°st.

A lecke elv√©gz√©se ut√°n n√©zd meg a [Generat√≠v AI tanul√°si gy≈±jtem√©ny√ºnket](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), hogy tov√°bb fejleszd a generat√≠v AI ismereteidet!

Gratul√°lunk!! Befejezted a kurzus v2 sorozat√°nak utols√≥ leck√©j√©t! Ne hagyd abba a tanul√°st √©s az √©p√≠t√©st. **N√©zd meg a [FORR√ÅSOK](RESOURCES.md?WT.mc_id=academic-105485-koreyst) oldalt tov√°bbi javaslatok√©rt csak ehhez a t√©m√°hoz.

Az els≈ë verzi√≥j√∫ lecke sorozatunkat is friss√≠tett√ºk t√∂bb feladattal √©s fogalommal. Sz√°nj egy percet a tud√°sod felfriss√≠t√©s√©re ‚Äì √©s k√©rj√ºk, [oszd meg k√©rd√©seidet √©s visszajelz√©seidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), hogy seg√≠ts nek√ºnk jav√≠tani ezeket a leck√©ket a k√∂z√∂ss√©g sz√°m√°ra.

---

**Felel≈ëss√©g kiz√°r√°sa**:  
Ez a dokumentum az [Co-op Translator](https://github.com/Azure/co-op-translator) AI ford√≠t√°si szolg√°ltat√°s seg√≠ts√©g√©vel lett leford√≠tva. B√°r t√∂reksz√ºnk a pontoss√°gra, k√©rj√ºk, vegye figyelembe, hogy az automatikus ford√≠t√°sok hib√°kat vagy pontatlans√°gokat tartalmazhatnak. Az eredeti dokumentum az eredeti nyelven tekintend≈ë hiteles forr√°snak. Fontos inform√°ci√≥k eset√©n javasolt professzion√°lis emberi ford√≠t√°st ig√©nybe venni. Nem v√°llalunk felel≈ëss√©get semmilyen f√©lre√©rt√©s√©rt vagy t√©ves √©rtelmez√©s√©rt, amely a ford√≠t√°s haszn√°lat√°b√≥l eredhet.