{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Εισαγωγή \n",
    "\n",
    "Αυτό το μάθημα θα καλύψει: \n",
    "- Τι είναι η κλήση συνάρτησης και οι περιπτώσεις χρήσης της \n",
    "- Πώς να δημιουργήσετε μια κλήση συνάρτησης χρησιμοποιώντας το OpenAI \n",
    "- Πώς να ενσωματώσετε μια κλήση συνάρτησης σε μια εφαρμογή \n",
    "\n",
    "## Στόχοι Μάθησης \n",
    "\n",
    "Μετά την ολοκλήρωση αυτού του μαθήματος θα γνωρίζετε πώς και θα κατανοείτε: \n",
    "\n",
    "-  Το σκοπό της χρήσης της κλήσης συνάρτησης \n",
    "- Ρύθμιση Κλήσης Συνάρτησης χρησιμοποιώντας την Υπηρεσία OpenAI \n",
    "- Σχεδιασμό αποτελεσματικών κλήσεων συνάρτησης για την περίπτωση χρήσης της εφαρμογής σας\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Κατανόηση Κλήσεων Συναρτήσεων \n",
    "\n",
    "Για αυτό το μάθημα, θέλουμε να δημιουργήσουμε μια λειτουργία για το εκπαιδευτικό μας startup που επιτρέπει στους χρήστες να χρησιμοποιούν ένα chatbot για να βρουν τεχνικά μαθήματα. Θα προτείνουμε μαθήματα που ταιριάζουν στο επίπεδο δεξιοτήτων τους, τον τρέχοντα ρόλο και την τεχνολογία ενδιαφέροντος. \n",
    "\n",
    "Για να ολοκληρώσουμε αυτό θα χρησιμοποιήσουμε έναν συνδυασμό: \n",
    " - `OpenAI` για να δημιουργήσουμε μια εμπειρία συνομιλίας για τον χρήστη\n",
    " - `Microsoft Learn Catalog API` για να βοηθήσουμε τους χρήστες να βρουν μαθήματα βάσει του αιτήματος του χρήστη \n",
    " - `Function Calling` για να πάρουμε το ερώτημα του χρήστη και να το στείλουμε σε μια συνάρτηση για να κάνουμε το αίτημα API. \n",
    "\n",
    "Για να ξεκινήσουμε, ας δούμε γιατί θα θέλαμε να χρησιμοποιήσουμε την κλήση συνάρτησης αρχικά: \n",
    "\n",
    "print(\"Μηνύματα στο επόμενο αίτημα:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # λάβετε μια νέα απάντηση από το GPT όπου μπορεί να δει την απάντηση της συνάρτησης\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Γιατί η Κλήση Συνάρτησης\n",
    "\n",
    "Αν έχετε ολοκληρώσει οποιοδήποτε άλλο μάθημα σε αυτό το μάθημα, πιθανότατα καταλαβαίνετε τη δύναμη της χρήσης Μεγάλων Γλωσσικών Μοντέλων (LLMs). Ελπίζουμε επίσης να μπορείτε να δείτε μερικούς από τους περιορισμούς τους.\n",
    "\n",
    "Η Κλήση Συνάρτησης είναι μια λειτουργία της Υπηρεσίας OpenAI σχεδιασμένη να αντιμετωπίζει τις ακόλουθες προκλήσεις:\n",
    "\n",
    "Μη Συνεπής Μορφοποίηση Απαντήσεων:\n",
    "- Πριν από την κλήση συνάρτησης, οι απαντήσεις από ένα μεγάλο γλωσσικό μοντέλο ήταν άμορφες και ασυνεπείς. Οι προγραμματιστές έπρεπε να γράφουν πολύπλοκο κώδικα επικύρωσης για να χειριστούν κάθε παραλλαγή στην έξοδο.\n",
    "\n",
    "Περιορισμένη Ενσωμάτωση με Εξωτερικά Δεδομένα:\n",
    "- Πριν από αυτή τη λειτουργία, ήταν δύσκολο να ενσωματωθούν δεδομένα από άλλα μέρη μιας εφαρμογής σε ένα πλαίσιο συνομιλίας.\n",
    "\n",
    "Με την τυποποίηση των μορφών απάντησης και την ενεργοποίηση της απρόσκοπτης ενσωμάτωσης με εξωτερικά δεδομένα, η κλήση συνάρτησης απλοποιεί την ανάπτυξη και μειώνει την ανάγκη για επιπλέον λογική επικύρωσης.\n",
    "\n",
    "Οι χρήστες δεν μπορούσαν να λάβουν απαντήσεις όπως \"Ποιος είναι ο τρέχων καιρός στη Στοκχόλμη;\". Αυτό συμβαίνει επειδή τα μοντέλα ήταν περιορισμένα στον χρόνο κατά τον οποίο εκπαιδεύτηκαν τα δεδομένα.\n",
    "\n",
    "Ας δούμε το παρακάτω παράδειγμα που απεικονίζει αυτό το πρόβλημα:\n",
    "\n",
    "Ας πούμε ότι θέλουμε να δημιουργήσουμε μια βάση δεδομένων με δεδομένα φοιτητών ώστε να μπορούμε να προτείνουμε το κατάλληλο μάθημα σε αυτούς. Παρακάτω έχουμε δύο περιγραφές φοιτητών που είναι πολύ παρόμοιες στα δεδομένα που περιέχουν.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θέλουμε να στείλουμε αυτό σε ένα LLM για να αναλύσει τα δεδομένα. Αυτό μπορεί αργότερα να χρησιμοποιηθεί στην εφαρμογή μας για να το στείλουμε σε ένα API ή να το αποθηκεύσουμε σε μια βάση δεδομένων.\n",
    "\n",
    "Ας δημιουργήσουμε δύο πανομοιότυπα prompts που θα καθοδηγούν το LLM σχετικά με τις πληροφορίες που μας ενδιαφέρουν:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Θέλουμε να στείλουμε αυτό σε ένα LLM για να αναλύσει τα μέρη που είναι σημαντικά για το προϊόν μας. Έτσι μπορούμε να δημιουργήσουμε δύο πανομοιότυπα prompts για να καθοδηγήσουμε το LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αφού δημιουργήσουμε αυτές τις δύο προτροπές, θα τις στείλουμε στο LLM χρησιμοποιώντας το `openai.ChatCompletion`. Αποθηκεύουμε την προτροπή στη μεταβλητή `messages` και αναθέτουμε τον ρόλο στο `user`. Αυτό γίνεται για να μιμηθούμε ένα μήνυμα από έναν χρήστη που γράφεται σε ένα chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα μπορούμε να στείλουμε και τα δύο αιτήματα στο LLM και να εξετάσουμε την απάντηση που λαμβάνουμε.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ακόμα και αν οι προτροπές είναι οι ίδιες και οι περιγραφές παρόμοιες, μπορούμε να λάβουμε διαφορετικές μορφές της ιδιότητας `Grades`.\n",
    "\n",
    "Αν εκτελέσετε το παραπάνω κελί πολλές φορές, η μορφή μπορεί να είναι `3.7` ή `3.7 GPA`.\n",
    "\n",
    "Αυτό συμβαίνει επειδή το LLM λαμβάνει μη δομημένα δεδομένα με τη μορφή της γραπτής προτροπής και επιστρέφει επίσης μη δομημένα δεδομένα. Χρειαζόμαστε μια δομημένη μορφή ώστε να ξέρουμε τι να περιμένουμε όταν αποθηκεύουμε ή χρησιμοποιούμε αυτά τα δεδομένα.\n",
    "\n",
    "Χρησιμοποιώντας κλήση λειτουργίας, μπορούμε να βεβαιωθούμε ότι λαμβάνουμε δομημένα δεδομένα πίσω. Όταν χρησιμοποιούμε κλήση λειτουργίας, το LLM δεν καλεί ή εκτελεί πραγματικά καμία λειτουργία. Αντίθετα, δημιουργούμε μια δομή για να ακολουθήσει το LLM στις απαντήσεις του. Στη συνέχεια, χρησιμοποιούμε αυτές τις δομημένες απαντήσεις για να ξέρουμε ποια λειτουργία να εκτελέσουμε στις εφαρμογές μας.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Διάγραμμα Ροής Κλήσης Συνάρτησης](../../../../translated_images/Function-Flow.083875364af4f4bb.el.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορούμε στη συνέχεια να πάρουμε αυτό που επιστρέφεται από τη συνάρτηση και να το στείλουμε πίσω στο LLM. Το LLM θα απαντήσει στη συνέχεια χρησιμοποιώντας φυσική γλώσσα για να απαντήσει στο ερώτημα του χρήστη.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Περιπτώσεις Χρήσης για κλήσεις συναρτήσεων\n",
    "\n",
    "**Κλήση Εξωτερικών Εργαλείων**  \n",
    "Τα chatbots είναι εξαιρετικά στο να παρέχουν απαντήσεις σε ερωτήσεις χρηστών. Χρησιμοποιώντας κλήσεις συναρτήσεων, τα chatbots μπορούν να χρησιμοποιούν μηνύματα από χρήστες για να ολοκληρώσουν συγκεκριμένες εργασίες. Για παράδειγμα, ένας φοιτητής μπορεί να ζητήσει από το chatbot να \"Στείλει email στον καθηγητή μου λέγοντας ότι χρειάζομαι περισσότερη βοήθεια με αυτό το θέμα\". Αυτό μπορεί να κάνει μια κλήση συνάρτησης στο `send_email(to: string, body: string)`\n",
    "\n",
    "**Δημιουργία Ερωτημάτων API ή Βάσης Δεδομένων**  \n",
    "Οι χρήστες μπορούν να βρουν πληροφορίες χρησιμοποιώντας φυσική γλώσσα που μετατρέπεται σε μορφοποιημένο ερώτημα ή αίτημα API. Ένα παράδειγμα θα μπορούσε να είναι ένας δάσκαλος που ζητά \"Ποιοι είναι οι φοιτητές που ολοκλήρωσαν την τελευταία εργασία\" το οποίο θα μπορούσε να καλέσει μια συνάρτηση με όνομα `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Δημιουργία Δομημένων Δεδομένων**  \n",
    "Οι χρήστες μπορούν να πάρουν ένα μπλοκ κειμένου ή CSV και να χρησιμοποιήσουν το LLM για να εξάγουν σημαντικές πληροφορίες από αυτό. Για παράδειγμα, ένας φοιτητής μπορεί να μετατρέψει ένα άρθρο της Wikipedia για τις ειρηνευτικές συμφωνίες σε κάρτες μνήμης AI. Αυτό μπορεί να γίνει χρησιμοποιώντας μια συνάρτηση που ονομάζεται `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Δημιουργία της Πρώτης Κλήσης Συνάρτησής Σας\n",
    "\n",
    "Η διαδικασία δημιουργίας μιας κλήσης συνάρτησης περιλαμβάνει 3 βασικά βήματα:  \n",
    "1. Κλήση του Chat Completions API με μια λίστα των συναρτήσεών σας και ένα μήνυμα χρήστη  \n",
    "2. Ανάγνωση της απάντησης του μοντέλου για να εκτελέσετε μια ενέργεια, π.χ. εκτέλεση μιας συνάρτησης ή κλήση API  \n",
    "3. Κάντε μια άλλη κλήση στο Chat Completions API με την απάντηση από τη συνάρτησή σας για να χρησιμοποιήσετε αυτές τις πληροφορίες για να δημιουργήσετε μια απάντηση προς τον χρήστη.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ροή μιας Κλήσης Συνάρτησης](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.el.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Στοιχεία μιας κλήσης συνάρτησης \n",
    "\n",
    "#### Είσοδος Χρηστών \n",
    "\n",
    "Το πρώτο βήμα είναι να δημιουργήσετε ένα μήνυμα χρήστη. Αυτό μπορεί να ανατεθεί δυναμικά λαμβάνοντας την τιμή από μια είσοδο κειμένου ή μπορείτε να αναθέσετε μια τιμή εδώ. Εάν είναι η πρώτη φορά που εργάζεστε με το API Συμπληρώσεων Συνομιλίας, πρέπει να ορίσουμε το `role` και το `content` του μηνύματος. \n",
    "\n",
    "Το `role` μπορεί να είναι είτε `system` (δημιουργία κανόνων), `assistant` (το μοντέλο) ή `user` (ο τελικός χρήστης). Για κλήση συνάρτησης, θα το αναθέσουμε ως `user` και ένα παράδειγμα ερώτησης. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Δημιουργία συναρτήσεων.\n",
    "\n",
    "Στη συνέχεια θα ορίσουμε μια συνάρτηση και τις παραμέτρους αυτής της συνάρτησης. Θα χρησιμοποιήσουμε μόνο μία συνάρτηση εδώ που ονομάζεται `search_courses`, αλλά μπορείτε να δημιουργήσετε πολλές συναρτήσεις.\n",
    "\n",
    "**Σημαντικό** : Οι συναρτήσεις περιλαμβάνονται στο μήνυμα συστήματος προς το LLM και θα συμπεριληφθούν στον αριθμό των διαθέσιμων tokens που έχετε στη διάθεσή σας.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ορισμοί** \n",
    "\n",
    "Η δομή ορισμού της συνάρτησης έχει πολλαπλά επίπεδα, το καθένα με τις δικές του ιδιότητες. Ακολουθεί μια ανάλυση της εμφωλευμένης δομής:\n",
    "\n",
    "**Ιδιότητες Συνάρτησης Επιπέδου Ανώτατου:**\n",
    "\n",
    "`name` - Το όνομα της συνάρτησης που θέλουμε να κληθεί. \n",
    "\n",
    "`description` - Αυτή είναι η περιγραφή του τρόπου λειτουργίας της συνάρτησης. Εδώ είναι σημαντικό να είμαστε συγκεκριμένοι και σαφείς \n",
    "\n",
    "`parameters` - Μια λίστα τιμών και μορφής που θέλετε το μοντέλο να παράγει στην απάντησή του \n",
    "\n",
    "**Ιδιότητες Αντικειμένου Παραμέτρων:**\n",
    "\n",
    "`type` - Ο τύπος δεδομένων του αντικειμένου παραμέτρων (συνήθως \"object\")\n",
    "\n",
    "`properties` - Λίστα των συγκεκριμένων τιμών που το μοντέλο θα χρησιμοποιήσει για την απάντησή του \n",
    "\n",
    "**Ιδιότητες Ατομικής Παραμέτρου:**\n",
    "\n",
    "`name` - Ορίζεται σιωπηρά από το κλειδί της ιδιότητας (π.χ., \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Ο τύπος δεδομένων αυτής της συγκεκριμένης παραμέτρου (π.χ., \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Περιγραφή της συγκεκριμένης παραμέτρου \n",
    "\n",
    "**Προαιρετικές Ιδιότητες:**\n",
    "\n",
    "`required` - Ένας πίνακας που απαριθμεί ποιες παράμετροι απαιτούνται για να ολοκληρωθεί η κλήση της συνάρτησης \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Κλήση της συνάρτησης  \n",
    "Αφού ορίσουμε μια συνάρτηση, τώρα πρέπει να την συμπεριλάβουμε στην κλήση προς το Chat Completion API. Το κάνουμε αυτό προσθέτοντας το `functions` στο αίτημα. Σε αυτή την περίπτωση `functions=functions`.  \n",
    "\n",
    "Υπάρχει επίσης η επιλογή να ορίσουμε το `function_call` σε `auto`. Αυτό σημαίνει ότι θα αφήσουμε το LLM να αποφασίσει ποια συνάρτηση πρέπει να κληθεί βάσει του μηνύματος του χρήστη αντί να το αναθέσουμε εμείς.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα ας δούμε την απάντηση και πώς είναι μορφοποιημένη: \n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Μπορείτε να δείτε ότι το όνομα της συνάρτησης καλείται και από το μήνυμα του χρήστη, το LLM μπόρεσε να βρει τα δεδομένα που ταιριάζουν στα επιχειρήματα της συνάρτησης. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Ενσωμάτωση Κλήσεων Συναρτήσεων σε μια Εφαρμογή. \n",
    "\n",
    "\n",
    "Αφού έχουμε δοκιμάσει την μορφοποιημένη απάντηση από το LLM, τώρα μπορούμε να την ενσωματώσουμε σε μια εφαρμογή. \n",
    "\n",
    "### Διαχείριση της ροής \n",
    "\n",
    "Για να το ενσωματώσουμε στην εφαρμογή μας, ας ακολουθήσουμε τα παρακάτω βήματα: \n",
    "\n",
    "Πρώτα, ας κάνουμε την κλήση στις υπηρεσίες OpenAI και να αποθηκεύσουμε το μήνυμα σε μια μεταβλητή που ονομάζεται `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα θα ορίσουμε τη συνάρτηση που θα καλεί το Microsoft Learn API για να πάρει μια λίστα μαθημάτων:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ως βέλτιστη πρακτική, θα δούμε στη συνέχεια αν το μοντέλο θέλει να καλέσει μια συνάρτηση. Μετά από αυτό, θα δημιουργήσουμε μία από τις διαθέσιμες συναρτήσεις και θα την αντιστοιχίσουμε στη συνάρτηση που καλείται.  \n",
    "Στη συνέχεια, θα πάρουμε τα ορίσματα της συνάρτησης και θα τα αντιστοιχίσουμε στα ορίσματα από το LLM.\n",
    "\n",
    "Τέλος, θα προσθέσουμε το μήνυμα κλήσης της συνάρτησης και τις τιμές που επιστράφηκαν από το μήνυμα `search_courses`. Αυτό δίνει στο LLM όλες τις πληροφορίες που χρειάζεται για να  \n",
    "απαντήσει στον χρήστη χρησιμοποιώντας φυσική γλώσσα.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Τώρα θα στείλουμε το ενημερωμένο μήνυμα στο LLM ώστε να λάβουμε μια απάντηση σε φυσική γλώσσα αντί για μια απάντηση μορφοποιημένη σε JSON API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Πρόκληση Κώδικα \n",
    "\n",
    "Εξαιρετική δουλειά! Για να συνεχίσετε την εκμάθησή σας στο OpenAI Function Calling μπορείτε να δημιουργήσετε: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst \n",
    " - Περισσότερες παραμέτρους της συνάρτησης που μπορεί να βοηθήσουν τους μαθητές να βρουν περισσότερα μαθήματα. Μπορείτε να βρείτε τις διαθέσιμες παραμέτρους API εδώ: \n",
    " - Δημιουργήστε μια άλλη κλήση συνάρτησης που λαμβάνει περισσότερες πληροφορίες από τον μαθητή, όπως η μητρική του γλώσσα \n",
    " - Δημιουργήστε χειρισμό σφαλμάτων όταν η κλήση της συνάρτησης και/ή η κλήση API δεν επιστρέφει κατάλληλα μαθήματα\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Αποποίηση ευθυνών**:  \nΑυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που επιδιώκουμε την ακρίβεια, παρακαλούμε να λάβετε υπόψη ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T10:21:23+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "el"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}