{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Βελτιστοποίηση Μοντέλων Open AI\n",
    "\n",
    "Αυτό το σημειωματάριο βασίζεται στις τρέχουσες οδηγίες που παρέχονται στην τεκμηρίωση [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) από την Open AI.\n",
    "\n",
    "Η βελτιστοποίηση βελτιώνει την απόδοση των θεμελιωδών μοντέλων για την εφαρμογή σας, εκπαιδεύοντάς τα εκ νέου με επιπλέον δεδομένα και πλαίσιο που σχετίζονται με τη συγκεκριμένη χρήση ή σενάριο. Σημειώστε ότι οι τεχνικές μηχανικής προτροπής όπως η _few shot learning_ και η _retrieval augmented generation_ σας επιτρέπουν να ενισχύσετε την προεπιλεγμένη προτροπή με σχετικά δεδομένα για να βελτιώσετε την ποιότητα. Ωστόσο, αυτές οι προσεγγίσεις περιορίζονται από το μέγιστο μέγεθος παραθύρου token του στοχευόμενου θεμελιώδους μοντέλου.\n",
    "\n",
    "Με τη βελτιστοποίηση, επανεκπαιδεύουμε ουσιαστικά το ίδιο το μοντέλο με τα απαιτούμενα δεδομένα (επιτρέποντάς μας να χρησιμοποιήσουμε πολλά περισσότερα παραδείγματα από όσα χωρούν στο μέγιστο παράθυρο token) - και αναπτύσσουμε μια _προσαρμοσμένη_ έκδοση του μοντέλου που δεν χρειάζεται πλέον να παρέχονται παραδείγματα κατά τον χρόνο συμπερασμού. Αυτό όχι μόνο βελτιώνει την αποτελεσματικότητα του σχεδιασμού της προτροπής μας (έχουμε μεγαλύτερη ευελιξία στη χρήση του παραθύρου token για άλλα πράγματα) αλλά ενδεχομένως βελτιώνει και το κόστος μας (μειώνοντας τον αριθμό των tokens που πρέπει να στείλουμε στο μοντέλο κατά τον χρόνο συμπερασμού).\n",
    "\n",
    "Η βελτιστοποίηση έχει 4 βήματα:\n",
    "1. Προετοιμάστε τα δεδομένα εκπαίδευσης και ανεβάστε τα.\n",
    "1. Εκτελέστε τη δουλειά εκπαίδευσης για να αποκτήσετε ένα βελτιστοποιημένο μοντέλο.\n",
    "1. Αξιολογήστε το βελτιστοποιημένο μοντέλο και επαναλάβετε για ποιότητα.\n",
    "1. Αναπτύξτε το βελτιστοποιημένο μοντέλο για συμπερασμό όταν είστε ικανοποιημένοι.\n",
    "\n",
    "Σημειώστε ότι δεν υποστηρίζουν όλα τα θεμελιώδη μοντέλα τη βελτιστοποίηση - [ελέγξτε την τεκμηρίωση OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) για τις πιο πρόσφατες πληροφορίες. Μπορείτε επίσης να βελτιστοποιήσετε ένα μοντέλο που έχει ήδη βελτιστοποιηθεί προηγουμένως. Σε αυτό το σεμινάριο, θα χρησιμοποιήσουμε το `gpt-35-turbo` ως το στοχευόμενο θεμελιώδες μοντέλο για βελτιστοποίηση.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Βήμα 1.1: Προετοιμάστε το Σύνολο Δεδομένων σας\n",
    "\n",
    "Ας δημιουργήσουμε ένα chatbot που θα σας βοηθά να κατανοήσετε τον περιοδικό πίνακα των στοιχείων απαντώντας σε ερωτήσεις για ένα στοιχείο με ένα λιμερικό. Σε _αυτό_ το απλό σεμινάριο, θα δημιουργήσουμε απλώς ένα σύνολο δεδομένων για να εκπαιδεύσουμε το μοντέλο με μερικά δείγματα απαντήσεων που δείχνουν τη μορφή που αναμένεται από τα δεδομένα. Σε μια πραγματική περίπτωση χρήσης, θα χρειαστεί να δημιουργήσετε ένα σύνολο δεδομένων με πολλά περισσότερα παραδείγματα. Επίσης, μπορεί να μπορείτε να χρησιμοποιήσετε ένα ανοιχτό σύνολο δεδομένων (για τον τομέα εφαρμογής σας) αν υπάρχει, και να το αναμορφώσετε για χρήση στην εκπαίδευση.\n",
    "\n",
    "Επειδή εστιάζουμε στο `gpt-35-turbo` και αναζητούμε απάντηση μίας μόνο γύρας (συμπλήρωση συνομιλίας), μπορούμε να δημιουργήσουμε παραδείγματα χρησιμοποιώντας [αυτήν την προτεινόμενη μορφή](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) που αντανακλά τις απαιτήσεις συμπλήρωσης συνομιλίας της OpenAI. Αν περιμένετε περιεχόμενο πολλαπλών γύρων συνομιλίας, θα χρησιμοποιούσατε τη [μορφή παραδείγματος πολλαπλών γύρων](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) που περιλαμβάνει μια παράμετρο `weight` για να υποδείξει ποια μηνύματα πρέπει να χρησιμοποιηθούν (ή όχι) στη διαδικασία εκπαίδευσης.\n",
    "\n",
    "Θα χρησιμοποιήσουμε τη πιο απλή μορφή μίας μόνο γύρας για το σεμινάριό μας εδώ. Τα δεδομένα είναι σε μορφή [jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) με 1 εγγραφή ανά γραμμή, κάθε μία αναπαριστάται ως αντικείμενο μορφοποιημένο σε JSON. Το απόσπασμα παρακάτω δείχνει 2 εγγραφές ως δείγμα - δείτε το [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) για το πλήρες δείγμα (10 παραδείγματα) που θα χρησιμοποιήσουμε για το σεμινάριο εκπαίδευσης. **Σημείωση:** Κάθε εγγραφή _πρέπει_ να ορίζεται σε μία μόνο γραμμή (όχι διαχωρισμένη σε πολλές γραμμές όπως είναι τυπικό σε ένα μορφοποιημένο αρχείο JSON)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Σε μια πραγματική περίπτωση χρήσης θα χρειαστείτε ένα πολύ μεγαλύτερο σύνολο παραδειγμάτων για καλά αποτελέσματα - η ανταλλαγή θα είναι μεταξύ της ποιότητας των απαντήσεων και του χρόνου/κόστους για την εκπαίδευση. Χρησιμοποιούμε ένα μικρό σύνολο ώστε να ολοκληρώσουμε γρήγορα την εκπαίδευση για να δείξουμε τη διαδικασία. Δείτε [αυτό το παράδειγμα OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) για ένα πιο σύνθετο σεμινάριο εκπαίδευσης.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Βήμα 1.2 Μεταφόρτωση του Συνόλου Δεδομένων σας\n",
    "\n",
    "Μεταφορτώστε τα δεδομένα χρησιμοποιώντας το Files API [όπως περιγράφεται εδώ](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Σημειώστε ότι για να εκτελέσετε αυτόν τον κώδικα, πρέπει πρώτα να έχετε κάνει τα εξής βήματα:\n",
    " - Να έχετε εγκαταστήσει το πακέτο Python `openai` (βεβαιωθείτε ότι χρησιμοποιείτε έκδοση >=0.28.0 για τις πιο πρόσφατες λειτουργίες)\n",
    " - Να έχετε ορίσει τη μεταβλητή περιβάλλοντος `OPENAI_API_KEY` με το κλειδί API του OpenAI σας\n",
    "Για να μάθετε περισσότερα, δείτε τον [Οδηγό Ρύθμισης](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) που παρέχεται για το μάθημα.\n",
    "\n",
    "Τώρα, εκτελέστε τον κώδικα για να δημιουργήσετε ένα αρχείο για μεταφόρτωση από το τοπικό σας αρχείο JSONL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Βήμα 2.1: Δημιουργήστε την εργασία Fine-tuning με το SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Βήμα 2.2: Έλεγχος της Κατάστασης της εργασίας\n",
    "\n",
    "Εδώ είναι μερικά πράγματα που μπορείτε να κάνετε με το API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Λίστα με τις τελευταίες n εργασίες fine-tuning\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Λήψη λεπτομερειών για μια συγκεκριμένη εργασία fine-tuning\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Ακύρωση μιας εργασίας fine-tuning\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Λίστα με έως n γεγονότα από την εργασία\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Το πρώτο βήμα της διαδικασίας είναι _η επικύρωση του αρχείου εκπαίδευσης_ για να βεβαιωθείτε ότι τα δεδομένα είναι στη σωστή μορφή.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Βήμα 2.3: Παρακολούθηση γεγονότων για την παρακολούθηση της προόδου\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Βήμα 2.4: Προβολή κατάστασης στον Πίνακα Ελέγχου OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορείτε επίσης να δείτε την κατάσταση επισκεπτόμενοι την ιστοσελίδα της OpenAI και εξερευνώντας την ενότητα _Fine-tuning_ της πλατφόρμας. Αυτό θα σας δείξει την κατάσταση της τρέχουσας εργασίας, και επίσης θα σας επιτρέψει να παρακολουθήσετε το ιστορικό των προηγούμενων εκτελέσεων εργασιών. Σε αυτήν την εικόνα, μπορείτε να δείτε ότι η προηγούμενη εκτέλεση απέτυχε, και η δεύτερη εκτέλεση πέτυχε. Για το πλαίσιο, αυτό συνέβη όταν η πρώτη εκτέλεση χρησιμοποίησε ένα αρχείο JSON με λανθασμένα μορφοποιημένες εγγραφές - μόλις διορθώθηκε, η δεύτερη εκτέλεση ολοκληρώθηκε με επιτυχία και έκανε το μοντέλο διαθέσιμο για χρήση.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/el/fine-tuned-model-status.563271727bf7bfba.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Μπορείτε επίσης να δείτε τα μηνύματα κατάστασης και τις μετρήσεις μετακινούμενοι προς τα κάτω στο οπτικό ταμπλό όπως φαίνεται:\n",
    "\n",
    "| Μηνύματα | Μετρήσεις |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/el/fine-tuned-messages-panel.4ed0c2da5ea1313b.webp) |  ![Metrics](../../../../../translated_images/el/fine-tuned-metrics-panel.700d7e4995a65229.webp)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Βήμα 3.1: Ανάκτηση ID & Δοκιμή του Μοντέλου με Fine-Tuning στον Κώδικα\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Βήμα 3.2: Φόρτωση & Δοκιμή του Εξατομικευμένου Μοντέλου στο Playground\n",
    "\n",
    "Τώρα μπορείτε να δοκιμάσετε το εξατομικευμένο μοντέλο με δύο τρόπους. Πρώτον, μπορείτε να επισκεφτείτε το Playground και να χρησιμοποιήσετε το αναπτυσσόμενο μενού Models για να επιλέξετε το νέο εξατομικευμένο μοντέλο από τις διαθέσιμες επιλογές. Η άλλη επιλογή είναι να χρησιμοποιήσετε την επιλογή \"Playground\" που εμφανίζεται στον πίνακα Fine-tuning (δείτε το στιγμιότυπο οθόνης παραπάνω), η οποία εκκινεί την ακόλουθη _συγκριτική_ προβολή που δείχνει τις εκδόσεις του βασικού και του εξατομικευμένου μοντέλου δίπλα-δίπλα για γρήγορη αξιολόγηση.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/el/fine-tuned-playground-compare.56e06f0ad8922016.webp)\n",
    "\n",
    "Απλώς συμπληρώστε το πλαίσιο συστήματος που χρησιμοποιήθηκε στα δεδομένα εκπαίδευσής σας και δώστε την ερώτηση δοκιμής σας. Θα παρατηρήσετε ότι και οι δύο πλευρές ενημερώνονται με το ίδιο πλαίσιο και ερώτηση. Εκτελέστε τη σύγκριση και θα δείτε τη διαφορά στις απαντήσεις μεταξύ τους. _Σημειώστε πώς το εξατομικευμένο μοντέλο αποδίδει την απάντηση στη μορφή που παρείχατε στα παραδείγματά σας, ενώ το βασικό μοντέλο απλώς ακολουθεί την εντολή του συστήματος_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/el/fine-tuned-playground-launch.5a26495c983c6350.webp)\n",
    "\n",
    "Θα παρατηρήσετε επίσης ότι η σύγκριση παρέχει τους μετρητές tokens για κάθε μοντέλο, καθώς και τον χρόνο που απαιτήθηκε για την εκτέλεση της πρόβλεψης. **Αυτό το συγκεκριμένο παράδειγμα είναι απλοϊκό και έχει σκοπό να δείξει τη διαδικασία, αλλά δεν αντικατοπτρίζει πραγματικό σύνολο δεδομένων ή σενάριο**. Μπορεί να παρατηρήσετε ότι και τα δύο δείγματα εμφανίζουν τον ίδιο αριθμό tokens (το πλαίσιο συστήματος και η εντολή χρήστη είναι ταυτόσημα), με το εξατομικευμένο μοντέλο να απαιτεί περισσότερο χρόνο για την εκτέλεση της πρόβλεψης (προσαρμοσμένο μοντέλο).\n",
    "\n",
    "Σε πραγματικά σενάρια, δεν θα χρησιμοποιείτε ένα απλό παράδειγμα όπως αυτό, αλλά θα κάνετε fine-tuning με πραγματικά δεδομένα (π.χ., κατάλογο προϊόντων για εξυπηρέτηση πελατών), όπου η ποιότητα της απάντησης θα είναι πολύ πιο εμφανής. Σε _αυτό_ το πλαίσιο, η επίτευξη ισοδύναμης ποιότητας απάντησης με το βασικό μοντέλο θα απαιτήσει περισσότερη προσαρμοσμένη μηχανική προτροπών, η οποία θα αυξήσει τη χρήση tokens και πιθανώς τον σχετικό χρόνο επεξεργασίας για την πρόβλεψη. _Για να το δοκιμάσετε, δείτε τα παραδείγματα fine-tuning στο OpenAI Cookbook για να ξεκινήσετε._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Αποποίηση ευθυνών**:  \nΑυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που επιδιώκουμε την ακρίβεια, παρακαλούμε να λάβετε υπόψη ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρεξηγήσεις ή λανθασμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T10:22:15+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "el"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}