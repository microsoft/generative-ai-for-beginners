{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Για να εκτελέσετε τα παρακάτω notebooks, αν δεν το έχετε κάνει ήδη, πρέπει να ορίσετε το openai key μέσα στο αρχείο .env ως `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια, θα φορτώσουμε το Embedding Index σε ένα Pandas Dataframe. Το Embedding Index είναι αποθηκευμένο σε ένα αρχείο JSON με όνομα `embedding_index_3m.json`. Το Embedding Index περιέχει τα Embeddings για κάθε ένα από τα απομαγνητοφωνημένα κείμενα του YouTube μέχρι τα τέλη Οκτωβρίου 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Στη συνέχεια, θα δημιουργήσουμε μια συνάρτηση με όνομα `get_videos` που θα αναζητά το Embedding Index για το ερώτημα. Η συνάρτηση θα επιστρέφει τα 5 βίντεο που μοιάζουν περισσότερο με το ερώτημα. Η συνάρτηση λειτουργεί ως εξής:\n",
    "\n",
    "1. Πρώτα, δημιουργείται ένα αντίγραφο του Embedding Index.\n",
    "2. Έπειτα, υπολογίζεται το Embedding για το ερώτημα χρησιμοποιώντας το OpenAI Embedding API.\n",
    "3. Στη συνέχεια, δημιουργείται μια νέα στήλη στο Embedding Index με όνομα `similarity`. Η στήλη `similarity` περιέχει την συνημίτονο ομοιότητα (cosine similarity) μεταξύ του Embedding του ερωτήματος και του Embedding για κάθε τμήμα βίντεο.\n",
    "4. Έπειτα, το Embedding Index φιλτράρεται με βάση τη στήλη `similarity`. Το Embedding Index φιλτράρεται ώστε να περιλαμβάνει μόνο βίντεο που έχουν συνημίτονο ομοιότητα μεγαλύτερη ή ίση με 0.75.\n",
    "5. Τέλος, το Embedding Index ταξινομείται με βάση τη στήλη `similarity` και επιστρέφονται τα 5 κορυφαία βίντεο.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Αυτή η συνάρτηση είναι πολύ απλή, απλώς εκτυπώνει τα αποτελέσματα του ερωτήματος αναζήτησης.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Πρώτα, το Embedding Index φορτώνεται σε ένα Pandas Dataframe.\n",
    "2. Στη συνέχεια, ζητείται από τον χρήστη να εισάγει ένα ερώτημα.\n",
    "3. Έπειτα, καλείται η συνάρτηση `get_videos` για να αναζητήσει το ερώτημα στο Embedding Index.\n",
    "4. Τέλος, καλείται η συνάρτηση `display_results` για να εμφανίσει τα αποτελέσματα στον χρήστη.\n",
    "5. Στη συνέχεια, ζητείται από τον χρήστη να εισάγει ένα νέο ερώτημα. Αυτή η διαδικασία συνεχίζεται μέχρι ο χρήστης να πληκτρολογήσει `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.el.png)\n",
    "\n",
    "Θα σας ζητηθεί να εισάγετε ένα ερώτημα. Πληκτρολογήστε το ερώτημά σας και πατήστε enter. Η εφαρμογή θα επιστρέψει μια λίστα με βίντεο που σχετίζονται με το ερώτημά σας. Επίσης, θα εμφανιστεί ένας σύνδεσμος που οδηγεί στο σημείο του βίντεο όπου βρίσκεται η απάντηση στην ερώτησή σας.\n",
    "\n",
    "Δοκιμάστε μερικά από τα παρακάτω ερωτήματα:\n",
    "\n",
    "- Τι είναι το Azure Machine Learning;\n",
    "- Πώς λειτουργούν τα συνελικτικά νευρωνικά δίκτυα;\n",
    "- Τι είναι ένα νευρωνικό δίκτυο;\n",
    "- Μπορώ να χρησιμοποιήσω Jupyter Notebooks με το Azure Machine Learning;\n",
    "- Τι είναι το ONNX;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Αποποίηση Ευθύνης**:  \nΑυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθεια για ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρανοήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "2c0494ceb4f5fc618a6abda0b5c09c73",
   "translation_date": "2025-08-25T18:58:50+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "el"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}