{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Το παρακάτω σημειωματάριο δημιουργήθηκε αυτόματα από το GitHub Copilot Chat και προορίζεται μόνο για αρχική ρύθμιση\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Εισαγωγή στη Μηχανική Προτροπών\n",
    "Η μηχανική προτροπών είναι η διαδικασία σχεδιασμού και βελτιστοποίησης προτροπών για εργασίες επεξεργασίας φυσικής γλώσσας. Περιλαμβάνει την επιλογή των κατάλληλων προτροπών, τη ρύθμιση των παραμέτρων τους και την αξιολόγηση της απόδοσής τους. Η μηχανική προτροπών είναι απαραίτητη για την επίτευξη υψηλής ακρίβειας και αποδοτικότητας στα μοντέλα NLP. Σε αυτή την ενότητα, θα εξερευνήσουμε τα βασικά της μηχανικής προτροπών χρησιμοποιώντας τα μοντέλα της OpenAI για εξερεύνηση.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Άσκηση 1: Κατακερματισμός (Tokenization)\n",
    "Εξερευνήστε τον κατακερματισμό χρησιμοποιώντας το tiktoken, έναν ανοιχτού κώδικα και γρήγορο tokenizer από την OpenAI.\n",
    "Δείτε το [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) για περισσότερα παραδείγματα.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Άσκηση 2: Επαλήθευση Ρύθμισης Κλειδιού OpenAI API\n",
    "\n",
    "Εκτελέστε τον παρακάτω κώδικα για να βεβαιωθείτε ότι το endpoint του OpenAI έχει ρυθμιστεί σωστά. Ο κώδικας απλώς δοκιμάζει ένα απλό βασικό prompt και ελέγχει την ολοκλήρωση. Η είσοδος `oh say can you see` θα πρέπει να ολοκληρωθεί με κάτι σαν `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]       \n",
    "    response = client.chat.completions.create(   \n",
    "        model=deployment,                                         \n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Άσκηση 3: Επινοήσεις\n",
    "Εξερευνήστε τι συμβαίνει όταν ζητάτε από το LLM να επιστρέψει απαντήσεις για ένα θέμα που μπορεί να μην υπάρχει, ή για θέματα που ίσως δεν γνωρίζει επειδή ήταν εκτός του προκαθορισμένου του συνόλου δεδομένων (πιο πρόσφατα). Δείτε πώς αλλάζει η απάντηση αν δοκιμάσετε διαφορετική προτροπή ή διαφορετικό μοντέλο.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Άσκηση 4: Βασισμένη σε Οδηγίες\n",
    "Χρησιμοποίησε τη μεταβλητή \"text\" για να ορίσεις το κύριο περιεχόμενο \n",
    "και τη μεταβλητή \"prompt\" για να δώσεις μια οδηγία σχετική με αυτό το κύριο περιεχόμενο.\n",
    "\n",
    "Εδώ ζητάμε από το μοντέλο να συνοψίσει το κείμενο για έναν μαθητή δευτέρας δημοτικού.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Άσκηση 5: Σύνθετο Prompt \n",
    "Δοκιμάστε ένα αίτημα που περιλαμβάνει μηνύματα από το σύστημα, τον χρήστη και τον βοηθό \n",
    "Το σύστημα ορίζει το πλαίσιο λειτουργίας του βοηθού\n",
    "Τα μηνύματα χρήστη & βοηθού δημιουργούν ένα διάλογο με πολλαπλές αλληλεπιδράσεις\n",
    "\n",
    "Σημειώστε πώς η προσωπικότητα του βοηθού ορίζεται ως \"σαρκαστική\" στο πλαίσιο του συστήματος. \n",
    "Δοκιμάστε να χρησιμοποιήσετε ένα διαφορετικό πλαίσιο προσωπικότητας. Ή δοκιμάστε μια διαφορετική σειρά μηνυμάτων εισόδου/εξόδου\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Άσκηση: Εξερεύνησε τη Διαίσθησή σου\n",
    "Τα παραπάνω παραδείγματα σου δίνουν μοτίβα που μπορείς να χρησιμοποιήσεις για να δημιουργήσεις νέες προτροπές (απλές, σύνθετες, οδηγιών κ.ά.) - δοκίμασε να φτιάξεις άλλες ασκήσεις για να εξερευνήσεις μερικές από τις άλλες ιδέες που έχουμε συζητήσει, όπως παραδείγματα, ενδείξεις και άλλα.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Αποποίηση Ευθύνης**:  \nΑυτό το έγγραφο έχει μεταφραστεί χρησιμοποιώντας την υπηρεσία αυτόματης μετάφρασης AI [Co-op Translator](https://github.com/Azure/co-op-translator). Παρόλο που καταβάλλουμε προσπάθειες για ακρίβεια, παρακαλούμε να γνωρίζετε ότι οι αυτόματες μεταφράσεις ενδέχεται να περιέχουν λάθη ή ανακρίβειες. Το πρωτότυπο έγγραφο στη μητρική του γλώσσα θα πρέπει να θεωρείται η αυθεντική πηγή. Για κρίσιμες πληροφορίες, συνιστάται επαγγελματική ανθρώπινη μετάφραση. Δεν φέρουμε ευθύνη για τυχόν παρανοήσεις ή εσφαλμένες ερμηνείες που προκύπτουν από τη χρήση αυτής της μετάφρασης.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "9b900544221c8d986e06ee6d25debef7",
   "translation_date": "2025-08-25T13:08:29+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/aoai-assignment.ipynb",
   "language_code": "el"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}