{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baue Textgenerierungs-Apps\n",
    "\n",
    "Im bisherigen Verlauf dieses Kurses hast du bereits zentrale Konzepte wie Prompts kennengelernt und erfahren, dass es sogar ein ganzes Fachgebiet namens „Prompt Engineering“ gibt. Viele Tools, mit denen du interagieren kannst – wie ChatGPT, Office 365, Microsoft Power Platform und viele mehr – unterstützen dich dabei, mit Prompts Aufgaben zu erledigen.\n",
    "\n",
    "Um eine solche Erfahrung in deine eigene App einzubauen, musst du Begriffe wie Prompts, Completions verstehen und eine passende Bibliothek auswählen. Genau das wirst du in diesem Kapitel lernen.\n",
    "\n",
    "## Einführung\n",
    "\n",
    "In diesem Kapitel wirst du:\n",
    "\n",
    "- Die openai-Bibliothek und ihre Grundkonzepte kennenlernen.\n",
    "- Eine Textgenerierungs-App mit openai bauen.\n",
    "- Verstehen, wie du Konzepte wie Prompt, Temperatur und Tokens nutzt, um eine Textgenerierungs-App zu erstellen.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "Am Ende dieser Lektion kannst du:\n",
    "\n",
    "- Erklären, was eine Textgenerierungs-App ist.\n",
    "- Eine Textgenerierungs-App mit openai bauen.\n",
    "- Deine App so konfigurieren, dass sie mehr oder weniger Tokens verwendet und die Temperatur anpassen, um unterschiedliche Ergebnisse zu erzielen.\n",
    "\n",
    "## Was ist eine Textgenerierungs-App?\n",
    "\n",
    "Normalerweise hat eine App, die du entwickelst, eine Art Benutzeroberfläche wie zum Beispiel:\n",
    "\n",
    "- Befehlsbasiert. Konsolenanwendungen sind typische Apps, bei denen du einen Befehl eingibst und eine Aufgabe ausgeführt wird. Zum Beispiel ist `git` eine befehlsbasierte App.\n",
    "- Benutzeroberfläche (UI). Manche Apps haben grafische Benutzeroberflächen (GUIs), bei denen du auf Buttons klickst, Text eingibst, Optionen auswählst und mehr.\n",
    "\n",
    "### Konsolen- und UI-Apps sind eingeschränkt\n",
    "\n",
    "Vergleiche das mit einer befehlsbasierten App, bei der du einen Befehl eintippst:\n",
    "\n",
    "- **Sie sind eingeschränkt.** Du kannst nicht einfach jeden beliebigen Befehl eingeben, sondern nur die, die die App unterstützt.\n",
    "- **Sprachspezifisch.** Manche Apps unterstützen zwar mehrere Sprachen, aber standardmäßig ist die App für eine bestimmte Sprache gebaut, auch wenn du weitere Sprachunterstützung hinzufügen kannst.\n",
    "\n",
    "### Vorteile von Textgenerierungs-Apps\n",
    "\n",
    "Worin unterscheidet sich also eine Textgenerierungs-App?\n",
    "\n",
    "In einer Textgenerierungs-App hast du mehr Flexibilität, bist nicht auf eine bestimmte Menge an Befehlen oder eine bestimmte Eingabesprache beschränkt. Stattdessen kannst du mit natürlicher Sprache mit der App interagieren. Ein weiterer Vorteil ist, dass du mit einer Datenquelle arbeitest, die auf einer riesigen Menge an Informationen trainiert wurde, während eine klassische App oft auf die Daten in einer Datenbank beschränkt ist.\n",
    "\n",
    "### Was kann ich mit einer Textgenerierungs-App bauen?\n",
    "\n",
    "Es gibt viele Möglichkeiten. Zum Beispiel:\n",
    "\n",
    "- **Ein Chatbot.** Ein Chatbot, der Fragen zu bestimmten Themen beantwortet, etwa zu deinem Unternehmen und seinen Produkten, ist ein gutes Beispiel.\n",
    "- **Helfer.** LLMs sind hervorragend geeignet, um Texte zusammenzufassen, Erkenntnisse aus Texten zu gewinnen, Texte wie Lebensläufe zu erstellen und vieles mehr.\n",
    "- **Code-Assistent.** Je nach verwendetem Sprachmodell kannst du einen Code-Assistenten bauen, der dir beim Programmieren hilft. Zum Beispiel kannst du Produkte wie GitHub Copilot oder ChatGPT nutzen, um beim Schreiben von Code unterstützt zu werden.\n",
    "\n",
    "## Wie kann ich loslegen?\n",
    "\n",
    "Du musst einen Weg finden, dich mit einem LLM zu verbinden. Das geht in der Regel auf zwei Arten:\n",
    "\n",
    "- Über eine API. Dabei stellst du Webanfragen mit deinem Prompt und erhältst generierten Text zurück.\n",
    "- Über eine Bibliothek. Bibliotheken kapseln die API-Aufrufe und machen die Nutzung einfacher.\n",
    "\n",
    "## Bibliotheken/SDKs\n",
    "\n",
    "Es gibt einige bekannte Bibliotheken, um mit LLMs zu arbeiten, zum Beispiel:\n",
    "\n",
    "- **openai**, diese Bibliothek macht es einfach, sich mit deinem Modell zu verbinden und Prompts zu senden.\n",
    "\n",
    "Dann gibt es Bibliotheken, die auf einer höheren Ebene arbeiten, wie:\n",
    "\n",
    "- **Langchain**. Langchain ist sehr bekannt und unterstützt Python.\n",
    "- **Semantic Kernel**. Semantic Kernel ist eine Bibliothek von Microsoft und unterstützt die Sprachen C#, Python und Java.\n",
    "\n",
    "## Erste App mit GitHub Models Playground und Azure AI Inference SDK\n",
    "\n",
    "Schauen wir uns an, wie wir unsere erste App bauen können, welche Bibliotheken wir brauchen, wie viel Aufwand das ist und so weiter.\n",
    "\n",
    "### Was ist GitHub Models?\n",
    "\n",
    "Willkommen bei [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Hier kannst du verschiedene KI-Modelle, die auf Azure AI gehostet werden, direkt im Playground auf GitHub oder nahtlos in deinem bevorzugten Code-Editor kostenlos ausprobieren.\n",
    "\n",
    "### Was brauche ich?\n",
    "\n",
    "* Ein GitHub-Konto: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Anmeldung für GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Los geht’s!\n",
    "\n",
    "### Ein Modell finden und testen\n",
    "\n",
    "Gehe zu [GitHub Models im Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![GitHub Models Hauptbildschirm mit einer Liste von Modellkarten wie Cohere, Meta llama, Mistral und GPT-Modellen](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.de.png)\n",
    "\n",
    "Wähle ein Modell aus – zum Beispiel [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Hier siehst du die Modellkarte. Du kannst:\n",
    "* Direkt mit dem Modell interagieren, indem du eine Nachricht in das Textfeld eingibst\n",
    "* Details zum Modell im Readme, unter Evaluation, Transparenz und Lizenz nachlesen\n",
    "* Im Bereich „About“ auf der rechten Seite Informationen zum Modellzugang einsehen\n",
    "\n",
    "![GitHub Models GPT-4o Modellkarte](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.de.png)\n",
    "\n",
    "Wir gehen aber direkt zum Playground, indem wir auf den ['Playground'-Button oben rechts](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst) klicken. Hier kannst du mit dem Modell interagieren, System-Prompts hinzufügen und Parameter anpassen – und bekommst außerdem den kompletten Code, um das Modell von überall aus zu nutzen. Verfügbar ab September 2024: Python, Javascript, C# und REST.\n",
    "\n",
    "![GitHub Models Playground mit Code und unterstützten Sprachen](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.de.png)  \n",
    "\n",
    "### Das Modell im eigenen IDE nutzen\n",
    "\n",
    "Zwei Möglichkeiten:\n",
    "1. **GitHub Codespaces** – nahtlose Integration mit Codespaces, kein Token nötig\n",
    "2. **VS Code (oder ein beliebiges IDE)** – du benötigst ein [Personal Access Token von GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "In beiden Fällen findest du die Anleitung über den grünen „Get started“-Button oben rechts.\n",
    "\n",
    "![Get Started-Bildschirm zeigt, wie du Codespaces nutzt oder ein Personal Access Token für dein eigenes IDE einrichtest](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.de.png)\n",
    "\n",
    "### 1. Codespaces\n",
    "\n",
    "* Wähle im „Get started“-Fenster „Run codespace“\n",
    "* Erstelle einen neuen Codespace (oder nutze einen bestehenden)\n",
    "* VS Code öffnet sich im Browser mit einer Auswahl an Beispiel-Notebooks in verschiedenen Sprachen, die du ausprobieren kannst\n",
    "* Führe das Beispiel ```./githubmodels-app.py``` aus.\n",
    "\n",
    "> Hinweis: In Codespaces musst du die Github Token-Variable nicht setzen, diesen Schritt kannst du überspringen\n",
    "\n",
    "**Gehe jetzt zum Abschnitt „Text generieren“ weiter unten, um mit der Aufgabe fortzufahren**\n",
    "\n",
    "### 2. VS Code (oder ein beliebiges IDE)\n",
    "\n",
    "Über den grünen „Get started“-Button findest du alle Infos, um in deinem bevorzugten IDE loszulegen. Dieses Beispiel zeigt VS Code.\n",
    "\n",
    "* Wähle Sprache und SDK – in diesem Beispiel nehmen wir Python und das Azure AI Inference SDK\n",
    "* Erstelle ein Personal Access Token auf GitHub. Das findest du im Bereich Developer Settings. Du musst dem Token keine Berechtigungen geben. Beachte, dass das Token an einen Microsoft-Dienst gesendet wird.\n",
    "* Lege eine Umgebungsvariable an, um dein Github Personal Access Token zu speichern – Beispiele gibt es für bash, powershell und die Windows-Eingabeaufforderung\n",
    "* Installiere die Abhängigkeiten: ```pip install azure-ai-inference```\n",
    "* Kopiere den Beispielcode in eine .py-Datei\n",
    "* Navigiere zu dem Ordner, in dem dein Code gespeichert ist, und führe die Datei aus: ```python filename.py```\n",
    "\n",
    "Nicht vergessen: Mit dem Azure AI Inference SDK kannst du ganz einfach verschiedene Modelle ausprobieren, indem du den Wert von `model_name` im Code änderst.\n",
    "\n",
    "Folgende Modelle stehen im GitHub Models Service ab September 2024 zur Verfügung:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Gehe jetzt zum Abschnitt „Text generieren“ weiter unten, um mit der Aufgabe fortzufahren**\n",
    "\n",
    "## Text generieren mit ChatCompletions\n",
    "\n",
    "Um Text zu generieren, verwendest du die Klasse `ChatCompletionsClient`.\n",
    "In `samples/python/azure_ai_inference/basic.py`, im Abschnitt für die Antwort, passe den Code für die user-Rolle an, indem du den content-Parameter wie unten änderst:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Führe die aktualisierte Datei aus, um das Ergebnis zu sehen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verschiedene Arten von Prompts für verschiedene Zwecke\n",
    "\n",
    "Jetzt hast du gesehen, wie man mit einem Prompt Text generiert. Du hast sogar ein Programm, das du anpassen und verändern kannst, um verschiedene Arten von Text zu erzeugen.\n",
    "\n",
    "Prompts können für ganz unterschiedliche Aufgaben verwendet werden. Zum Beispiel:\n",
    "\n",
    "- **Einen bestimmten Texttyp generieren**. Du kannst zum Beispiel ein Gedicht, Fragen für ein Quiz usw. generieren.\n",
    "- **Informationen nachschlagen**. Mit Prompts kannst du nach Informationen suchen, wie im folgenden Beispiel: 'Was bedeutet CORS in der Webentwicklung?'.\n",
    "- **Code generieren**. Du kannst Prompts nutzen, um Code zu erzeugen, zum Beispiel eine Regular Expression zur E-Mail-Validierung oder sogar ein ganzes Programm, wie eine Web-App.\n",
    "\n",
    "## Übung: Ein Rezeptgenerator\n",
    "\n",
    "Stell dir vor, du hast Zutaten zu Hause und möchtest etwas kochen. Dafür brauchst du ein Rezept. Eine Möglichkeit, Rezepte zu finden, ist eine Suchmaschine – oder du nutzt ein LLM dafür.\n",
    "\n",
    "Du könntest zum Beispiel folgenden Prompt schreiben:\n",
    "\n",
    "> \"Zeig mir 5 Rezepte für ein Gericht mit den folgenden Zutaten: Hähnchen, Kartoffeln und Karotten. Liste bei jedem Rezept alle verwendeten Zutaten auf.\"\n",
    "\n",
    "Mit diesem Prompt könntest du eine Antwort wie diese bekommen:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Das Ergebnis ist super, ich weiß jetzt, was ich kochen kann. Was jetzt noch hilfreich wäre:\n",
    "\n",
    "- Zutaten herausfiltern, die ich nicht mag oder auf die ich allergisch bin.\n",
    "- Eine Einkaufsliste erstellen, falls ich nicht alle Zutaten zu Hause habe.\n",
    "\n",
    "Für diese Fälle ergänzen wir den Prompt:\n",
    "\n",
    "> \"Bitte entferne Rezepte mit Knoblauch, da ich allergisch bin, und ersetze ihn durch etwas anderes. Erstelle außerdem eine Einkaufsliste für die Rezepte, wobei ich Hähnchen, Kartoffeln und Karotten bereits zu Hause habe.\"\n",
    "\n",
    "Jetzt bekommst du ein neues Ergebnis, nämlich:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Das sind deine fünf Rezepte, ohne Knoblauch, und du hast auch eine Einkaufsliste, die berücksichtigt, was du schon zu Hause hast.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Übung – Erstelle einen Rezeptgenerator\n",
    "\n",
    "Nachdem wir nun ein Szenario durchgespielt haben, schreiben wir Code, der zu diesem Beispiel passt. Gehe dazu wie folgt vor:\n",
    "\n",
    "1. Nutze die vorhandene Datei als Ausgangspunkt\n",
    "1. Erstelle eine Variable namens `prompt` und passe den Beispielcode wie unten gezeigt an:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn du jetzt den Code ausführst, solltest du eine Ausgabe ähnlich wie:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "sehen.\n",
    "\n",
    "> NOTE, dein LLM ist nicht deterministisch, daher kannst du jedes Mal, wenn du das Programm ausführst, unterschiedliche Ergebnisse erhalten.\n",
    "\n",
    "Super, schauen wir uns an, wie wir das Ganze verbessern können. Um Verbesserungen vorzunehmen, wollen wir sicherstellen, dass der Code flexibel ist, sodass Zutaten und die Anzahl der Rezepte leicht angepasst und verändert werden können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Den Code einmal ausprobieren könnte so aussehen:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Verbesserung durch Filter und Einkaufsliste\n",
    "\n",
    "Wir haben jetzt eine funktionierende App, die Rezepte erstellt und flexibel ist, da sie sowohl die Anzahl der Rezepte als auch die verwendeten Zutaten vom Nutzer abfragt.\n",
    "\n",
    "Um sie weiter zu verbessern, wollen wir Folgendes hinzufügen:\n",
    "\n",
    "- **Zutaten herausfiltern**. Wir möchten Zutaten herausfiltern können, die wir nicht mögen oder auf die wir allergisch sind. Um diese Änderung umzusetzen, können wir unseren bestehenden Prompt bearbeiten und am Ende eine Filterbedingung hinzufügen, zum Beispiel so:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Hier fügen wir `{filter}` ans Ende des Prompts an und erfassen auch den Filterwert vom Nutzer.\n",
    "\n",
    "    Ein Beispiel für eine Eingabe beim Ausführen des Programms könnte jetzt so aussehen:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Einkaufsliste erstellen**. Wir möchten eine Einkaufsliste erstellen, die berücksichtigt, was wir bereits zu Hause haben.\n",
    "\n",
    "    Für diese Funktion könnten wir entweder versuchen, alles in einem Prompt zu lösen, oder wir teilen es in zwei Prompts auf. Probieren wir den zweiten Ansatz. Hier schlagen wir vor, einen zusätzlichen Prompt hinzuzufügen, aber damit das funktioniert, müssen wir das Ergebnis des ersten Prompts als Kontext für den zweiten Prompt verwenden.\n",
    "\n",
    "    Suche die Stelle im Code, an der das Ergebnis des ersten Prompts ausgegeben wird, und füge darunter folgenden Code ein:\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Beachte Folgendes:\n",
    "\n",
    "    - Wir erstellen einen neuen Prompt, indem wir das Ergebnis des ersten Prompts an den neuen Prompt anhängen:\n",
    "    \n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Wir machen eine neue Anfrage, berücksichtigen aber auch die Anzahl der Tokens, die wir im ersten Prompt angefordert haben. Dieses Mal setzen wir `max_tokens` auf 1200. **Ein Wort zur Token-Länge**: Wir sollten überlegen, wie viele Tokens wir brauchen, um den gewünschten Text zu generieren. Tokens kosten Geld, daher sollten wir möglichst sparsam damit umgehen. Zum Beispiel: Können wir den Prompt so formulieren, dass wir weniger Tokens benötigen?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Wenn wir diesen Code ausprobieren, erhalten wir nun folgende Ausgabe:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Mit Temperature experimentieren**. Temperature haben wir bisher noch nicht erwähnt, aber es ist ein wichtiger Kontext für die Funktionsweise unseres Programms. Je höher der Temperature-Wert, desto zufälliger wird die Ausgabe. Je niedriger der Wert, desto vorhersehbarer ist das Ergebnis. Überlege dir, ob du mehr Abwechslung in deiner Ausgabe möchtest oder nicht.\n",
    "\n",
    "   Um die Temperature zu ändern, kannst du den Parameter `temperature` verwenden. Wenn du zum Beispiel eine Temperature von 0.5 nutzen möchtest, würdest du Folgendes tun:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Beachte: Je näher an 1.0, desto abwechslungsreicher die Ausgabe.\n",
    "\n",
    "\n",
    "## Aufgabe\n",
    "\n",
    "Für diese Aufgabe kannst du selbst entscheiden, was du bauen möchtest.\n",
    "\n",
    "Hier ein paar Vorschläge:\n",
    "\n",
    "- Optimiere die Rezeptgenerator-App weiter. Probiere verschiedene Temperature-Werte und Prompts aus, um zu sehen, was dabei herauskommt.\n",
    "- Baue einen \"Study Buddy\". Diese App sollte Fragen zu einem Thema beantworten können, zum Beispiel Python. Du könntest Prompts wie \"Was ist ein bestimmtes Thema in Python?\" verwenden oder einen Prompt, der sagt: Zeig mir Code zu einem bestimmten Thema usw.\n",
    "- History Bot: Lass Geschichte lebendig werden, indem du den Bot anweist, eine bestimmte historische Figur zu spielen, und stelle ihm Fragen zu seinem Leben und seiner Zeit.\n",
    "\n",
    "## Lösung\n",
    "\n",
    "### Study Buddy\n",
    "\n",
    "- \"Du bist ein Experte für die Programmiersprache Python\n",
    "\n",
    "    Schlage eine Anfängerlektion für Python im folgenden Format vor:\n",
    "    \n",
    "    Format:\n",
    "    - Konzepte:\n",
    "    - Kurze Erklärung der Lektion:\n",
    "    - Übung im Code mit Lösungen\"\n",
    "\n",
    "Oben ist ein Start-Prompt, schau, wie du ihn nutzen und nach deinen Wünschen anpassen kannst.\n",
    "\n",
    "### History Bot\n",
    "\n",
    "Hier sind einige Prompts, die du verwenden könntest:\n",
    "\n",
    "- \"Du bist Abe Lincoln, erzähle mir in 3 Sätzen etwas über dich und antworte mit Grammatik und Worten, wie Abe sie benutzt hätte\"\n",
    "- \"Du bist Abe Lincoln, antworte mit Grammatik und Worten, wie Abe sie benutzt hätte:\n",
    "\n",
    "   Erzähle mir von deinen größten Errungenschaften, in 300 Wörtern:\"\n",
    "\n",
    "## Wissenscheck\n",
    "\n",
    "Was bewirkt das Konzept Temperature?\n",
    "\n",
    "1. Es steuert, wie zufällig die Ausgabe ist.\n",
    "1. Es steuert, wie groß die Antwort ist.\n",
    "1. Es steuert, wie viele Tokens verwendet werden.\n",
    "\n",
    "A: 1\n",
    "\n",
    "Was ist eine gute Möglichkeit, Geheimnisse wie API-Keys zu speichern?\n",
    "\n",
    "1. Im Code.\n",
    "1. In einer Datei.\n",
    "1. In Umgebungsvariablen.\n",
    "\n",
    "A: 3, weil Umgebungsvariablen nicht im Code gespeichert werden und vom Code geladen werden können.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ausgangssprache gilt als maßgebliche Quelle. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T14:45:44+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}