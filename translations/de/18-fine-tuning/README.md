<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:34:55+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "de"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.de.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Feinabstimmung Ihres LLM

Die Nutzung gro√üer Sprachmodelle zum Erstellen generativer KI-Anwendungen bringt neue Herausforderungen mit sich. Ein zentrales Thema ist die Sicherstellung der Antwortqualit√§t (Genauigkeit und Relevanz) bei den vom Modell generierten Inhalten f√ºr eine bestimmte Nutzeranfrage. In vorherigen Lektionen haben wir Techniken wie Prompt Engineering und Retrieval-Augmented Generation besprochen, die versuchen, das Problem durch _Anpassung der Eingabeaufforderung_ an das bestehende Modell zu l√∂sen.

In der heutigen Lektion behandeln wir eine dritte Methode, die **Feinabstimmung**, bei der die Herausforderung durch _das erneute Training des Modells selbst_ mit zus√§tzlichen Daten angegangen wird. Tauchen wir in die Details ein.

## Lernziele

Diese Lektion f√ºhrt in das Konzept der Feinabstimmung vortrainierter Sprachmodelle ein, beleuchtet die Vorteile und Herausforderungen dieses Ansatzes und gibt Hinweise, wann und wie Feinabstimmung eingesetzt werden kann, um die Leistung Ihrer generativen KI-Modelle zu verbessern.

Am Ende dieser Lektion sollten Sie folgende Fragen beantworten k√∂nnen:

- Was ist Feinabstimmung bei Sprachmodellen?
- Wann und warum ist Feinabstimmung sinnvoll?
- Wie kann ich ein vortrainiertes Modell feinabstimmen?
- Welche Einschr√§nkungen hat die Feinabstimmung?

Bereit? Dann legen wir los.

## Illustrierter Leitfaden

M√∂chten Sie einen √úberblick dar√ºber bekommen, was wir behandeln, bevor wir tiefer einsteigen? Schauen Sie sich diesen illustrierten Leitfaden an, der die Lernreise dieser Lektion beschreibt ‚Äì vom Verst√§ndnis der Kernkonzepte und Motivation f√ºr Feinabstimmung bis hin zum Prozess und den Best Practices f√ºr die Durchf√ºhrung der Feinabstimmung. Das ist ein spannendes Thema, also vergessen Sie nicht, auch die [Ressourcen](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) Seite f√ºr weitere Links zu Ihrer selbstgesteuerten Lernreise zu besuchen!

![Illustrierter Leitfaden zur Feinabstimmung von Sprachmodellen](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.de.png)

## Was ist Feinabstimmung bei Sprachmodellen?

Gro√üe Sprachmodelle sind per Definition _vortrainiert_ auf gro√üen Mengen von Texten aus verschiedenen Quellen, darunter das Internet. Wie wir in vorherigen Lektionen gelernt haben, ben√∂tigen wir Techniken wie _Prompt Engineering_ und _Retrieval-Augmented Generation_, um die Qualit√§t der Antworten des Modells auf Nutzeranfragen (‚ÄûPrompts‚Äú) zu verbessern.

Eine beliebte Technik im Prompt Engineering besteht darin, dem Modell mehr Hinweise zu geben, was in der Antwort erwartet wird, entweder durch _Anweisungen_ (explizite Anleitung) oder _einige Beispiele_ (implizite Anleitung). Dies wird als _Few-Shot-Lernen_ bezeichnet, hat aber zwei Einschr√§nkungen:

- Die Token-Limits des Modells begrenzen die Anzahl der Beispiele, die Sie geben k√∂nnen, und schr√§nken die Wirksamkeit ein.
- Die Token-Kosten k√∂nnen es teuer machen, Beispiele zu jeder Eingabeaufforderung hinzuzuf√ºgen, und schr√§nken die Flexibilit√§t ein.

Feinabstimmung ist eine g√§ngige Praxis in maschinellen Lernsystemen, bei der ein vortrainiertes Modell mit neuen Daten erneut trainiert wird, um seine Leistung f√ºr eine bestimmte Aufgabe zu verbessern. Im Kontext von Sprachmodellen k√∂nnen wir das vortrainierte Modell _mit einer kuratierten Menge von Beispielen f√ºr eine bestimmte Aufgabe oder Anwendungsdom√§ne_ feinabstimmen, um ein **kundenspezifisches Modell** zu erstellen, das f√ºr diese spezielle Aufgabe oder Dom√§ne genauer und relevanter ist. Ein Nebeneffekt der Feinabstimmung ist, dass sie auch die Anzahl der f√ºr Few-Shot-Lernen ben√∂tigten Beispiele reduzieren kann ‚Äì was den Token-Verbrauch und die damit verbundenen Kosten senkt.

## Wann und warum sollten wir Modelle feinabstimmen?

In _diesem_ Kontext sprechen wir bei Feinabstimmung von **√ºberwachter** Feinabstimmung, bei der das erneute Training durch **Hinzuf√ºgen neuer Daten** erfolgt, die nicht Teil des urspr√ºnglichen Trainingsdatensatzes waren. Dies unterscheidet sich von einem un√ºberwachten Feinabstimmungsansatz, bei dem das Modell mit den urspr√ºnglichen Daten, aber mit anderen Hyperparametern erneut trainiert wird.

Wichtig ist, dass Feinabstimmung eine fortgeschrittene Technik ist, die ein gewisses Ma√ü an Fachwissen erfordert, um die gew√ºnschten Ergebnisse zu erzielen. Wird sie falsch durchgef√ºhrt, kann sie die erwarteten Verbesserungen ausbleiben lassen oder sogar die Leistung des Modells f√ºr Ihre Ziel-Dom√§ne verschlechtern.

Bevor Sie also lernen, ‚Äûwie‚Äú man Sprachmodelle feinabstimmt, sollten Sie wissen, ‚Äûwarum‚Äú Sie diesen Weg gehen sollten und ‚Äûwann‚Äú Sie mit dem Feinabstimmungsprozess beginnen sollten. Stellen Sie sich dazu folgende Fragen:

- **Anwendungsfall**: Was ist Ihr _Anwendungsfall_ f√ºr die Feinabstimmung? Welchen Aspekt des aktuellen vortrainierten Modells m√∂chten Sie verbessern?
- **Alternativen**: Haben Sie _andere Techniken_ ausprobiert, um die gew√ºnschten Ergebnisse zu erzielen? Nutzen Sie diese als Vergleichsbasis.
  - Prompt Engineering: Probieren Sie Techniken wie Few-Shot-Prompting mit Beispielen relevanter Antworten. Bewerten Sie die Qualit√§t der Antworten.
  - Retrieval Augmented Generation: Versuchen Sie, Prompts mit Suchergebnissen aus Ihren Daten zu erg√§nzen. Bewerten Sie die Qualit√§t der Antworten.
- **Kosten**: Haben Sie die Kosten f√ºr die Feinabstimmung ermittelt?
  - Feinabstimmf√§higkeit ‚Äì ist das vortrainierte Modell f√ºr Feinabstimmung verf√ºgbar?
  - Aufwand ‚Äì f√ºr die Vorbereitung der Trainingsdaten, Bewertung und Verfeinerung des Modells.
  - Rechenleistung ‚Äì f√ºr das Ausf√ºhren der Feinabstimmungsjobs und das Bereitstellen des feinabgestimmten Modells.
  - Daten ‚Äì Zugang zu ausreichend hochwertigen Beispielen f√ºr eine wirkungsvolle Feinabstimmung.
- **Nutzen**: Haben Sie den Nutzen der Feinabstimmung best√§tigt?
  - Qualit√§t ‚Äì hat das feinabgestimmte Modell die Basislinie √ºbertroffen?
  - Kosten ‚Äì reduziert es den Token-Verbrauch durch vereinfachte Prompts?
  - Erweiterbarkeit ‚Äì k√∂nnen Sie das Basismodell f√ºr neue Dom√§nen wiederverwenden?

Wenn Sie diese Fragen beantworten, k√∂nnen Sie entscheiden, ob Feinabstimmung der richtige Ansatz f√ºr Ihren Anwendungsfall ist. Idealerweise ist der Ansatz nur dann sinnvoll, wenn der Nutzen die Kosten √ºberwiegt. Sobald Sie sich entschieden haben, ist es Zeit, dar√ºber nachzudenken, _wie_ Sie das vortrainierte Modell feinabstimmen k√∂nnen.

M√∂chten Sie mehr Einblicke in den Entscheidungsprozess? Sehen Sie sich [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs) an.

## Wie k√∂nnen wir ein vortrainiertes Modell feinabstimmen?

Um ein vortrainiertes Modell feinabzustimmen, ben√∂tigen Sie:

- ein vortrainiertes Modell zur Feinabstimmung
- einen Datensatz f√ºr die Feinabstimmung
- eine Trainingsumgebung, um den Feinabstimmungsjob auszuf√ºhren
- eine Hosting-Umgebung, um das feinabgestimmte Modell bereitzustellen

## Feinabstimmung in der Praxis

Die folgenden Ressourcen bieten Schritt-f√ºr-Schritt-Anleitungen, die Sie durch ein praktisches Beispiel mit einem ausgew√§hlten Modell und einem kuratierten Datensatz f√ºhren. Um diese Tutorials durchzuarbeiten, ben√∂tigen Sie ein Konto beim jeweiligen Anbieter sowie Zugriff auf das relevante Modell und die Datens√§tze.

| Anbieter    | Tutorial                                                                                                                                                                       | Beschreibung                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Lernen Sie, wie Sie ein `gpt-35-turbo` f√ºr eine bestimmte Dom√§ne (‚ÄûRezeptassistent‚Äú) feinabstimmen, indem Sie Trainingsdaten vorbereiten, den Feinabstimmungsjob ausf√ºhren und das feinabgestimmte Modell f√ºr Inferenz verwenden.                                                                                                                                                                                                 |
| Azure OpenAI| [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Lernen Sie, wie Sie ein `gpt-35-turbo-0613` Modell **auf Azure** feinabstimmen, indem Sie Trainingsdaten erstellen und hochladen, den Feinabstimmungsjob ausf√ºhren sowie das neue Modell bereitstellen und verwenden.                                                                                                                                                                                                                 |
| Hugging Face| [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Dieser Blogbeitrag zeigt, wie man ein _offenes LLM_ (z. B. `CodeLlama 7B`) mit der [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) Bibliothek und [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) sowie offenen [Datens√§tzen](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) auf Hugging Face feinabstimmt. |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain| [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (oder AutoTrain Advanced) ist eine von Hugging Face entwickelte Python-Bibliothek, die Feinabstimmung f√ºr viele verschiedene Aufgaben, einschlie√ülich LLM-Feinabstimmung, erm√∂glicht. AutoTrain ist eine No-Code-L√∂sung und die Feinabstimmung kann in Ihrer eigenen Cloud, auf Hugging Face Spaces oder lokal durchgef√ºhrt werden. Es unterst√ºtzt eine webbasierte GUI, CLI und Training √ºber YAML-Konfigurationsdateien.                          |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Aufgabe

W√§hlen Sie eines der oben genannten Tutorials aus und arbeiten Sie es durch. _Wir k√∂nnten eine Version dieser Tutorials in Jupyter Notebooks in diesem Repository zur Referenz bereitstellen. Bitte nutzen Sie die Originalquellen direkt, um die aktuellsten Versionen zu erhalten_.

## Gute Arbeit! Setzen Sie Ihr Lernen fort.

Nach Abschluss dieser Lektion schauen Sie sich unsere [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) an, um Ihr Wissen √ºber generative KI weiter zu vertiefen!

Herzlichen Gl√ºckwunsch!! Sie haben die letzte Lektion der v2-Serie dieses Kurses abgeschlossen! H√∂ren Sie nicht auf zu lernen und zu bauen. \*\*Besuchen Sie die [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) Seite f√ºr eine Liste zus√§tzlicher Empfehlungen speziell zu diesem Thema.

Unsere v1-Lektionsreihe wurde ebenfalls mit weiteren Aufgaben und Konzepten aktualisiert. Nehmen Sie sich also eine Minute Zeit, um Ihr Wissen aufzufrischen ‚Äì und bitte [teilen Sie Ihre Fragen und Ihr Feedback](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), um uns zu helfen, diese Lektionen f√ºr die Community zu verbessern.

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner Ursprungssprache ist als ma√ügebliche Quelle zu betrachten. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.