<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T16:45:39+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "de"
}
-->
[![Open Source Models](../../../../../translated_images/de/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Feinabstimmung Ihres LLM

Die Verwendung gro√üer Sprachmodelle zum Erstellen generativer KI-Anwendungen bringt neue Herausforderungen mit sich. Ein zentrales Problem ist die Sicherstellung der Antwortqualit√§t (Genauigkeit und Relevanz) bei Inhalten, die vom Modell f√ºr eine bestimmte Benutzeranfrage generiert werden. In fr√ºheren Lektionen haben wir Techniken wie Prompt Engineering und retrieval-unterst√ºtzte Generierung besprochen, die versuchen, das Problem durch _Modifikation der Eingabeaufforderung_ an das bestehende Modell zu l√∂sen.

In der heutigen Lektion besprechen wir eine dritte Technik, **Feinabstimmung**, die versucht, die Herausforderung durch _Nachtrainieren des Modells selbst_ mit zus√§tzlichen Daten zu adressieren. Lassen Sie uns in die Details eintauchen.

## Lernziele

Diese Lektion f√ºhrt in das Konzept der Feinabstimmung vortrainierter Sprachmodelle ein, beleuchtet die Vorteile und Herausforderungen dieses Ansatzes und gibt Hinweise, wann und wie man Feinabstimmung einsetzt, um die Leistung Ihrer generativen KI-Modelle zu verbessern.

Am Ende dieser Lektion sollten Sie in der Lage sein, die folgenden Fragen zu beantworten:

- Was ist Feinabstimmung bei Sprachmodellen?
- Wann und warum ist Feinabstimmung n√ºtzlich?
- Wie kann ich ein vortrainiertes Modell feinabstimmen?
- Was sind die Einschr√§nkungen der Feinabstimmung?

Bereit? Lassen Sie uns anfangen.

## Illustrierter Leitfaden

M√∂chten Sie einen √úberblick √ºber das, was wir behandeln werden, bevor wir ins Detail gehen? Schauen Sie sich diesen illustrierten Leitfaden an, der die Lernreise f√ºr diese Lektion beschreibt ‚Äì vom Erlernen der Kernkonzepte und der Motivation f√ºr Feinabstimmung bis hin zum Verst√§ndnis des Prozesses und der bew√§hrten Methoden f√ºr die Ausf√ºhrung der Feinabstimmungsaufgabe. Dies ist ein faszinierendes Thema zur Erforschung, vergessen Sie also nicht, die [Ressourcen](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) Seite f√ºr zus√§tzliche Links zu Ihrer selbstgesteuerten Lernreise zu besuchen!

![Illustrierter Leitfaden f√ºr die Feinabstimmung von Sprachmodellen](../../../../../translated_images/de/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Was ist Feinabstimmung bei Sprachmodellen?

Gro√üe Sprachmodelle sind per Definition _vortrainiert_ auf gro√üen Mengen von Text, der aus vielf√§ltigen Quellen, einschlie√ülich des Internets, stammt. Wie wir in fr√ºheren Lektionen gelernt haben, ben√∂tigen wir Techniken wie _Prompt Engineering_ und _retrieval-unterst√ºtzte Generierung_, um die Qualit√§t der Modellantworten auf Benutzerfragen (‚ÄûPrompts‚Äú) zu verbessern.

Eine beliebte Prompt-Engineering-Technik besteht darin, dem Modell mehr Anweisungen dar√ºber zu geben, was in der Antwort erwartet wird, entweder durch _Anweisungen_ (explizite Anleitung) oder _durch das Geben einiger Beispiele_ (implizite Anleitung). Dies wird als _few-shot learning_ bezeichnet, hat jedoch zwei Einschr√§nkungen:

- Die Token-Grenzen des Modells k√∂nnen die Anzahl der Beispiele beschr√§nken, die Sie geben k√∂nnen, und die Wirksamkeit begrenzen.
- Die Token-Kosten des Modells k√∂nnen es teuer machen, bei jeder Aufforderung Beispiele hinzuzuf√ºgen, und die Flexibilit√§t einschr√§nken.

Feinabstimmung ist eine g√§ngige Praxis in maschinellen Lernsystemen, bei der wir ein vortrainiertes Modell nehmen und es mit neuen Daten nachtrainieren, um seine Leistung bei einer bestimmten Aufgabe zu verbessern. Im Kontext von Sprachmodellen k√∂nnen wir das vortrainierte Modell _mit einem kuratierten Satz von Beispielen f√ºr eine bestimmte Aufgabe oder Anwendungsdom√§ne_ feinabstimmen, um ein **benutzerdefiniertes Modell** zu erstellen, das f√ºr diese spezifische Aufgabe oder Dom√§ne m√∂glicherweise genauer und relevanter ist. Ein Nebeneffekt der Feinabstimmung ist, dass sie auch die Anzahl der Beispiele f√ºr Few-Shot-Lernen reduzieren kann ‚Äì wodurch der Token-Verbrauch und die damit verbundenen Kosten gesenkt werden.

## Wann und warum sollten wir Modelle feinabstimmen?

In _diesem_ Kontext, wenn wir von Feinabstimmung sprechen, meinen wir **√ºberwachte** Feinabstimmung, bei der das Nachtrainieren durch **Hinzuf√ºgen neuer Daten** erfolgt, die nicht Teil des urspr√ºnglichen Trainingsdatensatzes waren. Dies unterscheidet sich von einem un√ºberwachten Feinabstimmungsansatz, bei dem das Modell mit den Originaldaten, aber mit anderen Hyperparametern nachtrainiert wird.

Das Wichtigste ist, sich daran zu erinnern, dass Feinabstimmung eine fortgeschrittene Technik ist, die ein gewisses Ma√ü an Fachwissen erfordert, um die gew√ºnschten Ergebnisse zu erzielen. Wenn sie falsch durchgef√ºhrt wird, kann sie die erwarteten Verbesserungen nicht liefern und sogar die Leistung des Modells f√ºr Ihre Ziel-Dom√§ne verschlechtern.

Bevor Sie also lernen, ‚Äûwie‚Äú man Sprachmodelle feinabstimmt, m√ºssen Sie wissen, ‚Äûwarum‚Äú Sie diesen Weg einschlagen sollten, und ‚Äûwann‚Äú Sie den Prozess der Feinabstimmung starten sollten. Beginnen Sie damit, sich diese Fragen zu stellen:

- **Anwendungsfall**: Was ist Ihr _Anwendungsfall_ f√ºr die Feinabstimmung? Welchen Aspekt des aktuellen vortrainierten Modells m√∂chten Sie verbessern?
- **Alternativen**: Haben Sie _andere Techniken_ ausprobiert, um die gew√ºnschten Ergebnisse zu erzielen? Nutzen Sie diese, um eine Vergleichsbasis zu schaffen.
  - Prompt Engineering: Probieren Sie Techniken wie Few-Shot-Prompting mit Beispielen relevanter Prompt-Antworten. Bewerten Sie die Qualit√§t der Antworten.
  - Retrieval Augmented Generation: Versuchen Sie, Prompts mit Suchergebnissen Ihrer Daten anzureichern. Bewerten Sie die Qualit√§t der Antworten.
- **Kosten**: Haben Sie die Kosten der Feinabstimmung identifiziert?
  - Einstellbarkeit ‚Äì ist das vortrainierte Modell f√ºr Feinabstimmung verf√ºgbar?
  - Aufwand ‚Äì f√ºr die Vorbereitung der Trainingsdaten, Bewertung & Verfeinerung des Modells.
  - Rechenleistung ‚Äì f√ºr das Ausf√ºhren von Feinabstimmungsauftr√§gen und Bereitstellung des feinabgestimmten Modells
  - Daten ‚Äì Zugriff auf gen√ºgend qualitativ hochwertige Beispiele f√ºr eine wirkungsvolle Feinabstimmung
- **Vorteile**: Haben Sie die Vorteile der Feinabstimmung best√§tigt?
  - Qualit√§t ‚Äì hat das feinabgestimmte Modell die Grundlage √ºbertroffen?
  - Kosten ‚Äì reduziert es die Token-Nutzung durch Vereinfachung der Prompts?
  - Erweiterbarkeit ‚Äì k√∂nnen Sie das Basismodell f√ºr neue Dom√§nen wiederverwenden?

Durch das Beantworten dieser Fragen sollten Sie in der Lage sein zu entscheiden, ob Feinabstimmung der richtige Ansatz f√ºr Ihren Anwendungsfall ist. Idealerweise ist der Ansatz nur dann sinnvoll, wenn die Vorteile die Kosten √ºberwiegen. Sobald Sie sich entscheiden weiterzumachen, ist es an der Zeit, dar√ºber nachzudenken, _wie_ Sie das vortrainierte Modell feinabstimmen k√∂nnen.

M√∂chten Sie mehr Einblicke in den Entscheidungsprozess? Sehen Sie sich [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs) an.

## Wie k√∂nnen wir ein vortrainiertes Modell feinabstimmen?

Um ein vortrainiertes Modell feinabzustimmen, ben√∂tigen Sie:

- ein vortrainiertes Modell zur Feinabstimmung
- einen Datensatz zur Verwendung f√ºr die Feinabstimmung
- eine Trainingsumgebung, um den Feinabstimmungsjob auszuf√ºhren
- eine Hostingumgebung, um das feinabgestimmte Modell bereitzustellen

## Feinabstimmung in Aktion

Die folgenden Ressourcen bieten Schritt-f√ºr-Schritt-Anleitungen, die Sie durch ein echtes Beispiel mit einem ausgew√§hlten Modell und einem kuratierten Datensatz f√ºhren. Um diese Tutorials zu bearbeiten, ben√∂tigen Sie ein Konto beim jeweiligen Anbieter sowie Zugang zu den entsprechenden Modellen und Datens√§tzen.

| Anbieter    | Tutorial                                                                                                                                                                       | Beschreibung                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Lernen Sie, ein `gpt-35-turbo` f√ºr eine spezifische Dom√§ne ("Rezeptassistent") feinabzustimmen, indem Sie Trainingsdaten vorbereiten, den Feinabstimmungsjob ausf√ºhren und das feinabgestimmte Modell f√ºr Inferenz verwenden.                                                                                                                                                                                                     |
| Azure OpenAI| [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Lernen Sie, ein `gpt-35-turbo-0613` Modell **auf Azure** feinabzustimmen, indem Sie Schritte zur Erstellung & zum Hochladen von Trainingsdaten durchf√ºhren, den Feinabstimmungsjob ausf√ºhren, das neue Modell bereitstellen und verwenden.                                                                                                                                                                                          |
| Hugging Face| [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Dieser Blogbeitrag f√ºhrt Sie durch die Feinabstimmung eines _offenen LLM_ (z. B. `CodeLlama 7B`) unter Verwendung der [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) Bibliothek & [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) mit offenen [Datens√§tzen](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) auf Hugging Face. |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain| [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (oder AutoTrain Advanced) ist eine von Hugging Face entwickelte Python-Bibliothek, die das Feinabstimmen f√ºr viele verschiedene Aufgaben, einschlie√ülich LLM-Feinabstimmung, erlaubt. AutoTrain ist eine No-Code-L√∂sung, und die Feinabstimmung kann in Ihrer eigenen Cloud, auf Hugging Face Spaces oder lokal durchgef√ºhrt werden. Es unterst√ºtzt sowohl eine webbasierte GUI, eine CLI als auch Training via YAML-Konfigurationsdateien.                     |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü¶• Unsloth  | [Fine-tuning LLMs with Unsloth](https://github.com/unslothai/unsloth)                                                                                                         | Unsloth ist ein Open-Source-Framework, das LLM-Feinabstimmung und Reinforcement Learning (RL) unterst√ºtzt. Unsloth erleichtert lokales Training, Evaluation und Bereitstellung mit gebrauchsfertigen [Notebooks](https://github.com/unslothai/notebooks). Es unterst√ºtzt auch Text-to-Speech (TTS), BERT und multimodale Modelle. Um zu starten, lesen Sie ihren schrittweisen [Fine-tuning LLMs Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                          |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
## Aufgabe

W√§hlen Sie eines der oben genannten Tutorials aus und arbeiten Sie es durch. _Wir k√∂nnten eine Version dieser Tutorials in Jupyter Notebooks in diesem Repo nur zu Referenzzwecken nachbilden. Bitte verwenden Sie die Originalquellen direkt, um die aktuellsten Versionen zu erhalten_.

## Gro√üartige Arbeit! Setzen Sie Ihr Lernen fort.

Nach Abschluss dieser Lektion, sehen Sie sich unsere [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) an, um Ihre Kenntnisse zu generativer KI weiter zu vertiefen!

Herzlichen Gl√ºckwunsch!! Sie haben die letzte Lektion aus der v2-Serie dieses Kurses abgeschlossen! H√∂ren Sie nicht auf zu lernen und zu entwickeln. \*\*Schauen Sie auf der [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) Seite vorbei f√ºr eine Liste zus√§tzlicher Vorschl√§ge nur zu diesem Thema.

Unsere v1-Serie von Lektionen wurde ebenfalls mit weiteren Aufgaben und Konzepten aktualisiert. Nehmen Sie sich also eine Minute Zeit, um Ihr Wissen aufzufrischen ‚Äì und bitte [teilen Sie Ihre Fragen und Ihr Feedback](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), um uns zu helfen, diese Lektionen f√ºr die Community zu verbessern.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, k√∂nnen automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten. Die Originalfassung des Dokuments in der Ausgangssprache ist als ma√ügebliche Quelle zu betrachten. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die durch die Nutzung dieser √úbersetzung entstehen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->