{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die folgenden Notebooks auszuführen, müssen Sie, falls noch nicht geschehen, ein Modell bereitstellen, das `text-embedding-ada-002` als Basismodell verwendet, und den Bereitstellungsnamen in der .env-Datei als `AZURE_OPENAI_EMBEDDINGS_ENDPOINT` festlegen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Nächstes laden wir den Embedding-Index in ein Pandas Dataframe. Der Embedding-Index ist in einer JSON-Datei namens `embedding_index_3m.json` gespeichert. Der Embedding-Index enthält die Embeddings für jedes der YouTube-Transkripte bis Ende Oktober 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Nächstes erstellen wir eine Funktion namens `get_videos`, die den Embedding-Index nach der Anfrage durchsucht. Die Funktion gibt die 5 Videos zurück, die der Anfrage am ähnlichsten sind. Die Funktion arbeitet wie folgt:\n",
    "\n",
    "1. Zuerst wird eine Kopie des Embedding-Index erstellt.\n",
    "2. Anschließend wird das Embedding für die Anfrage mithilfe der OpenAI Embedding API berechnet.\n",
    "3. Dann wird im Embedding-Index eine neue Spalte namens `similarity` erstellt. Die Spalte `similarity` enthält die Kosinus-Ähnlichkeit zwischen dem Embedding der Anfrage und dem Embedding jedes Videosegments.\n",
    "4. Danach wird der Embedding-Index anhand der Spalte `similarity` gefiltert. Es werden nur Videos berücksichtigt, deren Kosinus-Ähnlichkeit mindestens 0,75 beträgt.\n",
    "5. Abschließend wird der Embedding-Index nach der Spalte `similarity` sortiert und die 5 besten Videos werden zurückgegeben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion ist sehr einfach, sie gibt nur die Ergebnisse der Suchanfrage aus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zuerst wird der Embedding-Index in ein Pandas Dataframe geladen.\n",
    "2. Anschließend werden Sie aufgefordert, eine Suchanfrage einzugeben.\n",
    "3. Danach wird die Funktion `get_videos` aufgerufen, um im Embedding-Index nach der Anfrage zu suchen.\n",
    "4. Schließlich wird die Funktion `display_results` aufgerufen, um die Ergebnisse für Sie anzuzeigen.\n",
    "5. Danach werden Sie erneut aufgefordert, eine weitere Suchanfrage einzugeben. Dieser Vorgang wiederholt sich, bis Sie `exit` eingeben.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.de.png)\n",
    "\n",
    "Sie werden aufgefordert, eine Suchanfrage einzugeben. Geben Sie eine Anfrage ein und drücken Sie die Eingabetaste. Die Anwendung gibt eine Liste von Videos zurück, die zur Anfrage passen. Außerdem erhalten Sie einen Link zu der Stelle im Video, an der die Antwort auf Ihre Frage zu finden ist.\n",
    "\n",
    "Hier sind einige Beispielanfragen, die Sie ausprobieren können:\n",
    "\n",
    "- Was ist Azure Machine Learning?\n",
    "- Wie funktionieren Convolutional Neural Networks?\n",
    "- Was ist ein neuronales Netzwerk?\n",
    "- Kann ich Jupyter Notebooks mit Azure Machine Learning verwenden?\n",
    "- Was ist ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ausgangssprache gilt als maßgebliche Quelle. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "32c6b8e9e87156b9c63ee62a6fd7f526",
   "translation_date": "2025-08-25T18:38:07+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}