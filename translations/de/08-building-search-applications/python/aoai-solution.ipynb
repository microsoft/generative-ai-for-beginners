{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um die folgenden Notebooks auszuführen, müssen Sie, falls noch nicht geschehen, ein Modell bereitstellen, das `text-embedding-ada-002` als Basismodell verwendet, und den Bereitstellungsnamen in der .env-Datei als `AZURE_OPENAI_EMBEDDINGS_ENDPOINT` festlegen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Nächstes laden wir den Embedding-Index in ein Pandas Dataframe. Der Embedding-Index ist in einer JSON-Datei namens `embedding_index_3m.json` gespeichert. Der Embedding-Index enthält die Embeddings für jedes der YouTube-Transkripte bis Ende Oktober 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als Nächstes erstellen wir eine Funktion namens `get_videos`, die im Embedding-Index nach der Abfrage sucht. Die Funktion gibt die 5 Videos zurück, die der Abfrage am ähnlichsten sind. Die Funktion funktioniert wie folgt:\n",
    "\n",
    "1. Zuerst wird eine Kopie des Embedding-Index erstellt.\n",
    "2. Als Nächstes wird das Embedding für die Abfrage mit der OpenAI Embedding API berechnet.\n",
    "3. Dann wird im Embedding-Index eine neue Spalte namens `similarity` erstellt. Die Spalte `similarity` enthält die Kosinusähnlichkeit zwischen dem Abfrage-Embedding und dem Embedding für jedes Videosegment.\n",
    "4. Anschließend wird der Embedding-Index anhand der Spalte `similarity` gefiltert. Der Embedding-Index wird so gefiltert, dass nur Videos enthalten sind, deren Kosinusähnlichkeit größer oder gleich 0,75 ist.\n",
    "5. Schließlich wird der Embedding-Index nach der Spalte `similarity` sortiert und die Top 5 Videos werden zurückgegeben.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Diese Funktion ist sehr einfach, sie gibt nur die Ergebnisse der Suchanfrage aus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Zuerst wird der Embedding-Index in ein Pandas Dataframe geladen.  \n",
    "2. Als Nächstes wird der Benutzer aufgefordert, eine Abfrage einzugeben.  \n",
    "3. Dann wird die Funktion `get_videos` aufgerufen, um den Embedding-Index nach der Abfrage zu durchsuchen.  \n",
    "4. Schließlich wird die Funktion `display_results` aufgerufen, um die Ergebnisse dem Benutzer anzuzeigen.  \n",
    "5. Der Benutzer wird dann aufgefordert, eine weitere Abfrage einzugeben. Dieser Vorgang wird fortgesetzt, bis der Benutzer `exit` eingibt.  \n",
    "\n",
    "![](../../../../translated_images/de/notebook-search.1e320b9c7fcbb0bc.webp)  \n",
    "\n",
    "Sie werden aufgefordert, eine Abfrage einzugeben. Geben Sie eine Abfrage ein und drücken Sie die Eingabetaste. Die Anwendung gibt eine Liste von Videos zurück, die für die Abfrage relevant sind. Die Anwendung gibt auch einen Link zu der Stelle im Video zurück, an der die Antwort auf die Frage zu finden ist.  \n",
    "\n",
    "Hier sind einige Abfragen zum Ausprobieren:  \n",
    "\n",
    "- Was ist Azure Machine Learning?  \n",
    "- Wie funktionieren konvolutionale neuronale Netze?  \n",
    "- Was ist ein neuronales Netzwerk?  \n",
    "- Kann ich Jupyter Notebooks mit Azure Machine Learning verwenden?  \n",
    "- Was ist ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ursprungssprache gilt als maßgebliche Quelle. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die aus der Nutzung dieser Übersetzung entstehen.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "ff5415e24294df268ec7e7a2b12af509",
   "translation_date": "2025-12-19T08:43:30+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}