<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0b5b016b0eb8a1cef2e3097620d8aa23",
  "translation_date": "2025-12-19T12:45:45+00:00",
  "source_file": "00-course-setup/03-providers.md",
  "language_code": "de"
}
-->
# Auswahl & Konfiguration eines LLM-Anbieters üîë

Aufgaben **k√∂nnen** auch so eingerichtet werden, dass sie gegen eine oder mehrere Large Language Model (LLM)-Bereitstellungen √ºber einen unterst√ºtzten Dienstanbieter wie OpenAI, Azure oder Hugging Face arbeiten. Diese bieten einen _gehosteten Endpunkt_ (API), auf den wir mit den richtigen Anmeldeinformationen (API-Schl√ºssel oder Token) programmgesteuert zugreifen k√∂nnen. In diesem Kurs besprechen wir diese Anbieter:

 - [OpenAI](https://platform.openai.com/docs/models?WT.mc_id=academic-105485-koreyst) mit diversen Modellen, einschlie√ülich der Kern-GPT-Serie.
 - [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/?WT.mc_id=academic-105485-koreyst) f√ºr OpenAI-Modelle mit Fokus auf Unternehmensreife
 - [Hugging Face](https://huggingface.co/docs/hub/index?WT.mc_id=academic-105485-koreyst) f√ºr Open-Source-Modelle und Inferenzserver

**Sie m√ºssen f√ºr diese √úbungen Ihre eigenen Konten verwenden**. Aufgaben sind optional, sodass Sie je nach Interesse einen, alle oder keinen der Anbieter einrichten k√∂nnen. Einige Hinweise zur Anmeldung:

| Anmeldung | Kosten | API-Schl√ºssel | Playground | Kommentare |
|:---|:---|:---|:---|:---|
| [OpenAI](https://platform.openai.com/signup?WT.mc_id=academic-105485-koreyst)| [Preise](https://openai.com/pricing#language-models?WT.mc_id=academic-105485-koreyst)| [Projektbasiert](https://platform.openai.com/api-keys?WT.mc_id=academic-105485-koreyst) | [No-Code, Web](https://platform.openai.com/playground?WT.mc_id=academic-105485-koreyst) | Mehrere Modelle verf√ºgbar |
| [Azure](https://aka.ms/azure/free?WT.mc_id=academic-105485-koreyst)| [Preise](https://azure.microsoft.com/pricing/details/cognitive-services/openai-service/?WT.mc_id=academic-105485-koreyst)| [SDK Quickstart](https://learn.microsoft.com/azure/ai-services/openai/quickstart?WT.mc_id=academic-105485-koreyst)| [Studio Quickstart](https://learn.microsoft.com/azure/ai-services/openai/quickstart?WT.mc_id=academic-105485-koreyst) |  [Zugang muss vorab beantragt werden](https://learn.microsoft.com/azure/ai-services/openai/?WT.mc_id=academic-105485-koreyst)|
| [Hugging Face](https://huggingface.co/join?WT.mc_id=academic-105485-koreyst) | [Preise](https://huggingface.co/pricing) | [Zugangstoken](https://huggingface.co/docs/hub/security-tokens?WT.mc_id=academic-105485-koreyst) | [Hugging Chat](https://huggingface.co/chat/?WT.mc_id=academic-105485-koreyst)| [Hugging Chat hat begrenzte Modelle](https://huggingface.co/chat/models?WT.mc_id=academic-105485-koreyst) |
| | | | | |

Folgen Sie den untenstehenden Anweisungen, um dieses Repository f√ºr die Verwendung mit verschiedenen Anbietern zu _konfigurieren_. Aufgaben, die einen bestimmten Anbieter erfordern, enthalten eines dieser Tags im Dateinamen:

- `aoai` - erfordert Azure OpenAI-Endpunkt, Schl√ºssel
- `oai` - erfordert OpenAI-Endpunkt, Schl√ºssel
- `hf` - erfordert Hugging Face-Token

Sie k√∂nnen einen, keinen oder alle Anbieter konfigurieren. Verwandte Aufgaben schlagen einfach mit einem Fehler fehl, wenn Anmeldeinformationen fehlen.

## Erstellen der `.env`-Datei

Wir gehen davon aus, dass Sie die obigen Hinweise bereits gelesen, sich beim entsprechenden Anbieter angemeldet und die erforderlichen Authentifizierungsdaten (API_KEY oder Token) erhalten haben. Im Fall von Azure OpenAI gehen wir davon aus, dass Sie auch eine g√ºltige Bereitstellung eines Azure OpenAI-Dienstes (Endpunkt) mit mindestens einem GPT-Modell f√ºr Chat Completion haben.

Der n√§chste Schritt ist, Ihre **lokalen Umgebungsvariablen** wie folgt zu konfigurieren:

1. Suchen Sie im Stammordner nach einer `.env.copy`-Datei, die Inhalte wie folgt haben sollte:

   ```bash
   # OpenAI Anbieter
   OPENAI_API_KEY='<add your OpenAI API key here>'

   ## Azure OpenAI
   AZURE_OPENAI_API_VERSION='2024-02-01' # Standard ist gesetzt!
   AZURE_OPENAI_API_KEY='<add your AOAI key here>'
   AZURE_OPENAI_ENDPOINT='<add your AOIA service endpoint here>'
   AZURE_OPENAI_DEPLOYMENT='<add your chat completion model name here>' 
   AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT='<add your embeddings model name here>'

   ## Hugging Face
   HUGGING_FACE_API_KEY='<add your HuggingFace API or token here>'
   ```

2. Kopieren Sie diese Datei mit dem folgenden Befehl zu `.env`. Diese Datei ist _gitignore-d_, um Geheimnisse sicher zu halten.

   ```bash
   cp .env.copy .env
   ```

3. F√ºllen Sie die Werte aus (ersetzen Sie die Platzhalter rechts vom `=`) wie im n√§chsten Abschnitt beschrieben.

4. (Optional) Wenn Sie GitHub Codespaces verwenden, haben Sie die M√∂glichkeit, Umgebungsvariablen als _Codespaces-Geheimnisse_ zu speichern, die mit diesem Repository verkn√ºpft sind. In diesem Fall m√ºssen Sie keine lokale .env-Datei einrichten. **Beachten Sie jedoch, dass diese Option nur funktioniert, wenn Sie GitHub Codespaces verwenden.** Wenn Sie stattdessen Docker Desktop verwenden, m√ºssen Sie die .env-Datei weiterhin einrichten.

## Bef√ºllen der `.env`-Datei

Werfen wir einen kurzen Blick auf die Variablennamen, um zu verstehen, was sie repr√§sentieren:

| Variable  | Beschreibung  |
| :--- | :--- |
| HUGGING_FACE_API_KEY | Dies ist das Benutzerzugangstoken, das Sie in Ihrem Profil eingerichtet haben |
| OPENAI_API_KEY | Dies ist der Autorisierungsschl√ºssel f√ºr die Nutzung des Dienstes f√ºr Nicht-Azure OpenAI-Endpunkte |
| AZURE_OPENAI_API_KEY | Dies ist der Autorisierungsschl√ºssel f√ºr die Nutzung dieses Dienstes |
| AZURE_OPENAI_ENDPOINT | Dies ist der bereitgestellte Endpunkt f√ºr eine Azure OpenAI-Ressource |
| AZURE_OPENAI_DEPLOYMENT | Dies ist der _Textgenerierung_-Modellbereitstellungsendpunkt |
| AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT | Dies ist der _Text-Embedding_-Modellbereitstellungsendpunkt |
| | |

Hinweis: Die letzten beiden Azure OpenAI-Variablen spiegeln standardm√§√üig ein Modell f√ºr Chat Completion (Textgenerierung) und Vektorsuche (Embeddings) wider. Anweisungen zum Einrichten werden in den entsprechenden Aufgaben definiert.

## Azure konfigurieren: Vom Portal

Die Azure OpenAI-Endpunkt- und Schl√ºsselwerte finden Sie im [Azure-Portal](https://portal.azure.com?WT.mc_id=academic-105485-koreyst), beginnen wir also dort.

1. Gehen Sie zum [Azure-Portal](https://portal.azure.com?WT.mc_id=academic-105485-koreyst)
1. Klicken Sie in der Seitenleiste (linkes Men√º) auf die Option **Schl√ºssel und Endpunkt**.
1. Klicken Sie auf **Schl√ºssel anzeigen** ‚Äì Sie sollten Folgendes sehen: SCHL√úSSEL 1, SCHL√úSSEL 2 und Endpunkt.
1. Verwenden Sie den Wert von SCHL√úSSEL 1 f√ºr AZURE_OPENAI_API_KEY
1. Verwenden Sie den Wert des Endpunkts f√ºr AZURE_OPENAI_ENDPOINT

Als N√§chstes ben√∂tigen wir die Endpunkte f√ºr die spezifischen Modelle, die wir bereitgestellt haben.

1. Klicken Sie in der Seitenleiste (linkes Men√º) f√ºr die Azure OpenAI-Ressource auf die Option **Modellbereitstellungen**.
1. Klicken Sie auf der Zielseite auf **Bereitstellungen verwalten**

Dies f√ºhrt Sie zur Azure OpenAI Studio-Website, wo wir die anderen Werte wie unten beschrieben finden.

## Azure konfigurieren: Vom Studio

1. Navigieren Sie zu [Azure OpenAI Studio](https://oai.azure.com?WT.mc_id=academic-105485-koreyst) **von Ihrer Ressource aus**, wie oben beschrieben.
1. Klicken Sie auf die Registerkarte **Bereitstellungen** (Seitenleiste, links), um die aktuell bereitgestellten Modelle anzuzeigen.
1. Wenn Ihr gew√ºnschtes Modell nicht bereitgestellt ist, verwenden Sie **Neue Bereitstellung erstellen**, um es bereitzustellen.
1. Sie ben√∂tigen ein _Textgenerierungs_-Modell ‚Äì wir empfehlen: **gpt-35-turbo**
1. Sie ben√∂tigen ein _Text-Embedding_-Modell ‚Äì wir empfehlen **text-embedding-ada-002**

Aktualisieren Sie nun die Umgebungsvariablen, um den verwendeten _Bereitstellungsnamen_ widerzuspiegeln. Dies ist normalerweise derselbe wie der Modellname, sofern Sie ihn nicht explizit ge√§ndert haben. Zum Beispiel k√∂nnten Sie haben:

```bash
AZURE_OPENAI_DEPLOYMENT='gpt-35-turbo'
AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT='text-embedding-ada-002'
```

**Vergessen Sie nicht, die .env-Datei nach dem Bearbeiten zu speichern**. Sie k√∂nnen die Datei jetzt schlie√üen und zu den Anweisungen zum Ausf√ºhren des Notebooks zur√ºckkehren.

## OpenAI konfigurieren: Vom Profil

 Ihren OpenAI-API-Schl√ºssel finden Sie in Ihrem [OpenAI-Konto](https://platform.openai.com/api-keys?WT.mc_id=academic-105485-koreyst). Wenn Sie noch keinen haben, k√∂nnen Sie sich anmelden und einen API-Schl√ºssel erstellen. Sobald Sie den Schl√ºssel haben, k√∂nnen Sie ihn verwenden, um die Variable `OPENAI_API_KEY` in der `.env`-Datei zu bef√ºllen.

## Hugging Face konfigurieren: Vom Profil

Ihr Hugging Face-Token finden Sie in Ihrem Profil unter [Access Tokens](https://huggingface.co/settings/tokens?WT.mc_id=academic-105485-koreyst). Ver√∂ffentlichen oder teilen Sie diese nicht √∂ffentlich. Erstellen Sie stattdessen ein neues Token f√ºr die Nutzung in diesem Projekt und kopieren Sie es in die `.env`-Datei unter der Variable `HUGGING_FACE_API_KEY`. _Hinweis:_ Dies ist technisch gesehen kein API-Schl√ºssel, wird aber f√ºr die Authentifizierung verwendet, daher behalten wir diese Namenskonvention zur Konsistenz bei.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner Ursprungssprache ist als ma√ügebliche Quelle zu betrachten. F√ºr wichtige Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die aus der Nutzung dieser √úbersetzung entstehen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->