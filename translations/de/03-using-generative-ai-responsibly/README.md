<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-17T22:55:23+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "de"
}
-->
# Verantwortungsbewusster Einsatz von generativer KI

[![Verantwortungsbewusster Einsatz von generativer KI](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.de.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _Klicken Sie auf das Bild oben, um das Video zu dieser Lektion anzusehen_

Es ist leicht, von KI und insbesondere generativer KI fasziniert zu sein, aber es ist wichtig, dar√ºber nachzudenken, wie man sie verantwortungsvoll einsetzen kann. Sie m√ºssen Aspekte wie Fairness, Schadensvermeidung und mehr ber√ºcksichtigen. Dieses Kapitel soll Ihnen den entsprechenden Kontext bieten, worauf Sie achten sollten und wie Sie aktiv Schritte unternehmen k√∂nnen, um Ihre Nutzung der KI zu verbessern.

## Einf√ºhrung

Diese Lektion behandelt:

- Warum Sie verantwortungsvolle KI priorisieren sollten, wenn Sie Anwendungen mit generativer KI entwickeln.
- Grundprinzipien der verantwortungsvollen KI und deren Bezug zur generativen KI.
- Wie Sie diese Prinzipien der verantwortungsvollen KI durch Strategien und Tools in die Praxis umsetzen k√∂nnen.

## Lernziele

Nach Abschluss dieser Lektion wissen Sie:

- Warum verantwortungsvolle KI beim Entwickeln von Anwendungen mit generativer KI wichtig ist.
- Wann Sie die Grundprinzipien der verantwortungsvollen KI ber√ºcksichtigen und anwenden sollten, wenn Sie Anwendungen mit generativer KI entwickeln.
- Welche Tools und Strategien Ihnen zur Verf√ºgung stehen, um das Konzept der verantwortungsvollen KI in die Praxis umzusetzen.

## Prinzipien der verantwortungsvollen KI

Die Begeisterung f√ºr generative KI war noch nie so gro√ü wie heute. Diese Begeisterung hat viele neue Entwickler, Aufmerksamkeit und Finanzierung in diesen Bereich gebracht. W√§hrend dies f√ºr alle, die Produkte und Unternehmen mit generativer KI entwickeln m√∂chten, sehr positiv ist, ist es auch wichtig, verantwortungsvoll vorzugehen.

Im Verlauf dieses Kurses konzentrieren wir uns darauf, unser Startup und unser Bildungsprodukt f√ºr KI aufzubauen. Wir werden die Prinzipien der verantwortungsvollen KI anwenden: Fairness, Inklusivit√§t, Zuverl√§ssigkeit/Sicherheit, Datenschutz, Transparenz und Verantwortlichkeit. Mit diesen Prinzipien werden wir untersuchen, wie sie sich auf die Nutzung der generativen KI in unseren Produkten beziehen.

## Warum sollten Sie verantwortungsvolle KI priorisieren?

Wenn Sie ein Produkt entwickeln, f√ºhrt ein menschenzentrierter Ansatz, bei dem Sie die Interessen Ihrer Nutzer im Blick behalten, zu den besten Ergebnissen.

Die Einzigartigkeit der generativen KI liegt in ihrer F√§higkeit, hilfreiche Antworten, Informationen, Anleitungen und Inhalte f√ºr Nutzer zu erstellen. Dies kann ohne viele manuelle Schritte erfolgen, was zu beeindruckenden Ergebnissen f√ºhren kann. Ohne angemessene Planung und Strategien kann dies jedoch leider auch zu sch√§dlichen Ergebnissen f√ºr Ihre Nutzer, Ihr Produkt und die Gesellschaft insgesamt f√ºhren.

Schauen wir uns einige (aber nicht alle) dieser potenziell sch√§dlichen Ergebnisse an:

### Halluzinationen

Halluzinationen sind ein Begriff, der verwendet wird, um zu beschreiben, wenn ein LLM Inhalte erzeugt, die entweder v√∂llig unsinnig sind oder nach anderen Informationsquellen nachweislich falsch sind.

Nehmen wir an, wir entwickeln eine Funktion f√ºr unser Startup, die es Sch√ºlern erm√∂glicht, historische Fragen an ein Modell zu stellen. Ein Sch√ºler stellt die Frage: `Wer war der einzige √úberlebende der Titanic?`

Das Modell gibt eine Antwort wie die folgende:

![Eingabeaufforderung mit der Frage "Wer war der einzige √úberlebende der Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Quelle: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Dies ist eine sehr selbstbewusste und ausf√ºhrliche Antwort. Leider ist sie falsch. Selbst mit minimaler Recherche w√ºrde man herausfinden, dass es mehr als einen √úberlebenden der Titanic-Katastrophe gab. F√ºr einen Sch√ºler, der gerade erst beginnt, dieses Thema zu erforschen, kann diese Antwort √ºberzeugend genug sein, um nicht hinterfragt zu werden und als Tatsache behandelt zu werden. Die Konsequenzen daraus k√∂nnen dazu f√ºhren, dass das KI-System unzuverl√§ssig ist und den Ruf unseres Startups negativ beeinflusst.

Mit jeder Iteration eines bestimmten LLM haben wir Leistungsverbesserungen bei der Minimierung von Halluzinationen gesehen. Selbst mit diesen Verbesserungen m√ºssen wir als Anwendungsentwickler und Nutzer weiterhin auf diese Einschr√§nkungen achten.

### Sch√§dliche Inhalte

Wir haben im vorherigen Abschnitt behandelt, wenn ein LLM falsche oder unsinnige Antworten erzeugt. Ein weiteres Risiko, das wir beachten m√ºssen, ist, wenn ein Modell mit sch√§dlichen Inhalten antwortet.

Sch√§dliche Inhalte k√∂nnen definiert werden als:

- Anweisungen geben oder Selbstverletzung oder Schaden an bestimmten Gruppen f√∂rdern.
- Hasserf√ºllte oder herabw√ºrdigende Inhalte.
- Anleitung zur Planung jeglicher Art von Angriffen oder Gewalttaten.
- Anweisungen geben, wie man illegale Inhalte findet oder illegale Handlungen begeht.
- Anzeige sexuell expliziter Inhalte.

F√ºr unser Startup m√∂chten wir sicherstellen, dass wir die richtigen Tools und Strategien haben, um zu verhindern, dass diese Art von Inhalten von Sch√ºlern gesehen wird.

### Mangel an Fairness

Fairness wird definiert als ‚ÄûSicherstellen, dass ein KI-System frei von Vorurteilen und Diskriminierung ist und alle Menschen fair und gleich behandelt.‚Äú In der Welt der generativen KI m√∂chten wir sicherstellen, dass ausschlie√üende Weltanschauungen marginalisierter Gruppen nicht durch die Ausgaben des Modells verst√§rkt werden.

Diese Arten von Ausgaben sind nicht nur sch√§dlich f√ºr den Aufbau positiver Produkterfahrungen f√ºr unsere Nutzer, sondern verursachen auch weiteren gesellschaftlichen Schaden. Als Anwendungsentwickler sollten wir immer eine breite und diverse Nutzerbasis im Blick behalten, wenn wir L√∂sungen mit generativer KI entwickeln.

## Wie man generative KI verantwortungsvoll einsetzt

Nachdem wir die Bedeutung von verantwortungsvoller generativer KI identifiziert haben, schauen wir uns 4 Schritte an, die wir unternehmen k√∂nnen, um unsere KI-L√∂sungen verantwortungsvoll zu entwickeln:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.de.png)

### Potenzielle Sch√§den messen

Beim Softwaretest testen wir die erwarteten Aktionen eines Nutzers in einer Anwendung. Ebenso ist das Testen einer vielf√§ltigen Reihe von Eingabeaufforderungen, die Nutzer h√∂chstwahrscheinlich verwenden werden, eine gute M√∂glichkeit, potenzielle Sch√§den zu messen.

Da unser Startup ein Bildungsprodukt entwickelt, w√§re es sinnvoll, eine Liste von bildungsbezogenen Eingabeaufforderungen vorzubereiten. Dies k√∂nnte ein bestimmtes Fachgebiet, historische Fakten und Eingabeaufforderungen zum Studentenleben abdecken.

### Potenzielle Sch√§den mindern

Es ist nun an der Zeit, Wege zu finden, wie wir den potenziellen Schaden, der durch das Modell und seine Antworten verursacht wird, verhindern oder begrenzen k√∂nnen. Wir k√∂nnen dies in 4 verschiedenen Ebenen betrachten:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.de.png)

- **Modell**. Das richtige Modell f√ºr den richtigen Anwendungsfall ausw√§hlen. Gr√∂√üere und komplexere Modelle wie GPT-4 k√∂nnen ein h√∂heres Risiko f√ºr sch√§dliche Inhalte darstellen, wenn sie auf kleinere und spezifischere Anwendungsf√§lle angewendet werden. Die Verwendung Ihrer Trainingsdaten zur Feinabstimmung reduziert ebenfalls das Risiko sch√§dlicher Inhalte.

- **Sicherheitssystem**. Ein Sicherheitssystem ist eine Reihe von Tools und Konfigurationen auf der Plattform, die das Modell bereitstellt und dabei hilft, Sch√§den zu mindern. Ein Beispiel hierf√ºr ist das Inhaltsfiltersystem im Azure OpenAI-Dienst. Systeme sollten auch Jailbreak-Angriffe und unerw√ºnschte Aktivit√§ten wie Anfragen von Bots erkennen.

- **Metaprompt**. Metaprompts und Grounding sind M√∂glichkeiten, wie wir das Modell basierend auf bestimmten Verhaltensweisen und Informationen lenken oder einschr√§nken k√∂nnen. Dies k√∂nnte die Verwendung von Systemeingaben sein, um bestimmte Grenzen des Modells zu definieren. Dar√ºber hinaus k√∂nnen Ausgaben bereitgestellt werden, die relevanter f√ºr den Umfang oder das Fachgebiet des Systems sind.

Es k√∂nnte auch die Verwendung von Techniken wie Retrieval Augmented Generation (RAG) sein, um das Modell nur Informationen aus einer Auswahl vertrauensw√ºrdiger Quellen abrufen zu lassen. Es gibt sp√§ter in diesem Kurs eine Lektion zum [Erstellen von Suchanwendungen](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Benutzererfahrung**. Die letzte Ebene ist dort, wo der Nutzer direkt √ºber die Schnittstelle unserer Anwendung mit dem Modell interagiert. Auf diese Weise k√∂nnen wir die UI/UX so gestalten, dass der Nutzer in den Arten von Eingaben, die er an das Modell senden kann, sowie in den Texten oder Bildern, die dem Nutzer angezeigt werden, eingeschr√§nkt wird. Beim Einsatz der KI-Anwendung m√ºssen wir auch transparent dar√ºber sein, was unsere generative KI-Anwendung kann und was nicht.

Wir haben eine ganze Lektion, die sich dem [Design von UX f√ºr KI-Anwendungen](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) widmet.

- **Modell bewerten**. Mit LLMs zu arbeiten kann herausfordernd sein, da wir nicht immer Kontrolle √ºber die Daten haben, auf denen das Modell trainiert wurde. Trotzdem sollten wir immer die Leistung und Ausgaben des Modells bewerten. Es ist weiterhin wichtig, die Genauigkeit, √Ñhnlichkeit, Fundiertheit und Relevanz der Ausgaben des Modells zu messen. Dies hilft, Transparenz und Vertrauen bei Stakeholdern und Nutzern zu schaffen.

### Eine verantwortungsvolle generative KI-L√∂sung betreiben

Der Aufbau einer operativen Praxis rund um Ihre KI-Anwendungen ist die letzte Phase. Dazu geh√∂rt die Zusammenarbeit mit anderen Teilen unseres Startups wie Recht und Sicherheit, um sicherzustellen, dass wir alle regulatorischen Richtlinien einhalten. Vor dem Start m√∂chten wir auch Pl√§ne f√ºr die Bereitstellung, den Umgang mit Vorf√§llen und das Rollback erstellen, um zu verhindern, dass unseren Nutzern Schaden zugef√ºgt wird.

## Tools

Auch wenn die Entwicklung verantwortungsvoller KI-L√∂sungen nach viel Arbeit klingt, ist diese Arbeit die M√ºhe wert. Mit dem Wachstum des Bereichs der generativen KI werden auch die Tools reifen, die Entwicklern helfen, Verantwortung effizient in ihre Arbeitsabl√§ufe zu integrieren. Zum Beispiel kann [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) dabei helfen, sch√§dliche Inhalte und Bilder √ºber eine API-Anfrage zu erkennen.

## Wissenstest

Worauf m√ºssen Sie achten, um eine verantwortungsvolle Nutzung von KI sicherzustellen?

1. Dass die Antwort korrekt ist.
1. Sch√§dliche Nutzung, dass KI nicht f√ºr kriminelle Zwecke verwendet wird.
1. Sicherstellen, dass die KI frei von Vorurteilen und Diskriminierung ist.

A: 2 und 3 sind korrekt. Verantwortungsvolle KI hilft Ihnen, dar√ºber nachzudenken, wie sch√§dliche Auswirkungen und Vorurteile gemindert werden k√∂nnen und mehr.

## üöÄ Herausforderung

Lesen Sie mehr √ºber [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) und sehen Sie, was Sie f√ºr Ihre Nutzung √ºbernehmen k√∂nnen.

## Gro√üartige Arbeit, setzen Sie Ihr Lernen fort

Nachdem Sie diese Lektion abgeschlossen haben, schauen Sie sich unsere [Generative AI Learning Collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) an, um Ihr Wissen √ºber generative KI weiter zu vertiefen!

Gehen Sie weiter zu Lektion 4, in der wir uns mit den [Grundlagen des Prompt Engineering](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) besch√§ftigen!

---

**Haftungsausschluss**:  
Dieses Dokument wurde mit dem KI-√úbersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) √ºbersetzt. Obwohl wir uns um Genauigkeit bem√ºhen, beachten Sie bitte, dass automatisierte √úbersetzungen Fehler oder Ungenauigkeiten enthalten k√∂nnen. Das Originaldokument in seiner urspr√ºnglichen Sprache sollte als ma√ügebliche Quelle betrachtet werden. F√ºr kritische Informationen wird eine professionelle menschliche √úbersetzung empfohlen. Wir √ºbernehmen keine Haftung f√ºr Missverst√§ndnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser √úbersetzung ergeben.