{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Erstellung einer Anwendung zur Bildgenerierung\n",
    "\n",
    "LLMs können mehr als nur Texte generieren. Es ist auch möglich, Bilder aus Textbeschreibungen zu erzeugen. Bilder als Modalität sind in vielen Bereichen äußerst nützlich, etwa in der Medizintechnik, Architektur, Tourismus, Spieleentwicklung und mehr. In diesem Kapitel schauen wir uns die zwei bekanntesten Modelle zur Bildgenerierung an: DALL-E und Midjourney.\n",
    "\n",
    "## Einführung\n",
    "\n",
    "In dieser Lektion behandeln wir:\n",
    "\n",
    "- Bildgenerierung und warum sie nützlich ist.\n",
    "- DALL-E und Midjourney: Was sind sie und wie funktionieren sie?\n",
    "- Wie man eine Anwendung zur Bildgenerierung entwickelt.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "Nach Abschluss dieser Lektion kannst du:\n",
    "\n",
    "- Eine Anwendung zur Bildgenerierung erstellen.\n",
    "- Grenzen für deine Anwendung mit Meta-Prompts festlegen.\n",
    "- Mit DALL-E und Midjourney arbeiten.\n",
    "\n",
    "## Warum eine Anwendung zur Bildgenerierung entwickeln?\n",
    "\n",
    "Anwendungen zur Bildgenerierung sind eine tolle Möglichkeit, die Fähigkeiten von Generativer KI zu erkunden. Sie können zum Beispiel genutzt werden für:\n",
    "\n",
    "- **Bildbearbeitung und -synthese**. Du kannst Bilder für verschiedene Anwendungsfälle generieren, etwa zur Bildbearbeitung oder Bildsynthese.\n",
    "\n",
    "- **Einsatz in verschiedenen Branchen**. Sie können auch verwendet werden, um Bilder für unterschiedliche Branchen zu erzeugen, wie Medizintechnik, Tourismus, Spieleentwicklung und mehr.\n",
    "\n",
    "## Szenario: Edu4All\n",
    "\n",
    "Im Rahmen dieser Lektion arbeiten wir weiterhin mit unserem Startup Edu4All. Die Schüler erstellen Bilder für ihre Aufgaben – welche Bilder sie wählen, bleibt ihnen überlassen. Sie könnten zum Beispiel Illustrationen für ihr eigenes Märchen gestalten, einen neuen Charakter für ihre Geschichte erschaffen oder ihre Ideen und Konzepte visualisieren.\n",
    "\n",
    "Hier ein Beispiel, was die Schüler von Edu4All generieren könnten, wenn sie im Unterricht an Monumenten arbeiten:\n",
    "\n",
    "![Edu4All Startup, Unterricht zu Monumenten, Eiffelturm](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.de.png)\n",
    "\n",
    "mit einem Prompt wie\n",
    "\n",
    "> „Hund neben dem Eiffelturm im frühen Morgenlicht“\n",
    "\n",
    "## Was sind DALL-E und Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) und [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) sind zwei der bekanntesten Modelle zur Bildgenerierung. Sie ermöglichen es, mit Prompts Bilder zu erzeugen.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Beginnen wir mit DALL-E, einem generativen KI-Modell, das Bilder aus Textbeschreibungen erstellt.\n",
    "\n",
    "> [DALL-E ist eine Kombination aus zwei Modellen, CLIP und diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** ist ein Modell, das sogenannte Embeddings erzeugt – numerische Darstellungen von Daten – aus Bildern und Text.\n",
    "\n",
    "- **Diffused attention** ist ein Modell, das aus diesen Embeddings Bilder generiert. DALL-E wurde mit einem Datensatz aus Bildern und Texten trainiert und kann Bilder aus Textbeschreibungen erzeugen. Zum Beispiel kann DALL-E Bilder von einer Katze mit Hut oder einem Hund mit Irokesenschnitt generieren.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney funktioniert ähnlich wie DALL-E und erzeugt Bilder aus Text-Prompts. Auch mit Midjourney kann man Bilder mit Prompts wie „Katze mit Hut“ oder „Hund mit Irokesenschnitt“ generieren.\n",
    "\n",
    "![Von Midjourney generiertes Bild, mechanische Taube](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Bildquelle Wikipedia, Bild generiert mit Midjourney*\n",
    "\n",
    "## Wie funktionieren DALL-E und Midjourney?\n",
    "\n",
    "Zunächst [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E ist ein generatives KI-Modell, das auf der Transformer-Architektur mit einem *autoregressiven Transformer* basiert.\n",
    "\n",
    "Ein *autoregressiver Transformer* beschreibt, wie ein Modell Bilder aus Textbeschreibungen erzeugt: Es generiert ein Pixel nach dem anderen und nutzt die bereits erzeugten Pixel, um das nächste zu erstellen. Dabei werden mehrere Schichten eines neuronalen Netzwerks durchlaufen, bis das Bild fertig ist.\n",
    "\n",
    "Mit diesem Prozess steuert DALL-E die Attribute, Objekte, Eigenschaften und mehr im generierten Bild. DALL-E 2 und 3 bieten dabei noch mehr Kontrolle über das erzeugte Bild.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen deiner ersten Bildgenerierungsanwendung\n",
    "\n",
    "Was braucht man also, um eine Bildgenerierungsanwendung zu bauen? Du benötigst folgende Bibliotheken:\n",
    "\n",
    "- **python-dotenv**: Es wird dringend empfohlen, diese Bibliothek zu verwenden, um deine Geheimnisse in einer *.env*-Datei außerhalb des Codes zu speichern.\n",
    "- **openai**: Mit dieser Bibliothek interagierst du mit der OpenAI API.\n",
    "- **pillow**: Damit kannst du in Python mit Bildern arbeiten.\n",
    "- **requests**: Diese Bibliothek hilft dir, HTTP-Anfragen zu stellen.\n",
    "\n",
    "1. Erstelle eine Datei *.env* mit folgendem Inhalt:\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sammle die oben genannten Bibliotheken in einer Datei namens *requirements.txt*, zum Beispiel so:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. Erstelle als Nächstes eine virtuelle Umgebung und installiere die Bibliotheken:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Für Windows verwende die folgenden Befehle, um deine virtuelle Umgebung zu erstellen und zu aktivieren:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Füge den folgenden Code in eine Datei namens *app.py* ein:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Lass uns diesen Code erklären:\n",
    "\n",
    "- Zuerst importieren wir die benötigten Bibliotheken, darunter die OpenAI-Bibliothek, die dotenv-Bibliothek, die requests-Bibliothek und die Pillow-Bibliothek.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- Danach erstellen wir das Objekt, das den API-Schlüssel aus deiner ``.env``-Datei ausliest.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- Als Nächstes erzeugen wir das Bild:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Der obige Code gibt ein JSON-Objekt zurück, das die URL des generierten Bildes enthält. Wir können die URL verwenden, um das Bild herunterzuladen und in einer Datei zu speichern.\n",
    "\n",
    "- Zum Schluss öffnen wir das Bild und zeigen es mit dem Standard-Bildbetrachter an:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Weitere Details zur Bilderzeugung\n",
    "\n",
    "Schauen wir uns den Code, der das Bild erzeugt, genauer an:\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** ist der Texteingabe, der zur Erzeugung des Bildes verwendet wird. In diesem Fall nutzen wir den Prompt „Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils“.\n",
    "- **size** ist die Größe des erzeugten Bildes. In diesem Beispiel erstellen wir ein Bild mit 1024x1024 Pixeln.\n",
    "- **n** ist die Anzahl der erzeugten Bilder. Hier werden zwei Bilder generiert.\n",
    "\n",
    "Es gibt noch weitere Möglichkeiten, was du mit Bildern machen kannst, auf die wir im nächsten Abschnitt eingehen.\n",
    "\n",
    "## Zusätzliche Möglichkeiten der Bilderzeugung\n",
    "\n",
    "Du hast bisher gesehen, wie wir mit wenigen Zeilen Python-Code ein Bild generieren konnten. Es gibt jedoch noch mehr, was du mit Bildern machen kannst.\n",
    "\n",
    "Du kannst außerdem Folgendes tun:\n",
    "\n",
    "- **Bearbeitungen durchführen**. Indem du ein bestehendes Bild, eine Maske und einen Prompt angibst, kannst du ein Bild verändern. Zum Beispiel kannst du einem Teil eines Bildes etwas hinzufügen. Stell dir unser Hasenbild vor – du könntest dem Hasen einen Hut aufsetzen. Dazu gibst du das Bild, eine Maske (die den zu ändernden Bereich markiert) und einen Textprompt an, der beschreibt, was gemacht werden soll.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    Das Ausgangsbild würde nur den Hasen enthalten, aber das Endbild hätte den Hut auf dem Hasen.\n",
    "    \n",
    "- **Variationen erstellen**. Die Idee ist, dass du ein bestehendes Bild nimmst und darum bittest, Variationen davon zu erstellen. Um eine Variation zu erzeugen, gibst du ein Bild und einen Textprompt an und verwendest Code wie folgt:\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ausgangssprache gilt als maßgebliche Quelle. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:29:46+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}