{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entwicklung einer Anwendung zur Bildgenerierung\n",
    "\n",
    "LLMs können mehr als nur Texte generieren. Es ist auch möglich, Bilder aus Textbeschreibungen zu erstellen. Bilder als zusätzliche Modalität sind in vielen Bereichen äußerst nützlich, zum Beispiel in der Medizintechnik, Architektur, im Tourismus, in der Spieleentwicklung und mehr. In diesem Kapitel schauen wir uns die zwei bekanntesten Bildgenerierungsmodelle an: DALL-E und Midjourney.\n",
    "\n",
    "## Einführung\n",
    "\n",
    "In dieser Lektion behandeln wir:\n",
    "\n",
    "- Bildgenerierung und warum sie nützlich ist.\n",
    "- DALL-E und Midjourney: Was sind sie und wie funktionieren sie?\n",
    "- Wie man eine Anwendung zur Bildgenerierung entwickelt.\n",
    "\n",
    "## Lernziele\n",
    "\n",
    "Nach Abschluss dieser Lektion kannst du:\n",
    "\n",
    "- Eine Anwendung zur Bildgenerierung erstellen.\n",
    "- Grenzen für deine Anwendung mit Meta-Prompts festlegen.\n",
    "- Mit DALL-E und Midjourney arbeiten.\n",
    "\n",
    "## Warum eine Anwendung zur Bildgenerierung entwickeln?\n",
    "\n",
    "Bildgenerierungsanwendungen sind eine tolle Möglichkeit, die Fähigkeiten von Generativer KI zu erkunden. Sie können zum Beispiel verwendet werden für:\n",
    "\n",
    "- **Bildbearbeitung und -synthese**. Du kannst Bilder für verschiedene Anwendungsfälle generieren, etwa zur Bildbearbeitung oder zur Bildsynthese.\n",
    "\n",
    "- **Einsatz in verschiedenen Branchen**. Sie können auch genutzt werden, um Bilder für unterschiedliche Branchen zu erstellen, wie Medizintechnik, Tourismus, Spieleentwicklung und mehr.\n",
    "\n",
    "## Szenario: Edu4All\n",
    "\n",
    "Im Rahmen dieser Lektion arbeiten wir weiterhin mit unserem Startup Edu4All. Die Schüler erstellen Bilder für ihre Aufgaben – welche Bilder sie wählen, bleibt ihnen überlassen. Sie könnten zum Beispiel Illustrationen für ihr eigenes Märchen gestalten, einen neuen Charakter für ihre Geschichte erschaffen oder ihre Ideen und Konzepte visualisieren.\n",
    "\n",
    "Hier ein Beispiel, was die Schüler von Edu4All generieren könnten, wenn sie im Unterricht an Monumenten arbeiten:\n",
    "\n",
    "![Edu4All Startup, Unterricht zu Monumenten, Eiffelturm](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.de.png)\n",
    "\n",
    "mit einem Prompt wie\n",
    "\n",
    "> „Hund neben dem Eiffelturm im frühen Morgenlicht“\n",
    "\n",
    "## Was sind DALL-E und Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) und [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) sind zwei der bekanntesten Bildgenerierungsmodelle. Sie ermöglichen es, mit Prompts Bilder zu erzeugen.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Beginnen wir mit DALL-E, einem Generativen KI-Modell, das Bilder aus Textbeschreibungen erstellt.\n",
    "\n",
    "> [DALL-E ist eine Kombination aus zwei Modellen, CLIP und diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** ist ein Modell, das sogenannte Embeddings erzeugt – numerische Darstellungen von Daten – aus Bildern und Text.\n",
    "\n",
    "- **Diffused attention** ist ein Modell, das aus diesen Embeddings Bilder generiert. DALL-E wurde mit einem Datensatz aus Bildern und Texten trainiert und kann Bilder aus Textbeschreibungen erstellen. Zum Beispiel kann DALL-E ein Bild von einer Katze mit Hut oder einem Hund mit Irokesenschnitt generieren.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney funktioniert ähnlich wie DALL-E und erstellt Bilder aus Text-Prompts. Auch mit Midjourney kann man Bilder mit Prompts wie „Katze mit Hut“ oder „Hund mit Irokesenschnitt“ generieren.\n",
    "\n",
    "![Von Midjourney generiertes Bild, mechanische Taube](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Bildquelle Wikipedia, Bild generiert mit Midjourney*\n",
    "\n",
    "## Wie funktionieren DALL-E und Midjourney?\n",
    "\n",
    "Zunächst [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E ist ein Generatives KI-Modell, das auf der Transformer-Architektur mit einem *autoregressiven Transformer* basiert.\n",
    "\n",
    "Ein *autoregressiver Transformer* beschreibt, wie ein Modell Bilder aus Textbeschreibungen generiert: Es erzeugt ein Pixel nach dem anderen und nutzt die bereits generierten Pixel, um das nächste zu erstellen. Das geschieht über mehrere Schichten eines neuronalen Netzwerks, bis das Bild fertig ist.\n",
    "\n",
    "Mit diesem Prozess steuert DALL-E die Attribute, Objekte, Eigenschaften und mehr im generierten Bild. DALL-E 2 und 3 bieten dabei noch mehr Kontrolle über das erzeugte Bild,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Erstellen Ihrer ersten Bildgenerierungsanwendung\n",
    "\n",
    "Was braucht man also, um eine Bildgenerierungsanwendung zu erstellen? Sie benötigen die folgenden Bibliotheken:\n",
    "\n",
    "- **python-dotenv**: Es wird dringend empfohlen, diese Bibliothek zu verwenden, um Ihre Zugangsdaten in einer *.env*-Datei getrennt vom Code zu speichern.\n",
    "- **openai**: Mit dieser Bibliothek interagieren Sie mit der OpenAI API.\n",
    "- **pillow**: Um mit Bildern in Python zu arbeiten.\n",
    "- **requests**: Diese Bibliothek hilft Ihnen, HTTP-Anfragen zu stellen.\n",
    "\n",
    "1. Erstellen Sie eine Datei *.env* mit folgendem Inhalt:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Diese Informationen finden Sie im Azure-Portal für Ihre Ressource im Abschnitt „Schlüssel und Endpunkt“.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sammle die oben genannten Bibliotheken in einer Datei namens *requirements.txt*, zum Beispiel so:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. Erstelle als Nächstes eine virtuelle Umgebung und installiere die Bibliotheken:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Für Windows verwende die folgenden Befehle, um deine virtuelle Umgebung zu erstellen und zu aktivieren:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Füge den folgenden Code in eine Datei namens *app.py* ein:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Lass uns diesen Code erklären:\n",
    "\n",
    "- Zuerst importieren wir die benötigten Bibliotheken, darunter die OpenAI-Bibliothek, die dotenv-Bibliothek, die requests-Bibliothek und die Pillow-Bibliothek.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Als Nächstes laden wir die Umgebungsvariablen aus der *.env*-Datei.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Danach legen wir den Endpunkt, den Schlüssel für die OpenAI API, die Version und den Typ fest.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Anschließend generieren wir das Bild:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Der obige Code gibt ein JSON-Objekt zurück, das die URL des generierten Bildes enthält. Wir können die URL verwenden, um das Bild herunterzuladen und in einer Datei zu speichern.\n",
    "\n",
    "- Zum Schluss öffnen wir das Bild und zeigen es mit dem Standard-Bildbetrachter an:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Weitere Details zur Bildgenerierung\n",
    "\n",
    "Schauen wir uns den Code zur Bildgenerierung genauer an:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** ist der Text, der zur Generierung des Bildes verwendet wird. In diesem Fall nutzen wir den Prompt „Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils“.\n",
    "- **size** ist die Größe des generierten Bildes. In diesem Beispiel erzeugen wir ein Bild mit 1024x1024 Pixeln.\n",
    "- **n** ist die Anzahl der generierten Bilder. Hier werden zwei Bilder erzeugt.\n",
    "- **temperature** ist ein Parameter, der die Zufälligkeit der Ausgabe eines generativen KI-Modells steuert. Der Wert liegt zwischen 0 und 1, wobei 0 bedeutet, dass die Ausgabe deterministisch ist, und 1, dass sie zufällig ist. Der Standardwert ist 0,7.\n",
    "\n",
    "Es gibt noch weitere Möglichkeiten mit Bildern, auf die wir im nächsten Abschnitt eingehen.\n",
    "\n",
    "## Zusätzliche Möglichkeiten der Bildgenerierung\n",
    "\n",
    "Du hast bisher gesehen, wie wir mit wenigen Zeilen Python-Code ein Bild generieren konnten. Es gibt jedoch noch mehr, was du mit Bildern machen kannst.\n",
    "\n",
    "Du kannst außerdem Folgendes tun:\n",
    "\n",
    "- **Bearbeitungen durchführen**. Indem du ein bestehendes Bild, eine Maske und einen Prompt angibst, kannst du ein Bild verändern. Zum Beispiel kannst du einem Teil eines Bildes etwas hinzufügen. Stell dir unser Hasenbild vor – du könntest dem Hasen einen Hut aufsetzen. Dazu gibst du das Bild, eine Maske (die den zu ändernden Bereich markiert) und einen Textprompt an, der beschreibt, was gemacht werden soll.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    Das Ausgangsbild würde nur den Hasen enthalten, aber das Endbild hätte den Hut auf dem Hasen.\n",
    "\n",
    "- **Variationen erstellen**.\n",
    "    Sieh dir unser [OpenAI-Notebook für weitere Informationen an](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Haftungsausschluss**:  \nDieses Dokument wurde mit dem KI-Übersetzungsdienst [Co-op Translator](https://github.com/Azure/co-op-translator) übersetzt. Obwohl wir uns um Genauigkeit bemühen, beachten Sie bitte, dass automatisierte Übersetzungen Fehler oder Ungenauigkeiten enthalten können. Das Originaldokument in seiner Ausgangssprache gilt als maßgebliche Quelle. Für wichtige Informationen wird eine professionelle menschliche Übersetzung empfohlen. Wir übernehmen keine Haftung für Missverständnisse oder Fehlinterpretationen, die sich aus der Nutzung dieser Übersetzung ergeben.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:06:37+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "de"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}