{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crea aplicaciones de generación de texto\n",
    "\n",
    "A lo largo de este curso has visto que existen conceptos clave como los prompts e incluso toda una disciplina llamada \"ingeniería de prompts\". Muchas herramientas con las que puedes interactuar, como ChatGPT, Office 365, Microsoft Power Platform y más, te permiten usar prompts para lograr diferentes objetivos.\n",
    "\n",
    "Si quieres añadir una experiencia similar en una aplicación, necesitas entender conceptos como prompts, completions y elegir una librería con la que trabajar. Eso es exactamente lo que aprenderás en este capítulo.\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En este capítulo, vas a:\n",
    "\n",
    "- Aprender sobre la librería openai y sus conceptos principales.\n",
    "- Crear una aplicación de generación de texto usando openai.\n",
    "- Entender cómo usar conceptos como prompt, temperatura y tokens para construir una app de generación de texto.\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Al final de esta lección, podrás:\n",
    "\n",
    "- Explicar qué es una aplicación de generación de texto.\n",
    "- Crear una aplicación de generación de texto usando openai.\n",
    "- Configurar tu app para usar más o menos tokens y también cambiar la temperatura, para obtener resultados variados.\n",
    "\n",
    "## ¿Qué es una aplicación de generación de texto?\n",
    "\n",
    "Normalmente, cuando creas una aplicación, tiene algún tipo de interfaz como las siguientes:\n",
    "\n",
    "- Basada en comandos. Las aplicaciones de consola son típicas apps donde escribes un comando y realiza una tarea. Por ejemplo, `git` es una app basada en comandos.\n",
    "- Interfaz de usuario (UI). Algunas apps tienen interfaces gráficas donde haces clic en botones, escribes texto, seleccionas opciones y más.\n",
    "\n",
    "### Las apps de consola y UI son limitadas\n",
    "\n",
    "Compáralo con una app basada en comandos donde escribes un comando:\n",
    "\n",
    "- **Es limitada**. No puedes escribir cualquier comando, solo los que la app soporta.\n",
    "- **Idioma específico**. Algunas apps soportan varios idiomas, pero por defecto la app está hecha para un idioma específico, aunque puedas añadir soporte para más idiomas.\n",
    "\n",
    "### Beneficios de las apps de generación de texto\n",
    "\n",
    "¿En qué se diferencia una app de generación de texto?\n",
    "\n",
    "En una app de generación de texto tienes más flexibilidad, no estás limitado a un conjunto de comandos o a un idioma específico de entrada. En cambio, puedes usar lenguaje natural para interactuar con la app. Otro beneficio es que ya estás interactuando con una fuente de datos que ha sido entrenada con una gran cantidad de información, mientras que una app tradicional puede estar limitada a lo que hay en una base de datos.\n",
    "\n",
    "### ¿Qué puedo crear con una app de generación de texto?\n",
    "\n",
    "Hay muchas cosas que puedes construir. Por ejemplo:\n",
    "\n",
    "- **Un chatbot**. Un chatbot que responda preguntas sobre temas como tu empresa y sus productos puede ser una buena opción.\n",
    "- **Asistente**. Los LLMs son muy buenos para tareas como resumir textos, obtener ideas a partir de texto, generar textos como currículums y más.\n",
    "- **Asistente de código**. Dependiendo del modelo de lenguaje que uses, puedes crear un asistente de código que te ayude a programar. Por ejemplo, puedes usar productos como GitHub Copilot o ChatGPT para ayudarte a escribir código.\n",
    "\n",
    "## ¿Cómo puedo empezar?\n",
    "\n",
    "Necesitas encontrar una forma de integrarte con un LLM, lo que normalmente implica dos enfoques:\n",
    "\n",
    "- Usar una API. Aquí construyes peticiones web con tu prompt y recibes texto generado como respuesta.\n",
    "- Usar una librería. Las librerías ayudan a encapsular las llamadas a la API y facilitan su uso.\n",
    "\n",
    "## Librerías/SDKs\n",
    "\n",
    "Existen algunas librerías conocidas para trabajar con LLMs como:\n",
    "\n",
    "- **openai**, esta librería facilita la conexión con tu modelo y el envío de prompts.\n",
    "\n",
    "Luego hay librerías que operan a un nivel más alto como:\n",
    "\n",
    "- **Langchain**. Langchain es muy conocida y soporta Python.\n",
    "- **Semantic Kernel**. Semantic Kernel es una librería de Microsoft que soporta C#, Python y Java.\n",
    "\n",
    "## Primera app usando GitHub Models Playground y Azure AI Inference SDK\n",
    "\n",
    "Veamos cómo podemos crear nuestra primera app, qué librerías necesitamos, cuánto trabajo requiere y más.\n",
    "\n",
    "### ¿Qué es GitHub Models?\n",
    "\n",
    "Bienvenido a [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Aquí tienes todo listo para explorar diferentes modelos de IA alojados en Azure AI, todos accesibles desde un playground en GitHub o directamente en tu IDE favorito, gratis para probar.\n",
    "\n",
    "### ¿Qué necesito?\n",
    "\n",
    "* Una cuenta de GitHub: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Registrarte en GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "¡Vamos a empezar!\n",
    "\n",
    "### Encuentra un modelo y pruébalo\n",
    "\n",
    "Navega a [GitHub Models en el Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Pantalla principal de GitHub Models mostrando una lista de tarjetas de modelos como Cohere, Meta llama, Mistral y modelos GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.es.png)\n",
    "\n",
    "Elige un modelo, por ejemplo [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Aquí verás la tarjeta del modelo. Puedes:\n",
    "* Interactuar con el modelo directamente escribiendo un mensaje en el cuadro de texto\n",
    "* Leer detalles sobre el modelo en las pestañas de readme, Evaluación, Transparencia y Licencia\n",
    "* Además de revisar la sección 'About' para el acceso al modelo a la derecha\n",
    "\n",
    "![Tarjeta de modelo GPT-4o en GitHub Models](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.es.png)\n",
    "\n",
    "Pero vamos a ir directamente al playground haciendo clic en el ['Playground' arriba a la derecha](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Aquí puedes interactuar con el modelo, añadir prompts de sistema y cambiar parámetros, pero también obtener todo el código que necesitas para ejecutarlo desde cualquier lugar. Disponible desde septiembre de 2024: Python, Javascript, C# y REST.\n",
    "\n",
    "![Experiencia de Playground de GitHub Models mostrando código y lenguajes](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.es.png)  \n",
    "\n",
    "### Usemos el modelo en nuestro propio IDE\n",
    "\n",
    "Tienes dos opciones:\n",
    "1. **GitHub Codespaces** - integración directa con Codespaces y no necesitas token para empezar\n",
    "2. **VS Code (o tu IDE favorito)** - necesitas obtener un [Personal Access Token de GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "En ambos casos, las instrucciones están disponibles en el botón verde 'Get started' arriba a la derecha.\n",
    "\n",
    "![Pantalla Get Started mostrando cómo acceder a Codespaces o usar un personal access token para configurar en tu propio IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.es.png)\n",
    "\n",
    "### 1. Codespaces\n",
    "\n",
    "* Desde la ventana 'Get started' elige \"Run codespace\"\n",
    "* Crea un nuevo codespace (o usa uno existente)\n",
    "* VS Code se abrirá en tu navegador con un conjunto de notebooks de ejemplo en varios lenguajes que puedes probar\n",
    "* Ejecuta el ejemplo ```./githubmodels-app.py```.\n",
    "\n",
    "> Nota: En codespaces no es necesario establecer la variable Github Token, puedes saltarte este paso\n",
    "\n",
    "**Ahora pasa a la sección 'Generar texto' más abajo para continuar con esta actividad**\n",
    "\n",
    "### 2. VS Code (o cualquier IDE favorito)\n",
    "\n",
    "Desde el botón verde 'Get started' tienes toda la información necesaria para ejecutar en tu IDE favorito. Este ejemplo mostrará VS Code\n",
    "\n",
    "* Selecciona el lenguaje y SDK - en este ejemplo elegimos Python y Azure AI Inference SDK\n",
    "* Crea un personal access token en GitHub. Esto se encuentra en la sección Developer Settings. No necesitas dar permisos al token. Ten en cuenta que el token se enviará a un servicio de Microsoft.\n",
    "* Crea una variable de entorno para guardar tu personal access token de Github - hay ejemplos para bash, powershell y el símbolo del sistema de Windows\n",
    "* Instala las dependencias: ```pip install azure-ai-inference```\n",
    "* Copia el código de ejemplo básico en un archivo .py\n",
    "* Navega a donde guardaste tu código y ejecuta el archivo: ```python filename.py```\n",
    "\n",
    "Recuerda que usando Azure AI Inference SDK, puedes experimentar fácilmente con diferentes modelos modificando el valor de `model_name` en el código.\n",
    "\n",
    "Los siguientes modelos están disponibles en el servicio GitHub Models a partir de septiembre de 2024:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Ahora pasa a la sección 'Generar texto' más abajo para continuar con esta actividad**\n",
    "\n",
    "## Generar texto con ChatCompletions\n",
    "\n",
    "La forma de generar texto es usando la clase `ChatCompletionsClient`.\n",
    "En `samples/python/azure_ai_inference/basic.py`, en la sección de respuesta del código, actualiza el código del rol de usuario cambiando el parámetro content por el siguiente:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Ejecuta el archivo actualizado para ver el resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes tipos de prompts, para distintas cosas\n",
    "\n",
    "Ahora ya viste cómo generar texto usando un prompt. Incluso tienes un programa funcionando que puedes modificar y cambiar para generar distintos tipos de texto.\n",
    "\n",
    "Los prompts se pueden usar para todo tipo de tareas. Por ejemplo:\n",
    "\n",
    "- **Generar un tipo de texto**. Por ejemplo, puedes generar un poema, preguntas para un cuestionario, etc.\n",
    "- **Buscar información**. Puedes usar prompts para buscar información, como en el siguiente ejemplo: '¿Qué significa CORS en desarrollo web?'.\n",
    "- **Generar código**. Puedes usar prompts para generar código, por ejemplo, crear una expresión regular para validar correos electrónicos o incluso generar un programa completo, como una aplicación web.\n",
    "\n",
    "## Ejercicio: un generador de recetas\n",
    "\n",
    "Imagina que tienes ingredientes en casa y quieres cocinar algo. Para eso, necesitas una receta. Una forma de encontrar recetas es usar un buscador o podrías usar un LLM para hacerlo.\n",
    "\n",
    "Podrías escribir un prompt como este:\n",
    "\n",
    "> \"Muéstrame 5 recetas para un plato con los siguientes ingredientes: pollo, papas y zanahorias. Por cada receta, enumera todos los ingredientes usados\"\n",
    "\n",
    "Con el prompt anterior, podrías obtener una respuesta similar a:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Este resultado es genial, ya sé qué cocinar. En este punto, algunas mejoras útiles podrían ser:\n",
    "\n",
    "- Filtrar ingredientes que no me gustan o a los que soy alérgico.\n",
    "- Generar una lista de compras, en caso de que no tenga todos los ingredientes en casa.\n",
    "\n",
    "Para los casos anteriores, vamos a añadir un prompt adicional:\n",
    "\n",
    "> \"Por favor, elimina las recetas con ajo porque soy alérgico y reemplázalo por otro ingrediente. Además, genera una lista de compras para las recetas, considerando que ya tengo pollo, papas y zanahorias en casa.\"\n",
    "\n",
    "Ahora tienes un nuevo resultado, que sería:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Ahí tienes tus cinco recetas, sin ajo y también una lista de compras considerando lo que ya tienes en casa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio - crea un generador de recetas\n",
    "\n",
    "Ahora que hemos repasado un escenario, vamos a escribir código que se ajuste al escenario mostrado. Para hacerlo, sigue estos pasos:\n",
    "\n",
    "1. Usa el archivo existente como punto de partida\n",
    "1. Crea una variable `prompt` y modifica el código de ejemplo como se muestra a continuación:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si ahora ejecutas el código, deberías ver una salida similar a:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> [!NOTE] Ten en cuenta que tu LLM no es determinista, así que podrías obtener resultados diferentes cada vez que ejecutes el programa.\n",
    "\n",
    "Genial, veamos cómo podemos mejorar las cosas. Para mejorar, queremos asegurarnos de que el código sea flexible, de modo que los ingredientes y el número de recetas puedan mejorarse y cambiarse.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar el código podría verse así:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Mejorar agregando filtro y lista de compras\n",
    "\n",
    "Ahora tenemos una aplicación funcional capaz de generar recetas y es flexible porque depende de las entradas del usuario, tanto en la cantidad de recetas como en los ingredientes utilizados.\n",
    "\n",
    "Para mejorarla aún más, queremos agregar lo siguiente:\n",
    "\n",
    "- **Filtrar ingredientes**. Queremos poder filtrar ingredientes que no nos gustan o a los que somos alérgicos. Para lograr este cambio, podemos editar nuestro prompt existente y añadir una condición de filtro al final, así:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Arriba, agregamos `{filter}` al final del prompt y también capturamos el valor del filtro del usuario.\n",
    "\n",
    "    Un ejemplo de entrada al ejecutar el programa ahora podría verse así:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Generar una lista de compras**. Queremos crear una lista de compras, considerando lo que ya tenemos en casa.\n",
    "\n",
    "    Para esta funcionalidad, podríamos intentar resolver todo en un solo prompt o dividirlo en dos. Probemos la segunda opción. Aquí sugerimos agregar un prompt adicional, pero para que funcione, necesitamos añadir el resultado del primer prompt como contexto al segundo prompt.\n",
    "\n",
    "    Ubica la parte del código que imprime el resultado del primer prompt y añade el siguiente código debajo:\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Ten en cuenta lo siguiente:\n",
    "\n",
    "    - Estamos construyendo un nuevo prompt añadiendo el resultado del primer prompt al nuevo prompt:\n",
    "\n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Hacemos una nueva solicitud, pero también considerando la cantidad de tokens que pedimos en el primer prompt, así que esta vez decimos que `max_tokens` es 1200. **Una nota sobre la longitud de los tokens**. Debemos considerar cuántos tokens necesitamos para generar el texto que queremos. Los tokens cuestan dinero, así que donde sea posible, debemos tratar de ser económicos con la cantidad de tokens que usamos. Por ejemplo, ¿podemos redactar el prompt para usar menos tokens?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Probando este código, ahora obtenemos el siguiente resultado:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Experimentando con la temperatura**. La temperatura es algo que no hemos mencionado hasta ahora pero es un contexto importante para el funcionamiento de nuestro programa. Cuanto mayor sea el valor de la temperatura, más aleatorio será el resultado. Por el contrario, cuanto menor sea el valor, más predecible será la respuesta. Piensa si quieres que tu resultado tenga variación o no.\n",
    "\n",
    "   Para modificar la temperatura, puedes usar el parámetro `temperature`. Por ejemplo, si quieres usar una temperatura de 0.5, harías lo siguiente:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Nota, cuanto más cerca de 1.0, más variado será el resultado.\n",
    "\n",
    "\n",
    "## Ejercicio\n",
    "\n",
    "Para este ejercicio, puedes elegir qué construir.\n",
    "\n",
    "Aquí tienes algunas sugerencias:\n",
    "\n",
    "- Ajusta la aplicación generadora de recetas para mejorarla aún más. Prueba diferentes valores de temperatura y modifica los prompts para ver qué puedes lograr.\n",
    "- Construye un \"compañero de estudio\". Esta aplicación debería poder responder preguntas sobre un tema, por ejemplo Python. Podrías tener prompts como \"¿Qué es cierto tema en Python?\", o podrías tener un prompt que diga, muéstrame código sobre cierto tema, etc.\n",
    "- Bot de historia, haz que la historia cobre vida, instruye al bot para que interprete a un personaje histórico y hazle preguntas sobre su vida y época.\n",
    "\n",
    "## Solución\n",
    "\n",
    "### Compañero de estudio\n",
    "\n",
    "- \"Eres un experto en el lenguaje Python\n",
    "\n",
    "    Sugiere una lección para principiantes de Python en el siguiente formato:\n",
    "    \n",
    "    Formato:\n",
    "    - conceptos:\n",
    "    - breve explicación de la lección:\n",
    "    - ejercicio en código con soluciones\"\n",
    "\n",
    "Arriba tienes un prompt inicial, prueba cómo puedes usarlo y ajustarlo a tu gusto.\n",
    "\n",
    "### Bot de historia\n",
    "\n",
    "Aquí tienes algunos prompts que podrías usar:\n",
    "\n",
    "- \"Eres Abe Lincoln, cuéntame sobre ti en 3 frases, y responde usando la gramática y palabras que Abe usaría\"\n",
    "- \"Eres Abe Lincoln, responde usando la gramática y palabras que Abe usaría:\n",
    "\n",
    "   Cuéntame sobre tus mayores logros, en 300 palabras:\"\n",
    "\n",
    "## Comprobación de conocimientos\n",
    "\n",
    "¿Qué hace el concepto de temperatura?\n",
    "\n",
    "1. Controla cuán aleatorio es el resultado.\n",
    "1. Controla cuán grande es la respuesta.\n",
    "1. Controla cuántos tokens se usan.\n",
    "\n",
    "R: 1\n",
    "\n",
    "¿Cuál es una buena forma de guardar secretos como claves de API?\n",
    "\n",
    "1. En el código.\n",
    "1. En un archivo.\n",
    "1. En variables de entorno.\n",
    "\n",
    "R: 3, porque las variables de entorno no se guardan en el código y pueden cargarse desde el código.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisión, tenga en cuenta que las traducciones automáticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que surjan del uso de esta traducción.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T14:44:31+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "es"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}