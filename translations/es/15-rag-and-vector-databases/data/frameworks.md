<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:24:46+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "es"
}
-->
# Frameworks de Redes Neuronales

Como ya hemos aprendido, para poder entrenar redes neuronales de manera eficiente necesitamos hacer dos cosas:

* Operar con tensores, por ejemplo, multiplicar, sumar y calcular funciones como sigmoid o softmax
* Calcular gradientes de todas las expresiones, para poder realizar optimizaci√≥n mediante descenso de gradiente

Aunque la biblioteca `numpy` puede hacer la primera parte, necesitamos alg√∫n mecanismo para calcular gradientes. En nuestro framework que desarrollamos en la secci√≥n anterior, tuvimos que programar manualmente todas las funciones derivadas dentro del m√©todo `backward`, que realiza la retropropagaci√≥n. Idealmente, un framework deber√≠a darnos la posibilidad de calcular gradientes de *cualquier expresi√≥n* que definamos.

Otra cosa importante es poder realizar c√°lculos en GPU, o en cualquier otra unidad de c√≥mputo especializada, como TPU. El entrenamiento de redes neuronales profundas requiere *muchos* c√°lculos, y poder paralelizar esos c√°lculos en GPUs es muy importante.

> ‚úÖ El t√©rmino 'paralelizar' significa distribuir los c√°lculos entre m√∫ltiples dispositivos.

Actualmente, los dos frameworks de redes neuronales m√°s populares son: TensorFlow y PyTorch. Ambos proporcionan una API de bajo nivel para operar con tensores tanto en CPU como en GPU. Sobre esta API de bajo nivel, existen APIs de m√°s alto nivel, llamadas Keras y PyTorch Lightning, respectivamente.

API de Bajo Nivel | TensorFlow | PyTorch
-----------------|------------|---------
API de Alto Nivel | Keras      | PyTorch

Las **APIs de bajo nivel** en ambos frameworks te permiten construir los llamados **grafos computacionales**. Este grafo define c√≥mo calcular la salida (usualmente la funci√≥n de p√©rdida) con los par√°metros de entrada dados, y puede enviarse para su c√°lculo en GPU, si est√° disponible. Existen funciones para diferenciar este grafo computacional y calcular gradientes, que luego pueden usarse para optimizar los par√°metros del modelo.

Las **APIs de alto nivel** consideran las redes neuronales como una **secuencia de capas**, y facilitan mucho la construcci√≥n de la mayor√≠a de las redes neuronales. Entrenar el modelo usualmente requiere preparar los datos y luego llamar a una funci√≥n `fit` para realizar el entrenamiento.

La API de alto nivel te permite construir redes neuronales t√≠picas muy r√°pido sin preocuparte por muchos detalles. Al mismo tiempo, la API de bajo nivel ofrece mucho m√°s control sobre el proceso de entrenamiento, por lo que se usa mucho en investigaci√≥n, cuando se trabaja con nuevas arquitecturas de redes neuronales.

Tambi√©n es importante entender que puedes usar ambas APIs juntas, por ejemplo, puedes desarrollar tu propia arquitectura de capa de red usando la API de bajo nivel, y luego usarla dentro de una red m√°s grande construida y entrenada con la API de alto nivel. O puedes definir una red usando la API de alto nivel como una secuencia de capas, y luego usar tu propio ciclo de entrenamiento de bajo nivel para realizar la optimizaci√≥n. Ambas APIs usan los mismos conceptos b√°sicos subyacentes y est√°n dise√±adas para funcionar bien juntas.

## Aprendizaje

En este curso, ofrecemos la mayor√≠a del contenido tanto para PyTorch como para TensorFlow. Puedes elegir tu framework preferido y solo seguir los notebooks correspondientes. Si no est√°s seguro de qu√© framework elegir, lee algunas discusiones en internet sobre **PyTorch vs. TensorFlow**. Tambi√©n puedes echar un vistazo a ambos frameworks para entender mejor.

Cuando sea posible, usaremos APIs de alto nivel por simplicidad. Sin embargo, creemos que es importante entender c√≥mo funcionan las redes neuronales desde cero, por lo que al principio empezamos trabajando con la API de bajo nivel y tensores. Sin embargo, si quieres avanzar r√°pido y no quieres invertir mucho tiempo en aprender estos detalles, puedes saltarte esa parte y pasar directamente a los notebooks de la API de alto nivel.

## ‚úçÔ∏è Ejercicios: Frameworks

Contin√∫a tu aprendizaje en los siguientes notebooks:

API de Bajo Nivel | Notebook TensorFlow+Keras | PyTorch
-----------------|----------------------------|---------
API de Alto Nivel | Keras                      | *PyTorch Lightning*

Despu√©s de dominar los frameworks, repasemos el concepto de sobreajuste.

# Sobreajuste

El sobreajuste es un concepto extremadamente importante en aprendizaje autom√°tico, ¬°y es fundamental entenderlo bien!

Considera el siguiente problema de aproximar 5 puntos (representados por `x` en los gr√°ficos a continuaci√≥n):

!linear | overfit
-------------------------|--------------------------
**Modelo lineal, 2 par√°metros** | **Modelo no lineal, 7 par√°metros**
Error de entrenamiento = 5.3 | Error de entrenamiento = 0
Error de validaci√≥n = 5.1 | Error de validaci√≥n = 20

* A la izquierda, vemos una buena aproximaci√≥n con una l√≠nea recta. Debido a que el n√∫mero de par√°metros es adecuado, el modelo capta correctamente la distribuci√≥n de los puntos.
* A la derecha, el modelo es demasiado potente. Como solo tenemos 5 puntos y el modelo tiene 7 par√°metros, puede ajustarse para pasar por todos los puntos, haciendo que el error de entrenamiento sea 0. Sin embargo, esto impide que el modelo entienda el patr√≥n correcto detr√°s de los datos, por lo que el error de validaci√≥n es muy alto.

Es muy importante encontrar un equilibrio correcto entre la complejidad del modelo (n√∫mero de par√°metros) y la cantidad de muestras de entrenamiento.

## Por qu√© ocurre el sobreajuste

  * No hay suficientes datos de entrenamiento
  * Modelo demasiado complejo
  * Demasiado ruido en los datos de entrada

## C√≥mo detectar el sobreajuste

Como puedes ver en el gr√°fico anterior, el sobreajuste se detecta por un error de entrenamiento muy bajo y un error de validaci√≥n alto. Normalmente, durante el entrenamiento veremos que tanto el error de entrenamiento como el de validaci√≥n comienzan a disminuir, y luego en alg√∫n punto el error de validaci√≥n puede dejar de disminuir y empezar a aumentar. Esto ser√° una se√±al de sobreajuste, e indicar√° que probablemente deber√≠amos detener el entrenamiento en ese punto (o al menos guardar una copia del modelo).

sobreajuste

## C√≥mo prevenir el sobreajuste

Si ves que ocurre sobreajuste, puedes hacer una de las siguientes cosas:

 * Aumentar la cantidad de datos de entrenamiento
 * Disminuir la complejidad del modelo
 * Usar alguna t√©cnica de regularizaci√≥n, como Dropout, que veremos m√°s adelante.

## Sobreajuste y el compromiso sesgo-varianza

El sobreajuste es en realidad un caso de un problema m√°s general en estad√≠stica llamado compromiso sesgo-varianza. Si consideramos las posibles fuentes de error en nuestro modelo, podemos ver dos tipos de errores:

* Los **errores de sesgo** son causados porque nuestro algoritmo no puede capturar correctamente la relaci√≥n entre los datos de entrenamiento. Esto puede deberse a que nuestro modelo no es lo suficientemente potente (**subajuste**).
* Los **errores de varianza** son causados porque el modelo aproxima el ruido en los datos de entrada en lugar de la relaci√≥n significativa (**sobreajuste**).

Durante el entrenamiento, el error de sesgo disminuye (a medida que nuestro modelo aprende a aproximar los datos) y el error de varianza aumenta. Es importante detener el entrenamiento ‚Äî ya sea manualmente (cuando detectamos sobreajuste) o autom√°ticamente (introduciendo regularizaci√≥n) ‚Äî para evitar el sobreajuste.

## Conclusi√≥n

En esta lecci√≥n, aprendiste sobre las diferencias entre las diversas APIs de los dos frameworks de IA m√°s populares, TensorFlow y PyTorch. Adem√°s, aprendiste sobre un tema muy importante: el sobreajuste.

## üöÄ Desaf√≠o

En los notebooks acompa√±antes, encontrar√°s 'tareas' al final; trabaja con los notebooks y completa las tareas.

## Repaso y Estudio Aut√≥nomo

Investiga sobre los siguientes temas:

- TensorFlow
- PyTorch
- Sobreajuste

Hazte las siguientes preguntas:

- ¬øCu√°l es la diferencia entre TensorFlow y PyTorch?
- ¬øCu√°l es la diferencia entre sobreajuste y subajuste?

## Tarea

En este laboratorio, se te pide resolver dos problemas de clasificaci√≥n usando redes totalmente conectadas de una y varias capas, utilizando PyTorch o TensorFlow.

**Aviso legal**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.