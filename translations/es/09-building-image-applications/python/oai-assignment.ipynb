{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creando una aplicación de generación de imágenes\n",
    "\n",
    "Los LLMs no solo sirven para generar texto. También es posible crear imágenes a partir de descripciones en texto. Contar con imágenes como modalidad puede ser muy útil en áreas como tecnología médica, arquitectura, turismo, desarrollo de videojuegos y más. En este capítulo, veremos los dos modelos de generación de imágenes más populares: DALL-E y Midjourney.\n",
    "\n",
    "## Introducción\n",
    "\n",
    "En esta lección, cubriremos:\n",
    "\n",
    "- Generación de imágenes y por qué es útil.\n",
    "- DALL-E y Midjourney, qué son y cómo funcionan.\n",
    "- Cómo podrías construir una aplicación de generación de imágenes.\n",
    "\n",
    "## Objetivos de aprendizaje\n",
    "\n",
    "Después de completar esta lección, podrás:\n",
    "\n",
    "- Crear una aplicación de generación de imágenes.\n",
    "- Definir límites para tu aplicación usando meta-prompts.\n",
    "- Trabajar con DALL-E y Midjourney.\n",
    "\n",
    "## ¿Por qué crear una aplicación de generación de imágenes?\n",
    "\n",
    "Las aplicaciones de generación de imágenes son una excelente manera de explorar las capacidades de la IA generativa. Se pueden usar, por ejemplo, para:\n",
    "\n",
    "- **Edición y síntesis de imágenes**. Puedes generar imágenes para distintos casos de uso, como edición y síntesis de imágenes.\n",
    "\n",
    "- **Aplicación en diversas industrias**. También se pueden usar para generar imágenes en sectores como tecnología médica, turismo, desarrollo de videojuegos y más.\n",
    "\n",
    "## Escenario: Edu4All\n",
    "\n",
    "Como parte de esta lección, continuaremos trabajando con nuestra startup, Edu4All. Los estudiantes crearán imágenes para sus evaluaciones; el tipo de imagen depende de cada estudiante, pero podrían ser ilustraciones para su propio cuento de hadas, crear un nuevo personaje para su historia o ayudarles a visualizar sus ideas y conceptos.\n",
    "\n",
    "Por ejemplo, esto es lo que los estudiantes de Edu4All podrían generar si están trabajando en clase sobre monumentos:\n",
    "\n",
    "![Startup Edu4All, clase sobre monumentos, Torre Eiffel](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.es.png)\n",
    "\n",
    "usando un prompt como\n",
    "\n",
    "> \"Perro junto a la Torre Eiffel al amanecer\"\n",
    "\n",
    "## ¿Qué son DALL-E y Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) y [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) son dos de los modelos de generación de imágenes más populares; permiten usar prompts para crear imágenes.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Comencemos con DALL-E, que es un modelo de IA generativa que crea imágenes a partir de descripciones en texto.\n",
    "\n",
    "> [DALL-E es una combinación de dos modelos, CLIP y atención difusa](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** es un modelo que genera embeddings, que son representaciones numéricas de datos, a partir de imágenes y texto.\n",
    "\n",
    "- **Atención difusa** es un modelo que genera imágenes a partir de embeddings. DALL-E se entrena con un conjunto de datos de imágenes y texto, y puede usarse para crear imágenes a partir de descripciones en texto. Por ejemplo, DALL-E puede generar imágenes de un gato con sombrero o un perro con cresta.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney funciona de manera similar a DALL-E: genera imágenes a partir de prompts en texto. Midjourney también puede usarse para crear imágenes con prompts como “un gato con sombrero” o “un perro con cresta”.\n",
    "\n",
    "![Imagen generada por Midjourney, paloma mecánica](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Crédito de la imagen: Wikipedia, imagen generada por Midjourney*\n",
    "\n",
    "## ¿Cómo funcionan DALL-E y Midjourney?\n",
    "\n",
    "Primero, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E es un modelo de IA generativa basado en la arquitectura transformer con un *transformer autorregresivo*.\n",
    "\n",
    "Un *transformer autorregresivo* define cómo un modelo genera imágenes a partir de descripciones en texto: genera un píxel a la vez y luego usa los píxeles generados para crear el siguiente. Este proceso pasa por varias capas de una red neuronal hasta que la imagen está completa.\n",
    "\n",
    "Con este proceso, DALL-E controla atributos, objetos, características y más en la imagen que genera. Sin embargo, DALL-E 2 y 3 ofrecen un mayor control sobre la imagen generada,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creando tu primera aplicación de generación de imágenes\n",
    "\n",
    "Entonces, ¿qué se necesita para crear una aplicación de generación de imágenes? Necesitas las siguientes librerías:\n",
    "\n",
    "- **python-dotenv**, se recomienda mucho usar esta librería para mantener tus secretos en un archivo *.env* separado del código.\n",
    "- **openai**, esta es la librería que usarás para interactuar con la API de OpenAI.\n",
    "- **pillow**, para trabajar con imágenes en Python.\n",
    "- **requests**, para ayudarte a hacer solicitudes HTTP.\n",
    "\n",
    "\n",
    "1. Crea un archivo *.env* con el siguiente contenido:\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reúne las bibliotecas anteriores en un archivo llamado *requirements.txt* de la siguiente manera:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. Luego, crea un entorno virtual e instala las bibliotecas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Para Windows, utiliza los siguientes comandos para crear y activar tu entorno virtual:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Agrega el siguiente código en un archivo llamado *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Vamos a explicar este código:\n",
    "\n",
    "- Primero, importamos las librerías necesarias, incluyendo la librería de OpenAI, dotenv, requests y Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- Después, creamos el objeto, que obtendrá la clave de API desde tu archivo ``.env``.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- Luego, generamos la imagen:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    El código anterior responde con un objeto JSON que contiene la URL de la imagen generada. Podemos usar esa URL para descargar la imagen y guardarla en un archivo.\n",
    "\n",
    "- Por último, abrimos la imagen y usamos el visor de imágenes estándar para mostrarla:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Más detalles sobre la generación de imágenes\n",
    "\n",
    "Veamos el código que genera la imagen con más detalle:\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** es el texto que se utiliza para generar la imagen. En este caso, usamos el prompt \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".\n",
    "- **size** es el tamaño de la imagen que se genera. En este ejemplo, generamos una imagen de 1024x1024 píxeles.\n",
    "- **n** es la cantidad de imágenes que se generan. Aquí estamos generando dos imágenes.\n",
    "\n",
    "Hay más cosas que puedes hacer con imágenes y que veremos en la siguiente sección.\n",
    "\n",
    "## Capacidades adicionales de la generación de imágenes\n",
    "\n",
    "Hasta ahora has visto cómo pudimos generar una imagen usando unas pocas líneas en Python. Sin embargo, hay más cosas que puedes hacer con imágenes.\n",
    "\n",
    "También puedes hacer lo siguiente:\n",
    "\n",
    "- **Realizar ediciones**. Al proporcionar una imagen existente, una máscara y un prompt, puedes modificar una imagen. Por ejemplo, puedes agregar algo a una parte de la imagen. Imagina nuestra imagen del conejo, podrías agregarle un sombrero al conejo. Para hacerlo, debes proporcionar la imagen, una máscara (que identifica la zona donde se hará el cambio) y un prompt de texto que indique lo que se debe hacer.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    La imagen base solo tendría el conejo, pero la imagen final mostraría el sombrero en el conejo.\n",
    "    \n",
    "- **Crear variaciones**. La idea es que tomas una imagen existente y pides que se creen variaciones. Para crear una variación, proporcionas una imagen y un prompt de texto, y el código sería así:\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Descargo de responsabilidad**:  \nEste documento ha sido traducido utilizando el servicio de traducción automática [Co-op Translator](https://github.com/Azure/co-op-translator). Si bien nos esforzamos por lograr precisión, tenga en cuenta que las traducciones automáticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para información crítica, se recomienda una traducción profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones erróneas que surjan del uso de esta traducción.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:29:23+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "es"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}