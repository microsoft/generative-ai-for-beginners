# Explorando y comparando diferentes LLMs

[![Explorando y comparando diferentes LLMs](../../../translated_images/02-lesson-banner.png?WT.96d85175e46909d65f6895923ed5f3ad0ae5e874792ccad49542fcfe8ebd12dd.es.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Haz clic en la imagen de arriba para ver el video de esta lecci√≥n_

En la lecci√≥n anterior, vimos c√≥mo la IA Generativa est√° cambiando el panorama tecnol√≥gico, c√≥mo funcionan los Modelos de Lenguaje Grande (LLMs) y c√≥mo una empresa, como nuestra startup, puede aplicarlos a sus casos de uso y crecer. En este cap√≠tulo, vamos a comparar y contrastar diferentes tipos de modelos de lenguaje grande (LLMs) para entender sus pros y contras.

El siguiente paso en el camino de nuestra startup es explorar el panorama actual de los LLMs y entender cu√°les son adecuados para nuestro caso de uso.

## Introducci√≥n

Esta lecci√≥n cubrir√°:

- Diferentes tipos de LLMs en el panorama actual.
- Probar, iterar y comparar diferentes modelos para tu caso de uso en Azure.
- C√≥mo desplegar un LLM.

## Objetivos de aprendizaje

Despu√©s de completar esta lecci√≥n, podr√°s:

- Seleccionar el modelo adecuado para tu caso de uso.
- Entender c√≥mo probar, iterar y mejorar el rendimiento de tu modelo.
- Saber c√≥mo las empresas despliegan modelos.

## Entender diferentes tipos de LLMs

Los LLMs pueden tener m√∫ltiples categorizaciones basadas en su arquitectura, datos de entrenamiento y caso de uso. Entender estas diferencias ayudar√° a nuestra startup a seleccionar el modelo correcto para el escenario y entender c√≥mo probar, iterar y mejorar el rendimiento.

Existen muchos tipos diferentes de modelos LLM, tu elecci√≥n de modelo depende de para qu√© planeas usarlos, tus datos, cu√°nto est√°s dispuesto a pagar y m√°s.

Dependiendo de si planeas usar los modelos para texto, audio, video, generaci√≥n de im√°genes, etc., podr√≠as optar por un tipo diferente de modelo.

- **Reconocimiento de audio y voz**. Para este prop√≥sito, los modelos tipo Whisper son una gran elecci√≥n ya que son de prop√≥sito general y est√°n orientados al reconocimiento de voz. Est√° entrenado en audio diverso y puede realizar reconocimiento de voz multiling√ºe. Aprende m√°s sobre [modelos tipo Whisper aqu√≠](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generaci√≥n de im√°genes**. Para la generaci√≥n de im√°genes, DALL-E y Midjourney son dos opciones muy conocidas. DALL-E es ofrecido por Azure OpenAI. [Lee m√°s sobre DALL-E aqu√≠](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) y tambi√©n en el Cap√≠tulo 9 de este curr√≠culo.

- **Generaci√≥n de texto**. La mayor√≠a de los modelos est√°n entrenados en generaci√≥n de texto y tienes una gran variedad de opciones desde GPT-3.5 hasta GPT-4. Vienen a diferentes costos, siendo GPT-4 el m√°s caro. Vale la pena echar un vistazo al [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para evaluar qu√© modelos se adaptan mejor a tus necesidades en t√©rminos de capacidad y costo.

- **Multimodalidad**. Si buscas manejar m√∫ltiples tipos de datos en entrada y salida, podr√≠as querer ver modelos como [gpt-4 turbo con visi√≥n o gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - las √∫ltimas versiones de modelos de OpenAI - que son capaces de combinar el procesamiento del lenguaje natural con la comprensi√≥n visual, permitiendo interacciones a trav√©s de interfaces multimodales.

Seleccionar un modelo significa que obtienes algunas capacidades b√°sicas, que podr√≠an no ser suficientes. A menudo tienes datos espec√≠ficos de la empresa que de alguna manera necesitas comunicar al LLM. Hay algunas opciones diferentes sobre c√≥mo abordar eso, m√°s sobre eso en las secciones siguientes.

### Modelos Fundacionales versus LLMs

El t√©rmino Modelo Fundacional fue [acu√±ado por investigadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) y definido como un modelo de IA que sigue algunos criterios, tales como:

- **Est√°n entrenados usando aprendizaje no supervisado o aprendizaje auto-supervisado**, lo que significa que est√°n entrenados en datos multimodales no etiquetados, y no requieren anotaci√≥n o etiquetado humano de datos para su proceso de entrenamiento.
- **Son modelos muy grandes**, basados en redes neuronales muy profundas entrenadas en miles de millones de par√°metros.
- **Normalmente est√°n destinados a servir como una ‚Äòbase‚Äô para otros modelos**, lo que significa que pueden usarse como punto de partida para que otros modelos se construyan sobre ellos, lo que puede hacerse mediante ajuste fino.

![Modelos Fundacionales versus LLMs](../../../translated_images/FoundationModel.png?WT.9690c2a9f6be278baf730a5b26ea901ac6d6ede04cad555ef2b59d774ba557eb.es.mc_id=academic-105485-koreyst)

Fuente de la imagen: [Gu√≠a esencial para modelos fundacionales y modelos de lenguaje grande | por Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para aclarar a√∫n m√°s esta distinci√≥n, tomemos ChatGPT como ejemplo. Para construir la primera versi√≥n de ChatGPT, un modelo llamado GPT-3.5 sirvi√≥ como modelo fundacional. Esto significa que OpenAI us√≥ algunos datos espec√≠ficos de chat para crear una versi√≥n ajustada de GPT-3.5 que estaba especializada en desempe√±arse bien en escenarios conversacionales, como chatbots.

![Modelo Fundacional](../../../translated_images/Multimodal.png?WT.29151b07403f77b38d7dc2a3069f4c171198d59c9df6bdfccd4326c209db4432.es.mc_id=academic-105485-koreyst)

Fuente de la imagen: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos de C√≥digo Abierto versus Propietarios

Otra forma de categorizar los LLMs es si son de c√≥digo abierto o propietarios.

Los modelos de c√≥digo abierto son modelos que est√°n disponibles para el p√∫blico y pueden ser usados por cualquiera. A menudo son puestos a disposici√≥n por la empresa que los cre√≥, o por la comunidad de investigaci√≥n. Estos modelos pueden ser inspeccionados, modificados y personalizados para los diversos casos de uso en LLMs. Sin embargo, no siempre est√°n optimizados para uso en producci√≥n, y pueden no ser tan eficientes como los modelos propietarios. Adem√°s, la financiaci√≥n para modelos de c√≥digo abierto puede ser limitada, y pueden no ser mantenidos a largo plazo o no ser actualizados con la √∫ltima investigaci√≥n. Ejemplos de modelos de c√≥digo abierto populares incluyen [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) y [LLaMA](https://llama.meta.com).

Los modelos propietarios son modelos que son propiedad de una empresa y no est√°n disponibles para el p√∫blico. Estos modelos a menudo est√°n optimizados para uso en producci√≥n. Sin embargo, no se permite que sean inspeccionados, modificados o personalizados para diferentes casos de uso. Adem√°s, no siempre est√°n disponibles de forma gratuita y pueden requerir una suscripci√≥n o pago para su uso. Tambi√©n, los usuarios no tienen control sobre los datos que se utilizan para entrenar el modelo, lo que significa que deben confiar en el propietario del modelo para garantizar el compromiso con la privacidad de los datos y el uso responsable de la IA. Ejemplos de modelos propietarios populares incluyen [Modelos de OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) o [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Generaci√≥n de Im√°genes versus Generaci√≥n de Texto y C√≥digo

Los LLMs tambi√©n pueden categorizarse por la salida que generan.

Los embeddings son un conjunto de modelos que pueden convertir texto en una forma num√©rica, llamada embedding, que es una representaci√≥n num√©rica del texto de entrada. Los embeddings facilitan que las m√°quinas entiendan las relaciones entre palabras o frases y pueden ser consumidos como entradas por otros modelos, como modelos de clasificaci√≥n o modelos de clustering que tienen un mejor rendimiento en datos num√©ricos. Los modelos de embedding a menudo se utilizan para el aprendizaje por transferencia, donde se construye un modelo para una tarea sustituta para la cual hay una abundancia de datos, y luego los pesos del modelo (embeddings) se reutilizan para otras tareas posteriores. Un ejemplo de esta categor√≠a es [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.png?WT.15a2282d046c6d94a54f553fa9e7f19e3ef0e65f9eb05f4d476a5d28b2dead18.es.mc_id=academic-105485-koreyst)

Los modelos de generaci√≥n de im√°genes son modelos que generan im√°genes. Estos modelos a menudo se utilizan para la edici√≥n de im√°genes, s√≠ntesis de im√°genes y traducci√≥n de im√°genes. Los modelos de generaci√≥n de im√°genes a menudo se entrenan en grandes conjuntos de datos de im√°genes, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), y pueden usarse para generar nuevas im√°genes o para editar im√°genes existentes con t√©cnicas de inpainting, super-resoluci√≥n y colorizaci√≥n. Ejemplos incluyen [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) y [Modelos de Difusi√≥n Estable](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generaci√≥n de im√°genes](../../../translated_images/Image.png?WT.6a1995ff7d9be5a713e6aaee5f1625f31620756937c283e292ef5ffe1e30ed11.es.mc_id=academic-105485-koreyst)

Los modelos de generaci√≥n de texto y c√≥digo son modelos que generan texto o c√≥digo. Estos modelos a menudo se utilizan para la resumisi√≥n de texto, traducci√≥n y respuesta a preguntas. Los modelos de generaci√≥n de texto a menudo se entrenan en grandes conjuntos de datos de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), y pueden usarse para generar nuevo texto o para responder preguntas. Los modelos de generaci√≥n de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), a menudo se entrenan en grandes conjuntos de datos de c√≥digo, como GitHub, y pueden usarse para generar nuevo c√≥digo o para corregir errores en el c√≥digo existente.

![Generaci√≥n de texto y c√≥digo](../../../translated_images/Text.png?WT.b55b7b9b96faac1d758fb555436c56c5a323a55743b75e70198160caca3fb73c.es.mc_id=academic-105485-koreyst)

### Encoder-Decoder versus Solo Decoder

Para hablar sobre los diferentes tipos de arquitecturas de LLMs, usemos una analog√≠a.

Imagina que tu gerente te dio una tarea para escribir un cuestionario para los estudiantes. Tienes dos colegas; uno se encarga de crear el contenido y el otro se encarga de revisarlo.

El creador de contenido es como un modelo de Solo Decoder, puede mirar el tema y ver lo que ya escribiste y luego puede escribir un curso basado en eso. Son muy buenos escribiendo contenido atractivo e informativo, pero no son muy buenos entendiendo el tema y los objetivos de aprendizaje. Algunos ejemplos de modelos Decoder son los modelos de la familia GPT, como GPT-3.

El revisor es como un modelo de Solo Encoder, miran el curso escrito y las respuestas, notando la relaci√≥n entre ellos y entendiendo el contexto, pero no son buenos generando contenido. Un ejemplo de modelo Solo Encoder ser√≠a BERT.

Imagina que tambi√©n podemos tener a alguien que pueda crear y revisar el cuestionario, este es un modelo Encoder-Decoder. Algunos ejemplos ser√≠an BART y T5.

### Servicio versus Modelo

Ahora, hablemos de la diferencia entre un servicio y un modelo. Un servicio es un producto que es ofrecido por un Proveedor de Servicios en la Nube, y a menudo es una combinaci√≥n de modelos, datos y otros componentes. Un modelo es el componente central de un servicio, y a menudo es un modelo fundacional, como un LLM.

Los servicios a menudo est√°n optimizados para uso en producci√≥n y a menudo son m√°s f√°ciles de usar que los modelos, a trav√©s de una interfaz gr√°fica de usuario. Sin embargo, los servicios no siempre est√°n disponibles de forma gratuita y pueden requerir una suscripci√≥n o pago para su uso, a cambio de aprovechar el equipo y los recursos del propietario del servicio, optimizando los gastos y escalando f√°cilmente. Un ejemplo de servicio es [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que ofrece un plan de tarifas de pago por uso, lo que significa que los usuarios son cobrados proporcionalmente a cu√°nto usan el servicio. Adem√°s, Azure OpenAI Service ofrece seguridad de nivel empresarial y un marco de IA responsable adem√°s de las capacidades de los modelos.

Los modelos son solo la Red Neuronal, con los par√°metros, pesos y otros. Permiten a las empresas operar localmente, sin embargo, necesitar√≠an comprar equipo, construir una estructura para escalar y comprar una licencia o usar un modelo de c√≥digo abierto. Un modelo como LLaMA est√° disponible para ser usado, requiriendo poder computacional para ejecutar el modelo.

## C√≥mo probar e iterar con diferentes modelos para entender el rendimiento en Azure

Una vez que nuestro equipo ha explorado el panorama actual de los LLMs e identificado algunos buenos candidatos para sus escenarios, el siguiente paso es probarlos en sus datos y en su carga de trabajo. Este es un proceso iterativo, realizado mediante experimentos y medidas. La mayor√≠a de los modelos que mencionamos en p√°rrafos anteriores (modelos de OpenAI, modelos de c√≥digo abierto como Llama2 y transformadores de Hugging Face) est√°n disponibles en el [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) en [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) es una Plataforma en la Nube dise√±ada para desarrolladores que desean construir aplicaciones de IA generativa y gestionar todo el ciclo de desarrollo, desde la experimentaci√≥n hasta la evaluaci√≥n, combinando todos los servicios de Azure AI en un √∫nico centro con una pr√°ctica interfaz gr√°fica. El Cat√°logo de Modelos en Azure AI Studio permite al usuario:

- Encontrar el Modelo Fundacional de inter√©s en el cat√°logo, ya sea propietario o de c√≥digo abierto, filtrando por tarea, licencia o nombre. Para mejorar la b√∫squeda, los modelos est√°n organizados en colecciones, como la colecci√≥n de Azure OpenAI, colecci√≥n de Hugging Face y m√°s.

![Cat√°logo de Modelos](../../../translated_images/AzureAIStudioModelCatalog.png?WT.cd7b78fc6a7b010869adb0defabce1ea5fbe62131aa7f59e54a083be8d789d24.es.mc_id=academic-105485-koreyst)

- Revisar la tarjeta del modelo, incluyendo una descripci√≥n detallada del uso previsto y datos de entrenamiento, ejemplos de c√≥digo y resultados de evaluaci√≥n en la biblioteca de evaluaciones internas.

![Tarjeta del Modelo](../../../translated_images/ModelCard.png?WT.cd385d3d0228f86cef5987e3074be75f377a95ba505d6805f7c6965dc5972693.es.mc_id=academic-105485-koreyst)
- Compara los benchmarks entre modelos y conjuntos de datos disponibles en la industria para evaluar cu√°l se ajusta al escenario empresarial, a trav√©s del panel de [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.png?WT.634f688bb2a74b3c90a9212ecfb9b99045405b2414be3d17429cfea319c06f61.es.mc_id=academic-105485-koreyst)

- Ajusta el modelo en datos de entrenamiento personalizados para mejorar el rendimiento del modelo en una carga de trabajo espec√≠fica, aprovechando las capacidades de experimentaci√≥n y seguimiento de Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.png?WT.523a6ab7580c924e42e8478d072fb670f879033779b8ab5a6abb155d2fc63d5a.es.mc_id=academic-105485-koreyst)

- Despliega el modelo preentrenado original o la versi√≥n ajustada para una inferencia remota en tiempo real - computaci√≥n gestionada - o un endpoint de API sin servidor - [pago por uso](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - para permitir que las aplicaciones lo consuman.

![Model deployment](../../../translated_images/ModelDeploy.png?WT.a765ca6b7a396eb5d2fd346f8a211542f6fe578e2218bbe16f9fcdb5ca8f3661.es.mc_id=academic-105485-koreyst)

> [!NOTE]
> No todos los modelos en el cat√°logo est√°n actualmente disponibles para ajuste fino y/o despliegue de pago por uso. Consulta la tarjeta del modelo para obtener detalles sobre las capacidades y limitaciones del modelo.

## Mejorando los resultados de LLM

Hemos explorado con nuestro equipo de startup diferentes tipos de LLMs y una plataforma en la nube (Azure Machine Learning) que nos permite comparar diferentes modelos, evaluarlos en datos de prueba, mejorar el rendimiento y desplegarlos en endpoints de inferencia.

Pero ¬øcu√°ndo deber√≠an considerar ajustar un modelo en lugar de usar uno preentrenado? ¬øExisten otros enfoques para mejorar el rendimiento del modelo en cargas de trabajo espec√≠ficas?

Hay varios enfoques que una empresa puede usar para obtener los resultados que necesita de un LLM. Puedes seleccionar diferentes tipos de modelos con distintos grados de entrenamiento al desplegar un LLM en producci√≥n, con diferentes niveles de complejidad, costo y calidad. Aqu√≠ hay algunos enfoques diferentes:

- **Ingenier√≠a de prompts con contexto**. La idea es proporcionar suficiente contexto cuando solicitas para asegurar que obtienes las respuestas que necesitas.

- **Generaci√≥n Aumentada por Recuperaci√≥n, RAG**. Tus datos pueden existir en una base de datos o endpoint web, por ejemplo, para asegurar que estos datos, o un subconjunto de ellos, se incluyan al momento de solicitar, puedes obtener los datos relevantes y hacer que formen parte del prompt del usuario.

- **Modelo ajustado**. Aqu√≠, entrenas el modelo m√°s en tus propios datos, lo que lleva a que el modelo sea m√°s exacto y responda mejor a tus necesidades, pero podr√≠a ser costoso.

![LLMs deployment](../../../translated_images/Deploy.png?WT.0eeb36a208bf2bf97ea1058e54c74e13f5c810679cd7f3600cb2084b98d737be.es.mc_id=academic-105485-koreyst)

Fuente de la imagen: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ingenier√≠a de Prompts con Contexto

Los LLMs preentrenados funcionan muy bien en tareas generales de lenguaje natural, incluso llam√°ndolos con un prompt corto, como una oraci√≥n para completar o una pregunta, el llamado aprendizaje "zero-shot".

Sin embargo, cuanto m√°s el usuario pueda enmarcar su consulta, con una solicitud detallada y ejemplos ‚Äì el Contexto ‚Äì m√°s precisa y cercana a las expectativas del usuario ser√° la respuesta. En este caso, hablamos de aprendizaje "one-shot" si el prompt incluye solo un ejemplo y "few-shot learning" si incluye m√∫ltiples ejemplos. La ingenier√≠a de prompts con contexto es el enfoque m√°s rentable para comenzar.

### Generaci√≥n Aumentada por Recuperaci√≥n (RAG)

Los LLMs tienen la limitaci√≥n de que solo pueden usar los datos que se han utilizado durante su entrenamiento para generar una respuesta. Esto significa que no saben nada sobre los hechos que ocurrieron despu√©s de su proceso de entrenamiento, y no pueden acceder a informaci√≥n no p√∫blica (como datos de la empresa). Esto se puede superar a trav√©s de RAG, una t√©cnica que aumenta el prompt con datos externos en forma de fragmentos de documentos, considerando los l√≠mites de longitud del prompt. Esto es compatible con herramientas de bases de datos Vector (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperan los fragmentos √∫tiles de diversas fuentes de datos predefinidas y los agregan al Contexto del prompt.

Esta t√©cnica es muy √∫til cuando una empresa no tiene suficientes datos, tiempo o recursos para ajustar un LLM, pero a√∫n desea mejorar el rendimiento en una carga de trabajo espec√≠fica y reducir los riesgos de fabricaciones, es decir, mistificaci√≥n de la realidad o contenido da√±ino.

### Modelo ajustado

El ajuste fino es un proceso que aprovecha el aprendizaje por transferencia para 'adaptar' el modelo a una tarea posterior o para resolver un problema espec√≠fico. A diferencia del aprendizaje few-shot y RAG, resulta en un nuevo modelo generado, con pesos y sesgos actualizados. Requiere un conjunto de ejemplos de entrenamiento que consisten en una sola entrada (el prompt) y su salida asociada (la finalizaci√≥n). Este ser√≠a el enfoque preferido si:

- **Usando modelos ajustados**. Una empresa desear√≠a usar modelos ajustados menos capaces (como modelos de incrustaci√≥n) en lugar de modelos de alto rendimiento, resultando en una soluci√≥n m√°s rentable y r√°pida.

- **Considerando la latencia**. La latencia es importante para un caso de uso espec√≠fico, por lo que no es posible usar prompts muy largos o el n√∫mero de ejemplos que deben aprenderse del modelo no encaja con el l√≠mite de longitud del prompt.

- **Manteni√©ndose actualizado**. Una empresa tiene muchos datos de alta calidad y etiquetas de verdad fundamental y los recursos necesarios para mantener estos datos actualizados a lo largo del tiempo.

### Modelo entrenado

Entrenar un LLM desde cero es sin duda el enfoque m√°s dif√≠cil y complejo de adoptar, requiriendo grandes cantidades de datos, recursos calificados y potencia computacional adecuada. Esta opci√≥n deber√≠a considerarse solo en un escenario donde una empresa tenga un caso de uso espec√≠fico del dominio y una gran cantidad de datos centrados en el dominio.

## Comprobaci√≥n de conocimiento

¬øCu√°l podr√≠a ser un buen enfoque para mejorar los resultados de finalizaci√≥n de LLM?

1. Ingenier√≠a de prompts con contexto
2. RAG
3. Modelo ajustado

A:3, si tienes el tiempo y los recursos y datos de alta calidad, el ajuste fino es la mejor opci√≥n para mantenerse actualizado. Sin embargo, si est√°s buscando mejorar las cosas y te falta tiempo, vale la pena considerar primero RAG.

## üöÄ Desaf√≠o

Lee m√°s sobre c√≥mo puedes [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para tu negocio.

## Buen trabajo, contin√∫a tu aprendizaje

Despu√©s de completar esta lecci√≥n, consulta nuestra [colecci√≥n de aprendizaje de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tus conocimientos en IA Generativa.

Dir√≠gete a la Lecci√≥n 3 donde veremos c√≥mo [construir con IA Generativa de manera responsable](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci√≥n autom√°tica basados en IA. Si bien nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional humana. No nos hacemos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.