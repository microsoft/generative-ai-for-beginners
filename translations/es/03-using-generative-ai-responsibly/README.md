<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:46:23+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "es"
}
-->
# Uso Responsable de la IA Generativa

[![Uso Responsable de la IA Generativa](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.es.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Haz clic en la imagen de arriba para ver el video de esta lecci√≥n_

Es f√°cil sentirse fascinado por la IA y, en particular, por la IA generativa, pero es necesario considerar c√≥mo usarla de manera responsable. Debes tener en cuenta aspectos como garantizar que los resultados sean justos, no da√±inos y m√°s. Este cap√≠tulo tiene como objetivo brindarte el contexto mencionado, qu√© considerar y c√≥mo tomar medidas activas para mejorar el uso de la IA.

## Introducci√≥n

Esta lecci√≥n cubrir√°:

- Por qu√© debes priorizar la IA Responsable al construir aplicaciones de IA Generativa.
- Principios fundamentales de la IA Responsable y c√≥mo se relacionan con la IA Generativa.
- C√≥mo poner en pr√°ctica estos principios de IA Responsable mediante estrategias y herramientas.

## Objetivos de Aprendizaje

Despu√©s de completar esta lecci√≥n sabr√°s:

- La importancia de la IA Responsable al construir aplicaciones de IA Generativa.
- Cu√°ndo pensar y aplicar los principios fundamentales de la IA Responsable al construir aplicaciones de IA Generativa.
- Qu√© herramientas y estrategias tienes disponibles para poner en pr√°ctica el concepto de IA Responsable.

## Principios de IA Responsable

El entusiasmo por la IA Generativa nunca ha sido tan alto. Este entusiasmo ha atra√≠do a muchos desarrolladores nuevos, atenci√≥n y financiamiento a este campo. Aunque esto es muy positivo para quienes buscan crear productos y empresas usando IA Generativa, tambi√©n es importante que avancemos de manera responsable.

A lo largo de este curso, nos enfocamos en construir nuestra startup y nuestro producto educativo de IA. Usaremos los principios de IA Responsable: Equidad, Inclusi√≥n, Confiabilidad/Seguridad, Seguridad y Privacidad, Transparencia y Responsabilidad. Con estos principios, exploraremos c√≥mo se relacionan con nuestro uso de la IA Generativa en nuestros productos.

## Por qu√© Debes Priorizar la IA Responsable

Al construir un producto, adoptar un enfoque centrado en las personas, manteniendo en mente el mejor inter√©s de tus usuarios, conduce a los mejores resultados.

La singularidad de la IA Generativa es su capacidad para crear respuestas √∫tiles, informaci√≥n, orientaci√≥n y contenido para los usuarios. Esto se puede hacer sin muchos pasos manuales, lo que puede generar resultados muy impresionantes. Sin una planificaci√≥n y estrategias adecuadas, desafortunadamente tambi√©n puede conducir a resultados da√±inos para tus usuarios, tu producto y la sociedad en general.

Veamos algunos (pero no todos) de estos posibles resultados da√±inos:

### Alucinaciones

Las alucinaciones son un t√©rmino que se usa para describir cuando un LLM produce contenido que es completamente absurdo o algo que sabemos que es incorrecto seg√∫n otras fuentes de informaci√≥n.

Por ejemplo, supongamos que construimos una funci√≥n para nuestra startup que permite a los estudiantes hacer preguntas hist√≥ricas a un modelo. Un estudiante pregunta: `¬øQui√©n fue el √∫nico sobreviviente del Titanic?`

El modelo produce una respuesta como la siguiente:

![Prompt diciendo "¬øQui√©n fue el √∫nico sobreviviente del Titanic?"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fuente: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Esta es una respuesta muy segura y detallada. Desafortunadamente, es incorrecta. Incluso con una m√≠nima investigaci√≥n, se descubrir√≠a que hubo m√°s de un sobreviviente del desastre del Titanic. Para un estudiante que reci√©n comienza a investigar este tema, esta respuesta puede ser lo suficientemente persuasiva como para no ser cuestionada y ser tomada como un hecho. Las consecuencias pueden hacer que el sistema de IA sea poco confiable y afectar negativamente la reputaci√≥n de nuestra startup.

Con cada iteraci√≥n de cualquier LLM, hemos visto mejoras en el rendimiento para minimizar las alucinaciones. Aun con esta mejora, como desarrolladores de aplicaciones y usuarios, debemos seguir siendo conscientes de estas limitaciones.

### Contenido Da√±ino

En la secci√≥n anterior cubrimos cuando un LLM produce respuestas incorrectas o sin sentido. Otro riesgo que debemos tener en cuenta es cuando un modelo responde con contenido da√±ino.

El contenido da√±ino se puede definir como:

- Proporcionar instrucciones o fomentar el autoda√±o o da√±o a ciertos grupos.
- Contenido odioso o denigrante.
- Guiar la planificaci√≥n de cualquier tipo de ataque o acto violento.
- Proporcionar instrucciones sobre c√≥mo encontrar contenido ilegal o cometer actos ilegales.
- Mostrar contenido sexual expl√≠cito.

Para nuestra startup, queremos asegurarnos de tener las herramientas y estrategias adecuadas para evitar que este tipo de contenido sea visto por los estudiantes.

### Falta de Equidad

La equidad se define como ‚Äúasegurar que un sistema de IA est√© libre de sesgos y discriminaci√≥n y que trate a todos de manera justa e igualitaria.‚Äù En el mundo de la IA Generativa, queremos asegurarnos de que las visiones excluyentes de grupos marginados no se refuercen en la salida del modelo.

Este tipo de resultados no solo son destructivos para construir experiencias positivas de producto para nuestros usuarios, sino que tambi√©n causan un da√±o social mayor. Como desarrolladores de aplicaciones, siempre debemos tener en mente una base de usuarios amplia y diversa al construir soluciones con IA Generativa.

## C√≥mo Usar la IA Generativa de Forma Responsable

Ahora que hemos identificado la importancia de la IA Generativa Responsable, veamos 4 pasos que podemos seguir para construir nuestras soluciones de IA de manera responsable:

![Ciclo de Mitigaci√≥n](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.es.png)

### Medir los Da√±os Potenciales

En las pruebas de software, evaluamos las acciones esperadas de un usuario en una aplicaci√≥n. De manera similar, probar un conjunto diverso de prompts que los usuarios probablemente usar√°n es una buena forma de medir posibles da√±os.

Dado que nuestra startup est√° construyendo un producto educativo, ser√≠a bueno preparar una lista de prompts relacionados con la educaci√≥n. Esto podr√≠a cubrir ciertos temas, hechos hist√≥ricos y preguntas sobre la vida estudiantil.

### Mitigar los Da√±os Potenciales

Es momento de encontrar formas para prevenir o limitar el da√±o potencial causado por el modelo y sus respuestas. Podemos verlo en 4 capas diferentes:

![Capas de Mitigaci√≥n](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.es.png)

- **Modelo**. Elegir el modelo adecuado para el caso de uso correcto. Modelos m√°s grandes y complejos como GPT-4 pueden implicar un mayor riesgo de contenido da√±ino cuando se aplican a casos de uso m√°s peque√±os y espec√≠ficos. Usar tus datos de entrenamiento para ajustar el modelo tambi√©n reduce el riesgo de contenido da√±ino.

- **Sistema de Seguridad**. Un sistema de seguridad es un conjunto de herramientas y configuraciones en la plataforma que sirve al modelo y ayuda a mitigar da√±os. Un ejemplo es el sistema de filtrado de contenido en el servicio Azure OpenAI. Los sistemas tambi√©n deben detectar ataques de jailbreak y actividades no deseadas como solicitudes de bots.

- **Metaprompt**. Los metaprompts y el grounding son formas de dirigir o limitar el modelo bas√°ndonos en ciertos comportamientos e informaci√≥n. Esto puede ser usar entradas del sistema para definir ciertos l√≠mites del modelo. Adem√°s, proporcionar salidas que sean m√°s relevantes al alcance o dominio del sistema.

Tambi√©n puede incluir t√©cnicas como Retrieval Augmented Generation (RAG) para que el modelo solo extraiga informaci√≥n de una selecci√≥n de fuentes confiables. Hay una lecci√≥n m√°s adelante en este curso sobre [construcci√≥n de aplicaciones de b√∫squeda](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Experiencia de Usuario**. La capa final es donde el usuario interact√∫a directamente con el modelo a trav√©s de la interfaz de nuestra aplicaci√≥n. De esta forma podemos dise√±ar la UI/UX para limitar los tipos de entradas que el usuario puede enviar al modelo, as√≠ como el texto o im√°genes que se muestran. Al desplegar la aplicaci√≥n de IA, tambi√©n debemos ser transparentes sobre lo que nuestra aplicaci√≥n de IA Generativa puede y no puede hacer.

Tenemos una lecci√≥n completa dedicada a [Dise√±ar UX para Aplicaciones de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Evaluar el modelo**. Trabajar con LLMs puede ser un desaf√≠o porque no siempre tenemos control sobre los datos con los que se entren√≥ el modelo. Sin embargo, siempre debemos evaluar el rendimiento y las salidas del modelo. Es importante medir la precisi√≥n, similitud, fundamentaci√≥n y relevancia de la salida. Esto ayuda a proporcionar transparencia y confianza a las partes interesadas y usuarios.

### Operar una Soluci√≥n de IA Generativa Responsable

Construir una pr√°ctica operativa alrededor de tus aplicaciones de IA es la etapa final. Esto incluye colaborar con otras √°reas de nuestra startup como Legal y Seguridad para asegurar el cumplimiento de todas las pol√≠ticas regulatorias. Antes de lanzar, tambi√©n queremos crear planes para la entrega, manejo de incidentes y reversi√≥n para evitar que cualquier da√±o a nuestros usuarios se agrave.

## Herramientas

Aunque el trabajo de desarrollar soluciones de IA Responsable puede parecer mucho, es un esfuerzo que vale la pena. A medida que el √°rea de IA Generativa crece, m√°s herramientas para ayudar a los desarrolladores a integrar la responsabilidad eficientemente en sus flujos de trabajo madurar√°n. Por ejemplo, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) puede ayudar a detectar contenido e im√°genes da√±inas mediante una solicitud API.

## Verificaci√≥n de Conocimientos

¬øQu√© cosas debes tener en cuenta para asegurar un uso responsable de la IA?

1. Que la respuesta sea correcta.  
1. Uso da√±ino, que la IA no se use para fines criminales.  
1. Asegurar que la IA est√© libre de sesgos y discriminaci√≥n.

R: 2 y 3 son correctas. La IA Responsable te ayuda a considerar c√≥mo mitigar efectos da√±inos, sesgos y m√°s.

## üöÄ Desaf√≠o

Lee sobre [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) y ve qu√© puedes adoptar para tu uso.

## Excelente trabajo, contin√∫a aprendiendo

Despu√©s de completar esta lecci√≥n, revisa nuestra [colecci√≥n de aprendizaje de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tus conocimientos en IA Generativa.

¬°Dir√≠gete a la Lecci√≥n 4 donde veremos los [Fundamentos de la Ingenier√≠a de Prompts](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso legal**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.