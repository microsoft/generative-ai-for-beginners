<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T09:24:55+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "es"
}
-->
# Uso Responsable de la IA Generativa

[![Uso Responsable de la IA Generativa](../../../translated_images/03-lesson-banner.63a265562d8a9f9230f5c636ab303a0137d11420177528f475b0a05c5f6a9ff9.es.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Haz clic en la imagen de arriba para ver el video de esta lecci√≥n_

Es f√°cil sentirse fascinado por la IA y la IA generativa en particular, pero es necesario considerar c√≥mo usarla de manera responsable. Debes tener en cuenta aspectos como garantizar que el resultado sea justo, no perjudicial y m√°s. Este cap√≠tulo tiene como objetivo proporcionarte el contexto mencionado, qu√© considerar y c√≥mo tomar medidas activas para mejorar tu uso de la IA.

## Introducci√≥n

Esta lecci√≥n cubrir√°:

- Por qu√© deber√≠as priorizar la IA Responsable al construir aplicaciones de IA Generativa.
- Principios fundamentales de la IA Responsable y c√≥mo se relacionan con la IA Generativa.
- C√≥mo poner estos principios de IA Responsable en pr√°ctica a trav√©s de estrategia y herramientas.

## Objetivos de Aprendizaje

Despu√©s de completar esta lecci√≥n sabr√°s:

- La importancia de la IA Responsable al construir aplicaciones de IA Generativa.
- Cu√°ndo pensar y aplicar los principios fundamentales de la IA Responsable al construir aplicaciones de IA Generativa.
- Qu√© herramientas y estrategias est√°n disponibles para ti para poner en pr√°ctica el concepto de IA Responsable.

## Principios de IA Responsable

La emoci√≥n por la IA Generativa nunca ha sido mayor. Esta emoci√≥n ha atra√≠do a muchos nuevos desarrolladores, atenci√≥n y financiamiento a este espacio. Aunque esto es muy positivo para cualquiera que busque construir productos y empresas usando IA Generativa, tambi√©n es importante proceder de manera responsable.

A lo largo de este curso, nos enfocamos en construir nuestra startup y nuestro producto educativo de IA. Usaremos los principios de IA Responsable: Equidad, Inclusividad, Fiabilidad/Seguridad, Seguridad y Privacidad, Transparencia y Responsabilidad. Con estos principios, exploraremos c√≥mo se relacionan con nuestro uso de la IA Generativa en nuestros productos.

## Por Qu√© Deber√≠as Priorizar la IA Responsable

Al construir un producto, adoptar un enfoque centrado en el ser humano, manteniendo el mejor inter√©s de tu usuario en mente, conduce a los mejores resultados.

La singularidad de la IA Generativa es su poder para crear respuestas √∫tiles, informaci√≥n, orientaci√≥n y contenido para los usuarios. Esto se puede hacer sin muchos pasos manuales, lo que puede llevar a resultados muy impresionantes. Sin una planificaci√≥n y estrategias adecuadas, tambi√©n puede, lamentablemente, llevar a algunos resultados perjudiciales para tus usuarios, tu producto y la sociedad en general.

Veamos algunos (pero no todos) de estos resultados potencialmente perjudiciales:

### Alucinaciones

Las alucinaciones son un t√©rmino utilizado para describir cuando un LLM produce contenido que es completamente absurdo o algo que sabemos que es incorrecto basado en otras fuentes de informaci√≥n.

Tomemos, por ejemplo, que construimos una caracter√≠stica para nuestra startup que permite a los estudiantes hacer preguntas hist√≥ricas a un modelo. Un estudiante hace la pregunta `Who was the sole survivor of Titanic?`

El modelo produce una respuesta como la siguiente:

![Indicador diciendo "¬øQui√©n fue el √∫nico sobreviviente del Titanic?"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fuente: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Esta es una respuesta muy confiada y completa. Desafortunadamente, es incorrecta. Incluso con una m√≠nima cantidad de investigaci√≥n, uno descubrir√≠a que hubo m√°s de un sobreviviente del desastre del Titanic. Para un estudiante que reci√©n comienza a investigar este tema, esta respuesta puede ser lo suficientemente persuasiva como para no ser cuestionada y tratada como un hecho. Las consecuencias de esto pueden llevar a que el sistema de IA sea poco fiable y afectar negativamente la reputaci√≥n de nuestra startup.

Con cada iteraci√≥n de cualquier LLM dado, hemos visto mejoras en el rendimiento en torno a minimizar las alucinaciones. Incluso con esta mejora, nosotros, como constructores de aplicaciones y usuarios, todav√≠a necesitamos estar conscientes de estas limitaciones.

### Contenido Da√±ino

Cubierto en la secci√≥n anterior cuando un LLM produce respuestas incorrectas o absurdas. Otro riesgo del que necesitamos estar conscientes es cuando un modelo responde con contenido da√±ino.

El contenido da√±ino puede definirse como:

- Proporcionar instrucciones o fomentar el autoda√±o o da√±o a ciertos grupos.
- Contenido odioso o degradante.
- Guiar la planificaci√≥n de cualquier tipo de ataque o actos violentos.
- Proporcionar instrucciones sobre c√≥mo encontrar contenido ilegal o cometer actos ilegales.
- Mostrar contenido sexualmente expl√≠cito.

Para nuestra startup, queremos asegurarnos de tener las herramientas y estrategias adecuadas para prevenir que este tipo de contenido sea visto por los estudiantes.

### Falta de Equidad

La equidad se define como "asegurar que un sistema de IA est√© libre de sesgos y discriminaci√≥n y que trate a todos de manera justa e igualitaria". En el mundo de la IA Generativa, queremos asegurarnos de que las visiones del mundo excluyentes de grupos marginados no sean reforzadas por la salida del modelo.

Estos tipos de salidas no solo son destructivos para construir experiencias de producto positivas para nuestros usuarios, sino que tambi√©n causan un da√±o social adicional. Como constructores de aplicaciones, siempre debemos tener en cuenta una base de usuarios amplia y diversa al construir soluciones con IA Generativa.

## C√≥mo Usar la IA Generativa de Manera Responsable

Ahora que hemos identificado la importancia de la IA Generativa Responsable, veamos 4 pasos que podemos tomar para construir nuestras soluciones de IA de manera responsable:

![Ciclo de Mitigaci√≥n](../../../translated_images/mitigate-cycle.f82610b2048bda5a84aaa3a3cb2cda8b35fe614a7269743fdc63cbc2cbb8f20f.es.png)

### Medir Da√±os Potenciales

En las pruebas de software, probamos las acciones esperadas de un usuario en una aplicaci√≥n. De manera similar, probar un conjunto diverso de indicaciones que los usuarios probablemente van a usar es una buena manera de medir el da√±o potencial.

Dado que nuestra startup est√° construyendo un producto educativo, ser√≠a bueno preparar una lista de indicaciones relacionadas con la educaci√≥n. Esto podr√≠a ser para cubrir un cierto tema, hechos hist√≥ricos y preguntas sobre la vida estudiantil.

### Mitigar Da√±os Potenciales

Ahora es el momento de encontrar formas en las que podamos prevenir o limitar el da√±o potencial causado por el modelo y sus respuestas. Podemos ver esto en 4 capas diferentes:

![Capas de Mitigaci√≥n](../../../translated_images/mitigation-layers.db2d802e3affb2f49681cf8ae39e8f1a67ff1ce29c3f1099c96948a841d62037.es.png)

- **Modelo**. Elegir el modelo adecuado para el caso de uso adecuado. Modelos m√°s grandes y complejos como GPT-4 pueden causar m√°s riesgo de contenido da√±ino cuando se aplican a casos de uso m√°s peque√±os y espec√≠ficos. Usar tus datos de entrenamiento para ajustar tambi√©n reduce el riesgo de contenido da√±ino.

- **Sistema de Seguridad**. Un sistema de seguridad es un conjunto de herramientas y configuraciones en la plataforma que sirve al modelo que ayuda a mitigar el da√±o. Un ejemplo de esto es el sistema de filtrado de contenido en el servicio Azure OpenAI. Los sistemas tambi√©n deben detectar ataques de jailbreak y actividad no deseada como solicitudes de bots.

- **Metaprompt**. Los metaprompts y el anclaje son formas en las que podemos dirigir o limitar el modelo basado en ciertos comportamientos e informaci√≥n. Esto podr√≠a ser usar entradas del sistema para definir ciertos l√≠mites del modelo. Adem√°s, proporcionar salidas que sean m√°s relevantes para el alcance o dominio del sistema.

Tambi√©n puede ser usar t√©cnicas como la Generaci√≥n Aumentada por Recuperaci√≥n (RAG) para que el modelo solo extraiga informaci√≥n de una selecci√≥n de fuentes confiables. Hay una lecci√≥n m√°s adelante en este curso para [construir aplicaciones de b√∫squeda](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Experiencia del Usuario**. La capa final es donde el usuario interact√∫a directamente con el modelo a trav√©s de la interfaz de nuestra aplicaci√≥n de alguna manera. De esta manera podemos dise√±ar la UI/UX para limitar al usuario en los tipos de entradas que pueden enviar al modelo, as√≠ como el texto o im√°genes mostradas al usuario. Al implementar la aplicaci√≥n de IA, tambi√©n debemos ser transparentes sobre lo que nuestra aplicaci√≥n de IA Generativa puede y no puede hacer.

Tenemos una lecci√≥n completa dedicada a [Dise√±ar UX para Aplicaciones de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluar el modelo**. Trabajar con LLMs puede ser desafiante porque no siempre tenemos control sobre los datos con los que se entren√≥ el modelo. Independientemente, siempre debemos evaluar el rendimiento y las salidas del modelo. Todav√≠a es importante medir la precisi√≥n del modelo, la similitud, la fundamentaci√≥n y la relevancia de la salida. Esto ayuda a proporcionar transparencia y confianza a las partes interesadas y usuarios.

### Operar una Soluci√≥n de IA Generativa Responsable

Construir una pr√°ctica operativa alrededor de tus aplicaciones de IA es la etapa final. Esto incluye asociarse con otras partes de nuestra startup como Legal y Seguridad para asegurarnos de que cumplimos con todas las pol√≠ticas regulatorias. Antes de lanzar, tambi√©n queremos construir planes alrededor de la entrega, manejo de incidentes y retroceso para prevenir cualquier da√±o a nuestros usuarios de crecer.

## Herramientas

Aunque el trabajo de desarrollar soluciones de IA Responsable puede parecer mucho, es un trabajo que vale la pena el esfuerzo. A medida que el √°rea de la IA Generativa crece, m√°s herramientas para ayudar a los desarrolladores a integrar eficientemente la responsabilidad en sus flujos de trabajo madurar√°n. Por ejemplo, la [Seguridad de Contenido de Azure AI](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) puede ayudar a detectar contenido e im√°genes da√±inas a trav√©s de una solicitud de API.

## Verificaci√≥n de Conocimiento

¬øQu√© son algunas cosas de las que necesitas preocuparte para asegurar un uso responsable de la IA?

1. Que la respuesta sea correcta.
2. Uso da√±ino, que la IA no se use para prop√≥sitos criminales.
3. Asegurar que la IA est√© libre de sesgos y discriminaci√≥n.

A: 2 y 3 son correctas. La IA Responsable te ayuda a considerar c√≥mo mitigar efectos da√±inos y sesgos y m√°s.

## üöÄ Desaf√≠o

Lee sobre [Seguridad de Contenido de Azure AI](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) y ve qu√© puedes adoptar para tu uso.

## Gran Trabajo, Contin√∫a Tu Aprendizaje

Despu√©s de completar esta lecci√≥n, consulta nuestra [colecci√≥n de aprendizaje de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir aumentando tus conocimientos de IA Generativa.

Dir√≠gete a la Lecci√≥n 4 donde veremos [Fundamentos de la Ingenier√≠a de Prompts](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n de IA [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n humana profesional. No somos responsables de ning√∫n malentendido o interpretaci√≥n err√≥nea que surja del uso de esta traducci√≥n.