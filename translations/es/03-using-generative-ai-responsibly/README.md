# Uso Responsable de la IA Generativa

[![Uso Responsable de la IA Generativa](../../../translated_images/03-lesson-banner.png?WT.b0b917735411b39a55748e827c5c3121004890110b27f306bfe685c450c81ff9.es.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Haz clic en la imagen de arriba para ver el video de esta lecci칩n_

Es f치cil sentirse fascinado por la IA y la IA generativa en particular, pero es importante considerar c칩mo usarla de manera responsable. Debes considerar aspectos como asegurar que el resultado sea justo, no da침ino y m치s. Este cap칤tulo tiene como objetivo proporcionarte el contexto mencionado, qu칠 considerar y c칩mo tomar medidas activas para mejorar tu uso de la IA.

## Introducci칩n

Esta lecci칩n cubrir치:

- Por qu칠 deber칤as priorizar la IA Responsable al construir aplicaciones de IA Generativa.
- Principios fundamentales de la IA Responsable y c칩mo se relacionan con la IA Generativa.
- C칩mo poner en pr치ctica estos principios de IA Responsable a trav칠s de estrategias y herramientas.

## Objetivos de Aprendizaje

Al completar esta lecci칩n, sabr치s:

- La importancia de la IA Responsable al construir aplicaciones de IA Generativa.
- Cu치ndo pensar y aplicar los principios fundamentales de la IA Responsable al construir aplicaciones de IA Generativa.
- Qu칠 herramientas y estrategias est치n disponibles para poner en pr치ctica el concepto de IA Responsable.

## Principios de IA Responsable

La emoci칩n por la IA Generativa nunca ha sido tan alta. Esta emoci칩n ha atra칤do a muchos nuevos desarrolladores, atenci칩n y financiamiento a este espacio. Si bien esto es muy positivo para cualquiera que busque construir productos y empresas utilizando IA Generativa, tambi칠n es importante proceder de manera responsable.

A lo largo de este curso, nos enfocamos en construir nuestra startup y nuestro producto educativo de IA. Usaremos los principios de la IA Responsable: Equidad, Inclusividad, Confiabilidad/Seguridad, Seguridad y Privacidad, Transparencia y Responsabilidad. Con estos principios, exploraremos c칩mo se relacionan con nuestro uso de la IA Generativa en nuestros productos.

## Por Qu칠 Deber칤as Priorizar la IA Responsable

Al construir un producto, adoptar un enfoque centrado en el ser humano teniendo en cuenta el mejor inter칠s de tus usuarios conduce a los mejores resultados.

La singularidad de la IA Generativa es su capacidad para crear respuestas 칰tiles, informaci칩n, orientaci칩n y contenido para los usuarios. Esto se puede hacer sin muchos pasos manuales, lo que puede llevar a resultados muy impresionantes. Sin una planificaci칩n y estrategias adecuadas, tambi칠n puede, lamentablemente, conducir a algunos resultados da침inos para tus usuarios, tu producto y la sociedad en general.

Veamos algunos (pero no todos) de estos resultados potencialmente da침inos:

### Alucinaciones

Las alucinaciones son un t칠rmino utilizado para describir cuando un LLM produce contenido que es completamente sin sentido o algo que sabemos que es incorrecto f치cticamente basado en otras fuentes de informaci칩n.

Tomemos, por ejemplo, que construimos una funci칩n para nuestra startup que permite a los estudiantes hacer preguntas hist칩ricas a un modelo. Un estudiante hace la pregunta `Who was the sole survivor of Titanic?`

El modelo produce una respuesta como la siguiente:

![Prompt diciendo "쯈ui칠n fue el 칰nico sobreviviente del Titanic?"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fuente: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Esta es una respuesta muy confiada y completa. Desafortunadamente, es incorrecta. Incluso con una cantidad m칤nima de investigaci칩n, uno descubrir칤a que hubo m치s de un sobreviviente del desastre del Titanic. Para un estudiante que reci칠n comienza a investigar este tema, esta respuesta puede ser lo suficientemente persuasiva como para no ser cuestionada y tratada como un hecho. Las consecuencias de esto pueden llevar a que el sistema de IA sea poco confiable y afecte negativamente la reputaci칩n de nuestra startup.

Con cada iteraci칩n de cualquier LLM dado, hemos visto mejoras en el rendimiento en torno a minimizar las alucinaciones. Incluso con esta mejora, nosotros como constructores y usuarios de aplicaciones todav칤a necesitamos ser conscientes de estas limitaciones.

### Contenido Da침ino

En la secci칩n anterior cubrimos cuando un LLM produce respuestas incorrectas o sin sentido. Otro riesgo del que debemos estar conscientes es cuando un modelo responde con contenido da침ino.

El contenido da침ino se puede definir como:

- Proporcionar instrucciones o alentar el autoda침o o el da침o a ciertos grupos.
- Contenido odioso o denigrante.
- Guiar la planificaci칩n de cualquier tipo de ataque o actos violentos.
- Proporcionar instrucciones sobre c칩mo encontrar contenido ilegal o cometer actos ilegales.
- Mostrar contenido sexualmente expl칤cito.

Para nuestra startup, queremos asegurarnos de tener las herramientas y estrategias adecuadas para evitar que este tipo de contenido sea visto por los estudiantes.

### Falta de Equidad

La equidad se define como "asegurar que un sistema de IA est칠 libre de sesgos y discriminaci칩n y que trate a todos de manera justa e igualitaria". En el mundo de la IA Generativa, queremos asegurarnos de que las visiones del mundo excluyentes de los grupos marginados no sean reforzadas por la salida del modelo.

Estos tipos de salidas no solo son destructivos para construir experiencias de producto positivas para nuestros usuarios, sino que tambi칠n causan un da침o social adicional. Como constructores de aplicaciones, siempre debemos tener en mente una base de usuarios amplia y diversa al construir soluciones con IA Generativa.

## C칩mo Usar la IA Generativa de Manera Responsable

Ahora que hemos identificado la importancia de la IA Generativa Responsable, veamos 4 pasos que podemos tomar para construir nuestras soluciones de IA de manera responsable:

![Ciclo de Mitigaci칩n](../../../translated_images/mitigate-cycle.png?WT.ffc987e1880649a302a311432b78f49faa64e46f65df6350c9c409b5ed79549b.es.mc_id=academic-105485-koreyst)

### Medir Da침os Potenciales

En las pruebas de software, probamos las acciones esperadas de un usuario en una aplicaci칩n. De manera similar, probar un conjunto diverso de prompts que los usuarios probablemente usar치n es una buena manera de medir el da침o potencial.

Dado que nuestra startup est치 construyendo un producto educativo, ser칤a bueno preparar una lista de prompts relacionados con la educaci칩n. Esto podr칤a ser para cubrir un cierto tema, hechos hist칩ricos y prompts sobre la vida estudiantil.

### Mitigar Da침os Potenciales

Ahora es el momento de encontrar formas en las que podamos prevenir o limitar el da침o potencial causado por el modelo y sus respuestas. Podemos ver esto en 4 capas diferentes:

![Capas de Mitigaci칩n](../../../translated_images/mitigation-layers.png?WT.cb109f48e143f1ff4dee760b4b0c9477c7d11c2fe57f3efdd89f68c1109f2de6.es.mc_id=academic-105485-koreyst)

- **Modelo**. Elegir el modelo correcto para el caso de uso correcto. Modelos m치s grandes y complejos como GPT-4 pueden causar m치s riesgo de contenido da침ino cuando se aplican a casos de uso m치s peque침os y espec칤ficos. Usar tus datos de entrenamiento para ajustar tambi칠n reduce el riesgo de contenido da침ino.

- **Sistema de Seguridad**. Un sistema de seguridad es un conjunto de herramientas y configuraciones en la plataforma que sirve al modelo que ayuda a mitigar el da침o. Un ejemplo de esto es el sistema de filtrado de contenido en el servicio de Azure OpenAI. Los sistemas tambi칠n deben detectar ataques de fuga y actividades no deseadas como solicitudes de bots.

- **Metaprompt**. Los metaprompts y la fundamentaci칩n son formas en que podemos dirigir o limitar el modelo basado en ciertos comportamientos e informaci칩n. Esto podr칤a ser usar entradas del sistema para definir ciertos l칤mites del modelo. Adem치s, proporcionar salidas que sean m치s relevantes para el alcance o dominio del sistema.

Tambi칠n puede ser usar t칠cnicas como la Generaci칩n Aumentada por Recuperaci칩n (RAG) para que el modelo solo obtenga informaci칩n de una selecci칩n de fuentes confiables. Hay una lecci칩n m치s adelante en este curso para [construir aplicaciones de b칰squeda](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Experiencia del Usuario**. La capa final es donde el usuario interact칰a directamente con el modelo a trav칠s de la interfaz de nuestra aplicaci칩n de alguna manera. De esta manera, podemos dise침ar la UI/UX para limitar al usuario en los tipos de entradas que pueden enviar al modelo, as칤 como el texto o las im치genes mostradas al usuario. Al desplegar la aplicaci칩n de IA, tambi칠n debemos ser transparentes sobre lo que nuestra aplicaci칩n de IA Generativa puede y no puede hacer.

Tenemos una lecci칩n completa dedicada a [Dise침ar UX para Aplicaciones de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluar el modelo**. Trabajar con LLMs puede ser un desaf칤o porque no siempre tenemos control sobre los datos con los que se entren칩 el modelo. Independientemente, siempre debemos evaluar el rendimiento y las salidas del modelo. A칰n es importante medir la precisi칩n, similitud, fundamentaci칩n y relevancia de la salida del modelo. Esto ayuda a proporcionar transparencia y confianza a los interesados y usuarios.

### Operar una Soluci칩n de IA Generativa Responsable

Construir una pr치ctica operacional alrededor de tus aplicaciones de IA es la etapa final. Esto incluye asociarse con otras partes de nuestra startup como Legal y Seguridad para asegurarnos de que cumplimos con todas las pol칤ticas regulatorias. Antes de lanzar, tambi칠n queremos construir planes alrededor de la entrega, manejo de incidentes y retroceso para evitar cualquier da침o a nuestros usuarios mientras crecemos.

## Herramientas

Si bien el trabajo de desarrollar soluciones de IA Responsable puede parecer mucho, es un esfuerzo que vale la pena. A medida que el 치rea de la IA Generativa crece, m치s herramientas para ayudar a los desarrolladores a integrar la responsabilidad en sus flujos de trabajo de manera eficiente madurar치n. Por ejemplo, el [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) puede ayudar a detectar contenido e im치genes da침inas a trav칠s de una solicitud de API.

## Verificaci칩n de Conocimientos

쮺u치les son algunas cosas de las que necesitas preocuparte para asegurar un uso responsable de la IA?

1. Que la respuesta sea correcta.
1. Uso da침ino, que la IA no se use para prop칩sitos criminales.
1. Asegurar que la IA est칠 libre de sesgos y discriminaci칩n.

A: 2 y 3 son correctas. La IA Responsable te ayuda a considerar c칩mo mitigar efectos da침inos y sesgos y m치s.

## 游 Desaf칤o

Lee sobre [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) y ve qu칠 puedes adoptar para tu uso.

## Gran Trabajo, Contin칰a Tu Aprendizaje

Despu칠s de completar esta lecci칩n, consulta nuestra [colecci칩n de Aprendizaje de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tu conocimiento en IA Generativa.

Dir칤gete a la Lecci칩n 4 donde veremos [Fundamentos de Ingenier칤a de Prompts](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando servicios de traducci칩n autom치tica basados en inteligencia artificial. Aunque nos esforzamos por lograr precisi칩n, tenga en cuenta que las traducciones autom치ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci칩n cr칤tica, se recomienda la traducci칩n profesional humana. No nos hacemos responsables de ning칰n malentendido o interpretaci칩n err칩nea que surja del uso de esta traducci칩n.