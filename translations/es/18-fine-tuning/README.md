<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T22:50:04+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "es"
}
-->
[![Modelos de C√≥digo Abierto](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.es.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Ajuste Fino de Tu LLM

Usar modelos de lenguaje grande para construir aplicaciones de IA generativa trae nuevos desaf√≠os. Un problema clave es garantizar la calidad de las respuestas (precisi√≥n y relevancia) en el contenido generado por el modelo para una solicitud espec√≠fica del usuario. En lecciones anteriores, discutimos t√©cnicas como la ingenier√≠a de prompts y la generaci√≥n aumentada por recuperaci√≥n que intentan resolver el problema _modificando la entrada del prompt_ al modelo existente.

En la lecci√≥n de hoy, discutimos una tercera t√©cnica, **ajuste fino**, que intenta abordar el desaf√≠o _reentrenando el modelo en s√≠ mismo_ con datos adicionales. Vamos a profundizar en los detalles.

## Objetivos de Aprendizaje

Esta lecci√≥n introduce el concepto de ajuste fino para modelos de lenguaje preentrenados, explora los beneficios y desaf√≠os de este enfoque, y proporciona orientaci√≥n sobre cu√°ndo y c√≥mo usar el ajuste fino para mejorar el rendimiento de tus modelos de IA generativa.

Al final de esta lecci√≥n, deber√≠as poder responder las siguientes preguntas:

- ¬øQu√© es el ajuste fino para modelos de lenguaje?
- ¬øCu√°ndo y por qu√© es √∫til el ajuste fino?
- ¬øC√≥mo puedo ajustar un modelo preentrenado?
- ¬øCu√°les son las limitaciones del ajuste fino?

¬øListo? Comencemos.

## Gu√≠a Ilustrada

¬øQuieres tener una visi√≥n general de lo que cubriremos antes de profundizar? Consulta esta gu√≠a ilustrada que describe el recorrido de aprendizaje para esta lecci√≥n: desde aprender los conceptos b√°sicos y la motivaci√≥n para el ajuste fino, hasta entender el proceso y las mejores pr√°cticas para ejecutar la tarea de ajuste fino. Este es un tema fascinante para explorar, as√≠ que no olvides revisar la p√°gina de [Recursos](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) para obtener enlaces adicionales que apoyen tu aprendizaje autodirigido.

![Gu√≠a Ilustrada para el Ajuste Fino de Modelos de Lenguaje](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.es.png)

## ¬øQu√© es el ajuste fino para modelos de lenguaje?

Por definici√≥n, los modelos de lenguaje grande est√°n _preentrenados_ en grandes cantidades de texto provenientes de diversas fuentes, incluyendo internet. Como hemos aprendido en lecciones anteriores, necesitamos t√©cnicas como _ingenier√≠a de prompts_ y _generaci√≥n aumentada por recuperaci√≥n_ para mejorar la calidad de las respuestas del modelo a las preguntas del usuario ("prompts").

Una t√©cnica popular de ingenier√≠a de prompts implica dar al modelo m√°s orientaci√≥n sobre lo que se espera en la respuesta, ya sea proporcionando _instrucciones_ (orientaci√≥n expl√≠cita) o _d√°ndole algunos ejemplos_ (orientaci√≥n impl√≠cita). Esto se conoce como _aprendizaje de pocos ejemplos_ pero tiene dos limitaciones:

- Los l√≠mites de tokens del modelo pueden restringir la cantidad de ejemplos que puedes dar y limitar la efectividad.
- Los costos de tokens del modelo pueden hacer que sea caro agregar ejemplos a cada prompt y limitar la flexibilidad.

El ajuste fino es una pr√°ctica com√∫n en sistemas de aprendizaje autom√°tico donde tomamos un modelo preentrenado y lo reentrenamos con nuevos datos para mejorar su rendimiento en una tarea espec√≠fica. En el contexto de los modelos de lenguaje, podemos ajustar el modelo preentrenado _con un conjunto curado de ejemplos para una tarea o dominio de aplicaci√≥n espec√≠fico_ para crear un **modelo personalizado** que puede ser m√°s preciso y relevante para esa tarea o dominio espec√≠fico. Un beneficio adicional del ajuste fino es que tambi√©n puede reducir la cantidad de ejemplos necesarios para el aprendizaje de pocos ejemplos, reduciendo el uso de tokens y los costos relacionados.

## ¬øCu√°ndo y por qu√© deber√≠amos ajustar los modelos?

En _este_ contexto, cuando hablamos de ajuste fino, nos referimos al ajuste fino **supervisado**, donde el reentrenamiento se realiza **agregando nuevos datos** que no formaban parte del conjunto de datos original de entrenamiento. Esto es diferente de un enfoque de ajuste fino no supervisado, donde el modelo se reentrena en los datos originales, pero con diferentes hiperpar√°metros.

Lo importante a recordar es que el ajuste fino es una t√©cnica avanzada que requiere cierto nivel de experiencia para obtener los resultados deseados. Si se hace incorrectamente, puede que no proporcione las mejoras esperadas e incluso puede degradar el rendimiento del modelo para tu dominio objetivo.

Entonces, antes de aprender "c√≥mo" ajustar modelos de lenguaje, necesitas saber "por qu√©" deber√≠as tomar esta ruta y "cu√°ndo" comenzar el proceso de ajuste fino. Comienza haci√©ndote estas preguntas:

- **Caso de Uso**: ¬øCu√°l es tu _caso de uso_ para el ajuste fino? ¬øQu√© aspecto del modelo preentrenado actual quieres mejorar?
- **Alternativas**: ¬øHas probado _otras t√©cnicas_ para lograr los resultados deseados? √ösalas para crear una l√≠nea base para la comparaci√≥n.
  - Ingenier√≠a de prompts: Prueba t√©cnicas como el uso de pocos ejemplos con ejemplos de respuestas relevantes al prompt. Eval√∫a la calidad de las respuestas.
  - Generaci√≥n Aumentada por Recuperaci√≥n: Prueba aumentar los prompts con resultados de consultas recuperados al buscar en tus datos. Eval√∫a la calidad de las respuestas.
- **Costos**: ¬øHas identificado los costos del ajuste fino?
  - Ajustabilidad: ¬øEst√° disponible el modelo preentrenado para ajuste fino?
  - Esfuerzo: para preparar datos de entrenamiento, evaluar y refinar el modelo.
  - Computaci√≥n: para ejecutar trabajos de ajuste fino y desplegar el modelo ajustado.
  - Datos: acceso a suficientes ejemplos de calidad para el impacto del ajuste fino.
- **Beneficios**: ¬øHas confirmado los beneficios del ajuste fino?
  - Calidad: ¬øel modelo ajustado super√≥ la l√≠nea base?
  - Costo: ¬øreduce el uso de tokens simplificando los prompts?
  - Extensibilidad: ¬øpuedes reutilizar el modelo base para nuevos dominios?

Al responder estas preguntas, deber√≠as poder decidir si el ajuste fino es el enfoque correcto para tu caso de uso. Idealmente, el enfoque es v√°lido solo si los beneficios superan los costos. Una vez que decidas proceder, es hora de pensar en _c√≥mo_ puedes ajustar el modelo preentrenado.

¬øQuieres obtener m√°s informaci√≥n sobre el proceso de toma de decisiones? Mira [Ajustar o no ajustar](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## ¬øC√≥mo podemos ajustar un modelo preentrenado?

Para ajustar un modelo preentrenado, necesitas tener:

- un modelo preentrenado para ajustar
- un conjunto de datos para usar en el ajuste fino
- un entorno de entrenamiento para ejecutar el trabajo de ajuste fino
- un entorno de alojamiento para desplegar el modelo ajustado

## Ajuste Fino en Acci√≥n

Los siguientes recursos proporcionan tutoriales paso a paso para guiarte a trav√©s de un ejemplo real usando un modelo seleccionado con un conjunto de datos curado. Para trabajar en estos tutoriales, necesitas una cuenta en el proveedor espec√≠fico, junto con acceso al modelo y conjuntos de datos relevantes.

| Proveedor    | Tutorial                                                                                                                                                                       | Descripci√≥n                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [C√≥mo ajustar modelos de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Aprende a ajustar un `gpt-35-turbo` para un dominio espec√≠fico ("asistente de recetas") preparando datos de entrenamiento, ejecutando el trabajo de ajuste fino y usando el modelo ajustado para inferencia.                                                                                                                                                                                                                         |
| Azure OpenAI | [Tutorial de ajuste fino de GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Aprende a ajustar un modelo `gpt-35-turbo-0613` **en Azure** siguiendo pasos para crear y cargar datos de entrenamiento, ejecutar el trabajo de ajuste fino. Despliega y utiliza el nuevo modelo.                                                                                                                                                                                                                                     |
| Hugging Face | [Ajuste fino de LLMs con Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Este blog explica c√≥mo ajustar un _LLM abierto_ (ej: `CodeLlama 7B`) usando la biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) y [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) con conjuntos de datos abiertos en [Hugging Face](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst). |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Ajuste fino de LLMs con AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (o AutoTrain Advanced) es una biblioteca de Python desarrollada por Hugging Face que permite el ajuste fino para muchas tareas diferentes, incluyendo el ajuste fino de LLM. AutoTrain es una soluci√≥n sin c√≥digo y el ajuste fino puede realizarse en tu propia nube, en Hugging Face Spaces o localmente. Admite tanto una interfaz gr√°fica basada en web, CLI y entrenamiento mediante archivos de configuraci√≥n yaml.                     |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Tarea

Selecciona uno de los tutoriales anteriores y sigue los pasos. _Podemos replicar una versi√≥n de estos tutoriales en Jupyter Notebooks en este repositorio solo como referencia. Por favor, utiliza las fuentes originales directamente para obtener las versiones m√°s recientes_.

## ¬°Buen Trabajo! Contin√∫a Aprendiendo.

Despu√©s de completar esta lecci√≥n, consulta nuestra [colecci√≥n de aprendizaje de IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir ampliando tus conocimientos sobre IA generativa.

¬°Felicidades! Has completado la √∫ltima lecci√≥n de la serie v2 de este curso. No dejes de aprender y construir. \*\*Consulta la p√°gina de [RECURSOS](RESOURCES.md?WT.mc_id=academic-105485-koreyst) para obtener una lista de sugerencias adicionales sobre este tema.

Nuestra serie de lecciones v1 tambi√©n ha sido actualizada con m√°s tareas y conceptos. As√≠ que t√≥mate un minuto para refrescar tus conocimientos, y por favor [comparte tus preguntas y comentarios](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) para ayudarnos a mejorar estas lecciones para la comunidad.

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que surjan del uso de esta traducci√≥n.