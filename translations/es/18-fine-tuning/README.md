<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:34:37+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "es"
}
-->
[![Modelos de C√≥digo Abierto](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.es.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Ajuste fino de tu LLM

Usar grandes modelos de lenguaje para construir aplicaciones de IA generativa trae nuevos desaf√≠os. Un problema clave es asegurar la calidad de las respuestas (precisi√≥n y relevancia) en el contenido generado por el modelo para una solicitud espec√≠fica del usuario. En lecciones anteriores, discutimos t√©cnicas como la ingenier√≠a de prompts y la generaci√≥n aumentada por recuperaci√≥n, que intentan resolver el problema _modificando la entrada del prompt_ al modelo existente.

En la lecci√≥n de hoy, hablaremos de una tercera t√©cnica, el **ajuste fino**, que busca abordar el desaf√≠o _reentrenando el modelo mismo_ con datos adicionales. Vamos a profundizar en los detalles.

## Objetivos de aprendizaje

Esta lecci√≥n introduce el concepto de ajuste fino para modelos de lenguaje preentrenados, explora los beneficios y desaf√≠os de este enfoque, y ofrece orientaci√≥n sobre cu√°ndo y c√≥mo usar el ajuste fino para mejorar el rendimiento de tus modelos de IA generativa.

Al final de esta lecci√≥n, deber√≠as poder responder las siguientes preguntas:

- ¬øQu√© es el ajuste fino para modelos de lenguaje?
- ¬øCu√°ndo y por qu√© es √∫til el ajuste fino?
- ¬øC√≥mo puedo ajustar finamente un modelo preentrenado?
- ¬øCu√°les son las limitaciones del ajuste fino?

¬øListo? Comencemos.

## Gu√≠a ilustrada

¬øQuieres tener una visi√≥n general de lo que cubriremos antes de profundizar? Consulta esta gu√≠a ilustrada que describe el recorrido de aprendizaje para esta lecci√≥n, desde entender los conceptos clave y la motivaci√≥n para el ajuste fino, hasta comprender el proceso y las mejores pr√°cticas para ejecutar la tarea de ajuste fino. Es un tema fascinante para explorar, as√≠ que no olvides visitar la p√°gina de [Recursos](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) para enlaces adicionales que apoyen tu aprendizaje autodirigido.

![Gu√≠a ilustrada para el ajuste fino de modelos de lenguaje](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.es.png)

## ¬øQu√© es el ajuste fino para modelos de lenguaje?

Por definici√≥n, los grandes modelos de lenguaje est√°n _preentrenados_ con grandes cantidades de texto provenientes de diversas fuentes, incluyendo internet. Como aprendimos en lecciones anteriores, necesitamos t√©cnicas como la _ingenier√≠a de prompts_ y la _generaci√≥n aumentada por recuperaci√≥n_ para mejorar la calidad de las respuestas del modelo a las preguntas del usuario ("prompts").

Una t√©cnica popular de ingenier√≠a de prompts consiste en darle al modelo m√°s orientaci√≥n sobre lo que se espera en la respuesta, ya sea proporcionando _instrucciones_ (gu√≠a expl√≠cita) o _d√°ndole algunos ejemplos_ (gu√≠a impl√≠cita). Esto se conoce como _aprendizaje con pocos ejemplos_ (few-shot learning), pero tiene dos limitaciones:

- Los l√≠mites de tokens del modelo pueden restringir la cantidad de ejemplos que puedes dar y limitar la efectividad.
- Los costos de tokens del modelo pueden hacer que sea caro a√±adir ejemplos a cada prompt y limitar la flexibilidad.

El ajuste fino es una pr√°ctica com√∫n en sistemas de aprendizaje autom√°tico donde tomamos un modelo preentrenado y lo reentrenamos con datos nuevos para mejorar su rendimiento en una tarea espec√≠fica. En el contexto de modelos de lenguaje, podemos ajustar finamente el modelo preentrenado _con un conjunto curado de ejemplos para una tarea o dominio de aplicaci√≥n espec√≠fico_ para crear un **modelo personalizado** que puede ser m√°s preciso y relevante para esa tarea o dominio. Un beneficio adicional del ajuste fino es que tambi√©n puede reducir la cantidad de ejemplos necesarios para el aprendizaje con pocos ejemplos, disminuyendo el uso de tokens y los costos relacionados.

## ¬øCu√°ndo y por qu√© deber√≠amos ajustar finamente los modelos?

En _este_ contexto, cuando hablamos de ajuste fino, nos referimos al ajuste fino **supervisado**, donde el reentrenamiento se realiza **a√±adiendo nuevos datos** que no formaban parte del conjunto de entrenamiento original. Esto es diferente de un enfoque de ajuste fino no supervisado, donde el modelo se reentrena con los datos originales, pero con diferentes hiperpar√°metros.

Lo importante a recordar es que el ajuste fino es una t√©cnica avanzada que requiere cierto nivel de experiencia para obtener los resultados deseados. Si se hace incorrectamente, puede no proporcionar las mejoras esperadas e incluso degradar el rendimiento del modelo para el dominio objetivo.

Por eso, antes de aprender "c√≥mo" ajustar finamente modelos de lenguaje, necesitas saber "por qu√©" deber√≠as tomar esta ruta y "cu√°ndo" comenzar el proceso de ajuste fino. Comienza haci√©ndote estas preguntas:

- **Caso de uso**: ¬øCu√°l es tu _caso de uso_ para el ajuste fino? ¬øQu√© aspecto del modelo preentrenado actual quieres mejorar?
- **Alternativas**: ¬øHas probado _otras t√©cnicas_ para lograr los resultados deseados? √ösalas para crear una l√≠nea base de comparaci√≥n.
  - Ingenier√≠a de prompts: Prueba t√©cnicas como few-shot prompting con ejemplos de respuestas relevantes. Eval√∫a la calidad de las respuestas.
  - Generaci√≥n aumentada por recuperaci√≥n: Prueba a aumentar los prompts con resultados de consultas recuperadas buscando en tus datos. Eval√∫a la calidad de las respuestas.
- **Costos**: ¬øHas identificado los costos del ajuste fino?
  - Ajustabilidad: ¬øEl modelo preentrenado est√° disponible para ajuste fino?
  - Esfuerzo: Para preparar los datos de entrenamiento, evaluar y refinar el modelo.
  - Computaci√≥n: Para ejecutar los trabajos de ajuste fino y desplegar el modelo ajustado.
  - Datos: Acceso a ejemplos de calidad suficiente para que el ajuste fino tenga impacto.
- **Beneficios**: ¬øHas confirmado los beneficios del ajuste fino?
  - Calidad: ¬øEl modelo ajustado super√≥ la l√≠nea base?
  - Costo: ¬øReduce el uso de tokens al simplificar los prompts?
  - Extensibilidad: ¬øPuedes reutilizar el modelo base para nuevos dominios?

Al responder estas preguntas, deber√≠as poder decidir si el ajuste fino es el enfoque adecuado para tu caso de uso. Idealmente, el enfoque es v√°lido solo si los beneficios superan los costos. Una vez que decidas continuar, es momento de pensar en _c√≥mo_ puedes ajustar finamente el modelo preentrenado.

¬øQuieres m√°s informaci√≥n sobre el proceso de toma de decisiones? Mira [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## ¬øC√≥mo podemos ajustar finamente un modelo preentrenado?

Para ajustar finamente un modelo preentrenado, necesitas tener:

- un modelo preentrenado para ajustar
- un conjunto de datos para usar en el ajuste fino
- un entorno de entrenamiento para ejecutar el trabajo de ajuste fino
- un entorno de hospedaje para desplegar el modelo ajustado

## Ajuste fino en acci√≥n

Los siguientes recursos ofrecen tutoriales paso a paso para guiarte a trav√©s de un ejemplo real usando un modelo seleccionado con un conjunto de datos curado. Para trabajar con estos tutoriales, necesitas una cuenta en el proveedor espec√≠fico, junto con acceso al modelo y conjuntos de datos relevantes.

| Proveedor    | Tutorial                                                                                                                                                                      | Descripci√≥n                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [C√≥mo ajustar finamente modelos de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)     | Aprende a ajustar finamente un `gpt-35-turbo` para un dominio espec√≠fico ("asistente de recetas") preparando datos de entrenamiento, ejecutando el trabajo de ajuste fino y usando el modelo ajustado para inferencia.                                                                                                                                                                                                              |
| Azure OpenAI | [Tutorial de ajuste fino GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Aprende a ajustar finamente un modelo `gpt-35-turbo-0613` **en Azure** siguiendo los pasos para crear y subir datos de entrenamiento, ejecutar el trabajo de ajuste fino, desplegar y usar el nuevo modelo.                                                                                                                                                                                                                         |
| Hugging Face | [Ajuste fino de LLMs con Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                            | Este art√≠culo te gu√≠a para ajustar finamente un _LLM abierto_ (ej: `CodeLlama 7B`) usando la librer√≠a [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) y [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) con conjuntos de datos abiertos en Hugging Face.                                                                 |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ü§ó AutoTrain | [Ajuste fino de LLMs con AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                      | AutoTrain (o AutoTrain Advanced) es una librer√≠a de Python desarrollada por Hugging Face que permite el ajuste fino para muchas tareas diferentes, incluyendo ajuste fino de LLMs. AutoTrain es una soluci√≥n sin c√≥digo y el ajuste fino puede hacerse en tu propia nube, en Hugging Face Spaces o localmente. Soporta interfaz web, CLI y entrenamiento mediante archivos de configuraci√≥n yaml.                                                                                 |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |

## Tarea

Selecciona uno de los tutoriales anteriores y sigue sus pasos. _Podr√≠amos replicar una versi√≥n de estos tutoriales en Jupyter Notebooks en este repositorio solo como referencia. Por favor, usa las fuentes originales directamente para obtener las versiones m√°s recientes_.

## ¬°Buen trabajo! Contin√∫a aprendiendo.

Despu√©s de completar esta lecci√≥n, visita nuestra [colecci√≥n de aprendizaje de IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tus conocimientos en IA generativa.

¬°Felicidades! Has completado la lecci√≥n final de la serie v2 de este curso. No dejes de aprender y crear. \*\*Consulta la p√°gina de [RECURSOS](RESOURCES.md?WT.mc_id=academic-105485-koreyst) para una lista de sugerencias adicionales solo para este tema.

Nuestra serie v1 de lecciones tambi√©n ha sido actualizada con m√°s tareas y conceptos. As√≠ que t√≥mate un momento para refrescar tus conocimientos y por favor [comparte tus preguntas y comentarios](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) para ayudarnos a mejorar estas lecciones para la comunidad.

**Aviso legal**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.