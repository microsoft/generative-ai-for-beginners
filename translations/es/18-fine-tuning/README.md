<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-05-20T07:34:56+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "es"
}
-->
[![Modelos de C√≥digo Abierto](../../../translated_images/18-lesson-banner.8487555c3e3225eefc1dc84e72c8e00bce1ee76db867a080628fb0fbb04aa0d2.es.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Ajuste Fino de tu LLM

Usar modelos de lenguaje grandes para construir aplicaciones de IA generativa presenta nuevos desaf√≠os. Un problema clave es asegurar la calidad de las respuestas (precisi√≥n y relevancia) en el contenido generado por el modelo para una solicitud espec√≠fica del usuario. En lecciones anteriores, discutimos t√©cnicas como la ingenier√≠a de prompts y la generaci√≥n aumentada por recuperaci√≥n que intentan resolver el problema _modificando la entrada del prompt_ al modelo existente.

En la lecci√≥n de hoy, discutimos una tercera t√©cnica, **ajuste fino**, que intenta abordar el desaf√≠o _reentrenando el modelo mismo_ con datos adicionales. Vamos a sumergirnos en los detalles.

## Objetivos de Aprendizaje

Esta lecci√≥n introduce el concepto de ajuste fino para modelos de lenguaje preentrenados, explora los beneficios y desaf√≠os de este enfoque, y ofrece orientaci√≥n sobre cu√°ndo y c√≥mo usar el ajuste fino para mejorar el rendimiento de tus modelos de IA generativa.

Al final de esta lecci√≥n, deber√≠as poder responder las siguientes preguntas:

- ¬øQu√© es el ajuste fino para modelos de lenguaje?
- ¬øCu√°ndo y por qu√© es √∫til el ajuste fino?
- ¬øC√≥mo puedo ajustar finamente un modelo preentrenado?
- ¬øCu√°les son las limitaciones del ajuste fino?

¬øListo? Vamos a comenzar.

## Gu√≠a Ilustrada

¬øQuieres tener una visi√≥n general de lo que cubriremos antes de profundizar? Echa un vistazo a esta gu√≠a ilustrada que describe el viaje de aprendizaje para esta lecci√≥n, desde aprender los conceptos b√°sicos y la motivaci√≥n para el ajuste fino, hasta entender el proceso y las mejores pr√°cticas para ejecutar la tarea de ajuste fino. Este es un tema fascinante para explorar, as√≠ que no olvides visitar la p√°gina de [Recursos](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) para enlaces adicionales que apoyen tu viaje de aprendizaje autodirigido.

![Gu√≠a Ilustrada para el Ajuste Fino de Modelos de Lenguaje](../../../translated_images/18-fine-tuning-sketchnote.92733966235199dd260184b1aae3a84b877c7496bc872d8e63ad6fa2dd96bafc.es.png)

## ¬øQu√© es el ajuste fino para modelos de lenguaje?

Por definici√≥n, los modelos de lenguaje grandes est√°n _preentrenados_ en grandes cantidades de texto provenientes de diversas fuentes, incluyendo internet. Como hemos aprendido en lecciones anteriores, necesitamos t√©cnicas como _ingenier√≠a de prompts_ y _generaci√≥n aumentada por recuperaci√≥n_ para mejorar la calidad de las respuestas del modelo a las preguntas del usuario ("prompts").

Una t√©cnica popular de ingenier√≠a de prompts implica darle al modelo m√°s orientaci√≥n sobre lo que se espera en la respuesta, ya sea proporcionando _instrucciones_ (orientaci√≥n expl√≠cita) o _d√°ndole algunos ejemplos_ (orientaci√≥n impl√≠cita). Esto se conoce como _aprendizaje de pocos ejemplos_, pero tiene dos limitaciones:

- Los l√≠mites de tokens del modelo pueden restringir el n√∫mero de ejemplos que puedes dar y limitar la efectividad.
- Los costos de tokens del modelo pueden hacer que sea caro a√±adir ejemplos a cada prompt y limitar la flexibilidad.

El ajuste fino es una pr√°ctica com√∫n en los sistemas de aprendizaje autom√°tico donde tomamos un modelo preentrenado y lo reentrenamos con nuevos datos para mejorar su rendimiento en una tarea espec√≠fica. En el contexto de los modelos de lenguaje, podemos ajustar finamente el modelo preentrenado _con un conjunto de ejemplos curados para una tarea o dominio de aplicaci√≥n espec√≠fico_ para crear un **modelo personalizado** que puede ser m√°s preciso y relevante para esa tarea o dominio espec√≠fico. Un beneficio adicional del ajuste fino es que tambi√©n puede reducir el n√∫mero de ejemplos necesarios para el aprendizaje de pocos ejemplos, reduciendo el uso de tokens y los costos relacionados.

## ¬øCu√°ndo y por qu√© deber√≠amos ajustar finamente los modelos?

En _este_ contexto, cuando hablamos de ajuste fino, nos referimos al ajuste fino **supervisado** donde el reentrenamiento se realiza **a√±adiendo nuevos datos** que no formaban parte del conjunto de datos de entrenamiento original. Esto es diferente de un enfoque de ajuste fino no supervisado donde el modelo se reentrena en los datos originales, pero con diferentes hiperpar√°metros.

Lo clave a recordar es que el ajuste fino es una t√©cnica avanzada que requiere cierto nivel de experiencia para obtener los resultados deseados. Si se hace incorrectamente, puede que no proporcione las mejoras esperadas, e incluso puede degradar el rendimiento del modelo para tu dominio objetivo.

Entonces, antes de aprender "c√≥mo" ajustar finamente los modelos de lenguaje, necesitas saber "por qu√©" deber√≠as tomar esta ruta y "cu√°ndo" comenzar el proceso de ajuste fino. Comienza pregunt√°ndote estas preguntas:

- **Caso de Uso**: ¬øCu√°l es tu _caso de uso_ para el ajuste fino? ¬øQu√© aspecto del modelo preentrenado actual quieres mejorar?
- **Alternativas**: ¬øHas intentado _otras t√©cnicas_ para lograr los resultados deseados? √ösalas para crear una l√≠nea base para la comparaci√≥n.
  - Ingenier√≠a de prompts: Intenta t√©cnicas como el uso de pocos ejemplos con ejemplos de respuestas de prompts relevantes. Eval√∫a la calidad de las respuestas.
  - Generaci√≥n Aumentada por Recuperaci√≥n: Intenta aumentar los prompts con resultados de consulta recuperados al buscar en tus datos. Eval√∫a la calidad de las respuestas.
- **Costos**: ¬øHas identificado los costos para el ajuste fino?
  - Ajustabilidad: ¬øEst√° disponible el modelo preentrenado para ajuste fino?
  - Esfuerzo: para preparar datos de entrenamiento, evaluar y refinar el modelo.
  - Computaci√≥n: para ejecutar trabajos de ajuste fino y desplegar el modelo ajustado.
  - Datos: acceso a ejemplos de calidad suficiente para el impacto del ajuste fino.
- **Beneficios**: ¬øHas confirmado los beneficios del ajuste fino?
  - Calidad: ¬øel modelo ajustado super√≥ la l√≠nea base?
  - Costo: ¬øreduce el uso de tokens simplificando los prompts?
  - Extensibilidad: ¬øpuedes reutilizar el modelo base para nuevos dominios?

Al responder estas preguntas, deber√≠as poder decidir si el ajuste fino es el enfoque correcto para tu caso de uso. Idealmente, el enfoque es v√°lido solo si los beneficios superan los costos. Una vez que decidas proceder, es hora de pensar en _c√≥mo_ puedes ajustar finamente el modelo preentrenado.

¬øQuieres obtener m√°s informaci√≥n sobre el proceso de toma de decisiones? Mira [Ajustar finamente o no ajustar finamente](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## ¬øC√≥mo podemos ajustar finamente un modelo preentrenado?

Para ajustar finamente un modelo preentrenado, necesitas tener:

- un modelo preentrenado para ajustar
- un conjunto de datos para usar en el ajuste fino
- un entorno de entrenamiento para ejecutar el trabajo de ajuste fino
- un entorno de alojamiento para desplegar el modelo ajustado

## Ajuste Fino en Acci√≥n

Los siguientes recursos proporcionan tutoriales paso a paso para guiarte a trav√©s de un ejemplo real usando un modelo seleccionado con un conjunto de datos curado. Para trabajar en estos tutoriales, necesitas una cuenta en el proveedor espec√≠fico, junto con acceso al modelo y conjuntos de datos relevantes.

| Proveedor    | Tutorial                                                                                                                                                                       | Descripci√≥n                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [C√≥mo ajustar finamente modelos de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)       | Aprende a ajustar finamente un `gpt-35-turbo` para un dominio espec√≠fico ("asistente de recetas") preparando datos de entrenamiento, ejecutando el trabajo de ajuste fino y usando el modelo ajustado para inferencia.                                                                                                                                                                                                                                              |
| Azure OpenAI | [Tutorial de ajuste fino de GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Aprende a ajustar finamente un modelo `gpt-35-turbo-0613` **en Azure** tomando pasos para crear y subir datos de entrenamiento, ejecutar el trabajo de ajuste fino. Despliega y usa el nuevo modelo.                                                                                                                                                                                                                                                                 |
| Hugging Face | [Ajuste fino de LLMs con Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | Esta publicaci√≥n de blog te gu√≠a en el ajuste fino de un _LLM abierto_ (ej: `CodeLlama 7B`) usando la biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) y [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) con conjuntos de datos abiertos en [datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) en Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain | [Ajuste fino de LLMs con AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                       | AutoTrain (o AutoTrain Advanced) es una biblioteca de Python desarrollada por Hugging Face que permite el ajuste fino para muchas tareas diferentes, incluyendo el ajuste fino de LLM. AutoTrain es una soluci√≥n sin c√≥digo y el ajuste fino puede realizarse en tu propia nube, en Hugging Face Spaces o localmente. Soporta tanto una interfaz gr√°fica web, CLI y entrenamiento mediante archivos de configuraci√≥n yaml.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Tarea

Selecciona uno de los tutoriales anteriores y rec√≥rrelos. _Podemos replicar una versi√≥n de estos tutoriales en Jupyter Notebooks en este repositorio solo para referencia. Por favor, utiliza las fuentes originales directamente para obtener las versiones m√°s recientes_.

## ¬°Buen Trabajo! Contin√∫a Tu Aprendizaje.

Despu√©s de completar esta lecci√≥n, visita nuestra [colecci√≥n de Aprendizaje de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tu conocimiento de IA Generativa.

¬°Felicidades! Has completado la √∫ltima lecci√≥n de la serie v2 de este curso. No dejes de aprender y construir. **Consulta la p√°gina de [RECURSOS](RESOURCES.md?WT.mc_id=academic-105485-koreyst) para una lista de sugerencias adicionales solo para este tema.

Nuestra serie de lecciones v1 tambi√©n ha sido actualizada con m√°s tareas y conceptos. As√≠ que t√≥mate un minuto para refrescar tu conocimiento, y por favor [comparte tus preguntas y comentarios](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) para ayudarnos a mejorar estas lecciones para la comunidad.

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por lograr precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n humana profesional. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que surjan del uso de esta traducci√≥n.