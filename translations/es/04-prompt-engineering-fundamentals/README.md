# Fundamentos de la Ingenier√≠a de Prompts

[![Fundamentos de la Ingenier√≠a de Prompts](../../../translated_images/es/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introducci√≥n
Este m√≥dulo cubre conceptos esenciales y t√©cnicas para crear prompts efectivos en modelos generativos de IA. La forma en que escribes tu prompt para un LLM tambi√©n importa. Un prompt cuidadosamente elaborado puede lograr una mejor calidad de respuesta. Pero, ¬øqu√© significan exactamente t√©rminos como _prompt_ e _ingenier√≠a de prompts_? ¬øY c√≥mo mejoro el _input_ del prompt que env√≠o al LLM? Estas son las preguntas que intentaremos responder en este cap√≠tulo y el siguiente.

La _IA generativa_ es capaz de crear contenido nuevo (por ejemplo, texto, im√°genes, audio, c√≥digo, etc.) en respuesta a las solicitudes de los usuarios. Lo logra usando _Modelos de Lenguaje a Gran Escala_ como la serie GPT de OpenAI ("Generative Pre-trained Transformer") que est√°n entrenados para usar lenguaje natural y c√≥digo.

Ahora los usuarios pueden interactuar con estos modelos usando paradigmas familiares como el chat, sin necesidad de experiencia t√©cnica ni capacitaci√≥n. Los modelos son _basados en prompts_: los usuarios env√≠an un texto (prompt) y obtienen la respuesta de la IA (completado). Luego pueden "chatear con la IA" de forma iterativa, en conversaciones de varios turnos, refinando su prompt hasta que la respuesta cumpla sus expectativas.

Los "prompts" ahora se vuelven la principal _interfaz de programaci√≥n_ para las aplicaciones de IA generativa, indicando a los modelos qu√© hacer e influyendo en la calidad de las respuestas devueltas. La "Ingenier√≠a de Prompts" es un campo en r√°pido crecimiento que se centra en el _dise√±o y optimizaci√≥n_ de prompts para entregar respuestas consistentes y de calidad a gran escala.

## Objetivos de Aprendizaje

En esta lecci√≥n, aprenderemos qu√© es la Ingenier√≠a de Prompts, por qu√© es importante y c√≥mo podemos crear prompts m√°s efectivos para un modelo y objetivo de aplicaci√≥n determinados. Entenderemos conceptos clave y mejores pr√°cticas para la ingenier√≠a de prompts, y conoceremos un entorno interactivo de Jupyter Notebooks ("sandbox") donde podemos ver estos conceptos aplicados a ejemplos reales.

Al final de esta lecci√≥n podremos:

1. Explicar qu√© es la ingenier√≠a de prompts y por qu√© es importante.
2. Describir los componentes de un prompt y c√≥mo se usan.
3. Aprender mejores pr√°cticas y t√©cnicas para la ingenier√≠a de prompts.
4. Aplicar t√©cnicas aprendidas a ejemplos reales, usando un endpoint de OpenAI.

## T√©rminos Clave

Ingenier√≠a de Prompts: La pr√°ctica de dise√±ar y refinar entradas para guiar a los modelos de IA hacia la producci√≥n de salidas deseadas.  
Tokenizaci√≥n: El proceso de convertir texto en unidades m√°s peque√±as, llamadas tokens, que un modelo puede entender y procesar.  
LLMs Ajustados por Instrucci√≥n: Modelos de Lenguaje a Gran Escala (LLMs) que han sido afinados con instrucciones espec√≠ficas para mejorar la precisi√≥n y relevancia de sus respuestas.

## Sandbox de Aprendizaje

Actualmente, la ingenier√≠a de prompts es m√°s un arte que una ciencia. La mejor forma de mejorar nuestra intuici√≥n es _practicar m√°s_ y adoptar un enfoque de prueba y error que combine experiencia en el dominio de aplicaci√≥n con t√©cnicas recomendadas y optimizaciones espec√≠ficas para el modelo.

El Jupyter Notebook que acompa√±a esta lecci√≥n provee un entorno _sandbox_ donde puedes probar lo que aprendes, ya sea sobre la marcha o como parte del desaf√≠o de c√≥digo al final. Para ejecutar los ejercicios, necesitar√°s:

1. **Una clave API de Azure OpenAI**: el endpoint del servicio para un LLM desplegado.  
2. **Un entorno de ejecuci√≥n Python**: donde se pueda ejecutar el Notebook.  
3. **Variables de entorno locales**: _completa los pasos del [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) ahora para estar listo_.

El notebook incluye ejercicios _iniciales_, pero se te anima a a√±adir tus propias secciones de _Markdown_ (descripci√≥n) y _C√≥digo_ (peticiones de prompt) para probar m√°s ejemplos o ideas y as√≠ desarrollar tu intuici√≥n para el dise√±o de prompts.

## Gu√≠a Ilustrada

¬øQuieres tener una visi√≥n general de lo que cubre esta lecci√≥n antes de profundizar? Consulta esta gu√≠a ilustrada, que te dar√° una percepci√≥n de los temas principales y los puntos clave para reflexionar en cada uno. La hoja de ruta de la lecci√≥n te lleva desde comprender los conceptos y desaf√≠os b√°sicos hasta abordarlos con t√©cnicas y mejores pr√°cticas relevantes de ingenier√≠a de prompts. Nota que la secci√≥n "T√©cnicas Avanzadas" en esta gu√≠a se refiere a contenido cubierto en el _siguiente_ cap√≠tulo de este curr√≠culo.

![Gu√≠a Ilustrada de Ingenier√≠a de Prompts](../../../translated_images/es/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## Nuestra Startup

Ahora, hablemos de c√≥mo _este tema_ se relaciona con nuestra misi√≥n en la startup de [llevar la innovaci√≥n en IA a la educaci√≥n](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplicaciones impulsadas por IA de _aprendizaje personalizado_, as√≠ que pensemos en c√≥mo distintos usuarios de nuestra aplicaci√≥n podr√≠an "dise√±ar" prompts:

- **Administradores** podr√≠an pedirle a la IA que _analice datos del curr√≠culo para identificar brechas en la cobertura_. La IA puede resumir resultados o visualizarlos con c√≥digo.
- **Educadores** podr√≠an pedirle a la IA que _genere un plan de lecci√≥n para un p√∫blico y tema objetivo_. La IA puede construir el plan personalizado en un formato especificado.
- **Estudiantes** podr√≠an pedirle a la IA que _los tutorice en una materia dif√≠cil_. La IA ahora puede guiar a los estudiantes con lecciones, pistas y ejemplos adaptados a su nivel.

Eso es solo la punta del iceberg. Consulta [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - una biblioteca open-source de prompts curada por expertos en educaci√≥n - para tener una idea m√°s amplia de las posibilidades. _¬°Prueba ejecutar algunos de esos prompts en el sandbox o usando el OpenAI Playground para ver qu√© pasa!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## ¬øQu√© es la Ingenier√≠a de Prompts?

Comenzamos esta lecci√≥n definiendo la **Ingenier√≠a de Prompts** como el proceso de _dise√±ar y optimizar_ entradas de texto (prompts) para entregar respuestas (completados) consistentes y de calidad para un objetivo y modelo dados. Podemos pensar en esto como un proceso de dos pasos:

- _dise√±ar_ el prompt inicial para un modelo y objetivo espec√≠ficos  
- _refinar_ el prompt iterativamente para mejorar la calidad de la respuesta

Este es necesariamente un proceso de prueba y error que requiere intuici√≥n y esfuerzo del usuario para obtener resultados √≥ptimos. ¬øPor qu√© es importante? Para responder a esa pregunta, primero necesitamos entender tres conceptos:

- _Tokenizaci√≥n_ = c√≥mo el modelo "ve" el prompt  
- _LLMs base_ = c√≥mo el modelo base "procesa" un prompt  
- _LLMs ajustados por instrucci√≥n_ = c√≥mo el modelo puede ahora entender "tareas"

### Tokenizaci√≥n

Un LLM ve los prompts como una _secuencia de tokens_, donde diferentes modelos (o versiones de un modelo) pueden tokenizar el mismo prompt de manera diferente. Dado que los LLMs se entrenan con tokens (y no con texto en bruto), la forma en que se tokenizan los prompts tiene un impacto directo en la calidad de la respuesta generada.

Para tener una intuici√≥n de c√≥mo funciona la tokenizaci√≥n, prueba herramientas como el [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) que se muestra a continuaci√≥n. Copia tu prompt y observa c√≥mo se convierte en tokens, prestando atenci√≥n a c√≥mo se manejan los espacios en blanco y los signos de puntuaci√≥n. Ten en cuenta que este ejemplo muestra un LLM m√°s antiguo (GPT-3), por lo que probar con un modelo m√°s nuevo podr√≠a producir un resultado diferente.

![Tokenizaci√≥n](../../../translated_images/es/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Concepto: Modelos Base

Una vez tokenizado un prompt, la funci√≥n principal del ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (o modelo base) es predecir el siguiente token en esa secuencia. Dado que los LLMs se entrenan con grandes conjuntos de datos textuales, tienen una buena comprensi√≥n de las relaciones estad√≠sticas entre tokens y pueden hacer esa predicci√≥n con cierta confianza. N√≥tese que no "entienden" el _significado_ de las palabras en el prompt o el token; solo ven un patr√≥n que pueden "completar" con su siguiente predicci√≥n. Pueden continuar prediciendo la secuencia hasta que sea terminada por intervenci√≥n del usuario o alguna condici√≥n preestablecida.

¬øQuieres ver c√≥mo funcionan las completaciones basadas en prompts? Introduce el prompt anterior en el Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) con la configuraci√≥n predeterminada. El sistema est√° configurado para tratar los prompts como solicitudes de informaci√≥n, as√≠ que deber√≠as ver un completado que satisfaga este contexto.

Pero, ¬øqu√© pasa si el usuario quiere ver algo espec√≠fico que cumpla ciertos criterios u objetivo de tarea? Aqu√≠ es donde entran los LLMs _ajustados por instrucciones_.

![Completado Base LLM en Chat](../../../translated_images/es/04-playground-chat-base.65b76fcfde0caa67.webp)

### Concepto: LLMs Ajustados por Instrucci√≥n

Un [LLM Ajustado por Instrucci√≥n](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) parte del modelo base y lo afina con ejemplos o pares de entrada/salida (por ejemplo, "mensajes" de varios turnos) que pueden contener instrucciones claras, y la IA intenta seguir esa instrucci√≥n en la respuesta.

Esto utiliza t√©cnicas como el Aprendizaje por Refuerzo con Retroalimentaci√≥n Humana (RLHF) que pueden entrenar al modelo para _seguir instrucciones_ y _aprender de la retroalimentaci√≥n_, de modo que produzca respuestas mejor adaptadas a aplicaciones pr√°cticas y m√°s relevantes para los objetivos del usuario.

Prob√©moslo: revisa el prompt anterior, pero ahora cambia el _mensaje del sistema_ para proporcionar la siguiente instrucci√≥n como contexto:

> _Resume el contenido que se te proporciona para un estudiante de segundo grado. Mant√©n el resultado en un p√°rrafo con 3-5 puntos clave._

¬øVes c√≥mo el resultado ahora est√° ajustado para reflejar el objetivo y formato deseados? Un educador puede usar directamente esta respuesta en sus diapositivas para esa clase.

![Completado LLM Ajustado por Instrucci√≥n en Chat](../../../translated_images/es/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## ¬øPor qu√© necesitamos la Ingenier√≠a de Prompts?

Ahora que sabemos c√≥mo los LLMs procesan los prompts, hablemos de _por qu√©_ necesitamos la ingenier√≠a de prompts. La respuesta radica en el hecho de que los LLMs actuales presentan varios desaf√≠os que hacen que obtener _completados fiables y consistentes_ sea m√°s dif√≠cil sin poner esfuerzo en la construcci√≥n y optimizaci√≥n del prompt. Por ejemplo:

1. **Las respuestas del modelo son estoc√°sticas.** El _mismo prompt_ probablemente produzca respuestas diferentes en distintos modelos o versiones de modelos. E incluso puede producir resultados distintos con el _mismo modelo_ en diferentes momentos. _Las t√©cnicas de ingenier√≠a de prompts pueden ayudarnos a minimizar estas variaciones proporcionando mejores gu√≠as_.

1. **Los modelos pueden fabricar respuestas.** Los modelos est√°n preentrenados con conjuntos de datos _grandes pero finitos_, lo que significa que carecen de conocimiento sobre conceptos fuera de ese alcance de entrenamiento. Como resultado, pueden producir completados inexactos, imaginarios o directamente contradictorios a hechos conocidos. _Las t√©cnicas de ingenier√≠a de prompts ayudan a los usuarios a identificar y mitigar tales fabricaciones, por ejemplo, pidiendo a la IA citas o razonamientos_.

1. **Las capacidades del modelo variar√°n.** Los modelos m√°s nuevos o generaciones posteriores tendr√°n capacidades m√°s amplias pero tambi√©n traer√°n peculiaridades y compromisos √∫nicos en costo y complejidad. _La ingenier√≠a de prompts puede ayudarnos a desarrollar mejores pr√°cticas y flujos de trabajo que abstraigan diferencias y se adapten a requerimientos espec√≠ficos del modelo de manera escalable y fluida_.

Veamos esto en acci√≥n en el Playground de OpenAI o Azure OpenAI:

- Usa el mismo prompt con diferentes despliegues de LLM (por ejemplo, OpenAI, Azure OpenAI, Hugging Face): ¬øviste las variaciones?  
- Usa el mismo prompt repetidamente con el _mismo_ despliegue de LLM (por ejemplo, playground de Azure OpenAI): ¬øen qu√© difirieron estas variaciones?

### Ejemplo de Fabricaciones

En este curso usamos el t√©rmino **"fabricaci√≥n"** para referirnos al fen√≥meno donde los LLMs a veces generan informaci√≥n incorrecta desde el punto de vista factual debido a sus limitaciones en el entrenamiento u otras restricciones. Puede que tambi√©n hayas o√≠do hablar de esto como _"alucinaciones"_ en art√≠culos populares o papers de investigaci√≥n. Sin embargo, recomendamos enf√°ticamente usar _"fabricaci√≥n"_ para no antropomorfizar accidentalmente el comportamiento, atribuyendo una caracter√≠stica humana a un resultado impulsado por m√°quina. Esto tambi√©n refuerza las [directrices de IA Responsable](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) desde una perspectiva terminol√≥gica, eliminando t√©rminos que pueden considerarse ofensivos o no inclusivos en algunos contextos.

¬øQuieres tener una idea de c√≥mo funcionan las fabricaciones? Piensa en un prompt que instruye a la IA a generar contenido sobre un tema inexistente (para asegurarte de que no se encuentra en el conjunto de entrenamiento). Por ejemplo: intent√© este prompt:

> **Prompt:** genera un plan de lecci√≥n sobre la Guerra Marciana de 2076.
Una b√∫squeda en la web me mostr√≥ que exist√≠an relatos ficticios (por ejemplo, series de televisi√≥n o libros) sobre guerras marcianas, pero ninguno en 2076. El sentido com√∫n tambi√©n nos dice que 2076 est√° _en el futuro_ y, por lo tanto, no puede estar asociado a un evento real.

Entonces, ¬øqu√© ocurre cuando ejecutamos este prompt con diferentes proveedores de LLM?

> **Respuesta 1**: OpenAI Playground (GPT-35)

![Respuesta 1](../../../translated_images/es/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Respuesta 2**: Azure OpenAI Playground (GPT-35)

![Respuesta 2](../../../translated_images/es/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Respuesta 3**: : Hugging Face Chat Playground (LLama-2)

![Respuesta 3](../../../translated_images/es/04-fabrication-huggingchat.faf82a0a51278956.webp)

Como se esperaba, cada modelo (o versi√≥n del modelo) produce respuestas ligeramente diferentes gracias al comportamiento estoc√°stico y a las variaciones en la capacidad del modelo. Por ejemplo, un modelo apunta a una audiencia de 8¬∫ grado mientras que el otro asume un estudiante de secundaria. Pero los tres modelos generaron respuestas que podr√≠an convencer a un usuario no informado de que el evento fue real.

T√©cnicas de ingenier√≠a de prompts como el _metaprompting_ y la _configuraci√≥n de temperatura_ pueden reducir las fabricaciones del modelo hasta cierto punto. Nuevas _arquitecturas_ de ingenier√≠a de prompts tambi√©n incorporan nuevas herramientas y t√©cnicas de manera fluida en el flujo del prompt para mitigar o reducir algunos de estos efectos.

## Estudio de caso: GitHub Copilot

Cerremos esta secci√≥n teniendo una idea de c√≥mo se emplea la ingenier√≠a de prompts en soluciones del mundo real al analizar un Estudio de caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot es tu "programador asistente con IA" ‚Äî convierte prompts de texto en completaciones de c√≥digo y est√° integrado en tu entorno de desarrollo (por ejemplo, Visual Studio Code) para brindar una experiencia de usuario fluida. Como se documenta en la serie de blogs a continuaci√≥n, la versi√≥n m√°s temprana se bas√≥ en el modelo OpenAI Codex ‚Äî con ingenieros que r√°pidamente se dieron cuenta de la necesidad de ajustar finamente el modelo y desarrollar mejores t√©cnicas de ingenier√≠a de prompts para mejorar la calidad del c√≥digo. En julio, [presentaron un modelo IA mejorado que va m√°s all√° de Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para ofrecer sugerencias a√∫n m√°s r√°pidas.

Lee las publicaciones en orden para seguir su trayecto de aprendizaje.

- **Mayo 2023** | [GitHub Copilot est√° mejorando en entender tu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mayo 2023** | [Dentro de GitHub: Trabajando con los LLM detr√°s de GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Junio 2023** | [C√≥mo escribir mejores prompts para GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Julio 2023** | [.. GitHub Copilot va m√°s all√° de Codex con modelo IA mejorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Julio 2023** | [Gu√≠a para desarrolladores sobre ingenier√≠a de prompts y LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Septiembre 2023** | [C√≥mo construir una aplicaci√≥n empresarial con LLM: lecciones de GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Tambi√©n puedes explorar su [blog de Ingenier√≠a](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para m√°s publicaciones como [esta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que muestra c√≥mo estos modelos y t√©cnicas se _aplican_ para impulsar aplicaciones reales.

---

<!--
LESSON TEMPLATE:
Este m√≥dulo deber√≠a cubrir el concepto central #2.
Refuerza el concepto con ejemplos y referencias.

CONCEPTO #2:
Dise√±o de Prompts.
Ilustrado con ejemplos.
-->

## Construcci√≥n de Prompts

Hemos visto por qu√© la ingenier√≠a de prompts es importante ‚Äî ahora entendamos c√≥mo se _construyen_ los prompts para poder evaluar distintas t√©cnicas para un dise√±o de prompts m√°s efectivo.

### Prompt B√°sico

Empecemos con el prompt b√°sico: una entrada de texto enviada al modelo sin otro contexto. Aqu√≠ un ejemplo ‚Äî cuando enviamos las primeras palabras del himno nacional estadounidense a la API de [Completion de OpenAI](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) este completa inmediatamente la respuesta con las siguientes l√≠neas, ilustrando el comportamiento b√°sico de predicci√≥n.

| Prompt (Entrada)     | Completion (Salida)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Parece que est√°s empezando la letra de "The Star-Spangled Banner", el himno nacional de los Estados Unidos. La letra completa es ... |

### Prompt Complejo

Ahora a√±adamos contexto e instrucciones a ese prompt b√°sico. La [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir un prompt complejo como una colecci√≥n de _mensajes_ con:

- Pares de entrada/salida que reflejan la entrada del _usuario_ y la respuesta del _asistente_.
- Mensaje del sistema que establece el contexto para el comportamiento o personalidad del asistente.

La solicitud queda ahora en la forma siguiente, donde la _tokenizaci√≥n_ captura efectivamente informaci√≥n relevante del contexto y la conversaci√≥n. Cambiar el contexto del sistema puede ser tan impactante para la calidad de las completaciones como la entrada del usuario.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt de Instrucci√≥n

En los ejemplos anteriores, el prompt del usuario era una consulta de texto simple que se puede interpretar como una solicitud de informaci√≥n. Con los prompts de _instrucci√≥n_, podemos usar ese texto para especificar una tarea con m√°s detalle, proporcionando mejor gu√≠a a la IA. Aqu√≠ un ejemplo:

| Prompt (Entrada)                                                                                                                                                                                                                         | Completion (Salida)                                                                                                | Tipo de Instrucci√≥n |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------- | :------------------- |
| Escribe una descripci√≥n de la Guerra Civil                                                                                                                                                                                             | _devuelve un p√°rrafo simple_                                                                                        | Simple               |
| Escribe una descripci√≥n de la Guerra Civil. Proporciona fechas y eventos clave y describe su importancia                                                                                                                                 | _devuelve un p√°rrafo seguido de una lista de fechas clave con descripciones_                                       | Compleja             |
| Escribe una descripci√≥n de la Guerra Civil en 1 p√°rrafo. Proporciona 3 puntos con fechas clave y su importancia. Proporciona 3 puntos m√°s con figuras hist√≥ricas clave y sus contribuciones. Devuelve la salida como un archivo JSON   | _devuelve detalles m√°s extensos en un cuadro de texto, formateado como JSON que puedes copiar-pegar y validar_      | Compleja. Formateada.|

## Contenido Primario

En los ejemplos anteriores, el prompt a√∫n era bastante abierto, dejando que el LLM decidiera qu√© parte de su dataset preentrenado era relevante. Con el patr√≥n de dise√±o de _contenido primario_, el texto de entrada se divide en dos partes:

- una instrucci√≥n (acci√≥n)
- contenido relevante (que influye en la acci√≥n)

Aqu√≠ un ejemplo donde la instrucci√≥n es "resume esto en 2 oraciones".

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Completion (Salida)                                                                                                                                                                                                                                                                            |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter es el quinto planeta desde el Sol y el mayor del Sistema Solar. Es un gigante gaseoso con una masa mil veces menor que la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por civilizaciones antiguas desde antes de la historia registrada. Lleva el nombre del dios romano J√∫piter.[19] Cuando se observa desde la Tierra, J√∫piter puede ser lo suficientemente brillante como para que su luz reflejada proyecte sombras visibles,[20] y es en promedio el tercer objeto natural m√°s brillante en el cielo nocturno despu√©s de la Luna y Venus. <br/> **Resume esto en 2 oraciones cortas** | J√∫piter, el quinto planeta desde el Sol, es el mayor del Sistema Solar y es conocido por ser uno de los objetos m√°s brillantes en el cielo nocturno. Llamado as√≠ por el dios romano J√∫piter, es un gigante gaseoso cuya masa es dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. |

El segmento de contenido primario puede usarse de varias formas para impulsar instrucciones m√°s efectivas:

- **Ejemplos** ‚Äî en lugar de decirle al modelo qu√© hacer con una instrucci√≥n expl√≠cita, darle ejemplos de lo que debe hacer y permitir que infiera el patr√≥n.
- **Se√±ales** ‚Äî seguir la instrucci√≥n con una "se√±al" que prepara la completaci√≥n, guiando al modelo hacia respuestas m√°s relevantes.
- **Plantillas** ‚Äî son 'recetas' repetibles para prompts con marcadores de posici√≥n (variables) que pueden personalizarse con datos para casos de uso espec√≠ficos.

Exploremos estas opciones en la pr√°ctica.

### Uso de Ejemplos

Esta es una aproximaci√≥n en la que usas el contenido primario para "alimentar al modelo" con ejemplos del resultado deseado para una instrucci√≥n dada, y permitir que infiera el patr√≥n para la salida deseada. Seg√∫n la cantidad de ejemplos proporcionados, podemos tener prompting de cero disparos (zero-shot), un disparo (one-shot), pocos disparos (few-shot), etc.

El prompt ahora consta de tres componentes:

- Una descripci√≥n de la tarea
- Algunos ejemplos del resultado deseado
- El inicio de un nuevo ejemplo (que se vuelve una descripci√≥n impl√≠cita de la tarea)

| Tipo de Aprendizaje | Prompt (Entrada)                                                                                                                               | Completion (Salida)         |
| :------------------ | :--------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot           | "The Sun is Shining". Traduce al espa√±ol                                                                                                       | "El Sol est√° brillando".    |
| One-shot            | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                          | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot            | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk => | Baloncesto                 |
|                     |                                                                                                                                                 |                             |

Observa c√≥mo tuvimos que dar una instrucci√≥n expl√≠cita ("Traduce al espa√±ol") en el prompting zero-shot, pero se infiere en el ejemplo one-shot. El ejemplo few-shot muestra c√≥mo agregar m√°s ejemplos permite que los modelos hagan inferencias m√°s precisas sin instrucciones adicionales.

### Se√±ales en el Prompt

Otra t√©cnica para usar contenido primario es proporcionar _se√±ales_ en lugar de ejemplos. En este caso, damos al modelo un empuj√≥n en la direcci√≥n correcta al _empezar_ con un fragmento que refleja el formato de respuesta deseado. Luego el modelo "toma la se√±al" para continuar en esa l√≠nea.

| N√∫mero de Se√±ales | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Salida)                                                                                                                                                                                                                                                                                       |
| :---------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                  | J√∫piter es el quinto planeta desde el Sol y el mayor del Sistema Solar. Es un gigante gaseoso con una masa mil veces menor que la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por civilizaciones antiguas desde antes de la historia registrada. <br/>**Resume esto**                                       | J√∫piter es el planeta m√°s grande de nuestro Sistema Solar y el quinto desde el Sol. Es un gigante gaseoso con una masa 1/1000 de la del Sol, pero es m√°s pesado que todos los dem√°s planetas combinados. Las civilizaciones antiguas han conocido a J√∫piter durante mucho tiempo y es f√°cilmente visible en el cielo nocturno. |
| 1              | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Resumir Esto** <br/> Lo que aprendimos es que J√∫piter | es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas combinados. Es f√°cilmente visible a simple vista y ha sido conocido desde tiempos antiguos.                        |
| 2              | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Resumir Esto** <br/> Top 3 Datos que Aprendimos:         | 1. J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. <br/> 2. Es un gigante gaseoso con una masa de una mil√©sima parte de la del Sol...<br/> 3. J√∫piter ha sido visible a simple vista desde tiempos antiguos ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Plantillas de Prompt

Una plantilla de prompt es una _receta predefinida para un prompt_ que puede almacenarse y reutilizarse seg√∫n sea necesario, para generar experiencias de usuario m√°s consistentes a escala. En su forma m√°s simple, es simplemente una colecci√≥n de ejemplos de prompts como [este de OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que proporciona tanto los componentes interactivos del prompt (mensajes de usuario y sistema) como el formato de solicitud impulsado por API, para facilitar la reutilizaci√≥n.

En su forma m√°s compleja como [este ejemplo de LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) contiene _marcadores de posici√≥n_ que pueden reemplazarse con datos de diversas fuentes (entrada del usuario, contexto del sistema, fuentes de datos externas, etc.) para generar un prompt din√°micamente. Esto nos permite crear una biblioteca de prompts reutilizables que pueden usarse para generar experiencias de usuario **program√°ticamente** y de manera coherente a escala.

Finalmente, el verdadero valor de las plantillas radica en la capacidad de crear y publicar _bibliotecas de prompts_ para dominios de aplicaci√≥n verticales, donde la plantilla del prompt est√° ahora _optimizadas_ para reflejar contexto o ejemplos espec√≠ficos de la aplicaci√≥n, haciendo que las respuestas sean m√°s relevantes y precisas para el p√∫blico objetivo. El repositorio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) es un gran ejemplo de este enfoque, que selecciona una biblioteca de prompts para el dominio educativo con √©nfasis en objetivos clave como planificaci√≥n de lecciones, dise√±o curricular, tutor√≠a de estudiantes, etc.

## Contenido de Apoyo

Si pensamos en la construcci√≥n de un prompt como tener una instrucci√≥n (tarea) y un objetivo (contenido principal), entonces el _contenido secundario_ es como contexto adicional que proporcionamos para **influir en la salida de alguna manera**. Podr√≠an ser par√°metros de ajuste, instrucciones de formato, taxonom√≠as de temas, etc. que pueden ayudar al modelo a _adaptar_ su respuesta para adecuarse a los objetivos o expectativas del usuario deseados.

Por ejemplo: dado un cat√°logo de cursos con metadatos extensos (nombre, descripci√≥n, nivel, etiquetas de metadatos, instructor, etc.) sobre todos los cursos disponibles en el plan de estudios:

- podemos definir una instrucci√≥n para "resumir el cat√°logo de cursos para oto√±o 2023"
- podemos usar el contenido principal para proporcionar algunos ejemplos del resultado deseado
- podemos usar el contenido secundario para identificar las 5 "etiquetas" de mayor inter√©s.

Ahora, el modelo puede proporcionar un resumen en el formato mostrado por los ejemplos, pero si un resultado tiene m√∫ltiples etiquetas, puede priorizar las 5 etiquetas identificadas en el contenido secundario.

---

<!--
PLANTILLA DE LECCI√ìN:
Esta unidad debe cubrir el concepto central #1.
Refuerce el concepto con ejemplos y referencias.

CONCEPTO #3:
T√©cnicas de Ingenier√≠a de Prompts.
¬øCu√°les son algunas t√©cnicas b√°sicas para la ingenier√≠a de prompts?
Il√∫stralo con algunos ejercicios.
-->

## Mejores Pr√°cticas para Prompts

Ahora que sabemos c√≥mo se pueden _construir_ los prompts, podemos empezar a pensar en c√≥mo _dise√±arlos_ para reflejar las mejores pr√°cticas. Podemos verlo en dos partes: tener la _mentalidad_ correcta y aplicar las _t√©cnicas_ adecuadas.

### Mentalidad de Ingenier√≠a de Prompts

La Ingenier√≠a de Prompts es un proceso de prueba y error, as√≠ que tenga en cuenta tres factores amplios:

1. **Importa el Entendimiento del Dominio.** La precisi√≥n y relevancia de la respuesta dependen del _dominio_ en el que opera esa aplicaci√≥n o usuario. Aplique su intuici√≥n y experiencia en el dominio para **personalizar las t√©cnicas** a√∫n m√°s. Por ejemplo, defina _personalidades espec√≠ficas del dominio_ en sus prompts del sistema, o use _plantillas espec√≠ficas del dominio_ en sus prompts de usuario. Proporcione contenido secundario que refleje contextos espec√≠ficos del dominio, o use _se√±ales y ejemplos espec√≠ficos del dominio_ para guiar al modelo hacia patrones de uso conocidos.

2. **Importa el Entendimiento del Modelo.** Sabemos que los modelos son estoc√°sticos por naturaleza. Pero las implementaciones del modelo tambi√©n pueden variar en cuanto al conjunto de datos de entrenamiento que utilizan (conocimiento preentrenado), las capacidades que ofrecen (por ejemplo, v√≠a API o SDK) y el tipo de contenido para el que est√°n optimizados (p. ej., c√≥digo vs im√°genes vs texto). Entienda las fortalezas y limitaciones del modelo que est√° usando, y use ese conocimiento para _priorizar tareas_ o construir _plantillas personalizadas_ que est√©n optimizadas para las capacidades del modelo.

3. **Importa la Iteraci√≥n y Validaci√≥n.** Los modelos est√°n evolucionando r√°pidamente, al igual que las t√©cnicas para la ingenier√≠a de prompts. Como experto en el dominio, puede tener otro contexto o criterios espec√≠ficos para _su_ aplicaci√≥n que quiz√°s no apliquen a la comunidad m√°s amplia. Use herramientas y t√©cnicas de ingenier√≠a de prompts para "arrancar" la construcci√≥n inicial del prompt, luego itere y valide los resultados usando su propia intuici√≥n y experiencia en el dominio. Registre sus observaciones y cree una **base de conocimiento** (p. ej., bibliotecas de prompts) que pueda usarse como l√≠nea base para otros, permitiendo iteraciones m√°s r√°pidas en el futuro.

## Mejores Pr√°cticas Comunes

Ahora veamos las mejores pr√°cticas comunes recomendadas por los practicantes de [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) y [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Qu√©                               | Por qu√©                                                                                                                                                                                                                                             |
| :-------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Evaluar los modelos m√°s recientes | Las nuevas generaciones de modelos probablemente tienen caracter√≠sticas y calidad mejoradas, pero tambi√©n pueden generar costos m√°s altos. Eval√∫elos por impacto, luego tome decisiones de migraci√≥n.                                               |
| Separar instrucciones y contexto  | Verifique si su modelo/proveedor define _delimitadores_ para distinguir instrucciones, contenido primario y secundario m√°s claramente. Esto puede ayudar a los modelos a asignar pesos con mayor precisi√≥n a los tokens.                            |
| Ser espec√≠fico y claro            | Brinde m√°s detalles sobre el contexto, resultado, duraci√≥n, formato, estilo deseados. Esto mejorar√° tanto la calidad como la consistencia de las respuestas. Capture recetas en plantillas reutilizables.                                            |
| Ser descriptivo, usar ejemplos    | Los modelos pueden responder mejor a un enfoque de "mostrar y contar". Comience con un enfoque `zero-shot` donde da una instrucci√≥n (pero sin ejemplos) y luego pruebe `few-shot` como refinamiento, proporcionando algunos ejemplos del resultado deseado. Use analog√≠as. |
| Usar se√±ales para iniciar respuestas | Imp√∫lselo hacia un resultado deseado d√°ndole algunas palabras o frases iniciales que pueda usar como punto de partida para la respuesta.                                                                                                         |
| Repetir para reforzar             | A veces debe repetir las instrucciones al modelo. D√© instrucciones antes y despu√©s del contenido principal, use una instrucci√≥n y una se√±al, etc. Itere y valide para ver qu√© funciona.                                                            |
| El orden importa                  | El orden en que presenta la informaci√≥n al modelo puede afectar la salida, incluso en los ejemplos de aprendizaje, debido al sesgo de recencia. Pruebe diferentes opciones para ver cu√°l funciona mejor.                                              |
| Dar una ‚Äúsalida‚Äù al modelo        | Proporcione al modelo una respuesta alternativa de respaldo que pueda ofrecer si no puede completar la tarea por alguna raz√≥n. Esto puede reducir las posibilidades de respuestas falsas o inventadas.                                              |
|                                  |                                                                                                                                                                                                                                                     |

Como con cualquier mejor pr√°ctica, recuerde que _su experiencia puede variar_ seg√∫n el modelo, la tarea y el dominio. √öselas como punto de partida y realice iteraciones para encontrar lo que mejor le funcione. Reeval√∫e constantemente su proceso de ingenier√≠a de prompts a medida que aparecen nuevos modelos y herramientas, enfoc√°ndose en la escalabilidad del proceso y la calidad de las respuestas.

<!--
PLANTILLA DE LECCI√ìN:
Esta unidad debe proporcionar un desaf√≠o de c√≥digo si es aplicable

DESAF√çO:
Enlace a un Jupyter Notebook con solo comentarios de c√≥digo en las instrucciones (las secciones de c√≥digo est√°n vac√≠as).

SOLUCI√ìN:
Enlace a una copia de ese Notebook con los prompts completados y ejecutados, mostrando c√≥mo podr√≠a ser un ejemplo.
-->

## Tarea

¬°Felicidades! ¬°Llegaste al final de la lecci√≥n! Es momento de poner a prueba algunos de esos conceptos y t√©cnicas con ejemplos reales.

Para nuestra tarea, usaremos un Jupyter Notebook con ejercicios que puede completar de forma interactiva. Tambi√©n puede extender el Notebook con sus propias celdas de Markdown y c√≥digo para explorar ideas y t√©cnicas por su cuenta.

### Para comenzar, haga un fork del repo, luego

- (Recomendado) Inicie GitHub Codespaces
- (Alternativamente) Clone el repo en su dispositivo local y √∫selo con Docker Desktop
- (Alternativamente) Abra el Notebook con su entorno de ejecuci√≥n preferido.

### Despu√©s, configure sus variables de entorno

- Copie el archivo `.env.copy` en la ra√≠z del repo a `.env` y complete los valores de `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` y `AZURE_OPENAI_DEPLOYMENT`. Regrese a la secci√≥n [Learning Sandbox](../../../04-prompt-engineering-fundamentals) para aprender c√≥mo hacerlo.

### Luego, abra el Jupyter Notebook

- Seleccione el kernel de ejecuci√≥n. Si usa la opci√≥n 1 o 2, simplemente seleccione el kernel predeterminado Python 3.10.x proporcionado por el contenedor de desarrollo.

Ya est√° listo para ejecutar los ejercicios. Note que aqu√≠ no hay respuestas _correctas o incorrectas_ ‚Äî solo explorar opciones por prueba y error y construir intuici√≥n sobre lo que funciona para un modelo y dominio de aplicaci√≥n espec√≠ficos.

_Por esa raz√≥n no hay segmentos de Soluci√≥n de C√≥digo en esta lecci√≥n. En cambio, el Notebook tendr√° celdas Markdown tituladas "Mi Soluci√≥n:" que muestran un ejemplo de salida para referencia._

 <!--
PLANTILLA DE LECCI√ìN:
Envolver la secci√≥n con un resumen y recursos para aprendizaje autodirigido.
-->

## Comprobaci√≥n de conocimientos

¬øCu√°l de los siguientes es un buen prompt que sigue algunas pr√°cticas razonables?

1. Mu√©strame una imagen de un coche rojo
2. Mu√©strame una imagen de un coche rojo de marca Volvo y modelo XC90 estacionado junto a un acantilado con el sol poni√©ndose
3. Mu√©strame una imagen de un coche rojo de marca Volvo y modelo XC90

R: 2, es el mejor prompt porque proporciona detalles sobre el "qu√©" e incluye especificaciones (no cualquier coche sino una marca y modelo espec√≠ficos) y tambi√©n describe el entorno general. La 3 es la siguiente mejor porque tambi√©n contiene mucha descripci√≥n.

## üöÄ Desaf√≠o

Intente aprovechar la t√©cnica de "se√±al" con el prompt: Complete la oraci√≥n "Mu√©strame una imagen de un coche rojo de marca Volvo y ". ¬øCon qu√© responde y c√≥mo lo mejorar√≠a?

## ¬°Gran trabajo! Contin√∫e su aprendizaje

¬øQuiere aprender m√°s sobre diferentes conceptos de Ingenier√≠a de Prompts? Vaya a la [p√°gina de aprendizaje continuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar otros grandes recursos sobre este tema.

¬°Avance a la Lecci√≥n 5 donde veremos [t√©cnicas avanzadas de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso legal**:
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por la precisi√≥n, tenga en cuenta que las traducciones autom√°ticas pueden contener errores o inexactitudes. El documento original en su idioma nativo debe considerarse la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda la traducci√≥n profesional humana. No nos responsabilizamos por malentendidos o interpretaciones err√≥neas derivadas del uso de esta traducci√≥n.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->