<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b3cb38518cf4fe7714d2f5e74dfa3eb",
  "translation_date": "2025-10-03T08:09:11+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "es"
}
-->
# Fundamentos de la Ingenier√≠a de Prompts

[![Fundamentos de la Ingenier√≠a de Prompts](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.es.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introducci√≥n
Este m√≥dulo cubre conceptos y t√©cnicas esenciales para crear prompts efectivos en modelos de IA generativa. La forma en que redactes tu prompt para un LLM tambi√©n es importante. Un prompt cuidadosamente dise√±ado puede lograr una mejor calidad de respuesta. Pero, ¬øqu√© significan exactamente t√©rminos como _prompt_ e _ingenier√≠a de prompts_? ¬øY c√≥mo puedo mejorar el _input_ del prompt que env√≠o al LLM? Estas son las preguntas que intentaremos responder en este cap√≠tulo y el siguiente.

La _IA generativa_ es capaz de crear contenido nuevo (por ejemplo, texto, im√°genes, audio, c√≥digo, etc.) en respuesta a solicitudes de los usuarios. Esto se logra utilizando _Modelos de Lenguaje Extenso_ como la serie GPT ("Generative Pre-trained Transformer") de OpenAI, que est√°n entrenados para usar lenguaje natural y c√≥digo.

Los usuarios ahora pueden interactuar con estos modelos utilizando paradigmas familiares como el chat, sin necesidad de experiencia t√©cnica o formaci√≥n previa. Los modelos est√°n basados en _prompts_: los usuarios env√≠an un texto de entrada (prompt) y reciben la respuesta de la IA (completion). Luego pueden "chatear con la IA" de manera iterativa, en conversaciones de m√∫ltiples turnos, refinando su prompt hasta que la respuesta cumpla con sus expectativas.

Los "prompts" se convierten ahora en la principal _interfaz de programaci√≥n_ para aplicaciones de IA generativa, indicando a los modelos qu√© hacer e influyendo en la calidad de las respuestas generadas. La "Ingenier√≠a de Prompts" es un campo de estudio en r√°pido crecimiento que se centra en el _dise√±o y optimizaci√≥n_ de prompts para ofrecer respuestas consistentes y de calidad a escala.

## Objetivos de Aprendizaje

En esta lecci√≥n, aprenderemos qu√© es la Ingenier√≠a de Prompts, por qu√© es importante y c√≥mo podemos crear prompts m√°s efectivos para un modelo y objetivo de aplicaci√≥n espec√≠ficos. Comprenderemos conceptos clave y mejores pr√°cticas para la ingenier√≠a de prompts, y aprenderemos sobre un entorno interactivo de "sandbox" en Jupyter Notebooks donde podemos aplicar estos conceptos a ejemplos reales.

Al final de esta lecci√≥n, seremos capaces de:

1. Explicar qu√© es la ingenier√≠a de prompts y por qu√© es importante.
2. Describir los componentes de un prompt y c√≥mo se utilizan.
3. Aprender mejores pr√°cticas y t√©cnicas para la ingenier√≠a de prompts.
4. Aplicar las t√©cnicas aprendidas a ejemplos reales, utilizando un endpoint de OpenAI.

## T√©rminos Clave

Ingenier√≠a de Prompts: La pr√°ctica de dise√±ar y refinar entradas para guiar a los modelos de IA hacia la producci√≥n de resultados deseados.  
Tokenizaci√≥n: El proceso de convertir texto en unidades m√°s peque√±as, llamadas tokens, que un modelo puede entender y procesar.  
LLMs Ajustados por Instrucciones: Modelos de Lenguaje Extenso (LLMs) que han sido ajustados con instrucciones espec√≠ficas para mejorar la precisi√≥n y relevancia de sus respuestas.

## Sandbox de Aprendizaje

La ingenier√≠a de prompts es actualmente m√°s arte que ciencia. La mejor manera de mejorar nuestra intuici√≥n al respecto es _practicar m√°s_ y adoptar un enfoque de prueba y error que combine experiencia en el dominio de la aplicaci√≥n con t√©cnicas recomendadas y optimizaciones espec√≠ficas del modelo.

El Jupyter Notebook que acompa√±a esta lecci√≥n proporciona un entorno de _sandbox_ donde puedes probar lo que aprendes, ya sea mientras avanzas o como parte del desaf√≠o de c√≥digo al final. Para ejecutar los ejercicios, necesitar√°s:

1. **Una clave de API de Azure OpenAI**: el endpoint del servicio para un LLM desplegado.  
2. **Un entorno de ejecuci√≥n de Python**: en el que se pueda ejecutar el Notebook.  
3. **Variables de entorno locales**: _completa los pasos de [CONFIGURACI√ìN](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) ahora para estar listo_.  

El notebook incluye ejercicios _iniciales_, pero se te anima a agregar tus propias secciones de _Markdown_ (descripci√≥n) y _C√≥digo_ (solicitudes de prompts) para probar m√°s ejemplos o ideas, y desarrollar tu intuici√≥n para el dise√±o de prompts.

## Gu√≠a Ilustrada

¬øQuieres obtener una visi√≥n general de lo que cubre esta lecci√≥n antes de profundizar? Consulta esta gu√≠a ilustrada, que te da una idea de los temas principales tratados y los puntos clave para reflexionar en cada uno. El mapa de la lecci√≥n te lleva desde la comprensi√≥n de los conceptos y desaf√≠os b√°sicos hasta abordarlos con t√©cnicas relevantes de ingenier√≠a de prompts y mejores pr√°cticas. Ten en cuenta que la secci√≥n "T√©cnicas Avanzadas" en esta gu√≠a se refiere a contenido cubierto en el _pr√≥ximo_ cap√≠tulo de este curr√≠culo.

![Gu√≠a Ilustrada de Ingenier√≠a de Prompts](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.es.png)

## Nuestra Startup

Ahora, hablemos de c√≥mo _este tema_ se relaciona con nuestra misi√≥n de startup de [llevar la innovaci√≥n de la IA a la educaci√≥n](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplicaciones impulsadas por IA para el _aprendizaje personalizado_, as√≠ que pensemos en c√≥mo diferentes usuarios de nuestra aplicaci√≥n podr√≠an "dise√±ar" prompts:

- **Administradores** podr√≠an pedir a la IA que _analice datos curriculares para identificar brechas en la cobertura_. La IA puede resumir los resultados o visualizarlos con c√≥digo.  
- **Educadores** podr√≠an pedir a la IA que _genere un plan de lecci√≥n para una audiencia y tema espec√≠ficos_. La IA puede crear el plan personalizado en un formato especificado.  
- **Estudiantes** podr√≠an pedir a la IA que _les ense√±e una materia dif√≠cil_. La IA ahora puede guiar a los estudiantes con lecciones, pistas y ejemplos adaptados a su nivel.  

Eso es solo la punta del iceberg. Consulta [Prompts para la Educaci√≥n](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst), una biblioteca de prompts de c√≥digo abierto curada por expertos en educaci√≥n, para obtener una visi√≥n m√°s amplia de las posibilidades. _¬°Prueba algunos de esos prompts en el sandbox o usando el OpenAI Playground para ver qu√© sucede!_

<!--
PLANTILLA DE LECCI√ìN:
Esta unidad debe cubrir el concepto clave #1.
Refuerza el concepto con ejemplos y referencias.

CONCEPTO #1:
Ingenier√≠a de Prompts.
Def√≠nelo y explica por qu√© es necesario.
-->

## ¬øQu√© es la Ingenier√≠a de Prompts?

Comenzamos esta lecci√≥n definiendo **Ingenier√≠a de Prompts** como el proceso de _dise√±ar y optimizar_ entradas de texto (prompts) para ofrecer respuestas consistentes y de calidad (completions) para un objetivo de aplicaci√≥n y modelo espec√≠ficos. Podemos pensar en esto como un proceso de 2 pasos:

- _Dise√±ar_ el prompt inicial para un modelo y objetivo espec√≠ficos.  
- _Refinar_ el prompt de manera iterativa para mejorar la calidad de la respuesta.  

Este es necesariamente un proceso de prueba y error que requiere intuici√≥n y esfuerzo por parte del usuario para obtener resultados √≥ptimos. Entonces, ¬øpor qu√© es importante? Para responder a esa pregunta, primero necesitamos entender tres conceptos:

- _Tokenizaci√≥n_: c√≥mo el modelo "ve" el prompt.  
- _LLMs Base_: c√≥mo el modelo base "procesa" un prompt.  
- _LLMs Ajustados por Instrucciones_: c√≥mo el modelo ahora puede ver "tareas".  

### Tokenizaci√≥n

Un LLM ve los prompts como una _secuencia de tokens_, donde diferentes modelos (o versiones de un modelo) pueden tokenizar el mismo prompt de diferentes maneras. Dado que los LLMs est√°n entrenados en tokens (y no en texto sin procesar), la forma en que los prompts se tokenizan tiene un impacto directo en la calidad de la respuesta generada.

Para obtener una intuici√≥n sobre c√≥mo funciona la tokenizaci√≥n, prueba herramientas como el [Tokenizador de OpenAI](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) que se muestra a continuaci√≥n. Copia tu prompt y observa c√≥mo se convierte en tokens, prestando atenci√≥n a c√≥mo se manejan los caracteres de espacio y los signos de puntuaci√≥n. Ten en cuenta que este ejemplo muestra un LLM m√°s antiguo (GPT-3), por lo que probar esto con un modelo m√°s reciente puede producir un resultado diferente.

![Tokenizaci√≥n](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.es.png)

### Concepto: Modelos Base

Una vez que un prompt se tokeniza, la funci√≥n principal del ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (o modelo base) es predecir el siguiente token en esa secuencia. Dado que los LLMs est√°n entrenados con conjuntos de datos masivos de texto, tienen una buena comprensi√≥n de las relaciones estad√≠sticas entre los tokens y pueden hacer esa predicci√≥n con cierta confianza. Ten en cuenta que no entienden el _significado_ de las palabras en el prompt o token; solo ven un patr√≥n que pueden "completar" con su pr√≥xima predicci√≥n. Pueden continuar prediciendo la secuencia hasta que el usuario intervenga o se cumpla alguna condici√≥n preestablecida.

¬øQuieres ver c√≥mo funciona la completaci√≥n basada en prompts? Ingresa el prompt anterior en el [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) de Azure OpenAI Studio con la configuraci√≥n predeterminada. El sistema est√° configurado para tratar los prompts como solicitudes de informaci√≥n, por lo que deber√≠as ver una completaci√≥n que satisfaga este contexto.

Pero, ¬øqu√© pasa si el usuario quiere ver algo espec√≠fico que cumpla con ciertos criterios u objetivos de tarea? Aqu√≠ es donde entran en juego los LLMs ajustados por instrucciones.

![Completaci√≥n de Chat con LLM Base](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.es.png)

### Concepto: LLMs Ajustados por Instrucciones

Un [LLM Ajustado por Instrucciones](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) comienza con el modelo base y lo ajusta con ejemplos o pares de entrada/salida (por ejemplo, "mensajes" de m√∫ltiples turnos) que pueden contener instrucciones claras, y la respuesta de la IA intenta seguir esa instrucci√≥n.

Esto utiliza t√©cnicas como el Aprendizaje por Refuerzo con Retroalimentaci√≥n Humana (RLHF) que pueden entrenar al modelo para _seguir instrucciones_ y _aprender de la retroalimentaci√≥n_, de modo que produzca respuestas m√°s adecuadas para aplicaciones pr√°cticas y m√°s relevantes para los objetivos del usuario.

Prob√©moslo: vuelve al prompt anterior, pero ahora cambia el _mensaje del sistema_ para proporcionar la siguiente instrucci√≥n como contexto:

> _Resume el contenido que se te proporcione para un estudiante de segundo grado. Limita el resultado a un p√°rrafo con 3-5 puntos clave._

¬øVes c√≥mo el resultado ahora est√° ajustado para reflejar el objetivo y formato deseados? Un educador ahora puede usar directamente esta respuesta en sus diapositivas para esa clase.

![Completaci√≥n de Chat con LLM Ajustado por Instrucciones](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.es.png)

## ¬øPor qu√© necesitamos la Ingenier√≠a de Prompts?

Ahora que sabemos c√≥mo los prompts son procesados por los LLMs, hablemos de _por qu√©_ necesitamos la ingenier√≠a de prompts. La respuesta radica en el hecho de que los LLMs actuales presentan una serie de desaf√≠os que hacen que lograr _completaciones confiables y consistentes_ sea m√°s dif√≠cil sin dedicar esfuerzo a la construcci√≥n y optimizaci√≥n de prompts. Por ejemplo:

1. **Las respuestas del modelo son estoc√°sticas.** El _mismo prompt_ probablemente producir√° respuestas diferentes con diferentes modelos o versiones de modelos. Y puede incluso producir resultados diferentes con el _mismo modelo_ en diferentes momentos. _Las t√©cnicas de ingenier√≠a de prompts pueden ayudarnos a minimizar estas variaciones proporcionando mejores l√≠mites_.  

1. **Los modelos pueden fabricar respuestas.** Los modelos est√°n preentrenados con conjuntos de datos _grandes pero finitos_, lo que significa que carecen de conocimiento sobre conceptos fuera de ese alcance de entrenamiento. Como resultado, pueden producir completaciones que son inexactas, imaginarias o directamente contradictorias a hechos conocidos. _Las t√©cnicas de ingenier√≠a de prompts ayudan a los usuarios a identificar y mitigar estas fabricaciones, por ejemplo, pidiendo a la IA citas o razonamientos_.  

1. **Las capacidades de los modelos var√≠an.** Los modelos m√°s nuevos o generaciones de modelos tendr√°n capacidades m√°s ricas, pero tambi√©n traer√°n peculiaridades √∫nicas y compensaciones en costo y complejidad. _La ingenier√≠a de prompts puede ayudarnos a desarrollar mejores pr√°cticas y flujos de trabajo que abstraigan las diferencias y se adapten a los requisitos espec√≠ficos del modelo de manera escalable y fluida_.  

Veamos esto en acci√≥n en el OpenAI o Azure OpenAI Playground:

- Usa el mismo prompt con diferentes despliegues de LLM (por ejemplo, OpenAI, Azure OpenAI, Hugging Face): ¬ønotaste las variaciones?  
- Usa el mismo prompt repetidamente con el _mismo_ despliegue de LLM (por ejemplo, el playground de Azure OpenAI): ¬øc√≥mo difer√≠an estas variaciones?  

### Ejemplo de Fabricaciones

En este curso, usamos el t√©rmino **"fabricaci√≥n"** para referirnos al fen√≥meno en el que los LLMs a veces generan informaci√≥n incorrecta debido a limitaciones en su entrenamiento u otras restricciones. Tambi√©n puedes haber escuchado este t√©rmino como _"alucinaciones"_ en art√≠culos populares o trabajos de investigaci√≥n. Sin embargo, recomendamos encarecidamente usar _"fabricaci√≥n"_ como t√©rmino para no atribuir accidentalmente un rasgo humano a un resultado impulsado por una m√°quina. Esto tambi√©n refuerza las [directrices de IA Responsable](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) desde una perspectiva terminol√≥gica, eliminando t√©rminos que tambi√©n podr√≠an considerarse ofensivos o no inclusivos en algunos contextos.

¬øQuieres tener una idea de c√≥mo funcionan las fabricaciones? Piensa en un prompt que instruya a la IA a generar contenido sobre un tema inexistente (para asegurarte de que no se encuentre en el conjunto de datos de entrenamiento). Por ejemplo, intent√© este prompt:

> **Prompt:** genera un plan de lecci√≥n sobre la Guerra Marciana de 2076.
Una b√∫squeda en la web me mostr√≥ que existen relatos ficticios (por ejemplo, series de televisi√≥n o libros) sobre guerras marcianas, pero ninguno ambientado en 2076. El sentido com√∫n tambi√©n nos dice que 2076 est√° _en el futuro_ y, por lo tanto, no puede estar asociado con un evento real.

Entonces, ¬øqu√© sucede cuando probamos este mensaje con diferentes proveedores de modelos de lenguaje?

> **Respuesta 1**: OpenAI Playground (GPT-35)

![Respuesta 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.es.png)

> **Respuesta 2**: Azure OpenAI Playground (GPT-35)

![Respuesta 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.es.png)

> **Respuesta 3**: Hugging Face Chat Playground (LLama-2)

![Respuesta 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.es.png)

Como era de esperar, cada modelo (o versi√≥n del modelo) genera respuestas ligeramente diferentes debido al comportamiento estoc√°stico y las variaciones en las capacidades del modelo. Por ejemplo, un modelo se dirige a una audiencia de octavo grado, mientras que otro asume un estudiante de secundaria. Sin embargo, los tres modelos generaron respuestas que podr√≠an convencer a un usuario desinformado de que el evento fue real.

T√©cnicas de ingenier√≠a de mensajes como _metaprompting_ y _configuraci√≥n de temperatura_ pueden reducir las fabricaciones del modelo hasta cierto punto. Nuevas arquitecturas de ingenier√≠a de mensajes tambi√©n incorporan herramientas y t√©cnicas nuevas de manera fluida en el flujo del mensaje, para mitigar o reducir algunos de estos efectos.

## Estudio de Caso: GitHub Copilot

Concluyamos esta secci√≥n obteniendo una idea de c√≥mo se utiliza la ingenier√≠a de mensajes en soluciones del mundo real, analizando un estudio de caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot es tu "programador asistente de IA": convierte mensajes de texto en sugerencias de c√≥digo y est√° integrado en tu entorno de desarrollo (por ejemplo, Visual Studio Code) para una experiencia de usuario fluida. Como se documenta en la serie de blogs a continuaci√≥n, la versi√≥n m√°s temprana se bas√≥ en el modelo OpenAI Codex, y los ingenieros r√°pidamente se dieron cuenta de la necesidad de ajustar el modelo y desarrollar mejores t√©cnicas de ingenier√≠a de mensajes para mejorar la calidad del c√≥digo. En julio, [presentaron un modelo de IA mejorado que va m√°s all√° de Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugerencias a√∫n m√°s r√°pidas.

Lee las publicaciones en orden para seguir su proceso de aprendizaje.

- **Mayo 2023** | [GitHub Copilot est√° mejorando en la comprensi√≥n de tu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mayo 2023** | [Dentro de GitHub: Trabajando con los modelos de lenguaje detr√°s de GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Junio 2023** | [C√≥mo escribir mejores mensajes para GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Julio 2023** | [GitHub Copilot va m√°s all√° de Codex con un modelo de IA mejorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Julio 2023** | [Gu√≠a para desarrolladores sobre ingenier√≠a de mensajes y modelos de lenguaje](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Septiembre 2023** | [C√≥mo construir una aplicaci√≥n empresarial con modelos de lenguaje: Lecciones de GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Tambi√©n puedes explorar su [blog de ingenier√≠a](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para m√°s publicaciones como [esta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), que muestra c√≥mo estos modelos y t√©cnicas se _aplican_ para impulsar aplicaciones del mundo real.

---

## Construcci√≥n de Mensajes

Ya hemos visto por qu√© la ingenier√≠a de mensajes es importante; ahora entendamos c√≥mo se _construyen_ los mensajes para poder evaluar diferentes t√©cnicas que permitan un dise√±o m√°s efectivo.

### Mensaje B√°sico

Comencemos con el mensaje b√°sico: una entrada de texto enviada al modelo sin ning√∫n otro contexto. Aqu√≠ hay un ejemplo: cuando enviamos las primeras palabras del himno nacional de los Estados Unidos a la [API de Completion de OpenAI](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), responde instant√°neamente _completando_ con las siguientes l√≠neas, ilustrando el comportamiento b√°sico de predicci√≥n.

| Mensaje (Entrada) | Respuesta (Salida)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Parece que est√°s comenzando la letra de "The Star-Spangled Banner", el himno nacional de los Estados Unidos. La letra completa es...      |

### Mensaje Complejo

Ahora agreguemos contexto e instrucciones a ese mensaje b√°sico. La [API de Chat Completion](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir un mensaje complejo como una colecci√≥n de _mensajes_ con:

- Pares de entrada/salida que reflejan la entrada del _usuario_ y la respuesta del _asistente_.
- Mensaje del sistema que establece el contexto para el comportamiento o personalidad del asistente.

La solicitud ahora tiene la forma que se muestra a continuaci√≥n, donde la _tokenizaci√≥n_ captura de manera efectiva informaci√≥n relevante del contexto y la conversaci√≥n. Cambiar el contexto del sistema puede ser tan impactante en la calidad de las respuestas como las entradas proporcionadas por el usuario.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```


### Mensaje de Instrucci√≥n

En los ejemplos anteriores, el mensaje del usuario era una consulta de texto simple que puede interpretarse como una solicitud de informaci√≥n. Con los mensajes de _instrucci√≥n_, podemos usar ese texto para especificar una tarea con m√°s detalle, proporcionando una mejor orientaci√≥n a la IA. Aqu√≠ hay un ejemplo:

| Mensaje (Entrada)                                                                                                                                                                                                                         | Respuesta (Salida)                                                                                                        | Tipo de Instrucci√≥n |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Escribe una descripci√≥n de la Guerra Civil                                                                                                                                                                                                   | _devuelve un p√°rrafo simple_                                                                                              | Simple              |
| Escribe una descripci√≥n de la Guerra Civil. Proporciona fechas y eventos clave y describe su importancia                                                                                                                                     | _devuelve un p√°rrafo seguido de una lista de fechas clave con descripciones_                                             | Complejo             |
| Escribe una descripci√≥n de la Guerra Civil en un p√°rrafo. Proporciona 3 puntos clave con fechas y su importancia. Proporciona 3 puntos m√°s con figuras hist√≥ricas clave y sus contribuciones. Devuelve la salida como un archivo JSON | _devuelve detalles m√°s extensos en un cuadro de texto, formateados como JSON que puedes copiar y pegar en un archivo para validar seg√∫n sea necesario_ | Complejo. Formateado. |

## Contenido Principal

En los ejemplos anteriores, el mensaje segu√≠a siendo bastante abierto, permitiendo que el modelo de lenguaje decidiera qu√© parte de su conjunto de datos preentrenado era relevante. Con el patr√≥n de dise√±o de _contenido principal_, el texto de entrada se divide en dos partes:

- una instrucci√≥n (acci√≥n)
- contenido relevante (que influye en la acci√≥n)

Aqu√≠ hay un ejemplo donde la instrucci√≥n es "resume esto en 2 oraciones".

| Mensaje (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Respuesta (Salida)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno y ha sido conocido por civilizaciones antiguas desde antes de la historia registrada. Lleva el nombre del dios romano J√∫piter. Cuando se observa desde la Tierra, J√∫piter puede ser lo suficientemente brillante como para que su luz reflejada proyecte sombras visibles, y es, en promedio, el tercer objeto natural m√°s brillante en el cielo nocturno despu√©s de la Luna y Venus. <br/> **Resume esto en 2 oraciones cortas** | J√∫piter, el quinto planeta desde el Sol, es el m√°s grande del Sistema Solar y es conocido por ser uno de los objetos m√°s brillantes en el cielo nocturno. Nombrado en honor al dios romano J√∫piter, es un gigante gaseoso cuya masa es dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. |

El segmento de contenido principal puede usarse de varias maneras para impulsar instrucciones m√°s efectivas:

- **Ejemplos**: en lugar de decirle al modelo qu√© hacer con una instrucci√≥n expl√≠cita, dale ejemplos de lo que debe hacer y deja que infiera el patr√≥n.
- **Indicadores**: sigue la instrucci√≥n con un "indicador" que prepara la respuesta, guiando al modelo hacia respuestas m√°s relevantes.
- **Plantillas**: estas son "recetas" repetibles para mensajes con marcadores de posici√≥n (variables) que pueden personalizarse con datos para casos de uso espec√≠ficos.

Exploremos estas t√©cnicas en acci√≥n.

### Uso de Ejemplos

Este es un enfoque donde utilizas el contenido principal para "alimentar al modelo" con algunos ejemplos del resultado deseado para una instrucci√≥n dada y dejas que infiera el patr√≥n para el resultado deseado. Seg√∫n la cantidad de ejemplos proporcionados, podemos tener mensajes de cero ejemplos, un ejemplo, pocos ejemplos, etc.

El mensaje ahora consta de tres componentes:

- Una descripci√≥n de la tarea
- Algunos ejemplos del resultado deseado
- El inicio de un nuevo ejemplo (que se convierte en una descripci√≥n impl√≠cita de la tarea)

| Tipo de Aprendizaje | Mensaje (Entrada)                                                                                                                                        | Respuesta (Salida)         |
| :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Cero ejemplos     | "The Sun is Shining". Traducir al espa√±ol                                                                                                            | "El Sol est√° brillando".    |
| Un ejemplo      | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Pocos ejemplos      | El jugador corri√≥ las bases => B√©isbol <br/> El jugador hizo un ace => Tenis <br/> El jugador hizo un seis => Cricket <br/> El jugador hizo un mate => | Baloncesto                  |
|               |                                                                                                                                                       |                             |

Observa c√≥mo tuvimos que proporcionar una instrucci√≥n expl√≠cita ("Traducir al espa√±ol") en el ejemplo de cero ejemplos, pero se infiere en el ejemplo de un ejemplo. El ejemplo de pocos ejemplos muestra c√≥mo agregar m√°s ejemplos permite que los modelos hagan inferencias m√°s precisas sin instrucciones adicionales.

### Indicadores en el Mensaje

Otra t√©cnica para usar contenido principal es proporcionar _indicadores_ en lugar de ejemplos. En este caso, estamos dando al modelo un empuj√≥n en la direcci√≥n correcta _comenzando_ con un fragmento que refleja el formato de respuesta deseado. El modelo luego "toma el indicador" para continuar en esa l√≠nea.

| N√∫mero de Indicadores | Mensaje (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Respuesta (Salida)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno y ha sido conocido por civilizaciones antiguas desde antes de la historia registrada. <br/>**Resume Esto**                                       | J√∫piter es el planeta m√°s grande de nuestro Sistema Solar y el quinto desde el Sol. Es un gigante gaseoso con una masa 1/1000 de la del Sol, pero m√°s pesado que todos los dem√°s planetas juntos. Las civilizaciones antiguas han conocido J√∫piter durante mucho tiempo, y es f√°cilmente visible en el cielo nocturno. |
| 1              | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Res√∫melo** <br/> Lo que aprendimos es que J√∫piter | es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas combinados. Es f√°cilmente visible a simple vista y ha sido conocido desde tiempos antiguos.                        |
| 2              | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil√©sima parte de la del Sol, pero dos veces y media la de todos los dem√°s planetas del Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Res√∫melo** <br/> Los 3 datos principales que aprendimos:         | 1. J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. <br/> 2. Es un gigante gaseoso con una masa mil√©sima parte de la del Sol...<br/> 3. J√∫piter ha sido visible a simple vista desde tiempos antiguos ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Plantillas de Prompts

Una plantilla de prompt es una _receta predefinida para un prompt_ que puede almacenarse y reutilizarse seg√∫n sea necesario, para ofrecer experiencias de usuario m√°s consistentes a gran escala. En su forma m√°s simple, es simplemente una colecci√≥n de ejemplos de prompts como [este de OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que proporciona tanto los componentes interactivos del prompt (mensajes de usuario y sistema) como el formato de solicitud impulsado por API, para apoyar la reutilizaci√≥n.

En su forma m√°s compleja, como [este ejemplo de LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), contiene _marcadores de posici√≥n_ que pueden reemplazarse con datos de diversas fuentes (entrada del usuario, contexto del sistema, fuentes de datos externas, etc.) para generar un prompt din√°micamente. Esto nos permite crear una biblioteca de prompts reutilizables que pueden usarse para ofrecer experiencias de usuario consistentes **program√°ticamente** a gran escala.

Finalmente, el verdadero valor de las plantillas radica en la capacidad de crear y publicar _bibliotecas de prompts_ para dominios de aplicaci√≥n verticales, donde la plantilla de prompt ahora est√° _optimizada_ para reflejar contextos o ejemplos espec√≠ficos de la aplicaci√≥n que hacen que las respuestas sean m√°s relevantes y precisas para la audiencia objetivo. El repositorio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) es un gran ejemplo de este enfoque, curando una biblioteca de prompts para el √°mbito educativo con √©nfasis en objetivos clave como planificaci√≥n de lecciones, dise√±o curricular, tutor√≠a estudiantil, etc.

## Contenido de Apoyo

Si pensamos en la construcci√≥n de prompts como una instrucci√≥n (tarea) y un objetivo (contenido principal), entonces el _contenido secundario_ es como contexto adicional que proporcionamos para **influir en el resultado de alguna manera**. Podr√≠a ser par√°metros de ajuste, instrucciones de formato, taxonom√≠as de temas, etc., que pueden ayudar al modelo a _adaptar_ su respuesta para cumplir con los objetivos o expectativas del usuario.

Por ejemplo: Dado un cat√°logo de cursos con metadatos extensos (nombre, descripci√≥n, nivel, etiquetas de metadatos, instructor, etc.) sobre todos los cursos disponibles en el curr√≠culo:

- podemos definir una instrucci√≥n para "resumir el cat√°logo de cursos para el oto√±o de 2023"
- podemos usar el contenido principal para proporcionar algunos ejemplos del resultado deseado
- podemos usar el contenido secundario para identificar las 5 "etiquetas" principales de inter√©s.

Ahora, el modelo puede proporcionar un resumen en el formato mostrado por los ejemplos dados, pero si un resultado tiene m√∫ltiples etiquetas, puede priorizar las 5 etiquetas identificadas en el contenido secundario.

---

<!--
PLANTILLA DE LECCI√ìN:
Esta unidad debe cubrir el concepto principal #1.
Refuerza el concepto con ejemplos y referencias.

CONCEPTO #3:
T√©cnicas de Ingenier√≠a de Prompts.
¬øCu√°les son algunas t√©cnicas b√°sicas para la ingenier√≠a de prompts?
Il√∫stralo con algunos ejercicios.
-->

## Mejores Pr√°cticas para Prompts

Ahora que sabemos c√≥mo se pueden _construir_ los prompts, podemos empezar a pensar en c√≥mo _dise√±arlos_ para reflejar mejores pr√°cticas. Podemos pensar en esto en dos partes: tener la _mentalidad_ adecuada y aplicar las _t√©cnicas_ correctas.

### Mentalidad para la Ingenier√≠a de Prompts

La Ingenier√≠a de Prompts es un proceso de prueba y error, as√≠ que ten en cuenta tres factores generales:

1. **El conocimiento del dominio importa.** La precisi√≥n y relevancia de la respuesta es una funci√≥n del _dominio_ en el que opera esa aplicaci√≥n o usuario. Aplica tu intuici√≥n y experiencia en el dominio para **personalizar t√©cnicas** a√∫n m√°s. Por ejemplo, define _personalidades espec√≠ficas del dominio_ en tus prompts del sistema, o utiliza _plantillas espec√≠ficas del dominio_ en tus prompts de usuario. Proporciona contenido secundario que refleje contextos espec√≠ficos del dominio, o utiliza _pistas y ejemplos espec√≠ficos del dominio_ para guiar al modelo hacia patrones de uso familiares.

2. **El conocimiento del modelo importa.** Sabemos que los modelos son estoc√°sticos por naturaleza. Pero las implementaciones de los modelos tambi√©n pueden variar en t√©rminos del conjunto de datos de entrenamiento que utilizan (conocimiento preentrenado), las capacidades que proporcionan (por ejemplo, a trav√©s de API o SDK) y el tipo de contenido para el que est√°n optimizados (por ejemplo, c√≥digo vs. im√°genes vs. texto). Comprende las fortalezas y limitaciones del modelo que est√°s utilizando y usa ese conocimiento para _priorizar tareas_ o construir _plantillas personalizadas_ optimizadas para las capacidades del modelo.

3. **La iteraci√≥n y validaci√≥n importan.** Los modelos est√°n evolucionando r√°pidamente, al igual que las t√©cnicas para la ingenier√≠a de prompts. Como experto en el dominio, puedes tener otros contextos o criterios espec√≠ficos de _tu_ aplicaci√≥n que pueden no aplicarse a la comunidad en general. Utiliza herramientas y t√©cnicas de ingenier√≠a de prompts para "dar inicio" a la construcci√≥n de prompts, luego itera y valida los resultados utilizando tu propia intuici√≥n y experiencia en el dominio. Registra tus ideas y crea una **base de conocimiento** (por ejemplo, bibliotecas de prompts) que puedan usarse como una nueva l√≠nea base por otros, para iteraciones m√°s r√°pidas en el futuro.

## Mejores Pr√°cticas

Ahora veamos las mejores pr√°cticas comunes recomendadas por [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) y los practicantes de [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Qu√©                               | Por qu√©                                                                                                                                                                                                                                               |
| :-------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Eval√∫a los modelos m√°s recientes. | Las nuevas generaciones de modelos probablemente tengan caracter√≠sticas y calidad mejoradas, pero tambi√©n pueden implicar costos m√°s altos. Eval√∫alos para medir el impacto y luego toma decisiones de migraci√≥n.                                        |
| Separa instrucciones y contexto   | Verifica si tu modelo/proveedor define _delimitadores_ para distinguir instrucciones, contenido principal y contenido secundario m√°s claramente. Esto puede ayudar a los modelos a asignar pesos m√°s precisos a los tokens.                             |
| S√© espec√≠fico y claro             | Da m√°s detalles sobre el contexto deseado, el resultado, la longitud, el formato, el estilo, etc. Esto mejorar√° tanto la calidad como la consistencia de las respuestas. Captura recetas en plantillas reutilizables.                                  |
| S√© descriptivo, usa ejemplos      | Los modelos pueden responder mejor a un enfoque de "mostrar y contar". Comienza con un enfoque `zero-shot` donde le das una instrucci√≥n (pero sin ejemplos), luego prueba `few-shot` como refinamiento, proporcionando algunos ejemplos del resultado deseado. Usa analog√≠as. |
| Usa pistas para iniciar completaciones | Gu√≠alo hacia un resultado deseado d√°ndole algunas palabras o frases iniciales que pueda usar como punto de partida para la respuesta.                                                                                                               |
| Repite                            | A veces puede ser necesario repetir las instrucciones al modelo. Da instrucciones antes y despu√©s de tu contenido principal, usa una instrucci√≥n y una pista, etc. Itera y valida para ver qu√© funciona.                                              |
| El orden importa                  | El orden en que presentas la informaci√≥n al modelo puede impactar el resultado, incluso en los ejemplos de aprendizaje, gracias al sesgo de recencia. Prueba diferentes opciones para ver qu√© funciona mejor.                                           |
| Dale al modelo una "salida"       | Proporciona al modelo una respuesta de _respaldo_ que pueda dar si no puede completar la tarea por alguna raz√≥n. Esto puede reducir las posibilidades de que los modelos generen respuestas falsas o fabricadas.                                       |
|                                   |                                                                                                                                                                                                                                                       |

Como con cualquier mejor pr√°ctica, recuerda que _tu experiencia puede variar_ seg√∫n el modelo, la tarea y el dominio. Usa estas como punto de partida e itera para encontrar lo que funciona mejor para ti. Reeval√∫a constantemente tu proceso de ingenier√≠a de prompts a medida que nuevos modelos y herramientas est√©n disponibles, con un enfoque en la escalabilidad del proceso y la calidad de las respuestas.

<!--
PLANTILLA DE LECCI√ìN:
Esta unidad debe proporcionar un desaf√≠o de c√≥digo si aplica.

DESAF√çO:
Enlace a un Jupyter Notebook con solo los comentarios en las instrucciones (las secciones de c√≥digo est√°n vac√≠as).

SOLUCI√ìN:
Enlace a una copia de ese Notebook con los prompts completados y ejecutados, mostrando un ejemplo.
-->

## Tarea

¬°Felicidades! ¬°Llegaste al final de la lecci√≥n! Es hora de poner a prueba algunos de esos conceptos y t√©cnicas con ejemplos reales.

Para nuestra tarea, utilizaremos un Jupyter Notebook con ejercicios que puedes completar de manera interactiva. Tambi√©n puedes extender el Notebook con tus propias celdas de Markdown y C√≥digo para explorar ideas y t√©cnicas por tu cuenta.

### Para comenzar, haz un fork del repositorio, luego

- (Recomendado) Lanza GitHub Codespaces
- (Alternativamente) Clona el repositorio en tu dispositivo local y √∫salo con Docker Desktop
- (Alternativamente) Abre el Notebook con tu entorno de ejecuci√≥n de Notebook preferido.

### Luego, configura tus variables de entorno

- Copia el archivo `.env.copy` en la ra√≠z del repositorio a `.env` y completa los valores de `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` y `AZURE_OPENAI_DEPLOYMENT`. Regresa a la [secci√≥n de Sandbox de Aprendizaje](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) para aprender c√≥mo hacerlo.

### Luego, abre el Jupyter Notebook

- Selecciona el kernel de ejecuci√≥n. Si usas las opciones 1 o 2, simplemente selecciona el kernel predeterminado de Python 3.10.x proporcionado por el contenedor de desarrollo.

Est√°s listo para ejecutar los ejercicios. Ten en cuenta que aqu√≠ no hay respuestas _correctas o incorrectas_, solo se trata de explorar opciones mediante prueba y error y construir intuici√≥n sobre lo que funciona para un modelo y dominio de aplicaci√≥n dado.

_Por esta raz√≥n, no hay segmentos de Soluci√≥n de C√≥digo en esta lecci√≥n. En cambio, el Notebook tendr√° celdas de Markdown tituladas "Mi Soluci√≥n:" que muestran un ejemplo de salida como referencia._

 <!--
PLANTILLA DE LECCI√ìN:
Cierra la secci√≥n con un resumen y recursos para aprendizaje autodirigido.
-->

## Verificaci√≥n de conocimiento

¬øCu√°l de las siguientes es un buen prompt siguiendo algunas pr√°cticas razonables?

1. Mu√©strame una imagen de un coche rojo
2. Mu√©strame una imagen de un coche rojo de la marca Volvo y modelo XC90 estacionado junto a un acantilado con el sol poni√©ndose
3. Mu√©strame una imagen de un coche rojo de la marca Volvo y modelo XC90

R: 2, es el mejor prompt ya que proporciona detalles sobre "qu√©" y entra en especificaciones (no cualquier coche, sino una marca y modelo espec√≠ficos) y tambi√©n describe el entorno general. 3 es el siguiente mejor ya que tambi√©n contiene mucha descripci√≥n.

## üöÄ Desaf√≠o

Intenta aprovechar la t√©cnica de "pista" con el prompt: Completa la frase "Mu√©strame una imagen de un coche rojo de la marca Volvo y ". ¬øQu√© responde, y c√≥mo lo mejorar√≠as?

## ¬°Buen trabajo! Contin√∫a tu aprendizaje

¬øQuieres aprender m√°s sobre diferentes conceptos de Ingenier√≠a de Prompts? Ve a la [p√°gina de aprendizaje continuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar otros recursos excelentes sobre este tema.

Dir√≠gete a la Lecci√≥n 5 donde veremos [t√©cnicas avanzadas de prompts](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst).

---

**Descargo de responsabilidad**:  
Este documento ha sido traducido utilizando el servicio de traducci√≥n autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Aunque nos esforzamos por garantizar la precisi√≥n, tenga en cuenta que las traducciones automatizadas pueden contener errores o imprecisiones. El documento original en su idioma nativo debe considerarse como la fuente autorizada. Para informaci√≥n cr√≠tica, se recomienda una traducci√≥n profesional realizada por humanos. No nos hacemos responsables de malentendidos o interpretaciones err√≥neas que puedan surgir del uso de esta traducci√≥n.