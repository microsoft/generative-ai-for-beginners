<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a8b2d4bb727c877ebf9edff8623d16b9",
  "translation_date": "2025-09-06T10:24:24+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "bg"
}
-->
[![Open Source Models](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.bg.png)](https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst)

## Въведение

Светът на отворените LLM модели е вълнуващ и постоянно се развива. Този урок има за цел да предостави задълбочен поглед върху отворените модели. Ако търсите информация за това как собственическите модели се сравняват с отворените модели, посетете урока ["Изследване и сравнение на различни LLM модели"](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst). Този урок също така ще разгледа темата за фина настройка, но по-подробно обяснение може да бъде намерено в урока ["Фина настройка на LLM модели"](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst).

## Цели на обучението

- Придобиване на разбиране за отворените модели
- Разбиране на предимствата от работата с отворени модели
- Изследване на наличните отворени модели в Hugging Face и Azure AI Studio

## Какво представляват отворените модели?

Отвореният софтуер играе ключова роля в развитието на технологиите в различни области. Инициативата за отворен код (OSI) е дефинирала [10 критерия за софтуер](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst), за да бъде класифициран като отворен код. Изходният код трябва да бъде споделен открито под лиценз, одобрен от OSI.

Докато разработването на LLM модели има сходни елементи с разработването на софтуер, процесът не е напълно идентичен. Това предизвика много дискусии в общността относно дефиницията на отворен код в контекста на LLM моделите. За да бъде един модел съобразен с традиционната дефиниция на отворен код, следната информация трябва да бъде публично достъпна:

- Данните, използвани за обучение на модела.
- Пълните тегла на модела като част от обучението.
- Кодът за оценка.
- Кодът за фина настройка.
- Пълните тегла на модела и метриките за обучение.

В момента има само няколко модела, които отговарят на тези критерии. [OLMo моделът, създаден от Allen Institute for Artificial Intelligence (AllenAI)](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst) е един от тях.

За целите на този урок, ще наричаме моделите "отворени модели", тъй като те може да не отговарят на горните критерии към момента на писане.

## Предимства на отворените модели

**Висока персонализация** - Тъй като отворените модели се публикуват с подробна информация за обучението, изследователите и разработчиците могат да модифицират вътрешната структура на модела. Това позволява създаването на силно специализирани модели, които са фино настроени за конкретна задача или област на изследване. Някои примери за това са генериране на код, математически операции и биология.

**Цена** - Цената на токен за използване и внедряване на тези модели е по-ниска от тази на собственическите модели. Когато изграждате приложения за генеративен AI, трябва да се разгледа съотношението между производителност и цена при работа с тези модели за вашия случай на употреба.

![Model Cost](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.bg.png)  
Източник: Artificial Analysis

**Гъвкавост** - Работата с отворени модели ви позволява да бъдете гъвкави по отношение на използването на различни модели или комбинирането им. Пример за това е [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst), където потребителят може директно да избере модела, който се използва в потребителския интерфейс:

![Choose Model](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.bg.png)

## Изследване на различни отворени модели

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), разработен от Meta, е отворен модел, оптимизиран за приложения, базирани на чат. Това се дължи на метода му за фина настройка, който включва голямо количество диалог и обратна връзка от хора. С този метод моделът генерира повече резултати, които са съобразени с очакванията на хората, което осигурява по-добро потребителско изживяване.

Някои примери за фино настроени версии на Llama включват [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst), който се специализира в японски език, и [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), който е подобрена версия на базовия модел.

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) е отворен модел с акцент върху висока производителност и ефективност. Той използва подхода Mixture-of-Experts, който комбинира група от специализирани експертни модели в една система, където в зависимост от входа се избират определени модели за използване. Това прави изчисленията по-ефективни, тъй като моделите се занимават само с входовете, в които са специализирани.

Някои примери за фино настроени версии на Mistral включват [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst), който е фокусиран върху медицинската област, и [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), който извършва математически изчисления.

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) е LLM, създаден от Института за технологични иновации (**TII**). Falcon-40B е обучен с 40 милиарда параметри, което показва, че се представя по-добре от GPT-3 с по-малък бюджет за изчисления. Това се дължи на използването на алгоритъма FlashAttention и multiquery attention, които намаляват изискванията за памет по време на извеждане. С намаленото време за извеждане Falcon-40B е подходящ за приложения за чат.

Някои примери за фино настроени версии на Falcon са [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst), асистент, базиран на отворени модели, и [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), който предоставя по-висока производителност от базовия модел.

## Как да изберем

Няма универсален отговор за избора на отворен модел. Добро начало е използването на функцията за филтриране по задачи в Azure AI Studio. Това ще ви помогне да разберете какви типове задачи моделът е бил обучен да изпълнява. Hugging Face също поддържа класация на LLM модели, която показва най-добре представящите се модели според определени метрики.

Когато искате да сравните LLM модели от различни типове, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) е друг отличен ресурс:

![Model Quality](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.bg.png)  
Източник: Artificial Analysis

Ако работите върху конкретен случай на употреба, търсенето на фино настроени версии, които са фокусирани върху същата област, може да бъде ефективно. Експериментирането с множество отворени модели, за да видите как се представят според вашите и очакванията на потребителите, е друга добра практика.

## Следващи стъпки

Най-добрата част от отворените модели е, че можете да започнете да работите с тях доста бързо. Разгледайте [Azure AI Foundry Model Catalog](https://ai.azure.com?WT.mc_id=academic-105485-koreyst), който включва специфична колекция от Hugging Face с модели, които обсъдихме тук.

## Обучението не спира тук, продължете пътешествието

След като завършите този урок, разгледайте нашата [колекция за обучение по генеративен AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), за да продължите да развивате знанията си за генеративен AI!

---

**Отказ от отговорност**:  
Този документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за недоразумения или погрешни интерпретации, произтичащи от използването на този превод.