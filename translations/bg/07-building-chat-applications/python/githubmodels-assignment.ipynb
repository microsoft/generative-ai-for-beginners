{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Глава 7: Създаване на чат приложения\n",
    "## Бърз старт с Github Models API\n",
    "\n",
    "Този тетрадка е адаптирана от [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), която включва тетрадки за достъп до услугите на [Azure OpenAI](notebook-azure-openai.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Общ преглед  \n",
    "„Големите езикови модели са функции, които преобразуват текст в текст. Когато получат входен низ от текст, големият езиков модел се опитва да предвиди какъв текст ще последва“(1). Този „бърз старт“ наръчник ще запознае потребителите с основните концепции на LLM, основните изисквания за работа с AML, кратко въведение в дизайна на подсказки и няколко кратки примера за различни приложения.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Съдържание\n",
    "\n",
    "[Общ преглед](../../../../07-building-chat-applications/python)  \n",
    "[Как да използвате OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[1. Създаване на вашия OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[2. Инсталация](../../../../07-building-chat-applications/python)  \n",
    "[3. Данни за достъп](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Примери за употреба](../../../../07-building-chat-applications/python)  \n",
    "[1. Обобщаване на текст](../../../../07-building-chat-applications/python)  \n",
    "[2. Класифициране на текст](../../../../07-building-chat-applications/python)  \n",
    "[3. Генериране на нови имена на продукти](../../../../07-building-chat-applications/python)  \n",
    "[4. Фино настройване на класификатор](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Референции](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Създайте първия си prompt  \n",
    "Това кратко упражнение ще ви даде основни познания за подаване на prompts към модел в Github Models за проста задача „обобщение“.\n",
    "\n",
    "\n",
    "**Стъпки**:  \n",
    "1. Инсталирайте библиотеката `azure-ai-inference` във вашата python среда, ако все още не сте го направили.  \n",
    "2. Заредете стандартните помощни библиотеки и настройте Github Models идентификационни данни.  \n",
    "3. Изберете модел за вашата задача  \n",
    "4. Създайте прост prompt за модела  \n",
    "5. Изпратете заявката си към API-то на модела!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Инсталирайте `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Импортирайте помощни библиотеки и създайте идентификационни данни\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Откриване на подходящия модел  \n",
    "Моделите GPT-3.5-turbo или GPT-4 могат да разбират и генерират естествен език.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Дизайн на подканите  \n",
    "\n",
    "„Магията на големите езикови модели е, че като се обучават да минимизират грешката при предсказване върху огромни количества текст, моделите в крайна сметка научават концепции, които са полезни за тези предсказвания. Например, те научават концепции като“(1):\n",
    "\n",
    "* как се пише правилно\n",
    "* как работи граматиката\n",
    "* как да перифразират\n",
    "* как да отговарят на въпроси\n",
    "* как да водят разговор\n",
    "* как да пишат на много езици\n",
    "* как да програмират\n",
    "* и др.\n",
    "\n",
    "#### Как да управляваме голям езиков модел  \n",
    "„От всички входове към голям езиков модел, най-голямо влияние има текстовата подканa(1).\n",
    "\n",
    "Големите езикови модели могат да бъдат подканени да генерират изход по няколко начина:\n",
    "\n",
    "Инструкция: Кажете на модела какво искате\n",
    "Довършване: Подтикнете модела да довърши началото на това, което искате\n",
    "Демонстрация: Покажете на модела какво искате, като използвате:\n",
    "Няколко примера в подканата\n",
    "Стотици или хиляди примери в тренировъчен набор за фино настройване“\n",
    "\n",
    "\n",
    "\n",
    "#### Има три основни насоки за създаване на подканa:\n",
    "\n",
    "**Показвайте и обяснявайте**. Направете ясно какво искате – чрез инструкции, примери или комбинация от двете. Ако искате моделът да подреди списък по азбучен ред или да класифицира абзац по настроение, покажете му, че това очаквате.\n",
    "\n",
    "**Осигурете качествени данни**. Ако се опитвате да създадете класификатор или да накарате модела да следва определен шаблон, уверете се, че има достатъчно примери. Прегледайте внимателно примерите си – моделът обикновено е достатъчно умен да разпознае елементарни правописни грешки и пак да ви даде отговор, но може и да приеме, че това е нарочно, което да повлияе на резултата.\n",
    "\n",
    "**Проверете настройките си.** Настройките temperature и top_p контролират доколко детерминиран е моделът при генериране на отговор. Ако искате отговор, при който има само един правилен вариант, задайте ги по-ниски. Ако търсите по-разнообразни отговори, може да ги увеличите. Най-честата грешка при тези настройки е да се смята, че те управляват „умността“ или „креативността“ на модела.\n",
    "\n",
    "\n",
    "Източник: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Обобщаване на текст  \n",
    "#### Предизвикателство  \n",
    "Обобщете текст, като добавите 'tl;dr:' в края на даден откъс. Обърнете внимание как моделът разбира как да изпълнява различни задачи без допълнителни инструкции. Можете да експериментирате с по-описателни подсказки от tl;dr, за да промените поведението на модела и да персонализирате обобщението, което получавате(3).  \n",
    "\n",
    "Последни изследвания показват значителен напредък в много NLP задачи и бенчмаркове чрез предварително обучение върху голям корпус от текст, последвано от дообучаване за конкретна задача. Макар архитектурата обикновено да е независима от задачата, този метод все пак изисква специфични за задачата набори от данни с хиляди или десетки хиляди примери. За разлика от това, хората обикновено могат да изпълнят нова езикова задача само с няколко примера или с прости инструкции – нещо, с което настоящите NLP системи все още имат трудности. Тук показваме, че увеличаването на мащаба на езиковите модели значително подобрява независимото от задачата изпълнение с малко примери, като понякога дори достига конкурентност с предишни най-добри подходи за дообучаване.  \n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Упражнения за различни случаи на употреба  \n",
    "1. Обобщаване на текст  \n",
    "2. Класифициране на текст  \n",
    "3. Генериране на нови имена на продукти\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Класифицирай текст  \n",
    "#### Предизвикателство  \n",
    "Класифицирай елементи в категории, които се задават по време на изпълнение. В следния пример предоставяме както категориите, така и текста за класифициране в подканата (*playground_reference).\n",
    "\n",
    "Запитване от клиент: Здравейте, един от бутоните на клавиатурата на лаптопа ми се счупи наскоро и ще ми трябва заместител:\n",
    "\n",
    "Класифицирана категория:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Генериране на нови имена за продукти\n",
    "#### Предизвикателство\n",
    "Създайте имена на продукти от примерни думи. Включваме в подсказката информация за продукта, за който ще генерираме имена. Даваме и подобен пример, за да покажем какъв модел очакваме. Зададената стойност на температурата е висока, за да се получат по-случайни и иновативни отговори.\n",
    "\n",
    "Описание на продукта: Домашен уред за приготвяне на млечни шейкове\n",
    "Ключови думи: бърз, здравословен, компактен.\n",
    "Имена на продукти: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Описание на продукта: Чифт обувки, които пасват на всеки размер крак.\n",
    "Ключови думи: адаптивен, пасва, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Референции  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Примери](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Най-добри практики за фино настройване на GPT-3 за класифициране на текст](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# За повече помощ  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Сътрудници\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Отказ от отговорност**:  \nТози документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, имайте предвид, че автоматичните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия изходен език следва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за недоразумения или погрешни тълкувания, произтичащи от използването на този превод.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:50:22+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "bg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}