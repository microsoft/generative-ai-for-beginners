{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фино настройване на Open AI модели\n",
    "\n",
    "Този тетрадка е базирана на актуалните насоки, предоставени в [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) документацията на Open AI.\n",
    "\n",
    "Финото настройване подобрява работата на базовите модели за вашето приложение, като ги дообучава с допълнителни данни и контекст, свързани с конкретния случай или сценарий. Имайте предвид, че техники като _few shot learning_ и _retrieval augmented generation_ ви позволяват да обогатите стандартния prompt с подходящи данни за по-добро качество. Тези подходи обаче са ограничени от максималния брой токени, които моделът може да обработи наведнъж.\n",
    "\n",
    "С финото настройване на практика дообучаваме самия модел с нужните данни (което ни позволява да използваме много повече примери, отколкото могат да се поберат в максималния прозорец от токени) – и внедряваме _персонализирана_ версия на модела, която вече не изисква примери по време на инференция. Това не само подобрява ефективността на нашия prompt дизайн (имаме повече свобода да използваме токен прозореца за други неща), но потенциално и намалява разходите ни (като намалява броя токени, които трябва да изпратим към модела при инференция).\n",
    "\n",
    "Финото настройване включва 4 стъпки:\n",
    "1. Подгответе тренировъчните данни и ги качете.\n",
    "1. Стартирайте обучението, за да получите фино настроен модел.\n",
    "1. Оценете фино настроения модел и повторете за по-добро качество.\n",
    "1. Внедрете фино настроения модел за инференция, когато сте доволни от резултатите.\n",
    "\n",
    "Имайте предвид, че не всички базови модели поддържат фино настройване – [проверете документацията на OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) за най-актуална информация. Можете също да фино настроите вече фино настроен модел. В този урок ще използваме `gpt-35-turbo` като целеви базов модел за фино настройване.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 1.1: Подгответе вашия датасет\n",
    "\n",
    "Нека създадем чатбот, който ви помага да разбирате периодичната таблица на елементите, като отговаря на въпроси за даден елемент с лимерик. В _този_ прост урок ще създадем датасет, с който да обучим модела, като включим няколко примерни отговора, които показват очаквания формат на данните. В реална ситуация ще трябва да създадете датасет с много повече примери. Може също да използвате отворен датасет (за вашата област), ако има такъв, и да го преформатирате за нуждите на финото обучение.\n",
    "\n",
    "Тъй като се фокусираме върху `gpt-35-turbo` и искаме едноетапен отговор (chat completion), можем да създадем примери, използвайки [този препоръчан формат](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), който отразява изискванията на OpenAI за chat completion. Ако очаквате многoетапно разговорно съдържание, ще използвате [формата за многоетапни примери](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), който включва параметър `weight`, за да се посочи кои съобщения да се използват (или не) при финото обучение.\n",
    "\n",
    "Тук ще използваме по-опростения едноетапен формат за нашия урок. Данните са във [jsonl формат](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) с по 1 запис на ред, като всеки е представен като JSON-обект. Примерът по-долу показва 2 записа – вижте [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) за пълния примерен набор (10 примера), който ще използваме за нашия урок по фино обучение. **Забележка:** Всеки запис _трябва_ да бъде дефиниран на един ред (да не се разделя на няколко реда, както е обичайно при форматиран JSON файл)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "В реална ситуация ще ви трябва много по-голям набор от примери за добри резултати – балансът е между качеството на отговорите и времето/разходите за фино обучение. Използваме малък набор, за да можем бързо да завършим финото обучение и да илюстрираме процеса. Вижте [този пример от OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) за по-сложен урок по фино обучение.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 1.2 Качете вашия набор от данни\n",
    "\n",
    "Качете данните с помощта на Files API [както е описано тук](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Имайте предвид, че за да изпълните този код, първо трябва да сте направили следните стъпки:\n",
    " - Инсталирали сте Python пакета `openai` (уверете се, че използвате версия >=0.28.0 за най-новите функции)\n",
    " - Зададен е променливата на средата `OPENAI_API_KEY` с вашия OpenAI API ключ\n",
    "За повече информация вижте [Ръководството за настройка](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), предоставено за курса.\n",
    "\n",
    "Сега изпълнете кода, за да създадете файл за качване от вашия локален JSONL файл.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 2.1: Създайте задача за фино настройване с помощта на SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 2.2: Проверете статуса на задачата\n",
    "\n",
    "Ето няколко неща, които можете да направите с API-то `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Показва последните n задачи за фино настройване\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Получавате подробности за конкретна задача за фино настройване\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Отменя задача за фино настройване\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Показва до n събития от задачата\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Първата стъпка в процеса е _валидиране на тренировъчния файл_, за да сте сигурни, че данните са в правилния формат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 2.3: Проследявайте събития, за да следите напредъка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 2.4: Вижте статуса в OpenAI таблото\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете да видите статуса, като посетите уебсайта на OpenAI и разгледате секцията _Fine-tuning_ на платформата. Там ще видите статуса на текущата задача, както и ще можете да проследите историята на предишните изпълнения. На тази снимка се вижда, че предишното изпълнение е неуспешно, а второто е успешно. За контекст – това се случи, когато първото изпълнение използва JSON файл с неправилно форматирани записи – след като това беше поправено, второто изпълнение завърши успешно и моделът стана достъпен за използване.\n",
    "\n",
    "![Статус на Fine-tuning задачата](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.bg.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете също така да видите съобщенията за състоянието и метриките, като превъртите надолу във визуалното табло, както е показано:\n",
    "\n",
    "| Съобщения | Метрики |\n",
    "|:---|:---|\n",
    "| ![Съобщения](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.bg.png) |  ![Метрики](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.bg.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 3.1: Вземете ID и тествайте фино настроения модел в кода\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 3.2: Зареждане и тестване на фино-настроения модел в Playground\n",
    "\n",
    "Вече можете да тествате фино-настроения модел по два начина. Първо, можете да посетите Playground и да използвате падащото меню Models, за да изберете новия си фино-настроен модел от наличните опции. Другият вариант е да използвате опцията \"Playground\", която се показва в панела за фино настройване (вижте снимката по-горе). Тя стартира _сравнителен_ изглед, който показва основния и фино-настроения модел един до друг за бърза оценка.\n",
    "\n",
    "![Статус на фино-настройваща задача](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.bg.png)\n",
    "\n",
    "Просто попълнете системния контекст, използван във вашите тренировъчни данни, и въведете тестовия си въпрос. Ще забележите, че и двете страни се обновяват с един и същ контекст и въпрос. Стартирайте сравнението и ще видите разликата в отговорите между тях. _Обърнете внимание как фино-настроеният модел форматира отговора според примера, който сте предоставили, докато основният модел просто следва системния prompt_.\n",
    "\n",
    "![Статус на фино-настройваща задача](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.bg.png)\n",
    "\n",
    "Ще забележите, че сравнението също така показва броя на токените за всеки модел и времето, необходимо за инференция. **Този конкретен пример е опростен и има за цел да покаже процеса, но не отразява реален набор от данни или ситуация**. Може да забележите, че и двата примера показват еднакъв брой токени (системният контекст и потребителският prompt са идентични), като фино-настроеният модел отнема повече време за инференция (персонализиран модел).\n",
    "\n",
    "В реални ситуации няма да използвате толкова елементарен пример, а ще настройвате модела с реални данни (например продуктов каталог за обслужване на клиенти), където качеството на отговора ще бъде много по-очевидно. В _такъв_ контекст, за да постигнете същото качество на отговора с основния модел, ще е необходима по-сложна работа по създаване на prompt-и, което ще увеличи използването на токени и евентуално времето за обработка при инференция. _За да опитате това, разгледайте примерите за фино настройване в OpenAI Cookbook._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Отказ от отговорност**:  \nТози документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, имайте предвид, че автоматичните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия изходен език следва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за недоразумения или погрешни тълкувания, произтичащи от използването на този превод.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:55:45+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "bg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}