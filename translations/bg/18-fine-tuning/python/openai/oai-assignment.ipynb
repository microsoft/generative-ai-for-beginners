{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фина настройка на модели на Open AI\n",
    "\n",
    "Този бележник е базиран на текущите указания, предоставени в документацията за [Фина настройка](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) от Open AI.\n",
    "\n",
    "Фината настройка подобрява представянето на основните модели за вашето приложение чрез повторно обучение с допълнителни данни и контекст, релевантни за конкретния случай на употреба или сценарий. Обърнете внимание, че техники за инженеринг на подканите като _few shot learning_ и _retrieval augmented generation_ ви позволяват да подобрите стандартната подканваща фраза с релевантни данни за повишаване на качеството. Въпреки това, тези подходи са ограничени от максималния размер на прозореца за токени на целевия основен модел.\n",
    "\n",
    "С фината настройка ефективно преобучаваме самия модел с необходимите данни (което ни позволява да използваме много повече примери, отколкото могат да се поберат в максималния прозорец за токени) - и внедряваме _персонализирана_ версия на модела, която вече не се нуждае от предоставяне на примери по време на извеждане. Това не само подобрява ефективността на дизайна на подканите ни (имаме повече гъвкавост при използването на прозореца за токени за други неща), но потенциално подобрява и разходите ни (чрез намаляване на броя токени, които трябва да изпращаме към модела по време на извеждане).\n",
    "\n",
    "Фината настройка има 4 стъпки:\n",
    "1. Подгответе тренировъчните данни и ги качете.\n",
    "1. Стартирайте тренировъчната задача, за да получите фино настроен модел.\n",
    "1. Оценете фино настроения модел и итеративно подобрявайте качеството.\n",
    "1. Внедрете фино настроения модел за извеждане, когато сте доволни.\n",
    "\n",
    "Обърнете внимание, че не всички основни модели поддържат фина настройка - [проверете документацията на OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) за най-актуална информация. Можете също да фино настроите вече фино настроен модел. В този урок ще използваме `gpt-35-turbo` като наш целеви основен модел за фина настройка.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 1.1: Подгответе своя набор от данни\n",
    "\n",
    "Нека създадем чатбот, който да ви помогне да разберете периодичната таблица на елементите, като отговаря на въпроси за даден елемент с лимерик. В _този_ прост урок ще създадем само набор от данни, за да обучим модела с няколко примерни отговора, които показват очаквания формат на данните. В реален случай на употреба ще трябва да създадете набор от данни с много повече примери. Може също да използвате отворен набор от данни (за вашата област на приложение), ако такъв съществува, и да го преформатирате за използване при фино настройване.\n",
    "\n",
    "Тъй като се фокусираме върху `gpt-35-turbo` и търсим еднооборотен отговор (чат завършек), можем да създадем примери, използвайки [този предложен формат](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), който отразява изискванията за чат завършек на OpenAI. Ако очаквате многооборотно разговорно съдържание, ще използвате [формата за многооборотни примери](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), който включва параметър `weight`, за да сигнализира кои съобщения трябва да се използват (или не) в процеса на фино настройване.\n",
    "\n",
    "Ще използваме по-простия еднооборотен формат за нашия урок тук. Данните са във [jsonl формат](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) с 1 запис на ред, всеки представен като JSON-обект. Фрагментът по-долу показва 2 записа като пример - вижте [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) за пълния примерен набор (10 примера), който ще използваме за нашия урок по фино настройване. **Забележка:** Всеки запис _трябва_ да бъде дефиниран в един ред (не разделен на няколко реда, както е типично за форматиран JSON файл)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "В реален случай на употреба ще ви трябва много по-голям набор от примери за добри резултати - компромисът ще бъде между качеството на отговорите и времето/разходите за фино настройване. Ние използваме малък набор, за да можем бързо да завършим финото настройване и да илюстрираме процеса. Вижте [този пример от OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) за по-сложен урок по фино настройване.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Стъпка 1.2 Качване на вашия набор от данни\n",
    "\n",
    "Качете данните, използвайки Files API [както е описано тук](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Обърнете внимание, че за да изпълните този код, трябва първо да сте направили следните стъпки:\n",
    " - Инсталирали сте Python пакета `openai` (уверете се, че използвате версия >=0.28.0 за най-новите функции)\n",
    " - Зададете променливата на средата `OPENAI_API_KEY` със своя OpenAI API ключ\n",
    "За да научите повече, вижте [Ръководството за настройка](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), предоставено за курса.\n",
    "\n",
    "Сега изпълнете кода, за да създадете файл за качване от вашия локален JSONL файл.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Стъпка 2.1: Създаване на задача за фино настройване с SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Стъпка 2.2: Проверете състоянието на задачата\n",
    "\n",
    "Ето няколко неща, които можете да направите с API-то `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Изброява последните n задачи за фино настройване\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Вземете подробности за конкретна задача за фино настройване\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Отменете задача за фино настройване\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Изброява до n събития от задачата\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Първата стъпка от процеса е _валидиране на тренировъчния файл_, за да се уверите, че данните са в правилния формат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Стъпка 2.3: Следете събитията, за да наблюдавате напредъка\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Стъпка 2.4: Преглед на статуса в OpenAI таблото за управление\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете също да видите статуса, като посетите уебсайта на OpenAI и разгледате секцията _Фина настройка_ на платформата. Там ще видите статуса на текущата задача, както и ще можете да проследите историята на предишните изпълнения на задачите. На този екран можете да видите, че предишното изпълнение е неуспешно, а второто изпълнение е успешно. За контекст, това се случи, когато първото изпълнение използва JSON файл с неправилно форматирани записи - след като беше поправено, второто изпълнение завърши успешно и направи модела достъпен за използване.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/bg/fine-tuned-model-status.563271727bf7bfba.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете също да видите съобщенията за състоянието и метриките, като превъртите по-надолу в визуалния табло, както е показано:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/bg/fine-tuned-messages-panel.4ed0c2da5ea1313b.png) |  ![Metrics](../../../../../translated_images/bg/fine-tuned-metrics-panel.700d7e4995a65229.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Стъпка 3.1: Вземете ID и тествайте фино настроения модел в кода\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Стъпка 3.2: Зареждане и тестване на фино настроен модел в Playground\n",
    "\n",
    "Сега можете да тествате фино настроения модел по два начина. Първо, можете да посетите Playground и да използвате падащото меню Models, за да изберете новия си фино настроен модел от изброените опции. Другата опция е да използвате опцията \"Playground\", показана в панела за фино настройване (вижте екранната снимка по-горе), която стартира следния _сравнителен_ изглед, който показва основния и фино настроения модел един до друг за бърза оценка.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/bg/fine-tuned-playground-compare.56e06f0ad8922016.png)\n",
    "\n",
    "Просто попълнете системния контекст, използван в данните за обучение, и задайте своя тестов въпрос. Ще забележите, че и двете страни се актуализират с идентичен контекст и въпрос. Стартирайте сравнението и ще видите разликата в изходите между тях. _Обърнете внимание как фино настроеният модел генерира отговора във формата, който сте предоставили в примерите си, докато основният модел просто следва системната подсказка_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/bg/fine-tuned-playground-launch.5a26495c983c6350.png)\n",
    "\n",
    "Ще забележите, че сравнението също така предоставя броя на токените за всеки модел и времето, необходимо за извеждане на резултата. **Този конкретен пример е опростен и има за цел да покаже процеса, но не отразява реален набор от данни или сценарий**. Може да забележите, че и двата примера показват същия брой токени (системният контекст и потребителската подсказка са идентични), като фино настроеният модел отнема повече време за извеждане на резултата (персонализиран модел).\n",
    "\n",
    "В реални сценарии няма да използвате такъв опростен пример, а ще правите фино настройване с реални данни (например продуктов каталог за обслужване на клиенти), където качеството на отговора ще бъде много по-очевидно. В _този_ контекст, постигането на еквивалентно качество на отговора с основния модел ще изисква повече персонализиране на подсказките, което ще увеличи използването на токени и потенциално свързаното време за обработка при извеждане на резултата. _За да изпробвате това, разгледайте примерите за фино настройване в OpenAI Cookbook, за да започнете._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Отказ от отговорност**:  \nТози документ е преведен с помощта на AI преводаческа услуга [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, моля, имайте предвид, че автоматизираните преводи могат да съдържат грешки или неточности. Оригиналният документ на неговия роден език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Ние не носим отговорност за каквито и да е недоразумения или неправилни тълкувания, произтичащи от използването на този превод.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:36:59+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "bg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}