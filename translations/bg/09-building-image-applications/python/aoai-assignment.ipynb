{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Създаване на приложение за генериране на изображения\n",
    "\n",
    "Големите езикови модели (LLM) не се ограничават само до генериране на текст. Възможно е също така да се създават изображения на база текстови описания. Изображенията като модалност са изключително полезни в различни сфери като медицински технологии, архитектура, туризъм, разработка на игри и други. В тази глава ще разгледаме двата най-популярни модела за генериране на изображения – DALL-E и Midjourney.\n",
    "\n",
    "## Въведение\n",
    "\n",
    "В този урок ще разгледаме:\n",
    "\n",
    "- Генериране на изображения и защо това е полезно.\n",
    "- DALL-E и Midjourney – какво представляват и как работят.\n",
    "- Как да създадете приложение за генериране на изображения.\n",
    "\n",
    "## Учебни цели\n",
    "\n",
    "След като завършите този урок, ще можете да:\n",
    "\n",
    "- Създавате приложение за генериране на изображения.\n",
    "- Определяте граници за вашето приложение чрез мета-подкани.\n",
    "- Работите с DALL-E и Midjourney.\n",
    "\n",
    "## Защо да създадем приложение за генериране на изображения?\n",
    "\n",
    "Приложенията за генериране на изображения са чудесен начин да изследвате възможностите на генеративния изкуствен интелект. Те могат да се използват например за:\n",
    "\n",
    "- **Редактиране и синтез на изображения**. Можете да създавате изображения за различни цели, като редактиране или синтез на изображения.\n",
    "\n",
    "- **Приложение в различни индустрии**. Могат да се използват за създаване на изображения в различни сфери като медицински технологии, туризъм, разработка на игри и други.\n",
    "\n",
    "## Сценарий: Edu4All\n",
    "\n",
    "В този урок ще продължим да работим със стартиращата компания Edu4All. Учениците ще създават изображения за своите задачи – какви точно изображения ще изберат, зависи от тях. Те могат да бъдат илюстрации към собствена приказка, нов герой за историята им или визуализация на идеи и концепции.\n",
    "\n",
    "Ето какво биха могли да създадат учениците на Edu4All, ако работят в час по паметници:\n",
    "\n",
    "![Edu4All startup, class on monuments, Eifel Tower](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.bg.png)\n",
    "\n",
    "с помощта на подкана като\n",
    "\n",
    "> \"Куче до Айфеловата кула на сутрешна слънчева светлина\"\n",
    "\n",
    "## Какво представляват DALL-E и Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) и [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) са два от най-популярните модела за генериране на изображения, които позволяват да използвате подкани за създаване на изображения.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Да започнем с DALL-E – това е генеративен AI модел, който създава изображения на база текстови описания.\n",
    "\n",
    "> [DALL-E е комбинация от два модела – CLIP и дифузно внимание](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** е модел, който създава ембединг представяния – числови представяния на данни – от изображения и текст.\n",
    "\n",
    "- **Дифузно внимание** е модел, който генерира изображения от ембедингите. DALL-E е обучен върху набор от изображения и текст и може да създава изображения по текстови описания. Например, DALL-E може да генерира изображение на котка с шапка или куче с ирокез.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney работи по подобен начин на DALL-E – създава изображения по текстови подкани. С Midjourney също може да се генерират изображения с подкани като „котка с шапка“ или „куче с ирокез“.\n",
    "\n",
    "\n",
    "![Image generated by Midjourney, mechanical pigeon](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Източник: Wikipedia, изображение, генерирано с Midjourney*\n",
    "\n",
    "## Как работят DALL-E и Midjourney\n",
    "\n",
    "Първо, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E е генеративен AI модел, базиран на трансформър архитектура с *авторегресивен трансформър*.\n",
    "\n",
    "*Авторегресивният трансформър* определя как моделът създава изображения от текстови описания – генерира по един пиксел наведнъж, като използва вече създадените пиксели, за да създаде следващия. Това се случва през множество слоеве на невронна мрежа, докато изображението стане завършено.\n",
    "\n",
    "Чрез този процес DALL-E контролира атрибути, обекти, характеристики и други елементи в създаваното изображение. DALL-E 2 и 3 обаче предоставят още по-голям контрол върху генерираното изображение,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Създаване на първото ви приложение за генериране на изображения\n",
    "\n",
    "Какво е необходимо, за да създадете приложение за генериране на изображения? Трябват ви следните библиотеки:\n",
    "\n",
    "- **python-dotenv** – силно се препоръчва да използвате тази библиотека, за да държите своите тайни в *.env* файл, отделно от кода.\n",
    "- **openai** – тази библиотека ще използвате, за да работите с OpenAI API.\n",
    "- **pillow** – за работа с изображения в Python.\n",
    "- **requests** – за да правите HTTP заявки.\n",
    "\n",
    "1. Създайте файл *.env* със следното съдържание:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Тази информация ще намерите в Azure Portal за вашия ресурс, в секцията \"Keys and Endpoint\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Съберете горните библиотеки във файл, наречен *requirements.txt*, по следния начин:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. След това създайте виртуална среда и инсталирайте библиотеките:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> За Windows използвайте следните команди, за да създадете и активирате вашата виртуална среда:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Добавете следния код във файл с име *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Нека обясним този код:\n",
    "\n",
    "- Първо, импортираме необходимите библиотеки, включително OpenAI библиотеката, dotenv, requests и Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- След това зареждаме променливите на средата от файла *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- После задаваме endpoint, ключа за OpenAI API, версията и типа.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- След това генерираме изображението:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Горният код връща JSON обект, който съдържа URL адреса на генерираното изображение. Можем да използваме този URL, за да изтеглим изображението и да го запазим във файл.\n",
    "\n",
    "- Накрая отваряме изображението и използваме стандартния преглед на изображения, за да го покажем:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Повече подробности за генерирането на изображението\n",
    "\n",
    "Нека разгледаме по-подробно кода, който генерира изображението:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** е текстовият подканващ низ, който се използва за генериране на изображението. В този случай използваме подканата \"Зайче на кон, държащо близалка, на мъглива поляна, където растат нарциси\".\n",
    "- **size** е размерът на генерираното изображение. В този случай генерираме изображение с размер 1024x1024 пиксела.\n",
    "- **n** е броят на генерираните изображения. В този случай генерираме две изображения.\n",
    "- **temperature** е параметър, който контролира случайността на изхода на генеративния AI модел. Стойността е между 0 и 1, където 0 означава, че изходът е детерминиран, а 1 — че е случаен. Стандартната стойност е 0.7.\n",
    "\n",
    "Има още неща, които можете да правите с изображения, които ще разгледаме в следващата секция.\n",
    "\n",
    "## Допълнителни възможности за генериране на изображения\n",
    "\n",
    "Досега видяхте как можем да генерираме изображение с няколко реда код на Python. Но има и още възможности при работата с изображения.\n",
    "\n",
    "Можете също така да правите следното:\n",
    "\n",
    "- **Редактиране**. Като предоставите съществуващо изображение, маска и подканващ текст, можете да промените изображението. Например, можете да добавите нещо към определена част от изображението. Представете си нашето изображение със зайчето — можете да добавите шапка на зайчето. Това става като подадете изображението, маска (която определя зоната за промяна) и текстова подканва, която описва какво трябва да се направи.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    Основното изображение ще съдържа само заека, но крайното изображение ще има шапка върху заека.\n",
    "\n",
    "- **Създаване на вариации**.\n",
    "    Вижте нашия [OpenAI notebook за повече информация](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Отказ от отговорност**:  \nТози документ е преведен с помощта на AI услуга за превод [Co-op Translator](https://github.com/Azure/co-op-translator). Въпреки че се стремим към точност, имайте предвид, че автоматичните преводи може да съдържат грешки или неточности. Оригиналният документ на неговия изходен език трябва да се счита за авторитетен източник. За критична информация се препоръчва професионален човешки превод. Не носим отговорност за недоразумения или погрешни тълкувания, произтичащи от използването на този превод.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:25:07+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "bg"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}