{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Luku 7: Keskustelusovellusten rakentaminen\n",
    "## Github Models API pikaopas\n",
    "\n",
    "Tämä muistikirja on muokattu [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) -kokoelmasta, joka sisältää muistikirjoja [Azure OpenAI](notebook-azure-openai.ipynb) -palveluiden käyttöön.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Yleiskatsaus  \n",
    "\"Suuret kielimallit ovat funktioita, jotka muuntavat tekstiä tekstiksi. Kun niille annetaan syötteenä tekstijono, suuri kielimalli yrittää ennustaa, mikä teksti tulee seuraavaksi.\"(1). Tämä \"pika-aloitus\" -muistikirja esittelee käyttäjille korkean tason LLM-käsitteitä, ydinkirjastot, joita tarvitaan AML:n käyttöönottoon, kevyen johdatuksen kehotteiden suunnitteluun sekä useita lyhyitä esimerkkejä erilaisista käyttötapauksista.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sisällysluettelo  \n",
    "\n",
    "[Yleiskatsaus](../../../../07-building-chat-applications/python)  \n",
    "[Kuinka käyttää OpenAI-palvelua](../../../../07-building-chat-applications/python)  \n",
    "[1. OpenAI-palvelun luominen](../../../../07-building-chat-applications/python)  \n",
    "[2. Asennus](../../../../07-building-chat-applications/python)    \n",
    "[3. Tunnistetiedot](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Käyttötapaukset](../../../../07-building-chat-applications/python)    \n",
    "[1. Tekstin tiivistäminen](../../../../07-building-chat-applications/python)  \n",
    "[2. Tekstin luokittelu](../../../../07-building-chat-applications/python)  \n",
    "[3. Uusien tuotenimien generointi](../../../../07-building-chat-applications/python)  \n",
    "[4. Luokittelijan hienosäätö](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Viitteet](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Luo ensimmäinen kehotteesi  \n",
    "Tämä lyhyt harjoitus antaa perustiedot siitä, miten voit lähettää kehotteita mallille Github Modelsissa yksinkertaista tehtävää, kuten \"yhteenvetoa\", varten.\n",
    "\n",
    "**Vaiheet**:  \n",
    "1. Asenna `azure-ai-inference`-kirjasto Python-ympäristöösi, jos et ole vielä tehnyt niin.  \n",
    "2. Lataa tavalliset apukirjastot ja määritä Github Models -tunnukset.  \n",
    "3. Valitse malli tehtävääsi varten  \n",
    "4. Luo yksinkertainen kehotus mallille  \n",
    "5. Lähetä pyyntösi mallin API:lle!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Asenna `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Tuo apukirjastot ja luo tunnistetiedot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Oikean mallin löytäminen  \n",
    "GPT-3.5-turbo- tai GPT-4-mallit pystyvät ymmärtämään ja tuottamaan luonnollista kieltä.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Kehotteen suunnittelu  \n",
    "\n",
    "\"Suurten kielimallien taika on siinä, että kun niitä opetetaan minimoimaan ennustusvirhe valtavien tekstimäärien avulla, mallit oppivat samalla käsitteitä, jotka auttavat näissä ennustuksissa. Esimerkiksi ne oppivat käsitteitä kuten\"(1):\n",
    "\n",
    "* miten kirjoitetaan oikein\n",
    "* miten kielioppi toimii\n",
    "* miten ilmaista asiat toisin sanoin\n",
    "* miten vastata kysymyksiin\n",
    "* miten käydä keskustelua\n",
    "* miten kirjoittaa monilla kielillä\n",
    "* miten koodata\n",
    "* jne.\n",
    "\n",
    "#### Miten ohjata suurta kielimallia  \n",
    "\"Kaikista suuren kielimallin syötteistä ylivoimaisesti merkittävin on tekstikehote(1).\n",
    "\n",
    "Suuria kielimalleja voidaan ohjata tuottamaan haluttua tulosta muutamalla tavalla:\n",
    "\n",
    "Ohjeistus: Kerro mallille, mitä haluat\n",
    "Täydennys: Johdata malli täydentämään haluamasi alku\n",
    "Esimerkki: Näytä mallille, mitä haluat, joko:\n",
    "Muutama esimerkki kehotteessa\n",
    "Satoja tai tuhansia esimerkkejä hienosäädön harjoitusaineistossa\"\n",
    "\n",
    "\n",
    "\n",
    "#### Kolme perusohjetta kehotteiden luomiseen:\n",
    "\n",
    "**Näytä ja kerro**. Tee selväksi, mitä haluat, joko ohjeilla, esimerkeillä tai näiden yhdistelmällä. Jos haluat mallin laittavan listan aakkosjärjestykseen tai luokittelemaan kappaleen tunnetilan mukaan, näytä sille, että tätä haluat.\n",
    "\n",
    "**Käytä laadukasta aineistoa**. Jos yrität rakentaa luokittelijaa tai saada mallin noudattamaan tiettyä kaavaa, varmista, että esimerkkejä on riittävästi. Tarkista esimerkkisi huolellisesti — malli on yleensä tarpeeksi fiksu huomaamaan perus kirjoitusvirheet ja antaa silti vastauksen, mutta se saattaa myös olettaa virheiden olevan tarkoituksellisia, mikä voi vaikuttaa vastaukseen.\n",
    "\n",
    "**Tarkista asetukset.** Temperature- ja top_p-asetukset säätelevät, kuinka määrätietoisesti malli tuottaa vastauksen. Jos haluat vastauksen, johon on vain yksi oikea vaihtoehto, kannattaa nämä asettaa matalalle. Jos taas haluat monipuolisempia vastauksia, voit nostaa arvoja. Yleisin virhe näiden asetusten kanssa on olettaa, että ne säätelevät \"älykkyyttä\" tai \"luovuutta\".\n",
    "\n",
    "\n",
    "Lähde: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Tiivistä teksti  \n",
    "#### Haaste  \n",
    "Tiivistä teksti lisäämällä 'tl;dr:' tekstikappaleen loppuun. Huomaa, miten malli osaa suorittaa useita tehtäviä ilman lisäohjeita. Voit kokeilla kuvaavampia kehotteita kuin tl;dr muokataksesi mallin toimintaa ja räätälöidäksesi tiivistelmän haluamallasi tavalla(3).  \n",
    "\n",
    "Viimeaikaiset tutkimukset ovat osoittaneet merkittäviä edistysaskeleita monissa NLP-tehtävissä ja -mittareissa, kun ensin esikoulutetaan suurella tekstikorpuksella ja sen jälkeen hienosäädetään tiettyyn tehtävään. Vaikka arkkitehtuuri on yleensä tehtäväriippumaton, tämä menetelmä vaatii silti tuhansien tai jopa kymmenientuhansien esimerkkien tehtäväkohtaisia hienosäätöaineistoja. Ihmiset sen sijaan pystyvät yleensä suorittamaan uuden kielitehtävän vain muutaman esimerkin tai yksinkertaisten ohjeiden avulla – tässä nykyiset NLP-järjestelmät ovat vielä pitkälti haasteiden edessä. Tässä osoitamme, että kielimallien skaalaaminen parantaa huomattavasti tehtäväriippumatonta, vähäesimerkkistä suorituskykyä, ja joskus jopa yltää kilpailemaan aiempien huipputason hienosäätömenetelmien kanssa.\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Harjoituksia eri käyttötarkoituksiin  \n",
    "1. Tiivistä teksti  \n",
    "2. Luokittele teksti  \n",
    "3. Luo uusia tuotenimiä\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Luokittele teksti  \n",
    "#### Haaste  \n",
    "Luokittele kohteet kategorioihin, jotka annetaan vasta ennustevaiheessa. Seuraavassa esimerkissä annamme sekä kategoriat että luokiteltavan tekstin kehotteessa (*playground_reference).\n",
    "\n",
    "Asiakaskysely: Hei, yksi kannettavani näppäimistä meni rikki hiljattain ja tarvitsisin siihen uuden:\n",
    "\n",
    "Luokiteltu kategoria:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Luo uusia tuotenimiä\n",
    "#### Haaste\n",
    "Luo tuotenimiä esimerkkisanojen pohjalta. Tässä annamme kehotteessa tietoa tuotteesta, jolle haluamme keksiä nimiä. Mukana on myös vastaava esimerkki, joka näyttää toivotun mallin. Olemme lisäksi asettaneet temperature-arvon korkeaksi, jotta vastauksista tulisi sattumanvaraisempia ja luovempia.\n",
    "\n",
    "Tuotekuvaus: Kotikäyttöinen pirtelökone\n",
    "Siemensanat: nopea, terveellinen, kompakti.\n",
    "Tuotenimet: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Tuotekuvaus: Kengät, jotka sopivat kaikenkokoisiin jalkoihin.\n",
    "Siemensanat: mukautuva, istuvuus, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Viitteet  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Esimerkit](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Parhaat käytännöt GPT-3:n hienosäätöön tekstin luokittelua varten](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Lisäapua varten  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Avustajat\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Vastuuvapauslauseke**:  \nTämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Pyrimme tarkkuuteen, mutta huomioithan, että automaattiset käännökset saattavat sisältää virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäisellä kielellä tulee pitää ensisijaisena lähteenä. Kriittisissä tapauksissa suosittelemme ammattimaisen ihmiskääntäjän käyttöä. Emme ole vastuussa tämän käännöksen käytöstä mahdollisesti aiheutuvista väärinkäsityksistä tai tulkinnoista.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:41:12+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "fi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}