<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b4b0266fbadbba7ded891b6485adc66d",
  "translation_date": "2025-10-17T19:42:08+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "fi"
}
-->
# Tiedonhakuun perustuva generointi (RAG) ja vektoripohjaiset tietokannat

[![Tiedonhakuun perustuva generointi (RAG) ja vektoripohjaiset tietokannat](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.fi.png)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Hakusovelluksia k√§sittelev√§ss√§ oppitunnissa opimme lyhyesti, kuinka omia tietoja voidaan integroida suurten kielimallien (LLM) kanssa. T√§ss√§ oppitunnissa syvennymme tarkemmin siihen, miten voit ankkuroida omat tietosi LLM-sovellukseen, prosessin toimintaan ja menetelmiin tietojen tallentamiseksi, mukaan lukien upotukset ja teksti.

> **Video tulossa pian**

## Johdanto

T√§ss√§ oppitunnissa k√§sitell√§√§n seuraavia aiheita:

- Johdatus RAG:iin, mit√§ se on ja miksi sit√§ k√§ytet√§√§n teko√§lyss√§.

- Ymm√§rrys vektoripohjaisista tietokannoista ja niiden luominen sovellustamme varten.

- K√§yt√§nn√∂n esimerkki siit√§, miten RAG integroidaan sovellukseen.

## Oppimistavoitteet

T√§m√§n oppitunnin j√§lkeen osaat:

- Selitt√§√§ RAG:n merkityksen tiedon haussa ja k√§sittelyss√§.

- M√§√§ritt√§√§ RAG-sovelluksen ja ankkuroida omat tietosi LLM:√§√§n.

- Tehokkaasti integroida RAG ja vektoripohjaiset tietokannat LLM-sovelluksiin.

## Meid√§n skenaario: LLM:n parantaminen omilla tiedoillamme

T√§ss√§ oppitunnissa haluamme lis√§t√§ omat muistiinpanomme koulutusalustaan, mik√§ mahdollistaa chatbotin tarjoavan enemm√§n tietoa eri aiheista. K√§ytt√§m√§ll√§ muistiinpanojamme oppijat voivat opiskella paremmin ja ymm√§rt√§√§ eri aiheita, mik√§ helpottaa kokeisiin valmistautumista. Skenaarion luomiseksi k√§yt√§mme:

- `Azure OpenAI:` LLM, jota k√§yt√§mme chatbotin luomiseen.

- `AI for beginners -oppitunti neuroverkoista`: data, johon ankkuroidaan LLM.

- `Azure AI Search` ja `Azure Cosmos DB:` vektoripohjainen tietokanta tietojen tallentamiseen ja hakemistoindeksin luomiseen.

K√§ytt√§j√§t voivat luoda harjoituskokeita muistiinpanoistaan, kertauskortteja ja tiivist√§√§ ne ytimekk√§iksi yhteenvedoiksi. Aloitetaan katsomalla, mit√§ RAG on ja miten se toimii:

## Tiedonhakuun perustuva generointi (RAG)

LLM-pohjainen chatbot k√§sittelee k√§ytt√§j√§n antamia kyselyit√§ ja tuottaa vastauksia. Se on suunniteltu vuorovaikutteiseksi ja keskustelee k√§ytt√§jien kanssa monista eri aiheista. Sen vastaukset ovat kuitenkin rajallisia sen tarjoaman kontekstin ja perustavanlaatuisen koulutusdatan osalta. Esimerkiksi GPT-4:n tietopohja kattaa tiedot syyskuuhun 2021 asti, mik√§ tarkoittaa, ett√§ se ei tunne tapahtumia t√§m√§n ajankohdan j√§lkeen. Lis√§ksi LLM:ien koulutuksessa k√§ytetty data ei sis√§ll√§ luottamuksellisia tietoja, kuten henkil√∂kohtaisia muistiinpanoja tai yrityksen tuotemanuaalia.

### Miten RAG (tiedonhakuun perustuva generointi) toimii

![kuva, joka n√§ytt√§√§ miten RAG toimii](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.fi.png)

Oletetaan, ett√§ haluat ottaa k√§ytt√∂√∂n chatbotin, joka luo kyselyit√§ muistiinpanoistasi. Tarvitset yhteyden tietopohjaan. T√§ss√§ RAG tulee apuun. RAG toimii seuraavasti:

- **Tietopohja:** Ennen hakua dokumentit t√§ytyy sy√∂tt√§√§ ja esik√§sitell√§, yleens√§ jakamalla suuret dokumentit pienempiin osiin, muuntamalla ne tekstin upotuksiksi ja tallentamalla ne tietokantaan.

- **K√§ytt√§j√§n kysely:** K√§ytt√§j√§ esitt√§√§ kysymyksen.

- **Haku:** Kun k√§ytt√§j√§ esitt√§√§ kysymyksen, upotusmalli hakee asiaankuuluvat tiedot tietopohjasta tarjotakseen enemm√§n kontekstia, joka sis√§llytet√§√§n kyselyyn.

- **Generointi:** LLM parantaa vastaustaan haettujen tietojen perusteella. T√§m√§ mahdollistaa sen, ett√§ vastaus perustuu paitsi ennalta koulutettuun dataan my√∂s lis√§ttyyn kontekstiin. Haettu data k√§ytet√§√§n LLM:n vastausten parantamiseen. LLM palauttaa sitten vastauksen k√§ytt√§j√§n kysymykseen.

![kuva, joka n√§ytt√§√§ RAG:n arkkitehtuurin](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.fi.png)

RAG:n arkkitehtuuri toteutetaan transformereilla, jotka koostuvat kahdesta osasta: kooderista ja dekooderista. Esimerkiksi, kun k√§ytt√§j√§ esitt√§√§ kysymyksen, sy√∂tetty teksti "koodataan" vektoreiksi, jotka sis√§lt√§v√§t sanojen merkityksen, ja vektorit "dekoodataan" dokumentti-indeksiimme ja luodaan uutta teksti√§ k√§ytt√§j√§n kyselyn perusteella. LLM k√§ytt√§√§ sek√§ kooderi-dekooderi-mallia tuottaakseen vastauksen.

Kaksi l√§hestymistapaa RAG:n toteuttamiseen ehdotetun artikkelin mukaan: [Retrieval-Augmented Generation for Knowledge intensive NLP (luonnollisen kielen k√§sittelyohjelmisto) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) ovat:

- **_RAG-Sequence_** k√§ytt√§√§ haettuja dokumentteja ennustaakseen parhaan mahdollisen vastauksen k√§ytt√§j√§n kyselyyn.

- **RAG-Token** k√§ytt√§√§ dokumentteja seuraavan tokenin tuottamiseen ja hakee sitten vastauksen k√§ytt√§j√§n kyselyyn.

### Miksi k√§ytt√§√§ RAG:ia?

- **Tietojen rikkaus:** varmistaa, ett√§ tekstivastaukset ovat ajan tasalla ja ajankohtaisia. Se parantaa suorituskyky√§ alakohtaisissa teht√§viss√§ p√§√§sem√§ll√§ k√§siksi sis√§iseen tietopohjaan.

- V√§hent√§√§ virheellist√§ tietoa k√§ytt√§m√§ll√§ **todennettavissa olevaa dataa** tietopohjasta tarjotakseen kontekstia k√§ytt√§j√§n kyselyihin.

- Se on **kustannustehokas**, koska se on taloudellisempi verrattuna LLM:n hienos√§√§t√∂√∂n.

## Tietopohjan luominen

Sovelluksemme perustuu henkil√∂kohtaisiin tietoihimme, eli AI For Beginners -opetussuunnitelman neuroverkko-oppituntiin.

### Vektoripohjaiset tietokannat

Vektoripohjainen tietokanta, toisin kuin perinteiset tietokannat, on erikoistunut tietokanta, joka on suunniteltu tallentamaan, hallitsemaan ja hakemaan upotettuja vektoreita. Se tallentaa dokumenttien numeeriset esitykset. Datan pilkkominen numeerisiin upotuksiin helpottaa AI-j√§rjestelm√§n kyky√§ ymm√§rt√§√§ ja k√§sitell√§ dataa.

Tallennamme upotuksemme vektoripohjaisiin tietokantoihin, koska LLM:ill√§ on rajoitus sy√∂tteen√§ hyv√§ksyttyjen tokenien m√§√§r√§ss√§. Koska et voi v√§litt√§√§ kaikkia upotuksia LLM:lle, meid√§n t√§ytyy pilkkoa ne osiin, ja kun k√§ytt√§j√§ esitt√§√§ kysymyksen, upotukset, jotka ovat l√§himp√§n√§ kysymyst√§, palautetaan yhdess√§ kyselyn kanssa. Pilkkominen my√∂s v√§hent√§√§ kustannuksia LLM:lle v√§litettyjen tokenien m√§√§r√§ss√§.

Joistakin suosituista vektoripohjaisista tietokannoista mainittakoon Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Voit luoda Azure Cosmos DB -mallin k√§ytt√§m√§ll√§ Azure CLI:t√§ seuraavalla komennolla:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist√§ upotuksiin

Ennen kuin tallennamme datamme, meid√§n t√§ytyy muuntaa se vektoripohjaisiksi upotuksiksi ennen sen tallentamista tietokantaan. Jos ty√∂skentelet suurten dokumenttien tai pitkien tekstien kanssa, voit pilkkoa ne odotettujen kyselyiden perusteella. Pilkkominen voidaan tehd√§ lause- tai kappaletasolla. Koska pilkkominen johdetaan sanojen ymp√§rill√§ olevista merkityksist√§, voit lis√§t√§ jonkin muun kontekstin pilkottuun osaan, esimerkiksi lis√§√§m√§ll√§ dokumentin otsikon tai sis√§llytt√§m√§ll√§ teksti√§ ennen tai j√§lkeen pilkotun osan. Voit pilkkoa datan seuraavasti:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Kun data on pilkottu, voimme sitten upottaa tekstimme eri upotusmalleilla. Joitakin malleja, joita voit k√§ytt√§√§, ovat: word2vec, ada-002 OpenAI:lta, Azure Computer Vision ja monet muut. Mallin valinta riippuu k√§ytt√§mist√§si kielist√§, koodattavan sis√§ll√∂n tyypist√§ (teksti/kuvat/√§√§ni), sy√∂tteen koosta, jonka se voi koodata, ja upotuksen pituudesta.

Esimerkki upotetusta tekstist√§ OpenAI:n `text-embedding-ada-002` -mallilla:
![kissan upotus](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.fi.png)

## Tiedonhaku ja vektorihaku

Kun k√§ytt√§j√§ esitt√§√§ kysymyksen, hakija muuntaa sen vektoriksi k√§ytt√§m√§ll√§ kyselykooderia, ja etsii sitten dokumentti-indeksist√§mme asiaankuuluvia vektoreita, jotka liittyv√§t sy√∂tteeseen. Kun haku on tehty, se muuntaa sek√§ sy√∂tevektorin ett√§ dokumenttivektorit tekstiksi ja v√§litt√§√§ ne LLM:lle.

### Tiedonhaku

Tiedonhaku tapahtuu, kun j√§rjestelm√§ yritt√§√§ nopeasti l√∂yt√§√§ dokumentit indeksist√§, jotka t√§ytt√§v√§t hakukriteerit. Hakijan tavoitteena on saada dokumentteja, joita k√§ytet√§√§n tarjoamaan konteksti ja ankkuroimaan LLM omiin tietoihisi.

Tietokannassamme voidaan suorittaa hakuja useilla tavoilla, kuten:

- **Avainsanahaku** - k√§ytet√§√§n tekstihakuun.

- **Semanttinen haku** - k√§ytt√§√§ sanojen semanttista merkityst√§.

- **Vektorihaku** - muuntaa dokumentit tekstist√§ vektoriesityksiksi upotusmallien avulla. Haku tehd√§√§n kysym√§ll√§ dokumentteja, joiden vektoriesitykset ovat l√§himp√§n√§ k√§ytt√§j√§n kysymyst√§.

- **Hybridi** - yhdistelm√§ avainsana- ja vektorihakua.

Haun haasteena on, kun tietokannassa ei ole samanlaista vastausta kyselyyn, j√§rjestelm√§ palauttaa parhaan mahdollisen tiedon, jonka se voi l√∂yt√§√§. Voit kuitenkin k√§ytt√§√§ taktiikoita, kuten asettaa maksimiet√§isyyden relevanssille tai k√§ytt√§√§ hybridihakua, joka yhdist√§√§ sek√§ avainsana- ett√§ vektorihakua. T√§ss√§ oppitunnissa k√§yt√§mme hybridihakua, joka yhdist√§√§ sek√§ vektori- ett√§ avainsanahaun. Tallennamme datamme datafreimiin, jossa sarakkeet sis√§lt√§v√§t pilkotut osat sek√§ upotukset.

### Vektorien samankaltaisuus

Hakija etsii tietopohjasta upotuksia, jotka ovat l√§hell√§ toisiaan, l√§himm√§t naapurit, koska ne ovat tekstej√§, jotka ovat samankaltaisia. Skenaariossa, jossa k√§ytt√§j√§ esitt√§√§ kyselyn, se ensin upotetaan ja sitten yhdistet√§√§n samankaltaisiin upotuksiin. Yleinen mitta, jota k√§ytet√§√§n arvioimaan, kuinka samankaltaisia eri vektorit ovat, on kosinimainen samankaltaisuus, joka perustuu kahden vektorin v√§liseen kulmaan.

Voimme mitata samankaltaisuutta my√∂s muilla vaihtoehdoilla, kuten euklidisella et√§isyydell√§, joka on suora viiva vektorien p√§√§tepisteiden v√§lill√§, ja pistetulolla, joka mittaa kahden vektorin vastaavien elementtien tuotteiden summan.

### Hakemisto

Kun teemme tiedonhakua, meid√§n t√§ytyy rakentaa hakemisto tietopohjallemme ennen hakua. Hakemisto tallentaa upotuksemme ja voi nopeasti hakea samankaltaisimmat osat jopa suuresta tietokannasta. Voimme luoda hakemiston paikallisesti k√§ytt√§m√§ll√§:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Uudelleenj√§rjestely

Kun olet tehnyt kyselyn tietokantaan, saatat tarvita tulosten lajittelua relevanssin mukaan. Uudelleenj√§rjestely LLM hy√∂dynt√§√§ koneoppimista parantaakseen hakutulosten relevanssia j√§rjest√§m√§ll√§ ne t√§rkeimmist√§ alkaen. Azure AI Search -palvelussa uudelleenj√§rjestely tehd√§√§n automaattisesti semanttisen uudelleenj√§rjestelij√§n avulla. Esimerkki siit√§, miten uudelleenj√§rjestely toimii l√§himpien naapureiden avulla:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Kaiken yhdist√§minen

Viimeinen vaihe on lis√§t√§ LLM mukaan, jotta voimme saada vastauksia, jotka perustuvat omiin tietoihimme. Voimme toteuttaa sen seuraavasti:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Sovelluksen arviointi

### Arviointikriteerit

- Vastauksien laatu: varmistetaan, ett√§ ne kuulostavat luonnollisilta, sujuvilta ja ihmism√§isilt√§.

- Tietojen ankkurointi: arvioidaan, tuliko vastaus toimitetuista dokumenteista.

- Relevanssi: arvioidaan, vastaako vastaus kysymyst√§ ja liittyyk√∂ se siihen.

- Sujuvuus: arvioidaan, onko vastaus kieliopillisesti j√§rkev√§.

## K√§ytt√∂tapaukset RAG:lle ja vektoripohjaisille tietokannoille

RAG:n ja vektoripohjaisten tietokantojen k√§ytt√∂ voi parantaa sovellustasi monin tavoin, kuten:

- Kysymys-vastaus: yrityksesi datan ankkurointi chattiin, jota ty√∂ntekij√§t voivat k√§ytt√§√§ kysymysten esitt√§miseen.

- Suositusj√§rjestelm√§t: j√§rjestelm√§, joka yhdist√§√§ samankaltaisimmat arvot, kuten elokuvat, ravintolat ja paljon muuta.

- Chatbot-palvelut: voit tallentaa chat-historian ja personoida keskustelun k√§ytt√§j√§n datan perusteella.

- Kuvahaku vektoripohjaisten upotusten avulla, hy√∂dyllinen kuvantunnistuksessa ja poikkeavuuksien havaitsemisessa.

## Yhteenveto

Olemme k√§sitelleet RAG:n perusalueet datan lis√§√§misest√§ sovellukseen, k√§ytt√§j√§n kyselyst√§ ja vastauksesta. RAG:n luomisen yksinkertaistamiseksi voit k√§ytt√§√§ kehyksi√§, kuten Semantic Kernel, Langchain tai Autogen.

## Teht√§v√§

Jatka oppimista tiedonhakuun perustuvasta generoinnista (RAG) rakentamalla:

- Sovellukselle k√§ytt√∂liittym√§ valitsemallasi kehysratkaisulla.

- Hy√∂dynn√§ kehyst√§, kuten LangChain tai Semantic Kernel, ja luo sovelluksesi uudelleen.

Onnittelut oppitunnin suorittamisesta üëè.

## Oppiminen ei lopu t√§h√§n, jatka matkaasi

Oppitunnin j√§lkeen tutustu [Generative AI Learning -kokoelmaan](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) jatkaaksesi Generatiivisen AI:n osaamisen kehitt√§mist√§!

---

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ tulisi katsoa ensisijaiseksi l√§hteeksi. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa v√§√§rink√§sityksist√§ tai virhetulkinnoista, jotka johtuvat t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§.