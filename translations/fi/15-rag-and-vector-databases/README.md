<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-05-20T01:34:20+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "fi"
}
-->
# Tiedonhakuun perustuva generointi (RAG) ja vektoripohjaiset tietokannat

[![Tiedonhakuun perustuva generointi (RAG) ja vektoripohjaiset tietokannat](../../../translated_images/15-lesson-banner.799d0cd2229970edb365f6667a4c7b3a0f526eb8698baa7d2e05c3bd49a5d83f.fi.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

Hakusovellusten oppitunnilla opimme lyhyesti, kuinka integroida omaa dataa suuriin kielimalleihin (LLM). T√§ss√§ oppitunnissa syvennymme tarkemmin siihen, miten voit sitoa datasi LLM-sovellukseesi, prosessin mekaniikkaan ja menetelmiin datan tallentamiseksi, mukaan lukien sek√§ upotukset ett√§ teksti.

> **Video tulossa pian**

## Johdanto

T√§ss√§ oppitunnissa k√§sittelemme seuraavia asioita:

- Johdatus RAG:iin, mit√§ se on ja miksi sit√§ k√§ytet√§√§n teko√§lyss√§.

- Ymm√§rrys siit√§, mit√§ vektoripohjaiset tietokannat ovat ja kuinka luoda sellainen sovelluksellemme.

- K√§yt√§nn√∂n esimerkki siit√§, kuinka integroida RAG sovellukseen.

## Oppimistavoitteet

Oppitunnin suorittamisen j√§lkeen pystyt:

- Selitt√§m√§√§n RAG:n merkityksen datan haussa ja k√§sittelyss√§.

- Asentamaan RAG-sovelluksen ja sitomaan datasi LLM:√§√§n.

- Tehokkaasti integroimaan RAG:n ja vektoripohjaiset tietokannat LLM-sovelluksiin.

## Meid√§n skenaario: LLM:n parantaminen omalla datalla

T√§ss√§ oppitunnissa haluamme lis√§t√§ omat muistiinpanomme koulutusstartuppiin, jolloin chatbot voi saada enemm√§n tietoa eri aiheista. K√§ytt√§m√§ll√§ muistiinpanojamme oppijat voivat opiskella paremmin ja ymm√§rt√§√§ eri aiheita, mik√§ helpottaa kokeisiin valmistautumista. Skenaarion luomiseksi k√§yt√§mme:

- `Azure OpenAI:` LLM, jota k√§yt√§mme chatbotin luomiseen

- `AI for beginners' lesson on Neural Networks`: t√§m√§ on data, johon LLM perustetaan

- `Azure AI Search` ja `Azure Cosmos DB:` vektoripohjainen tietokanta datan tallentamiseen ja hakemistoindeksin luomiseen

K√§ytt√§j√§t voivat luoda harjoituskyselyit√§ muistiinpanoistaan, kertauskortteja ja tiivist√§√§ ne ytimekk√§iksi katsauksiksi. Aloittaaksemme, katsotaan mit√§ RAG on ja miten se toimii:

## Tiedonhakuun perustuva generointi (RAG)

LLM-pohjainen chatbot k√§sittelee k√§ytt√§j√§n kehotteita luodakseen vastauksia. Se on suunniteltu olemaan vuorovaikutteinen ja keskustelemaan k√§ytt√§jien kanssa laajasta aihevalikoimasta. Sen vastaukset ovat kuitenkin rajallisia annetun kontekstin ja sen perustavan koulutusaineiston mukaan. Esimerkiksi GPT-4:n tietokatko on syyskuussa 2021, mik√§ tarkoittaa, ett√§ se ei tunne tapahtumia, jotka ovat tapahtuneet t√§m√§n ajankohdan j√§lkeen. Lis√§ksi LLM:ien koulutuksessa k√§ytetty data ei sis√§ll√§ luottamuksellista tietoa, kuten henkil√∂kohtaisia muistiinpanoja tai yrityksen tuotek√§sikirjaa.

### Miten RAG:t (Tiedonhakuun perustuva generointi) toimivat

![Piirros, joka n√§ytt√§√§ miten RAG:t toimivat](../../../translated_images/how-rag-works.d87a7ed9c30f43126bb9e8e259be5d66e16cd1fef65374e6914746ba9bfb0b2f.fi.png)

Oletetaan, ett√§ haluat ottaa k√§ytt√∂√∂n chatbotin, joka luo kyselyit√§ muistiinpanoistasi, tarvitset yhteyden tietokantaan. T√§ss√§ RAG tulee apuun. RAG:t toimivat seuraavasti:

- **Tietokanta:** Ennen hakua n√§m√§ dokumentit tulee ottaa vastaan ja esik√§sitell√§, yleens√§ pilkkomalla suuria dokumentteja pienempiin osiin, muuntamalla ne tekstin upotuksiksi ja tallentamalla ne tietokantaan.

- **K√§ytt√§j√§n kysely:** k√§ytt√§j√§ esitt√§√§ kysymyksen

- **Haku:** Kun k√§ytt√§j√§ esitt√§√§ kysymyksen, upotusmalli hakee asiaankuuluvan tiedon tietokannastamme tarjotakseen enemm√§n kontekstia, joka sis√§llytet√§√§n kehotteeseen.

- **Parannettu generointi:** LLM parantaa vastaustaan haetun datan perusteella. Se mahdollistaa, ett√§ generoitava vastaus perustuu paitsi ennalta koulutettuun dataan my√∂s asiaankuuluvaan tietoon lis√§tyst√§ kontekstista. Haettu data k√§ytet√§√§n LLM:n vastausten parantamiseen. LLM palauttaa sitten vastauksen k√§ytt√§j√§n kysymykseen.

![Piirros, joka n√§ytt√§√§ RAG:n arkkitehtuurin](../../../translated_images/encoder-decode.75eebc7093ccefec17568eebc80d3d0b831ecf2ea204566377a04c77a5a57ebb.fi.png)

RAG:n arkkitehtuuri toteutetaan k√§ytt√§en transformereita, jotka koostuvat kahdesta osasta: kooderista ja dekooderista. Esimerkiksi, kun k√§ytt√§j√§ esitt√§√§ kysymyksen, sy√∂teteksti 'koodataan' vektoreiksi, jotka kuvaavat sanojen merkityst√§, ja vektorit 'dekoodataan' dokumentti-indeksiimme ja luovat uutta teksti√§ k√§ytt√§j√§n kyselyn perusteella. LLM k√§ytt√§√§ sek√§ kooderi-dekooderi mallia tuottaakseen lopputuloksen.

Kaksi l√§hestymistapaa RAG:n toteuttamiseen ehdotetun paperin mukaan: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) ovat:

- **_RAG-Sequence_** k√§ytt√§en haettuja dokumentteja ennustamaan paras mahdollinen vastaus k√§ytt√§j√§n kyselyyn

- **RAG-Token** k√§ytt√§en dokumentteja seuraavan tokenin generointiin, sitten hakemaan niit√§ vastaamaan k√§ytt√§j√§n kyselyyn

### Miksi k√§ytt√§isit RAG:t√§?¬†

- **Tietorikkaus:** varmistaa, ett√§ tekstivastaukset ovat ajan tasalla ja ajankohtaisia. Se parantaa suorituskyky√§ alakohtaisissa teht√§viss√§ p√§√§sem√§ll√§ sis√§iseen tietokantaan.

- V√§hent√§√§ virheellisi√§ tietoja k√§ytt√§m√§ll√§ **todennettavaa dataa** tietokannassa tarjotakseen kontekstia k√§ytt√§j√§n kyselyihin.

- Se on **kustannustehokas**, koska ne ovat taloudellisempia verrattuna LLM:n hienos√§√§t√∂√∂n.

## Tietokannan luominen

Sovelluksemme perustuu henkil√∂kohtaiseen dataamme, eli Neuroverkkotunnille AI For Beginners -opetussuunnitelmassa.

### Vektoripohjaiset tietokannat

Vektoripohjainen tietokanta, toisin kuin perinteiset tietokannat, on erikoistunut tietokanta, joka on suunniteltu tallentamaan, hallitsemaan ja hakemaan upotettuja vektoreita. Se tallentaa dokumenttien numeerisia esityksi√§. Datan pilkkominen numeerisiin upotuksiin helpottaa AI-j√§rjestelm√§mme datan ymm√§rt√§mist√§ ja k√§sittely√§.

Tallennamme upotuksemme vektoripohjaisiin tietokantoihin, koska LLM:ill√§ on rajoitus sy√∂tteen√§ hyv√§ksytt√§vien tokenien m√§√§r√§ss√§. Koska et voi antaa koko upotuksia LLM:lle, meid√§n t√§ytyy pilkkoa ne osiin, ja kun k√§ytt√§j√§ esitt√§√§ kysymyksen, upotukset, jotka ovat eniten kysymyksen kaltaisia, palautetaan yhdess√§ kehotteen kanssa. Pilkkominen my√∂s v√§hent√§√§ kustannuksia LLM:lle l√§hetett√§vien tokenien m√§√§r√§ss√§.

Joitakin suosittuja vektoripohjaisia tietokantoja ovat Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Voit luoda Azure Cosmos DB -mallin k√§ytt√§en Azure CLI:t√§ seuraavalla komennolla:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist√§ upotuksiin

Ennen kuin tallennamme datamme, meid√§n t√§ytyy muuntaa se vektoriupotuksiksi ennen kuin se tallennetaan tietokantaan. Jos ty√∂skentelet suurten dokumenttien tai pitkien tekstien kanssa, voit pilkkoa ne odotettujen kyselyiden perusteella. Pilkkominen voidaan tehd√§ lause- tai kappaletasolla. Koska pilkkominen johtaa merkityksiin ymp√§r√∂ivist√§ sanoista, voit lis√§t√§ jonkin muun kontekstin osaan, esimerkiksi lis√§√§m√§ll√§ dokumentin otsikon tai sis√§llytt√§m√§ll√§ teksti√§ ennen tai j√§lkeen osan. Voit pilkkoa datan seuraavasti:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Kun pilkottu, voimme sitten upottaa tekstimme eri upotusmallien avulla. Joitakin malleja, joita voit k√§ytt√§√§, ovat: word2vec, ada-002 OpenAI:lta, Azure Computer Vision ja paljon muuta. Mallin valinta riippuu k√§ytt√§mist√§si kielist√§, koodatun sis√§ll√∂n tyypist√§ (teksti/kuvat/audio), sy√∂tteen koosta, jonka se voi koodata, ja upotuksen pituudesta.

Esimerkki upotetusta tekstist√§ k√§ytt√§en OpenAI:n `text-embedding-ada-002` mallia on:
![Kissan sanan upotus](../../../translated_images/cat.3db013cbca4fd5d90438ea7b312ad0364f7686cf79931ab15cd5922151aea53e.fi.png)

## Tiedonhaku ja vektorihaku

Kun k√§ytt√§j√§ esitt√§√§ kysymyksen, hakija muuntaa sen vektoriksi k√§ytt√§en kyselyn kooderia, sitten se etsii dokumentti-hakemistoistamme asiaankuuluvia vektoreita dokumentissa, jotka liittyv√§t sy√∂tteeseen. Kun tehty, se muuntaa sek√§ sy√∂tevektorin ett√§ dokumenttivektorit tekstiksi ja kuljettaa sen LLM:n l√§pi.

### Tiedonhaku

Tiedonhaku tapahtuu, kun j√§rjestelm√§ yritt√§√§ nopeasti l√∂yt√§√§ dokumentit hakemistosta, jotka t√§ytt√§v√§t hakukriteerit. Hakijan tavoite on saada dokumentit, joita k√§ytet√§√§n kontekstin tarjoamiseen ja LLM:n sitomiseen dataasi.

Tietokannassamme on useita tapoja tehd√§ haku, kuten:

- **Avainsanahaku** - k√§ytet√§√§n tekstihakuihin

- **Semanttinen haku** - k√§ytt√§√§ sanojen semanttista merkityst√§

- **Vektorihaku** - muuntaa dokumentit tekstist√§ vektoriesityksiksi upotusmallien avulla. Haku tehd√§√§n kyselem√§ll√§ dokumentteja, joiden vektoriedustukset ovat l√§himp√§n√§ k√§ytt√§j√§n kysymyst√§.

- **Hybridihaku** - yhdistelm√§ sek√§ avainsana- ett√§ vektorihakua.

Haaste tiedonhaussa tulee, kun tietokannassa ei ole vastaavaa vastausta kyselyyn, j√§rjestelm√§ palauttaa sitten parhaan saatavilla olevan tiedon, kuitenkin voit k√§ytt√§√§ taktiikoita kuten asettaa enimm√§iset√§isyys relevanssille tai k√§ytt√§√§ hybridihakua, joka yhdist√§√§ sek√§ avainsanat ett√§ vektorihakua. T√§ss√§ oppitunnissa k√§yt√§mme hybridihakua, yhdistelm√§√§ sek√§ vektori- ett√§ avainsanahakua. Tallennamme datamme tietokehykseen, jossa on sarakkeita, jotka sis√§lt√§v√§t osat sek√§ upotukset.

### Vektorien samankaltaisuus

Hakija etsii tietokannasta upotuksia, jotka ovat l√§hell√§ toisiaan, l√§hin naapuri, koska ne ovat tekstej√§, jotka ovat samankaltaisia. Skenaariossa, jossa k√§ytt√§j√§ esitt√§√§ kyselyn, se ensin upotetaan, sitten se yhdistet√§√§n samankaltaisiin upotuksiin. Yleinen mittaus, jota k√§ytet√§√§n l√∂yt√§m√§√§n, kuinka samankaltaisia eri vektorit ovat, on kosinivirhe, joka perustuu kahden vektorin v√§liseen kulmaan.

Voimme mitata samankaltaisuutta k√§ytt√§m√§ll√§ muita vaihtoehtoja, kuten Euklidista et√§isyytt√§, joka on suora viiva vektorien p√§√§tepisteiden v√§lill√§, ja pistetuloa, joka mittaa kahden vektorin vastaavien elementtien tuotteiden summaa.

### Hakemisto

Kun teemme tiedonhakua, meid√§n t√§ytyy rakentaa hakemisto tietokannallemme ennen kuin suoritamme haun. Hakemisto tallentaa upotuksemme ja voi nopeasti hakea samankaltaisimmat osat jopa suuressa tietokannassa. Voimme luoda hakemistomme paikallisesti k√§ytt√§m√§ll√§:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Uudelleenj√§rjestely

Kun olet kysellyt tietokantaa, saatat tarvita tulosten lajittelua relevanssin mukaan. Uudelleenj√§rjestely LLM hy√∂dynt√§√§ koneoppimista parantaakseen hakutulosten relevanssia j√§rjest√§m√§ll√§ ne relevantimmista alkaen. K√§ytt√§en Azure AI Searchia, uudelleenj√§rjestely tehd√§√§n automaattisesti sinulle k√§ytt√§en semanttista uudelleenj√§rjestelij√§√§. Esimerkki siit√§, kuinka uudelleenj√§rjestely toimii l√§himpien naapureiden avulla:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Kaiken yhdist√§minen

Viimeinen vaihe on lis√§t√§ LLM mukaan, jotta voimme saada vastauksia, jotka perustuvat dataamme. Voimme toteuttaa sen seuraavasti:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Sovelluksen arviointi

### Arviointimetriikat

- Tarjottujen vastausten laatu varmistaen, ett√§ ne kuulostavat luonnollisilta, sujuvilta ja ihmism√§isilt√§

- Datan perustuvuus: arvioida, onko vastaus tullut toimitetuista dokumenteista

- Relevanssi: arvioida, vastaako vastaus kysymykseen ja liittyyk√∂ se siihen

- Sujuvuus - onko vastaus kieliopillisesti j√§rkev√§

## K√§ytt√∂tapaukset RAG:n (Tiedonhakuun perustuva generointi) ja vektoripohjaisten tietokantojen k√§yt√∂lle

On monia erilaisia k√§ytt√∂tapauksia, joissa funktiokutsut voivat parantaa sovellustasi, kuten:

- Kysymys ja vastaus: yrityksesi datan perustaminen chattiin, jota ty√∂ntekij√§t voivat k√§ytt√§√§ kysymysten esitt√§miseen.

- Suositusj√§rjestelm√§t: jossa voit luoda j√§rjestelm√§n, joka yhdist√§√§ samankaltaisimmat arvot, esim. elokuvat, ravintolat ja paljon muuta.

- Chatbot-palvelut: voit tallentaa chat-historian ja henkil√∂kohtaistaa keskustelun k√§ytt√§j√§n datan perusteella.

- Kuvahaku vektoripohjaisten upotusten perusteella, hy√∂dyllinen kuvatunnistuksessa ja poikkeavuuksien havaitsemisessa.

## Yhteenveto

Olemme k√§sitelleet RAG:n perusalueet datan lis√§√§misest√§ sovellukseen, k√§ytt√§j√§n kyselyyn ja lopputulokseen. RAG:n luomisen yksinkertaistamiseksi voit k√§ytt√§√§ kehyksi√§, kuten Semanti Kernel, Langchain tai Autogen.

## Teht√§v√§

Jatkaaksesi oppimista tiedonhakuun perustuvan generoinnin (RAG) parissa, voit rakentaa:

- Rakenna k√§ytt√∂liittym√§ sovellukselle k√§ytt√§en valitsemaasi kehyst√§

- Hy√∂dynn√§ kehyst√§, joko LangChain tai Semanttinen Kernel, ja luo sovelluksesi uudelleen.

Onnittelut oppitunnin suorittamisesta üëè.

## Oppiminen ei lopu t√§h√§n, jatka matkaa

Oppitunnin suorittamisen j√§lkeen tutustu [Generatiivisen AI:n oppimiskokoelmaamme](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) jatkaaksesi Generatiivisen AI:n tietosi kehitt√§mist√§!

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Pyrimme tarkkuuteen, mutta huomioithan, ett√§ automaattiset k√§√§nn√∂kset saattavat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ ensisijaisena l√§hteen√§. Kriittisen tiedon kohdalla suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ johtuvista v√§√§rink√§sityksist√§ tai virhetulkinnoista.