<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-07-09T16:14:55+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "fi"
}
-->
# Retrieval Augmented Generation (RAG) ja vektoritietokannat

[![Retrieval Augmented Generation (RAG) ja vektoritietokannat](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.fi.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

Hakusovellusten oppitunnilla opimme lyhyesti, miten oma data voidaan integroida suurten kielimallien (LLM) kanssa. T√§ss√§ oppitunnissa sukellamme syvemm√§lle siihen, miten data voidaan perustaa LLM-sovellukseen, prosessin toimintaperiaatteisiin ja datan tallennusmenetelmiin, mukaan lukien sek√§ upotukset ett√§ teksti.

> **Video tulossa pian**

## Johdanto

T√§ss√§ oppitunnissa k√§sittelemme seuraavaa:

- Johdanto RAG:iin, mit√§ se on ja miksi sit√§ k√§ytet√§√§n teko√§lyss√§ (artificial intelligence).

- Ymm√§rrys siit√§, mit√§ vektoritietokannat ovat ja miten luodaan oma tietokanta sovellustamme varten.

- K√§yt√§nn√∂n esimerkki siit√§, miten RAG integroidaan sovellukseen.

## Oppimistavoitteet

Oppitunnin suorittamisen j√§lkeen osaat:

- Selitt√§√§ RAG:n merkityksen datan hakemisessa ja k√§sittelyss√§.

- M√§√§ritt√§√§ RAG-sovelluksen ja perustaa datasi LLM:√§√§n.

- Tehokkaasti integroida RAG ja vektoritietokannat LLM-sovelluksiin.

## Tilanteemme: LLM-malliemme parantaminen omalla datallamme

T√§ss√§ oppitunnissa haluamme lis√§t√§ omat muistiinpanomme koulutusteknologia-startupiin, jotta chatbot saa enemm√§n tietoa eri aiheista. Muistiinpanojen avulla oppijat voivat opiskella paremmin ja ymm√§rt√§√§ eri aiheita, mik√§ helpottaa kokeisiin valmistautumista. Tilanteen luomiseksi k√§yt√§mme:

- `Azure OpenAI:` LLM, jota k√§yt√§mme chatbotin luomiseen

- `AI for beginners' lesson on Neural Networks:` data, johon perustamme LLM:n

- `Azure AI Search` ja `Azure Cosmos DB:` vektoritietokanta datan tallentamiseen ja hakemisto luomiseen

K√§ytt√§j√§t voivat luoda muistiinpanoistaan harjoituskyselyit√§, kertausmuistikortteja ja tiivistelmi√§. Aloitetaan katsomalla, mit√§ RAG on ja miten se toimii:

## Retrieval Augmented Generation (RAG)

LLM-pohjainen chatbot k√§sittelee k√§ytt√§j√§n sy√∂tteit√§ vastauksien luomiseksi. Se on suunniteltu olemaan vuorovaikutteinen ja keskustelemaan monista eri aiheista. Sen vastaukset kuitenkin rajoittuvat annettuun kontekstiin ja sen perustana olevaan koulutusdataan. Esimerkiksi GPT-4:n tiet√§mys kattaa syyskuun 2021 asti, eli se ei tunne t√§m√§n j√§lkeen tapahtuneita asioita. Lis√§ksi LLM:ien koulutusdata ei sis√§ll√§ luottamuksellista tietoa, kuten henkil√∂kohtaisia muistiinpanoja tai yrityksen tuotemanuaalia.

### Miten RAG toimii

![kuva, joka n√§ytt√§√§ miten RAG toimii](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.fi.png)

Oletetaan, ett√§ haluat ottaa k√§ytt√∂√∂n chatbotin, joka luo kyselyit√§ muistiinpanoistasi. Tarvitset yhteyden tietopohjaan. T√§ss√§ RAG astuu kuvaan. RAG toimii seuraavasti:

- **Tietopohja:** Ennen hakua dokumentit t√§ytyy sy√∂tt√§√§ ja esik√§sitell√§, yleens√§ pilkkomalla suuret dokumentit pienempiin osiin, muuntamalla ne tekstin upotuksiksi ja tallentamalla tietokantaan.

- **K√§ytt√§j√§n kysely:** k√§ytt√§j√§ esitt√§√§ kysymyksen

- **Haku:** Kun k√§ytt√§j√§ kysyy, upotusmalli hakee relevanttia tietoa tietopohjasta tarjotakseen lis√§kontekstia, joka liitet√§√§n sy√∂tteeseen.

- **Laajennettu generointi:** LLM parantaa vastaustaan haetun datan perusteella. N√§in vastaus perustuu paitsi esikoulutettuun dataan my√∂s lis√§ttyyn kontekstiin. Haettu data k√§ytet√§√§n LLM:n vastausten rikastamiseen. LLM palauttaa vastauksen k√§ytt√§j√§n kysymykseen.

![kuva, joka n√§ytt√§√§ RAG-arkkitehtuurin](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.fi.png)

RAG-arkkitehtuuri toteutetaan transformereilla, jotka koostuvat kahdesta osasta: enkooderista ja dekooderista. Esimerkiksi kun k√§ytt√§j√§ esitt√§√§ kysymyksen, sy√∂teteksti 'enkoodataan' vektoreiksi, jotka kuvaavat sanojen merkityst√§, ja vektorit 'dekoodataan' dokumenttihakemistoon, joka luo uutta teksti√§ k√§ytt√§j√§n kyselyn perusteella. LLM k√§ytt√§√§ sek√§ enkooderi-dekooderi-mallia tuottaakseen vastauksen.

Kaksi l√§hestymistapaa RAG:n toteutukseen ehdotetun artikkelin [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) mukaan ovat:

- **_RAG-Sequence_** k√§ytt√§√§ haettuja dokumentteja ennustamaan paras mahdollinen vastaus k√§ytt√§j√§n kyselyyn

- **RAG-Token** k√§ytt√§√§ dokumentteja seuraavan tokenin generointiin ja hakee niit√§ vastatakseen k√§ytt√§j√§n kyselyyn

### Miksi k√§ytt√§√§ RAG:ia?

- **Tietosis√§ll√∂n rikkaus:** varmistaa, ett√§ tekstivastaukset ovat ajan tasalla ja ajankohtaisia. Parantaa suorituskyky√§ erityisaloilla p√§√§sem√§ll√§ k√§siksi sis√§iseen tietopohjaan.

- V√§hent√§√§ virheellisi√§ vastauksia hy√∂dynt√§m√§ll√§ **tarkistettavissa olevaa dataa** tietopohjassa k√§ytt√§j√§n kyselyiden kontekstina.

- On **kustannustehokas**, koska se on edullisempaa kuin LLM:n hienos√§√§t√∂.

## Tietopohjan luominen

Sovelluksemme perustuu henkil√∂kohtaiseen dataamme, eli AI For Beginners -kurssin Neuroverkot-oppituntiin.

### Vektoritietokannat

Vektoritietokanta on erikoistunut tietokanta, joka on suunniteltu tallentamaan, hallitsemaan ja hakemaan upotettuja vektoreita. Se tallentaa dokumenttien numeeriset esitykset. Datan pilkkominen numeerisiksi upotuksiksi helpottaa teko√§lyj√§rjestelm√§mme datan ymm√§rt√§mist√§ ja k√§sittely√§.

Tallennamme upotuksemme vektoritietokantoihin, koska LLM:ill√§ on rajoitus sy√∂tteen tokenien m√§√§r√§ss√§. Koska koko upotusta ei voi sy√∂tt√§√§ LLM:√§√§n kerralla, meid√§n t√§ytyy pilkkoa se osiin, ja kun k√§ytt√§j√§ esitt√§√§ kysymyksen, todenn√§k√∂isimm√§t upotukset palautetaan sy√∂tteen mukana. Pilkkominen my√∂s v√§hent√§√§ tokenien m√§√§r√§√§, mik√§ pienent√§√§ kustannuksia.

Suosittuja vektoritietokantoja ovat Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Voit luoda Azure Cosmos DB -mallin Azure CLI:ll√§ seuraavalla komennolla:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist√§ upotuksiin

Ennen datan tallentamista meid√§n t√§ytyy muuntaa se vektoriupotuksiksi. Jos ty√∂skentelet suurten dokumenttien tai pitkien tekstien kanssa, voit pilkkoa ne odotettavien kyselyiden mukaan. Pilkkominen voidaan tehd√§ lause- tai kappaletasolla. Koska pilkkominen perustuu sanojen ymp√§rill√§ olevaan merkitykseen, voit lis√§t√§ pilkkoon my√∂s muuta kontekstia, esimerkiksi dokumentin otsikon tai teksti√§ ennen tai j√§lkeen pilkon. Voit pilkkoa datan seuraavasti:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Kun data on pilkottu, voimme upottaa tekstin eri upotusmalleilla. Joitakin malleja ovat: word2vec, OpenAI:n ada-002, Azure Computer Vision ja monet muut. Mallin valinta riippuu k√§ytett√§vist√§ kielist√§, koodattavan sis√§ll√∂n tyypist√§ (teksti/kuvat/√§√§ni), sy√∂tteen koosta ja upotuksen pituudesta.

Esimerkki upotetusta tekstist√§ OpenAI:n `text-embedding-ada-002` -mallilla on:
![kuva sanan cat upotuksesta](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.fi.png)

## Haku ja vektorihaku

Kun k√§ytt√§j√§ esitt√§√§ kysymyksen, hakija muuntaa sen vektoriksi k√§ytt√§en kyselyenkooderia, jonka j√§lkeen se etsii dokumenttihakemistostamme relevantteja vektoreita, jotka liittyv√§t sy√∂tteeseen. T√§m√§n j√§lkeen sek√§ sy√∂tevektori ett√§ dokumenttivektorit muunnetaan tekstiksi ja sy√∂tet√§√§n LLM:√§√§n.

### Haku

Haku tapahtuu, kun j√§rjestelm√§ yritt√§√§ nopeasti l√∂yt√§√§ hakemistosta dokumentit, jotka t√§ytt√§v√§t hakuehdot. Hakijan tavoitteena on l√∂yt√§√§ dokumentit, joita k√§ytet√§√§n tarjoamaan kontekstia ja perustamaan LLM datallesi.

Tietokannassa hakemiseen on useita tapoja, kuten:

- **Avainsanahaku** ‚Äì k√§ytet√§√§n tekstihakuihin

- **Semanttinen haku** ‚Äì hy√∂dynt√§√§ sanojen merkityst√§

- **Vektorihaku** ‚Äì muuntaa dokumentit tekstist√§ vektoriedustuksiksi upotusmallien avulla. Haku tehd√§√§n kyselyll√§, joka etsii dokumentteja, joiden vektoriesitykset ovat l√§himp√§n√§ k√§ytt√§j√§n kysymyst√§.

- **Hybridihaku** ‚Äì yhdistelm√§ avainsana- ja vektorihakua.

Haasteena haussa on, jos tietokannasta ei l√∂ydy vastaavaa vastausta kyselyyn, j√§rjestelm√§ palauttaa parhaan mahdollisen tiedon. Voit kuitenkin k√§ytt√§√§ keinoja, kuten asettaa maksimiet√§isyyden relevanssille tai k√§ytt√§√§ hybridihakua, joka yhdist√§√§ avainsana- ja vektorihakua. T√§ss√§ oppitunnissa k√§yt√§mme hybridihakua, joka yhdist√§√§ molemmat. Tallennamme datamme dataframeen, jossa on sarakkeet pilkuille ja upotuksille.

### Vektorien samankaltaisuus

Hakija etsii tietopohjasta upotuksia, jotka ovat l√§hell√§ toisiaan, eli l√§himm√§t naapurit, koska ne ovat samankaltaisia tekstej√§. Kun k√§ytt√§j√§ esitt√§√§ kyselyn, se upotetaan ja verrataan samankaltaisiin upotuksiin. Yleisin mittari vektorien samankaltaisuuden arviointiin on kosiniet√§isyys, joka perustuu kahden vektorin v√§liseen kulmaan.

Voimme mitata samankaltaisuutta my√∂s muilla tavoilla, kuten euklidisella et√§isyydell√§, joka on suora viiva vektorien p√§iden v√§lill√§, tai pistetulolla, joka mittaa kahden vektorin vastaavien alkioiden tulon summan.

### Hakemisto

Hakua varten meid√§n t√§ytyy rakentaa hakemisto tietopohjalle ennen haun suorittamista. Hakemisto tallentaa upotuksemme ja pystyy nopeasti hakemaan samankaltaisimmat pilkut, vaikka tietokanta olisi suuri. Voimme luoda hakemistomme paikallisesti seuraavasti:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Uudelleenj√§rjestely

Kun olet hakenut tietokannasta, saatat haluta j√§rjest√§√§ tulokset relevanssin mukaan. Uudelleenj√§rjestelyss√§ LLM hy√∂dynt√§√§ koneoppimista parantaakseen hakutulosten relevanssia j√§rjest√§m√§ll√§ ne t√§rkeimm√§st√§ alkaen. Azure AI Searchissa uudelleenj√§rjestely tehd√§√§n automaattisesti semanttisen uudelleenj√§rjest√§j√§n avulla. Esimerkki uudelleenj√§rjestelyst√§ l√§himpien naapureiden avulla:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Kaiken yhdist√§minen

Viimeinen vaihe on lis√§t√§ LLM mukaan, jotta saamme vastauksia, jotka perustuvat dataamme. Voimme toteuttaa sen seuraavasti:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Sovelluksen arviointi

### Arviointimittarit

- Vastauksien laatu: varmistetaan, ett√§ ne kuulostavat luonnollisilta, sujuvilta ja ihmism√§isilt√§

- Datan perustellisuus: arvioidaan, tuleeko vastaus toimitetuista dokumenteista

- Relevanssi: arvioidaan, vastaako vastaus esitetty√§ kysymyst√§ ja liittyyk√∂ siihen

- Sujuvuus: arvioidaan, onko vastaus kieliopillisesti j√§rkev√§

## K√§ytt√∂tapaukset RAG:ille ja vektoritietokannoille

RAG:ia ja vektoritietokantoja voidaan hy√∂dynt√§√§ monissa eri k√§ytt√∂tapauksissa, kuten:

- Kysymys-vastausj√§rjestelm√§t: yrityksen datan perustaminen chattiin, jota ty√∂ntekij√§t voivat k√§ytt√§√§ kysymyksiin vastaamiseen.

- Suositusj√§rjestelm√§t: j√§rjestelm√§t, jotka l√∂yt√§v√§t samankaltaisimmat arvot, esim. elokuvat, ravintolat ja paljon muuta.

- Chatbot-palvelut: keskusteluhistorian tallentaminen ja keskustelun personointi k√§ytt√§j√§tiedon perusteella.

- Kuvahaku vektoriupotusten avulla, hy√∂dyllinen kuvatunnistuksessa ja poikkeavuuksien havaitsemisessa.

## Yhteenveto

Olemme k√§sitelleet RAG:n perusalueet: datan lis√§√§misen sovellukseen, k√§ytt√§j√§n kyselyn ja vastauksen. RAG:n luomisen helpottamiseksi voit k√§ytt√§√§ kehyksi√§ kuten Semantic Kernel, Langchain tai Autogen.

## Teht√§v√§

Jatka oppimista Retrieval Augmented Generation (RAG) -aiheesta rakentamalla:

- K√§ytt√∂liittym√§ sovellukselle valitsemallasi kehysymp√§rist√∂ll√§

- Hy√∂dynn√§ kehyst√§, joko LangChainia tai Semantic Kernelia, ja rakenna sovelluksesi uudelleen.

Onnittelut oppitunnin suorittamisesta üëè.

## Oppiminen ei lopu t√§h√§n, jatka matkaa

Oppitunnin j√§lkeen tutustu [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) -kokoelmaamme ja jatka Generative AI -osaamisesi kehitt√§mist√§!

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattik√§√§nn√∂ksiss√§ saattaa esiinty√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§iskielell√§ tulee pit√§√§ virallisena l√§hteen√§. T√§rkeiss√§ tiedoissa suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ aiheutuvista v√§√§rinymm√§rryksist√§ tai tulkinnoista.