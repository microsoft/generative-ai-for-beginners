<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2210a0466c812d9defc4df2d9a709ff9",
  "translation_date": "2026-01-18T18:26:12+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "fi"
}
-->
# Hakuavusteinen generointi (Retrieval Augmented Generation, RAG) ja vektoritietokannat

[![Hakuavusteinen generointi (RAG) ja vektoritietokannat](../../../../../translated_images/fi/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Hakusovellusten oppitunnissa opimme lyhyesti, miten omat tietosi voidaan integroida suuriin kielimalleihin (LLM). T√§ss√§ oppitunnissa syvennymme lis√§√§ siihen, miten data voidaan perustaa LLM-sovelluksessasi, prosessin mekanismeihin ja tapoihin tallentaa tietoa, mukaan lukien sis√§√§ntulot ja teksti.

> **Video tulossa pian**

## Johdanto

T√§ss√§ oppitunnissa k√§sittelemme seuraavaa:

- Johdanto RAGiin, mit√§ se on ja miksi sit√§ k√§ytet√§√§n teko√§lyss√§ (AI).

- Ymm√§rrys siit√§, mit√§ vektoritietokannat ovat, ja kuinka luoda sellainen sovellustamme varten.

- K√§yt√§nn√∂n esimerkki siit√§, miten RAG integroidaan sovellukseen.

## Oppimistavoitteet

Oppitunnin suorittamisen j√§lkeen osaat:

- Selitt√§√§ RAGin merkityksen tiedon haussa ja k√§sittelyss√§.

- M√§√§ritt√§√§ RAG-sovelluksen ja perustaa datasi LLM:√§√§n.

- Tehokkaasti integroida RAG ja vektoritietokannat LLM-sovelluksiin.

## Tilanteemme: LLM-mallimme rikastaminen omalla datallamme

T√§ss√§ oppitunnissa haluamme lis√§t√§ omat muistiinpanomme koulutusteknologiayritykseen, jonka avulla chatbot voi saada lis√§√§ tietoa eri aiheista. K√§ytt√§en n√§it√§ muistiinpanoja oppijat pystyv√§t opiskelemaan paremmin ja ymm√§rt√§m√§√§n eri aiheita, mik√§ helpottaa valmistautumista kokeisiin. Luodaksemme t√§m√§n tilanteen k√§yt√§mme:

- `Azure OpenAI:` LLM, jota k√§yt√§mme chatbotin luomiseen

- `AI for beginners' lesson on Neural Networks`: t√§m√§ toimii datana, johon perustamme LLM:n

- `Azure AI Search` ja `Azure Cosmos DB:` vektoritietokanta datan tallentamiseen ja hakuhakemiston luomiseen

K√§ytt√§j√§t voivat luoda harjoituskyselyj√§ muistiinpanoistaan, kertaustikkukortteja ja tiivist√§√§ sis√§lt√∂√§ ytimekk√§iksi yhteenvetoiksi. Aloitetaan katsomalla, mit√§ RAG on ja miten se toimii:

## Hakuavusteinen generointi (RAG)

LLM-pohjainen chatbot k√§sittelee k√§ytt√§j√§n kehotteita luodakseen vastauksia. Se on suunniteltu olemaan vuorovaikutteinen ja k√§sittelem√§√§n erilaisia aiheita. Sen vastaukset rajoittuvat kuitenkin annettuun kontekstiin ja sen perustietoihin. Esimerkiksi GPT-4:ll√§ tiedon katkaisu on syyskuussa 2021, joten se ei tunne t√§m√§n j√§lkeen tapahtuneita asioita. Lis√§ksi LLM:n koulutuksessa k√§ytetty data ei sis√§ll√§ luottamuksellista tietoa, kuten henkil√∂kohtaisia muistiinpanoja tai yrityksen k√§ytt√∂ohjeita.

### Miten RAG toimii

![kuvaus RAGin toiminnasta](../../../../../translated_images/fi/how-rag-works.f5d0ff63942bd3a6.webp)

Oletetaan, ett√§ haluat ottaa k√§ytt√∂√∂n chatbotin, joka luo kyselyit√§ muistiinpanoistasi. Tarvitset t√§ll√∂in yhteyden tietopohjaan. T√§ss√§ vaiheessa RAG astuu kuvaan. RAG toimii seuraavasti:

- **Tietopohja:** Ennen hakua dokumentit on sy√∂tett√§v√§ ja esik√§sitelt√§v√§, yleens√§ suurten dokumenttien pilkkominen pienemmiksi osasiksi, muuttaminen tekstipohjaisiksi upotuksiksi (embedding) ja tallentaminen tietokantaan.

- **K√§ytt√§j√§n kysymys:** k√§ytt√§j√§ esitt√§√§ kysymyksen

- **Haku:** Kun k√§ytt√§j√§ kysyy, upotusmalli hakee tietopohjastamme relevanttia tietoa, jolla rikastetaan pyynt√∂√§.

- **Rikastettu generointi:** LLM parantaa vastaustaan haetun tiedon perusteella. N√§in vastaus ei perustu pelk√§st√§√§n ennakkoon koulutettuun dataan, vaan my√∂s lis√§ttyyn relevanttiin kontekstiin. Hae data k√§ytet√§√§n LLM:n vastausten rikastamiseen. LLM palauttaa vastauksen k√§ytt√§j√§n kysymykseen.

![kuvaus RAG-arkkitehtuurista](../../../../../translated_images/fi/encoder-decode.f2658c25d0eadee2.webp)

RAG-arkkitehtuuri toteutetaan transformer-tekniikalla, joka koostuu kahdesta osasta: kooderista ja purkajasta. Esimerkiksi kun k√§ytt√§j√§ kysyy, sy√∂tett√§v√§ teksti koodataan vektoreiksi, jotka edustavat sanojen merkityst√§, ja vektorit dekoodataan dokumenttihakemistoon ja generoidaan uutta teksti√§ k√§ytt√§j√§n kysymyksen pohjalta. LLM k√§ytt√§√§ sek√§ kooderin ett√§ purkajan mallia vasteen luomiseen.

Kaksi l√§hestymistapaa RAGin toteutukseen ehdotetun tutkielman [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) mukaan ovat:

- **_RAG-Sequence_**, jossa haetuilla dokumenteilla ennustetaan paras mahdollinen vastaus k√§ytt√§j√§n kyselyyn

- **RAG-Token**, jossa dokumentteja k√§ytet√§√§n seuraavan tokenin generointiin, mink√§ j√§lkeen haetaan lis√§tietoja vastauksen muodostamiseksi

### Miksi k√§ytt√§√§ RAG:ia?

- **Tiedon rikkaus:** varmistaa, ett√§ tekstivastaukset ovat ajantasaisia ja relevantteja. Parantaa siten suorituskyky√§ toimialakohtaisissa teht√§viss√§ p√§√§sem√§ll√§ k√§siksi sis√§iseen tietopohjaan.

- V√§hent√§√§ virheellisi√§ tietoja hy√∂dynt√§m√§ll√§ **tarkistettavissa olevaa dataa** tietopohjassa k√§ytt√§j√§n kysymyksen kontekstina.

- On **kustannustehokas**, koska se on edullisempaa verrattuna LLM:n hienos√§√§t√∂√∂n.

## Tutustumme tietopohjan luomiseen

Sovelluksemme perustuu henkil√∂kohtaiseen dataamme eli AI For Beginners -koulutuksen Neuroverkot-oppituntiin.

### Vektoritietokannat

Vektoritietokanta on perinteisest√§ tietokannasta poiketen erikoistunut tietokanta, joka on suunniteltu tallentamaan, hallinnoimaan ja hakemaan upotettuja vektoreita. Se s√§ilytt√§√§ dokumenttien numeeriset esitykset. Datan muuntaminen numeerisiksi upotuksiksi helpottaa teko√§lyj√§rjestelm√§n tiedon ymm√§rt√§mist√§ ja k√§sittely√§.

Tallennamme upotuksemme vektoritietokantoihin, koska LLM:ill√§ on rajoitus sille, kuinka monta tokenia se voi vastaanottaa sy√∂tteen√§. Koska koko upotusta ei voi sy√∂tt√§√§ kerralla, pilkomme ne osiin ja kun k√§ytt√§j√§ kysyy, ne upotukset, jotka parhaiten vastaavat kysymyst√§, palautetaan yhdess√§ kehotteen kanssa. Pilkkominen my√∂s v√§hent√§√§ kustannuksia tokenien m√§√§r√§n suhteen LLM:lle.

Tunnettuja vektoritietokantoja ovat esimerkiksi Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Voit luoda Azure Cosmos DB -mallin Azure CLI:ll√§ seuraavalla komennolla:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist√§ upotuksiin

Ennen datan tallentamista meid√§n tulee muuntaa se vektoriedustuksiin. Jos k√§sittelet suuria dokumentteja tai pitki√§ tekstej√§, voit pilkkoa ne kysymysten odotettavissa olevien aiheiden mukaan. Pilkkominen voidaan tehd√§ lause- tai kappaletasolla. Koska pilkkominen hy√∂dynt√§√§ sanojen ymp√§rist√∂√§, voit lis√§t√§ pilkkoon my√∂s muuta kontekstia, esimerkiksi dokumentin otsikon tai teksti√§ ennen tai j√§lkeen pilkon. Voit pilkkoa tiedon esimerkiksi n√§in:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # Jos viimeinen osa ei saavuttanut v√§himm√§ispituutta, lis√§√§ se kuitenkin
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Kun data on pilkottu, voimme upottaa sen k√§ytt√§en erilaisia upotusmalleja. Joitakin k√§ytett√§viss√§ olevia malleja ovat mm. word2vec, OpenAI:n ada-002, Azure Computer Vision ja monet muut. Mallin valinta riippuu kielest√§, sis√§ll√∂n tyypist√§ (teksti/kuva/√§√§ni), koosta ja upotuksen pituudesta.

Esimerkki OpenAI:n `text-embedding-ada-002`-mallilla upotetusta tekstist√§ on:
![sanasta cat upotuskuva](../../../../../translated_images/fi/cat.74cbd7946bc9ca38.webp)

## Haku ja vektorihaut

Kun k√§ytt√§j√§ esitt√§√§ kysymyksen, hakualgoritmi muuntaa sen vektoriksi k√§ytt√§en kyselyn kooderia, jonka j√§lkeen se etsii dokumenttihakemistostamme relevantit vektorit, jotka liittyv√§t sy√∂tteeseen. Sen j√§lkeen sek√§ sy√∂tevektori ett√§ dokumenttivektorit muutetaan tekstiksi ja sy√∂tet√§√§n LLM:lle.

### Haku

Haku tapahtuu, kun j√§rjestelm√§ yritt√§√§ nopeasti l√∂yt√§√§ hakukriteerit t√§ytt√§vi√§ dokumentteja hakemistosta. Haun tavoitteena on saada dokumentteja, joita k√§ytet√§√§n kontekstin tarjoamiseen ja LLM:n perustamiseen sinun dataasi vasten.

Tietokantahakuja voidaan tehd√§ monella tavalla, kuten:

- **Avainsanahaku** ‚Äì k√§ytet√§√§n tekstihauissa

- **Vektorihaku** ‚Äì muuntaa dokumentit tekstist√§ vektoriesityksiksi upotusmallien avulla, mahdollistaen **semanttisen haun**, joka hakee sanojen merkityksen perusteella. Haku tapahtuu l√∂yt√§m√§ll√§ dokumenttien vektoriesitykset, jotka ovat l√§himp√§n√§ k√§ytt√§j√§n kysymyst√§.

- **Hybridihaku** ‚Äì yhdistelm√§ avainsana- ja vektorihakua.

Haaste hakemisessa syntyy, jos tietokannasta ei l√∂ydy samankaltaista vastausta kyselyyn. J√§rjestelm√§ palauttaa silloin parhaan mahdollisen tiedon, mutta voit k√§ytt√§√§ keinoja, kuten asettaa maksimiet√§isyys merkitykselle tai tehd√§ hybridihaku, joka yhdist√§√§ avainsana- ja vektorihakutoiminnot. T√§ss√§ oppitunnissa k√§yt√§mme hybridihakua, joka on sek√§ vektori- ett√§ avainsanahaku. Tallennamme datamme tietokehykseen, jossa sarakkeissa on sek√§ pilkotut osat ett√§ upotukset.

### Vektoril√§hesyyys

Hakualgoritmi etsii tietokannasta upotuksia, jotka ovat l√§hell√§ toisiaan, eli l√§himm√§t naapurit, koska ne ovat samankaltaisia tekstej√§. Kun k√§ytt√§j√§ tekee kyselyn, se upotetaan ja verrataan samankaltaisiin upotuksiin. Yleisin tapa mitata kahden vektorin samankaltaisuutta on kosinil√§hesyyteen perustuva mittaus, joka mittaa kulmaa vektorien v√§lill√§.

Voimme mitata samankaltaisuutta my√∂s muilla tavoilla, kuten euklidisella et√§isyydell√§, joka mittaa suorimman suoran pisteiden v√§lill√§, tai pistetulolla, joka mittaa kahden vektorin vastaavien alkioiden tulosten summan.

### Hakemisto

Hakua varten meid√§n tulee rakentaa hakemisto tietopohjalle ennen haun tekemist√§. Hakemisto tallentaa upotuksemme ja pystyy nopeasti hakemaan l√§himm√§t osat suuristakin tietokannoista. Voimme luoda hakemistomme paikallisesti n√§in:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Luo hakemisto
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# Indeksin kyselyyn voit k√§ytt√§√§ kneighbors-metodia
distances, indices = nbrs.kneighbors(embeddings)
```

### Uudelleenj√§rjest√§minen

Kun olet kysellyt tietokantaa, saatat haluta j√§rjest√§√§ tulokset merkityksellisyyden mukaan. Uudelleenj√§rjestelyss√§ LLM hy√∂dynt√§√§ koneoppimista hakutulosten relevanttiuden parantamiseksi ja j√§rjest√§√§ ne arvokkaimmasta eteenp√§in. Azure AI Search k√§ytt√§√§ automaattista semanttista uudelleenj√§rjest√§j√§√§. Esimerkki uudelleenj√§rjestelyn toiminnasta k√§ytt√§en l√§himpi√§ naapureita:

```python
# Etsi samankaltaisimmat asiakirjat
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Tulosta samankaltaisimmat asiakirjat
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Kaiken yhdist√§minen

Viimeinen vaihe on liitt√§√§ LLM mukaan, jotta saamme vastaukset, jotka perustuvat dataamme. Voimme toteuttaa sen n√§in:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Muunna kysymys kyselyvektoriksi
    query_vector = create_embeddings(user_input)

    # Etsi samankaltaisimmat asiakirjat
    distances, indices = nbrs.kneighbors([query_vector])

    # lis√§√§ asiakirjat kyselyyn kontekstin tarjoamiseksi
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # yhdist√§ historia ja k√§ytt√§j√§n sy√∂te
    history.append(user_input)

    # luo viestiobjekti
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # k√§yt√§ keskustelun t√§ydent√§mist√§ vastauksen luomiseen
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Sovelluksen arviointi

### Arviointimittarit

- Vastauksien laatu: varmista, ett√§ ne kuulostavat luonnollisilta, sujuvilta ja ihmism√§isilt√§.

- Datan perusteltavuus: arvioi, onko vastaus per√§isin toimitetuista dokumenteista.

- Relevanssi: arvioi, vastaako vastaus esitettyyn kysymykseen ja liittyyk√∂ siihen.

- Sujuvuus: tarkastellaan, onko vastaus kieliopillisesti j√§rkev√§.

## K√§ytt√∂tapauksia RAGin ja vektoritietokantojen hy√∂dynt√§miseen

Funktiokutsut voivat parantaa sovellustasi monissa eri tilanteissa, kuten:

- Kysymys-vastaus -palvelu: perusta yrityksesi data keskusteluun, johon ty√∂ntekij√§t voivat esitt√§√§ kysymyksi√§.

- Suositusj√§rjestelm√§t: voit luoda j√§rjestelm√§n, joka l√∂yt√§√§ samankaltaisimmat arvot, esimerkiksi elokuvat, ravintolat ja paljon muuta.

- Chatbot-palvelut: voit tallentaa keskusteluhistorian ja personoida keskustelua k√§ytt√§j√§tietoon perustuen.

- Kuvahaku vektoripohjaisten upotusten avulla, hy√∂dyllinen kuvatunnistuksessa ja poikkeamien havaitsemisessa.

## Yhteenveto

Olemme k√§yneet l√§pi RAGin perusalueet, oman datan lis√§√§misest√§ sovellukseen, k√§ytt√§j√§n kyselyn k√§sittelyyn ja vastauksen muodostamiseen. RAGin luomisen helpottamiseksi voi k√§ytt√§√§ kehyksi√§, kuten Semantic Kernel, Langchain tai Autogen.

## Teht√§v√§

Jatka hakuvahvistetun generoinnin (RAG) opiskelua rakentamalla:

- Luo sovellukselle k√§ytt√∂liittym√§ haluamallasi kehitysymp√§rist√∂ll√§.

- Hy√∂dynn√§ kehyst√§, joko LangChain tai Semantic Kernel, ja tee sovelluksesi uudelleen.

Onnittelut oppitunnin suorittamisesta üëè.

## Oppiminen ei lopu t√§h√§n, jatka matkaasi

Oppitunnin j√§lkeen tutustu [Generatiivisen teko√§lyn oppimiskokoelmaamme](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) jatkaaksesi generatiivisen teko√§lyn osaamisesi kehitt√§mist√§!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Pyrimme tarkkuuteen, mutta huomioithan, ett√§ automaattik√§√§nn√∂ksiss√§ saattaa esiinty√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§inen asiakirja sen alkuper√§isell√§ kielell√§ on virallinen l√§hde. T√§rkeit√§ tietoja varten suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ aiheutuvista v√§√§rinymm√§rryksist√§ tai tulkinnoista.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->