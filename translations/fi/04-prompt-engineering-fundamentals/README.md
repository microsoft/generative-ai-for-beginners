<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T15:48:21+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "fi"
}
-->
# Prompt Engineering - Perusteet

## Johdanto

T√§ss√§ moduulissa k√§sitell√§√§n keskeisi√§ k√§sitteit√§ ja tekniikoita tehokkaiden kehotteiden luomiseksi generatiivisissa teko√§lymalleissa. Tapa, jolla kirjoitat kehotteesi LLM:lle, on my√∂s t√§rke√§. Huolellisesti laadittu kehotus voi parantaa vastausten laatua. Mutta mit√§ tarkalleen ottaen tarkoittavat termit _kehotus_ ja _kehotussuunnittelu_? Ja miten voin parantaa LLM:lle l√§hett√§m√§√§ni kehotteen _sis√§lt√∂√§_? N√§ihin kysymyksiin pyrimme vastaamaan t√§ss√§ ja seuraavassa luvussa.

_Generatiivinen teko√§ly_ kykenee luomaan uutta sis√§lt√∂√§ (esim. teksti√§, kuvia, √§√§nt√§, koodia jne.) k√§ytt√§j√§n pyynt√∂jen perusteella. T√§m√§ saavutetaan _laajojen kielimallien_ avulla, kuten OpenAI:n GPT-sarjan ("Generative Pre-trained Transformer") avulla, jotka on koulutettu k√§ytt√§m√§√§n luonnollista kielt√§ ja koodia.

K√§ytt√§j√§t voivat nyt olla vuorovaikutuksessa n√§iden mallien kanssa tutuilla tavoilla, kuten chatin avulla, ilman teknist√§ osaamista tai koulutusta. Mallit ovat _kehotuspohjaisia_ - k√§ytt√§j√§t l√§hett√§v√§t tekstisy√∂tteen (kehotus) ja saavat takaisin teko√§lyn vastauksen (t√§ydent√§minen). He voivat sitten "keskustella teko√§lyn kanssa" iteratiivisesti, monikierroksisissa keskusteluissa, hienos√§√§t√§en kehotettaan, kunnes vastaus vastaa heid√§n odotuksiaan.

"Kehotteet" ovat nyt ensisijainen _ohjelmointirajapinta_ generatiivisille teko√§lysovelluksille, kertoen malleille, mit√§ tehd√§ ja vaikuttaen palautettujen vastausten laatuun. "Kehotussuunnittelu" on nopeasti kasvava tutkimusalue, joka keskittyy kehotteiden _suunnitteluun ja optimointiin_ tuottamaan johdonmukaisia ja laadukkaita vastauksia laajassa mittakaavassa.

## Oppimistavoitteet

T√§ss√§ oppitunnissa opimme, mit√§ kehotussuunnittelu on, miksi se on t√§rke√§√§ ja miten voimme luoda tehokkaampia kehotteita tietylle mallille ja sovellustavoitteelle. Ymm√§rr√§mme kehotussuunnittelun keskeiset k√§sitteet ja parhaat k√§yt√§nn√∂t - ja opimme interaktiivisesta Jupyter Notebooks -"hiekkalaatikko" -ymp√§rist√∂st√§, jossa voimme n√§hd√§ n√§m√§ k√§sitteet sovellettuna todellisiin esimerkkeihin.

Oppitunnin lopussa pystymme:

1. Selitt√§m√§√§n, mit√§ kehotussuunnittelu on ja miksi se on t√§rke√§√§.
2. Kuvailemaan kehotteen osat ja niiden k√§ytt√∂tavat.
3. Oppimaan parhaat k√§yt√§nn√∂t ja tekniikat kehotussuunnitteluun.
4. Soveltamaan opittuja tekniikoita todellisiin esimerkkeihin k√§ytt√§en OpenAI-p√§√§tepistett√§.

## Keskeiset termit

Kehotussuunnittelu: K√§yt√§nt√∂ suunnitella ja hienos√§√§t√§√§ sy√∂tteit√§ ohjaamaan teko√§lymalleja tuottamaan haluttuja tuloksia.
Tokenisointi: Prosessi, jossa teksti muunnetaan pienemmiksi yksik√∂iksi, joita kutsutaan tokeneiksi, joita malli voi ymm√§rt√§√§ ja k√§sitell√§.
Ohjeistuksella hienos√§√§detyt LLM:t: Laajennetut kielimallit (LLM:t), joita on hienos√§√§detty erityisill√§ ohjeilla parantamaan niiden vastausten tarkkuutta ja merkityksellisyytt√§.

## Oppimishiekkalaatikko

Kehotussuunnittelu on t√§ll√§ hetkell√§ enemm√§n taidetta kuin tiedett√§. Paras tapa parantaa intuitiotamme siit√§ on _harjoitella enemm√§n_ ja omaksua kokeilu- ja erehdysl√§hestymistapa, joka yhdist√§√§ sovellusalueen asiantuntemuksen suositeltuihin tekniikoihin ja mallikohtaisiin optimointeihin.

T√§m√§n oppitunnin mukana tuleva Jupyter Notebook tarjoaa _hiekkalaatikko_ -ymp√§rist√∂n, jossa voit kokeilla oppimaasi - joko matkan varrella tai osana koodin haasteita lopussa. Harjoitusten suorittamiseen tarvitset:

1. **Azure OpenAI API -avain** - palvelup√§√§tepiste k√§ytt√∂√∂notetulle LLM:lle.
2. **Python-ajonaika** - jossa Notebook voidaan suorittaa.
3. **Paikalliset ymp√§rist√∂muuttujat** - _suorita [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) vaiheet nyt valmistautuaksesi_.

Notebook sis√§lt√§√§ _aloitus_ -harjoituksia - mutta sinua kannustetaan lis√§√§m√§√§n omia _Markdown_ (kuvaus) ja _Code_ (kehotuspyynn√∂t) osioita kokeillaksesi enemm√§n esimerkkej√§ tai ideoita - ja kehitt√§√§ksesi intuitiotasi kehotussuunnittelussa.

## Kuvitettu opas

Haluatko saada yleiskuvan siit√§, mit√§ t√§m√§ oppitunti kattaa ennen kuin sukellat sis√§√§n? Tutustu t√§h√§n kuvitettuun oppaaseen, joka antaa sinulle k√§sityksen t√§rkeimmist√§ aiheista, joita k√§sitell√§√§n, ja keskeisist√§ havainnoista, joita sinun tulisi pohtia kussakin niist√§. Oppitunnin tiekartta vie sinut ydinajatusten ja haasteiden ymm√§rt√§misest√§ niiden k√§sittelyyn asiaankuuluvilla kehotussuunnittelutekniikoilla ja parhailla k√§yt√§nn√∂ill√§. Huomaa, ett√§ t√§m√§n oppaan "Edistyneet tekniikat" -osio viittaa seuraavan luvun sis√§lt√∂√∂n t√§ss√§ opetussuunnitelmassa.

## Startup-yrityksemme

Keskustellaan nyt siit√§, miten _t√§m√§ aihe_ liittyy startup-yrityksemme teht√§v√§√§n [tuoda teko√§lyinnovaatioita koulutukseen](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Haluamme rakentaa teko√§lypohjaisia sovelluksia _henkil√∂kohtaiseen oppimiseen_ - joten mietit√§√§n, miten eri k√§ytt√§j√§t sovelluksessamme saattavat "suunnitella" kehotteita:

- **Yll√§pit√§j√§t** saattavat pyyt√§√§ teko√§ly√§ _analysoimaan opetussuunnitelman tietoja katvealueiden tunnistamiseksi_. Teko√§ly voi tiivist√§√§ tulokset tai visualisoida ne koodin avulla.
- **Opettajat** saattavat pyyt√§√§ teko√§ly√§ _luomaan oppituntisuunnitelman kohdeyleis√∂lle ja aiheelle_. Teko√§ly voi rakentaa henkil√∂kohtaisen suunnitelman m√§√§ritellyss√§ muodossa.
- **Oppilaat** saattavat pyyt√§√§ teko√§ly√§ _opettamaan heit√§ vaikeassa aiheessa_. Teko√§ly voi nyt opastaa oppilaita oppitunneilla, vihjeill√§ ja esimerkeill√§, jotka on r√§√§t√§l√∂ity heid√§n tasolleen.

T√§m√§ on vain j√§√§vuoren huippu. Tutustu [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - avoimen l√§hdekoodin kehotekirjastoon, jonka ovat kuratoineet koulutuksen asiantuntijat - saadaksesi laajemman k√§sityksen mahdollisuuksista! _Kokeile ajaa joitain n√§ist√§ kehotteista hiekkalaatikossa tai k√§ytt√§m√§ll√§ OpenAI Playgroundia n√§hd√§ksesi, mit√§ tapahtuu!_

## Mit√§ on kehotussuunnittelu?

Aloitimme t√§m√§n oppitunnin m√§√§rittelem√§ll√§ **kehotussuunnittelun** prosessiksi, jossa _suunnitellaan ja optimoidaan_ tekstisy√∂tteit√§ (kehotteita) tuottamaan johdonmukaisia ja laadukkaita vastauksia (t√§ydent√§misi√§) tietylle sovellustavoitteelle ja mallille. Voimme ajatella t√§t√§ kaksivaiheisena prosessina:

- _suunnitellaan_ alkuper√§inen kehotus tietylle mallille ja tavoitteelle
- _hienos√§√§det√§√§n_ kehotusta iteratiivisesti parantamaan vastauksen laatua

T√§m√§ on v√§ltt√§m√§tt√§ kokeilu- ja erehdysprosessi, joka vaatii k√§ytt√§j√§n intuitiota ja vaivann√§k√∂√§ optimaalisten tulosten saavuttamiseksi. Miksi se sitten on t√§rke√§√§? Vastaamme t√§h√§n kysymykseen ymm√§rt√§m√§ll√§ ensin kolme k√§sitett√§:

- _Tokenisointi_ = miten malli "n√§kee" kehotteen
- _Perus-LLM:t_ = miten perusmalli "k√§sittelee" kehotteen
- _Ohjeistuksella hienos√§√§detyt LLM:t_ = miten malli voi nyt n√§hd√§ "teht√§v√§t"

### Tokenisointi

LLM n√§kee kehotteet _tokenien sarjana_, jossa eri mallit (tai mallin versiot) voivat tokenisoida saman kehotteen eri tavoin. Koska LLM:t on koulutettu tokeneilla (eik√§ raakatekstill√§), kehotteiden tokenisoinnin tapa vaikuttaa suoraan tuotetun vastauksen laatuun.

Jos haluat saada k√§sityksen tokenisoinnin toiminnasta, kokeile ty√∂kaluja, kuten [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst). Kopioi kehotteesi - ja katso, miten se muunnetaan tokeneiksi, kiinnitt√§en huomiota siihen, miten v√§lily√∂nnit ja v√§limerkit k√§sitell√§√§n. Huomaa, ett√§ t√§m√§ esimerkki n√§ytt√§√§ vanhemman LLM:n (GPT-3) - joten kokeilemalla t√§t√§ uudemmalla mallilla voi tuottaa erilaisen tuloksen.

### K√§site: Perusmallit

Kun kehotus on tokenisoitu, "Perus-LLM":n (tai perusmallin) ensisijainen teht√§v√§ on ennustaa token kyseisess√§ sarjassa. Koska LLM:t on koulutettu massiivisilla tekstidatakoosteilla, niill√§ on hyv√§ k√§sitys tokenien v√§lisist√§ tilastollisista suhteista ja ne voivat tehd√§ ennusteen luottavaisesti. Huomaa, ett√§ ne eiv√§t ymm√§rr√§ sanojen _merkityst√§_ kehotteessa tai tokenissa; ne vain n√§kev√§t kuvion, jonka ne voivat "t√§ydent√§√§" seuraavalla ennusteellaan. Ne voivat jatkaa ennustamista, kunnes k√§ytt√§j√§ keskeytt√§√§ ne tai jokin ennalta m√§√§ritelty ehto t√§yttyy.

Haluatko n√§hd√§, miten kehotepohjainen t√§ydent√§minen toimii? Sy√∂t√§ yll√§ oleva kehotus Azure OpenAI Studion [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) oletusasetuksilla. J√§rjestelm√§ on konfiguroitu k√§sittelem√§√§n kehotteita tiedonpyynt√∂in√§ - joten sinun pit√§isi n√§hd√§ t√§ydent√§minen, joka t√§ytt√§√§ t√§m√§n kontekstin.

Mutta ent√§ jos k√§ytt√§j√§ halusi n√§hd√§ jotain erityist√§, joka t√§ytt√§√§ jonkin kriteerin tai teht√§v√§n tavoitteen? T√§ss√§ kohtaa _ohjeistuksella hienos√§√§detyt_ LLM:t tulevat kuvaan.

### K√§site: Ohjeistuksella hienos√§√§detyt LLM:t

[Ohjeistuksella hienos√§√§detty LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) alkaa perusmallista ja hienos√§√§t√§√§ sit√§ esimerkkien tai sy√∂te/vastausparien (esim. monikierroksisten "viestien") avulla, jotka voivat sis√§lt√§√§ selkeit√§ ohjeita - ja teko√§lyn vastaus yritt√§√§ noudattaa kyseist√§ ohjetta.

T√§m√§ k√§ytt√§√§ tekniikoita, kuten vahvistusoppimista ihmisen palautteen avulla (RLHF), jotka voivat kouluttaa mallia _seuraamaan ohjeita_ ja _oppimaan palautteesta_, jotta se tuottaa vastauksia, jotka soveltuvat paremmin k√§yt√§nn√∂n sovelluksiin ja ovat merkityksellisempi√§ k√§ytt√§j√§n tavoitteille.

Kokeillaan sit√§ - palataan yll√§ olevaan kehotteeseen, mutta nyt muutetaan _j√§rjestelm√§viesti_ antamaan seuraava ohje kontekstina:

> _Tiivist√§ sinulle annettu sis√§lt√∂ toisen luokan oppilaalle. Pid√§ tulos yhdess√§ kappaleessa, jossa on 3-5 kohtaa._

N√§etk√∂, miten tulos on nyt hienos√§√§detty heijastamaan haluttua tavoitetta ja muotoa? Opettaja voi nyt suoraan k√§ytt√§√§ t√§t√§ vastausta kyseisen luokan dioissa.

## Miksi tarvitsemme kehotussuunnittelua?

Nyt kun tied√§mme, miten LLM:t k√§sittelev√§t kehotteita, keskustellaan _miksi_ tarvitsemme kehotussuunnittelua. Vastaus l√∂ytyy siit√§, ett√§ nykyiset LLM:t aiheuttavat useita haasteita, jotka tekev√§t _luotettavien ja johdonmukaisten t√§ydennysten_ saavuttamisesta haastavampaa ilman kehotteen rakentamiseen ja optimointiin panostamista. Esimerkiksi:

1. **Mallien vastaukset ovat stokastisia.** _Sama kehotus_ tuottaa todenn√§k√∂isesti erilaisia vastauksia eri malleilla tai malliversioilla. Ja se voi jopa tuottaa erilaisia tuloksia _samalla mallilla_ eri aikoina. _Kehotussuunnittelutekniikoilla voimme minimoida n√§it√§ vaihteluita tarjoamalla parempia suojakaiteita_.

2. **Mallit voivat sepitt√§√§ vastauksia.** Mallit on esikoulutettu _laajoilla mutta rajallisilla_ tietokokonaisuuksilla, mik√§ tarkoittaa, ett√§ niilt√§ puuttuu tiet√§mys koulutuksen ulkopuolisista k√§sitteist√§. T√§m√§n seurauksena ne voivat tuottaa t√§ydennyksi√§, jotka ovat ep√§tarkkoja, kuvitteellisia tai suoraan ristiriidassa tunnettujen faktojen kanssa. _Kehotussuunnittelutekniikoilla autamme k√§ytt√§ji√§ tunnistamaan ja lievent√§m√§√§n t√§llaisia sepityksi√§ esim. pyyt√§m√§ll√§ teko√§lylt√§ viittauksia tai perusteluja_.

3. **Mallien kyvyt vaihtelevat.** Uudemmilla malleilla tai mallisukupolvilla on rikkaampia kykyj√§, mutta ne tuovat my√∂s ainutlaatuisia omituisuuksia ja kompromisseja kustannuksissa ja monimutkaisuudessa. _Kehotussuunnittelulla voimme kehitt√§√§ parhaita k√§yt√§nt√∂j√§ ja ty√∂nkulkuja, jotka abstrahoivat erot ja mukautuvat mallikohtaisiin vaatimuksiin skaalautuvalla, saumattomalla tavalla_.

Katsotaanpa t√§t√§ toiminnassa OpenAI:n tai Azure OpenAI:n Playgroundissa:

- K√§yt√§ samaa kehotetta eri LLM-j√§rjestelmiss√§ (esim. OpenAI, Azure OpenAI, Hugging Face) - n√§itk√∂ vaihteluita?
- K√§yt√§ samaa kehotetta toistuvasti _samassa_ LLM-j√§rjestelm√§ss√§ (esim. Azure OpenAI Playground) - miten n√§m√§ vaihtelut erosivat?

### Sepitysten esimerkki

T√§ss√§ kurssissa k√§yt√§mme termi√§ **"sepitys"** viittaamaan ilmi√∂√∂n, jossa LLM:t joskus tuottavat tosiasiallisesti virheellist√§ tietoa koulutuksen rajoitusten tai muiden rajoitteiden vuoksi. Saatat my√∂s olla kuullut t√§t√§ kutsuttavan _"hallusinaatioiksi"_ suosituissa artikkeleissa tai tutkimuspapereissa. Suosittelemme kuitenkin vahvasti k√§ytt√§m√§√§n termi√§ _"sepitys"_ niin, ettemme vahingossa inhimillist√§isi k√§ytt√§ytymist√§ antamalla koneohjatulle tulokselle ihmism√§ist√§ ominaisuutta. T√§m√§ my√∂s vahvistaa [Vastuullisen teko√§lyn ohjeita](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) terminologian n√§k√∂kulmasta, poistamalla termej√§, joita saatetaan pit√§√§ loukkaavina tai ep√§inklusiivisina joissakin yhteyksiss√§.

Haluatko saada k√§sityksen siit√§, miten sepitykset toimivat? Mieti kehotetta, joka ohjeistaa teko√§ly√§ tuottamaan sis√§lt√∂√§ olemattomasta aiheesta (jotta se ei l√∂ydy koulutusaineistosta). Esimerkiksi - kokeilin t√§t√§ kehotetta:

> **Kehotus:** luo oppituntisuunnitelma Marsin sodasta vuodelta 2076.

Verkkohaku n√§ytti minulle, ett√§ oli olemassa fiktiivisi√§ kertomuksia (esim. televisiosarjoja tai kirjoja) Marsin sodista - mutta ei vuodelta 2076. J√§rki my√∂s kertoo meille, ett√§ vuosi 2076 on _tulevaisuudessa_ ja siten, sit√§ ei voida liitt√§√§ todelliseen tapahtumaan.

Mit√§ tapahtuu, kun ajamme t√§m√§n kehotteen eri LLM-tarjoajilla?

> **Vastaus 1**: OpenAI Playground (GPT-35)

> **Vastaus 2**: Azure OpenAI Playground (GPT-35)

> **Vastaus 3**: Hugging Face Chat Playground (LLama-2)

Kuten odotettiin, jokainen malli (
Lopulta mallipohjien todellinen arvo piilee kyvyss√§ luoda ja julkaista _kehotekirjastoja_ vertikaalisille sovellusalueille - joissa kehotemalli on nyt _optimoitu_ heijastamaan sovelluskohtaisia konteksteja tai esimerkkej√§, jotka tekev√§t vastauksista k√§ytt√§j√§yleis√∂lle osuvampia ja tarkempia. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) -tietovarasto on hyv√§ esimerkki t√§st√§ l√§hestymistavasta, kuratoiden kirjaston kehotteita koulutusalueelle, keskittyen keskeisiin tavoitteisiin kuten oppituntien suunnittelu, opetussuunnitelman suunnittelu, opiskelijoiden ohjaus jne.

## Tukisis√§lt√∂

Jos ajattelemme kehotteen rakentamista sis√§lt√§v√§n ohjeen (teht√§v√§) ja kohteen (ensisijainen sis√§lt√∂), niin _toissijainen sis√§lt√∂_ on kuin lis√§konteksti, jonka annamme **vaikuttaaksemme jollain tavalla tulokseen**. Se voi olla s√§√§t√∂parametreja, muotoiluohjeita, aiheluokituksia jne., jotka voivat auttaa mallia _r√§√§t√§l√∂im√§√§n_ vastauksensa vastaamaan haluttuja k√§ytt√§j√§n tavoitteita tai odotuksia.

Esimerkiksi: Annetaan kurssiluettelo, jossa on laaja metatieto (nimi, kuvaus, taso, metatietotunnisteet, opettaja jne.) kaikista opetussuunnitelman kursseista:

- voimme m√§√§ritell√§ ohjeen "tiivist√§√§ syksyn 2023 kurssiluettelo"
- voimme k√§ytt√§√§ ensisijaista sis√§lt√∂√§ antaaksemme muutamia esimerkkej√§ halutusta tuloksesta
- voimme k√§ytt√§√§ toissijaista sis√§lt√∂√§ tunnistaaksemme viisi kiinnostavinta "tunnistetta".

Nyt malli voi tarjota yhteenvedon muodossa, joka on esitetty muutamissa esimerkeiss√§ - mutta jos tuloksessa on useita tunnisteita, se voi priorisoida toissijaisessa sis√§ll√∂ss√§ tunnistetut viisi tunnistetta.

---

<!--
OPETUSMALLI:
T√§m√§n yksik√∂n tulisi kattaa ydinajatus #1.
Vahvista konsepti esimerkeill√§ ja viitteill√§.

KONSEPTI #3:
Kehotetekniikat.
Mitk√§ ovat perusmenetelmi√§ kehotetekniikoissa?
Havainnollista se harjoituksilla.
-->

## Kehotetekniikoiden parhaat k√§yt√§nn√∂t

Nyt kun tied√§mme, kuinka kehotteita voidaan _rakentaa_, voimme alkaa mietti√§, kuinka _suunnitella_ niit√§ heijastamaan parhaita k√§yt√§nt√∂j√§. Voimme ajatella t√§t√§ kahdessa osassa - oikean _ajattelutavan_ omaksuminen ja oikeiden _tekniikoiden_ soveltaminen.

### Kehotetekniikoiden ajattelutapa

Kehotetekniikka on kokeilu- ja erehdysprosessi, joten pid√§ mieless√§ kolme laajaa ohjaavaa tekij√§√§:

1. **Toimialan ymm√§rt√§minen on t√§rke√§√§.** Vastausten tarkkuus ja osuvuus ovat _toimialan_ funktio, jossa sovellus tai k√§ytt√§j√§ toimii. K√§yt√§ intuitiotasi ja toimialaosaamistasi **r√§√§t√§l√∂id√§ksesi tekniikoita** edelleen. M√§√§rit√§ esimerkiksi _toimialakohtaisia persoonallisuuksia_ j√§rjestelm√§kehotteissasi tai k√§yt√§ _toimialakohtaisia malleja_ k√§ytt√§j√§kehotteissasi. Tarjoa toissijaista sis√§lt√∂√§, joka heijastaa toimialakohtaisia konteksteja, tai k√§yt√§ _toimialakohtaisia vihjeit√§ ja esimerkkej√§_ ohjataksesi mallia kohti tuttuja k√§ytt√∂tapoja.

2. **Mallin ymm√§rt√§minen on t√§rke√§√§.** Tied√§mme, ett√§ mallit ovat luonteeltaan satunnaisia. Mutta mallien toteutukset voivat my√∂s vaihdella k√§ytt√§m√§ns√§ harjoitusdatan (ennalta koulutettu tieto), tarjoamiensa ominaisuuksien (esim. API:n tai SDK:n kautta) ja sen sis√§ll√∂n tyypin mukaan, johon ne on optimoitu (esim. koodi vs. kuvat vs. teksti). Ymm√§rr√§ k√§ytt√§m√§si mallin vahvuudet ja rajoitukset, ja k√§yt√§ t√§t√§ tietoa _priorisoidaksesi teht√§vi√§_ tai rakentaaksesi _r√§√§t√§l√∂ityj√§ malleja_, jotka on optimoitu mallin ominaisuuksille.

3. **Iteraatio ja validointi ovat t√§rkeit√§.** Mallit kehittyv√§t nopeasti, ja niin kehittyv√§t my√∂s kehotetekniikat. Toimiala-asiantuntijana sinulla voi olla muuta kontekstia tai kriteerej√§ _sinun_ erityissovelluksellesi, joka ei v√§ltt√§m√§tt√§ koske laajempaa yhteis√∂√§. K√§yt√§ kehotetekniikkaty√∂kaluja ja -menetelmi√§ "aloittaaksesi" kehotteen rakentamisen, sitten toista ja validoi tulokset k√§ytt√§en omaa intuitiotasi ja toimialaosaamistasi. Tallenna oivalluksesi ja luo **tietokanta** (esim. kehotekirjastot), jota muut voivat k√§ytt√§√§ uutena l√§ht√∂kohtana nopeampiin iterointeihin tulevaisuudessa.

## Parhaat k√§yt√§nn√∂t

Katsotaanpa nyt yleisi√§ parhaita k√§yt√§nt√∂j√§, joita [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) ja [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) -k√§yt√§nn√∂n harjoittajat suosittelevat.

| Mit√§                               | Miksi                                                                                                                                                                                                                                               |
| :--------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Arvioi uusimmat mallit.            | Uudet mallisukupolvet todenn√§k√∂isesti tarjoavat parannettuja ominaisuuksia ja laatua - mutta voivat my√∂s aiheuttaa korkeampia kustannuksia. Arvioi niiden vaikutus ja tee sitten siirtym√§p√§√§t√∂kset.                                                 |
| Erottele ohjeet ja konteksti       | Tarkista, m√§√§ritteleek√∂ mallisi/toimittajasi _erottimia_ ohjeiden, ensisijaisen ja toissijaisen sis√§ll√∂n selke√§mp√§√§n erottamiseen. T√§m√§ voi auttaa malleja kohdistamaan painotukset tarkemmin tokeneihin.                                            |
| Ole tarkka ja selke√§               | Anna enemm√§n yksityiskohtia halutusta kontekstista, tuloksesta, pituudesta, muodosta, tyylist√§ jne. T√§m√§ parantaa sek√§ vastausten laatua ett√§ johdonmukaisuutta. Tallenna reseptit uudelleenk√§ytett√§viin malleihin.                                 |
| Ole kuvaileva, k√§yt√§ esimerkkej√§   | Mallit voivat vastata paremmin "n√§yt√§ ja kerro" -l√§hestymistapaan. Aloita `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an ‚Äúout‚Äù           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` -arvoilla. Palaa [Learning Sandbox -osioon](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) oppiaksesi lis√§√§.

### Seuraavaksi avaa Jupyter Notebook

- Valitse ajonaikainen ydin. Jos k√§yt√§t vaihtoehtoja 1 tai 2, valitse yksinkertaisesti oletusarvoinen Python 3.10.x -ydin, jonka dev-kontti tarjoaa.

Olet valmis suorittamaan harjoitukset. Huomaa, ett√§ t√§√§ll√§ ei ole _oikeita tai v√§√§ri√§_ vastauksia - vain vaihtoehtojen tutkimista kokeilemalla ja erehdyksell√§ ja intuition rakentamista siit√§, mik√§ toimii tietylle mallille ja sovellusalueelle.

_T√§st√§ syyst√§ t√§ss√§ oppitunnissa ei ole koodiratkaisuosuuksia. Sen sijaan Notebookissa on Markdown-soluja, jotka on otsikoitu "My Solution:", ja ne n√§ytt√§v√§t yhden esimerkkituloksen viitteeksi._

<!--
OPETUSMALLI:
P√§√§t√§ osio yhteenvedolla ja resursseilla itseohjautuvaan oppimiseen.
-->

## Tietojen tarkistus

Mik√§ seuraavista on hyv√§ kehotus, joka noudattaa kohtuullisia parhaita k√§yt√§nt√∂j√§?

1. N√§yt√§ minulle kuva punaisesta autosta
2. N√§yt√§ minulle kuva punaisesta autosta, merkilt√§√§n Volvo ja malliltaan XC90, joka on pys√§k√∂ity jyrk√§nteen reunalle auringon laskiessa
3. N√§yt√§ minulle kuva punaisesta autosta, merkilt√§√§n Volvo ja malliltaan XC90

A: 2, se on paras kehotus, koska se antaa yksityiskohtia "mist√§" ja menee yksityiskohtiin (ei vain mik√§ tahansa auto, vaan tietty merkki ja malli) ja se my√∂s kuvailee kokonaisasetelman. 3 on seuraavaksi paras, koska se sis√§lt√§√§ my√∂s paljon kuvailua.

## üöÄ Haaste

Katso, voitko hy√∂dynt√§√§ "vihje" -tekniikkaa kehotteella: T√§ydenn√§ lause "N√§yt√§ minulle kuva punaisesta autosta, merkilt√§√§n Volvo ja ". Mit√§ se vastaa, ja miten parantaisit sit√§?

## Hienoa ty√∂t√§! Jatka oppimista

Haluatko oppia lis√§√§ erilaisista kehotetekniikoista? Mene [jatkuvan oppimisen sivulle](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) l√∂yt√§√§ksesi muita hienoja resursseja t√§st√§ aiheesta.

Siirry oppituntiin 5, jossa tarkastelemme [edistyneit√§ kehotetekniikoita](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset saattavat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ auktoritatiivisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ johtuvista v√§√§rink√§sityksist√§ tai virheellisist√§ tulkinnoista.