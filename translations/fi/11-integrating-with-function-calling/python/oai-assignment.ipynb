{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Johdanto\n",
    "\n",
    "Tässä oppitunnissa käsitellään:\n",
    "- Mitä funktiokutsu on ja sen käyttötapaukset\n",
    "- Kuinka luoda funktiokutsu OpenAI:n avulla\n",
    "- Kuinka integroida funktiokutsu sovellukseen\n",
    "\n",
    "## Oppimistavoitteet\n",
    "\n",
    "Oppitunnin suorittamisen jälkeen osaat ja ymmärrät:\n",
    "\n",
    "- Funktiokutsun käytön tarkoituksen\n",
    "- Funktiokutsun määrittämisen OpenAI-palvelussa\n",
    "- Kuinka suunnitella tehokkaita funktiokutsuja sovelluksesi käyttötarkoitukseen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funktiokutsujen ymmärtäminen\n",
    "\n",
    "Tässä oppitunnissa haluamme rakentaa ominaisuuden koulutusstartupillemme, joka antaa käyttäjien käyttää chatbotia teknisten kurssien löytämiseen. Suosittelemme kursseja, jotka sopivat heidän taitotasoonsa, nykyiseen rooliinsa ja kiinnostuksen kohteena olevaan teknologiaan.\n",
    "\n",
    "Tämän toteuttamiseksi käytämme yhdistelmää:\n",
    " - `OpenAI` luomaan käyttäjälle chat-kokemuksen\n",
    " - `Microsoft Learn Catalog API` auttamaan käyttäjiä löytämään kursseja käyttäjän pyynnön perusteella\n",
    " - `Funktiokutsua` ottamaan käyttäjän kyselyn ja lähettämään se funktiolle API-pyynnön tekemiseksi.\n",
    "\n",
    "Aloittaaksemme katsotaan, miksi haluaisimme käyttää funktiokutsua ylipäätään:\n",
    "\n",
    "print(\"Viestit seuraavassa pyynnössä:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # saa uuden vastauksen GPT:ltä, jossa se voi nähdä funktion vastauksen\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miksi funktiokutsu\n",
    "\n",
    "Jos olet suorittanut minkä tahansa muun oppitunnin tässä kurssissa, ymmärrät todennäköisesti suurten kielimallien (LLM) käytön voiman. Toivottavasti näet myös joitakin niiden rajoituksia.\n",
    "\n",
    "Funktiokutsu on OpenAI-palvelun ominaisuus, joka on suunniteltu ratkaisemaan seuraavat haasteet:\n",
    "\n",
    "Epäjohdonmukainen vastausten muotoilu:\n",
    "- Ennen funktiokutsua suurten kielimallien vastaukset olivat jäsentämättömiä ja epäjohdonmukaisia. Kehittäjien piti kirjoittaa monimutkaista validointikoodia käsitelläkseen jokaisen tulosvaihtelun.\n",
    "\n",
    "Rajoitettu integraatio ulkoisten tietojen kanssa:\n",
    "- Ennen tätä ominaisuutta oli vaikeaa sisällyttää sovelluksen muiden osien tietoja keskustelukontekstiin.\n",
    "\n",
    "Vakioimalla vastausmuodot ja mahdollistamalla saumaton integraatio ulkoisten tietojen kanssa funktiokutsu yksinkertaistaa kehitystä ja vähentää lisävalidointilogiikan tarvetta.\n",
    "\n",
    "Käyttäjät eivät voineet saada vastauksia kuten \"Mikä on tämänhetkinen sää Tukholmassa?\". Tämä johtuu siitä, että mallit olivat rajoitettuja siihen aikaan, jolloin data oli koulutettu.\n",
    "\n",
    "Katsotaan alla olevaa esimerkkiä, joka havainnollistaa tätä ongelmaa:\n",
    "\n",
    "Oletetaan, että haluamme luoda opiskelijatietokannan, jotta voimme ehdottaa heille oikeaa kurssia. Alla on kaksi kuvausta opiskelijoista, jotka ovat hyvin samankaltaisia sisältämiensä tietojen osalta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haluamme lähettää tämän LLM:lle tietojen jäsentämistä varten. Tätä voidaan myöhemmin käyttää sovelluksessamme lähettämään tiedot API:lle tai tallentamaan ne tietokantaan.\n",
    "\n",
    "Luodaan kaksi identtistä kehotetta, joissa ohjeistamme LLM:ää siitä, mistä tiedoista olemme kiinnostuneita:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haluamme lähettää tämän LLM:lle jäsentämään osat, jotka ovat tärkeitä tuotteellemme. Joten voimme luoda kaksi identtistä kehotetta ohjaamaan LLM:ää:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Näiden kahden kehotteen luomisen jälkeen lähetämme ne LLM:lle käyttämällä `openai.ChatCompletion`-toimintoa. Tallennamme kehotteen `messages`-muuttujaan ja asetamme rooliksi `user`. Tämä jäljittelee käyttäjän kirjoittamaa viestiä chatbotille.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyt voimme lähettää molemmat pyynnöt LLM:lle ja tarkastella saamaamme vastausta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaikka kehotteet ovat samat ja kuvaukset samankaltaisia, voimme saada erilaisia muotoja `Grades`-ominaisuudelle.\n",
    "\n",
    "Jos suoritat yllä olevan solun useita kertoja, muoto voi olla `3.7` tai `3.7 GPA`.\n",
    "\n",
    "Tämä johtuu siitä, että LLM ottaa vastaan jäsentämätöntä dataa kirjoitetun kehotteen muodossa ja palauttaa myös jäsentämätöntä dataa. Tarvitsemme jäsennellyn muodon, jotta tiedämme, mitä odottaa tallennettaessa tai käytettäessä tätä dataa.\n",
    "\n",
    "Käyttämällä funktion kutsumista voimme varmistaa, että saamme takaisin jäsenneltyä dataa. Funktion kutsumisen yhteydessä LLM ei itse asiassa kutsu tai suorita mitään funktioita. Sen sijaan luomme rakenteen, jota LLM noudattaa vastauksissaan. Käytämme sitten näitä jäsenneltyjä vastauksia tietääksemme, mitä funktiota sovelluksissamme suoritetaan.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funktiokutsun kulku kaavio](../../../../translated_images/fi/Function-Flow.083875364af4f4bb.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voimme sitten ottaa funktion palauttaman arvon ja lähettää sen takaisin LLM:lle. LLM vastaa luonnollisella kielellä käyttäjän kysymykseen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Käyttötapaukset funktiokutsujen käyttämiseen\n",
    "\n",
    "**Ulkoisten työkalujen kutsuminen**  \n",
    "Chatbotit ovat erinomaisia vastaamaan käyttäjien kysymyksiin. Funktiokutsujen avulla chatbotit voivat käyttää käyttäjien viestejä tiettyjen tehtävien suorittamiseen. Esimerkiksi opiskelija voi pyytää chatbotilta \"Lähetä sähköposti ohjaajalleni, jossa sanon tarvitsevani lisää apua tässä aiheessa\". Tämä voi tehdä funktiokutsun `send_email(to: string, body: string)`\n",
    "\n",
    "**API- tai tietokantakyselyiden luominen**  \n",
    "Käyttäjät voivat löytää tietoa luonnollisella kielellä, joka muunnetaan muotoilluksi kyselyksi tai API-pyynnöksi. Esimerkkinä voisi olla opettaja, joka kysyy \"Ketkä opiskelijat ovat suorittaneet viimeisen tehtävän\", mikä voisi kutsua funktiota nimeltä `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Rakenteellisen datan luominen**  \n",
    "Käyttäjät voivat ottaa tekstilohkon tai CSV-tiedoston ja käyttää LLM:ää tärkeän tiedon poimimiseen siitä. Esimerkiksi opiskelija voi muuntaa Wikipedia-artikkelin rauhansopimuksista luodakseen tekoälymuistikortteja. Tämä voidaan tehdä käyttämällä funktiota nimeltä `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensimmäisen funktiokutsun luominen\n",
    "\n",
    "Funktiokutsun luomiseen kuuluu 3 päävaihetta:\n",
    "1. Chat Completions -rajapinnan kutsuminen funktiolistallasi ja käyttäjän viestillä\n",
    "2. Mallin vastauksen lukeminen toiminnon suorittamiseksi, eli funktion tai API-kutsun suorittaminen\n",
    "3. Toinen kutsu Chat Completions -rajapintaan funktion vastauksella, jotta tätä tietoa voidaan käyttää vastauksen luomiseen käyttäjälle.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funktion kutsun kulku](../../../../translated_images/fi/LLM-Flow.3285ed8caf4796d7.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktion kutsun osat\n",
    "\n",
    "#### Käyttäjän syöte\n",
    "\n",
    "Ensimmäinen vaihe on luoda käyttäjän viesti. Tämä voidaan määrittää dynaamisesti ottamalla arvo tekstisyötteestä tai voit määrittää arvon tässä. Jos käytät Chat Completions API:a ensimmäistä kertaa, meidän täytyy määritellä viestin `role` ja `content`.\n",
    "\n",
    "`role` voi olla joko `system` (sääntöjen luominen), `assistant` (malli) tai `user` (loppukäyttäjä). Funktiokutsujen yhteydessä määritämme tämän arvoksi `user` ja annamme esimerkkikysymyksen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktioiden luominen.\n",
    "\n",
    "Seuraavaksi määrittelemme funktion ja sen parametrit. Käytämme tässä vain yhtä funktiota nimeltä `search_courses`, mutta voit luoda useita funktioita.\n",
    "\n",
    "**Tärkeää**: Funktiot sisällytetään järjestelmäviestiin LLM:lle, ja ne lasketaan käytettävissä olevien tokenien määrään.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Määritelmät** \n",
    "\n",
    "Funktiomääritelmän rakenne sisältää useita tasoja, joista jokaisella on omat ominaisuutensa. Tässä on erittely sisäkkäisestä rakenteesta:\n",
    "\n",
    "**Ylimmän tason funktion ominaisuudet:**\n",
    "\n",
    "`name` - Funktion nimi, jota haluamme kutsuttavan. \n",
    "\n",
    "`description` - Kuvaus siitä, miten funktio toimii. Tässä on tärkeää olla tarkka ja selkeä. \n",
    "\n",
    "`parameters` - Lista arvoista ja muodosta, jonka haluat mallin tuottavan vastauksessaan. \n",
    "\n",
    "**Parametrien objektin ominaisuudet:**\n",
    "\n",
    "`type` - Parametrien objektin tietotyyppi (yleensä \"object\")\n",
    "\n",
    "`properties` - Lista erityisistä arvoista, joita malli käyttää vastauksessaan. \n",
    "\n",
    "**Yksittäisten parametrien ominaisuudet:**\n",
    "\n",
    "`name` - Määritellään implisiittisesti ominaisuuden avaimella (esim. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Tämän tietyn parametrin tietotyyppi (esim. \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Kuvaus tästä erityisestä parametrista. \n",
    "\n",
    "**Valinnaiset ominaisuudet:**\n",
    "\n",
    "`required` - Taulukko, joka listaa, mitkä parametrit ovat pakollisia funktion kutsun suorittamiseksi. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktion kutsuminen  \n",
    "Kun funktio on määritelty, meidän täytyy nyt sisällyttää se Chat Completion API -kutsuun. Teemme tämän lisäämällä `functions` pyyntöön. Tässä tapauksessa `functions=functions`.  \n",
    "\n",
    "On myös vaihtoehto asettaa `function_call` arvoksi `auto`. Tämä tarkoittaa, että annamme LLM:n päättää, mikä funktio tulisi kutsua käyttäjän viestin perusteella sen sijaan, että määrittäisimme sen itse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Katsotaanpa nyt vastausta ja miten se on muotoiltu:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Voit nähdä, että funktion nimi kutsutaan ja käyttäjän viestin perusteella LLM pystyi löytämään tiedot, jotka sopivat funktion argumentteihin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funktiokutsujen integroiminen sovellukseen. \n",
    "\n",
    "\n",
    "Kun olemme testanneet muotoillun vastauksen LLM:ltä, voimme nyt integroida tämän sovellukseen. \n",
    "\n",
    "### Virran hallinta \n",
    "\n",
    "Integroidaksemme tämän sovellukseemme, tehdään seuraavat vaiheet: \n",
    "\n",
    "Ensiksi tehdään kutsu OpenAI-palveluihin ja tallennetaan viesti muuttujaan nimeltä `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyt määrittelemme funktion, joka kutsuu Microsoft Learn -rajapintaa saadakseen kurssilistan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parhaana käytäntönä tarkistamme sitten, haluaako malli kutsua funktiota. Tämän jälkeen luomme yhden käytettävissä olevista funktioista ja vastaamme sen funktioon, jota kutsutaan.  \n",
    "Otamme sitten funktion argumentit ja yhdistämme ne LLM:n argumentteihin.\n",
    "\n",
    "Lopuksi liitämme funktiokutsun viestin ja arvot, jotka palautettiin `search_courses`-viestillä. Tämä antaa LLM:lle kaiken tarvittavan tiedon vastatakseen käyttäjälle luonnollisella kielellä.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyt lähetämme päivitetyn viestin LLM:lle, jotta voimme saada luonnollisen kielen vastauksen API:n JSON-muotoisen vastauksen sijaan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Koodhaushaaste\n",
    "\n",
    "Hienoa työtä! Jatkaaksesi OpenAI Function Calling -oppimista voit rakentaa: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Lisää funktiolle parametreja, jotka voivat auttaa oppijoita löytämään enemmän kursseja. Saatavilla olevat API-parametrit löytyvät täältä:  \n",
    " - Luo toinen funktiokutsu, joka ottaa oppijalta enemmän tietoja, kuten heidän äidinkielensä  \n",
    " - Luo virheenkäsittely, kun funktiokutsu ja/tai API-kutsu ei palauta sopivia kursseja  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Vastuuvapauslauseke**:\nTämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, otathan huomioon, että automaattikäännöksissä saattaa esiintyä virheitä tai epätarkkuuksia. Alkuperäinen asiakirja sen alkuperäiskielellä on virallinen lähde. Tärkeissä asioissa suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa tämän käännöksen käytöstä aiheutuvista väärinymmärryksistä tai tulkinnoista.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T10:43:20+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "fi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}