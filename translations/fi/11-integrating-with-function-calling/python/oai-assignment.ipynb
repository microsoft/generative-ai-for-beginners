{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Johdanto\n",
    "\n",
    "Tässä oppitunnissa käsitellään:\n",
    "- Mitä funktiokutsut ovat ja mihin niitä käytetään\n",
    "- Miten luodaan funktiokutsu OpenAI:n avulla\n",
    "- Miten funktiokutsu integroidaan sovellukseen\n",
    "\n",
    "## Oppimistavoitteet\n",
    "\n",
    "Tämän oppitunnin jälkeen osaat ja ymmärrät:\n",
    "\n",
    "- Miksi funktiokutsuja käytetään\n",
    "- Miten otetaan käyttöön funktiokutsu OpenAI-palvelussa\n",
    "- Miten suunnitellaan toimivia funktiokutsuja oman sovelluksen tarpeisiin\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ymmärrä funktiokutsut\n",
    "\n",
    "Tässä oppitunnissa haluamme rakentaa ominaisuuden koulutus-startupillemme, jonka avulla käyttäjät voivat käyttää chatbotia löytääkseen teknisiä kursseja. Suosittelemme kursseja, jotka sopivat heidän taitotasoonsa, nykyiseen rooliinsa ja kiinnostuksen kohteena olevaan teknologiaan.\n",
    "\n",
    "Tämän toteuttamiseksi käytämme yhdistelmää seuraavista:\n",
    " - `OpenAI` luomaan käyttäjälle keskustelukokemuksen\n",
    " - `Microsoft Learn Catalog API` auttamaan käyttäjiä löytämään kursseja heidän pyyntönsä perusteella\n",
    " - `Function Calling` ottamaan käyttäjän kyselyn ja lähettämään sen funktiolle API-pyynnön tekemistä varten\n",
    "\n",
    "Aloitetaan katsomalla, miksi ylipäätään haluaisimme käyttää funktiokutsuja:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # hae uusi vastaus GPT:ltä, jossa se näkee funktion vastauksen\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Miksi Function Calling\n",
    "\n",
    "Jos olet käynyt läpi jonkin muun oppitunnin tässä kurssissa, ymmärrät todennäköisesti, kuinka tehokkaita Large Language Modelit (LLM:t) voivat olla. Toivottavasti olet myös huomannut niiden rajoituksia.\n",
    "\n",
    "Function Calling on OpenAI-palvelun ominaisuus, joka on suunniteltu ratkaisemaan seuraavat haasteet:\n",
    "\n",
    "Epäyhtenäinen vastausmuotoilu:\n",
    "- Ennen function callingia LLM:n vastaukset olivat jäsentymättömiä ja epäyhtenäisiä. Kehittäjien piti kirjoittaa monimutkaista tarkistuskoodia käsitelläkseen erilaisia vastausmuotoja.\n",
    "\n",
    "Rajoitettu integraatio ulkoiseen dataan:\n",
    "- Ennen tätä ominaisuutta oli hankalaa tuoda sovelluksen muista osista saatavaa dataa keskusteluun mukaan.\n",
    "\n",
    "Vakiinnuttamalla vastausmuodot ja mahdollistamalla sujuvan integraation ulkoisen datan kanssa, function calling helpottaa kehitystyötä ja vähentää lisävalidoinnin tarvetta.\n",
    "\n",
    "Käyttäjät eivät voineet saada vastauksia kuten \"Mikä on tämänhetkinen sää Tukholmassa?\". Tämä johtui siitä, että mallit olivat rajoittuneet siihen aikaan, jolloin niiden data oli koulutettu.\n",
    "\n",
    "Katsotaanpa alla olevaa esimerkkiä, joka havainnollistaa tätä ongelmaa:\n",
    "\n",
    "Oletetaan, että haluamme luoda tietokannan opiskelijoiden tiedoista, jotta voimme suositella heille sopivaa kurssia. Alla on kaksi opiskelijakuvausta, jotka sisältävät hyvin samankaltaista tietoa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haluamme lähettää tämän LLM:lle, jotta se voi jäsentää tiedot. Tätä voidaan myöhemmin käyttää sovelluksessamme, kun lähetämme tietoja API:lle tai tallennamme ne tietokantaan.\n",
    "\n",
    "Luodaan kaksi identtistä kehotetta, joilla ohjeistamme LLM:ää siitä, mitä tietoja olemme kiinnostuneita saamaan:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haluamme lähettää tämän LLM:lle, jotta se voi jäsentää tuotteellemme tärkeät osat. Näin voimme luoda kaksi identtistä kehotetta ohjeistamaan LLM:ää:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kun olemme luoneet nämä kaksi kehotetta, lähetämme ne LLM:lle käyttämällä `openai.ChatCompletion`. Tallennamme kehotteen `messages`-muuttujaan ja määritämme rooliksi `user`. Tämä jäljittelee käyttäjän viestin kirjoittamista chatbotille.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyt voimme lähettää molemmat pyynnöt LLM:lle ja tarkastella saamaamme vastausta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaikka kehotteet ovat samat ja kuvaukset muistuttavat toisiaan, voimme saada `Grades`-ominaisuudesta erilaisia muotoja.\n",
    "\n",
    "Jos suoritat yllä olevan solun useita kertoja, muoto voi olla joko `3.7` tai `3.7 GPA`.\n",
    "\n",
    "Tämä johtuu siitä, että LLM käsittelee jäsentymätöntä dataa kirjoitetun kehotteen muodossa ja palauttaa myös jäsentymätöntä dataa. Meidän täytyy käyttää jäsenneltyä muotoa, jotta tiedämme, mitä odottaa, kun tallennamme tai käytämme tätä dataa.\n",
    "\n",
    "Käyttämällä funktionaalista kutsua voimme varmistaa, että saamme takaisin jäsenneltyä dataa. Kun käytämme funktiokutsua, LLM ei oikeasti kutsu tai suorita mitään funktioita. Sen sijaan luomme rakenteen, jota LLM noudattaa vastauksissaan. Käytämme näitä jäsenneltyjä vastauksia tietääksemme, mitä funktiota sovelluksissamme tulee käyttää.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Funktiokutsun kulkukaavio](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.fi.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Käyttötapaukset funktiokutsuille\n",
    "\n",
    "**Ulkoisten työkalujen käyttäminen**  \n",
    "Chatbotit ovat erinomaisia vastaamaan käyttäjien kysymyksiin. Funktiokutsujen avulla chatbotit voivat käyttää käyttäjien viestejä tiettyjen tehtävien suorittamiseen. Esimerkiksi opiskelija voi pyytää chatbotia: \"Lähetä sähköposti opettajalleni ja kerro, että tarvitsen lisää apua tässä aiheessa.\" Tämä voi tehdä funktiokutsun `send_email(to: string, body: string)`\n",
    "\n",
    "**API- tai tietokantakyselyiden luominen**  \n",
    "Käyttäjät voivat etsiä tietoa luonnollisella kielellä, joka muunnetaan muotoiltuun kyselyyn tai API-pyyntöön. Esimerkkinä opettaja voi kysyä: \"Ketkä opiskelijat suorittivat viimeisimmän tehtävän?\" ja tämä voisi kutsua funktiota nimeltä `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Rakenteisen datan luominen**  \n",
    "Käyttäjät voivat ottaa tekstikappaleen tai CSV-tiedoston ja käyttää LLM:ää tärkeän tiedon poimimiseen siitä. Esimerkiksi opiskelija voi muuntaa Wikipedia-artikkelin rauhansopimuksista tekoälymuistikorteiksi. Tämä onnistuu käyttämällä funktiota `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ensimmäisen funktiokutsun luominen\n",
    "\n",
    "Funktiokutsun luominen koostuu kolmesta päävaiheesta:\n",
    "1. Kutsutaan Chat Completions APIa, annetaan lista funktioista ja käyttäjän viesti\n",
    "2. Luetaan mallin vastaus ja suoritetaan tarvittava toiminto, esimerkiksi funktio- tai API-kutsu\n",
    "3. Tehdään uusi kutsu Chat Completions APIin, annetaan funktiosta saatu vastaus, jotta mallilla on tarvittavat tiedot käyttäjälle vastaamiseen\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Flow of a Function Call](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.fi.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktion kutsun osat\n",
    "\n",
    "#### Käyttäjän syöte\n",
    "\n",
    "Ensimmäinen vaihe on luoda käyttäjän viesti. Tämän voi määrittää dynaamisesti ottamalla arvon tekstikentästä tai voit asettaa arvon suoraan tähän. Jos työskentelet Chat Completions API:n kanssa ensimmäistä kertaa, meidän täytyy määritellä viestin `role` ja `content`.\n",
    "\n",
    "`role` voi olla joko `system` (sääntöjen luominen), `assistant` (malli) tai `user` (loppukäyttäjä). Funktiokutsua varten asetamme tämän arvoksi `user` ja annamme esimerkkikysymyksen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktioiden luominen.\n",
    "\n",
    "Seuraavaksi määrittelemme funktion ja sen parametrit. Käytämme tässä vain yhtä funktiota nimeltä `search_courses`, mutta voit luoda useita eri funktioita.\n",
    "\n",
    "**Tärkeää**: Funktiot lisätään järjestelmäviestiin LLM:lle ja ne lasketaan mukaan käytettävissä oleviin tokeneihin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Määritelmät**\n",
    "\n",
    "Funktiomäärittelyn rakenne koostuu useista tasoista, joilla jokaisella on omat ominaisuutensa. Tässä on yhteenveto sisäkkäisestä rakenteesta:\n",
    "\n",
    "**Funktion ylimmän tason ominaisuudet:**\n",
    "\n",
    "`name` - Funktion nimi, joka halutaan kutsua.\n",
    "\n",
    "`description` - Kuvaus siitä, miten funktio toimii. Tässä on tärkeää olla tarkka ja selkeä.\n",
    "\n",
    "`parameters` - Lista arvoista ja muodosta, jotka halutaan mallin tuottavan vastauksessaan.\n",
    "\n",
    "**Parametriobjektin ominaisuudet:**\n",
    "\n",
    "`type` - Parametriobjektin tietotyyppi (yleensä \"object\")\n",
    "\n",
    "`properties` - Luettelo niistä arvoista, joita malli käyttää vastauksessaan\n",
    "\n",
    "**Yksittäisen parametrin ominaisuudet:**\n",
    "\n",
    "`name` - Määritellään epäsuorasti avaimen perusteella (esim. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Tämän tietyn parametrin tietotyyppi (esim. \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Kuvaus kyseisestä parametrista\n",
    "\n",
    "**Valinnaiset ominaisuudet:**\n",
    "\n",
    "`required` - Taulukko, jossa luetellaan, mitkä parametrit ovat pakollisia, jotta funktiokutsu voidaan suorittaa loppuun\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Funktiokutsun tekeminen\n",
    "Kun funktio on määritelty, meidän täytyy nyt liittää se Chat Completion API -kutsuun. Tämä tehdään lisäämällä `functions` pyyntöön. Tässä tapauksessa `functions=functions`.\n",
    "\n",
    "Lisäksi on mahdollista asettaa `function_call` arvoksi `auto`. Tämä tarkoittaa, että annamme LLM:n päättää, mitä funktiota tulisi kutsua käyttäjän viestin perusteella sen sijaan, että määrittelisimme sen itse.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyt tarkastellaan vastausta ja sen muotoilua:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Voit huomata, että funktion nimi on kutsuttu ja käyttäjän viestistä LLM pystyi löytämään tiedot, jotka sopivat funktion argumentteihin.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Funktiokutsujen integrointi sovellukseen.\n",
    "\n",
    "Kun olemme testanneet LLM:n muotoillun vastauksen, voimme nyt integroida sen sovellukseen.\n",
    "\n",
    "### Prosessin hallinta\n",
    "\n",
    "Jotta voimme integroida tämän sovellukseemme, tehdään seuraavat vaiheet:\n",
    "\n",
    "Ensin tehdään kutsu OpenAI-palveluihin ja tallennetaan viesti muuttujaan nimeltä `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyt määrittelemme funktion, joka kutsuu Microsoft Learn API:a saadakseen luettelon kursseista:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyvänä käytäntönä tarkistamme ensin, haluaako malli kutsua funktiota. Tämän jälkeen luomme jonkin saatavilla olevista funktioista ja yhdistämme sen kutsuttavaan funktioon.\n",
    "Seuraavaksi otamme funktion argumentit ja yhdistämme ne LLM:n antamiin argumentteihin.\n",
    "\n",
    "Lopuksi liitämme funktiokutsun viestin ja arvot, jotka `search_courses`-viesti palautti. Näin LLM:llä on kaikki tarvittava tieto, jotta se voi vastata käyttäjälle luonnollisella kielellä.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kooditehtävä\n",
    "\n",
    "Hienoa työtä! Jatkaaksesi OpenAI Function Calling -osaamisesi kehittämistä voit rakentaa: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Lisää funktion parametreja, jotka voivat auttaa oppijoita löytämään lisää kursseja. Löydät saatavilla olevat API-parametrit täältä:\n",
    " - Luo toinen funktiokutsu, joka ottaa oppijalta enemmän tietoa, kuten heidän äidinkielensä\n",
    " - Toteuta virheenkäsittely, jos funktiokutsu ja/tai API-kutsu ei palauta sopivia kursseja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Vastuuvapauslauseke**:  \nTämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Pyrimme tarkkuuteen, mutta huomioithan, että automaattiset käännökset saattavat sisältää virheitä tai epätarkkuuksia. Alkuperäistä asiakirjaa sen alkuperäisellä kielellä tulee pitää ensisijaisena lähteenä. Kriittisissä tapauksissa suosittelemme ammattimaisen ihmiskääntäjän käyttöä. Emme ole vastuussa tämän käännöksen käytöstä mahdollisesti aiheutuvista väärinkäsityksistä tai tulkinnoista.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:08:56+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "fi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}