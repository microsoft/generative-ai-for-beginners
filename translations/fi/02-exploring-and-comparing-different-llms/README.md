<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:30:42+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "fi"
}
-->
# Eri LLM-mallien tutkiminen ja vertailu

[![Eri LLM-mallien tutkiminen ja vertailu](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.fi.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Klikkaa yll√§ olevaa kuvaa n√§hd√§ksesi t√§m√§n oppitunnin videon_

Edellisess√§ oppitunnissa n√§imme, miten Generatiivinen teko√§ly muuttaa teknologia-alaa, miten Suuret Kielenmallit (LLM) toimivat ja miten yritys ‚Äì kuten meid√§n startupimme ‚Äì voi hy√∂dynt√§√§ niit√§ omissa k√§ytt√∂tapauksissaan ja kasvaa! T√§ss√§ luvussa vertailemme eri tyyppisi√§ suuria kielenmalleja (LLM) ymm√§rt√§√§ksemme niiden vahvuudet ja heikkoudet.

Seuraava askel startupimme matkalla on tutkia nykyist√§ LLM-maisemaa ja ymm√§rt√§√§, mitk√§ mallit sopivat parhaiten meid√§n k√§ytt√∂tapaukseemme.

## Johdanto

T√§ss√§ oppitunnissa k√§sitell√§√§n:

- Eri LLM-tyyppej√§ nykyisess√§ maisemassa.
- Mallien testaamista, iterointia ja vertailua k√§ytt√∂tapauksessasi Azuren ymp√§rist√∂ss√§.
- Miten LLM otetaan k√§ytt√∂√∂n.

## Oppimistavoitteet

Oppitunnin suorittamisen j√§lkeen osaat:

- Valita oikean mallin k√§ytt√∂tapaukseesi.
- Ymm√§rt√§√§, miten mallia testataan, kehitet√§√§n ja suorituskyky√§ parannetaan.
- Tiet√§√§, miten yritykset ottavat malleja k√§ytt√∂√∂n.

## Ymm√§rr√§ eri LLM-tyypit

LLM-malleja voidaan luokitella monella tavalla arkkitehtuurin, koulutusdatan ja k√§ytt√∂tarkoituksen perusteella. N√§iden erojen ymm√§rt√§minen auttaa startupiamme valitsemaan oikean mallin tilanteeseen sek√§ ymm√§rt√§m√§√§n, miten mallia testataan, kehitet√§√§n ja suorituskyky√§ parannetaan.

LLM-malleja on monenlaisia, ja mallin valinta riippuu siit√§, mihin aiot niit√§ k√§ytt√§√§, datastasi, budjetistasi ja muista tekij√∂ist√§.

Riippuen siit√§, aiotko k√§ytt√§√§ malleja tekstin, √§√§nen, videon, kuvan generointiin tai muuhun, saatat valita eri mallityypin.

- **√Ñ√§ni- ja puheentunnistus**. T√§h√§n tarkoitukseen Whisper-tyyppiset mallit ovat erinomainen valinta, sill√§ ne ovat yleisk√§ytt√∂isi√§ ja suunniteltu puheentunnistukseen. Ne on koulutettu monipuolisella √§√§nidatalla ja pystyv√§t monikieliseen puheentunnistukseen. Lue lis√§√§ [Whisper-tyyppisist√§ malleista t√§√§lt√§](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Kuvagenerointi**. Kuvagenerointiin DALL-E ja Midjourney ovat kaksi hyvin tunnettua vaihtoehtoa. DALL-E on saatavilla Azure OpenAI:n kautta. [Lue lis√§√§ DALL-E:st√§ t√§√§lt√§](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) sek√§ t√§m√§n oppimateriaalin luvusta 9.

- **Tekstintuotanto**. Useimmat mallit on koulutettu tekstintuotantoon, ja valinnanvaraa on laajasti GPT-3.5:st√§ GPT-4:√§√§n. Mallit eroavat hinnoiltaan, GPT-4 on kallein. Kannattaa tutustua [Azure OpenAI playgroundiin](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) arvioidaksesi, mitk√§ mallit sopivat parhaiten tarpeisiisi ominaisuuksien ja kustannusten osalta.

- **Monimodaalisuus**. Jos haluat k√§sitell√§ useita datatyyppej√§ sy√∂tteiss√§ ja tulosteissa, kannattaa tutustua malleihin kuten [gpt-4 turbo with vision tai gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ‚Äì OpenAI:n uusimpiin malleihin ‚Äì jotka yhdist√§v√§t luonnollisen kielen k√§sittelyn visuaaliseen ymm√§rrykseen mahdollistaen vuorovaikutuksen monimodaalisilla k√§ytt√∂liittymill√§.

Mallin valinta tarkoittaa, ett√§ saat perusominaisuudet, jotka eiv√§t v√§ltt√§m√§tt√§ riit√§. Usein yrityksell√§ on omaa dataa, josta LLM:lle t√§ytyy jotenkin kertoa. T√§h√§n on muutamia eri l√§hestymistapoja, joista lis√§√§ seuraavissa osioissa.

### Foundation-mallit vs. LLM:t

Termi Foundation Model (perusmalli) [m√§√§riteltiin Stanfordin tutkijoiden toimesta](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) ja tarkoittaa teko√§lymallia, joka t√§ytt√§√§ tietyt kriteerit, kuten:

- **Ne on koulutettu valvomattomalla tai itsevalvotulla oppimisella**, eli ne on koulutettu merkitsem√§tt√∂m√§ll√§ monimodaalisella datalla, eik√§ niiden koulutukseen tarvita ihmisen tekem√§√§ annotointia tai merkint√∂j√§.
- **Ne ovat eritt√§in suuria malleja**, perustuen syviin neuroverkkoihin, jotka on koulutettu miljardeilla parametreilla.
- **Ne on yleens√§ tarkoitettu toimimaan ‚Äòperustana‚Äô muille malleille**, eli niit√§ voidaan k√§ytt√§√§ l√§ht√∂kohtana muiden mallien rakentamiselle hienos√§√§t√§m√§ll√§.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.fi.png)

Kuvan l√§hde: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Selkeytt√§√§ksemme t√§t√§ eroa, otetaan esimerkkin√§ ChatGPT. Ensimm√§isen ChatGPT-version rakentamisessa GPT-3.5 toimi perustana. T√§m√§ tarkoittaa, ett√§ OpenAI k√§ytti chat-spesifist√§ dataa luodakseen hienos√§√§detyn version GPT-3.5:st√§, joka on erikoistunut toimimaan hyvin keskustelutilanteissa, kuten chatbotteina.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.fi.png)

Kuvan l√§hde: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Avoimen l√§hdekoodin vs. omistettavat mallit

Toinen tapa luokitella LLM-malleja on se, ovatko ne avoimen l√§hdekoodin vai omistettuja.

Avoimen l√§hdekoodin mallit ovat julkisesti saatavilla ja niit√§ voi k√§ytt√§√§ kuka tahansa. Ne julkaistaan usein niit√§ kehitt√§neen yrityksen tai tutkimusyhteis√∂n toimesta. N√§it√§ malleja saa tarkastella, muokata ja r√§√§t√§l√∂id√§ erilaisiin k√§ytt√∂tarkoituksiin. Ne eiv√§t kuitenkaan aina ole optimoituja tuotantok√§ytt√∂√∂n, eiv√§tk√§ v√§ltt√§m√§tt√§ ole yht√§ suorituskykyisi√§ kuin omistettavat mallit. Lis√§ksi avoimen l√§hdekoodin malleilla voi olla rajoitettu rahoitus, ne eiv√§t v√§ltt√§m√§tt√§ yll√§pid√§ pitk√§ll√§ aikav√§lill√§ tai p√§ivity uusimpaan tutkimukseen. Tunnettuja avoimen l√§hdekoodin malleja ovat esimerkiksi [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) ja [LLaMA](https://llama.meta.com).

Omistettavat mallit ovat yrityksen omistamia, eiv√§tk√§ ne ole julkisesti saatavilla. Ne on usein optimoitu tuotantok√§ytt√∂√∂n. Niit√§ ei saa tarkastella, muokata tai r√§√§t√§l√∂id√§ eri k√§ytt√∂tarkoituksiin. Lis√§ksi ne eiv√§t aina ole ilmaisia, vaan niiden k√§ytt√∂ voi vaatia tilauksen tai maksun. K√§ytt√§j√§t eiv√§t my√∂sk√§√§n hallitse mallin koulutuksessa k√§ytetty√§ dataa, joten mallin omistajaan on luotettava tietosuojan ja vastuullisen teko√§lyn k√§yt√∂n varmistamisessa. Tunnettuja omistettavia malleja ovat esimerkiksi [OpenAI:n mallit](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ja [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding vs. kuvagenerointi vs. teksti- ja koodigenerointi

LLM-mallit voidaan my√∂s luokitella niiden tuottaman tulosteen perusteella.

Embedding-mallit muuntavat tekstin numeeriseen muotoon, jota kutsutaan embeddingiksi. Embedding on numeerinen esitys sy√∂tteest√§. Embeddingit helpottavat koneiden ymm√§rt√§m√§√§n sanojen tai lauseiden v√§lisi√§ suhteita, ja niit√§ voidaan k√§ytt√§√§ muiden mallien sy√∂ttein√§, kuten luokittelu- tai klusterointimalleissa, jotka toimivat paremmin numeerisen datan kanssa. Embedding-malleja k√§ytet√§√§n usein siirto-oppimiseen, jossa malli rakennetaan korvaavaan teht√§v√§√§n, johon on runsaasti dataa, ja mallin painoja (embeddingej√§) hy√∂dynnet√§√§n muissa teht√§viss√§. Esimerkki t√§st√§ kategoriasta on [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.fi.png)

Kuvagenerointimallit tuottavat kuvia. N√§it√§ malleja k√§ytet√§√§n usein kuvan muokkaukseen, synteesiin ja k√§√§nn√∂kseen. Ne on koulutettu suurilla kuvadatoilla, kuten [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), ja niit√§ voidaan k√§ytt√§√§ uusien kuvien luomiseen tai olemassa olevien kuvien muokkaamiseen esimerkiksi inpainting-, superresoluutio- ja v√§ritysmenetelmill√§. Esimerkkej√§ ovat [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) ja [Stable Diffusion -mallit](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Kuvagenerointi](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.fi.png)

Teksti- ja koodigenerointimallit tuottavat teksti√§ tai koodia. N√§it√§ malleja k√§ytet√§√§n usein tekstin tiivist√§miseen, k√§√§nt√§miseen ja kysymyksiin vastaamiseen. Tekstintuotantomallit on koulutettu suurilla tekstidatoilla, kuten [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), ja niit√§ voidaan k√§ytt√§√§ uuden tekstin luomiseen tai kysymyksiin vastaamiseen. Koodigenerointimallit, kuten [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), on koulutettu suurilla koodidatoilla, kuten GitHubista, ja niit√§ voidaan k√§ytt√§√§ uuden koodin luomiseen tai olemassa olevan koodin virheiden korjaamiseen.

![Teksti- ja koodigenerointi](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.fi.png)

### Encoder-Decoder vs. pelkk√§ Decoder

Puhuttaessa eri LLM-arkkitehtuureista, k√§ytet√§√§n vertauskuvaa.

Kuvittele, ett√§ esimiehesi antoi sinulle teht√§v√§ksi laatia tietovisan opiskelijoille. Sinulla on kaksi kollegaa; toinen vastaa sis√§ll√∂n luomisesta ja toinen sen tarkistamisesta.

Sis√§ll√∂ntuottaja on kuin pelkk√§ Decoder-malli, h√§n katsoo aihetta ja mit√§ olet jo kirjoittanut, ja voi kirjoittaa kurssin sen pohjalta. He ovat hyvi√§ kirjoittamaan kiinnostavaa ja informatiivista sis√§lt√∂√§, mutta eiv√§t kovin hyvi√§ ymm√§rt√§m√§√§n aihetta ja oppimistavoitteita. Esimerkkej√§ Decoder-malleista ovat GPT-perheen mallit, kuten GPT-3.

Tarkastaja on kuin pelkk√§ Encoder-malli, h√§n katsoo kirjoitetun kurssin ja vastaukset, huomaa niiden v√§liset suhteet ja ymm√§rt√§√§ kontekstin, mutta ei ole hyv√§ sis√§ll√∂n tuottamisessa. Esimerkki Encoder-mallista on BERT.

Kuvittele, ett√§ meill√§ olisi joku, joka voisi sek√§ luoda ett√§ tarkistaa visan, t√§m√§ on Encoder-Decoder-malli. Esimerkkej√§ ovat BART ja T5.

### Palvelu vs. malli

Keskustellaan nyt palvelun ja mallin erosta. Palvelu on pilvipalveluntarjoajan tarjoama tuote, joka on usein yhdistelm√§ malleja, dataa ja muita komponentteja. Malli on palvelun ydinosa, usein foundation-malli, kuten LLM.

Palvelut on usein optimoitu tuotantok√§ytt√∂√∂n ja ne ovat usein helpompia k√§ytt√§√§ kuin mallit, esimerkiksi graafisen k√§ytt√∂liittym√§n kautta. Palvelut eiv√§t kuitenkaan aina ole ilmaisia, ja niiden k√§ytt√∂ voi vaatia tilauksen tai maksun, jolloin k√§ytt√§j√§ hy√∂dynt√§√§ palveluntarjoajan laitteistoa ja resursseja, optimoi kustannuksia ja skaalaa helposti. Esimerkki palvelusta on [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), joka tarjoaa k√§yt√∂n mukaan maksettavan hinnoittelumallin, eli k√§ytt√§jilt√§ veloitetaan k√§yt√∂n mukaan. Lis√§ksi Azure OpenAI Service tarjoaa yritystason tietoturvan ja vastuullisen teko√§lyn kehykset mallien ominaisuuksien lis√§ksi.

Mallissa on pelkk√§ neuroverkko, parametrit, painot ja muut. Yritykset voivat ajaa mallia paikallisesti, mutta t√§ll√∂in t√§ytyy hankkia laitteisto, rakentaa skaalautuva infrastruktuuri ja ostaa lisenssi tai k√§ytt√§√§ avoimen l√§hdekoodin mallia. Esimerkiksi LLaMA on saatavilla k√§ytett√§v√§ksi, mutta sen ajamiseen tarvitaan laskentatehoa.

## Miten testata ja iteratiivisesti kehitt√§√§ eri malleja suorituskyvyn ymm√§rt√§miseksi Azurella

Kun tiimimme on tutkinut nykyisen LLM-maiseman ja l√∂yt√§nyt hyvi√§ ehdokkaita omiin k√§ytt√∂tapauksiinsa, seuraava askel on testata niit√§ omalla datalla ja ty√∂kuormalla. T√§m√§ on iteratiivinen prosessi, joka tehd√§√§n kokeilujen ja mittausten avulla.
Suurin osa aiemmissa kappaleissa mainituista malleista (OpenAI-mallit, avoimen l√§hdekoodin mallit kuten Llama2 ja Hugging Face -transformerit) on saatavilla [Model Catalogissa](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) [Azure AI Studiossa](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) on pilvialusta, joka on suunniteltu kehitt√§jille generatiivisten teko√§lysovellusten rakentamiseen ja koko kehityssyklin hallintaan ‚Äì kokeilusta arviointiin ‚Äì yhdist√§m√§ll√§ kaikki Azure AI -palvelut yhdeksi keskukseksi k√§tev√§ll√§ k√§ytt√∂liittym√§ll√§. Azure AI Studion Model Catalog mahdollistaa k√§ytt√§j√§lle:

- L√∂yt√§√§ kiinnostavan Foundation Modelin katalogista ‚Äì joko omistusoikeudellisen tai avoimen l√§hdekoodin, suodattaen teht√§v√§n, lisenssin tai nimen mukaan. Hakemisen parantamiseksi mallit on j√§rjestetty kokoelmiin, kuten Azure OpenAI -kokoelma, Hugging Face -kokoelma ja muita.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.fi.png)

- Tarkastella mallikorttia, joka sis√§lt√§√§ yksityiskohtaisen kuvauksen suunnitellusta k√§yt√∂st√§ ja koulutusdatasta, koodiesimerkkej√§ sek√§ arviointituloksia sis√§isest√§ arviointikirjastosta.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.fi.png)

- Verrata suorituskykymittareita eri malleista ja teollisuudessa k√§ytett√§viss√§ olevista dataseteist√§ arvioidakseen, mik√§ sopii parhaiten liiketoimintatilanteeseen, [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) -v√§lilehden kautta.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.fi.png)

- Hienos√§√§t√§√§ mallia omalla koulutusdatalla parantaakseen mallin suorituskyky√§ tietyss√§ ty√∂kuormassa hy√∂dynt√§en Azure AI Studion kokeilu- ja seurantamahdollisuuksia.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.fi.png)

- Ota k√§ytt√∂√∂n alkuper√§inen esikoulutettu malli tai hienos√§√§detty versio et√§k√§ytt√∂√∂n reaaliaikaiseen p√§√§ttelyyn ‚Äì hallinnoituun laskentaan ‚Äì tai palvelimettomaan API-p√§√§tteeseen ‚Äì [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) ‚Äì jotta sovellukset voivat k√§ytt√§√§ sit√§.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.fi.png)


> [!NOTE]
> Kaikki katalogin mallit eiv√§t ole t√§ll√§ hetkell√§ saatavilla hienos√§√§t√∂√∂n ja/tai pay-as-you-go -k√§ytt√∂√∂nottoon. Tarkista mallikortista tiedot mallin ominaisuuksista ja rajoituksista.

## LLM-tulosten parantaminen

Olemme startup-tiimimme kanssa kokeilleet erilaisia LLM-malleja ja pilvialustaa (Azure Machine Learning), joka mahdollistaa eri mallien vertailun, arvioinnin testidatalla, suorituskyvyn parantamisen ja k√§ytt√∂√∂noton p√§√§ttelypisteiss√§.

Mutta milloin kannattaa harkita mallin hienos√§√§t√∂√§ sen sijaan, ett√§ k√§ytt√§isi valmiiksi koulutettua mallia? Onko olemassa muita tapoja parantaa mallin suorituskyky√§ tietyiss√§ ty√∂kuormissa?

Liiketoiminnalla on useita tapoja saada halutut tulokset LLM:st√§. Voit valita eri tyyppisi√§ malleja eri koulutustasoilla, kun otat LLM:n k√§ytt√∂√∂n tuotannossa, eri monimutkaisuus-, kustannus- ja laatutasojen mukaan. T√§ss√§ muutamia eri l√§hestymistapoja:

- **Promptin suunnittelu kontekstin kanssa**. Ajatuksena on antaa riitt√§v√§sti kontekstia promptissa, jotta saat tarvitsemasi vastaukset.

- **Retrieval Augmented Generation, RAG**. Data voi sijaita esimerkiksi tietokannassa tai web-p√§√§tepisteess√§, ja varmistaaksesi, ett√§ t√§m√§ data tai sen osa sis√§ltyy promptin aikaan, voit hakea relevantin datan ja liitt√§√§ sen osaksi k√§ytt√§j√§n promptia.

- **Hienos√§√§detty malli**. T√§ss√§ mallia on koulutettu lis√§√§ omalla datallasi, mik√§ tekee mallista tarkemman ja paremmin tarpeisiisi vastaavan, mutta se voi olla kallista.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.fi.png)

Kuvan l√§hde: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Promptin suunnittelu kontekstin kanssa

Esikoulutetut LLM-mallit toimivat eritt√§in hyvin yleisluontoisissa luonnollisen kielen teht√§viss√§, jopa lyhyell√§ promptilla, kuten lauseen t√§ydent√§misell√§ tai kysymyksell√§ ‚Äì ns. ‚Äúzero-shot‚Äù -oppiminen.

Mit√§ paremmin k√§ytt√§j√§ pystyy muotoilemaan kyselyns√§ yksityiskohtaisella pyynn√∂ll√§ ja esimerkeill√§ ‚Äì eli kontekstilla ‚Äì sit√§ tarkempi ja k√§ytt√§j√§n odotuksia vastaavampi vastaus on. T√§ss√§ puhutaan ‚Äúone-shot‚Äù -oppimisesta, jos promptissa on vain yksi esimerkki, ja ‚Äúfew-shot‚Äù -oppimisesta, jos esimerkkej√§ on useita.
Promptin suunnittelu kontekstin kanssa on kustannustehokkain tapa aloittaa.

### Retrieval Augmented Generation (RAG)

LLM-malleilla on rajoitus, ett√§ ne voivat k√§ytt√§√§ vain koulutuksessaan k√§ytetty√§ dataa vastauksen tuottamiseen. T√§m√§ tarkoittaa, etteiv√§t ne tied√§ mit√§√§n koulutuksen j√§lkeisist√§ tapahtumista, eiv√§tk√§ p√§√§se k√§siksi ei-julkiseen tietoon (kuten yritystietoihin).
T√§m√§n voi kiert√§√§ RAG-tekniikalla, joka t√§ydent√§√§ promptia ulkoisella datalla dokumenttien paloina, ottaen huomioon promptin pituusrajoitukset. T√§t√§ tukevat vektoritietokantaty√∂kalut (kuten [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), jotka hakevat hy√∂dylliset palat eri ennalta m√§√§ritellyist√§ tietol√§hteist√§ ja lis√§√§v√§t ne promptin kontekstiin.

T√§m√§ tekniikka on eritt√§in hy√∂dyllinen, kun liiketoiminnalla ei ole tarpeeksi dataa, aikaa tai resursseja hienos√§√§t√§√§ LLM:√§√§, mutta haluaa silti parantaa suorituskyky√§ tietyss√§ ty√∂kuormassa ja v√§hent√§√§ virheellisten tai haitallisten sis√§lt√∂jen riski√§.

### Hienos√§√§detty malli

Hienos√§√§t√∂ on prosessi, jossa hy√∂dynnet√§√§n siirto-oppimista mallin ‚Äúsovittamiseksi‚Äù alateht√§v√§√§n tai tietyn ongelman ratkaisuun. Toisin kuin few-shot-oppiminen ja RAG, hienos√§√§t√∂ tuottaa uuden mallin, jossa on p√§ivitetyt painot ja vinot. Se vaatii joukon koulutusesimerkkej√§, jotka koostuvat yhdest√§ sy√∂tteest√§ (promptista) ja siihen liittyv√§st√§ vastauksesta (t√§ydennys).
T√§m√§ on suositeltava l√§hestymistapa, jos:

- **K√§ytet√§√§n hienos√§√§dettyj√§ malleja**. Liiketoiminta haluaa k√§ytt√§√§ hienos√§√§dettyj√§ v√§hemm√§n tehokkaita malleja (kuten upotusmalleja) korkean suorituskyvyn mallien sijaan, mik√§ johtaa kustannustehokkaampaan ja nopeampaan ratkaisuun.

- **Viive on t√§rke√§**. Viive on t√§rke√§ tietylle k√§ytt√∂tapaukselle, joten ei ole mahdollista k√§ytt√§√§ hyvin pitki√§ prompteja tai esimerkkien m√§√§r√§√§, joka pit√§isi mallin oppia, ei mahdu promptin pituusrajoituksiin.

- **Pysy√§ ajan tasalla**. Liiketoiminnalla on paljon laadukasta dataa ja totuudenmukaisia tunnisteita sek√§ resurssit pit√§√§ data ajan tasalla ajan my√∂t√§.

### Koulutettu malli

LLM:n kouluttaminen alusta alkaen on kiistatta vaikein ja monimutkaisin l√§hestymistapa, joka vaatii valtavia m√§√§ri√§ dataa, osaavia resursseja ja sopivaa laskentatehoa. T√§t√§ vaihtoehtoa kannattaa harkita vain, jos liiketoiminnalla on toimialakohtainen k√§ytt√∂tapaus ja suuri m√§√§r√§ toimialakohtaista dataa.

## Tietovisa

Mik√§ voisi olla hyv√§ tapa parantaa LLM:n t√§ydennystuloksia?

1. Promptin suunnittelu kontekstin kanssa  
1. RAG  
1. Hienos√§√§detty malli

V:3, jos sinulla on aikaa, resursseja ja laadukasta dataa, hienos√§√§t√∂ on parempi vaihtoehto pysy√§ ajan tasalla. Jos kuitenkin haluat parantaa asioita ja sinulla on v√§h√§n aikaa, kannattaa ensin harkita RAG:ia.

## üöÄ Haaste

Lue lis√§√§ siit√§, miten voit [k√§ytt√§√§ RAG:ia](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) liiketoiminnassasi.

## Hienoa ty√∂t√§, jatka oppimista

Kun olet suorittanut t√§m√§n oppitunnin, tutustu [Generative AI Learning -kokoelmaamme](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) jatkaaksesi generatiivisen teko√§lyn osaamisesi kehitt√§mist√§!

Siirry oppitunnille 3, jossa tarkastelemme, miten [rakentaa generatiivisella teko√§lyll√§ vastuullisesti](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§m√§ll√§ teko√§lypohjaista k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattik√§√§nn√∂ksiss√§ saattaa esiinty√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§iskielell√§ tulee pit√§√§ virallisena l√§hteen√§. T√§rkeiss√§ asioissa suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ aiheutuvista v√§√§rinymm√§rryksist√§ tai tulkinnoista.