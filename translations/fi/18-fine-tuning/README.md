<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-05-20T07:51:17+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "fi"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.8487555c3e3225eefc1dc84e72c8e00bce1ee76db867a080628fb0fbb04aa0d2.fi.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# LLM:n hienos√§√§t√∂

Suurten kielimallien k√§ytt√∂ generatiivisten teko√§lysovellusten rakentamisessa tuo mukanaan uusia haasteita. Keskeinen ongelma on varmistaa mallin tuottaman sis√§ll√∂n vastausten laatu (tarkkuus ja osuvuus) tiettyyn k√§ytt√§j√§n pyynt√∂√∂n. Aiemmissa oppitunneissa k√§sittelimme tekniikoita, kuten kehotteiden suunnittelua ja hakutulosten lis√§√§mist√§, jotka pyrkiv√§t ratkaisemaan ongelman _muokkaamalla olemassa olevan mallin sy√∂tekehotetta_.

T√§m√§n p√§iv√§n oppitunnilla k√§sittelemme kolmatta tekniikkaa, **hienos√§√§t√∂√§**, joka pyrkii ratkaisemaan haasteen _kouluttamalla mallin uudelleen_ lis√§datalla. Tutustutaan yksityiskohtiin.

## Oppimistavoitteet

T√§m√§ oppitunti esittelee hienos√§√§d√∂n k√§sitteen esikoulutetuille kielimalleille, tutkii t√§m√§n l√§hestymistavan etuja ja haasteita sek√§ antaa ohjeita siit√§, milloin ja miten hienos√§√§t√∂√§ tulisi k√§ytt√§√§ generatiivisten teko√§lymallien suorituskyvyn parantamiseksi.

Oppitunnin lopussa sinun pit√§isi osata vastata seuraaviin kysymyksiin:

- Mit√§ on hienos√§√§t√∂ kielimalleille?
- Milloin ja miksi hienos√§√§t√∂ on hy√∂dyllist√§?
- Kuinka voin hienos√§√§t√§√§ esikoulutetun mallin?
- Mitk√§ ovat hienos√§√§d√∂n rajoitukset?

Valmis? Aloitetaan.

## Kuvitettu opas

Haluatko saada kokonaiskuvan siit√§, mit√§ k√§sittelemme ennen kuin sukellamme yksityiskohtiin? Tutustu t√§h√§n kuvitettuun oppaaseen, joka kuvaa oppimismatkaa t√§m√§n oppitunnin aikana - hienos√§√§d√∂n ydink√§sitteiden ja motivaation oppimisesta prosessin ja parhaiden k√§yt√§nt√∂jen ymm√§rt√§miseen hienos√§√§t√∂teht√§v√§n suorittamiseksi. T√§m√§ on kiehtova aihe tutkia, joten muista tarkistaa [Resurssit](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) -sivu saadaksesi lis√§linkkej√§ tukemaan itseohjautuvaa oppimismatkaasi!

![Kuvitettu opas kielimallien hienos√§√§t√∂√∂n](../../../translated_images/18-fine-tuning-sketchnote.92733966235199dd260184b1aae3a84b877c7496bc872d8e63ad6fa2dd96bafc.fi.png)

## Mit√§ on hienos√§√§t√∂ kielimalleille?

M√§√§ritelm√§n mukaan suuret kielimallit ovat _esikoulutettuja_ suurilla m√§√§rill√§ teksti√§, jotka on ker√§tty monista eri l√§hteist√§, mukaan lukien internetist√§. Kuten olemme oppineet aiemmilla oppitunneilla, tarvitsemme tekniikoita kuten _kehotteiden suunnittelu_ ja _hakutulosten lis√§√§minen_ parantaaksemme mallin vastausten laatua k√§ytt√§j√§n kysymyksiin ("kehotteisiin").

Yksi suosittu kehotteiden suunnittelutekniikka sis√§lt√§√§ mallille enemm√§n ohjeistusta siit√§, mit√§ vastaukselta odotetaan joko antamalla _ohjeita_ (eksplisiittinen ohjeistus) tai _antamalla muutamia esimerkkej√§_ (implisiittinen ohjeistus). T√§t√§ kutsutaan _few-shot learningiksi_, mutta sill√§ on kaksi rajoitusta:

- Mallin token-rajoitukset voivat rajoittaa annettavien esimerkkien m√§√§r√§√§ ja vaikuttavuutta.
- Mallin token-kustannukset voivat tehd√§ esimerkkien lis√§√§misest√§ jokaiseen kehotteeseen kallista ja rajoittaa joustavuutta.

Hienos√§√§t√∂ on yleinen k√§yt√§nt√∂ koneoppimisj√§rjestelmiss√§, joissa otetaan esikoulutettu malli ja koulutetaan se uudelleen uudella datalla parantamaan sen suorituskyky√§ tietyss√§ teht√§v√§ss√§. Kielimallien yhteydess√§ voimme hienos√§√§t√§√§ esikoulutettua mallia _kuratoidulla esimerkkijoukolla tietty√§ teht√§v√§√§ tai sovellusaluetta varten_ luodaksemme **r√§√§t√§l√∂idyn mallin**, joka voi olla tarkempi ja osuvampi kyseiselle teht√§v√§lle tai alueelle. Hienos√§√§d√∂n sivuhy√∂tyn√§ on, ett√§ se voi my√∂s v√§hent√§√§ few-shot learningin tarvitsemien esimerkkien m√§√§r√§√§ - v√§hent√§en token-k√§ytt√∂√§ ja siihen liittyvi√§ kustannuksia.

## Milloin ja miksi meid√§n pit√§isi hienos√§√§t√§√§ malleja?

_T√§ss√§_ yhteydess√§, kun puhumme hienos√§√§d√∂st√§, viittaamme **valvottuun** hienos√§√§t√∂√∂n, jossa uudelleenkoulutus tapahtuu **lis√§√§m√§ll√§ uutta dataa**, joka ei ollut osa alkuper√§ist√§ koulutusdatajoukkoa. T√§m√§ eroaa valvomattomasta hienos√§√§t√∂l√§hestymistavasta, jossa malli koulutetaan uudelleen alkuper√§isell√§ datalla, mutta eri hyperparametreilla.

Keskeinen asia muistaa on, ett√§ hienos√§√§t√∂ on edistynyt tekniikka, joka vaatii tietyn tason asiantuntemusta haluttujen tulosten saavuttamiseksi. Jos se tehd√§√§n v√§√§rin, se ei v√§ltt√§m√§tt√§ tuota odotettuja parannuksia, ja saattaa jopa heikent√§√§ mallin suorituskyky√§ kohdealueellasi.

Joten ennen kuin opit "miten" hienos√§√§t√§√§ kielimalleja, sinun t√§ytyy tiet√§√§ "miksi" sinun pit√§isi valita t√§m√§ reitti ja "milloin" aloittaa hienos√§√§t√∂prosessi. Aloita kysym√§ll√§ itselt√§si n√§m√§ kysymykset:

- **K√§ytt√∂tapaus**: Mik√§ on hienos√§√§d√∂n _k√§ytt√∂tapauksesi_? Mit√§ nykyisen esikoulutetun mallin ominaisuutta haluat parantaa?
- **Vaihtoehdot**: Oletko kokeillut _muita tekniikoita_ saavuttaaksesi halutut tulokset? K√§yt√§ niit√§ vertailukohtana.
  - Kehotteiden suunnittelu: Kokeile tekniikoita, kuten few-shot kehotteita, esimerkeill√§ asiaankuuluvista kehotusvastauksista. Arvioi vastausten laatua.
  - Hakutulosten lis√§√§minen: Kokeile kehotteiden rikastamista hakemalla tuloksia datastasi. Arvioi vastausten laatua.
- **Kustannukset**: Oletko tunnistanut hienos√§√§d√∂n kustannukset?
  - S√§√§t√∂mahdollisuus - onko esikoulutettu malli saatavilla hienos√§√§t√∂√∂n?
  - Ty√∂m√§√§r√§ - koulutusdatan valmistelu, mallin arviointi ja hienos√§√§t√∂.
  - Laskentateho - hienos√§√§t√∂ty√∂teht√§vien suorittaminen ja hienos√§√§detyn mallin k√§ytt√∂√∂notto
  - Data - riitt√§v√§n laadukkaiden esimerkkien saatavuus hienos√§√§d√∂n vaikutusta varten
- **Hy√∂dyt**: Oletko vahvistanut hienos√§√§d√∂n hy√∂dyt?
  - Laatu - ylittik√∂ hienos√§√§detty malli vertailukohdan?
  - Kustannus - v√§hent√§√§k√∂ se token-k√§ytt√∂√§ yksinkertaistamalla kehotteita?
  - Laajennettavuus - voiko perusmallia k√§ytt√§√§ uudelleen uusille alueille?

Vastaamalla n√§ihin kysymyksiin sinun pit√§isi pysty√§ p√§√§tt√§m√§√§n, onko hienos√§√§t√∂ oikea l√§hestymistapa k√§ytt√∂tapauksellesi. Ihannetapauksessa l√§hestymistapa on p√§tev√§ vain, jos hy√∂dyt ylitt√§v√§t kustannukset. Kun p√§√§t√§t edet√§, on aika mietti√§ _miten_ voit hienos√§√§t√§√§ esikoulutetun mallin.

Haluatko saada lis√§√§ n√§kemyksi√§ p√§√§t√∂ksentekoprosessista? Katso [Hienos√§√§t√§√§k√∂ vai ei](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kuinka voimme hienos√§√§t√§√§ esikoulutetun mallin?

Hienos√§√§t√§√§ksesi esikoulutetun mallin, tarvitset:

- esikoulutetun mallin hienos√§√§t√∂√∂n
- datan hienos√§√§t√∂√§ varten
- koulutusymp√§rist√∂n hienos√§√§t√∂ty√∂n suorittamiseen
- is√§nn√∂intiy

mp√§rist√∂n hienos√§√§detyn mallin k√§ytt√∂√∂nottoon

## Hienos√§√§t√∂ k√§yt√§nn√∂ss√§

Seuraavat resurssit tarjoavat vaiheittaisia tutoriaaleja, jotka opastavat sinua todellisen esimerkin l√§pi valitun mallin ja kuratoidun datasetin avulla. Ty√∂skennell√§ksesi n√§iden tutoriaalien l√§pi tarvitset tilin tietylle palveluntarjoajalle sek√§ p√§√§syn kyseiseen malliin ja datasetteihin.

| Palveluntarjoaja | Tutoriaali                                                                                                                                                                       | Kuvaus                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ---------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI           | [Kuinka hienos√§√§t√§√§ chat-malleja](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Opi hienos√§√§t√§m√§√§n `gpt-35-turbo` tietylle alueelle ("reseptiassistentti") valmistelemalla koulutusdata, suorittamalla hienos√§√§t√∂ty√∂ ja k√§ytt√§m√§ll√§ hienos√§√§detty√§ mallia p√§√§ttelyyn.                                                                                                                                                                                                                                              |
| Azure OpenAI     | [GPT 3.5 Turbon hienos√§√§t√∂opas](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Opi hienos√§√§t√§m√§√§n `gpt-35-turbo-0613` -malli **Azurella** tekem√§ll√§ toimenpiteit√§ koulutusdatan luomiseksi ja lataamiseksi, hienos√§√§t√∂ty√∂n suorittamiseksi. Ota uusi malli k√§ytt√∂√∂n ja k√§yt√§ sit√§.                                                                                                                                                                                                                                                                 |
| Hugging Face     | [LLM:ien hienos√§√§t√∂ Hugging Facella](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | T√§m√§ blogikirjoitus opastaa sinua hienos√§√§t√§m√§√§n _avointa LLM:√§√§_ (esim. `CodeLlama 7B`) k√§ytt√§m√§ll√§ [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) -kirjastoa ja [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) avoimilla [dataseteill√§](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) Hugging Facella. |
|                  |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ü§ó AutoTrain     | [LLM:ien hienos√§√§t√∂ AutoTrainilla](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (tai AutoTrain Advanced) on Hugging Facen kehitt√§m√§ python-kirjasto, joka mahdollistaa hienos√§√§d√∂n monille eri teht√§ville, mukaan lukien LLM-hienos√§√§t√∂. AutoTrain on kooditon ratkaisu ja hienos√§√§t√∂ voidaan tehd√§ omassa pilvess√§si, Hugging Face Spacesissa tai paikallisesti. Se tukee sek√§ verkkopohjaista k√§ytt√∂liittym√§√§, CLI:t√§ ett√§ koulutusta yaml-konfiguraatiotiedostojen avulla.                                                                               |
|                  |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Teht√§v√§

Valitse yksi yll√§ olevista tutoriaaleista ja k√§y se l√§pi. _Saatamme toistaa version n√§ist√§ tutoriaaleista Jupyter Notebooksissa t√§ss√§ repossa vain viitteeksi. K√§yt√§ alkuper√§isi√§ l√§hteit√§ saadaksesi uusimmat versiot_.

## Hyv√§√§ ty√∂t√§! Jatka oppimistasi.

T√§m√§n oppitunnin suorittamisen j√§lkeen tutustu [Generatiivinen AI -oppimiskokoelmaamme](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) jatkaaksesi Generatiivisen AI -tiet√§myksesi syvent√§mist√§!

Onnittelut!! Olet suorittanut kurssin v2-sarjan viimeisen oppitunnin! √Ñl√§ lopeta oppimista ja rakentamista. \*\*Tutustu [RESURSSIT](RESOURCES.md?WT.mc_id=academic-105485-koreyst) -sivuun saadaksesi lis√§ehdotuksia juuri t√§h√§n aiheeseen.

My√∂s v1-sarjamme oppitunteja on p√§ivitetty lis√§√§m√§ll√§ enemm√§n teht√§vi√§ ja k√§sitteit√§. Joten k√§yt√§ hetki p√§ivitt√§√§ksesi tietosi - ja jaa [kysymyksesi ja palautteesi](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) auttaaksesi meit√§ parantamaan n√§it√§ oppitunteja yhteis√∂lle.

**Vastuuvapauslauseke**:  
T√§m√§ asiakirja on k√§√§nnetty k√§ytt√§en AI-k√§√§nn√∂spalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, huomioithan, ett√§ automaattiset k√§√§nn√∂kset voivat sis√§lt√§√§ virheit√§ tai ep√§tarkkuuksia. Alkuper√§ist√§ asiakirjaa sen alkuper√§isell√§ kielell√§ tulisi pit√§√§ auktoritatiivisena l√§hteen√§. Kriittisen tiedon osalta suositellaan ammattimaista ihmisk√§√§nn√∂st√§. Emme ole vastuussa t√§m√§n k√§√§nn√∂ksen k√§yt√∂st√§ johtuvista v√§√§rink√§sityksist√§ tai virhetulkinnoista.