{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI -mallien hienosäätö\n",
    "\n",
    "Tämä muistikirja perustuu Open AI:n nykyisiin ohjeisiin, jotka löytyvät [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) -dokumentaatiosta.\n",
    "\n",
    "Hienosäätö parantaa perustamallien suorituskykyä sovelluksessasi uudelleenkouluttamalla mallia lisätyllä datalla ja kontekstilla, joka liittyy kyseiseen käyttötapaukseen tai tilanteeseen. Huomaa, että kehotteiden suunnittelutekniikat kuten _few shot learning_ ja _retrieval augmented generation_ mahdollistavat oletuskehotteen parantamisen asiaankuuluvalla datalla laadun parantamiseksi. Näillä lähestymistavoilla on kuitenkin rajoitus kohdemallin maksimimerkkimäärän suhteen.\n",
    "\n",
    "Hienosäädöllä koulutamme mallia käytännössä uudelleen tarvittavalla datalla (jolloin voimme käyttää paljon enemmän esimerkkejä kuin mitä mahtuu maksimimerkkimäärään) – ja otamme käyttöön _räätälöidyn_ version mallista, joka ei enää tarvitse esimerkkejä syötteen yhteydessä. Tämä parantaa paitsi kehotteen suunnittelun tehokkuutta (meillä on enemmän joustavuutta käyttää merkkimäärää muihin asioihin) myös mahdollisesti alentaa kustannuksia (vähentämällä mallille lähetettävien merkkien määrää syötteen yhteydessä).\n",
    "\n",
    "Hienosäädössä on 4 vaihetta:\n",
    "1. Valmistele koulutusdata ja lataa se.\n",
    "1. Suorita koulutusprosessi saadaksesi hienosäädetyn mallin.\n",
    "1. Arvioi hienosäädetty malli ja toista laadun parantamiseksi.\n",
    "1. Ota hienosäädetty malli käyttöön ennustettaessa, kun olet tyytyväinen.\n",
    "\n",
    "Huomaa, että kaikki perustamallit eivät tue hienosäätöä – [tarkista OpenAI:n dokumentaatiosta](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) viimeisimmät tiedot. Voit myös hienosäätää aiemmin hienosäädettyä mallia. Tässä opetusohjelmassa käytämme kohdemallina hienosäätöön `gpt-35-turbo` -mallia.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaihe 1.1: Valmistele aineistosi\n",
    "\n",
    "Rakennetaan chatbot, joka auttaa sinua ymmärtämään alkuaineiden jaksollista järjestelmää vastaamalla kysymyksiin alkuaineesta limerikin muodossa. Tässä yksinkertaisessa opetusohjelmassa luomme vain aineiston, jolla koulutamme mallin muutamilla esimerkkivastauksilla, jotka näyttävät odotetun tietomuodon. Todellisessa käyttötapauksessa sinun täytyy luoda aineisto paljon suuremmalla määrällä esimerkkejä. Saatat myös pystyä käyttämään avointa aineistoa (sovellusalueellesi), jos sellainen on olemassa, ja muotoilemaan sen uudelleen hienosäätöä varten.\n",
    "\n",
    "Koska keskitymme `gpt-35-turbo` -malliin ja haemme yksivaiheista vastausta (chat completion), voimme luoda esimerkkejä käyttäen [tätä ehdotettua muotoa](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), joka vastaa OpenAI:n chat completion -vaatimuksia. Jos odotat monivaiheista keskustelusisältöä, käyttäisit [monivaiheista esimerkkimuotoa](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), joka sisältää `weight`-parametrin ilmaistakseen, mitkä viestit tulisi ottaa mukaan (tai jättää pois) hienosäätöprosessissa.\n",
    "\n",
    "Käytämme tässä opetusohjelmassa yksinkertaisempaa yksivaiheista muotoa. Aineisto on [jsonl-muodossa](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst), jossa on yksi tietue per rivi, kukin JSON-muotoisena objektina. Alla oleva katkelma näyttää 2 tietuetta esimerkkinä – katso [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) koko esimerkkijoukkoa (10 esimerkkiä), jota käytämme hienosäätöopetuksessa. **Huom:** Jokainen tietue _täytyy_ määritellä yhdelle riville (ei jaettuna useammalle riville kuten tyypillisessä muotoillussa JSON-tiedostossa).\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Todellisessa käyttötapauksessa tarvitset paljon suuremman esimerkkijoukon hyvien tulosten saavuttamiseksi – kompromissi on vastausten laadun ja hienosäädön ajan/kustannusten välillä. Käytämme pientä joukkoa, jotta voimme suorittaa hienosäädön nopeasti ja havainnollistaa prosessia. Katso [tämä OpenAI Cookbook -esimerkki](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) monimutkaisemmasta hienosäätöoppaasta.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vaihe 1.2 Lataa tietojoukko\n",
    "\n",
    "Lataa tiedot käyttämällä Files API:a [kuten tässä on kuvattu](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Huomaa, että tämän koodin suorittamiseksi sinun on ensin tehtävä seuraavat vaiheet:\n",
    " - Asenna `openai` Python-paketti (varmista, että käytät versiota >=0.28.0 uusimpien ominaisuuksien vuoksi)\n",
    " - Aseta `OPENAI_API_KEY`-ympäristömuuttuja OpenAI API -avaimellasi\n",
    "Lisätietoja saat [Asennusoppaasta](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), joka on kurssilla tarjottu.\n",
    "\n",
    "Suorita nyt koodi luodaksesi tiedoston latausta varten paikallisesta JSONL-tiedostostasi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vaihe 2.1: Luo hienosäätötyö SDK:lla\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vaihe 2.2: Tarkista työn tila\n",
    "\n",
    "Tässä on muutamia asioita, joita voit tehdä `client.fine_tuning.jobs` -rajapinnalla:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Listaa viimeiset n hienosäätötyötä\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Hae tietoja tietystä hienosäätötyöstä\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Peruuta hienosäätötyö\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Listaa enintään n tapahtumaa työstä\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Prosessin ensimmäinen vaihe on _koulutustiedoston validointi_, jotta varmistetaan, että data on oikeassa muodossa.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vaihe 2.3: Seuraa tapahtumia edistymisen seuraamiseksi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaihe 2.4: Tarkastele tilaa OpenAI-hallintapaneelissa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voit myös tarkastella tilaa vierailemalla OpenAI:n verkkosivustolla ja tutkimalla alustan _Fine-tuning_-osiota. Tämä näyttää sinulle nykyisen työn tilan ja antaa myös seurata aiempien työn suorituskertojen historiaa. Tässä kuvakaappauksessa näet, että aiempi suoritus epäonnistui ja toinen suoritus onnistui. Kontekstin vuoksi tämä tapahtui, kun ensimmäisessä suorituksessa käytettiin JSON-tiedostoa, jossa oli väärin muotoiltuja tietueita – kun ne korjattiin, toinen suoritus valmistui onnistuneesti ja teki mallin käyttövalmiiksi.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fi/fine-tuned-model-status.563271727bf7bfba.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voit myös tarkastella tilaviestejä ja mittareita selaamalla alaspäin visuaalisessa kojelaudassa, kuten alla on esitetty:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fi/fine-tuned-messages-panel.4ed0c2da5ea1313b.png) |  ![Metrics](../../../../../translated_images/fi/fine-tuned-metrics-panel.700d7e4995a65229.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vaihe 3.1: Hae tunnus ja testaa hienosäädetty malli koodissa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Vaihe 3.2: Lataa ja testaa hienosäädetty malli Playgroundissa\n",
    "\n",
    "Voit nyt testata hienosäädettyä mallia kahdella tavalla. Ensinnäkin voit vierailla Playgroundissa ja käyttää Models-pudotusvalikkoa valitaksesi juuri hienosäädetyn mallisi listatuista vaihtoehdoista. Toinen vaihtoehto on käyttää Fine-tuning-paneelissa näkyvää \"Playground\"-vaihtoehtoa (katso yllä oleva kuvakaappaus), joka avaa seuraavan _vertailunäkymän_, jossa perustason ja hienosäädetyn mallin versiot näkyvät rinnakkain nopeaa arviointia varten.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fi/fine-tuned-playground-compare.56e06f0ad8922016.png)\n",
    "\n",
    "Täytä yksinkertaisesti järjestelmäkonteksti, jota käytit koulutusdatassasi, ja anna testikysymyksesi. Huomaat, että molemmat puolet päivittyvät identtisellä kontekstilla ja kysymyksellä. Suorita vertailu, niin näet eron niiden vastausten välillä. _Huomaa, miten hienosäädetty malli tuottaa vastauksen siinä muodossa, jonka annoit esimerkeissäsi, kun taas perustason malli noudattaa yksinkertaisesti järjestelmän kehotetta_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fi/fine-tuned-playground-launch.5a26495c983c6350.png)\n",
    "\n",
    "Huomaat myös, että vertailu näyttää tokenien määrän kullekin mallille sekä päättelyn suorittamiseen kuluneen ajan. **Tämä esimerkki on yksinkertainen ja tarkoitettu prosessin näyttämiseen, eikä se heijasta todellista datasarjaa tai tilannetta**. Saatat huomata, että molemmissa näytteissä on sama määrä tokeneita (järjestelmäkonteksti ja käyttäjän kehotus ovat identtiset), mutta hienosäädetty malli vie enemmän aikaa päättelyyn (mukautettu malli).\n",
    "\n",
    "Todellisissa tilanteissa et käytä tällaista leikkiesimerkkiä, vaan hienosäätö tehdään todelliseen dataan (esim. tuoteluettelo asiakaspalvelua varten), jolloin vastausten laatu on paljon ilmeisempi. _Tässä_ kontekstissa vastaavanlaisen vastauslaadun saaminen perustason mallilla vaatii enemmän mukautettua kehotteiden suunnittelua, mikä lisää tokenien käyttöä ja mahdollisesti myös päättelyyn kuluvaa aikaa. _Kokeillaksesi tätä, tutustu OpenAI Cookbookin hienosäätöesimerkkeihin._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Vastuuvapauslauseke**:\nTämä asiakirja on käännetty käyttämällä tekoälypohjaista käännöspalvelua [Co-op Translator](https://github.com/Azure/co-op-translator). Vaikka pyrimme tarkkuuteen, otathan huomioon, että automaattikäännöksissä saattaa esiintyä virheitä tai epätarkkuuksia. Alkuperäinen asiakirja sen alkuperäiskielellä on virallinen lähde. Tärkeissä asioissa suositellaan ammattimaista ihmiskäännöstä. Emme ole vastuussa tämän käännöksen käytöstä aiheutuvista väärinymmärryksistä tai tulkinnoista.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T10:44:06+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "fi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}