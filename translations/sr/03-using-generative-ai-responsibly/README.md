<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:51:51+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "sr"
}
-->
# Odgovorno koriÅ¡Ä‡enje generativne veÅ¡taÄke inteligencije

> _Kliknite na sliku iznad da biste pogledali video lekciju_

Lako je biti fasciniran veÅ¡taÄkom inteligencijom, a posebno generativnom veÅ¡taÄkom inteligencijom, ali treba razmisliti kako je koristiti odgovorno. Treba uzeti u obzir kako obezbediti da rezultati budu praviÄni, neÅ¡tetni i joÅ¡ mnogo toga. Ovo poglavlje ima za cilj da vam pruÅ¾i kontekst, Å¡ta treba uzeti u obzir i kako preduzeti aktivne korake za poboljÅ¡anje vaÅ¡eg koriÅ¡Ä‡enja veÅ¡taÄke inteligencije.

## Uvod

Ova lekcija Ä‡e pokriti:

- ZaÅ¡to bi trebalo da prioritizujete Odgovornu veÅ¡taÄku inteligenciju prilikom izgradnje aplikacija sa generativnom veÅ¡taÄkom inteligencijom.
- Osnovne principe Odgovorne veÅ¡taÄke inteligencije i kako se oni odnose na generativnu veÅ¡taÄku inteligenciju.
- Kako primeniti ove principe Odgovorne veÅ¡taÄke inteligencije kroz strategiju i alate.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije znaÄ‡ete:

- ZnaÄaj Odgovorne veÅ¡taÄke inteligencije prilikom izgradnje aplikacija sa generativnom veÅ¡taÄkom inteligencijom.
- Kada razmiÅ¡ljati i primeniti osnovne principe Odgovorne veÅ¡taÄke inteligencije prilikom izgradnje aplikacija sa generativnom veÅ¡taÄkom inteligencijom.
- Koji alati i strategije su vam dostupni da biste koncept Odgovorne veÅ¡taÄke inteligencije sproveli u praksu.

## Principi Odgovorne veÅ¡taÄke inteligencije

UzbuÄ‘enje oko generativne veÅ¡taÄke inteligencije nikada nije bilo veÄ‡e. Ovo uzbuÄ‘enje je privuklo mnogo novih programera, paÅ¾nje i finansiranja u ovu oblast. Iako je ovo veoma pozitivno za svakoga ko Å¾eli da gradi proizvode i kompanije koristeÄ‡i generativnu veÅ¡taÄku inteligenciju, vaÅ¾no je da postupamo odgovorno.

Tokom ovog kursa, fokusiramo se na izgradnju naÅ¡eg startapa i naÅ¡eg proizvoda za edukaciju o veÅ¡taÄkoj inteligenciji. KoristiÄ‡emo principe Odgovorne veÅ¡taÄke inteligencije: PraviÄnost, UkljuÄivost, Pouzdanost/Sigurnost, Bezbednost i Privatnost, Transparentnost i Odgovornost. Sa ovim principima, istraÅ¾iÄ‡emo kako se oni odnose na naÅ¡e koriÅ¡Ä‡enje generativne veÅ¡taÄke inteligencije u naÅ¡im proizvodima.

## ZaÅ¡to bi trebalo da prioritizujete Odgovornu veÅ¡taÄku inteligenciju

Prilikom izgradnje proizvoda, pristup usmeren na ljude koji ima u vidu najbolji interes korisnika vodi do najboljih rezultata.

Jedinstvenost generativne veÅ¡taÄke inteligencije je njena moÄ‡ da stvara korisne odgovore, informacije, smernice i sadrÅ¾aj za korisnike. Ovo se moÅ¾e postiÄ‡i bez mnogo manuelnih koraka, Å¡to moÅ¾e dovesti do veoma impresivnih rezultata. Bez odgovarajuÄ‡eg planiranja i strategija, to takoÄ‘e moÅ¾e naÅ¾alost dovesti do nekih Å¡tetnih rezultata za vaÅ¡e korisnike, vaÅ¡ proizvod i druÅ¡tvo u celini.

Pogledajmo neke (ali ne sve) od tih potencijalno Å¡tetnih rezultata:

### Halucinacije

Halucinacije su termin koji se koristi da opiÅ¡e kada LLM proizvodi sadrÅ¾aj koji je ili potpuno besmislen ili neÅ¡to Å¡to znamo da je ÄinjeniÄno pogreÅ¡no na osnovu drugih izvora informacija.

Uzmimo na primer da gradimo funkciju za naÅ¡ startap koja omoguÄ‡ava studentima da postavljaju istorijska pitanja modelu. Student postavlja pitanje `Who was the sole survivor of Titanic?`

Model proizvodi odgovor kao Å¡to je onaj ispod:

Ovo je veoma samouveren i detaljan odgovor. NaÅ¾alost, on je netaÄan. ÄŒak i sa minimalnom koliÄinom istraÅ¾ivanja, neko bi otkrio da je viÅ¡e od jedne osobe preÅ¾ivelo nesreÄ‡u Titanika. Za studenta koji tek poÄinje da istraÅ¾uje ovu temu, ovaj odgovor moÅ¾e biti dovoljno ubedljiv da ne bude doveden u pitanje i tretiran kao Äinjenica. Posledice ovoga mogu dovesti do toga da AI sistem bude nepouzdan i negativno utiÄe na reputaciju naÅ¡eg startapa.

Sa svakom iteracijom bilo kog datog LLM-a, videli smo poboljÅ¡anja u performansama u vezi sa minimizacijom halucinacija. ÄŒak i sa ovim poboljÅ¡anjem, mi kao graditelji aplikacija i korisnici i dalje moramo biti svesni ovih ograniÄenja.

### Å tetni sadrÅ¾aj

Pokrijemo u prethodnom delu kada LLM proizvodi netaÄne ili besmislene odgovore. Drugi rizik o kojem moramo biti svesni je kada model odgovara Å¡tetnim sadrÅ¾ajem.

Å tetni sadrÅ¾aj moÅ¾e biti definisan kao:

- PruÅ¾anje uputstava ili podsticanje na samopovreÄ‘ivanje ili povreÄ‘ivanje odreÄ‘enih grupa.
- Mrziteljski ili poniÅ¾avajuÄ‡i sadrÅ¾aj.
- Usmeravanje planiranja bilo kakvih napada ili nasilnih dela.
- PruÅ¾anje uputstava o tome kako pronaÄ‡i ilegalan sadrÅ¾aj ili poÄiniti ilegalna dela.
- Prikazivanje seksualno eksplicitnog sadrÅ¾aja.

Za naÅ¡ startap, Å¾elimo da budemo sigurni da imamo prave alate i strategije na mestu kako bismo spreÄili da ovaj tip sadrÅ¾aja bude viÄ‘en od strane studenata.

### Nedostatak praviÄnosti

PraviÄnost je definisana kao â€œosiguravanje da je AI sistem slobodan od pristrasnosti i diskriminacije i da se prema svima odnosi praviÄno i jednako.â€ U svetu generativne veÅ¡taÄke inteligencije, Å¾elimo da osiguramo da iskljuÄujuÄ‡i svetski pogledi marginalizovanih grupa nisu ojaÄani izlazom modela.

Ovi tipovi izlaza nisu samo destruktivni za izgradnju pozitivnih iskustava proizvoda za naÅ¡e korisnike, veÄ‡ uzrokuju i dalju druÅ¡tvenu Å¡tetu. Kao graditelji aplikacija, uvek treba da imamo Å¡iroku i raznoliku bazu korisnika na umu kada gradimo reÅ¡enja sa generativnom veÅ¡taÄkom inteligencijom.

## Kako koristiti generativnu veÅ¡taÄku inteligenciju odgovorno

Sada kada smo identifikovali znaÄaj Odgovorne generativne veÅ¡taÄke inteligencije, hajde da pogledamo 4 koraka koje moÅ¾emo preduzeti da odgovorno gradimo naÅ¡a AI reÅ¡enja:

### Merenje potencijalnih Å¡teta

U testiranju softvera, testiramo oÄekivane akcije korisnika na aplikaciji. SliÄno tome, testiranje raznovrsnog skupa upita koje korisnici najverovatnije koriste je dobar naÄin za merenje potencijalne Å¡tete.

PoÅ¡to naÅ¡ startap gradi edukativni proizvod, bilo bi dobro pripremiti listu upita vezanih za edukaciju. Ovo bi moglo pokriti odreÄ‘eni predmet, istorijske Äinjenice i upite o studentskom Å¾ivotu.

### UblaÅ¾avanje potencijalnih Å¡teta

Sada je vreme da pronaÄ‘emo naÄine kako moÅ¾emo spreÄiti ili ograniÄiti potencijalnu Å¡tetu uzrokovanu modelom i njegovim odgovorima. Ovo moÅ¾emo pogledati u 4 razliÄita sloja:

- **Model**. Biranje pravog modela za pravi sluÄaj upotrebe. VeÄ‡i i sloÅ¾eniji modeli poput GPT-4 mogu izazvati veÄ‡i rizik od Å¡tetnog sadrÅ¾aja kada se primenjuju na manje i specifiÄne sluÄajeve upotrebe. KoriÅ¡Ä‡enje vaÅ¡ih podataka za obuku za fino podeÅ¡avanje takoÄ‘e smanjuje rizik od Å¡tetnog sadrÅ¾aja.

- **Sigurnosni sistem**. Sigurnosni sistem je skup alata i konfiguracija na platformi koja sluÅ¾i modelu kako bi pomogla u ublaÅ¾avanju Å¡tete. Primer ovoga je sistem za filtriranje sadrÅ¾aja na Azure OpenAI servisu. Sistemi takoÄ‘e treba da detektuju napade iz zatvora i neÅ¾eljene aktivnosti poput zahteva od strane botova.

- **Metaprompt**. Metaprompts i uzemljenje su naÄini na koje moÅ¾emo usmeriti ili ograniÄiti model na osnovu odreÄ‘enih ponaÅ¡anja i informacija. Ovo bi moglo biti koriÅ¡Ä‡enje ulaza sistema za definisanje odreÄ‘enih granica modela. Pored toga, pruÅ¾anje izlaza koji su relevantniji za obim ili domen sistema.

TakoÄ‘e moÅ¾e biti koriÅ¡Ä‡enje tehnika poput Retrieval Augmented Generation (RAG) kako bi model povlaÄio informacije samo iz odabranih pouzdanih izvora. Postoji lekcija kasnije u ovom kursu za [izgradnju pretraÅ¾ivaÄkih aplikacija](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **KorisniÄko iskustvo**. Poslednji sloj je gde korisnik direktno komunicira sa modelom kroz interfejs naÅ¡e aplikacije na neki naÄin. Na ovaj naÄin moÅ¾emo dizajnirati UI/UX kako bismo ograniÄili korisnika na tipove unosa koje mogu poslati modelu, kao i tekst ili slike prikazane korisniku. Kada implementiramo AI aplikaciju, takoÄ‘e moramo biti transparentni o tome Å¡ta naÅ¡a generativna veÅ¡taÄka inteligencija moÅ¾e i ne moÅ¾e da uradi.

Imamo celu lekciju posveÄ‡enu [dizajniranju UX za AI aplikacije](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluacija modela**. Rad sa LLM-ovima moÅ¾e biti izazovno jer nemamo uvek kontrolu nad podacima na kojima je model obuÄen. Bez obzira na to, uvek treba da procenimo performanse i izlaze modela. I dalje je vaÅ¾no meriti taÄnost, sliÄnost, uzemljenost i relevantnost izlaza modela. Ovo pomaÅ¾e da se obezbedi transparentnost i poverenje za zainteresovane strane i korisnike.

### Operativno odgovorno generativno AI reÅ¡enje

Izgradnja operativne prakse oko vaÅ¡ih AI aplikacija je poslednja faza. Ovo ukljuÄuje partnerstvo sa drugim delovima naÅ¡eg startapa kao Å¡to su Pravni i Bezbednosni kako bismo osigurali da smo u skladu sa svim regulatornim politikama. Pre lansiranja, takoÄ‘e Å¾elimo da izgradimo planove oko isporuke, reÅ¡avanja incidenata i vraÄ‡anja na prethodno stanje kako bismo spreÄili bilo kakvu Å¡tetu naÅ¡im korisnicima od rasta.

## Alati

Iako rad na razvoju reÅ¡enja za Odgovornu veÅ¡taÄku inteligenciju moÅ¾e izgledati kao mnogo posla, to je posao koji se isplati. Kako oblast generativne veÅ¡taÄke inteligencije raste, sve viÅ¡e alata za pomoÄ‡ programerima da efikasno integriÅ¡u odgovornost u svoje radne tokove Ä‡e sazrevati. Na primer, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) moÅ¾e pomoÄ‡i u otkrivanju Å¡tetnog sadrÅ¾aja i slika putem API zahteva.

## Provera znanja

Na koje stvari treba da obratite paÅ¾nju kako biste osigurali odgovorno koriÅ¡Ä‡enje veÅ¡taÄke inteligencije?

1. Da je odgovor taÄan.
1. Å tetna upotreba, da se AI ne koristi u kriminalne svrhe.
1. Osiguranje da je AI slobodan od pristrasnosti i diskriminacije.

A: 2 i 3 su taÄne. Odgovorna veÅ¡taÄka inteligencija pomaÅ¾e vam da razmislite kako da ublaÅ¾ite Å¡tetne efekte i pristrasnosti i joÅ¡ mnogo toga.

## ğŸš€ Izazov

ProÄitajte viÅ¡e o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) i vidite Å¡ta moÅ¾ete usvojiti za svoju upotrebu.

## OdliÄan rad, nastavite sa uÄenjem

Nakon zavrÅ¡etka ove lekcije, pogledajte naÅ¡u [kolekciju za uÄenje o generativnoj veÅ¡taÄkoj inteligenciji](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili sa unapreÄ‘ivanjem svog znanja o generativnoj veÅ¡taÄkoj inteligenciji!

PreÄ‘ite na Lekciju 4 gde Ä‡emo pogledati [osnove inÅ¾enjeringa upita](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**ĞĞ´Ñ€Ğ¸Ñ†Ğ°ÑšĞµ Ğ¾Ğ´ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾ÑÑ‚Ğ¸**:  
ĞĞ²Ğ°Ñ˜ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ñ˜Ğµ Ğ¿Ñ€ĞµĞ²ĞµĞ´ĞµĞ½ ĞºĞ¾Ñ€Ğ¸ÑˆÑ›ĞµÑšĞµĞ¼ ÑƒÑĞ»ÑƒĞ³Ğµ Ğ·Ğ° Ğ¿Ñ€ĞµĞ²Ğ¾Ñ’ĞµÑšĞµ Ğ¿Ğ¾Ğ¼Ğ¾Ñ›Ñƒ Ğ²ĞµÑˆÑ‚Ğ°Ñ‡ĞºĞµ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ¸Ğ³ĞµĞ½Ñ†Ğ¸Ñ˜Ğµ [Co-op Translator](https://github.com/Azure/co-op-translator). Ğ˜Ğ°ĞºĞ¾ ÑĞµ Ñ‚Ñ€ÑƒĞ´Ğ¸Ğ¼Ğ¾ Ğ´Ğ° Ğ¾Ğ±ĞµĞ·Ğ±ĞµĞ´Ğ¸Ğ¼Ğ¾ Ñ‚Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚, Ğ¸Ğ¼Ğ°Ñ˜Ñ‚Ğµ Ğ½Ğ° ÑƒĞ¼Ñƒ Ğ´Ğ° Ğ°ÑƒÑ‚Ğ¾Ğ¼Ğ°Ñ‚ÑĞºĞ¸ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´Ğ¸ Ğ¼Ğ¾Ğ³Ñƒ ÑĞ°Ğ´Ñ€Ğ¶Ğ°Ñ‚Ğ¸ Ğ³Ñ€ĞµÑˆĞºĞµ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑ‚Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğ½Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ½Ğ° ÑĞ²Ğ¾Ğ¼ Ğ¸Ğ·Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ñ˜ĞµĞ·Ğ¸ĞºÑƒ Ñ‚Ñ€ĞµĞ±Ğ° ÑĞ¼Ğ°Ñ‚Ñ€Ğ°Ñ‚Ğ¸ Ğ¼ĞµÑ€Ğ¾Ğ´Ğ°Ğ²Ğ½Ğ¸Ğ¼ Ğ¸Ğ·Ğ²Ğ¾Ñ€Ğ¾Ğ¼. Ğ—Ğ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ˜Ğµ, Ğ¿Ñ€ĞµĞ¿Ğ¾Ñ€ÑƒÑ‡ÑƒÑ˜Ğµ ÑĞµ Ğ¿Ñ€Ğ¾Ñ„ĞµÑĞ¸Ğ¾Ğ½Ğ°Ğ»Ğ½Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´ Ğ¾Ğ´ ÑÑ‚Ñ€Ğ°Ğ½Ğµ Ñ™ÑƒĞ´Ğ¸. ĞĞ¸ÑĞ¼Ğ¾ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¸ Ğ·Ğ° Ğ±Ğ¸Ğ»Ğ¾ ĞºĞ°ĞºĞ²Ğ° Ğ½ĞµÑĞ¿Ğ¾Ñ€Ğ°Ğ·ÑƒĞ¼Ğ° Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ³Ñ€ĞµÑˆĞ½Ğ° Ñ‚ÑƒĞ¼Ğ°Ñ‡ĞµÑšĞ° ĞºĞ¾Ñ˜Ğ° Ğ¼Ğ¾Ğ³Ñƒ Ğ½Ğ°ÑÑ‚Ğ°Ñ‚Ğ¸ ĞºĞ¾Ñ€Ğ¸ÑˆÑ›ĞµÑšĞµĞ¼ Ğ¾Ğ²Ğ¾Ğ³ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´Ğ°.