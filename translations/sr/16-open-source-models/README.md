<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a8b2d4bb727c877ebf9edff8623d16b9",
  "translation_date": "2025-09-06T10:24:49+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "sr"
}
-->
[![Open Source Models](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.sr.png)](https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst)

## Увод

Свет отворених LLM модела је узбудљив и стално се развија. Ова лекција има за циљ да пружи детаљан увид у отворене моделе. Ако тражите информације о томе како се власнички модели упоређују са отвореним моделима, посетите лекцију ["Истраживање и упоређивање различитих LLM модела"](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst). Ова лекција ће такође обухватити тему фино подешавања, али детаљније објашњење можете пронаћи у лекцији ["Фино подешавање LLM модела"](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst).

## Циљеви учења

- Разумевање отворених модела
- Разумевање предности рада са отвореним моделима
- Истраживање доступних отворених модела на Hugging Face и Azure AI Studio

## Шта су отворени модели?

Отворени софтвер је одиграо кључну улогу у развоју технологије у различитим областима. Open Source Initiative (OSI) је дефинисао [10 критеријума за софтвер](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst) да би био класификован као отворен. Изворни код мора бити отворено доступан под лиценцом коју је одобрио OSI.

Иако развој LLM модела има сличне елементе као развој софтвера, процес није потпуно исти. Ово је довело до многих дискусија у заједници о дефиницији отвореног кода у контексту LLM модела. Да би модел био у складу са традиционалном дефиницијом отвореног кода, следеће информације треба да буду јавно доступне:

- Скупови података коришћени за обуку модела.
- Комплетне тежине модела као део обуке.
- Код за евалуацију.
- Код за фино подешавање.
- Комплетне тежине модела и метрике обуке.

Тренутно постоји само неколико модела који испуњавају ове критеријуме. [OLMo модел који је креирао Allen Institute for Artificial Intelligence (AllenAI)](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst) је један од њих.

За потребе ове лекције, моделе ћемо називати "отворени модели" јер можда не испуњавају горе наведене критеријуме у време писања.

## Предности отворених модела

**Висока прилагодљивост** - Пошто су отворени модели објављени са детаљним информацијама о обуци, истраживачи и програмери могу модификовати унутрашњост модела. Ово омогућава креирање високо специјализованих модела који су фино подешени за одређени задатак или област истраживања. Неки примери су генерисање кода, математичке операције и биологија.

**Цена** - Цена по токену за коришћење и примену ових модела је нижа у поређењу са власничким моделима. Приликом изградње апликација за генеративну вештачку интелигенцију, треба размотрити однос перформанси и цене у контексту вашег случаја употребе.

![Model Cost](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.sr.png)  
Извор: Artificial Analysis

**Флексибилност** - Рад са отвореним моделима омогућава флексибилност у коришћењу различитих модела или њиховом комбиновању. Пример за ово је [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst), где корисник може директно у корисничком интерфејсу изабрати модел који се користи:

![Choose Model](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.sr.png)

## Истраживање различитих отворених модела

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), који је развио Meta, је отворени модел оптимизован за апликације засноване на разговору. Ово је резултат методе фино подешавања која је укључивала велики број дијалога и повратних информација од људи. Овом методом модел производи резултате који су више у складу са људским очекивањима, што пружа боље корисничко искуство.

Неки примери фино подешених верзија Llama модела укључују [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst), који је специјализован за јапански језик, и [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), који је побољшана верзија основног модела.

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) је отворени модел са снажним фокусом на високе перформансе и ефикасност. Користи приступ Mixture-of-Experts, који комбинује групу специјализованих експертских модела у један систем где се, у зависности од уноса, одређени модели бирају за употребу. Ово чини рачунање ефикаснијим јер модели обрађују само уносе за које су специјализовани.

Неки примери фино подешених верзија Mistral модела укључују [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst), који је фокусиран на медицинску област, и [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), који обавља математичке прорачуне.

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) је LLM који је креирао Technology Innovation Institute (**TII**). Falcon-40B је обучен на 40 милијарди параметара, што је показало боље перформансе од GPT-3 уз мањи рачунарски буџет. Ово је резултат коришћења FlashAttention алгоритма и multiquery attention, који омогућавају смањење захтева за меморијом током времена инференције. Са овим смањеним временом инференције, Falcon-40B је погодан за апликације засноване на разговору.

Неки примери фино подешених верзија Falcon модела су [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst), асистент изграђен на отвореним моделима, и [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), који пружа боље перформансе од основног модела.

## Како изабрати

Не постоји један одговор на питање како изабрати отворени модел. Добро место за почетак је коришћење функције Azure AI Studio за филтрирање по задацима. Ово ће вам помоћи да разумете за које типове задатака је модел обучен. Hugging Face такође одржава LLM Leaderboard, који приказује најбоље моделе на основу одређених метрика.

Када желите да упоредите LLM моделе различитих типова, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) је још један одличан ресурс:

![Model Quality](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.sr.png)  
Извор: Artificial Analysis

Ако радите на специфичном случају употребе, претрага фино подешених верзија које су фокусиране на исту област може бити ефикасна. Експериментисање са више отворених модела како бисте видели како се они понашају у складу са вашим и очекивањима ваших корисника је још једна добра пракса.

## Следећи кораци

Најбољи део код отворених модела је то што можете брзо почети да радите са њима. Погледајте [Azure AI Foundry Model Catalog](https://ai.azure.com?WT.mc_id=academic-105485-koreyst), који садржи специфичну Hugging Face колекцију са моделима о којима смо овде говорили.

## Учење се не завршава овде, наставите путовање

Након завршетка ове лекције, погледајте нашу [Generative AI Learning колекцију](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) како бисте наставили да унапређујете своје знање о генеративној вештачкој интелигенцији!

---

**Одрицање од одговорности**:  
Овај документ је преведен коришћењем услуге за превођење помоћу вештачке интелигенције [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да обезбедимо тачност, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални превод од стране људи. Не преузимамо одговорност за било каква погрешна тумачења или неспоразуме који могу настати услед коришћења овог превода.