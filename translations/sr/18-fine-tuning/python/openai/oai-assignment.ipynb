{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фајн тунинг Open AI модела\n",
    "\n",
    "Овај нотебук је заснован на тренутним упутствима из [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) документације Open AI.\n",
    "\n",
    "Фајн тунинг побољшава перформансе основних модела за вашу апликацију поновним тренирањем са додатним подацима и контекстом релевантним за тај конкретан случај употребе или сценарио. Имајте у виду да технике инжењеринга упита као што су _few shot learning_ и _retrieval augmented generation_ омогућавају да побољшате подразумевани упит релевантним подацима како бисте побољшали квалитет. Међутим, ови приступи су ограничени максималном величином прозора токена циљаног основног модела.\n",
    "\n",
    "Фајн тунингом ефективно поново тренирамо сам модел са потребним подацима (што нам омогућава да користимо много више примера него што може да стане у максимални прозор токена) - и распоређујемо _прилагођену_ верзију модела која више не мора да има примере обезбеђене у време инференције. Ово не само да побољшава ефикасност дизајна нашег упита (имамо већу флексибилност у коришћењу прозора токена за друге ствари), већ потенцијално и смањује трошкове (смањењем броја токена које морамо послати моделу у време инференције).\n",
    "\n",
    "Фајн тунинг има 4 корака:\n",
    "1. Припремите податке за тренирање и отпремите их.\n",
    "1. Покрените посао тренирања да бисте добили фајн тунирани модел.\n",
    "1. Процените фајн тунирани модел и по потреби поновите ради квалитета.\n",
    "1. Распоредите фајн тунирани модел за инференцију када будете задовољни.\n",
    "\n",
    "Имајте у виду да не подржавају сви основни модели фајн тунинг - [проверите OpenAI документацију](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) за најновије информације. Такође можете фајн тунирати раније фајн тунирани модел. У овом туторијалу ћемо користити `gpt-35-turbo` као наш циљни основни модел за фајн тунинг.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 1.1: Припремите свој скуп података\n",
    "\n",
    "Хајде да направимо чатбот који ће вам помоћи да разумете периодни систем елемената тако што ће одговарати на питања о елементу у виду лимерика. У _овом_ једноставном туторијалу, направићемо само скуп података за тренирање модела са неколико примера одговора који показују очекивани формат података. У стварном случају употребе, потребно је направити скуп података са много више примера. Такође, можда ћете моћи да користите отворени скуп података (за вашу примену) ако постоји, и да га преформатирате за употребу у финој обуци.\n",
    "\n",
    "Пошто се фокусирамо на `gpt-35-turbo` и тражимо одговор у једном кораку (chat completion), можемо направити примере користећи [предложени формат](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) који одражава захтеве OpenAI за chat completion. Ако очекујете разговор у више корака, користили бисте [формат примера за више корака](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) који укључује параметар `weight` да означи које поруке треба користити (или не) у процесу фине обуке.\n",
    "\n",
    "За наш туторијал користићемо једноставнији формат за један корак. Податке су у [jsonl формату](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) са по једним записом по линији, сваки представљен као JSON објекат. Испод је приказано 2 записа као пример - погледајте [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) за цео пример (10 примера) који ћемо користити у овом туторијалу за фину обуку. **Напомена:** Сваки запис _мора_ бити дефинисан у једној линији (не сме бити раздвојен преко више линија као што је уобичајено у форматираном JSON фајлу)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "У стварном случају употребе биће вам потребан много већи скуп примера за добре резултате - компромис ће бити између квалитета одговора и времена/трошкова за фину обуку. Ми користимо мали скуп да бисмо брзо завршили фину обуку и илустровали процес. Погледајте [овaj пример из OpenAI Cookbook-а](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) за сложенији туторијал фине обуке.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Корак 1.2 Отпремите свој скуп података\n",
    "\n",
    "Отпремите податке користећи Files API [као што је описано овде](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Имајте у виду да да бисте покренули овај код, морате прво да урадите следеће кораке:\n",
    " - Инсталирали сте `openai` Python пакет (проверите да користите верзију >=0.28.0 за најновије функције)\n",
    " - Поставили сте `OPENAI_API_KEY` променљиву окружења на ваш OpenAI API кључ\n",
    "За више информација, погледајте [Водич за подешавање](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) обезбеђен за курс.\n",
    "\n",
    "Сада покрените код да бисте креирали фајл за отпремање из вашег локалног JSONL фајла.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Корак 2.1: Креирајте посао фино подешавање помоћу SDK-а\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Корак 2.2: Проверите статус посла\n",
    "\n",
    "Ево неколико ствари које можете урадити са `client.fine_tuning.jobs` API-јем:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Прикажи последњих n послова фино подешавања\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Добиј детаље о одређеном послу фино подешавања\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Откажи посао фино подешавања\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Прикажи до n догађаја из посла\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Први корак у процесу је _валидација тренинг фајла_ како би се осигурало да су подаци у исправном формату.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Корак 2.3: Пратите догађаје да бисте пратили напредак\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 2.4: Погледајте статус у OpenAI контролној табли\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такође можете проверити статус тако што ћете посетити OpenAI вебсајт и истражити одељак _Фино подешавање_ платформе. Ово ће вам показати статус тренутног посла, као и омогућити праћење историје претходних извршења послова. На овом снимку екрана можете видети да је претходно извршење било неуспешно, а друго извршење успешно. За контекст, ово се догодило када је прво извршење користило JSON фајл са неправилно форматираним записима - након исправке, друго извршење је успешно завршено и модел је постао доступан за коришћење.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.sr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такође можете видети статусне поруке и метрике померањем надоле у визуелној контролној табли као што је приказано:\n",
    "\n",
    "| Поруке | Метрике |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.sr.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.sr.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Корак 3.1: Преузмите ИД и тестирате фино подешени модел у коду\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Корак 3.2: Учитајте и тестирате фино подешени модел у Playground-у\n",
    "\n",
    "Сада можете тестирати фино подешени модел на два начина. Прво, можете посетити Playground и користити падајући мени Models да изаберете ваш ново фино подешени модел са листе опција. Друга опција је да користите опцију \"Playground\" приказану у панелу за фино подешавање (погледајте снимак екрана изнад) која покреће следећи _упоредни_ приказ који показује основни и фино подешени модел један поред другог за брзу процену.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.sr.png)\n",
    "\n",
    "Једноставно унесите системски контекст који сте користили у вашим подацима за обуку и поставите ваше тест питање. Приметићете да су обе стране ажуриране са идентичним контекстом и питањем. Покрените упоређивање и видећете разлику у излазима између њих. _Обратите пажњу како фино подешени модел приказује одговор у формату који сте навели у вашим примерима, док основни модел једноставно прати системски упит_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.sr.png)\n",
    "\n",
    "Приметићете да упоређивање такође пружа број токена за сваки модел и време потребно за извршење инференције. **Овај конкретан пример је поједностављен и има за циљ да покаже процес, али не одражава стварни скуп података или сценарио**. Можда ћете приметити да оба узорка показују исти број токена (системски контекст и кориснички упит су идентични) при чему фино подешени модел троши више времена за инференцију (прилагођени модел).\n",
    "\n",
    "У стварним сценаријима нећете користити овако једноставан пример, већ ћете фино подешавати на стварним подацима (нпр. каталог производа за корисничку подршку) где ће квалитет одговора бити много очигледнији. У _том_ контексту, добијање еквивалентног квалитета одговора са основним моделом захтеваће више прилагођеног инжењеринга упита што ће повећати коришћење токена и потенцијално време обраде за инференцију. _Да бисте то испробали, погледајте примере фино подешавања у OpenAI Cookbook-у да бисте почели._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Одрицање од одговорности**:\nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетним извором. За критичне информације препоручује се професионални људски превод. Нисмо одговорни за било каква неспоразума или погрешна тумачења која произилазе из коришћења овог превода.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:41:34+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}