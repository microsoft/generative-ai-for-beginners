{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Фино подешавање Open AI модела\n",
    "\n",
    "Овај бележник је заснован на тренутним упутствима из [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) документације од Open AI.\n",
    "\n",
    "Фино подешавање побољшава перформансе основних модела за вашу апликацију тако што се модел поново тренира са додатним подацима и контекстом који су релевантни за одређени случај или сценарио. Имајте у виду да технике као што су _few shot learning_ и _retrieval augmented generation_ омогућавају да обогатите основни упит релевантним подацима ради побољшања квалитета. Међутим, ови приступи су ограничени максималном величином прозора за токене код изабраног основног модела.\n",
    "\n",
    "Са финим подешавањем, ми заправо поново тренирамо сам модел са потребним подацима (што нам омогућава да користимо много више примера него што може да стане у максимални прозор за токене) – и постављамо _прилагођену_ верзију модела којој више није потребно да има примере у тренутку извођења. Ово не само да побољшава ефикасност нашег дизајна упита (имамо већу флексибилност у коришћењу прозора за токене за друге ствари), већ потенцијално смањује и трошкове (смањујући број токена које морамо да пошаљемо моделу у тренутку извођења).\n",
    "\n",
    "Фино подешавање има 4 корака:\n",
    "1. Припремите податке за тренирање и отпремите их.\n",
    "1. Покрените посао тренирања да добијете фино подешен модел.\n",
    "1. Оцените фино подешен модел и поновите процес ради квалитета.\n",
    "1. Поставите фино подешен модел за извођење када будете задовољни.\n",
    "\n",
    "Имајте у виду да не подржавају сви основни модели фино подешавање – [погледајте OpenAI документацију](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) за најновије информације. Такође можете фино подесити модел који је већ био фино подешаван. У овом туторијалу користићемо `gpt-35-turbo` као наш основни модел за фино подешавање.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 1.1: Припремите свој скуп података\n",
    "\n",
    "Хајде да направимо чет-бота који вам помаже да разумете периодни систем елемената тако што одговара на питања о неком елементу у виду лимерика. У _овом_ једноставном туторијалу, направићемо скуп података за тренирање модела са неколико примера одговора који показују очекивани формат података. У стварној примени, морали бисте да направите скуп података са много више примера. Можда ћете моћи да искористите и неки отворени скуп података (за вашу област) ако постоји, и да га прилагодите за фино подешавање.\n",
    "\n",
    "Пошто се фокусирамо на `gpt-35-turbo` и желимо одговор у једном кораку (chat completion), можемо направити примере користећи [овај предложени формат](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) који одговара OpenAI захтевима за chat completion. Ако очекујете разговор у више корака, користили бисте [формат за више корака](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) који укључује параметар `weight` да означи које поруке треба (или не треба) користити у процесу фино подешавања.\n",
    "\n",
    "Овде ћемо користити једноставнији формат са једним кораком. Подаци су у [jsonl формату](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) са једним записом по линији, где је сваки запис представљен као JSON објекат. Испод је приказано 2 записа као пример – погледајте [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) за комплетан скуп примера (10 примера) који ћемо користити у овом туторијалу за фино подешавање. **Напомена:** Сваки запис _мора_ бити дефинисан у једној линији (не раздвајајте га у више редова као што је уобичајено у форматираном JSON фајлу)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "У стварној примени биће вам потребан много већи скуп примера за добре резултате – баланс је између квалитета одговора и времена/трошкова за фино подешавање. Користимо мали скуп да бисмо брзо завршили фино подешавање и илустровали процес. Погледајте [овај пример из OpenAI Cookbook-а](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) за сложенији туторијал о финој обуци.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 1.2 Отпремите свој скуп података\n",
    "\n",
    "Отпремите податке користећи Files API [како је описано овде](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Имајте у виду да, да бисте покренули овај код, прво морате да урадите следеће кораке:\n",
    " - Инсталирали сте `openai` Python пакет (проверите да користите верзију >=0.28.0 ради најновијих функција)\n",
    " - Поставили сте `OPENAI_API_KEY` променљиву окружења на ваш OpenAI API кључ\n",
    "За више информација, погледајте [Упутство за подешавање](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) које је обезбеђено за овај курс.\n",
    "\n",
    "Сада покрените код да бисте креирали фајл за отпремање из вашег локалног JSONL фајла.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 2.1: Креирајте посао за фино подешавање помоћу SDK-a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 2.2: Проверите статус посла\n",
    "\n",
    "Ево неколико ствари које можете урадити помоћу `client.fine_tuning.jobs` API-ја:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Прикажи последњих n послова за фино подешавање\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Добиј детаље о одређеном послу за фино подешавање\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Откажи посао за фино подешавање\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Прикажи до n догађаја са посла\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Први корак у овом процесу је _валидација фајла за тренирање_ како би се осигурало да су подаци у исправном формату.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 2.3: Пратите догађаје да бисте пратили напредак\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 2.4: Погледајте статус на OpenAI контролној табли\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете такође да видите статус тако што ћете посетити OpenAI веб сајт и истражити одељак _Fine-tuning_ на платформи. Овде можете видети статус тренутног посла, као и пратити историју претходних извршавања. На овој слици екрана, можете видети да је претходно извршавање било неуспешно, а да је друго покретање било успешно. За контекст, ово се догодило када је прво покретање користило JSON фајл са неправилно форматираним записима – када је то исправљено, друго покретање је успешно завршено и модел је постао доступан за коришћење.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.sr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можете такође да видите статусне поруке и метрике тако што ћете скроловати ниже у визуелној контролној табли као што је приказано:\n",
    "\n",
    "| Поруке | Метрике |\n",
    "|:---|:---|\n",
    "| ![Поруке](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.sr.png) |  ![Метрике](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.sr.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 3.1: Преузмите ID и тестирајте фино подешени модел у коду\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Корак 3.2: Учитајте и тестирајте фино подешени модел у Playground-у\n",
    "\n",
    "Сада можете тестирати фино подешени модел на два начина. Прво, можете посетити Playground и користити падајући мени Models да изаберете свој нови фино подешени модел из понуђених опција. Друга опција је да користите \"Playground\" опцију која се приказује у панелу за фино подешавање (погледајте слику изнад), што покреће _упоредни_ приказ у коме се основни и фино подешени модел приказују један поред другог ради брзе процене.\n",
    "\n",
    "Само попуните системски контекст који сте користили у својим подацима за обуку и унесите своје тест питање. Приметићете да се обе стране ажурирају са истим контекстом и питањем. Покрените поређење и видећете разлику у излазима између њих. _Обратите пажњу како фино подешени модел приказује одговор у формату који сте навели у својим примерима, док основни модел само прати системски упит._\n",
    "\n",
    "Приметићете и да поређење приказује број токена за сваки модел, као и време потребно за инференцију. **Овај конкретан пример је поједностављен и служи само да прикаже процес, али не одражава стварни скуп података или сценарио из праксе.** Можда ћете приметити да оба примера имају исти број токена (системски контекст и кориснички упит су идентични), али да фино подешени модел троши више времена на инференцију (прилагођени модел).\n",
    "\n",
    "У стварним ситуацијама нећете користити овако једноставан пример, већ ћете фино подешавати модел на стварним подацима (нпр. каталог производа за корисничку подршку), где ће квалитет одговора бити много очигледнији. У _том_ контексту, да бисте добили једнак квалитет одговора са основним моделом, биће потребно више прилагођавања упита, што ће повећати потрошњу токена и потенцијално време обраде за инференцију. _Ако желите да испробате ово, погледајте примере фино подешавања у OpenAI Cookbook-у за почетак._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Одрицање од одговорности**:  \nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако настојимо да обезбедимо тачност, имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални људски превод. Не сносимо одговорност за било каква неспоразума или погрешна тумачења настала коришћењем овог превода.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:56:28+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}