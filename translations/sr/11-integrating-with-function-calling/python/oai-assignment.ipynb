{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Увод\n",
    "\n",
    "Ова лекција ће обухватити:\n",
    "- Шта је позивање функције и њене примене\n",
    "- Како направити позив функције користећи OpenAI\n",
    "- Како интегрисати позив функције у апликацију\n",
    "\n",
    "## Циљеви учења\n",
    "\n",
    "Након завршетка ове лекције знаћете како и разумети:\n",
    "\n",
    "- Сврху коришћења позивања функција\n",
    "- Подешавање позива функције користећи OpenAI сервис\n",
    "- Дизајнирање ефикасних позива функција за примену у вашој апликацији\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разумевање позива функција\n",
    "\n",
    "За ову лекцију, желимо да направимо функцију за наш едукативни стартап која омогућава корисницима да користе ћаскање са ботом како би пронашли техничке курсеве. Препоручићемо курсеве који одговарају њиховом нивоу вештина, тренутној улози и технологији од интереса.\n",
    "\n",
    "Да бисмо то завршили, користићемо комбинацију:\n",
    " - `OpenAI` за креирање искуства ћаскања за корисника\n",
    " - `Microsoft Learn Catalog API` да помогнемо корисницима да пронађу курсеве на основу захтева корисника\n",
    " - `Function Calling` да узмемо упит корисника и пошаљемо га функцији која ће направити API захтев.\n",
    "\n",
    "Да бисмо почели, погледајмо зашто бисмо уопште желели да користимо позив функције:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # добијање новог одговора од GPT где може видети одговор функције\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зашто позив функције\n",
    "\n",
    "Ако сте завршили било коју другу лекцију у овом курсу, вероватно разумете моћ коришћења великих језичких модела (LLMs). Надамо се да такође можете видети и неке од њихових ограничења.\n",
    "\n",
    "Позив функције је функција OpenAI сервиса дизајнирана да реши следеће изазове:\n",
    "\n",
    "Непоуздано форматирање одговора:\n",
    "- Пре позива функције, одговори великог језичког модела били су неструктурирани и непоуздани. Програмери су морали да пишу сложен код за валидацију како би обрадили сваку варијацију у излазу.\n",
    "\n",
    "Ограничена интеграција са спољним подацима:\n",
    "- Пре ове функције, било је тешко укључити податке из других делова апликације у контекст ћаскања.\n",
    "\n",
    "Стандартизовањем формата одговора и омогућавањем беспрекорне интеграције са спољним подацима, позив функције поједностављује развој и смањује потребу за додатном логиком валидације.\n",
    "\n",
    "Корисници нису могли добити одговоре као што је „Какво је тренутно време у Стокхолму?“. То је зато што су модели били ограничени на време када су подаци били обучавани.\n",
    "\n",
    "Погледајмо пример испод који илуструје овај проблем:\n",
    "\n",
    "Рецимо да желимо да креирамо базу података о студентима како бисмо им могли предложити прави курс. Испод имамо два описа студената која су веома слична у подацима које садрже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Желимо да ово пошаљемо LLM-у да би парсирао податке. Ово касније може да се користи у нашој апликацији за слање овога на API или чување у бази података.\n",
    "\n",
    "Хајде да направимо два идентична упита у којима ћемо LLM-у дати инструкције о томе које информације нас занимају:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Желимо да пошаљемо ово LLM-у да анализира делове који су важни за наш производ. Тако да можемо направити два идентична упита да упутимо LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Након креирања ова два упита, послаћемо их LLM-у користећи `openai.ChatCompletion`. Садржај упита чувамо у променљивој `messages` и додељујемо улогу `user`. Ово је да би се имитирало слање поруке од стране корисника ка ћаскању са ботом.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада можемо послати оба захтева LLM-у и испитати одговор који добијемо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иако су упити исти и описи слични, можемо добити различите формате својства `Grades`.\n",
    "\n",
    "Ако покренете горњу ћелију више пута, формат може бити `3.7` или `3.7 GPA`.\n",
    "\n",
    "То је зато што LLM узима неструктуриране податке у облику написаног упита и враћа такође неструктуриране податке. Потребно је да имамо структуриран формат како бисмо знали шта да очекујемо приликом чувања или коришћења тих података.\n",
    "\n",
    "Коришћењем функционалног позивања, можемо бити сигурни да ћемо добити структуриран податак назад. Када користимо функционално позивање, LLM заправо не позива или извршава било какве функције. Уместо тога, креирамо структуру коју LLM треба да прати у својим одговорима. Затим користимо те структуриранe одговоре да бисмо знали коју функцију да покренемо у нашим апликацијама.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Дијаграм тока позива функције](../../../../translated_images/sr/Function-Flow.083875364af4f4bb.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Затим можемо узети оно што функција врати и послати то назад LLM-у. LLM ће затим одговорити користећи природни језик како би одговорио на кориснички упит.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примери употребе позива функција\n",
    "\n",
    "**Позивање спољних алата**  \n",
    "Чатботови су одлични у пружању одговора на питања корисника. Коришћењем позива функција, чатботови могу користити поруке корисника да обаве одређене задатке. На пример, студент може затражити од чатбота да „Пошаље имејл мом предавачу у коме каже да ми је потребна додатна помоћ око овог предмета“. Ово може изазвати позив функције `send_email(to: string, body: string)`\n",
    "\n",
    "**Креирање API или упита базе података**  \n",
    "Корисници могу пронаћи информације користећи природни језик који се претвара у форматирани упит или API захтев. Пример за то може бити наставник који тражи „Који су студенти завршили последњи задатак“ што може изазвати позив функције `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Креирање структурираних података**  \n",
    "Корисници могу узети блок текста или CSV и користити LLM да из њега извуче важне информације. На пример, студент може претворити Википедијин чланак о мировним споразумима у AI флаш картице. Ово се може урадити коришћењем функције `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Креирање Вашег Првог Позива Функције\n",
    "\n",
    "Процес креирања позива функције укључује 3 главна корака:\n",
    "1. Позивање Chat Completions API-ја са списком ваших функција и поруком корисника\n",
    "2. Читање одговора модела да бисте извршили акцију, нпр. извршили функцију или API позив\n",
    "3. Још један позив Chat Completions API-ју са одговором из ваше функције да бисте користили те информације за креирање одговора кориснику.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ток позива функције](../../../../translated_images/sr/LLM-Flow.3285ed8caf4796d7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Елементи позива функције\n",
    "\n",
    "#### Кориснички унос\n",
    "\n",
    "Први корак је креирање корисничке поруке. Ово се може динамички доделити узимањем вредности из текстуалног уноса или можете овде доделити вредност. Ако је ово први пут да радите са Chat Completions API-јем, потребно је да дефинишемо `role` и `content` поруке.\n",
    "\n",
    "`role` може бити или `system` (креирање правила), `assistant` (модел) или `user` (крајњи корисник). За позив функције, доделићемо ово као `user` и пример питања.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Креирање функција.\n",
    "\n",
    "Следеће ћемо дефинисати функцију и параметре те функције. Овде ћемо користити само једну функцију која се зове `search_courses`, али можете креирати више функција.\n",
    "\n",
    "**Важно** : Функције су укључене у системску поруку за LLM и урачунате су у укупан број доступних токена које имате на располагању.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дефиниције** \n",
    "\n",
    "Структура дефиниције функције има више нивоа, сваки са својим својствима. Ево прегледа угнежђене структуре:\n",
    "\n",
    "**Својства функције на највишем нивоу:**\n",
    "\n",
    "`name` - Име функције коју желимо да позовемо.\n",
    "\n",
    "`description` - Ово је опис како функција ради. Важно је да буде прецизан и јасан.\n",
    "\n",
    "`parameters` - Листа вредности и формата које желите да модел произведе у свом одговору.\n",
    "\n",
    "**Својства објекта параметара:**\n",
    "\n",
    "`type` - Тип података објекта параметара (обично \"object\").\n",
    "\n",
    "`properties` - Листа специфичних вредности које ће модел користити за свој одговор.\n",
    "\n",
    "**Својства појединачних параметара:**\n",
    "\n",
    "`name` - Имплицитно дефинисано кључем својства (нпр. \"role\", \"product\", \"level\").\n",
    "\n",
    "`type` - Тип података овог конкретног параметра (нпр. \"string\", \"number\", \"boolean\").\n",
    "\n",
    "`description` - Опис конкретног параметра.\n",
    "\n",
    "**Опциона својства:**\n",
    "\n",
    "`required` - Низ који наводи који су параметри неопходни да би позив функције био извршен.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Позивање функције  \n",
    "Након дефинисања функције, сада је потребно укључити је у позив Chat Completion API-ја. То радимо додавањем `functions` у захтев. У овом случају `functions=functions`. \n",
    "\n",
    "Постоји и опција да се `function_call` подеси на `auto`. То значи да ћемо дозволити LLM-у да одлучи која функција треба да буде позвана на основу корисничке поруке, уместо да то ми сами одредимо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хајде сада да погледамо одговор и видимо како је форматиран:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Можете видети да је име функције позвано и да је LLM из поруке корисника успео да пронађе податке који одговарају аргументима функције.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Интеграција позива функција у апликацију. \n",
    "\n",
    "\n",
    "Након што смо тестирали форматирани одговор од LLM-а, сада можемо то интегрисати у апликацију. \n",
    "\n",
    "### Управљање током \n",
    "\n",
    "Да бисмо то интегрисали у нашу апликацију, хајде да предузмемо следеће кораке: \n",
    "\n",
    "Прво, хајде да позовемо OpenAI сервисе и сачувамо поруку у променљиву која се зове `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада ћемо дефинисати функцију која ће позивати Microsoft Learn API да добије листу курсева:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Као најбоља пракса, затим ћемо видети да ли модел жели да позове функцију. Након тога, креираћемо једну од доступних функција и упоредити је са функцијом која се позива.  \n",
    "Затим ћемо узети аргументе функције и мапирати их на аргументе из LLM-а.\n",
    "\n",
    "На крају, додаћемо поруку о позиву функције и вредности које су враћене поруком `search_courses`. Ово даје LLM-у све информације које су му потребне да одговори кориснику користећи природни језик.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада ћемо послати ажурирану поруку LLM-у како бисмо добили одговор у природном језику уместо одговора форматираног као API JSON.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изазов са кодом\n",
    "\n",
    "Одличан посао! Да бисте наставили са учењем о OpenAI Function Calling, можете направити: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Више параметара функције који могу помоћи ученицима да пронађу више курсева. Доступне API параметре можете пронаћи овде:  \n",
    " - Направите још један позив функције који узима више информација од ученика, као што је њихов матерњи језик  \n",
    " - Направите обраду грешака када позив функције и/или API позив не врати одговарајуће курсеве\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Одрицање од одговорности**:\nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако се трудимо да превод буде тачан, молимо вас да имате у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на његовом изворном језику треба сматрати ауторитетним извором. За критичне информације препоручује се професионални људски превод. Нисмо одговорни за било каква неспоразума или погрешна тумачења која произилазе из коришћења овог превода.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T11:40:44+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}