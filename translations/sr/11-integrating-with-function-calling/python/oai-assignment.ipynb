{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Увод\n",
    "\n",
    "Ова лекција ће обухватити:\n",
    "- Шта је позивање функција и у којим ситуацијама се користи\n",
    "- Како направити позив функције користећи OpenAI\n",
    "- Како интегрисати позив функције у апликацију\n",
    "\n",
    "## Циљеви учења\n",
    "\n",
    "Након што завршите ову лекцију, знаћете и разумећете:\n",
    "\n",
    "- Сврху коришћења позивања функција\n",
    "- Како подесити позив функције користећи OpenAI сервис\n",
    "- Како осмислити ефикасне позиве функција за потребе ваше апликације\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разумевање позивања функција\n",
    "\n",
    "У овој лекцији желимо да направимо функционалност за нашу едукативну стартап платформу која омогућава корисницима да преко чет-бота пронађу техничке курсеве. Препоручићемо курсеве који одговарају њиховом нивоу знања, тренутној улози и технологији која их занима.\n",
    "\n",
    "Да бисмо ово реализовали, користићемо комбинацију:\n",
    " - `OpenAI` за креирање чет искуства за корисника\n",
    " - `Microsoft Learn Catalog API` да помогнемо корисницима да пронађу курсеве на основу њихових захтева\n",
    " - `Function Calling` да преузме кориснички упит и пошаље га функцији која ће направити API захтев\n",
    "\n",
    "За почетак, хајде да видимо зашто бисмо уопште желели да користимо позивање функција:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # добијамо нови одговор од GPT који може да види одговор функције\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зашто коришћење функција\n",
    "\n",
    "Ако сте завршили било коју другу лекцију у овом курсу, вероватно већ разумете колико су Моћни Велики Језички Модели (LLMs). Надамо се да сте приметили и нека њихова ограничења.\n",
    "\n",
    "Функционално позивање (Function Calling) је могућност у OpenAI сервису која је направљена да реши следеће изазове:\n",
    "\n",
    "Неконзистентно форматирање одговора:\n",
    "- Пре увођења функционалног позивања, одговори великог језичког модела били су неструктурирани и непоуздани. Програмери су морали да пишу сложен код за валидацију како би обрадили све варијације у излазу.\n",
    "\n",
    "Ограничена интеграција са спољним подацима:\n",
    "- Пре ове могућности, било је тешко укључити податке из других делова апликације у контекст ћаскања.\n",
    "\n",
    "Стандартизовањем формата одговора и омогућавањем лаке интеграције са спољним подацима, функционално позивање поједностављује развој и смањује потребу за додатном логиком за валидацију.\n",
    "\n",
    "Корисници нису могли да добију одговоре попут „Какво је тренутно време у Стокхолму?“. Ово је зато што су модели били ограничени на период када су подаци били обучавани.\n",
    "\n",
    "Погледајмо пример испод који илуструје овај проблем:\n",
    "\n",
    "Рецимо да желимо да направимо базу података о студентима како бисмо им препоручили одговарајући курс. Испод имамо два описа студената који су веома слични по подацима које садрже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Желимо да пошаљемо ово LLM-у ради анализе података. Ово се касније може користити у нашој апликацији за слање ка API-ју или чување у бази података.\n",
    "\n",
    "Хајде да направимо два идентична упутства којима ћемо објаснити LLM-у које информације нас занимају:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Желимо да ово пошаљемо LLM-у да би анализирао делове који су важни за наш производ. Тако можемо направити два идентична упутства да дамо LLM-у:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Након креирања ова два упита, послаћемо их LLM-у користећи `openai.ChatCompletion`. Упит чувамо у променљивој `messages` и додељујемо улогу `user`. Ово је да бисмо имитирали поруку коју корисник шаље чет-боту.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада можемо послати оба захтева LLM-у и испитати одговор који добијемо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иако су упити исти и описи слични, можемо добити различите формате својства `Grades`.\n",
    "\n",
    "Ако покренете горњу ћелију више пута, формат може бити `3.7` или `3.7 GPA`.\n",
    "\n",
    "Ово се дешава зато што LLM прима неструктуриране податке у облику написаног упита и такође враћа неструктуриране податке. Потребан нам је структуриран формат како бисмо знали шта да очекујемо када чувамо или користимо те податке.\n",
    "\n",
    "Коришћењем функционалног позивања можемо обезбедити да добијамо структуиране податке. Када користимо функционално позивање, LLM заправо не позива и не извршава никакве функције. Уместо тога, креирамо структуру коју LLM треба да прати у својим одговорима. Затим користимо те структуиране одговоре да бисмо знали коју функцију да покренемо у нашим апликацијама.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Дијаграм тока позива функције](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.sr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примери употребе позива функција\n",
    "\n",
    "**Позивање спољашњих алата**  \n",
    "Ћаскање са ботовима је одлично за добијање одговора на питања корисника. Кроз позивање функција, ботови могу да користе поруке корисника како би обавили одређене задатке. На пример, студент може да затражи од бота: „Пошаљи имејл мом професору и реци да ми је потребна додатна помоћ око ове теме“. Ово може да покрене позив функције `send_email(to: string, body: string)`\n",
    "\n",
    "**Креирање API или база података упита**  \n",
    "Корисници могу да пронађу информације користећи природни језик који се затим претвара у форматиран упит или API захтев. Пример за ово је наставник који пита: „Који су ученици завршили последњи задатак“, што може да покрене функцију `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Креирање структурираног података**  \n",
    "Корисници могу да узму блок текста или CSV и користе LLM да извуку важне информације из њега. На пример, студент може да претвори Википедијин чланак о мировним споразумима у AI флеш картице. Ово се може урадити коришћењем функције `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Креирање вашег првог позива функције\n",
    "\n",
    "Процес креирања позива функције обухвата три главна корака:\n",
    "1. Позивање Chat Completions API-ја са списком ваших функција и поруком корисника\n",
    "2. Читање одговора модела ради извршавања неке радње, односно покретања функције или API позива\n",
    "3. Поновно позивање Chat Completions API-ја са одговором ваше функције како бисте ту информацију искористили за креирање одговора кориснику.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ток функцијског позива](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.sr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Елементи позива функције\n",
    "\n",
    "#### Кориснички унос\n",
    "\n",
    "Први корак је да се креира порука корисника. Ово може бити динамички додељено узимањем вредности из текстуалног уноса или можете овде доделити вредност. Ако први пут радите са Chat Completions API-јем, потребно је да дефинишемо `role` и `content` поруке.\n",
    "\n",
    "`role` може бити `system` (правила), `assistant` (модел) или `user` (крајњи корисник). За позивање функције, ово ћемо поставити као `user` и дати пример питања.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Креирање функција.\n",
    "\n",
    "Следеће ћемо дефинисати функцију и њене параметре. Овде ћемо користити само једну функцију под називом `search_courses`, али можете направити више функција.\n",
    "\n",
    "**Важно**: Функције се укључују у системску поруку LLM-у и улазе у укупан број доступних токена које имате на располагању.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дефиниције**\n",
    "\n",
    "Структура дефиниције функције има више нивоа, при чему сваки има своје особине. Ево прегледа угнежђене структуре:\n",
    "\n",
    "**Особине функције на највишем нивоу:**\n",
    "\n",
    "`name` - Име функције коју желимо да позовемо.\n",
    "\n",
    "`description` - Опис начина на који функција ради. Овде је важно бити прецизан и јасан.\n",
    "\n",
    "`parameters` - Листа вредности и формата које желите да модел врати у свом одговору.\n",
    "\n",
    "**Особине објекта параметара:**\n",
    "\n",
    "`type` - Тип података за објекат параметара (обично \"object\")\n",
    "\n",
    "`properties` - Листа конкретних вредности које ће модел користити у свом одговору\n",
    "\n",
    "**Особине појединачног параметра:**\n",
    "\n",
    "`name` - Имплицитно дефинисано кључем својства (нпр. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Тип података за овај конкретан параметар (нпр. \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Опис конкретног параметра\n",
    "\n",
    "**Опционе особине:**\n",
    "\n",
    "`required` - Низ који наводи који су параметри неопходни да би се позив функције успешно извршио\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Позив функције\n",
    "Након што смо дефинисали функцију, сада треба да је укључимо у позив ка Chat Completion API-ју. То радимо тако што додамо `functions` у захтев. У овом случају то је `functions=functions`.\n",
    "\n",
    "Постоји и опција да се подеси `function_call` на `auto`. То значи да ћемо дозволити LLM-у да сам одлучи коју функцију треба позвати на основу поруке корисника, уместо да то ми ручно одређујемо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада да погледамо одговор и видимо како је форматиран:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Можете да видите да је име функције позвано и да је LLM из корисничке поруке успео да пронађе податке који одговарају аргументима функције.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Интеграција позива функција у апликацију.\n",
    "\n",
    "Након што смо тестирали форматиран одговор од LLM-а, сада можемо да га интегришемо у апликацију.\n",
    "\n",
    "### Управљање током\n",
    "\n",
    "Да бисмо ово интегрисали у нашу апликацију, хајде да следимо ове кораке:\n",
    "\n",
    "Прво, позваћемо OpenAI сервисе и сачувати поруку у променљиву под именом `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада ћемо дефинисати функцију која ће позвати Microsoft Learn API да добије листу курсева:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Као најбољу праксу, прво ћемо проверити да ли модел жели да позове неку функцију. Након тога, креираћемо једну од доступних функција и повезаћемо је са функцијом која се позива.  \n",
    "Затим ћемо узети аргументе функције и мапирати их на аргументе из LLM-а.\n",
    "\n",
    "На крају, додаћемо поруку о позиву функције и вредности које су враћене поруком `search_courses`. Ово даје LLM-у све потребне информације да  \n",
    "кориснику одговори природним језиком.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изазов са кодом\n",
    "\n",
    "Одличан посао! Да бисте наставили са учењем о OpenAI Function Calling, можете направити: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    "- Још параметара функције који могу помоћи полазницима да пронађу више курсева. Доступне параметре API-ја можете пронаћи овде:  \n",
    "- Направите још један позив функције који узима више информација од полазника, као што је њихов матерњи језик  \n",
    "- Додајте обраду грешака када позив функције и/или API-ја не врати ниједан одговарајући курс\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Одрицање од одговорности**:  \nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако настојимо да обезбедимо тачност, имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални људски превод. Не сносимо одговорност за било каква неспоразума или погрешна тумачења настала коришћењем овог превода.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:21:59+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}