{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Увод\n",
    "\n",
    "Ова лекција ће обухватити:\n",
    "- Шта је позивање функција и у којим ситуацијама се користи\n",
    "- Како направити позив функције користећи Azure OpenAI\n",
    "- Како интегрисати позив функције у апликацију\n",
    "\n",
    "## Циљеви учења\n",
    "\n",
    "Након завршетка ове лекције знаћете и разумети:\n",
    "\n",
    "- Сврху коришћења позивања функција\n",
    "- Како подесити позив функције користећи Azure OpenAI Service\n",
    "- Како осмислити ефикасне позиве функција за потребе ваше апликације\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Разумевање позива функција\n",
    "\n",
    "У овој лекцији желимо да направимо функцију за нашу едукативну стартап компанију која омогућава корисницима да преко четбота пронађу техничке курсеве. Препоручићемо курсеве који одговарају њиховом нивоу знања, тренутној улози и технологији која их занима.\n",
    "\n",
    "Да бисмо ово реализовали, користићемо комбинацију:\n",
    " - `Azure Open AI` за креирање чет искуства за корисника\n",
    " - `Microsoft Learn Catalog API` да помогнемо корисницима да пронађу курсеве на основу њихових захтева\n",
    " - `Function Calling` да преузмемо кориснички упит и пошаљемо га функцији која ће направити API захтев\n",
    "\n",
    "Да бисмо започели, хајде да видимо зашто бисмо уопште желели да користимо позив функције:\n",
    "\n",
    "print(\"Поруке у следећем захтеву:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # добијамо нови одговор од GPT где може да види одговор функције\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Зашто позив функције\n",
    "\n",
    "Ако сте завршили било коју другу лекцију у овом курсу, вероватно разумете колико су Моћни Велики Језички Модели (LLMs). Надамо се да сте приметили и неке њихове ограничења.\n",
    "\n",
    "Позив функције је могућност Azure Open AI сервиса која решава следећа ограничења:\n",
    "1) Доследан формат одговора\n",
    "2) Могућност коришћења података из других извора апликације у оквиру чета\n",
    "\n",
    "Пре позива функције, одговори LLM-а су били неструктурирани и недоследни. Програмери су морали да пишу сложен код за валидацију како би могли да обраде сваки различит одговор.\n",
    "\n",
    "Корисници нису могли да добију одговоре попут „Какво је тренутно време у Стокхолму?“. Разлог је што су модели били ограничени на период када су подаци били обучени.\n",
    "\n",
    "Погледајмо пример испод који илуструје овај проблем:\n",
    "\n",
    "Рецимо да желимо да направимо базу података о студентима како бисмо им предложили одговарајући курс. Испод имамо два описа студената који су веома слични по подацима које садрже.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Желимо да пошаљемо ово LLM-у ради анализе података. Ово се касније може користити у нашој апликацији за слање ка API-ју или чување у бази података.\n",
    "\n",
    "Хајде да направимо два идентична упутства којима ћемо објаснити LLM-у које информације нас занимају:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Желимо да пошаљемо ово LLM-у да би анализирао делове који су важни за наш производ. Тако можемо направити два идентична упутства да дамо LLM-у:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Након креирања ова два упита, послаћемо их LLM-у користећи `openai.ChatCompletion`. Упит чувамо у променљивој `messages` и додељујемо улогу `user`. Ово је да бисмо имитирали поруку коју корисник шаље четботу.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада можемо послати оба захтева LLM-у и испитати одговор који добијемо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Иако су упити исти и описи слични, можемо добити различите формате својства `Grades`.\n",
    "\n",
    "Ако покренете горњу ћелију више пута, формат може бити `3.7` или `3.7 GPA`.\n",
    "\n",
    "Ово се дешава јер LLM прима неструктуриране податке у облику написаног упита и такође враћа неструктуриране податке. Потребан нам је структуриран формат како бисмо знали шта да очекујемо када чувамо или користимо те податке.\n",
    "\n",
    "Коришћењем функционалног позивања, можемо обезбедити да добијамо структуиране податке. Када користимо функционално позивање, LLM заправо не позива и не извршава никакве функције. Уместо тога, креирамо структуру коју LLM треба да прати у својим одговорима. Затим користимо те структуиране одговоре да бисмо знали коју функцију да покренемо у нашим апликацијама.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Дијаграм тока позива функције](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.sr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примери употребе позива функција\n",
    "\n",
    "**Позивање спољашњих алата**  \n",
    "Ћаскање са ботом је одлично за добијање одговора на питања корисника. Кроз позивање функција, ботови могу да користе поруке корисника за извршавање одређених задатака. На пример, студент може да затражи од бота: „Пошаљи имејл мом наставнику и реци да ми је потребна додатна помоћ око ове теме“. Ово може да покрене позив функције `send_email(to: string, body: string)`\n",
    "\n",
    "**Креирање API или база података упита**  \n",
    "Корисници могу да пронађу информације користећи природни језик који се затим претвара у форматиран упит или API захтев. Пример за ово је наставник који пита: „Који су ученици завршили последњи задатак“, што може да покрене функцију `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Креирање структурираног података**  \n",
    "Корисници могу да узму блок текста или CSV и користе LLM да извуку важне информације из њега. На пример, студент може да претвори чланак са Википедије о мировним споразумима у AI флеш картице. Ово се може урадити коришћењем функције `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Креирање вашег првог позива функције\n",
    "\n",
    "Процес креирања позива функције обухвата три главна корака:\n",
    "1. Позивање Chat Completions API-ја са списком ваших функција и поруком корисника\n",
    "2. Читање одговора модела ради извршавања неке радње, односно покретања функције или API позива\n",
    "3. Поновно слање захтева Chat Completions API-ју са одговором ваше функције како бисте ту информацију искористили за креирање одговора кориснику.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Ток функцијског позива](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.sr.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Елементи позива функције\n",
    "\n",
    "#### Кориснички унос\n",
    "\n",
    "Први корак је креирање поруке корисника. Ова порука може бити динамички додељена узимањем вредности из текстуалног уноса, или можете овде доделити вредност. Ако први пут радите са Chat Completions API-јем, потребно је да дефинишете `role` и `content` поруке.\n",
    "\n",
    "`role` може бити `system` (правила), `assistant` (модел) или `user` (крајњи корисник). За позивање функције, ово ћемо поставити као `user` и додати пример питања.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Креирање функција.\n",
    "\n",
    "Следеће ћемо дефинисати функцију и њене параметре. Овде ћемо користити само једну функцију под називом `search_courses`, али можете направити више функција.\n",
    "\n",
    "**Важно**: Функције се укључују у системску поруку LLM-у и рачунају се у укупан број доступних токена који имате.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Дефиниције**\n",
    "\n",
    "`name` - Име функције коју желимо да позовемо.\n",
    "\n",
    "`description` - Опис начина на који функција ради. Овде је важно бити прецизан и јасан.\n",
    "\n",
    "`parameters` - Списак вредности и формат који желите да модел генерише у свом одговору.\n",
    "\n",
    "`type` - Тип података у којем ће својства бити сачувана.\n",
    "\n",
    "`properties` - Списак конкретних вредности које ће модел користити за свој одговор.\n",
    "\n",
    "`name` - Име својства које ће модел користити у форматираном одговору.\n",
    "\n",
    "`type` - Тип података овог својства.\n",
    "\n",
    "`description` - Опис конкретног својства.\n",
    "\n",
    "**Опционо**\n",
    "\n",
    "`required` - неопходно својство да би позив функције био успешно завршен\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Позив функције\n",
    "Након што смо дефинисали функцију, сада треба да је укључимо у позив ка Chat Completion API-ју. То радимо тако што додамо `functions` у захтев. У овом случају то је `functions=functions`.\n",
    "\n",
    "Постоји и опција да се подеси `function_call` на `auto`. То значи да ћемо дозволити LLM-у да сам одлучи коју функцију треба позвати на основу поруке корисника, уместо да то ми ручно одређујемо.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хајде сада да погледамо одговор и видимо како је форматиран:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Можете видети да је позвана функција по имену и да је LLM из корисникове поруке успео да пронађе податке који одговарају аргументима функције.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Интегрисање позива функција у апликацију.\n",
    "\n",
    "Након што смо тестирали форматирани одговор од LLM-а, сада можемо да га интегришемо у апликацију.\n",
    "\n",
    "### Управљање током\n",
    "\n",
    "Да бисмо ово интегрисали у нашу апликацију, следићемо ове кораке:\n",
    "\n",
    "Прво, позваћемо Open AI сервисе и сачувати поруку у променљиву под именом `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сада ћемо дефинисати функцију која ће позвати Microsoft Learn API да добије листу курсева:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Као најбољу праксу, прво ћемо проверити да ли модел жели да позове неку функцију. Након тога, креираћемо једну од доступних функција и повезаћемо је са функцијом која се позива.  \n",
    "Затим ћемо узети аргументе функције и мапирати их на аргументе из LLM-а.\n",
    "\n",
    "На крају, додаћемо поруку о позиву функције и вредности које су враћене поруком `search_courses`. Ово даје LLM-у све потребне информације да  \n",
    "кориснику одговори природним језиком.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Изазов са кодом\n",
    "\n",
    "Одличан посао! Да наставиш са учењем о Azure Open AI Function Calling, можеш да направиш: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Више параметара функције који могу помоћи корисницима да лакше пронађу курсеве. Доступне API параметре можеш пронаћи овде:\n",
    " - Направи још један позив функције који узима више информација од корисника, као што је његов матерњи језик\n",
    " - Додај обраду грешака када позив функције и/или API позив не врати ниједан одговарајући курс\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Одрицање од одговорности**:  \nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако настојимо да обезбедимо тачност, имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални људски превод. Не сносимо одговорност за било каква неспоразума или погрешна тумачења настала коришћењем овог превода.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:33:01+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}