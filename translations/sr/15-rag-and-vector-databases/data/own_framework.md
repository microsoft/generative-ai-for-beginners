<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-05-20T02:27:33+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "sr"
}
-->
# Uvod u Neuronske MreÅ¾e. ViÅ¡eslojni Perceptron

U prethodnom delu, nauÄili ste o najjednostavnijem modelu neuronske mreÅ¾e - jednoslojnom perceptronu, linearnom modelu za klasifikaciju sa dve klase.

U ovom delu proÅ¡iriÄ‡emo ovaj model u fleksibilniji okvir, koji nam omoguÄ‡ava da:

* izvodimo **klasifikaciju sa viÅ¡e klasa** pored klasifikacije sa dve klase
* reÅ¡avamo **probleme regresije** pored klasifikacije
* razdvojimo klase koje nisu linearno razdvojive

TakoÄ‘e Ä‡emo razviti sopstveni modularni okvir u Python-u koji Ä‡e nam omoguÄ‡iti konstruisanje razliÄitih arhitektura neuronskih mreÅ¾a.

## Formalizacija MaÅ¡inskog UÄenja

PoÄnimo sa formalizacijom problema MaÅ¡inskog UÄenja. Pretpostavimo da imamo trening skup podataka **X** sa etiketama **Y**, i da treba da izgradimo model *f* koji Ä‡e davati Å¡to taÄnija predviÄ‘anja. Kvalitet predviÄ‘anja meri se pomoÄ‡u **funkcije gubitka** â„’. SledeÄ‡e funkcije gubitka se Äesto koriste:

* Za problem regresije, kada treba da predvidimo broj, moÅ¾emo koristiti **apsolutnu greÅ¡ku** âˆ‘<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, ili **kvadratnu greÅ¡ku** âˆ‘<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Za klasifikaciju, koristimo **0-1 gubitak** (Å¡to je u suÅ¡tini isto kao i **taÄnost** modela), ili **logistiÄki gubitak**.

Za jednoslojni perceptron, funkcija *f* je definisana kao linearna funkcija *f(x)=wx+b* (ovde je *w* matrica teÅ¾ina, *x* je vektor ulaznih karakteristika, a *b* je vektor pristrasnosti). Za razliÄite arhitekture neuronskih mreÅ¾a, ova funkcija moÅ¾e imati sloÅ¾eniji oblik.

> U sluÄaju klasifikacije, Äesto je poÅ¾eljno dobiti verovatnoÄ‡e odgovarajuÄ‡ih klasa kao izlaz mreÅ¾e. Da bismo pretvorili proizvoljne brojeve u verovatnoÄ‡e (npr. da normalizujemo izlaz), Äesto koristimo **softmax** funkciju Ïƒ, i funkcija *f* postaje *f(x)=Ïƒ(wx+b)*

U definiciji *f* iznad, *w* i *b* se nazivaju **parametri** Î¸=âŸ¨*w,b*âŸ©. Dati skup podataka âŸ¨**X**,**Y**âŸ©, moÅ¾emo izraÄunati ukupnu greÅ¡ku na celom skupu podataka kao funkciju parametara Î¸.

> âœ… **Cilj obuke neuronske mreÅ¾e je da minimizira greÅ¡ku variranjem parametara Î¸**

## Optimizacija Gradijentnim SpuÅ¡tanjem

Postoji dobro poznata metoda optimizacije funkcije zvana **gradijentno spuÅ¡tanje**. Ideja je da moÅ¾emo izraÄunati derivat (u viÅ¡edimenzionalnom sluÄaju zvan **gradijent**) funkcije gubitka u odnosu na parametre, i menjati parametre na takav naÄin da se greÅ¡ka smanjuje. Ovo se moÅ¾e formalizovati na sledeÄ‡i naÄin:

* Inicijalizujte parametre nekim sluÄajnim vrednostima w<sup>(0)</sup>, b<sup>(0)</sup>
* Ponavljajte sledeÄ‡i korak mnogo puta:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚b

Tokom obuke, koraci optimizacije bi trebalo da se raÄunaju uzimajuÄ‡i u obzir ceo skup podataka (setite se da se gubitak raÄuna kao zbir kroz sve uzorke obuke). MeÄ‘utim, u stvarnom Å¾ivotu uzimamo male delove skupa podataka zvane **minibatchevi**, i raÄunamo gradijente na osnovu podskupa podataka. PoÅ¡to se podskup uzima nasumiÄno svaki put, takva metoda se naziva **stohastiÄko gradijentno spuÅ¡tanje** (SGD).

## ViÅ¡eslojni Perceptroni i Unazadna Propagacija

Jednoslojna mreÅ¾a, kao Å¡to smo videli iznad, je sposobna da klasifikuje linearno razdvojive klase. Da bismo izgradili bogatiji model, moÅ¾emo kombinovati nekoliko slojeva mreÅ¾e. MatematiÄki to bi znaÄilo da funkcija *f* ima sloÅ¾eniji oblik i da Ä‡e se raÄunati u nekoliko koraka:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Î±(z<sub>1</sub>)+b<sub>2</sub>
* f = Ïƒ(z<sub>2</sub>)

Ovde je Î± **nelinearna aktivaciona funkcija**, Ïƒ je softmax funkcija, a parametri Î¸=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Algoritam gradijentnog spuÅ¡tanja bi ostao isti, ali bi bilo teÅ¾e izraÄunati gradijente. Dato pravilo diferencijacije lanca, moÅ¾emo izraÄunati derivate kao:

* âˆ‚â„’/âˆ‚w<sub>2</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚w<sub>2</sub>)
* âˆ‚â„’/âˆ‚w<sub>1</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚Î±)(âˆ‚Î±/âˆ‚z<sub>1</sub>)(âˆ‚z<sub>1</sub>/âˆ‚w<sub>1</sub>)

> âœ… Pravilo diferencijacije lanca se koristi za izraÄunavanje derivata funkcije gubitka u odnosu na parametre.

Napomena da je levi deo svih tih izraza isti, i tako moÅ¾emo efikasno izraÄunati derivate poÄevÅ¡i od funkcije gubitka i iduÄ‡i "unazad" kroz raÄunsku mreÅ¾u. Stoga se metoda obuke viÅ¡eslojnog perceptrona naziva **unazadna propagacija**, ili 'backprop'.

> TODO: citiranje slike

> âœ… PokriÄ‡emo unazadnu propagaciju mnogo detaljnije u naÅ¡em primeru u beleÅ¾nici.

## ZakljuÄak

U ovoj lekciji, izgradili smo sopstvenu biblioteku neuronskih mreÅ¾a i koristili smo je za jednostavan dvodimenzionalni zadatak klasifikacije.

## ğŸš€ Izazov

U prateÄ‡oj beleÅ¾nici, implementiraÄ‡ete sopstveni okvir za izgradnju i obuku viÅ¡eslojnih perceptrona. MoÄ‡i Ä‡ete detaljno videti kako funkcioniÅ¡u moderne neuronske mreÅ¾e.

PreÄ‘ite na beleÅ¾nicu OwnFramework i radite kroz nju.

## Pregled i Samostalno UÄenje

Unazadna propagacija je uobiÄajen algoritam koriÅ¡Ä‡en u AI i ML, vredan je detaljnijeg prouÄavanja.

## Zadatak

U ovoj laboratoriji, traÅ¾i se da koristite okvir koji ste konstruisali u ovoj lekciji da reÅ¡ite klasifikaciju rukom pisanih cifara iz MNIST skupa podataka.

* Uputstva
* BeleÅ¾nica

**ĞĞ´Ñ€Ğ¸Ñ†Ğ°ÑšĞµ Ğ¾Ğ´ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾ÑÑ‚Ğ¸**:  
ĞĞ²Ğ°Ñ˜ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ñ˜Ğµ Ğ¿Ñ€ĞµĞ²ĞµĞ´ĞµĞ½ ĞºĞ¾Ñ€Ğ¸ÑˆÑ›ĞµÑšĞµĞ¼ ÑƒÑĞ»ÑƒĞ³Ğµ Ğ¿Ñ€ĞµĞ²Ğ¾Ñ’ĞµÑšĞ° ÑƒĞ· Ğ¿Ğ¾Ğ¼Ğ¾Ñ› Ğ²ĞµÑˆÑ‚Ğ°Ñ‡ĞºĞµ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ¸Ğ³ĞµĞ½Ñ†Ğ¸Ñ˜Ğµ [Co-op Translator](https://github.com/Azure/co-op-translator). Ğ˜Ğ°ĞºĞ¾ ÑĞµ Ñ‚Ñ€ÑƒĞ´Ğ¸Ğ¼Ğ¾ Ğ´Ğ° Ğ¿Ğ¾ÑÑ‚Ğ¸Ğ³Ğ½ĞµĞ¼Ğ¾ Ñ‚Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚, Ğ¼Ğ¾Ğ»Ğ¸Ğ¼Ğ¾ Ğ²Ğ°Ñ Ğ´Ğ° Ğ±ÑƒĞ´ĞµÑ‚Ğµ ÑĞ²ĞµÑĞ½Ğ¸ Ğ´Ğ° Ğ°ÑƒÑ‚Ğ¾Ğ¼Ğ°Ñ‚Ğ¸Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´Ğ¸ Ğ¼Ğ¾Ğ³Ñƒ ÑĞ°Ğ´Ñ€Ğ¶Ğ°Ñ‚Ğ¸ Ğ³Ñ€ĞµÑˆĞºĞµ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑ‚Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğ½Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ½Ğ° ÑšĞµĞ³Ğ¾Ğ²Ğ¾Ğ¼ Ğ¸Ğ·Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ñ˜ĞµĞ·Ğ¸ĞºÑƒ Ñ‚Ñ€ĞµĞ±Ğ° ÑĞ¼Ğ°Ñ‚Ñ€Ğ°Ñ‚Ğ¸ Ğ°ÑƒÑ‚Ğ¾Ñ€Ğ¸Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¼ Ğ¸Ğ·Ğ²Ğ¾Ñ€Ğ¾Ğ¼. Ğ—Ğ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ˜Ğµ, Ğ¿Ñ€ĞµĞ¿Ğ¾Ñ€ÑƒÑ‡ÑƒÑ˜Ğµ ÑĞµ Ğ¿Ñ€Ğ¾Ñ„ĞµÑĞ¸Ğ¾Ğ½Ğ°Ğ»Ğ½Ğ¸ Ñ™ÑƒĞ´ÑĞºĞ¸ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´. ĞĞµ ÑĞ½Ğ¾ÑĞ¸Ğ¼Ğ¾ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾ÑÑ‚ Ğ·Ğ° Ğ±Ğ¸Ğ»Ğ¾ ĞºĞ°ĞºĞ²Ğ° Ğ¿Ğ¾Ğ³Ñ€ĞµÑˆĞ½Ğ° ÑÑ…Ğ²Ğ°Ñ‚Ğ°ÑšĞ° Ğ¸Ğ»Ğ¸ Ğ¿Ğ¾Ğ³Ñ€ĞµÑˆĞ½Ğ° Ñ‚ÑƒĞ¼Ğ°Ñ‡ĞµÑšĞ° ĞºĞ¾Ñ˜Ğ° Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ¸Ğ»Ğ°Ğ·Ğµ Ğ¸Ğ· ÑƒĞ¿Ğ¾Ñ‚Ñ€ĞµĞ±Ğµ Ğ¾Ğ²Ğ¾Ğ³ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´Ğ°.