<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-05-20T01:44:44+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "sr"
}
-->
# Generacija uz podr코ku pretra쬴vanja (RAG) i vektorske baze podataka

U lekciji o aplikacijama za pretragu, ukratko smo nau캜ili kako da integri코emo va코e sopstvene podatke u velike jezi캜ke modele (LLM). U ovoj lekciji, detaljnije 캖emo istra쬴ti koncepte utemeljenja va코ih podataka u va코oj LLM aplikaciji, mehanizme procesa i metode za skladi코tenje podataka, uklju캜uju캖i i ugradnje i tekst.

## Uvod

U ovoj lekciji pokri캖emo slede캖e:

- Uvod u RAG, 코ta je to i za코to se koristi u ve코ta캜koj inteligenciji (AI).

- Razumevanje 코ta su vektorske baze podataka i kreiranje jedne za na코u aplikaciju.

- Prakti캜an primer kako integrisati RAG u aplikaciju.

## Ciljevi u캜enja

Nakon zavr코etka ove lekcije, mo캖i 캖ete da:

- Objasnite zna캜aj RAG-a u preuzimanju i obradi podataka.

- Postavite RAG aplikaciju i utemeljite va코e podatke na LLM-u

- Efikasna integracija RAG-a i vektorskih baza podataka u LLM aplikacijama.

## Na코 scenario: unapre캠enje na코ih LLM-ova sa na코im sopstvenim podacima

Za ovu lekciju, 쬰limo da dodamo na코e sopstvene bele코ke u edukativni startap, koji omogu캖ava chatbotu da dobije vi코e informacija o razli캜itim temama. Koriste캖i bele코ke koje imamo, u캜enici 캖e mo캖i bolje da u캜e i razumeju razli캜ite teme, olak코avaju캖i im pripremu za ispite. Da bismo kreirali na코 scenario, koristi캖emo:

- `Azure OpenAI:` LLM koji 캖emo koristiti da kreiramo na코 chatbot

- `AI for beginners' lesson on Neural Networks`: ovo 캖e biti podaci na kojima 캖emo utemeljiti na코 LLM

- `Azure AI Search` i `Azure Cosmos DB:` vektorsku bazu podataka za skladi코tenje na코ih podataka i kreiranje indeksa pretrage

Korisnici 캖e mo캖i da kreiraju kvizove za ve쬭anje iz svojih bele코ki, kartice za reviziju i sa쬸u ih u koncizne preglede. Da bismo po캜eli, pogledajmo 코ta je RAG i kako funkcioni코e:

## Generacija uz podr코ku pretra쬴vanja (RAG)

Chatbot pokretan LLM-om obra캠uje korisni캜ke zahteve da generi코e odgovore. Dizajniran je da bude interaktivan i anga쬿je se sa korisnicima na 코irokom spektru tema. Me캠utim, njegovi odgovori su ograni캜eni kontekstom koji mu je dat i njegovim osnovnim podacima za obuku. Na primer, GPT-4 prekid znanja je septembar 2021, 코to zna캜i da mu nedostaje znanje o doga캠ajima koji su se dogodili nakon ovog perioda. Osim toga, podaci kori코캖eni za obuku LLM-ova isklju캜uju poverljive informacije kao 코to su li캜ne bele코ke ili priru캜nik za proizvode kompanije.

### Kako RAG-ovi (Generacija uz podr코ku pretra쬴vanja) funkcioni코u

Pretpostavimo da 쬰lite da postavite chatbot koji kreira kvizove iz va코ih bele코ki, bi캖e vam potrebna veza sa bazom znanja. Tu dolazi RAG. RAG-ovi funkcioni코u na slede캖i na캜in:

- **Baza znanja:** Pre preuzimanja, ovi dokumenti moraju biti uneti i prethodno obra캠eni, obi캜no razbijaju캖i velike dokumente u manje delove, pretvaraju캖i ih u tekstualne ugradnje i skladi코te캖i ih u bazi podataka.

- **Korisni캜ki upit:** korisnik postavlja pitanje

- **Preuzimanje:** Kada korisnik postavi pitanje, model za ugradnju preuzima relevantne informacije iz na코e baze znanja da pru쬴 vi코e konteksta koji 캖e biti uklju캜en u zahtev.

- **Generacija uz podr코ku:** LLM pobolj코ava svoj odgovor na osnovu preuzetih podataka. Omogu캖ava da generisani odgovor bude ne samo zasnovan na prethodno obu캜enim podacima ve캖 i na relevantnim informacijama iz dodatog konteksta. Preuzeti podaci se koriste za pobolj코anje odgovora LLM-a. LLM zatim vra캖a odgovor na korisni캜ko pitanje.

Arhitektura za RAG-ove se implementira kori코캖enjem transformatora koji se sastoje iz dva dela: kodera i dekodera. Na primer, kada korisnik postavi pitanje, ulazni tekst se 'kodira' u vektore koji hvataju zna캜enje re캜i, a vektori se 'dekodiraju' u na코 indeks dokumenata i generi코u novi tekst na osnovu korisni캜kog upita. LLM koristi model kodera-dekodera da generi코e izlaz.

Dva pristupa pri implementaciji RAG-a prema predlo쬰nom radu: [Generacija uz podr코ku pretra쬴vanja za zadatke NLP-a (softver za obradu prirodnog jezika) koji intenzivno koriste znanje](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) su:

- **_RAG-Sekvenca_** koriste캖i preuzete dokumente da predvidi najbolji mogu캖i odgovor na korisni캜ki upit

- **RAG-Tok** koriste캖i dokumente da generi코e slede캖i tok, zatim ih preuzme da odgovori na korisni캜ki upit

### Za코to biste koristili RAG-ove?

- **Bogatsvo informacija:** osigurava da tekstualni odgovori budu a쬿rirani i aktuelni. Stoga pobolj코ava performanse na zadacima specifi캜nim za domen pristupom unutra코njoj bazi znanja.

- Smanjuje fabrikaciju kori코캖enjem **proverljivih podataka** u bazi znanja da pru쬴 kontekst korisni캜kim upitima.

- **Ekonomi캜an je** jer su ekonomi캜niji u pore캠enju sa finim pode코avanjem LLM-a.

## Kreiranje baze znanja

Na코a aplikacija se zasniva na na코im li캜nim podacima tj. lekciji o neuronskim mre쬬ma u kurikulumu AI za po캜etnike.

### Vektorske baze podataka

Vektorska baza podataka, za razliku od tradicionalnih baza podataka, je specijalizovana baza podataka dizajnirana da skladi코ti, upravlja i pretra쬿je ugra캠ene vektore. Skladi코ti numeri캜ke reprezentacije dokumenata. Razbijanje podataka na numeri캜ke ugradnje olak코ava na코em AI sistemu da razume i obradi podatke.

Skladi코timo na코e ugradnje u vektorskim bazama podataka jer LLM-ovi imaju ograni캜enje broja tokena koje prihvataju kao ulaz. Kako ne mo쬰te proslediti sve ugradnje LLM-u, mora캖emo da ih razbijemo na delove i kada korisnik postavi pitanje, ugradnje koje su najbli쬰 pitanju 캖e biti vra캖ene zajedno sa zahtevom. Razbijanje tako캠e smanjuje tro코kove broja tokena koji se prosle캠uju kroz LLM.

Neke popularne vektorske baze podataka uklju캜uju Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant i DeepLake. Mo쬰te kreirati model Azure Cosmos DB koriste캖i Azure CLI sa slede캖om komandom:

### Od teksta do ugradnji

Pre nego 코to skladi코timo na코e podatke, moramo ih pretvoriti u vektorske ugradnje pre nego 코to budu skladi코teni u bazi podataka. Ako radite sa velikim dokumentima ili dugim tekstovima, mo쬰te ih razbiti na osnovu upita koje o캜ekujete. Razbijanje se mo쬰 uraditi na nivou re캜enice ili na nivou paragrafa. Kako razbijanje izvodi zna캜enja iz re캜i oko njih, mo쬰te dodati neki drugi kontekst delu, na primer, dodavanjem naslova dokumenta ili uklju캜ivanjem nekog teksta pre ili posle dela. Mo쬰te razbiti podatke na slede캖i na캜in:

Jednom kada su razbijeni, mo쬰mo zatim ugraditi na코 tekst koriste캖i razli캜ite modele za ugradnju. Neki modeli koje mo쬰te koristiti uklju캜uju: word2vec, ada-002 od OpenAI, Azure Computer Vision i mnoge druge. Odabir modela za kori코캖enje zavisi캖e od jezika koje koristite, tipa sadr쬬ja koji se kodira (tekst/slike/audio), veli캜ine ulaza koji mo쬰 kodirati i du쬴ne izlaza ugradnje.

Primer ugra캠enog teksta koriste캖i OpenAI-ov model `text-embedding-ada-002` je:

## Preuzimanje i vektorska pretraga

Kada korisnik postavi pitanje, preuzima캜 ga transformi코e u vektor koriste캖i kodera upita, zatim pretra쬿je kroz na코 indeks pretrage dokumenata za relevantne vektore u dokumentu koji su povezani sa ulazom. Kada zavr코i, konvertuje i ulazni vektor i vektore dokumenata u tekst i prosle캠uje ih kroz LLM.

### Preuzimanje

Preuzimanje se de코ava kada sistem poku코ava brzo da prona캠e dokumente iz indeksa koji zadovoljavaju kriterijume pretrage. Cilj preuzima캜a je da dobije dokumente koji 캖e se koristiti za pru쬬nje konteksta i utemeljenje LLM-a na va코im podacima.

Postoji nekoliko na캜ina za obavljanje pretrage unutar na코e baze podataka kao 코to su:

- **Pretraga po klju캜nim re캜ima** - koristi se za tekstualne pretrage

- **Semanti캜ka pretraga** - koristi semanti캜ko zna캜enje re캜i

- **Vektorska pretraga** - konvertuje dokumente iz teksta u vektorske reprezentacije koriste캖i modele za ugradnju. Preuzimanje 캖e se obaviti upitom dokumenata 캜ije su vektorske reprezentacije najbli쬰 korisni캜kom pitanju.

- **Hibridna** - kombinacija pretrage po klju캜nim re캜ima i vektorske pretrage.

Izazov sa preuzimanjem dolazi kada nema sli캜nog odgovora na upit u bazi podataka, sistem 캖e tada vratiti najbolje informacije koje mo쬰 dobiti, me캠utim, mo쬰te koristiti taktike kao 코to je postavljanje maksimalne udaljenosti za relevantnost ili kori코캖enje hibridne pretrage koja kombinuje i klju캜ne re캜i i vektorsku pretragu. U ovoj lekciji 캖emo koristiti hibridnu pretragu, kombinaciju vektorske i pretrage po klju캜nim re캜ima. Skladi코ti캖emo na코e podatke u okvir podataka sa kolonama koje sadr쬰 delove kao i ugradnje.

### Vektorska sli캜nost

Preuzima캜 캖e pretra쬴vati kroz bazu znanja za ugradnje koje su blizu jedna drugoj, najbli쬴 sused, jer su to tekstovi koji su sli캜ni. U slu캜aju da korisnik postavi upit, prvo se ugra캠uje, zatim se poklapa sa sli캜nim ugradnjama. Zajedni캜ka mera koja se koristi da se utvrdi koliko su sli캜ni razli캜iti vektori je kosinusna sli캜nost koja se zasniva na uglu izme캠u dva vektora.

Mo쬰mo meriti sli캜nost koriste캖i druge alternative koje mo쬰mo koristiti su Euklidska udaljenost koja je prava linija izme캠u krajnjih ta캜aka vektora i skalarni proizvod koji meri zbir proizvoda odgovaraju캖ih elemenata dva vektora.

### Indeks pretrage

Kada radimo preuzimanje, mora캖emo da izgradimo indeks pretrage za na코u bazu znanja pre nego 코to obavimo pretragu. Indeks 캖e skladi코titi na코e ugradnje i mo쬰 brzo preuzeti najsli캜nije delove 캜ak i u velikoj bazi podataka. Mo쬰mo kreirati na코 indeks lokalno koriste캖i:

### Ponovno rangiranje

Kada ste upitali bazu podataka, mo쬯a 캖ete morati da sortirate rezultate od najrelevantnijih. LLM za ponovno rangiranje koristi ma코insko u캜enje da pobolj코a relevantnost rezultata pretrage tako 코to ih pore캠a od najrelevantnijih. Koriste캖i Azure AI pretragu, ponovno rangiranje se automatski obavlja za vas koriste캖i semanti캜ko ponovno rangiranje. Primer kako ponovno rangiranje funkcioni코e koriste캖i najbli쬰 susede:

## Sve zajedno

Poslednji korak je dodavanje na코eg LLM-a u kombinaciju da bismo mogli da dobijemo odgovore koji su utemeljeni na na코im podacima. Mo쬰mo ga implementirati na slede캖i na캜in:

## Evaluacija na코e aplikacije

### Metodologija evaluacije

- Kvalitet odgovora koji se isporu캜uju osiguravaju캖i da zvu캜e prirodno, te캜no i kao ljudski

- Utemeljenost podataka: evaluacija da li je odgovor do코ao iz dostavljenih dokumenata

- Relevantnost: evaluacija da li odgovor odgovara i da li je povezan sa postavljenim pitanjem

- Te캜nost - da li odgovor ima smisla gramati캜ki

## Upotrebe za kori코캖enje RAG-a (Generacija uz podr코ku pretra쬴vanja) i vektorskih baza podataka

Postoji mnogo razli캜itih upotreba gde pozivi funkcija mogu pobolj코ati va코u aplikaciju kao 코to su:

- Postavljanje pitanja i odgovaranje: utemeljenje podataka va코e kompanije na chat koji zaposleni mogu koristiti za postavljanje pitanja.

- Sistemi preporuka: gde mo쬰te kreirati sistem koji poklapa najsli캜nije vrednosti npr. filmove, restorane i mnoge druge.

- Usluge chatbota: mo쬰te skladi코titi istoriju chatova i personalizovati razgovor na osnovu korisni캜kih podataka.

- Pretraga slika zasnovana na vektorskim ugradnjama, korisna kada radite prepoznavanje slika i otkrivanje anomalija.

## Rezime

Pokri캖emo osnovne oblasti RAG-a od dodavanja na코ih podataka u aplikaciju, korisni캜kog upita i izlaza. Da biste pojednostavili kreiranje RAG-a, mo쬰te koristiti okvire kao 코to su Semanti Kernel, Langchain ili Autogen.

## Zadaci

Da nastavite va코e u캜enje Generacije uz podr코ku pretra쬴vanja (RAG) mo쬰te izgraditi:

- Izgradite front-end za aplikaciju koriste캖i okvir po va코em izboru

- Iskoristite okvir, bilo LangChain ili Semantic Kernel, i ponovo kreirajte va코u aplikaciju.

캛estitamo na zavr코etku lekcije 游녪.

## U캜enje ne prestaje ovde, nastavite putovanje

Nakon zavr코etka ove lekcije, pogledajte na코u [kolekciju za u캜enje generativne AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) da nastavite sa unapre캠enjem va코eg znanja o generativnoj AI!

**뤯얨햣햨혞쒫썜뛣 쮏 쮏얧쮏쒫쮐햫쮐혝**:  
뤯쒫쮐 햢쮏쥄햪햣햫혝 햣 햣쒫왏얧왏 햨쮐햦혜혝햣혲혶햦 혞혜햩혞햡햟 향햟 AI 햣쒫쮏 [Co-op Translator](https://github.com/Azure/co-op-translator). 햊햟햨 혜햣 혝혞햢햦햪햣 향햟 혝쮐햫쮐혝, 쒫 햪쮏햦햪햣 햦햪햟혲혝햣 햣햢쒫쟳 햢햣햨햟 햟쒬쮏쨿썜혜햨햦혝햣 햣쒫쮏얧 햪쮏웷 햢햟 혜쮏얨햤햟혝 햡햣혣햨햦 햦햩햦 햫햣혝쮐햫쮐혝햦. 뤰햦햡햦햫햟햩햫햦쮐 햢쮏쥄햪햣햫혝 햫햟 햫햣햡쮏쒫쟳쮐 햦향쒫쮐햣햫 혲햟향햦햨 혝햣햠햟 햢햟 혜햣 혜햪햣혝햟 향햟 햟쒬쮐햦혝햣혝햣햫 햦향쒫쮐. 행햟 햨햦혝햦혢햫햦 햦햫혟쮐햪햟혡햦햦, 혜햣 햣쮐햟혢혞쒫 쮐햣혜햦쮏쫧썛햣햫 혢쮏쒫왐햨햦 햣쒫쮏. 햏햣 혜햪햣 쮏얧쮏쒫쮐햫햦 향햟 햫햦햨햟햨쒫 햫햣햢쮐햟향햠햦햟혴햟 햦햩햦 쮏햣혣햫햦 혝쮏햨혞쒫썜뛣 햨쮏 쮏쟳햩햣햡혞쒫썛썜 쮏 햨쮐햦혜혝햣혴햣혝 햫햟 쮏쒫쮐 햣쒫쮏.