<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-18T01:20:21+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "sr"
}
-->
# IstraÅ¾ivanje i poreÄ‘enje razliÄitih LLM-ova

[![IstraÅ¾ivanje i poreÄ‘enje razliÄitih LLM-ova](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.sr.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Kliknite na sliku iznad da pogledate video lekcije_

U prethodnoj lekciji videli smo kako generativna veÅ¡taÄka inteligencija menja tehnoloÅ¡ki pejzaÅ¾, kako funkcioniÅ¡u veliki jeziÄki modeli (LLM-ovi) i kako ih jedna kompanija - poput naÅ¡eg startapa - moÅ¾e primeniti na svoje sluÄajeve upotrebe i rasti! U ovom poglavlju Ä‡emo uporediti i suprotstaviti razliÄite vrste velikih jeziÄkih modela (LLM-ova) kako bismo razumeli njihove prednosti i mane.

SledeÄ‡i korak u razvoju naÅ¡eg startapa je istraÅ¾ivanje trenutnog pejzaÅ¾a LLM-ova i razumevanje koji su pogodni za naÅ¡ sluÄaj upotrebe.

## Uvod

Ova lekcija Ä‡e obuhvatiti:

- RazliÄite vrste LLM-ova u trenutnom pejzaÅ¾u.
- Testiranje, iteraciju i poreÄ‘enje razliÄitih modela za vaÅ¡ sluÄaj upotrebe u Azure-u.
- Kako implementirati LLM.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije, moÄ‡i Ä‡ete:

- Izabrati pravi model za vaÅ¡ sluÄaj upotrebe.
- Razumeti kako testirati, iterirati i poboljÅ¡ati performanse vaÅ¡eg modela.
- Znati kako kompanije implementiraju modele.

## Razumevanje razliÄitih vrsta LLM-ova

LLM-ovi se mogu klasifikovati na viÅ¡e naÄina, u zavisnosti od njihove arhitekture, podataka za obuku i sluÄaja upotrebe. Razumevanje ovih razlika pomoÄ‡i Ä‡e naÅ¡em startapu da izabere pravi model za scenario i razume kako testirati, iterirati i poboljÅ¡ati performanse.

Postoji mnogo razliÄitih vrsta LLM modela, a vaÅ¡ izbor modela zavisi od toga za Å¡ta ih nameravate koristiti, vaÅ¡ih podataka, budÅ¾eta i drugih faktora.

U zavisnosti od toga da li nameravate koristiti modele za generisanje teksta, zvuka, videa, slika i sliÄno, moÅ¾da Ä‡ete se odluÄiti za razliÄite vrste modela.

- **Prepoznavanje zvuka i govora**. Za ovu svrhu, modeli tipa Whisper su odliÄan izbor jer su univerzalni i namenjeni prepoznavanju govora. Trenirani su na raznovrsnim audio podacima i mogu obavljati prepoznavanje govora na viÅ¡e jezika. Saznajte viÅ¡e o [modelima tipa Whisper ovde](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generisanje slika**. Za generisanje slika, DALL-E i Midjourney su dva veoma poznata izbora. DALL-E nudi Azure OpenAI. [ProÄitajte viÅ¡e o DALL-E ovde](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) i takoÄ‘e u 9. poglavlju ovog kurikuluma.

- **Generisanje teksta**. VeÄ‡ina modela je trenirana za generisanje teksta i imate veliki izbor od GPT-3.5 do GPT-4. Oni dolaze sa razliÄitim troÅ¡kovima, pri Äemu je GPT-4 najskuplji. Vredi pogledati [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) kako biste procenili koji modeli najbolje odgovaraju vaÅ¡im potrebama u smislu sposobnosti i troÅ¡kova.

- **Multimodalnost**. Ako Å¾elite da radite sa viÅ¡e vrsta podataka u ulazu i izlazu, moÅ¾da biste Å¾eleli da istraÅ¾ite modele poput [gpt-4 turbo sa vizijom ili gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - najnovije verzije OpenAI modela - koji su sposobni da kombinuju obradu prirodnog jezika sa vizuelnim razumevanjem, omoguÄ‡avajuÄ‡i interakcije kroz multimodalne interfejse.

Izbor modela znaÄi da dobijate osnovne sposobnosti, koje moÅ¾da neÄ‡e biti dovoljne. ÄŒesto imate specifiÄne podatke za kompaniju koje nekako morate preneti LLM-u. Postoji nekoliko razliÄitih pristupa kako to uÄiniti, o Äemu Ä‡emo viÅ¡e govoriti u narednim odeljcima.

### Osnovni modeli naspram LLM-ova

Termin Osnovni model (Foundation Model) je [skovao tim istraÅ¾ivaÄa sa Stanforda](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) i definisan je kao AI model koji ispunjava odreÄ‘ene kriterijume, kao Å¡to su:

- **Trenirani su koristeÄ‡i nesupervizirano uÄenje ili samostalno supervizirano uÄenje**, Å¡to znaÄi da su trenirani na nepovezanim multimodalnim podacima i ne zahtevaju ljudsku anotaciju ili oznaÄavanje podataka za proces obuke.
- **To su veoma veliki modeli**, zasnovani na veoma dubokim neuronskim mreÅ¾ama treniranim na milijardama parametara.
- **ObiÄno su namenjeni da sluÅ¾e kao 'osnova' za druge modele**, Å¡to znaÄi da se mogu koristiti kao polazna taÄka za izgradnju drugih modela, Å¡to se moÅ¾e postiÄ‡i finim podeÅ¡avanjem.

![Osnovni modeli naspram LLM-ova](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.sr.png)

Izvor slike: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Da dodatno pojasnimo ovu razliku, uzmimo ChatGPT kao primer. Za izgradnju prve verzije ChatGPT-a, model nazvan GPT-3.5 sluÅ¾io je kao osnovni model. To znaÄi da je OpenAI koristio neke podatke specifiÄne za razgovor kako bi stvorio prilagoÄ‘enu verziju GPT-3.5 koja je specijalizovana za dobro funkcionisanje u scenarijima razgovora, poput chatbotova.

![Osnovni model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.sr.png)

Izvor slike: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Otvoreni kod naspram vlasniÄkih modela

JoÅ¡ jedan naÄin za kategorizaciju LLM-ova je da li su otvorenog koda ili vlasniÄki.

Modeli otvorenog koda su modeli koji su dostupni javnosti i mogu ih koristiti svi. ÄŒesto ih objavljuje kompanija koja ih je kreirala ili istraÅ¾ivaÄka zajednica. Ovi modeli mogu biti pregledani, modifikovani i prilagoÄ‘eni za razliÄite sluÄajeve upotrebe u LLM-ovima. MeÄ‘utim, nisu uvek optimizovani za proizvodnu upotrebu i moÅ¾da nisu tako performantni kao vlasniÄki modeli. Pored toga, finansiranje za modele otvorenog koda moÅ¾e biti ograniÄeno, moÅ¾da neÄ‡e biti dugoroÄno odrÅ¾avani ili aÅ¾urirani najnovijim istraÅ¾ivanjima. Primeri popularnih modela otvorenog koda ukljuÄuju [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) i [LLaMA](https://llama.meta.com).

VlasniÄki modeli su modeli koji su u vlasniÅ¡tvu kompanije i nisu dostupni javnosti. Ovi modeli su Äesto optimizovani za proizvodnu upotrebu. MeÄ‘utim, nije dozvoljeno da se pregledaju, modifikuju ili prilagoÄ‘avaju za razliÄite sluÄajeve upotrebe. Pored toga, nisu uvek dostupni besplatno i mogu zahtevati pretplatu ili plaÄ‡anje za koriÅ¡Ä‡enje. TakoÄ‘e, korisnici nemaju kontrolu nad podacima koji se koriste za obuku modela, Å¡to znaÄi da treba da veruju vlasniku modela da Ä‡e se pridrÅ¾avati obaveza o privatnosti podataka i odgovornoj upotrebi AI. Primeri popularnih vlasniÄkih modela ukljuÄuju [OpenAI modele](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ili [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### UgraÄ‘ivanje naspram generisanja slika naspram generisanja teksta i koda

LLM-ovi se takoÄ‘e mogu kategorizovati prema izlazu koji generiÅ¡u.

UgraÄ‘ivanja su skup modela koji mogu konvertovati tekst u numeriÄki oblik, nazvan ugraÄ‘ivanje, Å¡to je numeriÄka reprezentacija ulaznog teksta. UgraÄ‘ivanja olakÅ¡avaju maÅ¡inama razumevanje odnosa izmeÄ‘u reÄi ili reÄenica i mogu se koristiti kao ulazi za druge modele, poput modela za klasifikaciju ili klasterovanje koji imaju bolje performanse na numeriÄkim podacima. Modeli ugraÄ‘ivanja se Äesto koriste za transferno uÄenje, gde se model gradi za zamenski zadatak za koji postoji obilje podataka, a zatim se teÅ¾ine modela (ugraÄ‘ivanja) ponovo koriste za druge zadatke. Primer ove kategorije je [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![UgraÄ‘ivanje](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.sr.png)

Modeli za generisanje slika su modeli koji generiÅ¡u slike. Ovi modeli se Äesto koriste za ureÄ‘ivanje slika, sintezu slika i prevoÄ‘enje slika. Modeli za generisanje slika se Äesto treniraju na velikim skupovima podataka slika, kao Å¡to je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generisanje novih slika ili za ureÄ‘ivanje postojeÄ‡ih slika tehnikama poput inpainting-a, super-rezolucije i kolorizacije. Primeri ukljuÄuju [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) i [Stable Diffusion modele](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generisanje slika](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.sr.png)

Modeli za generisanje teksta i koda su modeli koji generiÅ¡u tekst ili kod. Ovi modeli se Äesto koriste za saÅ¾imanje teksta, prevoÄ‘enje i odgovaranje na pitanja. Modeli za generisanje teksta se Äesto treniraju na velikim skupovima podataka teksta, kao Å¡to je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generisanje novog teksta ili za odgovaranje na pitanja. Modeli za generisanje koda, poput [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), Äesto se treniraju na velikim skupovima podataka koda, kao Å¡to je GitHub, i mogu se koristiti za generisanje novog koda ili za ispravljanje greÅ¡aka u postojeÄ‡em kodu.

![Generisanje teksta i koda](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.sr.png)

### Encoder-Decoder naspram samo Decoder

Da bismo razgovarali o razliÄitim vrstama arhitektura LLM-ova, koristimo analogiju.

Zamislite da vam je menadÅ¾er dao zadatak da napiÅ¡ete kviz za studente. Imate dva kolege; jedan je zaduÅ¾en za kreiranje sadrÅ¾aja, a drugi za pregled.

Kreator sadrÅ¾aja je poput modela samo Decoder, moÅ¾e pogledati temu i videti Å¡ta ste veÄ‡ napisali, a zatim moÅ¾e napisati kurs na osnovu toga. Oni su veoma dobri u pisanju zanimljivog i informativnog sadrÅ¾aja, ali nisu baÅ¡ dobri u razumevanju teme i ciljeva uÄenja. Neki primeri modela samo Decoder su modeli iz GPT porodice, kao Å¡to je GPT-3.

Recenzent je poput modela samo Encoder, gleda kurs koji je napisan i odgovore, primeÄ‡ujuÄ‡i odnos izmeÄ‘u njih i razumevajuÄ‡i kontekst, ali nije dobar u generisanju sadrÅ¾aja. Primer modela samo Encoder bio bi BERT.

Zamislite da imamo nekoga ko bi mogao i da kreira i da pregleda kviz, to je model Encoder-Decoder. Neki primeri su BART i T5.

### Servis naspram modela

Sada, hajde da razgovaramo o razlici izmeÄ‘u servisa i modela. Servis je proizvod koji nudi provajder usluga u oblaku i Äesto je kombinacija modela, podataka i drugih komponenti. Model je osnovna komponenta servisa i Äesto je osnovni model, kao Å¡to je LLM.

Servisi su Äesto optimizovani za proizvodnu upotrebu i Äesto su lakÅ¡i za upotrebu od modela, putem grafiÄkog korisniÄkog interfejsa. MeÄ‘utim, servisi nisu uvek dostupni besplatno i mogu zahtevati pretplatu ili plaÄ‡anje za koriÅ¡Ä‡enje, u zamenu za koriÅ¡Ä‡enje opreme i resursa vlasnika servisa, optimizaciju troÅ¡kova i lako skaliranje. Primer servisa je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), koji nudi plan plaÄ‡anja po koriÅ¡Ä‡enju, Å¡to znaÄi da se korisnici naplaÄ‡uju proporcionalno koliko koriste servis. TakoÄ‘e, Azure OpenAI Service nudi sigurnost na nivou preduzeÄ‡a i okvir za odgovornu upotrebu AI-a uz moguÄ‡nosti modela.

Modeli su samo neuronske mreÅ¾e, sa parametrima, teÅ¾inama i ostalim. OmoguÄ‡avaju kompanijama da ih pokreÄ‡u lokalno, meÄ‘utim, potrebno je kupiti opremu, izgraditi strukturu za skaliranje i kupiti licencu ili koristiti model otvorenog koda. Model poput LLaMA je dostupan za koriÅ¡Ä‡enje, ali zahteva raÄunske resurse za pokretanje modela.

## Kako testirati i iterirati sa razliÄitim modelima kako biste razumeli performanse na Azure-u

Kada naÅ¡ tim istraÅ¾i trenutni pejzaÅ¾ LLM-ova i identifikuje neke dobre kandidate za svoje scenarije, sledeÄ‡i korak je testiranje na njihovim podacima i radnom optereÄ‡enju. Ovo je iterativni proces, koji se sprovodi kroz eksperimente i merenja.
VeÄ‡ina modela koje smo pomenuli u prethodnim paragrafima (OpenAI modeli, modeli otvorenog koda poput Llama2 i Hugging Face transformeri) dostupni su u [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) u [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je Cloud platforma dizajnirana za programere da kreiraju aplikacije generativne veÅ¡taÄke inteligencije i upravljaju celokupnim razvojnim ciklusom - od eksperimentisanja do evaluacije - kombinujuÄ‡i sve Azure AI usluge u jedan centar sa praktiÄnim grafiÄkim interfejsom. Model Catalog u Azure AI Studio omoguÄ‡ava korisnicima da:

- PronaÄ‘u osnovni model od interesa u katalogu - bilo vlasniÄki ili otvorenog koda, filtrirajuÄ‡i po zadatku, licenci ili imenu. Da bi se poboljÅ¡ala pretraga, modeli su organizovani u kolekcije, poput Azure OpenAI kolekcije, Hugging Face kolekcije i drugih.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.sr.png)

- Pregledaju karticu modela, ukljuÄujuÄ‡i detaljan opis namene i podataka za obuku, uzorke koda i rezultate evaluacije iz interne biblioteke evaluacija.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.sr.png)

- Uporede rezultate testiranja izmeÄ‘u modela i dostupnih datasetova u industriji kako bi procenili koji model najbolje odgovara poslovnom scenariju, putem [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panela.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.sr.png)

- Prilagode model na osnovu sopstvenih podataka za obuku kako bi poboljÅ¡ali performanse modela u specifiÄnom radnom optereÄ‡enju, koristeÄ‡i moguÄ‡nosti eksperimentisanja i praÄ‡enja u Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.sr.png)

- Postave originalni unapred obuÄeni model ili prilagoÄ‘enu verziju za udaljenu inferenciju u realnom vremenu - upravljano raÄunanje - ili serverless API endpoint - [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - kako bi aplikacije mogle da ga koriste.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.sr.png)

> [!NOTE]
> Nisu svi modeli u katalogu trenutno dostupni za prilagoÄ‘avanje i/ili pay-as-you-go postavljanje. Proverite karticu modela za detalje o moguÄ‡nostima i ograniÄenjima modela.

## PoboljÅ¡anje rezultata LLM-a

IstraÅ¾ili smo sa naÅ¡im startup timom razliÄite vrste LLM-ova i Cloud platformu (Azure Machine Learning) koja nam omoguÄ‡ava da uporedimo razliÄite modele, evaluiramo ih na test podacima, poboljÅ¡amo performanse i postavimo ih na inferencione endpointove.

Ali kada treba razmotriti prilagoÄ‘avanje modela umesto koriÅ¡Ä‡enja unapred obuÄenog? Postoje li drugi pristupi za poboljÅ¡anje performansi modela u specifiÄnim radnim optereÄ‡enjima?

Postoji nekoliko pristupa koje preduzeÄ‡e moÅ¾e koristiti da bi dobilo Å¾eljene rezultate od LLM-a. MoÅ¾ete odabrati razliÄite vrste modela sa razliÄitim stepenima obuke prilikom postavljanja LLM-a u produkciju, sa razliÄitim nivoima sloÅ¾enosti, troÅ¡kova i kvaliteta. Evo nekoliko razliÄitih pristupa:

- **InÅ¾enjering upita sa kontekstom**. Ideja je da se obezbedi dovoljno konteksta prilikom postavljanja upita kako bi se dobili Å¾eljeni odgovori.

- **Generacija uz podrÅ¡ku pretrage (RAG)**. VaÅ¡i podaci mogu postojati u bazi podataka ili na web endpointu, na primer, kako bi se osiguralo da su ti podaci, ili njihov podskup, ukljuÄeni u trenutku postavljanja upita, moÅ¾ete dohvatiti relevantne podatke i uÄiniti ih delom korisniÄkog upita.

- **PrilagoÄ‘eni model**. Ovde se model dodatno obuÄava na vaÅ¡im sopstvenim podacima, Å¡to dovodi do toga da model bude precizniji i odgovara vaÅ¡im potrebama, ali moÅ¾e biti skupo.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.sr.png)

Izvor slike: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### InÅ¾enjering upita sa kontekstom

Unapred obuÄeni LLM-ovi vrlo dobro funkcioniÅ¡u na generalizovanim zadacima prirodnog jezika, Äak i kada se pozivaju sa kratkim upitom, poput reÄenice za dovrÅ¡avanje ili pitanja â€“ takozvano â€zero-shotâ€œ uÄenje.

MeÄ‘utim, Å¡to korisnik bolje moÅ¾e da oblikuje svoj upit, sa detaljnim zahtevom i primerima â€“ Kontekstom â€“ to Ä‡e odgovor biti taÄniji i bliÅ¾i oÄekivanjima korisnika. U ovom sluÄaju govorimo o â€one-shotâ€œ uÄenju ako upit ukljuÄuje samo jedan primer i â€few-shot uÄenjuâ€œ ako ukljuÄuje viÅ¡e primera. InÅ¾enjering upita sa kontekstom je najisplativiji pristup za poÄetak.

### Generacija uz podrÅ¡ku pretrage (RAG)

LLM-ovi imaju ograniÄenje da mogu koristiti samo podatke koji su koriÅ¡Ä‡eni tokom njihove obuke za generisanje odgovora. To znaÄi da ne znaju niÅ¡ta o Äinjenicama koje su se dogodile nakon procesa obuke i ne mogu pristupiti ne-javnim informacijama (poput podataka kompanije). 

Ovo se moÅ¾e prevaziÄ‡i kroz RAG, tehniku koja proÅ¡iruje upit spoljnim podacima u obliku delova dokumenata, uzimajuÄ‡i u obzir ograniÄenja duÅ¾ine upita. Ovo podrÅ¾avaju alati za pretragu vektora (poput [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) koji pronalaze korisne delove iz razliÄitih unapred definisanih izvora podataka i dodaju ih u kontekst upita.

Ova tehnika je veoma korisna kada preduzeÄ‡e nema dovoljno podataka, vremena ili resursa za prilagoÄ‘avanje LLM-a, ali ipak Å¾eli da poboljÅ¡a performanse u specifiÄnom radnom optereÄ‡enju i smanji rizik od izmiÅ¡ljanja, tj. iskrivljavanja stvarnosti ili Å¡tetnog sadrÅ¾aja.

### PrilagoÄ‘eni model

PrilagoÄ‘avanje je proces koji koristi transferno uÄenje za â€prilagoÄ‘avanjeâ€œ modela odreÄ‘enom zadatku ili reÅ¡avanju specifiÄnog problema. Za razliku od few-shot uÄenja i RAG-a, rezultira generisanjem novog modela, sa aÅ¾uriranim teÅ¾inama i pristrasnostima. Zahteva skup primera za obuku koji se sastoje od jednog ulaza (upita) i njegovog povezanog izlaza (rezultata).

Ovo bi bio preferirani pristup ako:

- **KoriÅ¡Ä‡enje prilagoÄ‘enih modela**. PreduzeÄ‡e Å¾eli da koristi prilagoÄ‘ene manje sposobne modele (poput modela za ugraÄ‘ivanje) umesto modela visokih performansi, Å¡to rezultira isplativijim i brÅ¾im reÅ¡enjem.

- **Razmatranje latencije**. Latencija je vaÅ¾na za odreÄ‘eni sluÄaj upotrebe, pa nije moguÄ‡e koristiti veoma duge upite ili broj primera koji treba da se nauÄe od modela ne odgovara ograniÄenju duÅ¾ine upita.

- **OdrÅ¾avanje aÅ¾urnosti**. PreduzeÄ‡e ima mnogo visokokvalitetnih podataka i oznaka istine i resurse potrebne za odrÅ¾avanje ovih podataka aÅ¾urnim tokom vremena.

### ObuÄeni model

Obuka LLM-a od nule je bez sumnje najteÅ¾i i najsloÅ¾eniji pristup za usvajanje, zahtevajuÄ‡i ogromne koliÄine podataka, struÄne resurse i odgovarajuÄ‡u raÄunalnu moÄ‡. Ova opcija treba da se razmatra samo u scenariju gde preduzeÄ‡e ima sluÄaj upotrebe specifiÄan za odreÄ‘enu oblast i veliku koliÄinu podataka vezanih za tu oblast.

## Provera znanja

Koji bi mogao biti dobar pristup za poboljÅ¡anje rezultata LLM-a?

1. InÅ¾enjering upita sa kontekstom  
1. RAG  
1. PrilagoÄ‘eni model  

Odgovor: 3, ako imate vremena, resurse i visokokvalitetne podatke, prilagoÄ‘avanje je bolja opcija za odrÅ¾avanje aÅ¾urnosti. MeÄ‘utim, ako Å¾elite da poboljÅ¡ate stvari, a nemate dovoljno vremena, vredi prvo razmotriti RAG.

## ğŸš€ Izazov

ProÄitajte viÅ¡e o tome kako moÅ¾ete [koristiti RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) za vaÅ¡e poslovanje.

## OdliÄno uraÄ‘eno, nastavite sa uÄenjem

Nakon Å¡to zavrÅ¡ite ovu lekciju, pogledajte naÅ¡u [Generative AI Learning kolekciju](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili da unapreÄ‘ujete svoje znanje o generativnoj veÅ¡taÄkoj inteligenciji!

PreÄ‘ite na Lekciju 3 gde Ä‡emo razmotriti kako [odgovorno koristiti generativnu veÅ¡taÄku inteligenciju](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**ĞĞ´Ñ€Ğ¸Ñ†Ğ°ÑšĞµ Ğ¾Ğ´ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾ÑÑ‚Ğ¸**:  
ĞĞ²Ğ°Ñ˜ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ñ˜Ğµ Ğ¿Ñ€ĞµĞ²ĞµĞ´ĞµĞ½ Ğ¿Ğ¾Ğ¼Ğ¾Ñ›Ñƒ ÑƒÑĞ»ÑƒĞ³Ğµ Ğ·Ğ° Ğ¿Ñ€ĞµĞ²Ğ¾Ñ’ĞµÑšĞµ Ğ²ĞµÑˆÑ‚Ğ°Ñ‡ĞºĞµ Ğ¸Ğ½Ñ‚ĞµĞ»Ğ¸Ğ³ĞµĞ½Ñ†Ğ¸Ñ˜Ğµ [Co-op Translator](https://github.com/Azure/co-op-translator). Ğ˜Ğ°ĞºĞ¾ Ğ½Ğ°ÑÑ‚Ğ¾Ñ˜Ğ¸Ğ¼Ğ¾ Ğ´Ğ° Ğ¾Ğ±ĞµĞ·Ğ±ĞµĞ´Ğ¸Ğ¼Ğ¾ Ñ‚Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚, Ğ¼Ğ¾Ğ»Ğ¸Ğ¼Ğ¾ Ğ²Ğ°Ñ Ğ´Ğ° Ğ¸Ğ¼Ğ°Ñ‚Ğµ Ñƒ Ğ²Ğ¸Ğ´Ñƒ Ğ´Ğ° Ğ°ÑƒÑ‚Ğ¾Ğ¼Ğ°Ñ‚ÑĞºĞ¸ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´Ğ¸ Ğ¼Ğ¾Ğ³Ñƒ ÑĞ°Ğ´Ñ€Ğ¶Ğ°Ñ‚Ğ¸ Ğ³Ñ€ĞµÑˆĞºĞµ Ğ¸Ğ»Ğ¸ Ğ½ĞµÑ‚Ğ°Ñ‡Ğ½Ğ¾ÑÑ‚Ğ¸. ĞÑ€Ğ¸Ğ³Ğ¸Ğ½Ğ°Ğ»Ğ½Ğ¸ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚ Ğ½Ğ° ÑšĞµĞ³Ğ¾Ğ²Ğ¾Ğ¼ Ğ¸Ğ·Ğ²Ğ¾Ñ€Ğ½Ğ¾Ğ¼ Ñ˜ĞµĞ·Ğ¸ĞºÑƒ Ñ‚Ñ€ĞµĞ±Ğ° ÑĞ¼Ğ°Ñ‚Ñ€Ğ°Ñ‚Ğ¸ Ğ°ÑƒÑ‚Ğ¾Ñ€Ğ¸Ñ‚Ğ°Ñ‚Ğ¸Ğ²Ğ½Ğ¸Ğ¼ Ğ¸Ğ·Ğ²Ğ¾Ñ€Ğ¾Ğ¼. Ğ—Ğ° ĞºÑ€Ğ¸Ñ‚Ğ¸Ñ‡Ğ½Ğµ Ğ¸Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ˜Ğµ Ğ¿Ñ€ĞµĞ¿Ğ¾Ñ€ÑƒÑ‡ÑƒÑ˜Ğµ ÑĞµ Ğ¿Ñ€Ğ¾Ñ„ĞµÑĞ¸Ğ¾Ğ½Ğ°Ğ»Ğ½Ğ¸ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´ Ğ¾Ğ´ ÑÑ‚Ñ€Ğ°Ğ½Ğµ Ñ™ÑƒĞ´Ğ¸. ĞĞµ Ğ¿Ñ€ĞµÑƒĞ·Ğ¸Ğ¼Ğ°Ğ¼Ğ¾ Ğ¾Ğ´Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ½Ğ¾ÑÑ‚ Ğ·Ğ° Ğ±Ğ¸Ğ»Ğ¾ ĞºĞ°ĞºĞ²Ğ° Ğ¿Ğ¾Ğ³Ñ€ĞµÑˆĞ½Ğ° Ñ‚ÑƒĞ¼Ğ°Ñ‡ĞµÑšĞ° Ğ¸Ğ»Ğ¸ Ğ½ĞµÑĞ¿Ğ¾Ñ€Ğ°Ğ·ÑƒĞ¼Ğµ ĞºĞ¾Ñ˜Ğ¸ Ğ¼Ğ¾Ğ³Ñƒ Ğ½Ğ°ÑÑ‚Ğ°Ñ‚Ğ¸ ÑƒÑĞ»ĞµĞ´ ĞºĞ¾Ñ€Ğ¸ÑˆÑ›ĞµÑšĞ° Ğ¾Ğ²Ğ¾Ğ³ Ğ¿Ñ€ĞµĞ²Ğ¾Ğ´Ğ°.