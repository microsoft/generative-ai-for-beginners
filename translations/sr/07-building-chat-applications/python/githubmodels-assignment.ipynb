{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Поглавље 7: Израда чет апликација\n",
    "## Брзи почетак са Github Models API\n",
    "\n",
    "Овај бележник је прилагођен из [Azure OpenAI репозиторијума са примерима](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) који садржи бележнике за приступ [Azure OpenAI](notebook-azure-openai.ipynb) сервисима.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Преглед  \n",
    "„Велики језички модели су функције које пресликавају текст у текст. Када добију улазни низ текста, велики језички модел покушава да предвиди који ће текст следећи доћи“(1). Овај „брзи водич“ ће корисницима представити основне концепте великих језичких модела, кључне захтеве пакета за почетак рада са AML-ом, лагани увод у дизајн упита, као и неколико кратких примера различитих начина употребе.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Садржај  \n",
    "\n",
    "[Преглед](../../../../07-building-chat-applications/python)  \n",
    "[Како користити OpenAI сервис](../../../../07-building-chat-applications/python)  \n",
    "[1. Креирање вашег OpenAI сервиса](../../../../07-building-chat-applications/python)  \n",
    "[2. Инсталација](../../../../07-building-chat-applications/python)    \n",
    "[3. Акредитиви](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Примери употребе](../../../../07-building-chat-applications/python)    \n",
    "[1. Сажимање текста](../../../../07-building-chat-applications/python)  \n",
    "[2. Класификација текста](../../../../07-building-chat-applications/python)  \n",
    "[3. Генерисање нових имена производа](../../../../07-building-chat-applications/python)  \n",
    "[4. Фино подешавање класификатора](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Референце](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Направите свој први промпт  \n",
    "Ова кратка вежба ће вам дати основни увод у слање промптова моделу у Github Models за једноставан задатак „сажимање“.\n",
    "\n",
    "\n",
    "**Кораци**:  \n",
    "1. Инсталирајте библиотеку `azure-ai-inference` у своје Python окружење, ако то већ нисте урадили.  \n",
    "2. Учитајте стандардне помоћне библиотеке и подесите Github Models акредитиве.  \n",
    "3. Одаберите модел за свој задатак  \n",
    "4. Направите једноставан промпт за модел  \n",
    "5. Пошаљите свој захтев ка модел API-ју!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Инсталирајте `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Проналажење одговарајућег модела  \n",
    "GPT-3.5-turbo или GPT-4 модели могу да разумеју и генеришу природни језик.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Дизајн промпта  \n",
    "\n",
    "„Магија великих језичких модела је у томе што, тренирајући се да минимизују грешку у предвиђању на огромним количинама текста, модели на крају науче појмове који су корисни за ова предвиђања. На пример, они науче појмове као што су“(1):\n",
    "\n",
    "* како се пише\n",
    "* како функционише граматика\n",
    "* како се парафразира\n",
    "* како се одговара на питања\n",
    "* како се води разговор\n",
    "* како се пише на више језика\n",
    "* како се програмира\n",
    "* итд.\n",
    "\n",
    "#### Како контролисати велики језички модел  \n",
    "„Од свих улаза у велики језички модел, далеко највећи утицај има текстуални промпт(1).\n",
    "\n",
    "Велики језички модели могу се подстаћи да генеришу излаз на неколико начина:\n",
    "\n",
    "Инструкција: Реците моделу шта желите\n",
    "Довршавање: Наведите модел да доврши почетак онога што желите\n",
    "Демонстрација: Покажите моделу шта желите, било са:\n",
    "Неколико примера у самом промпту\n",
    "Много стотина или хиљада примера у датасету за фино подешавање“\n",
    "\n",
    "\n",
    "\n",
    "#### Постоје три основна правила за креирање промптова:\n",
    "\n",
    "**Покажите и реците.** Јасно ставите до знања шта желите, било инструкцијама, примерима или комбинацијом оба. Ако желите да модел поређа листу ставки по абецедном реду или да класификује пасус по сентименту, покажите му да је то оно што желите.\n",
    "\n",
    "**Обезбедите квалитетне податке.** Ако покушавате да направите класификатор или да модел прати неки образац, уверите се да има довољно примера. Обавезно проверите своје примере — модел је обично довољно паметан да препозна основне правописне грешке и да вам ипак да одговор, али може и да претпостави да је то намерно и то може утицати на одговор.\n",
    "\n",
    "**Проверите подешавања.** Подешавања temperature и top_p одређују колико ће модел бити детерминистички у генерисању одговора. Ако тражите одговор где постоји само један тачан одговор, онда би требало да их подесите ниже. Ако желите разноврсније одговоре, можда ћете желети да их подесите више. Најчешћа грешка коју људи праве са овим подешавањима је што мисле да су то контроле „паметности“ или „креативности“.\n",
    "\n",
    "\n",
    "Извор: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Сажми текст  \n",
    "#### Изазов  \n",
    "Сажми текст тако што ћеш додати 'tl;dr:' на крај пасуса. Обрати пажњу како модел разуме како да обави више задатака без додатних упутстава. Можеш да експериментишеш са описнијим упутствима од tl;dr да би променио понашање модела и прилагодио сажетак који добијаш(3).  \n",
    "\n",
    "Недавна истраживања су показала значајан напредак у многим NLP задацима и бенчмарковима кроз претходно тренирање на великом корпусу текста, а затим фино подешавање за одређени задатак. Иако је овај приступ обично независан од конкретног задатка по архитектури, и даље захтева скупове података за фино подешавање са хиљадама или десетинама хиљада примера. Насупрот томе, људи углавном могу да обаве нови језички задатак са само неколико примера или једноставних упутстава – што је нешто са чим се савремени NLP системи и даље углавном муче. Овде показујемо да повећање обима језичких модела значајно побољшава перформансе у задацима са мало примера, често достижући ниво конкурентности са претходним најбољим приступима фино подешавања.  \n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Вежбе за различите случајеве употребе  \n",
    "1. Сажми текст  \n",
    "2. Класификуј текст  \n",
    "3. Генериши нова имена производа\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Класификуј текст  \n",
    "#### Изазов  \n",
    "Класификуј ставке у категорије које се задају у тренутку извршавања. У следећем примеру, у упиту дајемо и категорије и текст који треба класификовати (*playground_reference).\n",
    "\n",
    "Кориснички упит: Здраво, један тастер на тастатури мог лаптопа се недавно поломио и треба ми замена:\n",
    "\n",
    "Класификована категорија:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Генериши нова имена производа\n",
    "#### Изазов\n",
    "Смишљај имена производа на основу пример речи. Овде у упутству дајемо информације о производу за који треба да се генеришу имена. Такође дајемо сличан пример да покажемо какав шаблон желимо да добијемо. Поставили смо вредност temperature високо да бисмо добили више случајних и иновативних одговора.\n",
    "\n",
    "Опис производа: Аппарат за прављење милкшејка код куће\n",
    "Кључне речи: брзо, здраво, компактно.\n",
    "Имена производа: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Опис производа: Пар ципела које могу да се прилагоде свакој величини стопала.\n",
    "Кључне речи: прилагодљиво, пристаје, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Референце  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Примери](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Најбоље праксе за фино подешавање GPT-3 за класификацију текста](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# За додатну помоћ  \n",
    "[OpenAI Комерцијални тим](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Сарадници\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Одрицање од одговорности**:  \nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако настојимо да обезбедимо тачност, имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални људски превод. Не сносимо одговорност за било каква неспоразума или погрешна тумачења настала коришћењем овог превода.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:51:17+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}