{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Поглавље 7: Израда чет апликација\n",
    "## Брзи почетак са OpenAI API-јем\n",
    "\n",
    "Овај нотебук је прилагођен из [Azure OpenAI репозиторијума са примерима](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) који садржи нотебуке за приступ [Azure OpenAI](notebook-azure-openai.ipynb) сервисима.\n",
    "\n",
    "Python OpenAI API ради и са Azure OpenAI моделима, уз неколико измена. Више о разликама можете сазнати овде: [Како да пребацујете између OpenAI и Azure OpenAI ендпоинта у Python-у](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Преглед  \n",
    "„Велики језички модели су функције које пресликавају текст у текст. Када добију улазни низ текста, велики језички модел покушава да предвиди који ће текст следећи доћи“(1). Овај „брзи водич“ ће корисницима представити основне концепте великих језичких модела, кључне захтеве пакета за почетак рада са AML-ом, лагани увод у дизајн упита, као и неколико кратких примера различитих начина употребе.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Садржај  \n",
    "\n",
    "[Преглед](../../../../07-building-chat-applications/python)  \n",
    "[Како користити OpenAI сервис](../../../../07-building-chat-applications/python)  \n",
    "[1. Креирање вашег OpenAI сервиса](../../../../07-building-chat-applications/python)  \n",
    "[2. Инсталација](../../../../07-building-chat-applications/python)    \n",
    "[3. Акредитиви](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Примери употребе](../../../../07-building-chat-applications/python)    \n",
    "[1. Сажимање текста](../../../../07-building-chat-applications/python)  \n",
    "[2. Класификација текста](../../../../07-building-chat-applications/python)  \n",
    "[3. Генерисање нових имена производа](../../../../07-building-chat-applications/python)  \n",
    "[4. Фино подешавање класификатора](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Референце](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Направите свој први промпт  \n",
    "Ова кратка вежба ће вам дати основни увод у слање промптова OpenAI моделу за једноставан задатак „сажимање“.\n",
    "\n",
    "\n",
    "**Кораци**:  \n",
    "1. Инсталирајте OpenAI библиотеку у своје Python окружење  \n",
    "2. Учитајте стандардне помоћне библиотеке и подесите своје уобичајене OpenAI безбедносне креденцијале за OpenAI сервис који сте креирали  \n",
    "3. Одаберите модел за свој задатак  \n",
    "4. Направите једноставан промпт за модел  \n",
    "5. Пошаљите свој захтев на API модела!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Проналажење одговарајућег модела  \n",
    "GPT-3.5-turbo или GPT-4 модели могу да разумеју и генеришу природни језик.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Дизајн промпта  \n",
    "\n",
    "„Магија великих језичких модела је у томе што, тренирајући се да минимизују грешку у предвиђању на огромним количинама текста, модели на крају науче појмове који су корисни за ова предвиђања. На пример, они науче појмове као што су“(1):\n",
    "\n",
    "* како се пише\n",
    "* како функционише граматика\n",
    "* како се парафразира\n",
    "* како се одговара на питања\n",
    "* како се води разговор\n",
    "* како се пише на више језика\n",
    "* како се програмира\n",
    "* итд.\n",
    "\n",
    "#### Како контролисати велики језички модел  \n",
    "„Од свих улаза у велики језички модел, далеко највећи утицај има текстуални промпт(1).\n",
    "\n",
    "Велики језички модели могу се подстаћи да генеришу излаз на неколико начина:\n",
    "\n",
    "Инструкција: Реците моделу шта желите\n",
    "Довршавање: Наведите модел да доврши почетак онога што желите\n",
    "Демонстрација: Покажите моделу шта желите, било са:\n",
    "Неколико примера у самом промпту\n",
    "Много стотина или хиљада примера у датасету за фино подешавање“\n",
    "\n",
    "\n",
    "\n",
    "#### Постоје три основне смернице за креирање промптова:\n",
    "\n",
    "**Покажите и реците.** Јасно ставите до знања шта желите, било инструкцијама, примерима или комбинацијом оба. Ако желите да модел поређа листу ставки по абецедном реду или да класификује пасус по сентименту, покажите му да је то оно што желите.\n",
    "\n",
    "**Обезбедите квалитетне податке.** Ако покушавате да направите класификатор или да модел прати неки образац, уверите се да има довољно примера. Обавезно проверите своје примере — модел је обично довољно паметан да препозна основне правописне грешке и да вам ипак да одговор, али може и да претпостави да је то намерно и то може утицати на одговор.\n",
    "\n",
    "**Проверите своја подешавања.** Подешавања temperature и top_p одређују колико ће модел бити детерминистички у генерисању одговора. Ако тражите одговор где постоји само један тачан одговор, онда би требало да их подесите ниже. Ако желите разноврсније одговоре, можда ћете желети да их подесите више. Најчешћа грешка коју људи праве са овим подешавањима је што мисле да су то контроле за „памет“ или „креативност“.\n",
    "\n",
    "\n",
    "Извор: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Сажми текст  \n",
    "#### Изазов  \n",
    "Сажмите текст тако што ћете додати 'tl;dr:' на крај пасуса. Обратите пажњу како модел разуме како да изврши више задатака без додатних упутстава. Можете експериментисати са описнијим упитима од tl;dr да бисте променили понашање модела и прилагодили сажетак који добијате(3).  \n",
    "\n",
    "Недавна истраживања су показала значајан напредак у многим NLP задацима и бенчмарковима кроз претходно тренирање на великом корпусу текста, а затим фино подешавање за одређени задатак. Иако је овај приступ обично независан од задатка по архитектури, и даље захтева специфичне скупова података за фино подешавање са хиљадама или десетинама хиљада примера. Насупрот томе, људи углавном могу да изврше нови језички задатак са само неколико примера или једноставних упутстава – што је нешто са чим се савремени NLP системи и даље углавном муче. Овде показујемо да повећање обима језичких модела значајно побољшава независне перформансе са мало примера, понекад чак достижући ниво конкурентности са претходним најбољим приступима фино подешавања.\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Вежбе за различите случајеве употребе  \n",
    "1. Сажми текст  \n",
    "2. Класификуј текст  \n",
    "3. Генериши нова имена производа\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Класификуј текст  \n",
    "#### Изазов  \n",
    "Класификуј ставке у категорије које се задају у тренутку извршавања. У следећем примеру, у упиту дајемо и категорије и текст који треба класификовати (*playground_reference).\n",
    "\n",
    "Кориснички упит: Здраво, један тастер на тастатури мог лаптопа се недавно поломио и треба ми замена:\n",
    "\n",
    "Класификована категорија:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Генериши нова имена производа\n",
    "#### Изазов\n",
    "Смисли имена производа на основу датих речи. Овде у упутству наводимо информације о производу за који треба да смислимо имена. Такође дајемо сличан пример да покажемо какав образац желимо да добијемо. Поставили смо и вредност temperature високо како бисмо добили насумичније и креативније одговоре.\n",
    "\n",
    "Опис производа: Аппарат за прављење милкшејкова код куће  \n",
    "Кључне речи: брзо, здраво, компактно.  \n",
    "Имена производа: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Опис производа: Пар ципела које могу да пристају свакој величини стопала.  \n",
    "Кључне речи: прилагодљиво, пристаје, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Референце  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Примери](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Најбоље праксе за фино подешавање GPT-3 за класификацију текста](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# За додатну помоћ  \n",
    "[OpenAI Комерцијални тим](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Сарадници\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Одрицање од одговорности**:  \nОвај документ је преведен коришћењем AI услуге за превођење [Co-op Translator](https://github.com/Azure/co-op-translator). Иако настојимо да обезбедимо тачност, имајте у виду да аутоматски преводи могу садржати грешке или нетачности. Оригинални документ на изворном језику треба сматрати меродавним извором. За критичне информације препоручује се професионални људски превод. Не сносимо одговорност за било каква неспоразума или погрешна тумачења настала коришћењем овог превода.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:30:36+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "sr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}