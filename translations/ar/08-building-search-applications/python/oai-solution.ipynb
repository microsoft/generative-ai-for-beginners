{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "لتشغيل دفاتر الملاحظات التالية، إذا لم تقم بذلك بعد، تحتاج إلى تعيين مفتاح openai داخل ملف .env باسم `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد ذلك، سنقوم بتحميل فهرس التضمين في إطار بيانات Pandas. يتم تخزين فهرس التضمين في ملف JSON يسمى `embedding_index_3m.json`. يحتوي فهرس التضمين على التضمينات لكل من نصوص يوتيوب حتى أواخر أكتوبر 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد ذلك، سنقوم بإنشاء دالة تسمى `get_videos` التي ستبحث في فهرس التضمين عن الاستعلام. ستُرجع الدالة أفضل 5 مقاطع فيديو هي الأكثر تشابهًا مع الاستعلام. تعمل الدالة كما يلي:\n",
    "\n",
    "1. أولاً، يتم إنشاء نسخة من فهرس التضمين.\n",
    "2. بعد ذلك، يتم حساب التضمين للاستعلام باستخدام واجهة برمجة تطبيقات التضمين من OpenAI.\n",
    "3. ثم يتم إنشاء عمود جديد في فهرس التضمين يسمى `similarity`. يحتوي عمود `similarity` على التشابه الكوني بين تضمين الاستعلام وتضمين كل مقطع فيديو.\n",
    "4. بعد ذلك، يتم تصفية فهرس التضمين بواسطة عمود `similarity`. يتم تصفية فهرس التضمين ليشمل فقط مقاطع الفيديو التي لها تشابه كوني أكبر من أو يساوي 0.75.\n",
    "5. أخيرًا، يتم فرز فهرس التضمين حسب عمود `similarity` ويتم إرجاع أفضل 5 مقاطع فيديو.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "هذه الدالة بسيطة جدًا، فهي فقط تطبع نتائج استعلام البحث.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. أولاً، يتم تحميل فهرس التضمين في إطار بيانات Pandas.\n",
    "2. بعد ذلك، يُطلب من المستخدم إدخال استعلام.\n",
    "3. ثم يتم استدعاء دالة `get_videos` للبحث في فهرس التضمين عن الاستعلام.\n",
    "4. أخيرًا، يتم استدعاء دالة `display_results` لعرض النتائج على المستخدم.\n",
    "5. ثم يُطلب من المستخدم إدخال استعلام آخر. تستمر هذه العملية حتى يدخل المستخدم `exit`.\n",
    "\n",
    "![](../../../../translated_images/ar/notebook-search.1e320b9c7fcbb0bc.png)\n",
    "\n",
    "سيُطلب منك إدخال استعلام. أدخل استعلامًا واضغط إدخال. ستُرجع التطبيق قائمة بالفيديوهات ذات الصلة بالاستعلام. كما ستُرجع التطبيق رابطًا إلى المكان في الفيديو حيث يقع جواب السؤال.\n",
    "\n",
    "إليك بعض الاستعلامات لتجربتها:\n",
    "\n",
    "- ما هو Azure Machine Learning؟\n",
    "- كيف تعمل الشبكات العصبية الالتفافية؟\n",
    "- ما هي الشبكة العصبية؟\n",
    "- هل يمكنني استخدام دفاتر Jupyter مع Azure Machine Learning؟\n",
    "- ما هو ONNX؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق به. للمعلومات الهامة، يُنصح بالاعتماد على الترجمة البشرية المهنية. نحن غير مسؤولين عن أي سوء فهم أو تفسير ناتج عن استخدام هذه الترجمة.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T08:52:25+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}