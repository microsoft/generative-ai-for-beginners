{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "لتشغيل دفاتر الملاحظات التالية، إذا لم تكن قد فعلت ذلك بعد، تحتاج إلى نشر نموذج يستخدم `text-embedding-ada-002` كنموذج أساسي وتعيين اسم النشر داخل ملف .env كـ `AZURE_OPENAI_EMBEDDINGS_ENDPOINT`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد ذلك، سنقوم بتحميل مؤشر التضمين في إطار بيانات Pandas. يتم تخزين مؤشر التضمين في ملف JSON يسمى `embedding_index_3m.json`. يحتوي مؤشر التضمين على التضمينات لكل من نصوص YouTube حتى أواخر أكتوبر 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد ذلك، سنقوم بإنشاء دالة باسم `get_videos` تبحث في فهرس التضمين عن الاستعلام المطلوب. ستعيد الدالة أفضل 5 فيديوهات الأكثر تشابهًا مع الاستعلام. تعمل الدالة بالطريقة التالية:\n",
    "\n",
    "1. أولاً، يتم إنشاء نسخة من فهرس التضمين.\n",
    "2. بعد ذلك، يتم حساب تضمين الاستعلام باستخدام واجهة برمجة تطبيقات تضمين OpenAI.\n",
    "3. ثم يتم إنشاء عمود جديد في فهرس التضمين باسم `similarity`. يحتوي هذا العمود على التشابه الكوني بين تضمين الاستعلام وتضمين كل مقطع فيديو.\n",
    "4. بعد ذلك، يتم تصفية فهرس التضمين حسب عمود `similarity`. يتم الاحتفاظ فقط بالفيديوهات التي لديها تشابه كوني أكبر من أو يساوي 0.75.\n",
    "5. أخيرًا، يتم ترتيب فهرس التضمين حسب عمود `similarity` وتتم إعادة أفضل 5 فيديوهات.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "هذه الدالة بسيطة جدًا، فهي فقط تطبع نتائج استعلام البحث.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. أولاً، يتم تحميل فهرس التضمين داخل إطار بيانات Pandas.\n",
    "2. بعد ذلك، يُطلب من المستخدم إدخال استعلام.\n",
    "3. ثم يتم استدعاء دالة `get_videos` للبحث في فهرس التضمين عن الاستعلام.\n",
    "4. أخيراً، يتم استدعاء دالة `display_results` لعرض النتائج على المستخدم.\n",
    "5. بعد ذلك، يُطلب من المستخدم إدخال استعلام آخر. تستمر هذه العملية حتى يقوم المستخدم بإدخال `exit`.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.ar.png)\n",
    "\n",
    "سيتم مطالبتك بإدخال استعلام. أدخل استعلامك واضغط على زر الإدخال. سيعرض التطبيق قائمة بالفيديوهات المتعلقة بالاستعلام الذي أدخلته. كما سيعرض التطبيق رابطاً للمكان في الفيديو الذي توجد فيه إجابة السؤال.\n",
    "\n",
    "إليك بعض الاستعلامات التي يمكنك تجربتها:\n",
    "\n",
    "- ما هو Azure Machine Learning؟\n",
    "- كيف تعمل الشبكات العصبية الالتفافية؟\n",
    "- ما هي الشبكة العصبية؟\n",
    "- هل يمكنني استخدام Jupyter Notebooks مع Azure Machine Learning؟\n",
    "- ما هو ONNX؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "32c6b8e9e87156b9c63ee62a6fd7f526",
   "translation_date": "2025-08-25T18:38:36+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}