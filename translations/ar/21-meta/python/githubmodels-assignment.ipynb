{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# البناء باستخدام نماذج عائلة Meta\n",
    "\n",
    "## المقدمة\n",
    "\n",
    "سنتناول في هذا الدرس:\n",
    "\n",
    "- استكشاف النموذجين الرئيسيين من عائلة Meta - Llama 3.1 و Llama 3.2\n",
    "- فهم حالات الاستخدام والسيناريوهات المناسبة لكل نموذج\n",
    "- مثال برمجي يوضح الميزات الفريدة لكل نموذج\n",
    "\n",
    "## عائلة نماذج Meta\n",
    "\n",
    "في هذا الدرس، سنستعرض نموذجين من عائلة Meta أو ما يسمى بـ \"قطيع Llama\" - وهما Llama 3.1 و Llama 3.2\n",
    "\n",
    "تتوفر هذه النماذج بعدة إصدارات ويمكن الحصول عليها من سوق النماذج على Github. لمزيد من التفاصيل حول استخدام نماذج Github لـ [النمذجة الأولية مع نماذج الذكاء الاصطناعي](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "إصدارات النماذج:\n",
    "- Llama 3.1 - 70B Instruct\n",
    "- Llama 3.1 - 405B Instruct\n",
    "- Llama 3.2 - 11B Vision Instruct\n",
    "- Llama 3.2 - 90B Vision Instruct\n",
    "\n",
    "*ملاحظة: يتوفر Llama 3 أيضاً على Github Models لكنه لن يكون ضمن محتوى هذا الدرس*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "بـ 405 مليار معلمة، تندرج Llama 3.1 ضمن فئة نماذج اللغة الكبيرة مفتوحة المصدر.\n",
    "\n",
    "هذا الإصدار هو تطوير للإصدار السابق Llama 3 من خلال تقديم:\n",
    "\n",
    "- نافذة سياق أكبر - 128 ألف رمز مقابل 8 آلاف رمز\n",
    "- حد أقصى أكبر لعدد الرموز الناتجة - 4096 مقابل 2048\n",
    "- دعم لغات متعددة بشكل أفضل - بسبب زيادة عدد الرموز المستخدمة في التدريب\n",
    "\n",
    "هذه الميزات تمكّن Llama 3.1 من التعامل مع حالات استخدام أكثر تعقيدًا عند بناء تطبيقات الذكاء الاصطناعي التوليدي، بما في ذلك:\n",
    "- استدعاء الدوال بشكل مباشر - القدرة على استدعاء أدوات ودوال خارج سير عمل النموذج اللغوي\n",
    "- أداء أفضل في استرجاع المعلومات المعزز - بفضل نافذة السياق الأكبر\n",
    "- توليد بيانات اصطناعية - القدرة على إنشاء بيانات فعّالة لمهام مثل التخصيص الدقيق\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### استدعاء الدوال الأصلية\n",
    "\n",
    "تم تحسين Llama 3.1 ليكون أكثر فعالية في استدعاء الدوال أو الأدوات. كما يحتوي على أداتين مدمجتين يمكن للنموذج التعرف على الحاجة لاستخدامهما بناءً على طلب المستخدم. هاتان الأداتان هما:\n",
    "\n",
    "- **Brave Search** - يمكن استخدامها للحصول على معلومات حديثة مثل حالة الطقس من خلال البحث على الإنترنت\n",
    "- **Wolfram Alpha** - يمكن استخدامها لإجراء حسابات رياضية معقدة، وبالتالي لن تحتاج لكتابة دوالك الخاصة\n",
    "\n",
    "يمكنك أيضًا إنشاء أدواتك المخصصة التي يمكن لـ LLM استدعاؤها.\n",
    "\n",
    "في مثال الكود أدناه:\n",
    "\n",
    "- نحدد الأدوات المتاحة (brave_search, wolfram_alpha) في رسالة النظام.\n",
    "- نرسل طلب مستخدم يسأل عن حالة الطقس في مدينة معينة.\n",
    "- سيستجيب LLM باستدعاء أداة Brave Search وسيبدو الاستدعاء بهذا الشكل `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`\n",
    "\n",
    "*ملاحظة: هذا المثال يقوم فقط باستدعاء الأداة، إذا كنت ترغب في الحصول على النتائج، ستحتاج إلى إنشاء حساب مجاني في صفحة Brave API وتعريف الدالة بنفسك*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### لاما 3.2\n",
    "\n",
    "على الرغم من أن لاما 3.1 هو نموذج لغوي كبير، إلا أن أحد قيوده هو عدم دعمه للوسائط المتعددة. أي أنه لا يستطيع استخدام أنواع مختلفة من المدخلات مثل الصور كمدخلات وتقديم ردود عليها. هذه القدرة تُعد من الميزات الرئيسية في لاما 3.2. وتشمل هذه الميزات أيضًا:\n",
    "\n",
    "- دعم الوسائط المتعددة - يمكنه تقييم كل من النصوص والصور كمدخلات\n",
    "- إصدارات بأحجام صغيرة إلى متوسطة (11B و90B) - هذا يوفر خيارات نشر مرنة،\n",
    "- إصدارات نصية فقط (1B و3B) - هذا يسمح بنشر النموذج على الأجهزة الطرفية أو المحمولة ويوفر استجابة سريعة\n",
    "\n",
    "دعم الوسائط المتعددة يُعد خطوة كبيرة في عالم النماذج مفتوحة المصدر. المثال البرمجي أدناه يأخذ صورة ونصًا كمدخلات للحصول على تحليل للصورة من لاما 3.2 90B.\n",
    "\n",
    "### دعم الوسائط المتعددة مع لاما 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## التعلم لا يتوقف هنا، واصل الرحلة\n",
    "\n",
    "بعد الانتهاء من هذا الدرس، اطلع على [مجموعة تعلم الذكاء الاصطناعي التوليدي](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) لمواصلة تطوير معرفتك في الذكاء الاصطناعي التوليدي!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:36:58+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}