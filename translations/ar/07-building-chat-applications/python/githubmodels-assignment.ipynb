{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# الفصل ٧: بناء تطبيقات الدردشة\n",
    "## البدء السريع مع واجهة برمجة تطبيقات نماذج Github\n",
    "\n",
    "تم تعديل هذا الدفتر من [مستودع عينات Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) الذي يحتوي على دفاتر تمكنك من الوصول إلى خدمات [Azure OpenAI](notebook-azure-openai.ipynb).\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# نظرة عامة  \n",
    "\"النماذج اللغوية الكبيرة هي دوال تقوم بتحويل النص إلى نص. عند إعطائها سلسلة نصية كمدخل، تحاول النماذج اللغوية الكبيرة التنبؤ بالنص الذي سيأتي بعد ذلك\"(1). هذا الدليل السريع سيعرّف المستخدمين على مفاهيم أساسية حول النماذج اللغوية الكبيرة، والمتطلبات الأساسية للبدء مع AML، ومقدمة مبسطة حول تصميم التعليمات، بالإضافة إلى عدة أمثلة قصيرة لحالات استخدام مختلفة.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## جدول المحتويات  \n",
    "\n",
    "[نظرة عامة](../../../../07-building-chat-applications/python)  \n",
    "[كيفية استخدام خدمة OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[1. إنشاء خدمة OpenAI الخاصة بك](../../../../07-building-chat-applications/python)  \n",
    "[2. التثبيت](../../../../07-building-chat-applications/python)    \n",
    "[3. بيانات الاعتماد](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[حالات الاستخدام](../../../../07-building-chat-applications/python)    \n",
    "[1. تلخيص النص](../../../../07-building-chat-applications/python)  \n",
    "[2. تصنيف النص](../../../../07-building-chat-applications/python)  \n",
    "[3. إنشاء أسماء جديدة للمنتجات](../../../../07-building-chat-applications/python)  \n",
    "[4. تحسين أداء المصنف](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[المراجع](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### أنشئ أول مطالبة لك  \n",
    "هذا التمرين القصير سيعطيك مقدمة أساسية حول كيفية إرسال مطالبات إلى نموذج في Github Models لأداء مهمة بسيطة مثل \"التلخيص\".\n",
    "\n",
    "**الخطوات**:  \n",
    "1. قم بتثبيت مكتبة `azure-ai-inference` في بيئة بايثون الخاصة بك إذا لم تكن قد قمت بذلك بالفعل.  \n",
    "2. حمّل مكتبات المساعدة القياسية وقم بإعداد بيانات اعتماد Github Models.  \n",
    "3. اختر نموذجاً لمهمتك  \n",
    "4. أنشئ مطالبة بسيطة للنموذج  \n",
    "5. أرسل طلبك إلى واجهة برمجة تطبيقات النموذج!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. تثبيت `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ٢. استيراد مكتبات المساعدة وإنشاء بيانات الاعتماد\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ٣. اختيار النموذج المناسب  \n",
    "نماذج GPT-3.5-turbo أو GPT-4 قادرة على فهم وتوليد اللغة الطبيعية.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ٤. تصميم الموجهات  \n",
    "\n",
    "\"سر النماذج اللغوية الكبيرة هو أنه من خلال تدريبها على تقليل خطأ التنبؤ عبر كميات هائلة من النصوص، تتعلم هذه النماذج مفاهيم مفيدة لهذه التنبؤات. على سبيل المثال، تتعلم مفاهيم مثل\"(١):\n",
    "\n",
    "* كيف تُكتب الكلمات بشكل صحيح\n",
    "* كيف تعمل القواعد اللغوية\n",
    "* كيف تعيد صياغة الجمل\n",
    "* كيف تجيب على الأسئلة\n",
    "* كيف تدير محادثة\n",
    "* كيف تكتب بلغات متعددة\n",
    "* كيف تبرمج\n",
    "* وغيرها\n",
    "\n",
    "#### كيف تتحكم في النموذج اللغوي الكبير  \n",
    "\"من بين جميع المدخلات للنموذج اللغوي الكبير، يبقى النص الذي تكتبه في الموجه هو الأكثر تأثيراً بفارق كبير(١).\n",
    "\n",
    "يمكن تحفيز النماذج اللغوية الكبيرة لإنتاج مخرجات بعدة طرق:\n",
    "\n",
    "التعليمات: أخبر النموذج بما تريد\n",
    "الإكمال: اجعل النموذج يكمل بداية ما ترغب به\n",
    "العرض: أرِ النموذج ما تريد، إما من خلال:\n",
    "بعض الأمثلة في الموجه\n",
    "مئات أو آلاف الأمثلة في مجموعة بيانات تدريبية مخصصة\"\n",
    "\n",
    "\n",
    "\n",
    "#### هناك ثلاث قواعد أساسية لإنشاء الموجهات:\n",
    "\n",
    "**وضح وبيّن**. اجعل ما تريده واضحاً سواء عبر التعليمات أو الأمثلة أو الجمع بينهما. إذا كنت تريد من النموذج ترتيب قائمة عناصر حسب الترتيب الأبجدي أو تصنيف فقرة حسب المشاعر، وضّح له ذلك.\n",
    "\n",
    "**قدّم بيانات ذات جودة**. إذا كنت تحاول بناء مصنف أو جعل النموذج يتبع نمطاً معيناً، تأكد من وجود أمثلة كافية. راجع أمثلتك جيداً — غالباً النموذج ذكي بما يكفي لتجاوز الأخطاء الإملائية البسيطة ويعطيك رداً، لكنه قد يفترض أن ذلك مقصود وقد يؤثر ذلك على الرد.\n",
    "\n",
    "**راجع الإعدادات الخاصة بك.** إعدادات temperature و top_p تتحكم في مدى حتمية النموذج في توليد الرد. إذا كنت تطلب منه إجابة واحدة صحيحة فقط، من الأفضل أن تضبط هذه الإعدادات على قيم منخفضة. أما إذا كنت تبحث عن ردود متنوعة أكثر، فقد ترغب في رفعها. الخطأ الأكثر شيوعاً هو أن يظن الناس أن هذه الإعدادات تتحكم في \"الذكاء\" أو \"الإبداع\" لدى النموذج.\n",
    "\n",
    "\n",
    "المصدر: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### كرر نفس الطلب، كيف تقارن النتائج؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## تلخيص النص  \n",
    "#### التحدي  \n",
    "تلخيص النص بإضافة 'tl;dr:' في نهاية المقطع. لاحظ كيف أن النموذج يفهم كيفية تنفيذ عدة مهام دون تعليمات إضافية. يمكنك تجربة مطالبات أكثر وصفية من tl;dr لتعديل سلوك النموذج وتخصيص التلخيص الذي تحصل عليه(3).  \n",
    "\n",
    "أظهرت الأبحاث الحديثة تقدماً كبيراً في العديد من مهام ومعايير معالجة اللغة الطبيعية من خلال التدريب المسبق على مجموعة ضخمة من النصوص، ثم تحسين النموذج لمهمة محددة. وعلى الرغم من أن هذه الطريقة غالباً ما تكون محايدة من حيث بنية المهمة، إلا أنها لا تزال تتطلب مجموعات بيانات مخصصة للتدريب تتكون من آلاف أو عشرات الآلاف من الأمثلة. بالمقابل، يستطيع البشر عادةً أداء مهمة لغوية جديدة من خلال عدد قليل من الأمثلة أو تعليمات بسيطة - وهو أمر لا تزال أنظمة معالجة اللغة الطبيعية الحالية تواجه صعوبة كبيرة فيه. هنا نوضح أن زيادة حجم نماذج اللغة يحسن بشكل كبير الأداء القليل الأمثلة والمحايد للمهمة، وأحياناً يصل إلى مستوى المنافسة مع أفضل طرق التحسين السابقة.\n",
    "\n",
    "tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# تمارين لعدة حالات استخدام  \n",
    "1. تلخيص النص  \n",
    "2. تصنيف النص  \n",
    "3. ابتكار أسماء جديدة للمنتجات\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## تصنيف النص  \n",
    "#### التحدي  \n",
    "صنّف العناصر ضمن الفئات التي يتم تزويدها وقت التنفيذ. في المثال التالي، نوفّر كلًا من الفئات والنص المطلوب تصنيفه في الموجه (*playground_reference).\n",
    "\n",
    "استفسار العميل: مرحبًا، أحد أزرار لوحة مفاتيح اللابتوب الخاصة بي انكسر مؤخرًا وأحتاج إلى بديل:\n",
    "\n",
    "الفئة المصنفة:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ابتكر أسماء جديدة للمنتجات\n",
    "#### التحدي\n",
    "قم بابتكار أسماء للمنتجات باستخدام كلمات مقترحة كمصدر للإلهام. في هذا التحدي، نعرض في التعليمات معلومات عن المنتج الذي نرغب في ابتكار أسماء له. كما نوفر مثالاً مشابهاً لنوضح النمط الذي نرغب في الحصول عليه. بالإضافة إلى ذلك، قمنا بضبط قيمة العشوائية على مستوى عالٍ لزيادة التنوع والابتكار في الإجابات.\n",
    "\n",
    "وصف المنتج: جهاز منزلي لصنع الميلك شيك\n",
    "كلمات مفتاحية: سريع، صحي، صغير الحجم.\n",
    "أسماء المنتجات: هوم شيكر، فيت شيكر، كويك شيك، شيك ميكر\n",
    "\n",
    "وصف المنتج: حذاء يمكن أن يناسب أي مقاس قدم.\n",
    "كلمات مفتاحية: قابل للتكيف، مناسب، أومني-فيت.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# المراجع  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [أمثلة OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [أفضل الممارسات لتحسين GPT-3 لتصنيف النصوص](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# للمزيد من المساعدة  \n",
    "[فريق تسويق OpenAI التجاري](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# المساهمون\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:22:13+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}