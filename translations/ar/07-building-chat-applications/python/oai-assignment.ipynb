{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# الفصل 7: بناء تطبيقات الدردشة\n",
    "## البدء السريع مع واجهة برمجة تطبيقات OpenAI\n",
    "\n",
    "تم تعديل هذا الدفتر من [مستودع عينات Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) الذي يتضمن دفاتر ملاحظات تصل إلى خدمات [Azure OpenAI](notebook-azure-openai.ipynb).\n",
    "\n",
    "تعمل واجهة برمجة تطبيقات OpenAI في بايثون مع نماذج Azure OpenAI أيضًا، مع بعض التعديلات البسيطة. يمكنك معرفة المزيد عن الفروقات هنا: [كيفية التبديل بين نقاط نهاية OpenAI و Azure OpenAI باستخدام بايثون](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# نظرة عامة  \n",
    "\"النماذج اللغوية الكبيرة هي دوال تقوم بتحويل النص إلى نص. عند إعطائها سلسلة نصية كمدخل، تحاول النماذج اللغوية الكبيرة التنبؤ بالنص الذي سيأتي بعد ذلك\"(1). هذا الدليل السريع سيعرّف المستخدمين على مفاهيم أساسية حول النماذج اللغوية الكبيرة، والمتطلبات الأساسية للبدء مع AML، ومقدمة مبسطة حول تصميم التعليمات، بالإضافة إلى عدة أمثلة قصيرة لحالات استخدام مختلفة.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## جدول المحتويات  \n",
    "\n",
    "[نظرة عامة](../../../../07-building-chat-applications/python)  \n",
    "[كيفية استخدام خدمة OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[1. إنشاء خدمة OpenAI الخاصة بك](../../../../07-building-chat-applications/python)  \n",
    "[2. التثبيت](../../../../07-building-chat-applications/python)    \n",
    "[3. بيانات الاعتماد](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[حالات الاستخدام](../../../../07-building-chat-applications/python)    \n",
    "[1. تلخيص النص](../../../../07-building-chat-applications/python)  \n",
    "[2. تصنيف النص](../../../../07-building-chat-applications/python)  \n",
    "[3. إنشاء أسماء منتجات جديدة](../../../../07-building-chat-applications/python)  \n",
    "[4. تحسين أداء المصنف](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[المراجع](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### أنشئ أول مطالبة لك  \n",
    "هذا التمرين القصير سيقدم لك مقدمة أساسية حول كيفية إرسال مطالبات إلى نموذج OpenAI لأداء مهمة بسيطة مثل \"التلخيص\".\n",
    "\n",
    "**الخطوات**:  \n",
    "1. قم بتثبيت مكتبة OpenAI في بيئة بايثون الخاصة بك  \n",
    "2. حمّل مكتبات المساعدة القياسية وقم بتعيين بيانات الاعتماد الأمنية المعتادة لخدمة OpenAI التي أنشأتها  \n",
    "3. اختر نموذجاً لمهمتك  \n",
    "4. أنشئ مطالبة بسيطة للنموذج  \n",
    "5. أرسل طلبك إلى واجهة برمجة تطبيقات النموذج!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ١. تثبيت OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ٢. استيراد مكتبات المساعدة وإنشاء بيانات الاعتماد\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ٣. اختيار النموذج المناسب  \n",
    "نماذج GPT-3.5-turbo أو GPT-4 قادرة على فهم وإنتاج اللغة الطبيعية.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ٤. تصميم التعليمات\n",
    "\n",
    "\"سر النماذج اللغوية الكبيرة هو أنه من خلال تدريبها على تقليل خطأ التنبؤ عبر كميات هائلة من النصوص، تتعلم هذه النماذج مفاهيم مفيدة لهذه التنبؤات. على سبيل المثال، تتعلم مفاهيم مثل\"(١):\n",
    "\n",
    "* كيفية التهجئة\n",
    "* كيف تعمل القواعد اللغوية\n",
    "* كيفية إعادة صياغة الكلام\n",
    "* كيفية الإجابة على الأسئلة\n",
    "* كيفية إجراء المحادثات\n",
    "* كيفية الكتابة بلغات متعددة\n",
    "* كيفية البرمجة\n",
    "* وغيرها\n",
    "\n",
    "#### كيف تتحكم في النموذج اللغوي الكبير\n",
    "\"من بين جميع المدخلات للنموذج اللغوي الكبير، الأكثر تأثيراً هو نص التعليمات (١).\n",
    "\n",
    "يمكن تحفيز النماذج اللغوية الكبيرة لإنتاج مخرجات بعدة طرق:\n",
    "\n",
    "التعليمات: أخبر النموذج بما تريد\n",
    "الإكمال: اجعل النموذج يكمل بداية ما ترغب به\n",
    "العرض: أرِ النموذج ما تريد، إما من خلال:\n",
    "بعض الأمثلة في التعليمات\n",
    "مئات أو آلاف الأمثلة في مجموعة بيانات تدريبية مخصصة\"\n",
    "\n",
    "\n",
    "\n",
    "#### هناك ثلاث إرشادات أساسية لإنشاء التعليمات:\n",
    "\n",
    "**أرِ ووضّح**. اجعل ما تريده واضحاً سواء عبر التعليمات أو الأمثلة أو الجمع بينهما. إذا كنت تريد من النموذج ترتيب قائمة عناصر أبجدياً أو تصنيف فقرة حسب المشاعر، وضّح له ذلك.\n",
    "\n",
    "**قدّم بيانات ذات جودة**. إذا كنت تحاول بناء مصنف أو جعل النموذج يتبع نمطاً معيناً، تأكد من وجود أمثلة كافية. راجع أمثلتك جيداً — النموذج غالباً ذكي بما يكفي لتجاوز الأخطاء الإملائية البسيطة ويعطيك رداً، لكنه قد يفترض أن ذلك مقصود ويمكن أن يؤثر على الرد.\n",
    "\n",
    "**تحقق من الإعدادات.** إعدادات temperature و top_p تتحكم في مدى حتمية النموذج في توليد الرد. إذا كنت تطلب رداً له إجابة واحدة صحيحة فقط، من الأفضل ضبط هذه الإعدادات على قيم منخفضة. إذا كنت تبحث عن ردود متنوعة أكثر، يمكنك رفعها. الخطأ الأكثر شيوعاً هو افتراض أن هذه الإعدادات تتحكم في \"الذكاء\" أو \"الإبداع\".\n",
    "\n",
    "المصدر: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### كرر نفس الطلب، كيف تقارن النتائج؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## تلخيص النص  \n",
    "#### التحدي  \n",
    "قم بتلخيص النص بإضافة 'tl;dr:' في نهاية المقطع. لاحظ كيف أن النموذج يفهم كيفية تنفيذ عدة مهام دون تعليمات إضافية. يمكنك تجربة مطالبات أكثر وصفية من tl;dr لتغيير سلوك النموذج وتخصيص التلخيص الذي تحصل عليه(3).  \n",
    "\n",
    "أظهرت الأبحاث الحديثة تقدماً كبيراً في العديد من مهام ومعايير معالجة اللغة الطبيعية من خلال التدريب المسبق على مجموعة ضخمة من النصوص، ثم تحسين النموذج لمهمة محددة. وعلى الرغم من أن هذه الطريقة غالباً ما تكون محايدة من حيث البنية، إلا أنها لا تزال تتطلب مجموعات بيانات مخصصة للتدريب تتكون من آلاف أو عشرات الآلاف من الأمثلة. بالمقابل، يستطيع البشر عادةً أداء مهمة لغوية جديدة من خلال عدد قليل من الأمثلة أو تعليمات بسيطة - وهو أمر لا تزال أنظمة معالجة اللغة الطبيعية الحالية تواجه صعوبة في تحقيقه. هنا نوضح أن زيادة حجم نماذج اللغة يحسن بشكل كبير الأداء المحايد للمهمة مع عدد قليل من الأمثلة، وأحياناً يصل إلى مستوى المنافسة مع أفضل الأساليب السابقة التي تعتمد على تحسين النموذج للمهمة المحددة.\n",
    "\n",
    "\n",
    "\n",
    "tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# تمارين لحالات استخدام متعددة  \n",
    "1. تلخيص النص  \n",
    "2. تصنيف النص  \n",
    "3. ابتكار أسماء جديدة للمنتجات\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## تصنيف النص  \n",
    "#### التحدي  \n",
    "صنّف العناصر ضمن الفئات التي يتم تزويدها وقت التنفيذ. في المثال التالي، نعرض كلًا من الفئات والنص المطلوب تصنيفه في الموجه (*playground_reference).\n",
    "\n",
    "استفسار العميل: مرحبًا، أحد أزرار لوحة مفاتيح اللابتوب الخاصة بي انكسر مؤخرًا وأحتاج إلى بديل:\n",
    "\n",
    "الفئة المصنفة:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ابتكر أسماء جديدة للمنتجات\n",
    "#### التحدي\n",
    "ابتكر أسماء منتجات باستخدام كلمات أمثلة. في هذا التحدي، ندرج في التعليمات معلومات عن المنتج الذي نرغب في ابتكار أسماء له. كما نوفر مثالاً مشابهاً ليوضح النمط الذي نرغب في الحصول عليه. كذلك قمنا بضبط قيمة العشوائية على مستوى عالٍ لزيادة التنوع والحصول على أفكار مبتكرة أكثر.\n",
    "\n",
    "وصف المنتج: جهاز منزلي لصنع الميلك شيك\n",
    "كلمات مفتاحية: سريع، صحي، صغير الحجم.\n",
    "أسماء المنتجات: هوم شيكر، فيت شيكر، كويك شيك، شيك ميكر\n",
    "\n",
    "وصف المنتج: زوج من الأحذية يمكن أن يناسب أي مقاس قدم.\n",
    "كلمات مفتاحية: قابل للتكيف، مناسب، أومني-فيت.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# المراجع  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [أمثلة OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [أفضل الممارسات لتخصيص GPT-3 لتصنيف النصوص](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# لمزيد من المساعدة  \n",
    "[فريق تسويق OpenAI](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# المساهمون\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:01:53+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}