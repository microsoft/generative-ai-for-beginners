{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# بناء تطبيق لتوليد الصور\n",
    "\n",
    "هناك استخدامات أكثر لنماذج اللغة الكبيرة (LLMs) غير توليد النصوص فقط. من الممكن أيضًا توليد صور من أوصاف نصية. وجود الصور كوسيلة يمكن أن يكون مفيدًا جدًا في العديد من المجالات مثل التكنولوجيا الطبية، والهندسة المعمارية، والسياحة، وتطوير الألعاب وغيرها. في هذا الفصل، سنستعرض أشهر نموذجين لتوليد الصور، وهما DALL-E وMidjourney.\n",
    "\n",
    "## المقدمة\n",
    "\n",
    "في هذا الدرس، سنغطي:\n",
    "\n",
    "- توليد الصور ولماذا هو مفيد.\n",
    "- DALL-E وMidjourney، ما هما وكيف يعملان.\n",
    "- كيف يمكنك بناء تطبيق لتوليد الصور.\n",
    "\n",
    "## أهداف التعلم\n",
    "\n",
    "بعد الانتهاء من هذا الدرس، ستكون قادرًا على:\n",
    "\n",
    "- بناء تطبيق لتوليد الصور.\n",
    "- تحديد حدود لتطبيقك باستخدام مطالبات ميتا (meta prompts).\n",
    "- العمل مع DALL-E وMidjourney.\n",
    "\n",
    "## لماذا نبني تطبيق لتوليد الصور؟\n",
    "\n",
    "تطبيقات توليد الصور طريقة رائعة لاستكشاف قدرات الذكاء الاصطناعي التوليدي. يمكن استخدامها، على سبيل المثال:\n",
    "\n",
    "- **تحرير الصور وتوليفها**. يمكنك توليد صور لمجموعة متنوعة من الاستخدامات، مثل تحرير الصور أو توليفها.\n",
    "\n",
    "- **تطبيقها في صناعات متعددة**. يمكن أيضًا استخدامها لتوليد صور لمجالات مثل التكنولوجيا الطبية، والسياحة، وتطوير الألعاب وغيرها.\n",
    "\n",
    "## سيناريو: Edu4All\n",
    "\n",
    "كجزء من هذا الدرس، سنواصل العمل مع شركتنا الناشئة Edu4All. سيقوم الطلاب بإنشاء صور لتقييماتهم، ونوع الصور متروك للطلاب، فقد تكون رسومات توضيحية لقصتهم الخيالية أو ابتكار شخصية جديدة لقصتهم أو مساعدتهم في تصور أفكارهم ومفاهيمهم.\n",
    "\n",
    "مثال على ما يمكن أن يولده طلاب Edu4All إذا كانوا يعملون في الصف على موضوع المعالم:\n",
    "\n",
    "![شركة Edu4All الناشئة، درس عن المعالم، برج إيفل](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.ar.png)\n",
    "\n",
    "باستخدام مطالبة مثل\n",
    "\n",
    "> \"كلب بجانب برج إيفل في ضوء شمس الصباح الباكر\"\n",
    "\n",
    "## ما هو DALL-E وMidjourney؟\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) و[Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) هما من أشهر نماذج توليد الصور، حيث يسمحان لك باستخدام مطالبات نصية لتوليد الصور.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "لنبدأ مع DALL-E، وهو نموذج ذكاء اصطناعي توليدي يقوم بتوليد الصور من الأوصاف النصية.\n",
    "\n",
    "> [DALL-E هو مزيج من نموذجين، CLIP والانتباه المنتشر](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP**، هو نموذج يقوم بإنشاء تمثيلات رقمية (embeddings) للبيانات من الصور والنصوص.\n",
    "\n",
    "- **الانتباه المنتشر**، هو نموذج يقوم بتوليد الصور من التمثيلات الرقمية. تم تدريب DALL-E على مجموعة بيانات من الصور والنصوص ويمكن استخدامه لتوليد صور من أوصاف نصية. على سبيل المثال، يمكن استخدام DALL-E لتوليد صورة لقطة ترتدي قبعة، أو كلب بتسريحة موهوك.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "يعمل Midjourney بطريقة مشابهة لـ DALL-E، حيث يولد صورًا من مطالبات نصية. يمكن أيضًا استخدام Midjourney لتوليد صور باستخدام مطالبات مثل \"قطة ترتدي قبعة\"، أو \"كلب بتسريحة موهوك\".\n",
    "\n",
    "![صورة مولدة بواسطة Midjourney، حمامة ميكانيكية](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*مصدر الصورة ويكيبيديا، الصورة مولدة بواسطة Midjourney*\n",
    "\n",
    "## كيف يعمل DALL-E وMidjourney\n",
    "\n",
    "أولاً، [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E هو نموذج ذكاء اصطناعي توليدي مبني على بنية المحول (transformer) مع *محول توليدي ذاتي*.\n",
    "\n",
    "*المحول التوليدي الذاتي* يحدد كيف يقوم النموذج بتوليد الصور من الأوصاف النصية، حيث يولد بكسلًا واحدًا في كل مرة، ثم يستخدم البكسلات المولدة لتوليد البكسل التالي. يمر عبر عدة طبقات في الشبكة العصبية حتى تكتمل الصورة.\n",
    "\n",
    "من خلال هذه العملية، يتحكم DALL-E في السمات، والأشياء، والخصائص، والمزيد في الصورة التي يولدها. ومع ذلك، لدى DALL-E 2 و3 قدرة أكبر على التحكم في الصورة المولدة،\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## بناء أول تطبيق لتوليد الصور\n",
    "\n",
    "ما الذي تحتاجه لبناء تطبيق لتوليد الصور؟ ستحتاج إلى المكتبات التالية:\n",
    "\n",
    "- **python-dotenv**، يُنصح بشدة باستخدام هذه المكتبة للاحتفاظ بمعلوماتك السرية في ملف *.env* بعيدًا عن الكود.\n",
    "- **openai**، هذه هي المكتبة التي ستستخدمها للتفاعل مع واجهة برمجة تطبيقات OpenAI.\n",
    "- **pillow**، للعمل مع الصور في بايثون.\n",
    "- **requests**، لمساعدتك في إرسال طلبات HTTP.\n",
    "\n",
    "1. أنشئ ملفًا باسم *.env* يحتوي على التالي:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    يمكنك العثور على هذه المعلومات في بوابة Azure ضمن قسم \"المفاتيح ونقطة النهاية\" الخاص بموردك.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. اجمع المكتبات المذكورة أعلاه في ملف باسم *requirements.txt* كما يلي:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. بعد ذلك، أنشئ بيئة افتراضية وقم بتثبيت المكتبات:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> بالنسبة لنظام ويندوز، استخدم الأوامر التالية لإنشاء وتفعيل البيئة الافتراضية الخاصة بك:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. أضف الكود التالي في ملف باسم *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "لنشرح هذا الكود:\n",
    "\n",
    "- أولاً، نقوم باستيراد المكتبات التي نحتاجها، بما في ذلك مكتبة OpenAI، ومكتبة dotenv، ومكتبة requests، ومكتبة Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- بعد ذلك، نقوم بتحميل متغيرات البيئة من ملف *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- بعد ذلك، نحدد نقطة النهاية، والمفتاح الخاص بواجهة برمجة تطبيقات OpenAI، بالإضافة إلى الإصدار والنوع.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- بعد ذلك، نقوم بتوليد الصورة:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    الكود أعلاه يعيد كائن JSON يحتوي على رابط الصورة التي تم توليدها. يمكننا استخدام هذا الرابط لتحميل الصورة وحفظها في ملف.\n",
    "\n",
    "- وأخيراً، نقوم بفتح الصورة واستخدام عارض الصور الافتراضي لعرضها:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### تفاصيل أكثر حول توليد الصورة\n",
    "\n",
    "دعونا نلقي نظرة على الكود الذي يولد الصورة بمزيد من التفصيل:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**، هو النص الذي يُستخدم لتوليد الصورة. في هذا المثال، نستخدم النص \"أرنب على حصان، يحمل مصاصة، في مرج ضبابي تنمو فيه أزهار النرجس\".\n",
    "- **size**، هو حجم الصورة التي سيتم توليدها. في هذا المثال، نقوم بتوليد صورة بحجم 1024x1024 بكسل.\n",
    "- **n**، هو عدد الصور التي سيتم توليدها. في هذا المثال، نقوم بتوليد صورتين.\n",
    "- **temperature**، هو معامل يتحكم في عشوائية مخرجات نموذج الذكاء الاصطناعي التوليدي. القيمة تتراوح بين 0 و 1، حيث أن 0 تعني أن المخرجات حتمية و1 تعني أن المخرجات عشوائية. القيمة الافتراضية هي 0.7.\n",
    "\n",
    "هناك أشياء أخرى يمكنك القيام بها مع الصور وسنغطيها في القسم التالي.\n",
    "\n",
    "## إمكانيات إضافية لتوليد الصور\n",
    "\n",
    "لقد رأيت حتى الآن كيف تمكنا من توليد صورة باستخدام بضعة أسطر في بايثون. ومع ذلك، هناك أشياء أخرى يمكنك القيام بها مع الصور.\n",
    "\n",
    "يمكنك أيضاً القيام بما يلي:\n",
    "\n",
    "- **إجراء تعديلات**. من خلال تزويد صورة موجودة بقناع ونص توجيهي، يمكنك تعديل الصورة. على سبيل المثال، يمكنك إضافة شيء إلى جزء من الصورة. تخيل صورة الأرنب الخاصة بنا، يمكنك إضافة قبعة للأرنب. الطريقة لفعل ذلك هي بتوفير الصورة، وقناع (لتحديد الجزء الذي سيتم تغييره) ونص يوضح ما يجب فعله.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    الصورة الأساسية ستحتوي فقط على الأرنب، لكن الصورة النهائية ستحتوي على الأرنب مع القبعة.\n",
    "\n",
    "- **إنشاء تنويعات**.\n",
    "    اطلع على [دفتر OpenAI الخاص بنا لمزيد من المعلومات](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:07:30+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}