{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# تحسين نماذج Open AI\n",
    "\n",
    "هذا الدفتر مبني على الإرشادات الحالية الموجودة في [التخصيص الدقيق](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) من Open AI.\n",
    "\n",
    "تحسين النماذج (Fine-tuning) يعزز أداء النماذج الأساسية لتطبيقك عن طريق إعادة تدريبها ببيانات وسياق إضافي مرتبط بحالة الاستخدام أو السيناريو المحدد. لاحظ أن تقنيات هندسة المطالبات مثل _التعلم بعدة أمثلة_ و _توليد الاسترجاع المعزز_ تتيح لك تحسين الطلب الافتراضي ببيانات ذات صلة لتحسين الجودة. مع ذلك، هذه الأساليب محدودة بحجم نافذة الرموز القصوى للنموذج الأساسي المستهدف.\n",
    "\n",
    "مع التخصيص الدقيق، نحن فعلياً نعيد تدريب النموذج نفسه بالبيانات المطلوبة (مما يسمح لنا باستخدام عدد أكبر بكثير من الأمثلة مقارنة بما يمكن وضعه في نافذة الرموز القصوى) - وننشر نسخة _مخصصة_ من النموذج لم تعد بحاجة لتوفير أمثلة لها أثناء وقت الاستدلال. هذا لا يحسن فقط فعالية تصميم المطالبة لدينا (لدينا مرونة أكبر في استخدام نافذة الرموز لأشياء أخرى) بل قد يحسن أيضاً من تكاليفنا (عن طريق تقليل عدد الرموز التي نحتاج لإرسالها للنموذج أثناء وقت الاستدلال).\n",
    "\n",
    "التخصيص الدقيق يتكون من 4 خطوات:\n",
    "1. تجهيز بيانات التدريب ورفعها.\n",
    "1. تشغيل مهمة التدريب للحصول على نموذج مخصص.\n",
    "1. تقييم النموذج المخصص وتكرار العملية لتحسين الجودة.\n",
    "1. نشر النموذج المخصص للاستخدام عند الرضا عن النتائج.\n",
    "\n",
    "لاحظ أن ليس كل النماذج الأساسية تدعم التخصيص الدقيق - [راجع توثيق OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) لأحدث المعلومات. يمكنك أيضاً تخصيص نموذج سبق تخصيصه من قبل. في هذا الدرس، سنستخدم `gpt-35-turbo` كنموذج أساسي مستهدف للتخصيص الدقيق.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 1.1: جهّز مجموعة البيانات الخاصة بك\n",
    "\n",
    "لنقم ببناء روبوت دردشة يساعدك على فهم الجدول الدوري للعناصر من خلال الإجابة على الأسئلة حول أي عنصر باستخدام قصيدة ليمريك. في هذا الدرس البسيط، سننشئ فقط مجموعة بيانات لتدريب النموذج مع بعض الأمثلة التي توضح الشكل المتوقع للبيانات. في الاستخدام الواقعي، ستحتاج إلى إنشاء مجموعة بيانات تحتوي على أمثلة أكثر بكثير. قد تتمكن أيضًا من استخدام مجموعة بيانات مفتوحة (في مجال تطبيقك) إذا كانت متوفرة، وإعادة تنسيقها لتناسب عملية التخصيص الدقيق.\n",
    "\n",
    "بما أننا نركز على `gpt-35-turbo` ونبحث عن إجابة من دورة واحدة (إكمال دردشة)، يمكننا إنشاء أمثلة باستخدام [هذا التنسيق المقترح](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) الذي يعكس متطلبات إكمال الدردشة في OpenAI. إذا كنت تتوقع محتوى حواري متعدد الدورات، ستستخدم [تنسيق الأمثلة متعدد الدورات](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) والذي يتضمن معلمة `weight` لتحديد أي الرسائل يجب استخدامها (أو تجاهلها) أثناء عملية التخصيص الدقيق.\n",
    "\n",
    "سنستخدم هنا التنسيق الأبسط لدورة واحدة في هذا الدرس. البيانات ستكون بصيغة [jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) مع سجل واحد في كل سطر، وكل سجل عبارة عن كائن بتنسيق JSON. المقطع أدناه يعرض سجلين كمثال - راجع [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) لمجموعة الأمثلة الكاملة (10 أمثلة) التي سنستخدمها في درس التخصيص الدقيق. **ملاحظة:** يجب أن يكون كل سجل _مكتوبًا_ في سطر واحد فقط (وليس مقسمًا عبر عدة أسطر كما هو معتاد في ملفات JSON المنسقة).\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "في الاستخدام الواقعي ستحتاج إلى مجموعة أمثلة أكبر بكثير للحصول على نتائج جيدة - التوازن سيكون بين جودة الإجابات والوقت/التكلفة لعملية التخصيص الدقيق. نحن نستخدم مجموعة صغيرة حتى نتمكن من إكمال التخصيص بسرعة لشرح العملية. راجع [هذا المثال من OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) لدرس تخصيص دقيق أكثر تعقيدًا.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 1.2 رفع مجموعة البيانات الخاصة بك\n",
    "\n",
    "قم برفع البيانات باستخدام واجهة برمجة التطبيقات للملفات (Files API) [كما هو موضح هنا](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). لاحظ أنه لكي تتمكن من تشغيل هذا الكود، يجب أن تكون قد قمت بالخطوات التالية أولاً:\n",
    " - تثبيت حزمة بايثون `openai` (تأكد من استخدام إصدار >=0.28.0 للحصول على أحدث الميزات)\n",
    " - تعيين متغير البيئة `OPENAI_API_KEY` إلى مفتاح واجهة برمجة التطبيقات الخاص بك من OpenAI\n",
    "للمزيد من المعلومات، راجع [دليل الإعداد](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) المقدم للدورة.\n",
    "\n",
    "الآن، شغّل الكود لإنشاء ملف للرفع من ملف JSONL المحلي الخاص بك.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 2.1: إنشاء مهمة التخصيص باستخدام SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 2.2: التحقق من حالة المهمة\n",
    "\n",
    "إليك بعض الأمور التي يمكنك القيام بها باستخدام واجهة برمجة التطبيقات `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - عرض آخر n مهام ضبط دقيق\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - الحصول على تفاصيل مهمة ضبط دقيق محددة\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - إلغاء مهمة ضبط دقيق\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - عرض حتى n حدث من المهمة\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "أول خطوة في العملية هي _التحقق من ملف التدريب_ للتأكد من أن البيانات بصيغة صحيحة.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 2.3: تتبع الأحداث لمراقبة التقدم\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 2.4: عرض الحالة في لوحة تحكم OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "يمكنك أيضًا عرض الحالة من خلال زيارة موقع OpenAI واستكشاف قسم _التخصيص الدقيق_ في المنصة. سيعرض لك ذلك حالة المهمة الحالية، كما يمكنك تتبع سجل تنفيذ المهام السابقة. في هذه الصورة، يمكنك أن ترى أن التنفيذ السابق فشل، بينما نجح التشغيل الثاني. للتوضيح، حدث هذا عندما استخدم التشغيل الأول ملف JSON يحتوي على سجلات بتنسيق غير صحيح - وبعد تصحيح ذلك، اكتمل التشغيل الثاني بنجاح وأصبح النموذج متاحًا للاستخدام.\n",
    "\n",
    "![حالة مهمة التخصيص الدقيق](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.ar.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "يمكنك أيضًا عرض رسائل الحالة والقياسات من خلال التمرير للأسفل في لوحة المعلومات المرئية كما هو موضح:\n",
    "\n",
    "| الرسائل | القياسات |\n",
    "|:---|:---|\n",
    "| ![الرسائل](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.ar.png) |  ![القياسات](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.ar.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 3.1: استرجاع المعرف واختبار النموذج المحسن في الكود\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### الخطوة 3.2: تحميل واختبار النموذج المحسن في الـ Playground\n",
    "\n",
    "يمكنك الآن اختبار النموذج الذي قمت بتحسينه بطريقتين. أولاً، يمكنك زيارة الـ Playground واستخدام قائمة النماذج المنسدلة لاختيار النموذج المحسن الجديد من بين الخيارات المتاحة. الخيار الآخر هو استخدام خيار \"Playground\" الظاهر في لوحة التحسين (انظر الصورة أعلاه)، والذي يفتح لك عرضًا _مقارنًا_ يعرض نسختي النموذج الأساسي والمحسن جنبًا إلى جنب لتقييم سريع.\n",
    "\n",
    "![حالة مهمة التحسين](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.ar.png)\n",
    "\n",
    "كل ما عليك فعله هو إدخال سياق النظام المستخدم في بيانات التدريب الخاصة بك وكتابة سؤال الاختبار. ستلاحظ أن كلا الجانبين يتم تحديثهما بنفس السياق والسؤال. بعد تشغيل المقارنة، ستلاحظ الفرق في النتائج بينهما. _لاحظ كيف أن النموذج المحسن يعرض الإجابة بالتنسيق الذي قدمته في أمثلتك، بينما النموذج الأساسي يكتفي باتباع تعليمات النظام فقط_.\n",
    "\n",
    "![حالة مهمة التحسين](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.ar.png)\n",
    "\n",
    "ستلاحظ أيضًا أن المقارنة تعرض عدد الرموز (tokens) لكل نموذج، والوقت المستغرق للاستدلال. **هذا المثال بالتحديد هو مثال بسيط يهدف إلى توضيح العملية فقط، ولا يعكس بيانات أو سيناريو واقعي**. قد تلاحظ أن كلا النموذجين يظهران نفس عدد الرموز (لأن سياق النظام وسؤال المستخدم متطابقان)، مع أن النموذج المحسن يستغرق وقتًا أطول في الاستدلال (لأنه نموذج مخصص).\n",
    "\n",
    "في الحالات الواقعية، لن تستخدم مثالًا بسيطًا كهذا، بل ستقوم بتحسين النموذج باستخدام بيانات حقيقية (مثل كتالوج المنتجات لخدمة العملاء)، حيث ستكون جودة الإجابة أكثر وضوحًا. في _هذا_ السياق، الحصول على جودة إجابة مماثلة باستخدام النموذج الأساسي سيتطلب هندسة موجهات مخصصة أكثر، مما سيزيد من استهلاك الرموز وربما الوقت اللازم للاستدلال. _لتجربة ذلك، اطلع على أمثلة التحسين في OpenAI Cookbook للبدء._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:31:01+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}