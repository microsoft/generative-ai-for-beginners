{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## المقدمة\n",
    "\n",
    "ستغطي هذه الدرس:\n",
    "- ما هو استدعاء الدالة وحالات استخدامه\n",
    "- كيفية إنشاء استدعاء دالة باستخدام OpenAI\n",
    "- كيفية دمج استدعاء دالة في تطبيق\n",
    "\n",
    "## أهداف التعلم\n",
    "\n",
    "بعد إكمال هذا الدرس ستعرف كيفية وتفهم:\n",
    "\n",
    "- الغرض من استخدام استدعاء الدالة\n",
    "- إعداد استدعاء دالة باستخدام خدمة OpenAI\n",
    "- تصميم استدعاءات دالة فعالة لحالة استخدام تطبيقك\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## فهم استدعاءات الدوال\n",
    "\n",
    "لهذا الدرس، نريد بناء ميزة لشركتنا الناشئة في مجال التعليم تتيح للمستخدمين استخدام روبوت دردشة للعثور على الدورات التقنية. سنوصي بدورات تناسب مستوى مهاراتهم، والدور الحالي، والتكنولوجيا التي يهتمون بها.\n",
    "\n",
    "لإكمال ذلك، سنستخدم مزيجًا من:\n",
    " - `OpenAI` لإنشاء تجربة دردشة للمستخدم\n",
    " - `Microsoft Learn Catalog API` لمساعدة المستخدمين في العثور على الدورات بناءً على طلب المستخدم\n",
    " - `Function Calling` لأخذ استعلام المستخدم وإرساله إلى دالة لإجراء طلب API.\n",
    "\n",
    "للبدء، دعونا ننظر لماذا نرغب في استخدام استدعاء الدوال في المقام الأول:\n",
    "\n",
    "print(\"الرسائل في الطلب التالي:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # الحصول على رد جديد من GPT حيث يمكنه رؤية استجابة الدالة\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### لماذا استدعاء الدوال\n",
    "\n",
    "إذا كنت قد أكملت أي درس آخر في هذه الدورة، فمن المحتمل أنك تفهم قوة استخدام نماذج اللغة الكبيرة (LLMs). ونأمل أن تكون قادرًا أيضًا على رؤية بعض محدودياتها.\n",
    "\n",
    "استدعاء الدوال هو ميزة في خدمة OpenAI مصممة لمعالجة التحديات التالية:\n",
    "\n",
    "تنسيق الاستجابة غير المتسق:\n",
    "- قبل استدعاء الدوال، كانت الاستجابات من نموذج اللغة الكبير غير منظمة وغير متسقة. كان على المطورين كتابة كود تحقق معقد للتعامل مع كل اختلاف في المخرجات.\n",
    "\n",
    "التكامل المحدود مع البيانات الخارجية:\n",
    "- قبل هذه الميزة، كان من الصعب دمج البيانات من أجزاء أخرى من التطبيق في سياق المحادثة.\n",
    "\n",
    "من خلال توحيد تنسيقات الاستجابة وتمكين التكامل السلس مع البيانات الخارجية، يبسط استدعاء الدوال عملية التطوير ويقلل الحاجة إلى منطق تحقق إضافي.\n",
    "\n",
    "لم يكن بإمكان المستخدمين الحصول على إجابات مثل \"ما هو الطقس الحالي في ستوكهولم؟\". وذلك لأن النماذج كانت محدودة بالوقت الذي تم تدريب البيانات عليه.\n",
    "\n",
    "لننظر إلى المثال أدناه الذي يوضح هذه المشكلة:\n",
    "\n",
    "لنفترض أننا نريد إنشاء قاعدة بيانات لبيانات الطلاب حتى نتمكن من اقتراح الدورة المناسبة لهم. أدناه لدينا وصفان لطلاب متشابهين جدًا في البيانات التي يحتويان عليها.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نريد إرسال هذا إلى نموذج لغة كبير لتحليل البيانات. يمكن استخدام هذا لاحقًا في تطبيقنا لإرسالها إلى واجهة برمجة تطبيقات أو تخزينها في قاعدة بيانات.\n",
    "\n",
    "لننشئ طلبين متطابقين نوجه من خلالهما نموذج اللغة الكبير حول المعلومات التي نهتم بها:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نريد إرسال هذا إلى نموذج اللغة الكبير لتحليل الأجزاء المهمة لمنتجنا. لذلك يمكننا إنشاء طلبين متطابقين لتوجيه نموذج اللغة الكبير:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد إنشاء هذين الطلبين، سنرسلهما إلى نموذج اللغة الكبير باستخدام `openai.ChatCompletion`. نقوم بتخزين الطلب في متغير `messages` ونعين الدور إلى `user`. هذا لمحاكاة رسالة من مستخدم تُكتب إلى روبوت المحادثة.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن يمكننا إرسال كلا الطلبين إلى نموذج اللغة الكبير وفحص الاستجابة التي نتلقاها.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "على الرغم من أن المطالبات متشابهة والوصف متقارب، يمكننا الحصول على تنسيقات مختلفة لخاصية `Grades`.\n",
    "\n",
    "إذا قمت بتشغيل الخلية أعلاه عدة مرات، قد يكون التنسيق `3.7` أو `3.7 GPA`.\n",
    "\n",
    "هذا لأن نموذج اللغة الكبير يأخذ بيانات غير منظمة في شكل المطالبة المكتوبة ويعيد أيضًا بيانات غير منظمة. نحتاج إلى وجود تنسيق منظم حتى نعرف ما الذي نتوقعه عند تخزين هذه البيانات أو استخدامها.\n",
    "\n",
    "باستخدام استدعاء الدوال، يمكننا التأكد من أننا نتلقى بيانات منظمة في الردود. عند استخدام استدعاء الدوال، لا يقوم نموذج اللغة الكبير فعليًا باستدعاء أو تشغيل أي دوال. بدلاً من ذلك، ننشئ هيكلًا ليتبعه نموذج اللغة الكبير في ردوده. ثم نستخدم تلك الردود المنظمة لمعرفة الدالة التي يجب تشغيلها في تطبيقاتنا.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![مخطط تدفق استدعاء الدالة](../../../../translated_images/ar/Function-Flow.083875364af4f4bb.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "يمكننا بعد ذلك أخذ ما يتم إرجاعه من الدالة وإرساله مرة أخرى إلى نموذج اللغة الكبير. ثم سيستجيب نموذج اللغة الكبير باستخدام اللغة الطبيعية للإجابة على استفسار المستخدم.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### حالات استخدام استدعاء الدوال\n",
    "\n",
    "**استدعاء الأدوات الخارجية**  \n",
    "تُعد روبوتات الدردشة ممتازة في تقديم إجابات على أسئلة المستخدمين. من خلال استخدام استدعاء الدوال، يمكن لروبوتات الدردشة استخدام رسائل المستخدمين لإكمال مهام معينة. على سبيل المثال، يمكن لطالب أن يطلب من روبوت الدردشة \"إرسال بريد إلكتروني إلى مدرسي يقول إنني أحتاج إلى مزيد من المساعدة في هذا الموضوع\". يمكن أن يقوم هذا باستدعاء دالة `send_email(to: string, body: string)`\n",
    "\n",
    "**إنشاء استعلامات API أو قواعد بيانات**  \n",
    "يمكن للمستخدمين العثور على المعلومات باستخدام اللغة الطبيعية التي تتحول إلى استعلام منسق أو طلب API. مثال على ذلك يمكن أن يكون مدرس يطلب \"من هم الطلاب الذين أكملوا الواجب الأخير\" والذي يمكن أن يستدعي دالة باسم `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**إنشاء بيانات منظمة**  \n",
    "يمكن للمستخدمين أخذ كتلة نصية أو CSV واستخدام نموذج اللغة الكبير لاستخراج المعلومات المهمة منها. على سبيل المثال، يمكن لطالب تحويل مقال من ويكيبيديا عن اتفاقيات السلام لإنشاء بطاقات تعليمية ذكية. يمكن القيام بذلك باستخدام دالة تسمى `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. إنشاء أول استدعاء دالة لك\n",
    "\n",
    "تتضمن عملية إنشاء استدعاء دالة 3 خطوات رئيسية:\n",
    "1. استدعاء واجهة برمجة تطبيقات إكمال الدردشة مع قائمة دوالك ورسالة المستخدم\n",
    "2. قراءة استجابة النموذج لأداء إجراء مثل تنفيذ دالة أو استدعاء واجهة برمجة تطبيقات\n",
    "3. إجراء استدعاء آخر لواجهة برمجة تطبيقات إكمال الدردشة مع الاستجابة من دالتك لاستخدام تلك المعلومات لإنشاء رد للمستخدم.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![تدفق استدعاء دالة](../../../../translated_images/ar/LLM-Flow.3285ed8caf4796d7.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### عناصر استدعاء الدالة\n",
    "\n",
    "#### إدخال المستخدم\n",
    "\n",
    "الخطوة الأولى هي إنشاء رسالة للمستخدم. يمكن تعيين هذه القيمة ديناميكيًا عن طريق أخذ قيمة من إدخال نصي أو يمكنك تعيين قيمة هنا. إذا كانت هذه هي المرة الأولى التي تعمل فيها مع واجهة برمجة تطبيقات إكمال الدردشة، نحتاج إلى تحديد `role` و `content` للرسالة.\n",
    "\n",
    "يمكن أن يكون `role` إما `system` (إنشاء القواعد)، أو `assistant` (النموذج) أو `user` (المستخدم النهائي). لاستدعاء الدالة، سنعين هذا كـ `user` وسؤال مثال.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### إنشاء الدوال.\n",
    "\n",
    "بعد ذلك سنقوم بتعريف دالة ومعاملات تلك الدالة. سنستخدم دالة واحدة فقط هنا تسمى `search_courses` ولكن يمكنك إنشاء دوال متعددة.\n",
    "\n",
    "**مهم**: يتم تضمين الدوال في رسالة النظام إلى نموذج اللغة الكبير وسيتم احتسابها ضمن عدد الرموز المتاحة لديك.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**التعريفات**\n",
    "\n",
    "هيكل تعريف الدالة يحتوي على مستويات متعددة، كل منها له خصائصه الخاصة. إليك تفصيل الهيكل المتداخل:\n",
    "\n",
    "**خصائص الدالة على المستوى الأعلى:**\n",
    "\n",
    "`name` - اسم الدالة التي نريد استدعاؤها.\n",
    "\n",
    "`description` - هذا هو وصف كيفية عمل الدالة. هنا من المهم أن تكون محددًا وواضحًا.\n",
    "\n",
    "`parameters` - قائمة بالقيم والصيغة التي تريد من النموذج إنتاجها في استجابته.\n",
    "\n",
    "**خصائص كائن المعلمات:**\n",
    "\n",
    "`type` - نوع بيانات كائن المعلمات (عادةً \"object\").\n",
    "\n",
    "`properties` - قائمة بالقيم المحددة التي سيستخدمها النموذج في استجابته.\n",
    "\n",
    "**خصائص المعلمة الفردية:**\n",
    "\n",
    "`name` - معرف ضمنيًا بواسطة مفتاح الخاصية (مثل \"role\"، \"product\"، \"level\").\n",
    "\n",
    "`type` - نوع بيانات هذه المعلمة المحددة (مثل \"string\"، \"number\"، \"boolean\").\n",
    "\n",
    "`description` - وصف المعلمة المحددة.\n",
    "\n",
    "**الخصائص الاختيارية:**\n",
    "\n",
    "`required` - مصفوفة تسرد المعلمات المطلوبة لإكمال استدعاء الدالة.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### إجراء استدعاء الدالة  \n",
    "بعد تعريف دالة، نحتاج الآن إلى تضمينها في استدعاء واجهة برمجة تطبيقات إكمال الدردشة. نقوم بذلك عن طريق إضافة `functions` إلى الطلب. في هذه الحالة `functions=functions`.  \n",
    "\n",
    "هناك أيضًا خيار لتعيين `function_call` إلى `auto`. هذا يعني أننا سنترك نموذج اللغة الكبير يقرر أي دالة يجب استدعاؤها بناءً على رسالة المستخدم بدلاً من تعيينها بأنفسنا.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن دعونا نلقي نظرة على الاستجابة ونرى كيف تم تنسيقها:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "يمكنك أن ترى أن اسم الدالة تم استدعاؤه ومن رسالة المستخدم، تمكن نموذج اللغة الكبير من العثور على البيانات لتناسب معطيات الدالة.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. دمج استدعاءات الدوال في تطبيق.\n",
    "\n",
    "بعد أن قمنا باختبار الاستجابة المنسقة من نموذج اللغة الكبير، يمكننا الآن دمج هذا في تطبيق.\n",
    "\n",
    "### إدارة التدفق\n",
    "\n",
    "لدمج هذا في تطبيقنا، دعونا نتبع الخطوات التالية:\n",
    "\n",
    "أولاً، دعونا نقوم بالاتصال بخدمات OpenAI وتخزين الرسالة في متغير يسمى `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن سنقوم بتعريف الدالة التي ستستدعي واجهة برمجة تطبيقات Microsoft Learn للحصول على قائمة الدورات:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "كممارسة مثلى، سنرى بعد ذلك ما إذا كان النموذج يرغب في استدعاء دالة. بعد ذلك، سننشئ واحدة من الدوال المتاحة ونتطابق معها الدالة التي يتم استدعاؤها.  \n",
    "ثم سنأخذ معاملات الدالة ونربطها بالمعاملات من LLM.\n",
    "\n",
    "أخيرًا، سنضيف رسالة استدعاء الدالة والقيم التي تم إرجاعها بواسطة رسالة `search_courses`. هذا يمنح LLM كل المعلومات التي يحتاجها للرد على المستخدم باستخدام اللغة الطبيعية.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن سنرسل الرسالة المحدثة إلى نموذج اللغة الكبير (LLM) حتى نتمكن من تلقي رد بلغة طبيعية بدلاً من رد منسق بصيغة JSON الخاصة بواجهة برمجة التطبيقات.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تحدي الكود\n",
    "\n",
    "عمل رائع! لمواصلة تعلمك لاستدعاء دوال OpenAI يمكنك بناء: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - المزيد من معلمات الدالة التي قد تساعد المتعلمين في العثور على المزيد من الدورات. يمكنك العثور على معلمات API المتاحة هنا:  \n",
    " - إنشاء استدعاء دالة آخر يأخذ المزيد من المعلومات من المتعلم مثل لغته الأم  \n",
    " - إنشاء معالجة للأخطاء عندما لا يعيد استدعاء الدالة و/أو استدعاء API أي دورات مناسبة\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة الآلية [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية المصدر الموثوق به. للمعلومات الهامة، يُنصح بالترجمة البشرية المهنية. نحن غير مسؤولين عن أي سوء فهم أو تفسير ناتج عن استخدام هذه الترجمة.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T08:54:33+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}