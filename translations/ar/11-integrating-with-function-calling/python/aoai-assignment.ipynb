{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## المقدمة\n",
    "\n",
    "ستتناول هذه الدرس:\n",
    "- ما هو استدعاء الدوال وحالات استخدامه\n",
    "- كيفية إنشاء استدعاء دالة باستخدام Azure OpenAI\n",
    "- كيفية دمج استدعاء دالة في تطبيق\n",
    "\n",
    "## أهداف التعلم\n",
    "\n",
    "بعد الانتهاء من هذا الدرس ستعرف وتفهم:\n",
    "\n",
    "- الهدف من استخدام استدعاء الدوال\n",
    "- إعداد استدعاء دالة باستخدام خدمة Azure OpenAI\n",
    "- تصميم استدعاءات دوال فعّالة لحالة استخدام تطبيقك\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## فهم استدعاء الدوال\n",
    "\n",
    "في هذا الدرس، نرغب في بناء ميزة لشركتنا الناشئة في مجال التعليم تتيح للمستخدمين استخدام روبوت دردشة للعثور على الدورات التقنية. سنوصي بالدورات التي تناسب مستوى مهاراتهم، ودورهم الحالي، والتقنية التي يهتمون بها.\n",
    "\n",
    "لإكمال ذلك، سنستخدم مزيجاً من:\n",
    " - `Azure Open AI` لإنشاء تجربة دردشة للمستخدم\n",
    " - `Microsoft Learn Catalog API` لمساعدة المستخدمين في العثور على الدورات بناءً على طلبهم\n",
    " - `Function Calling` لأخذ استفسار المستخدم وإرساله إلى دالة لإجراء طلب API.\n",
    "\n",
    "للبدء، دعونا نلقي نظرة على سبب رغبتنا في استخدام استدعاء الدوال من الأساس:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # الحصول على رد جديد من GPT حيث يمكنه رؤية استجابة الدالة\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### لماذا استخدام استدعاء الدوال\n",
    "\n",
    "إذا كنت قد أنهيت أي درس آخر في هذه الدورة، فمن المحتمل أنك تدرك قوة استخدام نماذج اللغة الكبيرة (LLMs). ونأمل أيضًا أنك لاحظت بعض القيود لديها.\n",
    "\n",
    "استدعاء الدوال هو ميزة في خدمة Azure Open AI تهدف إلى التغلب على القيود التالية:\n",
    "1) تنسيق استجابة ثابت\n",
    "2) القدرة على استخدام بيانات من مصادر أخرى في التطبيق ضمن سياق المحادثة\n",
    "\n",
    "قبل وجود استدعاء الدوال، كانت الردود من نماذج اللغة الكبيرة غير منظمة وغير متسقة. كان على المطورين كتابة شيفرة تحقق معقدة للتأكد من قدرتهم على التعامل مع كل اختلاف في الردود.\n",
    "\n",
    "لم يكن بإمكان المستخدمين الحصول على إجابات مثل \"ما هو الطقس الحالي في ستوكهولم؟\". وذلك لأن النماذج كانت محدودة بالبيانات التي تم تدريبها عليها فقط.\n",
    "\n",
    "لنلقِ نظرة على المثال أدناه الذي يوضح هذه المشكلة:\n",
    "\n",
    "لنفترض أننا نريد إنشاء قاعدة بيانات لمعلومات الطلاب حتى نتمكن من اقتراح الدورة المناسبة لهم. في الأسفل لدينا وصفان لطالبين يحتويان على بيانات متشابهة جدًا.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نريد إرسال هذا إلى نموذج لغوي كبير لتحليل البيانات. يمكن استخدام ذلك لاحقًا في تطبيقنا لإرساله إلى واجهة برمجة التطبيقات أو تخزينه في قاعدة بيانات.\n",
    "\n",
    "لنقم بإنشاء مطالبتين متطابقتين نوجه فيهما النموذج اللغوي حول المعلومات التي نهتم بها:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "نريد إرسال هذا إلى نموذج لغوي كبير لتحليل الأجزاء المهمة لمنتجنا. حتى نتمكن من إنشاء مطالبتين متطابقتين لإعطاء التعليمات للنموذج اللغوي الكبير:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بعد إنشاء هذين الطلبين، سنرسلهم إلى نموذج اللغة الكبير باستخدام `openai.ChatCompletion`. نقوم بتخزين الطلب في متغير `messages` ونعين الدور إلى `user`. هذا لمحاكاة رسالة من مستخدم يتم كتابتها إلى روبوت الدردشة.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن يمكننا إرسال كلا الطلبين إلى نموذج اللغة الكبير وفحص الاستجابة التي نتلقاها.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "على الرغم من أن التعليمات متشابهة والوصف متقارب، إلا أنه يمكننا الحصول على صيغ مختلفة لخاصية `Grades`.\n",
    "\n",
    "إذا قمت بتشغيل الخلية أعلاه عدة مرات، قد يكون الشكل إما `3.7` أو `3.7 GPA`.\n",
    "\n",
    "يحدث هذا لأن نموذج اللغة الكبير يتعامل مع بيانات غير منظمة على شكل تعليمات مكتوبة ويعيد أيضاً بيانات غير منظمة. نحن بحاجة إلى تنسيق منظم حتى نعرف ما الذي نتوقعه عند تخزين أو استخدام هذه البيانات.\n",
    "\n",
    "من خلال استخدام استدعاء الدوال، يمكننا التأكد من أننا نستلم بيانات منظمة. عند استخدام استدعاء الدوال، النموذج لا يقوم فعلياً باستدعاء أو تشغيل أي دوال. بدلاً من ذلك، نقوم بإنشاء هيكل للنموذج ليتبعه في ردوده. بعد ذلك نستخدم هذه الردود المنظمة لمعرفة أي دالة يجب تشغيلها في تطبيقاتنا.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![مخطط تدفق استدعاء الدالة](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ar.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### حالات استخدام استدعاء الدوال\n",
    "\n",
    "**استدعاء الأدوات الخارجية**  \n",
    "تُعتبر الدردشات الذكية ممتازة في تقديم الإجابات على أسئلة المستخدمين. من خلال استخدام استدعاء الدوال، يمكن للدردشة الذكية استخدام رسائل المستخدمين لتنفيذ مهام معينة. على سبيل المثال، يمكن لطالب أن يطلب من الدردشة الذكية \"إرسال بريد إلكتروني إلى معلمي وأخبره أنني بحاجة إلى مزيد من المساعدة في هذا الموضوع\". في هذه الحالة، يمكن استدعاء دالة مثل `send_email(to: string, body: string)`\n",
    "\n",
    "**إنشاء استعلامات API أو قواعد بيانات**  \n",
    "يمكن للمستخدمين البحث عن معلومات باستخدام اللغة الطبيعية التي يتم تحويلها إلى استعلام منسق أو طلب API. مثال على ذلك، معلم يطلب \"من هم الطلاب الذين أكملوا الواجب الأخير\"، ويمكن هنا استدعاء دالة باسم `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**إنشاء بيانات منظمة**  \n",
    "يمكن للمستخدمين أخذ نص أو ملف CSV واستخدام نموذج اللغة الكبير لاستخلاص المعلومات المهمة منه. على سبيل المثال، يمكن لطالب تحويل مقالة من ويكيبيديا عن اتفاقيات السلام إلى بطاقات مراجعة ذكية بالذكاء الاصطناعي. يمكن تنفيذ ذلك باستخدام دالة مثل `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ٢. إنشاء أول استدعاء دالة لك\n",
    "\n",
    "عملية إنشاء استدعاء دالة تتضمن ثلاث خطوات رئيسية:\n",
    "١. استدعاء واجهة برمجة التطبيقات لإكمال المحادثة مع قائمة الدوال الخاصة بك ورسالة المستخدم\n",
    "٢. قراءة رد النموذج لتنفيذ إجراء مثل تنفيذ دالة أو استدعاء واجهة برمجة تطبيقات\n",
    "٣. إجراء استدعاء آخر لواجهة برمجة التطبيقات لإكمال المحادثة مع الرد القادم من دالتك لاستخدام تلك المعلومات في إنشاء رد للمستخدم.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![تدفق استدعاء الدالة](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ar.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### عناصر استدعاء الدالة\n",
    "\n",
    "#### إدخال المستخدم\n",
    "\n",
    "الخطوة الأولى هي إنشاء رسالة من المستخدم. يمكن تعيين هذه الرسالة ديناميكياً من خلال أخذ قيمة من حقل إدخال نصي أو يمكنك تعيين قيمة هنا مباشرة. إذا كانت هذه هي المرة الأولى التي تتعامل فيها مع واجهة برمجة تطبيقات إكمال المحادثة، نحتاج إلى تحديد `role` و`content` للرسالة.\n",
    "\n",
    "يمكن أن تكون قيمة `role` إما `system` (لإنشاء القواعد)، أو `assistant` (النموذج)، أو `user` (المستخدم النهائي). في حالة استدعاء الدوال، سنحددها كـ `user` مع مثال على سؤال.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### إنشاء الدوال.\n",
    "\n",
    "الآن سنقوم بتعريف دالة ومعاملات هذه الدالة. سنستخدم هنا دالة واحدة فقط باسم `search_courses`، لكن يمكنك إنشاء عدة دوال.\n",
    "\n",
    "**مهم** : يتم تضمين الدوال في رسالة النظام إلى نموذج اللغة الكبير، وسيتم احتسابها ضمن عدد الرموز المتاحة لديك.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**تعريفات**\n",
    "\n",
    "`name` - اسم الدالة التي نريد استدعاءها.\n",
    "\n",
    "`description` - هذا هو الوصف لكيفية عمل الدالة. من المهم هنا أن يكون الوصف محددًا وواضحًا.\n",
    "\n",
    "`parameters` - قائمة بالقيم والصيغة التي تريد من النموذج أن ينتجها في رده.\n",
    "\n",
    "`type` - نوع البيانات التي سيتم تخزين الخصائص فيها.\n",
    "\n",
    "`properties` - قائمة بالقيم المحددة التي سيستخدمها النموذج في رده.\n",
    "\n",
    "`name` - اسم الخاصية التي سيستخدمها النموذج في رده المنسق.\n",
    "\n",
    "`type` - نوع البيانات لهذه الخاصية.\n",
    "\n",
    "`description` - وصف الخاصية المحددة.\n",
    "\n",
    "**اختياري**\n",
    "\n",
    "`required` - خاصية مطلوبة لإتمام استدعاء الدالة.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### إجراء استدعاء الدالة\n",
    "بعد تعريف الدالة، نحتاج الآن إلى تضمينها في الاستدعاء إلى واجهة برمجة تطبيقات إكمال الدردشة. نقوم بذلك عن طريق إضافة `functions` إلى الطلب. في هذه الحالة نكتب `functions=functions`.\n",
    "\n",
    "هناك أيضًا خيار لتعيين `function_call` إلى `auto`. هذا يعني أننا سنسمح لنموذج اللغة الكبير بتحديد أي دالة يجب استدعاؤها بناءً على رسالة المستخدم بدلاً من تعيينها بأنفسنا.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن دعونا نلقي نظرة على الاستجابة ونرى كيف تم تنسيقها:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "يمكنك أن ترى أن اسم الدالة تم استدعاؤه ومن خلال رسالة المستخدم، تمكن نموذج الذكاء الاصطناعي من إيجاد البيانات المناسبة لتعبئة معطيات الدالة.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. دمج استدعاءات الدوال في التطبيق\n",
    "\n",
    "بعد أن قمنا باختبار الاستجابة المنسقة من LLM، يمكننا الآن دمجها في التطبيق.\n",
    "\n",
    "### إدارة سير العمل\n",
    "\n",
    "لدمج هذا في تطبيقنا، دعونا نتبع الخطوات التالية:\n",
    "\n",
    "أولاً، سنقوم باستدعاء خدمات Open AI وتخزين الرسالة في متغير باسم `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "الآن سنعرّف الدالة التي ستستدعي واجهة برمجة تطبيقات Microsoft Learn للحصول على قائمة الدورات:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "كأفضل ممارسة، سنرى بعد ذلك ما إذا كان النموذج يرغب في استدعاء دالة. بعد ذلك، سنقوم بإنشاء واحدة من الدوال المتاحة ونطابقها مع الدالة التي تم استدعاؤها.\n",
    "بعدها سنأخذ معاملات الدالة ونربطها بالمعاملات القادمة من نموذج اللغة الكبير.\n",
    "\n",
    "وأخيرًا، سنضيف رسالة استدعاء الدالة والقيم التي تم إرجاعها بواسطة رسالة `search_courses`. هذا يمنح نموذج اللغة الكبير كل المعلومات التي يحتاجها\n",
    "للرد على المستخدم باستخدام لغة طبيعية.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تحدي البرمجة\n",
    "\n",
    "عمل رائع! لمواصلة تعلمك حول استدعاء الدوال في Azure Open AI يمكنك بناء: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - إضافة المزيد من معلمات الدالة التي قد تساعد المتعلمين في العثور على المزيد من الدورات. يمكنك العثور على معلمات الـ API المتاحة هنا:\n",
    " - إنشاء استدعاء دالة آخر يأخذ معلومات إضافية من المتعلم مثل لغته الأم\n",
    " - إنشاء معالجة للأخطاء عندما لا يُرجع استدعاء الدالة و/أو استدعاء الـ API أي دورات مناسبة\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**إخلاء المسؤولية**:  \nتمت ترجمة هذا المستند باستخدام خدمة الترجمة بالذكاء الاصطناعي [Co-op Translator](https://github.com/Azure/co-op-translator). بينما نسعى لتحقيق الدقة، يرجى العلم أن الترجمات الآلية قد تحتوي على أخطاء أو عدم دقة. يجب اعتبار المستند الأصلي بلغته الأصلية هو المصدر الموثوق. للمعلومات الهامة، يُنصح بالاستعانة بترجمة بشرية احترافية. نحن غير مسؤولين عن أي سوء فهم أو تفسير خاطئ ينشأ عن استخدام هذه الترجمة.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T19:55:28+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "ar"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}