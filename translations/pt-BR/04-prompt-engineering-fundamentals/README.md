# Fundamentos da Engenharia de Prompt

[![Fundamentos da Engenharia de Prompt](../../../translated_images/pt-BR/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introdu√ß√£o
Este m√≥dulo aborda conceitos e t√©cnicas essenciais para criar prompts eficazes em modelos generativos de IA. A forma como voc√™ escreve seu prompt para um LLM tamb√©m importa. Um prompt cuidadosamente elaborado pode alcan√ßar uma resposta de melhor qualidade. Mas o que exatamente significam termos como _prompt_ e _engenharia de prompt_? E como posso melhorar o _input_ do prompt que envio ao LLM? Essas s√£o as perguntas que tentaremos responder neste cap√≠tulo e no pr√≥ximo.

_A IA generativa_ √© capaz de criar conte√∫do novo (por exemplo, texto, imagens, √°udio, c√≥digo etc.) em resposta a solicita√ß√µes do usu√°rio. Ela realiza isso usando _Grandes Modelos de Linguagem_ como a s√©rie GPT da OpenAI ("Transformador Generativo Pr√©-treinado") que s√£o treinados para usar linguagem natural e c√≥digo.

Os usu√°rios agora podem interagir com esses modelos usando paradigmas familiares como chat, sem necessidade de conhecimento t√©cnico ou treinamento. Os modelos s√£o _baseados em prompt_ - os usu√°rios enviam um texto de entrada (prompt) e recebem a resposta da IA (completa√ß√£o). Eles podem ent√£o "conversar com a IA" de forma iterativa, em conversas de m√∫ltiplas etapas, refinando seu prompt at√© que a resposta atenda √†s suas expectativas.

"Prompts" tornam-se a principal _interface de programa√ß√£o_ para aplicativos de IA generativa, dizendo aos modelos o que fazer e influenciando a qualidade das respostas retornadas. A "Engenharia de Prompt" √© uma √°rea de estudo em r√°pido crescimento que se concentra no _projeto e otimiza√ß√£o_ de prompts para fornecer respostas consistentes e de qualidade em escala.

## Objetivos de Aprendizagem

Nesta li√ß√£o, aprendemos o que √© Engenharia de Prompt, por que ela √© importante e como podemos criar prompts mais eficazes para um dado modelo e objetivo de aplica√ß√£o. Vamos entender conceitos centrais e melhores pr√°ticas para engenharia de prompt - e conhecer um ambiente interativo de Jupyter Notebooks "sandbox" onde podemos ver esses conceitos aplicados a exemplos reais.

Ao final desta li√ß√£o, seremos capazes de:

1. Explicar o que √© engenharia de prompt e por que ela importa.
2. Descrever os componentes de um prompt e como eles s√£o usados.
3. Aprender melhores pr√°ticas e t√©cnicas para engenharia de prompt.
4. Aplicar as t√©cnicas aprendidas a exemplos reais, usando um endpoint OpenAI.

## Termos-Chave

Engenharia de Prompt: A pr√°tica de projetar e refinar entradas para guiar modelos de IA a produzirem sa√≠das desejadas.  
Tokeniza√ß√£o: O processo de converter texto em unidades menores, chamadas tokens, que um modelo pode entender e processar.  
LLMs Ajustados por Instru√ß√µes: Grandes Modelos de Linguagem (LLMs) que foram finamente ajustados com instru√ß√µes espec√≠ficas para melhorar a precis√£o e relev√¢ncia das suas respostas.

## Sandbox de Aprendizado

Engenharia de prompt √© atualmente mais arte do que ci√™ncia. A melhor maneira de melhorar nossa intui√ß√£o para ela √© _praticando mais_ e adotando uma abordagem de tentativa e erro que combina expertise no dom√≠nio da aplica√ß√£o com t√©cnicas recomendadas e otimiza√ß√µes espec√≠ficas de modelos.

O Jupyter Notebook que acompanha esta li√ß√£o oferece um ambiente _sandbox_ onde voc√™ pode experimentar o que aprende ‚Äî conforme avan√ßa ou como parte do desafio de c√≥digo no final. Para executar os exerc√≠cios, voc√™ precisar√° de:

1. **Uma chave de API do Azure OpenAI** - o endpoint do servi√ßo para um LLM implantado.  
2. **Um Runtime Python** - no qual o Notebook possa ser executado.  
3. **Vari√°veis de Ambiente Locais** - _complete as etapas do [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) agora para ficar pronto_.

O notebook vem com exerc√≠cios _iniciais_ - mas voc√™ √© incentivado a adicionar suas pr√≥prias se√ß√µes de _Markdown_ (descri√ß√£o) e _C√≥digo_ (solicita√ß√µes de prompt) para experimentar mais exemplos ou ideias - e construir sua intui√ß√£o para design de prompts.

## Guia Ilustrado

Quer ter uma vis√£o geral do que esta li√ß√£o cobre antes de come√ßar? Veja este guia ilustrado, que oferece uma ideia dos principais t√≥picos abordados e dos principais aprendizados para voc√™ refletir em cada um. O roteiro da li√ß√£o leva voc√™ desde a compreens√£o dos conceitos centrais e desafios at√© a abordagem deles com t√©cnicas e melhores pr√°ticas relevantes de engenharia de prompt. Observe que a se√ß√£o "T√©cnicas Avan√ßadas" deste guia se refere ao conte√∫do abordado no _pr√≥ximo_ cap√≠tulo deste curr√≠culo.

![Guia Ilustrado de Engenharia de Prompt](../../../translated_images/pt-BR/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## Nossa Startup

Agora, vamos falar sobre como _este tema_ se relaciona com a miss√£o da nossa startup de [trazer inova√ß√£o em IA para a educa√ß√£o](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplica√ß√µes de IA para _aprendizado personalizado_ - ent√£o vamos pensar em como diferentes usu√°rios do nosso aplicativo podem "desenhar" prompts:

- **Administradores** podem pedir para a IA _analisar dados curriculares para identificar lacunas na cobertura_. A IA pode resumir resultados ou visualiz√°-los com c√≥digo.
- **Educadores** podem pedir para a IA _gerar um plano de aula para um p√∫blico-alvo e tema espec√≠fico_. A IA pode construir o plano personalizado em um formato especificado.
- **Estudantes** podem pedir para a IA _tutorar em uma disciplina dif√≠cil_. A IA pode agora guiar os alunos com aulas, dicas e exemplos adequados ao seu n√≠vel.

Isso √© s√≥ a ponta do iceberg. Confira [Prompts Para Educa√ß√£o](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - uma biblioteca open source de prompts organizada por especialistas em educa√ß√£o - para ter uma no√ß√£o mais ampla das possibilidades! _Experimente executar alguns desses prompts no sandbox ou usando o OpenAI Playground para ver o que acontece!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## O que √© Engenharia de Prompt?

Come√ßamos esta li√ß√£o definindo **Engenharia de Prompt** como o processo de _projetar e otimizar_ entradas de texto (prompts) para entregar respostas (completa√ß√µes) consistentes e de qualidade para um dado objetivo de aplica√ß√£o e modelo. Podemos pensar nisso como um processo de 2 etapas:

- _projetar_ o prompt inicial para um dado modelo e objetivo  
- _refinar_ o prompt iterativamente para melhorar a qualidade da resposta

Este √© necessariamente um processo de tentativa e erro que requer intui√ß√£o e esfor√ßo do usu√°rio para obter resultados √≥timos. Ent√£o por que √© importante? Para responder a essa pergunta, primeiro precisamos entender tr√™s conceitos:

- _Tokeniza√ß√£o_ = como o modelo "v√™" o prompt  
- _LLMs Base_ = como o modelo base "processa" um prompt  
- _LLMs Ajustados por Instru√ß√£o_ = como o modelo pode agora "entender tarefas"

### Tokeniza√ß√£o

Um LLM v√™ prompts como uma _sequ√™ncia de tokens_ onde diferentes modelos (ou vers√µes de um modelo) podem tokenizar o mesmo prompt de maneiras diferentes. Como os LLMs s√£o treinados em tokens (e n√£o em texto bruto), a forma como os prompts s√£o tokenizados impacta diretamente a qualidade da resposta gerada.

Para entender intuitivamente como a tokeniza√ß√£o funciona, experimente ferramentas como o [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) mostrada abaixo. Copie seu prompt ‚Äî e veja como ele √© convertido em tokens, prestando aten√ß√£o em como espa√ßos em branco e sinais de pontua√ß√£o s√£o tratados. Observe que este exemplo mostra um LLM mais antigo (GPT-3) ‚Äî ent√£o tentar isso com um modelo mais novo pode gerar resultados diferentes.

![Tokeniza√ß√£o](../../../translated_images/pt-BR/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Conceito: Modelos Fundamentais

Uma vez que um prompt √© tokenizado, a fun√ß√£o principal do ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou modelo fundamental) √© prever o pr√≥ximo token naquela sequ√™ncia. Como LLMs s√£o treinados em conjuntos massivos de texto, eles t√™m uma boa no√ß√£o das rela√ß√µes estat√≠sticas entre tokens e podem fazer essa previs√£o com certa confian√ßa. Note que eles n√£o entendem o _significado_ das palavras no prompt ou token; eles apenas veem um padr√£o que podem "completar" com a pr√≥xima previs√£o. Eles podem continuar prevendo a sequ√™ncia at√© serem interrompidos por interven√ß√£o do usu√°rio ou alguma condi√ß√£o preestabelecida.

Quer ver como a completa√ß√£o baseada em prompt funciona? Cole o prompt acima no Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) com as configura√ß√µes padr√£o. O sistema est√° configurado para tratar os prompts como solicita√ß√µes de informa√ß√£o ‚Äî ent√£o voc√™ dever√° ver uma completamento que satisfa√ßa esse contexto.

Mas e se o usu√°rio quiser ver algo espec√≠fico que atenda a certos crit√©rios ou objetivo de tarefa? √â a√≠ que os LLMs _ajustados por instru√ß√£o_ entram em cena.

![Base LLM Chat Completion](../../../translated_images/pt-BR/04-playground-chat-base.65b76fcfde0caa67.webp)

### Conceito: LLMs Ajustados por Instru√ß√£o

Um [LLM Ajustado por Instru√ß√£o](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) come√ßa com o modelo fundamental e o ajusta finamente com exemplos ou pares entrada/sa√≠da (por exemplo, "mensagens" de m√∫ltiplas etapas) que podem conter instru√ß√µes claras ‚Äî e a resposta da IA tenta seguir essa instru√ß√£o.

Isso usa t√©cnicas como Aprendizado por Refor√ßo com Feedback Humano (RLHF) que podem treinar o modelo a _seguir instru√ß√µes_ e _aprender com feedback_ para produzir respostas mais adequadas a aplica√ß√µes pr√°ticas e mais relevantes aos objetivos do usu√°rio.

Vamos experimentar ‚Äî revisite o prompt acima, mas agora altere a _mensagem do sistema_ para fornecer a seguinte instru√ß√£o como contexto:

> _Resuma o conte√∫do fornecido para um aluno da segunda s√©rie. Mantenha o resultado em um par√°grafo com 3-5 t√≥picos._

Veja como o resultado agora est√° ajustado para refletir o objetivo e formato desejados? Um educador pode usar essa resposta diretamente nos seus slides para essa aula.

![Instruction Tuned LLM Chat Completion](../../../translated_images/pt-BR/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## Por que precisamos de Engenharia de Prompt?

Agora que sabemos como os prompts s√£o processados pelos LLMs, vamos falar sobre _por que_ precisamos de engenharia de prompt. A resposta est√° no fato de que os LLMs atuais apresentam diversos desafios que tornam _completa√ß√µes confi√°veis e consistentes_ mais dif√≠ceis de alcan√ßar sem esfor√ßo em constru√ß√£o e otimiza√ß√£o do prompt. Por exemplo:

1. **As respostas do modelo s√£o estoc√°sticas.** O _mesmo prompt_ provavelmente produzir√° respostas diferentes com modelos ou vers√µes diferentes. E pode at√© produzir resultados diferentes com o _mesmo modelo_ em diferentes momentos. _T√©cnicas de engenharia de prompt podem ajudar a minimizar essas varia√ß√µes fornecendo melhores barreiras_.

2. **Modelos podem fabricar respostas.** Modelos s√£o pr√©-treinados com _conjuntos de dados grandes, por√©m finitos_, o que significa que n√£o t√™m conhecimento sobre conceitos fora desse escopo de treinamento. Como resultado, podem produzir completa√ß√µes que s√£o incorretas, imagin√°rias ou diretamente contradizem fatos conhecidos. _T√©cnicas de engenharia de prompt ajudam usu√°rios a identificar e mitigar essas fabrica√ß√µes, por exemplo, pedindo cita√ß√µes ou racioc√≠nio da IA_.

3. **As capacidades dos modelos variam.** Modelos mais novos ou gera√ß√µes mais recentes ter√£o capacidades mais ricas, mas tamb√©m trazem caracter√≠sticas e trade-offs √∫nicos em custo e complexidade. _A engenharia de prompt pode ajudar a desenvolver melhores pr√°ticas e fluxos de trabalho que abstraem diferen√ßas e se adaptam a requisitos espec√≠ficos de modelos de maneira escal√°vel e integrada_.

Vamos ver isso em a√ß√£o no OpenAI ou Azure OpenAI Playground:

- Use o mesmo prompt em diferentes implanta√ß√µes de LLM (por exemplo, OpenAI, Azure OpenAI, Hugging Face) - voc√™ viu varia√ß√µes?  
- Use o mesmo prompt repetidamente com a _mesma_ implanta√ß√£o de LLM (por exemplo, playground Azure OpenAI) - como essas varia√ß√µes diferiram?

### Exemplo de Fabrica√ß√µes

Neste curso, usamos o termo **"fabrica√ß√£o"** para fazer refer√™ncia ao fen√¥meno em que os LLMs √†s vezes geram informa√ß√µes factualmente incorretas devido a limita√ß√µes em seu treinamento ou outras restri√ß√µes. Voc√™ tamb√©m pode ter ouvido isso chamado de _"alucina√ß√µes"_ em artigos populares ou pesquisas. Contudo, recomendamos fortemente usar _"fabrica√ß√£o"_ como termo para n√£o antropomorfizar acidentalmente o comportamento atribuindo uma caracter√≠stica humana a um resultado gerado por m√°quina. Isso tamb√©m refor√ßa as [diretrizes de IA respons√°vel](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) do ponto de vista terminol√≥gico, eliminando termos que podem ser considerados ofensivos ou n√£o inclusivos em alguns contextos.

Quer ter uma no√ß√£o de como as fabrica√ß√µes funcionam? Pense em um prompt que instrui a IA a gerar conte√∫do para um t√≥pico inexistente (para garantir que n√£o esteja no conjunto de treinamento). Por exemplo ‚Äî eu tentei este prompt:

> **Prompt:** gere um plano de aula sobre a Guerra Marciana de 2076.
Uma busca na web mostrou que existiam relatos fict√≠cios (por exemplo, s√©ries de televis√£o ou livros) sobre guerras em Marte - mas nenhum em 2076. O senso comum tamb√©m nos diz que 2076 est√° _no futuro_ e, portanto, n√£o pode estar associado a um evento real.

Ent√£o, o que acontece quando executamos este prompt com diferentes provedores de LLM?

> **Resposta 1**: OpenAI Playground (GPT-35)

![Response 1](../../../translated_images/pt-BR/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Resposta 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../../translated_images/pt-BR/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Resposta 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../../translated_images/pt-BR/04-fabrication-huggingchat.faf82a0a51278956.webp)

Como esperado, cada modelo (ou vers√£o do modelo) produz respostas ligeiramente diferentes gra√ßas ao comportamento estoc√°stico e √†s varia√ß√µes de capacidade do modelo. Por exemplo, um modelo direciona para um p√∫blico de 8¬™ s√©rie enquanto o outro assume um estudante do ensino m√©dio. Mas todos os tr√™s modelos geraram respostas que poderiam convencer um usu√°rio desinformado de que o evento era real.

T√©cnicas de engenharia de prompt como _metaprompting_ e _configura√ß√£o de temperatura_ podem reduzir algumas das fabrica√ß√µes do modelo at√© certo ponto. Novas _arquiteturas_ de engenharia de prompt tamb√©m incorporam novas ferramentas e t√©cnicas perfeitamente no fluxo do prompt, para mitigar ou reduzir alguns desses efeitos.

## Estudo de Caso: GitHub Copilot

Vamos encerrar esta se√ß√£o tendo uma no√ß√£o de como a engenharia de prompt √© usada em solu√ß√µes reais, analisando um Estudo de Caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot √© seu "Programador AI Parceiro" - ele converte prompts de texto em c√≥digos completos e est√° integrado ao seu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experi√™ncia fluida. Conforme documentado na s√©rie de blogs abaixo, a primeira vers√£o foi baseada no modelo OpenAI Codex - com engenheiros rapidamente percebendo a necessidade de ajustar o modelo e desenvolver melhores t√©cnicas de engenharia de prompt para melhorar a qualidade do c√≥digo. Em julho, eles [estrearam um modelo de IA melhorado que vai al√©m do Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugest√µes ainda mais r√°pidas.

Leia os posts na ordem para acompanhar a jornada de aprendizado deles.

- **Maio 2023** | [GitHub Copilot est√° melhorando na compreens√£o do seu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maio 2023** | [Dentro do GitHub: trabalhando com os LLMs por tr√°s do GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jun 2023** | [Como escrever melhores prompts para o GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [.. GitHub Copilot vai al√©m do Codex com modelo de IA melhorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [Guia do desenvolvedor para engenharia de prompt e LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Set 2023** | [Como construir um app executivo LLM: li√ß√µes do GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Voc√™ tamb√©m pode navegar no [blog de Engenharia](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) deles para mais posts como [este aqui](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que mostram como esses modelos e t√©cnicas s√£o _aplicados_ para impulsionar aplica√ß√µes no mundo real.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Constru√ß√£o de Prompt

J√° vimos por que a engenharia de prompt √© importante - agora vamos entender como prompts s√£o _constru√≠dos_ para que possamos avaliar diferentes t√©cnicas para um design de prompt mais eficaz.

### Prompt B√°sico

Vamos come√ßar com o prompt b√°sico: uma entrada de texto enviada ao modelo sem nenhum outro contexto. Aqui est√° um exemplo - quando enviamos as primeiras palavras do hino nacional dos EUA para a OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) ela imediatamente _completa_ a resposta com as pr√≥ximas linhas, ilustrando o comportamento b√°sico de predi√ß√£o.

| Prompt (Entrada)     | Completa√ß√£o (Sa√≠da)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Parece que voc√™ est√° come√ßando a letra de "The Star-Spangled Banner", o hino nacional dos Estados Unidos. A letra completa √© ... |

### Prompt Complexo

Agora vamos adicionar contexto e instru√ß√µes a esse prompt b√°sico. A [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir um prompt complexo como uma cole√ß√£o de _mensagens_ com:

- Pares de entrada/sa√≠da refletindo input do _usu√°rio_ e resposta do _assistente_.
- Mensagem do sistema definindo o contexto para o comportamento ou personalidade do assistente.

A requisi√ß√£o agora est√° na forma abaixo, onde a _tokeniza√ß√£o_ captura efetivamente informa√ß√µes relevantes do contexto e da conversa. Agora, mudar o contexto do sistema pode ser t√£o impactante na qualidade das completa√ß√µes quanto as entradas fornecidas pelo usu√°rio.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt de Instru√ß√£o

Nos exemplos acima, o prompt do usu√°rio era uma simples consulta em texto que pode ser interpretada como um pedido de informa√ß√£o. Com prompts de _instru√ß√£o_, podemos usar esse texto para especificar a tarefa com mais detalhes, fornecendo uma orienta√ß√£o melhor para a IA. Aqui est√° um exemplo:

| Prompt (Entrada)                                                                                                                                                                                                                         | Completa√ß√£o (Sa√≠da)                                                                                                        | Tipo de Instru√ß√£o   |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Escreva uma descri√ß√£o da Guerra Civil                                                                                                                                                                                                  | _retornou um par√°grafo simples_                                                                                           | Simples             |
| Escreva uma descri√ß√£o da Guerra Civil. Forne√ßa datas e eventos chave e descreva sua import√¢ncia                                                                                                                                         | _retornou um par√°grafo seguido por uma lista datas principais dos eventos com descri√ß√µes_                                  | Complexo            |
| Escreva uma descri√ß√£o da Guerra Civil em 1 par√°grafo. Forne√ßa 3 t√≥picos com datas-chave e sua import√¢ncia. Forne√ßa mais 3 t√≥picos com figuras hist√≥ricas importantes e suas contribui√ß√µes. Retorne a sa√≠da em um arquivo JSON       | _retorna um texto mais extensivo em uma caixa, formatado como JSON que voc√™ pode copiar e colar em um arquivo e validar_    | Complexo. Formatado. |

## Conte√∫do Prim√°rio

Nos exemplos acima, o prompt ainda era bastante aberto, permitindo que o LLM decidisse qual parte de seu conjunto de dados pr√©-treinado era relevante. Com o padr√£o de design _conte√∫do prim√°rio_, o texto de entrada √© dividido em duas partes:

- uma instru√ß√£o (a√ß√£o)
- conte√∫do relevante (que influencia a a√ß√£o)

Aqui est√° um exemplo onde a instru√ß√£o √© "resuma isto em 2 frases".

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Completa√ß√£o (Sa√≠da)                                                                                                                                                                                                                                                                           |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno e √© conhecido por civiliza√ß√µes antigas desde antes da hist√≥ria registrada. √â nomeado em homenagem ao deus romano J√∫piter.[19] Quando visto da Terra, J√∫piter pode ser brilhante o suficiente para que sua luz refletida projete sombras vis√≠veis,[20] e √© em m√©dia o terceiro objeto natural mais brilhante no c√©u noturno depois da Lua e V√™nus. <br/> **Resuma isto em 2 frases curtas** | J√∫piter, o quinto planeta a partir do Sol, √© o maior do Sistema Solar e √© conhecido por ser um dos objetos mais brilhantes no c√©u noturno. Nomeado em homenagem ao deus romano J√∫piter, √© um gigante gasoso cuja massa √© duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. |

O segmento de conte√∫do prim√°rio pode ser usado de v√°rias formas para direcionar instru√ß√µes mais eficazes:

- **Exemplos** - ao inv√©s de dizer ao modelo o que fazer com uma instru√ß√£o expl√≠cita, forne√ßa exemplos do que fazer e deixe-o inferir o padr√£o.
- **Dicas** - siga a instru√ß√£o com uma "dica" que prepara a conclus√£o, guiando o modelo para respostas mais relevantes.
- **Modelos** - estas s√£o 'receitas' repet√≠veis para prompts com espa√ßos reservados (vari√°veis) que podem ser customizados com dados para casos de uso espec√≠ficos.

Vamos explorar estes em a√ß√£o.

### Usando Exemplos

Esta √© uma abordagem onde voc√™ usa o conte√∫do prim√°rio para "alimentar o modelo" com alguns exemplos da sa√≠da desejada para uma dada instru√ß√£o, e deixa que ele infira o padr√£o para a sa√≠da desejada. Baseado na quantidade de exemplos fornecidos, podemos ter zero-shot prompting, one-shot prompting, few-shot prompting etc.

O prompt agora consiste em tr√™s componentes:

- Uma descri√ß√£o da tarefa
- Alguns exemplos da sa√≠da desejada
- O in√≠cio de um novo exemplo (que se torna uma descri√ß√£o impl√≠cita de tarefa)

| Tipo de Aprendizado | Prompt (Entrada)                                                                                                                                    | Completa√ß√£o (Sa√≠da)       |
| :------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------- |
| Zero-shot           | "O Sol est√° brilhando". Traduza para o espanhol                                                                                                  | "El Sol est√° brillando".   |
| One-shot            | "O Sol est√° brilhando" => "El Sol est√° brillando". <br> "√â um dia frio e ventoso" =>                                                            | "Es un d√≠a fr√≠o y ventoso".|
| Few-shot            | O jogador correu pelas bases => Baseball <br/> O jogador fez um ace => T√™nis <br/> O jogador fez um seis => Cr√≠quete <br/> O jogador fez uma enterrada => | Basquete                  |
|                     |                                                                                                                                                   |                           |

Note como tivemos que fornecer instru√ß√£o expl√≠cita ("Traduza para o espanhol") no zero-shot prompting, mas ela √© inferida no exemplo one-shot prompting. O exemplo few-shot mostra como adicionar mais exemplos permite que os modelos fa√ßam infer√™ncias mais precisas sem instru√ß√µes adicionais.

### Dicas no Prompt

Outra t√©cnica para usar conte√∫do prim√°rio √© fornecer _dicas_ ao inv√©s de exemplos. Neste caso, damos ao modelo um empurr√£o na dire√ß√£o certa, _come√ßando_ com um trecho que reflete o formato desejado da resposta. O modelo ent√£o "pega a dica" para continuar nessa linha.

| N√∫mero de Dicas | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completa√ß√£o (Sa√≠da)                                                                                                                                                                                                                                                                                     |
| :-------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 0               | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido h√° muito tempo pelas civiliza√ß√µes antigas. <br/>**Resuma Isto**                                       | J√∫piter √© o maior planeta do nosso Sistema Solar e o quinto a partir do Sol. √â um gigante gasoso com uma massa equivalente a 1/1000 da massa do Sol, mas √© mais pesado do que todos os outros planetas juntos. Civiliza√ß√µes antigas j√° conhecem J√∫piter h√° muito tempo e ele √© facilmente vis√≠vel no c√©u noturno. |
| 1              | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa de um mil√©simo da massa do Sol, mas duas vezes e meia a soma de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno e √© conhecido por civiliza√ß√µes antigas desde antes da hist√≥ria registrada. <br/>**Resuma Isso** <br/> O que aprendemos √© que J√∫piter | √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa de um mil√©simo da massa do Sol, mas duas vezes e meia a soma de todos os outros planetas juntos. √â facilmente vis√≠vel a olho nu e √© conhecido desde os tempos antigos.                        |
| 2              | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa de um mil√©simo da massa do Sol, mas duas vezes e meia a soma de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno e √© conhecido por civiliza√ß√µes antigas desde antes da hist√≥ria registrada. <br/>**Resuma Isso** <br/> Top 3 fatos que aprendemos:         | 1. J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. <br/> 2. √â um gigante gasoso com uma massa de um mil√©simo da massa do Sol...<br/> 3. J√∫piter tem sido vis√≠vel a olho nu desde os tempos antigos ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Modelos de Prompt

Um modelo de prompt √© uma _receita predefinida para um prompt_ que pode ser armazenada e reutilizada conforme necess√°rio, para conduzir experi√™ncias de usu√°rio mais consistentes em escala. Na sua forma mais simples, √© simplesmente uma cole√ß√£o de exemplos de prompt como [este do OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que fornece tanto os componentes interativos do prompt (mensagens do usu√°rio e do sistema) quanto o formato de requisi√ß√£o via API ‚Äî para suportar a reutiliza√ß√£o.

Em sua forma mais complexa, como [este exemplo do LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), ele cont√©m _espa√ßos reservados_ que podem ser substitu√≠dos por dados de v√°rias fontes (entrada do usu√°rio, contexto do sistema, fontes externas etc.) para gerar um prompt dinamicamente. Isso nos permite criar uma biblioteca de prompts reutiliz√°veis que podem ser usados para oferecer experi√™ncias de usu√°rio consistentes **programaticamente** em escala.

Finalmente, o verdadeiro valor dos modelos est√° na capacidade de criar e publicar _bibliotecas de prompts_ para dom√≠nios de aplica√ß√£o verticais ‚Äî onde o modelo de prompt √© agora _otimizado_ para refletir contexto espec√≠fico da aplica√ß√£o ou exemplos que tornam as respostas mais relevantes e precisas para o p√∫blico-alvo. O reposit√≥rio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √© um excelente exemplo dessa abordagem, reunindo uma biblioteca de prompts para o dom√≠nio educacional com √™nfase em objetivos chave como planejamento de aulas, design curricular, tutoria de estudantes, etc.

## Conte√∫do de Apoio

Se pensarmos na constru√ß√£o do prompt como tendo uma instru√ß√£o (tarefa) e um alvo (conte√∫do prim√°rio), ent√£o o _conte√∫do secund√°rio_ funciona como contexto adicional que fornecemos para **influenciar a sa√≠da de alguma forma**. Pode ser par√¢metros de ajuste, instru√ß√µes de formata√ß√£o, taxonomias tem√°ticas etc. que ajudam o modelo a _personalizar_ a resposta para adequar-se aos objetivos ou expectativas do usu√°rio.

Por exemplo: Dado um cat√°logo de cursos com metadados extensivos (nome, descri√ß√£o, n√≠vel, tags de metadados, instrutor etc.) sobre todos os cursos dispon√≠veis no curr√≠culo:

- podemos definir uma instru√ß√£o para "resumir o cat√°logo de cursos para o outono de 2023"
- podemos usar o conte√∫do prim√°rio para fornecer alguns exemplos da sa√≠da desejada
- podemos usar o conte√∫do secund√°rio para identificar as 5 principais "tags" de interesse.

Agora, o modelo pode fornecer um resumo no formato mostrado pelos exemplos ‚Äî mas se um resultado tiver m√∫ltiplas tags, pode priorizar as 5 tags identificadas no conte√∫do secund√°rio.

---

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve cobrir o conceito principal #1.
Reforce o conceito com exemplos e refer√™ncias.

CONCEITO #3:
T√©cnicas de Engenharia de Prompt.
Quais s√£o algumas t√©cnicas b√°sicas para engenharia de prompt?
Ilustre com alguns exerc√≠cios.
-->

## Melhores Pr√°ticas para Prompting

Agora que sabemos como os prompts podem ser _constru√≠dos_, podemos come√ßar a pensar em como _desenh√°-los_ para refletir as melhores pr√°ticas. Podemos pensar nisso em duas partes ‚Äî ter a _mentalidade_ adequada e aplicar as _t√©cnicas_ corretas.

### Mentalidade de Engenharia de Prompt

Engenharia de Prompt √© um processo de tentativa e erro, ent√£o mantenha em mente tr√™s fatores amplos que guiam:

1. **Entendimento do Dom√≠nio Importa.** A precis√£o e relev√¢ncia da resposta √© uma fun√ß√£o do _dom√≠nio_ em que a aplica√ß√£o ou usu√°rio opera. Aplique sua intui√ß√£o e expertise no dom√≠nio para **personalizar as t√©cnicas** ainda mais. Por exemplo, defina _personalidades espec√≠ficas do dom√≠nio_ em prompts do sistema, ou use _modelos espec√≠ficos do dom√≠nio_ nos prompts do usu√°rio. Forne√ßa conte√∫do secund√°rio que reflita contextos espec√≠ficos do dom√≠nio, ou use _sinais e exemplos espec√≠ficos do dom√≠nio_ para guiar o modelo a padr√µes de uso familiares.

2. **Entendimento do Modelo Importa.** Sabemos que modelos s√£o estoc√°sticos por natureza. Mas as implementa√ß√µes dos modelos tamb√©m podem variar em termos do conjunto de dados com que foram treinados (conhecimento pr√©-treinado), das capacidades que fornecem (ex.: via API ou SDK) e do tipo de conte√∫do para qual s√£o otimizados (ex.: c√≥digo vs imagens vs texto). Entenda os pontos fortes e limita√ß√µes do modelo que est√° usando e use esse conhecimento para _priorizar tarefas_ ou criar _modelos personalizados_ otimizados para as capacidades do modelo.

3. **Itera√ß√£o e Valida√ß√£o Importam.** Os modelos est√£o evoluindo rapidamente, assim como as t√©cnicas para engenharia de prompt. Como especialista no dom√≠nio, voc√™ pode ter outros contextos ou crit√©rios para _sua_ aplica√ß√£o espec√≠fica, que podem n√£o se aplicar √† comunidade mais ampla. Use ferramentas e t√©cnicas de engenharia de prompt para ‚Äúdar um pontap√© inicial‚Äù na constru√ß√£o do prompt, ent√£o itere e valide os resultados usando sua pr√≥pria intui√ß√£o e expertise do dom√≠nio. Registre suas percep√ß√µes e crie uma **base de conhecimento** (ex.: bibliotecas de prompt) que podem ser usadas como uma nova base para outros, para itera√ß√µes mais r√°pidas no futuro.

## Melhores Pr√°ticas

Agora vamos olhar as pr√°ticas recomendadas comuns pelos praticantes do [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) e do [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| O qu√™                             | Por qu√™                                                                                                                                                                                                                                            |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Avalie os modelos mais recentes. | Novas gera√ß√µes de modelos provavelmente t√™m recursos e qualidade melhorados ‚Äî mas podem tamb√©m acarretar custos maiores. Avalie-os em impacto e ent√£o decida sobre a migra√ß√£o.                                                                          |
| Separe instru√ß√µes e contexto     | Verifique se seu modelo/fornecedor define _delimitadores_ para distinguir instru√ß√µes, conte√∫do prim√°rio e secund√°rio mais claramente. Isso pode ajudar os modelos a atribuir pesos mais exatos aos tokens.                                            |
| Seja espec√≠fico e claro           | D√™ mais detalhes sobre o contexto desejado, resultado, extens√£o, formato, estilo etc. Isso melhora tanto a qualidade quanto a consist√™ncia das respostas. Registre receitas em modelos reutiliz√°veis.                                                  |
| Seja descritivo, use exemplos     | Modelos podem responder melhor com abordagem ‚Äúmostrar e contar‚Äù. Comece com uma abordagem `zero-shot` dando uma instru√ß√£o (sem exemplos), e depois tente `few-shot` como refinamento, fornecendo alguns exemplos da sa√≠da desejada. Use analogias.      |
| Use sinais para impulsionar respostas | Estimule o modelo rumo a um resultado desejado dando algumas palavras ou express√µes iniciais que ele possa usar como ponto de partida para a resposta.                                                                                            |
| Redobre esfor√ßos                 | √Äs vezes ser√° necess√°rio repetir instru√ß√µes para o modelo. D√™ instru√ß√µes antes e depois do conte√∫do prim√°rio, use instru√ß√£o e sinal juntos, etc. Itere e valide para ver o que funciona.                                                            |
| Ordem importa                     | A ordem em que voc√™ apresenta as informa√ß√µes ao modelo pode impactar o resultado, mesmo nos exemplos de aprendizado, devido ao vi√©s de rec√™ncia. Experimente diferentes op√ß√µes para ver o que funciona melhor.                                        |
| D√™ uma ‚Äúsa√≠da‚Äù ao modelo          | D√™ ao modelo uma resposta _fallback_ que ele pode fornecer se n√£o puder completar a tarefa por qualquer motivo. Isso reduz chances de gerar respostas falsas ou fabricadas.                                                                           |
|                                 |                                                                                                                                                                                                                                                   |

Como em qualquer melhor pr√°tica, lembre que _seus resultados podem variar_ dependendo do modelo, tarefa e dom√≠nio. Use estas como ponto de partida e itere para encontrar o que melhor funciona para voc√™. Reavalie constantemente seu processo de engenharia de prompt √† medida que novos modelos e ferramentas surgem, com foco em escalabilidade do processo e qualidade da resposta.

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve fornecer um desafio de c√≥digo se aplic√°vel

DESAFIO:
Link para um Jupyter Notebook com apenas coment√°rios no c√≥digo nas instru√ß√µes (se√ß√µes de c√≥digo vazias).

SOLU√á√ÉO:
Link para uma c√≥pia desse Notebook com os prompts preenchidos e executados, mostrando um exemplo.
-->

## Tarefa

Parab√©ns! Voc√™ chegou ao fim da li√ß√£o! √â hora de colocar alguns desses conceitos e t√©cnicas em pr√°tica com exemplos reais!

Para nossa tarefa, usaremos um Jupyter Notebook com exerc√≠cios que voc√™ pode completar interativamente. Voc√™ tamb√©m pode expandir o Notebook com suas pr√≥prias c√©lulas Markdown e de C√≥digo para explorar ideias e t√©cnicas por conta pr√≥pria.

### Para come√ßar, fa√ßa um fork do reposit√≥rio, depois

- (Recomendado) Inicie o GitHub Codespaces  
- (Alternativamente) Clone o reposit√≥rio para seu dispositivo local e use com Docker Desktop  
- (Alternativamente) Abra o Notebook com seu ambiente de runtime favorito.

### Em seguida, configure suas vari√°veis de ambiente

- Copie o arquivo `.env.copy` na raiz do reposit√≥rio para `.env` e preencha os valores `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` e `AZURE_OPENAI_DEPLOYMENT`. Volte para a se√ß√£o [Learning Sandbox](../../../04-prompt-engineering-fundamentals) para aprender como fazer.

### Depois, abra o Jupyter Notebook

- Selecione o kernel do runtime. Se usar as op√ß√µes 1 ou 2, selecione o kernel padr√£o Python 3.10.x fornecido pelo container de desenvolvimento.

Voc√™ est√° pronto para executar os exerc√≠cios. Note que n√£o existem respostas _certas ou erradas_ aqui ‚Äî apenas explora√ß√£o por tentativa e erro para construir intui√ß√£o sobre o que funciona para um determinado modelo e dom√≠nio de aplica√ß√£o.

_Por essa raz√£o n√£o h√° segmentos de Solu√ß√£o de C√≥digo nesta li√ß√£o. Em vez disso, o Notebook ter√° c√©lulas Markdown intituladas "Minha Solu√ß√£o:" mostrando uma sa√≠da de exemplo como refer√™ncia._

 <!--
MODELO DE LI√á√ÉO:
Encerre a se√ß√£o com um resumo e recursos para aprendizado autodirigido.
-->

## Verifica√ß√£o do Conhecimento

Qual dos seguintes prompts √© bom, seguindo algumas melhores pr√°ticas razo√°veis?

1. Mostre-me uma imagem de carro vermelho  
2. Mostre-me uma imagem de carro vermelho da marca Volvo e modelo XC90 estacionado perto de um penhasco com o sol se pondo  
3. Mostre-me uma imagem de carro vermelho da marca Volvo e modelo XC90

R: 2, √© o melhor prompt pois fornece detalhes sobre ‚Äúo qu√™‚Äù e vai aos espec√≠ficos (n√£o qualquer carro, mas uma marca e modelo espec√≠ficos) e tamb√©m descreve o cen√°rio geral. A op√ß√£o 3 √© a pr√≥xima melhor pois tamb√©m cont√©m muita descri√ß√£o.

## üöÄ Desafio

Veja se voc√™ consegue aproveitar a t√©cnica do ‚Äúsinal‚Äù com o prompt: Complete a frase "Mostre-me uma imagem de carro vermelho da marca Volvo e ". Como o modelo responde, e como voc√™ melhoraria?

## Excelente Trabalho! Continue seu Aprendizado

Quer aprender mais sobre diferentes conceitos de Engenharia de Prompt? Acesse a [p√°gina de aprendizado cont√≠nuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar outros √≥timos recursos sobre este tema.

Siga para a Li√ß√£o 5, onde veremos [t√©cnicas avan√ßadas de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->