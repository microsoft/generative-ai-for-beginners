{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bouw tekstgeneratie-apps\n",
    "\n",
    "Je hebt tot nu toe in deze leerlijn gezien dat er kernconcepten zijn zoals prompts en zelfs een heel vakgebied dat \"prompt engineering\" heet. Veel tools waarmee je kunt werken, zoals ChatGPT, Office 365, Microsoft Power Platform en meer, ondersteunen het gebruik van prompts om iets te bereiken.\n",
    "\n",
    "Om zo'n ervaring toe te voegen aan een app, moet je concepten als prompts, completions begrijpen en een bibliotheek kiezen om mee te werken. Dat is precies wat je in dit hoofdstuk gaat leren.\n",
    "\n",
    "## Introductie\n",
    "\n",
    "In dit hoofdstuk ga je:\n",
    "\n",
    "- Leren over de openai-bibliotheek en de belangrijkste concepten.\n",
    "- Een tekstgeneratie-app bouwen met openai.\n",
    "- Begrijpen hoe je concepten als prompt, temperature en tokens gebruikt om een tekstgeneratie-app te bouwen.\n",
    "\n",
    "## Leerdoelen\n",
    "\n",
    "Aan het einde van deze les kun je:\n",
    "\n",
    "- Uitleggen wat een tekstgeneratie-app is.\n",
    "- Een tekstgeneratie-app bouwen met openai.\n",
    "- Je app configureren om meer of minder tokens te gebruiken en ook de temperature aanpassen voor gevarieerde output.\n",
    "\n",
    "## Wat is een tekstgeneratie-app?\n",
    "\n",
    "Normaal gesproken heeft een app die je bouwt een soort interface zoals de volgende:\n",
    "\n",
    "- Op commando's gebaseerd. Console-apps zijn typische apps waarbij je een commando typt en er een taak wordt uitgevoerd. Bijvoorbeeld, `git` is een op commando's gebaseerde app.\n",
    "- Gebruikersinterface (UI). Sommige apps hebben grafische gebruikersinterfaces (GUI's) waarbij je op knoppen klikt, tekst invoert, opties selecteert en meer.\n",
    "\n",
    "### Console- en UI-apps zijn beperkt\n",
    "\n",
    "Vergelijk het met een op commando's gebaseerde app waarbij je een commando typt:\n",
    "\n",
    "- **Het is beperkt**. Je kunt niet zomaar elk commando typen, alleen de commando's die de app ondersteunt.\n",
    "- **Taalgebonden**. Sommige apps ondersteunen meerdere talen, maar standaard is de app gebouwd voor een specifieke taal, ook al kun je soms meer talen toevoegen.\n",
    "\n",
    "### Voordelen van tekstgeneratie-apps\n",
    "\n",
    "Hoe verschilt een tekstgeneratie-app dan?\n",
    "\n",
    "In een tekstgeneratie-app heb je meer flexibiliteit, je bent niet beperkt tot een set commando's of een specifieke invoertaal. In plaats daarvan kun je met natuurlijke taal met de app communiceren. Een ander voordeel is dat je werkt met een databron die getraind is op een enorme hoeveelheid informatie, terwijl een traditionele app vaak beperkt is tot wat er in een database staat.\n",
    "\n",
    "### Wat kan ik bouwen met een tekstgeneratie-app?\n",
    "\n",
    "Er zijn veel dingen die je kunt bouwen. Bijvoorbeeld:\n",
    "\n",
    "- **Een chatbot**. Een chatbot die vragen beantwoordt over onderwerpen, zoals je bedrijf en producten, kan een goede toepassing zijn.\n",
    "- **Hulpje**. LLM's zijn goed in dingen als het samenvatten van tekst, inzichten halen uit tekst, tekst genereren zoals cv's en meer.\n",
    "- **Code-assistent**. Afhankelijk van het taalmodel dat je gebruikt, kun je een code-assistent bouwen die je helpt bij het schrijven van code. Je kunt bijvoorbeeld een product als GitHub Copilot of ChatGPT gebruiken om je te ondersteunen bij het programmeren.\n",
    "\n",
    "## Hoe kan ik beginnen?\n",
    "\n",
    "Je moet een manier vinden om te integreren met een LLM, wat meestal neerkomt op de volgende twee benaderingen:\n",
    "\n",
    "- Gebruik een API. Hierbij maak je webverzoeken met je prompt en krijg je gegenereerde tekst terug.\n",
    "- Gebruik een bibliotheek. Bibliotheken kapselen de API-aanroepen in en maken het makkelijker om ermee te werken.\n",
    "\n",
    "## Bibliotheken/SDK's\n",
    "\n",
    "Er zijn een paar bekende bibliotheken om met LLM's te werken, zoals:\n",
    "\n",
    "- **openai**, deze bibliotheek maakt het eenvoudig om verbinding te maken met je model en prompts te versturen.\n",
    "\n",
    "Daarnaast zijn er bibliotheken die op een hoger niveau werken, zoals:\n",
    "\n",
    "- **Langchain**. Langchain is bekend en ondersteunt Python.\n",
    "- **Semantic Kernel**. Semantic Kernel is een bibliotheek van Microsoft die C#, Python en Java ondersteunt.\n",
    "\n",
    "## Eerste app met GitHub Models Playground en Azure AI Inference SDK\n",
    "\n",
    "Laten we kijken hoe we onze eerste app kunnen bouwen, welke bibliotheken we nodig hebben, wat er allemaal bij komt kijken, enzovoort.\n",
    "\n",
    "### Wat is GitHub Models?\n",
    "\n",
    "Welkom bij [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Alles staat klaar om verschillende AI-modellen te verkennen die worden gehost op Azure AI, allemaal toegankelijk via een playground op GitHub of direct in je favoriete code-IDE, gratis om uit te proberen.\n",
    "\n",
    "### Wat heb ik nodig?\n",
    "\n",
    "* Een GitHub-account: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Aanmelden voor GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Laten we beginnen!\n",
    "\n",
    "### Zoek een model en test het\n",
    "\n",
    "Navigeer naar [GitHub Models in de Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Hoofdscherm van GitHub Models met een lijst van modelkaarten zoals Cohere, Meta llama, Mistral en GPT-modellen](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.nl.png)\n",
    "\n",
    "Kies een model - bijvoorbeeld [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Hier zie je de modelkaart. Je kunt:\n",
    "* Direct met het model communiceren door een bericht in het tekstvak in te voeren\n",
    "* Details over het model lezen in de tabbladen readme, Evaluation, Transparency en License\n",
    "* Ook de sectie 'About' aan de rechterkant bekijken voor toegang tot het model\n",
    "\n",
    "![GitHub Models GPT-4o Model Card](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.nl.png)\n",
    "\n",
    "Maar we gaan direct naar de playground door op de ['Playground'-knop rechtsboven](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst) te klikken. Hier kun je met het model communiceren, systeem-prompts toevoegen en parameterdetails aanpassen – maar je krijgt ook alle code die je nodig hebt om dit overal te draaien. Beschikbaar vanaf september 2024: Python, Javascript, C# en REST.\n",
    "\n",
    "![GitHub Models Playground-ervaring met code en getoonde talen](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.nl.png)  \n",
    "\n",
    "### Het model gebruiken in je eigen IDE\n",
    "\n",
    "Twee opties:\n",
    "1. **GitHub Codespaces** – naadloze integratie met Codespaces en geen token nodig om te starten\n",
    "2. **VS Code (of een andere favoriete IDE)** – je hebt een [Personal Access Token van GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst) nodig\n",
    "\n",
    "In beide gevallen vind je instructies via de groene knop 'Get started' rechtsboven.\n",
    "\n",
    "![Get Started-scherm dat laat zien hoe je Codespaces gebruikt of een personal access token instelt in je eigen IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.nl.png)\n",
    "\n",
    "### 1. Codespaces\n",
    "\n",
    "* Kies in het 'Get started'-venster voor \"Run codespace\"\n",
    "* Maak een nieuwe codespace aan (of gebruik een bestaande)\n",
    "* VS Code opent in je browser met een set voorbeeldnotebooks in meerdere talen die je kunt proberen\n",
    "* Voer het voorbeeld uit ```./githubmodels-app.py```.\n",
    "\n",
    "> Opmerking: In codespaces hoef je de Github Token-variabele niet in te stellen, sla deze stap over\n",
    "\n",
    "**Ga nu verder naar de sectie 'Tekst genereren' hieronder om deze opdracht voort te zetten**\n",
    "\n",
    "### 2. VS Code (of een andere favoriete IDE)\n",
    "\n",
    "Via de groene 'Get started'-knop vind je alle informatie die je nodig hebt om in je favoriete IDE aan de slag te gaan. Dit voorbeeld laat VS Code zien.\n",
    "\n",
    "* Selecteer de taal en SDK – in dit voorbeeld kiezen we Python en Azure AI Inference SDK\n",
    "* Maak een personal access token aan op GitHub. Dit vind je onder Developer Settings. Je hoeft geen rechten toe te kennen aan het token. Let op: het token wordt naar een Microsoft-service gestuurd.\n",
    "* Maak een omgevingsvariabele aan om je Github personal access token op te slaan – voorbeelden zijn beschikbaar voor bash, powershell en windows command prompt\n",
    "* Installeer de benodigde dependencies: ```pip install azure-ai-inference```\n",
    "* Kopieer de basisvoorbeeldcode in een .py-bestand\n",
    "* Navigeer naar de locatie van je code en voer het bestand uit: ```python filename.py```\n",
    "\n",
    "Vergeet niet: met de Azure AI Inference SDK kun je eenvoudig experimenteren met verschillende modellen door de waarde van `model_name` in de code aan te passen.\n",
    "\n",
    "De volgende modellen zijn beschikbaar in de GitHub Models-service vanaf september 2024:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Ga nu verder naar de sectie 'Tekst genereren' hieronder om deze opdracht voort te zetten**\n",
    "\n",
    "## Tekst genereren met ChatCompletions\n",
    "\n",
    "De manier om tekst te genereren is door de klasse `ChatCompletionsClient` te gebruiken.\n",
    "In `samples/python/azure_ai_inference/basic.py`, in het response-gedeelte van de code, werk je de code bij voor de user role door de content-parameter te wijzigen naar het onderstaande:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Voer het bijgewerkte bestand uit om de output te zien\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verschillende soorten prompts, voor verschillende doeleinden\n",
    "\n",
    "Je hebt nu gezien hoe je tekst kunt genereren met een prompt. Je hebt zelfs een programma draaien dat je kunt aanpassen om verschillende soorten tekst te genereren.\n",
    "\n",
    "Prompts kun je voor allerlei taken gebruiken. Bijvoorbeeld:\n",
    "\n",
    "- **Een bepaald type tekst genereren**. Je kunt bijvoorbeeld een gedicht maken, quizvragen genereren, enzovoort.\n",
    "- **Informatie opzoeken**. Je kunt prompts gebruiken om informatie te zoeken, zoals in het volgende voorbeeld: 'Wat betekent CORS in webontwikkeling?'.\n",
    "- **Code genereren**. Je kunt prompts gebruiken om code te genereren, bijvoorbeeld een reguliere expressie om e-mails te valideren, of zelfs een heel programma, zoals een webapp.\n",
    "\n",
    "## Oefening: een recepten-generator\n",
    "\n",
    "Stel je hebt wat ingrediënten thuis en je wilt iets koken. Daarvoor heb je een recept nodig. Je kunt recepten zoeken via een zoekmachine, maar je kunt ook een LLM gebruiken.\n",
    "\n",
    "Je zou een prompt kunnen schrijven zoals:\n",
    "\n",
    "> \"Geef me 5 recepten voor een gerecht met de volgende ingrediënten: kip, aardappelen en wortels. Geef per recept alle gebruikte ingrediënten weer.\"\n",
    "\n",
    "Met deze prompt zou je bijvoorbeeld het volgende antwoord kunnen krijgen:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Dit resultaat is top, ik weet wat ik kan koken. Wat nu handig zou zijn:\n",
    "\n",
    "- Ingrediënten eruit filteren die ik niet lust of waarvoor ik allergisch ben.\n",
    "- Een boodschappenlijst maken, voor het geval ik niet alles in huis heb.\n",
    "\n",
    "Voor deze gevallen kun je een extra prompt toevoegen:\n",
    "\n",
    "> \"Verwijder recepten met knoflook, want ik ben allergisch, en vervang het door iets anders. Maak ook een boodschappenlijst voor de recepten, rekening houdend met dat ik kip, aardappelen en wortels al thuis heb.\"\n",
    "\n",
    "Nu krijg je een nieuw resultaat, namelijk:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Dat zijn je vijf recepten, zonder knoflook, en je hebt ook een boodschappenlijst die rekening houdt met wat je al in huis hebt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oefening - bouw een recepten-generator\n",
    "\n",
    "Nu we een scenario hebben doorgenomen, gaan we code schrijven die bij het getoonde scenario past. Volg hiervoor deze stappen:\n",
    "\n",
    "1. Gebruik het bestaande bestand als uitgangspunt\n",
    "1. Maak een `prompt`-variabele aan en pas de voorbeeldcode als volgt aan:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als je nu de code uitvoert, zou je een output moeten zien die lijkt op:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, je LLM is niet-deterministisch, dus je kunt elke keer dat je het programma uitvoert andere resultaten krijgen.\n",
    "\n",
    "Mooi, laten we kijken hoe we dingen kunnen verbeteren. Om dingen te verbeteren, willen we ervoor zorgen dat de code flexibel is, zodat ingrediënten en het aantal recepten makkelijk aangepast en verbeterd kunnen worden.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De code testen kan er zo uitzien:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Verbeteren door filter en boodschappenlijst toe te voegen\n",
    "\n",
    "We hebben nu een werkende app die recepten kan genereren en flexibel is omdat hij afhankelijk is van invoer van de gebruiker, zowel voor het aantal recepten als de gebruikte ingrediënten.\n",
    "\n",
    "Om het verder te verbeteren, willen we het volgende toevoegen:\n",
    "\n",
    "- **Ingrediënten filteren**. We willen ingrediënten kunnen uitsluiten die we niet lekker vinden of waarvoor we allergisch zijn. Om deze wijziging door te voeren, kunnen we onze bestaande prompt aanpassen en een filtervoorwaarde aan het einde toevoegen, zoals hieronder:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Hier voegen we `{filter}` toe aan het einde van de prompt en vangen we ook de filterwaarde van de gebruiker op.\n",
    "\n",
    "    Een voorbeeld van een invoer bij het uitvoeren van het programma kan er nu zo uitzien:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Een boodschappenlijst maken**. We willen een boodschappenlijst genereren, rekening houdend met wat we al thuis hebben.\n",
    "\n",
    "    Voor deze functionaliteit kunnen we proberen alles in één prompt op te lossen, of we kunnen het opdelen in twee prompts. Laten we de tweede aanpak proberen. Hier stellen we voor om een extra prompt toe te voegen, maar daarvoor moeten we het resultaat van de eerste prompt als context aan de tweede prompt meegeven.\n",
    "\n",
    "    Zoek het deel in de code waar het resultaat van de eerste prompt wordt geprint en voeg daaronder de volgende code toe:\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Let op het volgende:\n",
    "\n",
    "    - We maken een nieuwe prompt door het resultaat van de eerste prompt toe te voegen aan de nieuwe prompt:\n",
    "    \n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - We doen een nieuw verzoek, maar houden ook rekening met het aantal tokens dat we bij de eerste prompt hebben gevraagd, dus deze keer stellen we `max_tokens` in op 1200. **Een woord over tokenlengte**. We moeten nadenken over hoeveel tokens we nodig hebben om de gewenste tekst te genereren. Tokens kosten geld, dus waar mogelijk moeten we proberen zuinig om te gaan met het aantal tokens dat we gebruiken. Kunnen we bijvoorbeeld de prompt zo formuleren dat we minder tokens nodig hebben?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Als we deze code uitvoeren, krijgen we nu het volgende resultaat:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Experimenteren met temperatuur**. Temperatuur is iets wat we tot nu toe niet hebben genoemd, maar het is belangrijk voor hoe ons programma presteert. Hoe hoger de temperatuurwaarde, hoe willekeuriger de output zal zijn. Hoe lager de temperatuur, hoe voorspelbaarder het resultaat. Bedenk of je variatie in je output wilt of niet.\n",
    "\n",
    "   Om de temperatuur aan te passen, kun je de parameter `temperature` gebruiken. Bijvoorbeeld, als je een temperatuur van 0.5 wilt gebruiken, doe je:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Let op, hoe dichter bij 1.0, hoe gevarieerder de output.\n",
    "\n",
    "\n",
    "## Opdracht\n",
    "\n",
    "Voor deze opdracht mag je zelf kiezen wat je bouwt.\n",
    "\n",
    "Hier zijn wat suggesties:\n",
    "\n",
    "- Pas de recepten-generator app verder aan. Speel met temperatuurwaarden en de prompts om te zien wat je kunt bereiken.\n",
    "- Bouw een \"studie-buddy\". Deze app moet vragen kunnen beantwoorden over een onderwerp, bijvoorbeeld Python. Je kunt prompts maken als \"Wat is een bepaald onderwerp in Python?\", of een prompt die zegt, laat me code zien voor een bepaald onderwerp, enzovoort.\n",
    "- Geschiedenisbot, laat geschiedenis tot leven komen, instrueer de bot om een bepaald historisch figuur te spelen en stel vragen over zijn leven en tijd.\n",
    "\n",
    "## Oplossing\n",
    "\n",
    "### Studie-buddy\n",
    "\n",
    "- \"Je bent een expert in de Python-taal\n",
    "\n",
    "    Stel een beginnersles voor Python voor in het volgende format:\n",
    "    \n",
    "    Format:\n",
    "    - concepten:\n",
    "    - korte uitleg van de les:\n",
    "    - oefening in code met oplossingen\"\n",
    "\n",
    "Bovenstaande is een startprompt, kijk hoe je deze kunt gebruiken en aanpassen naar jouw wensen.\n",
    "\n",
    "### Geschiedenisbot\n",
    "\n",
    "Hier zijn wat prompts die je kunt gebruiken:\n",
    "\n",
    "- \"Je bent Abe Lincoln, vertel iets over jezelf in 3 zinnen, en reageer met grammatica en woorden zoals Abe zou gebruiken\"\n",
    "- \"Je bent Abe Lincoln, reageer met grammatica en woorden zoals Abe zou gebruiken:\n",
    "\n",
    "   Vertel over je grootste prestaties, in 300 woorden:\"\n",
    "\n",
    "## Kennischeck\n",
    "\n",
    "Wat doet het concept temperatuur?\n",
    "\n",
    "1. Het bepaalt hoe willekeurig de output is.\n",
    "1. Het bepaalt hoe groot het antwoord is.\n",
    "1. Het bepaalt hoeveel tokens er worden gebruikt.\n",
    "\n",
    "A: 1\n",
    "\n",
    "Wat is een goede manier om geheimen zoals API-sleutels op te slaan?\n",
    "\n",
    "1. In code.\n",
    "1. In een bestand.\n",
    "1. In omgevingsvariabelen.\n",
    "\n",
    "A: 3, omdat omgevingsvariabelen niet in de code worden opgeslagen en vanuit de code kunnen worden geladen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:\nDit document is vertaald met behulp van de AI-vertalingsdienst [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u er rekening mee te houden dat geautomatiseerde vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het originele document in de oorspronkelijke taal moet als de gezaghebbende bron worden beschouwd. Voor kritische informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T15:18:45+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "nl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}