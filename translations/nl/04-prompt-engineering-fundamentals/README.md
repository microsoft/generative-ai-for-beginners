<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0135e6c271f3ece8699050d4debbce88",
  "translation_date": "2025-10-17T19:57:13+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "nl"
}
-->
# Basisprincipes van Prompt Engineering

[![Basisprincipes van Prompt Engineering](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.nl.png)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introductie
Deze module behandelt essenti√´le concepten en technieken voor het maken van effectieve prompts in generatieve AI-modellen. De manier waarop je je prompt schrijft aan een LLM is van belang. Een zorgvuldig opgestelde prompt kan een betere kwaliteit van respons opleveren. Maar wat betekenen termen zoals _prompt_ en _prompt engineering_ precies? En hoe kan ik de prompt _input_ die ik naar de LLM stuur verbeteren? Dit zijn de vragen die we in dit hoofdstuk en het volgende proberen te beantwoorden.

_Generatieve AI_ is in staat om nieuwe content te cre√´ren (bijv. tekst, afbeeldingen, audio, code, etc.) als reactie op gebruikersverzoeken. Dit wordt bereikt met _Large Language Models_ zoals de GPT ("Generative Pre-trained Transformer") serie van OpenAI, die getraind zijn om natuurlijke taal en code te gebruiken.

Gebruikers kunnen nu met deze modellen communiceren via bekende paradigma's zoals chat, zonder technische expertise of training nodig te hebben. De modellen zijn _prompt-gebaseerd_ - gebruikers sturen een tekstinput (prompt) en krijgen een AI-respons (completion) terug. Ze kunnen vervolgens "met de AI chatten" in iteratieve, meerstaps gesprekken, waarbij ze hun prompt verfijnen totdat de respons aan hun verwachtingen voldoet.

"Prompts" worden nu de primaire _programmeerinterface_ voor generatieve AI-apps, waarbij ze de modellen vertellen wat te doen en de kwaliteit van de geretourneerde reacties be√Ønvloeden. "Prompt Engineering" is een snelgroeiend studiegebied dat zich richt op het _ontwerpen en optimaliseren_ van prompts om consistente en kwalitatieve reacties op schaal te leveren.

## Leerdoelen

In deze les leren we wat Prompt Engineering is, waarom het belangrijk is, en hoe we effectievere prompts kunnen maken voor een specifiek model en toepassingsdoel. We begrijpen kernconcepten en best practices voor prompt engineering - en leren over een interactieve Jupyter Notebooks "sandbox"-omgeving waar we deze concepten kunnen toepassen op echte voorbeelden.

Aan het einde van deze les kunnen we:

1. Uitleggen wat prompt engineering is en waarom het belangrijk is.
2. De componenten van een prompt beschrijven en hoe ze worden gebruikt.
3. Best practices en technieken voor prompt engineering leren.
4. Geleerde technieken toepassen op echte voorbeelden, met behulp van een OpenAI-endpoint.

## Belangrijke termen

Prompt Engineering: De praktijk van het ontwerpen en verfijnen van inputs om AI-modellen te sturen naar het produceren van gewenste outputs.  
Tokenization: Het proces van het omzetten van tekst in kleinere eenheden, genaamd tokens, die een model kan begrijpen en verwerken.  
Instruction-Tuned LLMs: Grote taalmodellen (LLMs) die zijn verfijnd met specifieke instructies om hun responsnauwkeurigheid en relevantie te verbeteren.

## Leeromgeving

Prompt engineering is momenteel meer kunst dan wetenschap. De beste manier om onze intu√Øtie ervoor te verbeteren is door _meer te oefenen_ en een trial-and-error aanpak te hanteren die toepassingsdomeinexpertise combineert met aanbevolen technieken en model-specifieke optimalisaties.

De Jupyter Notebook die bij deze les hoort biedt een _sandbox_-omgeving waar je kunt uitproberen wat je leert - terwijl je bezig bent of als onderdeel van de code-uitdaging aan het einde. Om de oefeningen uit te voeren, heb je nodig:

1. **Een Azure OpenAI API-sleutel** - de service endpoint voor een ge√Ømplementeerde LLM.  
2. **Een Python-runtime** - waarin de Notebook kan worden uitgevoerd.  
3. **Lokale omgevingsvariabelen** - _voltooi de [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) stappen nu om klaar te zijn_.  

De notebook bevat _startoefeningen_ - maar je wordt aangemoedigd om je eigen _Markdown_ (beschrijving) en _Code_ (promptverzoeken) secties toe te voegen om meer voorbeelden of idee√´n uit te proberen - en je intu√Øtie voor promptontwerp op te bouwen.

## Ge√Øllustreerde gids

Wil je een overzicht krijgen van wat deze les behandelt voordat je erin duikt? Bekijk deze ge√Øllustreerde gids, die je een idee geeft van de belangrijkste onderwerpen die worden behandeld en de belangrijkste inzichten om over na te denken bij elk onderwerp. De lesroutekaart neemt je mee van het begrijpen van de kernconcepten en uitdagingen tot het aanpakken ervan met relevante technieken en best practices voor prompt engineering. Merk op dat de sectie "Geavanceerde technieken" in deze gids verwijst naar inhoud die wordt behandeld in het _volgende_ hoofdstuk van dit curriculum.

![Ge√Øllustreerde gids voor Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.nl.png)

## Onze Startup

Laten we nu bespreken hoe _dit onderwerp_ verband houdt met onze missie om [AI-innovatie naar het onderwijs te brengen](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). We willen AI-gestuurde toepassingen voor _gepersonaliseerd leren_ bouwen - dus laten we nadenken over hoe verschillende gebruikers van onze applicatie prompts zouden kunnen "ontwerpen":

- **Beheerders** zouden de AI kunnen vragen om _curriculumgegevens te analyseren om hiaten in dekking te identificeren_. De AI kan resultaten samenvatten of ze visualiseren met code.  
- **Docenten** zouden de AI kunnen vragen om _een lesplan te genereren voor een specifieke doelgroep en onderwerp_. De AI kan het gepersonaliseerde plan in een gespecificeerd formaat opstellen.  
- **Studenten** zouden de AI kunnen vragen om _hen te begeleiden in een moeilijk vak_. De AI kan studenten nu begeleiden met lessen, hints en voorbeelden die zijn afgestemd op hun niveau.  

Dat is slechts het topje van de ijsberg. Bekijk [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - een open-source promptbibliotheek samengesteld door onderwijsdeskundigen - om een breder beeld te krijgen van de mogelijkheden! _Probeer enkele van die prompts uit in de sandbox of gebruik de OpenAI Playground om te zien wat er gebeurt!_

<!--
LESSON TEMPLATE:
Deze eenheid moet kernconcept #1 behandelen.
Versterk het concept met voorbeelden en referenties.

CONCEPT #1:
Prompt Engineering.
Definieer het en leg uit waarom het nodig is.
-->

## Wat is Prompt Engineering?

We begonnen deze les met het defini√´ren van **Prompt Engineering** als het proces van _ontwerpen en optimaliseren_ van tekstinputs (prompts) om consistente en kwalitatieve reacties (completions) te leveren voor een specifiek toepassingsdoel en model. We kunnen dit zien als een proces in twee stappen:

- Het _ontwerpen_ van de initi√´le prompt voor een specifiek model en doel.  
- Het _verfijnen_ van de prompt iteratief om de kwaliteit van de respons te verbeteren.  

Dit is noodzakelijkerwijs een trial-and-error proces dat gebruikersintu√Øtie en inspanning vereist om optimale resultaten te behalen. Maar waarom is het belangrijk? Om die vraag te beantwoorden, moeten we eerst drie concepten begrijpen:

- _Tokenization_ = hoe het model de prompt "ziet".  
- _Base LLMs_ = hoe het basismodel een prompt "verwerkt".  
- _Instruction-Tuned LLMs_ = hoe het model nu "taken" kan zien.  

### Tokenization

Een LLM ziet prompts als een _reeks van tokens_ waarbij verschillende modellen (of versies van een model) dezelfde prompt op verschillende manieren kunnen tokeniseren. Omdat LLMs getraind zijn op tokens (en niet op ruwe tekst), heeft de manier waarop prompts worden getokeniseerd een directe invloed op de kwaliteit van de gegenereerde respons.

Om een intu√Øtie te krijgen voor hoe tokenization werkt, kun je tools zoals de [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) proberen, zoals hieronder weergegeven. Kopieer je prompt erin - en zie hoe deze wordt omgezet in tokens, waarbij je let op hoe witruimtes en leestekens worden behandeld. Merk op dat dit voorbeeld een ouder LLM (GPT-3) toont - dus het proberen met een nieuwer model kan een ander resultaat opleveren.

![Tokenization](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.nl.png)

### Concept: Foundation Models

Zodra een prompt is getokeniseerd, is de primaire functie van het ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (of basismodel) om het volgende token in die reeks te voorspellen. Omdat LLMs zijn getraind op enorme tekstdatasets, hebben ze een goed gevoel voor de statistische relaties tussen tokens en kunnen ze die voorspelling met enige zekerheid maken. Merk op dat ze de _betekenis_ van de woorden in de prompt of token niet begrijpen; ze zien gewoon een patroon dat ze kunnen "voltooien" met hun volgende voorspelling. Ze kunnen doorgaan met het voorspellen van de reeks totdat ze worden be√´indigd door gebruikersinterventie of een vooraf vastgestelde voorwaarde.

Wil je zien hoe prompt-gebaseerde completie werkt? Voer de bovenstaande prompt in de Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) in met de standaardinstellingen. Het systeem is geconfigureerd om prompts te behandelen als verzoeken om informatie - dus je zou een completion moeten zien die aan deze context voldoet.

Maar wat als de gebruiker iets specifieks wilde zien dat aan bepaalde criteria of taakdoelen voldeed? Hier komen _instruction-tuned_ LLMs in beeld.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.nl.png)

### Concept: Instruction Tuned LLMs

Een [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) begint met het basismodel en verfijnt het met voorbeelden of input/output-paren (bijv. meerstaps "berichten") die duidelijke instructies kunnen bevatten - en de respons van de AI probeert die instructie te volgen.

Dit maakt gebruik van technieken zoals Reinforcement Learning with Human Feedback (RLHF) die het model kunnen trainen om _instructies te volgen_ en _te leren van feedback_, zodat het reacties produceert die beter geschikt zijn voor praktische toepassingen en relevanter zijn voor gebruikersdoelen.

Laten we het uitproberen - ga terug naar de bovenstaande prompt, maar verander nu het _systeembericht_ om de volgende instructie als context te geven:

> _Vat de inhoud samen die je krijgt voor een leerling uit groep 4. Beperk het resultaat tot √©√©n alinea met 3-5 bullet points._

Zie je hoe het resultaat nu is afgestemd op het gewenste doel en formaat? Een docent kan deze respons nu direct gebruiken in zijn of haar presentatie voor die les.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.nl.png)

## Waarom hebben we Prompt Engineering nodig?

Nu we weten hoe prompts worden verwerkt door LLMs, laten we bespreken _waarom_ we prompt engineering nodig hebben. Het antwoord ligt in het feit dat huidige LLMs een aantal uitdagingen vormen die het moeilijker maken om _betrouwbare en consistente completions_ te bereiken zonder moeite te doen in het construeren en optimaliseren van prompts. Bijvoorbeeld:

1. **Modelreacties zijn stochastisch.** De _zelfde prompt_ zal waarschijnlijk verschillende reacties opleveren met verschillende modellen of modelversies. En het kan zelfs verschillende resultaten opleveren met hetzelfde model op verschillende momenten. _Prompt engineering technieken kunnen ons helpen deze variaties te minimaliseren door betere richtlijnen te bieden_.  

1. **Modellen kunnen reacties verzinnen.** Modellen zijn vooraf getraind met _grote maar eindige_ datasets, wat betekent dat ze geen kennis hebben over concepten buiten die trainingsscope. Als gevolg hiervan kunnen ze completions produceren die onnauwkeurig, verzonnen of direct in tegenspraak zijn met bekende feiten. _Prompt engineering technieken helpen gebruikers om dergelijke verzinsels te identificeren en te beperken, bijvoorbeeld door de AI om citaten of redeneringen te vragen_.  

1. **Modelcapaciteiten zullen vari√´ren.** Nieuwere modellen of modelgeneraties zullen rijkere capaciteiten hebben, maar brengen ook unieke eigenaardigheden en afwegingen in kosten en complexiteit met zich mee. _Prompt engineering kan ons helpen best practices en workflows te ontwikkelen die verschillen abstraheren en zich aanpassen aan model-specifieke vereisten op schaalbare, naadloze manieren_.  

Laten we dit in actie zien in de OpenAI of Azure OpenAI Playground:

- Gebruik dezelfde prompt met verschillende LLM-implementaties (bijv. OpenAI, Azure OpenAI, Hugging Face) - zag je de variaties?  
- Gebruik dezelfde prompt herhaaldelijk met dezelfde LLM-implementatie (bijv. Azure OpenAI Playground) - hoe verschilden deze variaties?  

### Voorbeeld van verzinsels

In deze cursus gebruiken we de term **"verzinsels"** om het fenomeen te beschrijven waarbij LLMs soms feitelijk onjuiste informatie genereren vanwege beperkingen in hun training of andere beperkingen. Je hebt dit misschien ook gehoord als _"hallucinaties"_ in populaire artikelen of onderzoeksdocumenten. We raden echter sterk aan om _"verzinsels"_ als term te gebruiken, zodat we het gedrag niet per ongeluk antropomorfiseren door een menselijke eigenschap toe te schrijven aan een machinegedreven uitkomst. Dit versterkt ook de [Responsible AI-richtlijnen](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) vanuit terminologieperspectief, waarbij termen worden verwijderd die in sommige contexten als aanstootgevend of niet-inclusief kunnen worden beschouwd.

Wil je een idee krijgen van hoe verzinsels werken? Denk aan een prompt die de AI instrueert om content te genereren voor een niet-bestaand onderwerp (om ervoor te zorgen dat het niet in de trainingsdataset voorkomt). Bijvoorbeeld - ik probeerde deze prompt:

> **Prompt:** genereer een lesplan over de Mars-oorlog van 2076.
Een webzoektocht liet zien dat er fictieve verhalen (bijvoorbeeld televisieseries of boeken) bestaan over oorlogen op Mars - maar geen enkele in 2076. Het is ook logisch dat 2076 _in de toekomst_ ligt en dus niet kan worden gekoppeld aan een echte gebeurtenis.

Wat gebeurt er als we deze prompt uitvoeren met verschillende LLM-providers?

> **Reactie 1**: OpenAI Playground (GPT-35)

![Reactie 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.nl.png)

> **Reactie 2**: Azure OpenAI Playground (GPT-35)

![Reactie 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.nl.png)

> **Reactie 3**: Hugging Face Chat Playground (LLama-2)

![Reactie 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.nl.png)

Zoals verwacht produceert elk model (of modelversie) enigszins verschillende reacties dankzij stochastisch gedrag en variaties in modelcapaciteit. Bijvoorbeeld, het ene model richt zich op een publiek van groep 8, terwijl het andere uitgaat van een middelbare scholier. Maar alle drie de modellen genereerden reacties die een onwetende gebruiker zouden kunnen overtuigen dat de gebeurtenis echt was.

Technieken voor prompt engineering zoals _metaprompting_ en _temperatuurconfiguratie_ kunnen modelfabricaties tot op zekere hoogte verminderen. Nieuwe architecturen voor prompt engineering integreren ook naadloos nieuwe tools en technieken in de promptflow om sommige van deze effecten te beperken of te verminderen.

## Case Study: GitHub Copilot

Laten we dit gedeelte afsluiten door een idee te krijgen van hoe prompt engineering wordt gebruikt in oplossingen uit de praktijk, door te kijken naar een Case Study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot is jouw "AI Pair Programmer" - het zet tekstprompts om in codevoorstellen en is ge√Øntegreerd in je ontwikkelomgeving (bijvoorbeeld Visual Studio Code) voor een naadloze gebruikerservaring. Zoals gedocumenteerd in de reeks blogs hieronder, was de eerste versie gebaseerd op het OpenAI Codex-model - waarbij ingenieurs al snel inzagen dat het nodig was om het model te verfijnen en betere technieken voor prompt engineering te ontwikkelen om de codekwaliteit te verbeteren. In juli [introduceerden ze een verbeterd AI-model dat verder gaat dan Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) voor nog snellere suggesties.

Lees de berichten in volgorde om hun leerproces te volgen.

- **Mei 2023** | [GitHub Copilot wordt beter in het begrijpen van jouw code](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mei 2023** | [Binnen GitHub: Werken met de LLM's achter GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juni 2023** | [Hoe je betere prompts schrijft voor GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juli 2023** | [.. GitHub Copilot gaat verder dan Codex met verbeterd AI-model](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [Een ontwikkelaarsgids voor prompt engineering en LLM's](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **September 2023** | [Hoe je een zakelijke LLM-app bouwt: Lessen van GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Je kunt ook hun [Engineering blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) bekijken voor meer berichten zoals [deze](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) die laat zien hoe deze modellen en technieken _toegepast_ worden om echte toepassingen te realiseren.

---

<!--
LESSON TEMPLATE:
Deze unit moet kernconcept #2 behandelen.
Versterk het concept met voorbeelden en referenties.

CONCEPT #2:
Prompt Design.
Ge√Øllustreerd met voorbeelden.
-->

## Prompt Constructie

We hebben gezien waarom prompt engineering belangrijk is - nu gaan we begrijpen hoe prompts _geconstrueerd_ worden, zodat we verschillende technieken kunnen evalueren voor effectiever promptontwerp.

### Basisprompt

Laten we beginnen met de basisprompt: een tekstinvoer die naar het model wordt gestuurd zonder verdere context. Hier is een voorbeeld - wanneer we de eerste paar woorden van het Amerikaanse volkslied naar de OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) sturen, voltooit het onmiddellijk de reactie met de volgende regels, wat het basisvoorspellingsgedrag illustreert.

| Prompt (Invoer)     | Completion (Uitvoer)                                                                                                                        |
| :------------------ | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Het lijkt erop dat je begint met de tekst van "The Star-Spangled Banner," het volkslied van de Verenigde Staten. De volledige tekst is ... |

### Complexe Prompt

Nu voegen we context en instructies toe aan die basisprompt. De [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) stelt ons in staat een complexe prompt te construeren als een verzameling _berichten_ met:

- Input/output-paren die _gebruikers_ invoer en _assistent_ reactie weerspiegelen.
- Systeembericht dat de context voor het gedrag of de persoonlijkheid van de assistent instelt.

Het verzoek heeft nu de onderstaande vorm, waarbij de _tokenisatie_ effectief relevante informatie uit context en gesprek vastlegt. Het veranderen van de systeemcontext kan net zo veel invloed hebben op de kwaliteit van de reacties als de verstrekte gebruikersinvoer.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instructieprompt

In de bovenstaande voorbeelden was de gebruikersprompt een eenvoudige tekstquery die ge√Ønterpreteerd kan worden als een verzoek om informatie. Met _instructie_ prompts kunnen we die tekst gebruiken om een taak gedetailleerder te specificeren, waardoor de AI beter wordt begeleid. Hier is een voorbeeld:

| Prompt (Invoer)                                                                                                                                                                                                                         | Completion (Uitvoer)                                                                                                        | Type Instructie     |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Schrijf een beschrijving van de Burgeroorlog                                                                                                                                                                                            | _leverde een eenvoudige alinea_                                                                                            | Eenvoudig           |
| Schrijf een beschrijving van de Burgeroorlog. Geef belangrijke data en gebeurtenissen en beschrijf hun betekenis                                                                                                                        | _leverde een alinea gevolgd door een lijst van belangrijke datums met beschrijvingen_                                      | Complex             |
| Schrijf een beschrijving van de Burgeroorlog in 1 alinea. Geef 3 opsommingstekens met belangrijke data en hun betekenis. Geef 3 extra opsommingstekens met belangrijke historische figuren en hun bijdragen. Geef de uitvoer als een JSON-bestand | _leverde uitgebreidere details in een tekstvak, geformatteerd als JSON dat je kunt kopi√´ren en plakken naar een bestand en valideren indien nodig_ | Complex. Geformatteerd. |

## Primaire Content

In de bovenstaande voorbeelden was de prompt nog vrij open, waardoor de LLM kon beslissen welk deel van zijn voorgetrainde dataset relevant was. Met het _primaire content_ ontwerppatroon wordt de invoertekst verdeeld in twee delen:

- een instructie (actie)
- relevante content (die de actie be√Ønvloedt)

Hier is een voorbeeld waarbij de instructie is om "vat dit samen in 2 zinnen".

| Prompt (Invoer)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Uitvoer)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter is de vijfde planeet vanaf de zon en de grootste in het zonnestelsel. Het is een gasreus met een massa van een duizendste van die van de zon, maar twee-en-een-half keer die van alle andere planeten in het zonnestelsel samen. Jupiter is een van de helderste objecten die met het blote oog zichtbaar zijn in de nachtelijke hemel en is bekend bij oude beschavingen sinds v√≥√≥r de geschreven geschiedenis. Het is vernoemd naar de Romeinse god Jupiter.[19] Vanuit de aarde gezien kan Jupiter helder genoeg zijn om zijn gereflecteerde licht zichtbare schaduwen te laten werpen,[20] en is gemiddeld het op twee na helderste natuurlijke object in de nachtelijke hemel na de maan en Venus. <br/> **Vat dit samen in 2 korte zinnen** | Jupiter, de vijfde planeet vanaf de zon, is de grootste in het zonnestelsel en staat bekend als een van de helderste objecten in de nachtelijke hemel. Vernoemd naar de Romeinse god Jupiter, is het een gasreus met een massa die twee-en-een-half keer die van alle andere planeten in het zonnestelsel samen is. |

Het primaire contentsegment kan op verschillende manieren worden gebruikt om effectievere instructies te sturen:

- **Voorbeelden** - in plaats van het model expliciet te vertellen wat te doen met een instructie, geef je voorbeelden van wat te doen en laat je het patroon afleiden.
- **Hints** - volg de instructie met een "hint" die de voltooiing aanstuurt, waardoor het model naar relevantere reacties wordt geleid.
- **Sjablonen** - dit zijn herhaalbare 'recepten' voor prompts met placeholders (variabelen) die kunnen worden aangepast met gegevens voor specifieke toepassingen.

Laten we deze in actie bekijken.

### Gebruik van Voorbeelden

Dit is een aanpak waarbij je het primaire content gebruikt om het model "te voeden" met enkele voorbeelden van de gewenste uitvoer voor een gegeven instructie, en het patroon voor de gewenste uitvoer laat afleiden. Afhankelijk van het aantal verstrekte voorbeelden kunnen we zero-shot prompting, one-shot prompting, few-shot prompting etc. hebben.

De prompt bestaat nu uit drie componenten:

- Een taakbeschrijving
- Enkele voorbeelden van de gewenste uitvoer
- Het begin van een nieuw voorbeeld (dat een impliciete taakbeschrijving wordt)

| Leerwijze      | Prompt (Invoer)                                                                                                                                        | Completion (Uitvoer)         |
| :------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot      | "De zon schijnt". Vertaal naar Spaans                                                                                                                | "El Sol est√° brillando".    |
| One-shot       | "De zon schijnt" => ""El Sol est√° brillando". <br> "Het is een koude en winderige dag" =>                                                             | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot       | De speler rende over de honken => Honkbal <br/> De speler sloeg een ace => Tennis <br/> De speler sloeg een zes => Cricket <br/> De speler maakte een slam-dunk => | Basketbal                  |
|                |                                                                                                                                                       |                             |

Let op hoe we expliciete instructies moesten geven ("Vertaal naar Spaans") in zero-shot prompting, maar dit wordt afgeleid in het one-shot prompting voorbeeld. Het few-shot voorbeeld laat zien hoe het toevoegen van meer voorbeelden modellen in staat stelt nauwkeurigere afleidingen te maken zonder extra instructies.

### Prompt Hints

Een andere techniek voor het gebruik van primaire content is het geven van _hints_ in plaats van voorbeelden. In dit geval geven we het model een duwtje in de juiste richting door het _te starten_ met een fragment dat het gewenste responsformaat weerspiegelt. Het model "pakt de hint op" en gaat verder in die lijn.

| Aantal hints | Prompt (Invoer)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Uitvoer)                                                                                                                                                                                                                                                                                       |
| :----------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0            | Jupiter is de vijfde planeet vanaf de zon en de grootste in het zonnestelsel. Het is een gasreus met een massa van een duizendste van die van de zon, maar twee-en-een-half keer die van alle andere planeten in het zonnestelsel samen. Jupiter is een van de helderste objecten die met het blote oog zichtbaar zijn in de nachtelijke hemel en is bekend bij oude beschavingen sinds v√≥√≥r de geschreven geschiedenis. <br/>**Vat Dit Samen**                                       | Jupiter is de grootste planeet in ons zonnestelsel en de vijfde vanaf de zon. Het is een gasreus met een massa van 1/1000e van die van de zon, maar zwaarder dan alle andere planeten samen. Oude beschavingen kennen Jupiter al lang, en het is gemakkelijk zichtbaar in de nachtelijke hemel. |
| 1              | Jupiter is de vijfde planeet vanaf de zon en de grootste in het zonnestelsel. Het is een gasreus met een massa die duizendste is van die van de zon, maar twee√´nhalf keer die van alle andere planeten in het zonnestelsel samen. Jupiter is een van de helderste objecten die met het blote oog zichtbaar zijn aan de nachtelijke hemel en is al bekend bij oude beschavingen sinds v√≥√≥r de geschreven geschiedenis. <br/>**Samenvatting** <br/> Wat we hebben geleerd is dat Jupiter | de vijfde planeet vanaf de zon is en de grootste in het zonnestelsel. Het is een gasreus met een massa die duizendste is van die van de zon, maar twee√´nhalf keer die van alle andere planeten samen. Het is gemakkelijk zichtbaar met het blote oog en is al sinds de oudheid bekend.                        |
| 2              | Jupiter is de vijfde planeet vanaf de zon en de grootste in het zonnestelsel. Het is een gasreus met een massa die duizendste is van die van de zon, maar twee√´nhalf keer die van alle andere planeten in het zonnestelsel samen. Jupiter is een van de helderste objecten die met het blote oog zichtbaar zijn aan de nachtelijke hemel en is al bekend bij oude beschavingen sinds v√≥√≥r de geschreven geschiedenis. <br/>**Samenvatting** <br/> Top 3 feiten die we hebben geleerd:         | 1. Jupiter is de vijfde planeet vanaf de zon en de grootste in het zonnestelsel. <br/> 2. Het is een gasreus met een massa die duizendste is van die van de zon...<br/> 3. Jupiter is al sinds de oudheid zichtbaar met het blote oog ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Prompt Templates

Een prompttemplate is een _vooraf gedefinieerd recept voor een prompt_ dat kan worden opgeslagen en hergebruikt wanneer nodig, om meer consistente gebruikerservaringen op schaal te realiseren. In zijn eenvoudigste vorm is het simpelweg een verzameling van promptvoorbeelden zoals [dit voorbeeld van OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) die zowel de interactieve promptcomponenten (gebruikers- en systeemberichten) als het API-gestuurde aanvraagformaat biedt - om hergebruik te ondersteunen.

In zijn meer complexe vorm, zoals [dit voorbeeld van LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), bevat het _plaatsvervangers_ die kunnen worden vervangen door gegevens uit verschillende bronnen (gebruikersinvoer, systeemcontext, externe gegevensbronnen, enz.) om een prompt dynamisch te genereren. Dit stelt ons in staat om een bibliotheek van herbruikbare prompts te cre√´ren die consistentie in gebruikerservaringen **programmeerbaar** op schaal kunnen ondersteunen.

De echte waarde van templates ligt uiteindelijk in de mogelijkheid om _promptbibliotheken_ te cre√´ren en te publiceren voor specifieke toepassingsdomeinen - waarbij de prompttemplate nu _geoptimaliseerd_ is om toepassingsspecifieke context of voorbeelden te weerspiegelen die de reacties relevanter en nauwkeuriger maken voor de beoogde gebruikersgroep. De [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) repository is een goed voorbeeld van deze aanpak, waarbij een bibliotheek van prompts voor het onderwijsdomein wordt samengesteld met nadruk op belangrijke doelen zoals lesplanning, curriculumontwerp, begeleiding van studenten, enz.

## Ondersteunende inhoud

Als we nadenken over het construeren van prompts als het hebben van een instructie (taak) en een doel (primaire inhoud), dan is _secundaire inhoud_ als extra context die we bieden om **de output op een bepaalde manier te be√Ønvloeden**. Dit kan afstemmingsparameters, opmaak instructies, onderwerp taxonomie√´n, enz. omvatten die het model kunnen helpen om zijn reactie aan te passen aan de gewenste gebruikersdoelen of verwachtingen.

Bijvoorbeeld: Gegeven een cursuscatalogus met uitgebreide metadata (naam, beschrijving, niveau, metatag, docent, enz.) over alle beschikbare cursussen in het curriculum:

- we kunnen een instructie defini√´ren om "de cursuscatalogus voor herfst 2023 samen te vatten"
- we kunnen de primaire inhoud gebruiken om een paar voorbeelden van de gewenste output te geven
- we kunnen de secundaire inhoud gebruiken om de top 5 "tags" van interesse te identificeren.

Nu kan het model een samenvatting geven in het formaat dat wordt getoond door de paar voorbeelden - maar als een resultaat meerdere tags heeft, kan het prioriteit geven aan de 5 tags die in de secundaire inhoud zijn ge√Ødentificeerd.

---

<!--
LESSON TEMPLATE:
Deze unit moet kernconcept #1 behandelen.
Versterk het concept met voorbeelden en referenties.

CONCEPT #3:
Technieken voor prompt engineering.
Wat zijn enkele basistechnieken voor prompt engineering?
Illustreer dit met enkele oefeningen.
-->

## Best practices voor prompting

Nu we weten hoe prompts kunnen worden _geconstrueerd_, kunnen we gaan nadenken over hoe we ze kunnen _ontwerpen_ om best practices te weerspiegelen. We kunnen dit in twee delen bekijken - de juiste _mindset_ hebben en de juiste _technieken_ toepassen.

### Mindset voor prompt engineering

Prompt engineering is een proces van vallen en opstaan, dus houd drie brede leidende factoren in gedachten:

1. **Begrip van het domein is belangrijk.** De nauwkeurigheid en relevantie van de reactie is een functie van het _domein_ waarin die toepassing of gebruiker opereert. Gebruik je intu√Øtie en domeinexpertise om **technieken verder aan te passen**. Definieer bijvoorbeeld _domeinspecifieke persoonlijkheden_ in je systeemprompts, of gebruik _domeinspecifieke templates_ in je gebruikersprompts. Bied secundaire inhoud die domeinspecifieke contexten weerspiegelt, of gebruik _domeinspecifieke aanwijzingen en voorbeelden_ om het model te begeleiden naar vertrouwde gebruikspatronen.

2. **Begrip van het model is belangrijk.** We weten dat modellen van nature stochastisch zijn. Maar modelimplementaties kunnen ook vari√´ren in termen van de trainingsdataset die ze gebruiken (vooraf getrainde kennis), de mogelijkheden die ze bieden (bijv. via API of SDK) en het type inhoud waarvoor ze zijn geoptimaliseerd (bijv. code versus afbeeldingen versus tekst). Begrijp de sterke en zwakke punten van het model dat je gebruikt en gebruik die kennis om _taken te prioriteren_ of _aangepaste templates_ te maken die zijn geoptimaliseerd voor de mogelijkheden van het model.

3. **Iteratie en validatie zijn belangrijk.** Modellen evolueren snel, en dat geldt ook voor de technieken voor prompt engineering. Als domeinexpert heb je mogelijk andere context of criteria voor _jouw_ specifieke toepassing, die mogelijk niet van toepassing zijn op de bredere gemeenschap. Gebruik tools en technieken voor prompt engineering om het construeren van prompts te "starten", en herhaal en valideer de resultaten met je eigen intu√Øtie en domeinexpertise. Leg je inzichten vast en cre√´er een **kennisbasis** (bijv. promptbibliotheken) die door anderen kan worden gebruikt als nieuwe basis voor snellere iteraties in de toekomst.

## Best practices

Laten we nu kijken naar algemene best practices die worden aanbevolen door [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) en [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) practitioners.

| Wat                               | Waarom                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evalueer de nieuwste modellen.    | Nieuwe modelgeneraties hebben waarschijnlijk verbeterde functies en kwaliteit - maar kunnen ook hogere kosten met zich meebrengen. Evalueer ze op impact en neem vervolgens migratiebeslissingen.                                                    |
| Scheid instructies en context     | Controleer of je model/provider _scheidingstekens_ definieert om instructies, primaire en secundaire inhoud duidelijker te onderscheiden. Dit kan modellen helpen om nauwkeuriger gewichten toe te kennen aan tokens.                                 |
| Wees specifiek en duidelijk       | Geef meer details over de gewenste context, uitkomst, lengte, opmaak, stijl, enz. Dit zal zowel de kwaliteit als de consistentie van reacties verbeteren. Leg recepten vast in herbruikbare templates.                                              |
| Wees beschrijvend, gebruik voorbeelden | Modellen reageren mogelijk beter op een "show and tell"-aanpak. Begin met een `zero-shot` aanpak waarbij je een instructie geeft (maar geen voorbeelden) en probeer vervolgens `few-shot` als verfijning, waarbij je enkele voorbeelden van de gewenste output geeft. Gebruik analogie√´n. |
| Gebruik aanwijzingen om reacties te starten | Geef het een duwtje in de richting van een gewenste uitkomst door het enkele leidende woorden of zinnen te geven die het kan gebruiken als startpunt voor de reactie.                                                                                 |
| Herhaal                          | Soms moet je jezelf herhalen voor het model. Geef instructies voor en na je primaire inhoud, gebruik een instructie en een aanwijzing, enz. Herhaal en valideer om te zien wat werkt.                                                             |
| Volgorde is belangrijk            | De volgorde waarin je informatie aan het model presenteert kan invloed hebben op de output, zelfs in de leervoorbeelden, dankzij recency bias. Probeer verschillende opties om te zien wat het beste werkt.                                           |
| Geef het model een "uitweg"       | Geef het model een _fallback_ reactie die het kan geven als het de taak om welke reden dan ook niet kan voltooien. Dit kan de kans verkleinen dat modellen valse of verzonnen reacties genereren.                                                   |
|                                   |                                                                                                                                                                                                                                                   |

Zoals bij elke best practice, onthoud dat _je resultaten kunnen vari√´ren_ afhankelijk van het model, de taak en het domein. Gebruik deze als uitgangspunt en herhaal om te ontdekken wat het beste werkt voor jou. Evalueer je prompt engineering proces voortdurend opnieuw naarmate nieuwe modellen en tools beschikbaar komen, met een focus op schaalbaarheid van processen en kwaliteit van reacties.

<!--
LESSON TEMPLATE:
Deze unit moet een code-uitdaging bieden indien van toepassing

UITDAGING:
Link naar een Jupyter Notebook met alleen de code-opmerkingen in de instructies (code-secties zijn leeg).

OPLOSSING:
Link naar een kopie van dat Notebook met de prompts ingevuld en uitgevoerd, die laat zien wat √©√©n voorbeeld zou kunnen zijn.
-->

## Opdracht

Gefeliciteerd! Je hebt het einde van de les bereikt! Het is tijd om enkele van die concepten en technieken te testen met echte voorbeelden!

Voor onze opdracht gebruiken we een Jupyter Notebook met oefeningen die je interactief kunt voltooien. Je kunt het Notebook ook uitbreiden met je eigen Markdown- en Code-cellen om idee√´n en technieken zelf te verkennen.

### Om te beginnen, fork de repo, en

- (Aanbevolen) Start GitHub Codespaces
- (Alternatief) Clone de repo naar je lokale apparaat en gebruik het met Docker Desktop
- (Alternatief) Open het Notebook met je favoriete Notebook runtime-omgeving.

### Configureer vervolgens je omgevingsvariabelen

- Kopieer het bestand `.env.copy` in de root van de repo naar `.env` en vul de waarden in voor `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` en `AZURE_OPENAI_DEPLOYMENT`. Ga terug naar de [Learning Sandbox sectie](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) om te leren hoe.

### Open vervolgens het Jupyter Notebook

- Selecteer de runtime kernel. Als je optie 1 of 2 gebruikt, selecteer dan gewoon de standaard Python 3.10.x kernel die door de ontwikkelcontainer wordt geleverd.

Je bent helemaal klaar om de oefeningen uit te voeren. Houd er rekening mee dat er hier geen _goede of foute_ antwoorden zijn - het gaat erom opties te verkennen door middel van vallen en opstaan en intu√Øtie op te bouwen voor wat werkt in een bepaald model en toepassingsdomein.

_Om deze reden zijn er geen Code Solution segmenten in deze les. In plaats daarvan bevat het Notebook Markdown-cellen met de titel "Mijn oplossing:" die √©√©n voorbeeldoutput ter referentie tonen._

 <!--
LESSON TEMPLATE:
Sluit de sectie af met een samenvatting en bronnen voor zelfgestuurd leren.
-->

## Kennischeck

Welke van de volgende is een goede prompt die enkele redelijke best practices volgt?

1. Laat me een afbeelding zien van een rode auto
2. Laat me een afbeelding zien van een rode auto van het merk Volvo en model XC90 geparkeerd bij een klif met de zonsondergang
3. Laat me een afbeelding zien van een rode auto van het merk Volvo en model XC90

A: 2, dit is de beste prompt omdat het details geeft over "wat" en specifiek wordt (niet zomaar een auto, maar een specifiek merk en model) en het beschrijft ook de algehele setting. 3 is de volgende beste optie omdat het ook veel beschrijving bevat.

## üöÄ Uitdaging

Kun je de "aanwijzing"-techniek gebruiken met de prompt: Maak de zin af "Laat me een afbeelding zien van een rode auto van het merk Volvo en ". Wat geeft het als reactie, en hoe zou je het verbeteren?

## Goed gedaan! Ga door met leren

Wil je meer leren over verschillende Prompt Engineering concepten? Ga naar de [pagina voor voortgezet leren](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) om andere geweldige bronnen over dit onderwerp te vinden.

Ga verder naar Les 5 waar we kijken naar [geavanceerde prompting technieken](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Disclaimer**:  
Dit document is vertaald met behulp van de AI-vertalingsservice [Co-op Translator](https://github.com/Azure/co-op-translator). Hoewel we streven naar nauwkeurigheid, dient u zich ervan bewust te zijn dat geautomatiseerde vertalingen fouten of onnauwkeurigheden kunnen bevatten. Het originele document in de oorspronkelijke taal moet worden beschouwd als de gezaghebbende bron. Voor kritieke informatie wordt professionele menselijke vertaling aanbevolen. Wij zijn niet aansprakelijk voor misverstanden of verkeerde interpretaties die voortvloeien uit het gebruik van deze vertaling.