<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:28:04+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "ko"
}
-->
# Neural Network Frameworks

우리가 이미 배운 것처럼, 신경망을 효율적으로 학습시키기 위해서는 두 가지가 필요합니다:

* 텐서 연산을 수행하는 것, 예를 들어 곱셈, 덧셈, 그리고 sigmoid나 softmax 같은 함수 계산
* 모든 식의 기울기를 계산하여 경사 하강법 최적화를 수행하는 것

`numpy` 라이브러리는 첫 번째 부분을 처리할 수 있지만, 기울기를 계산하는 메커니즘이 필요합니다. 이전 섹션에서 개발한 프레임워크에서는 `backward` 메서드 안에 모든 미분 함수를 수동으로 프로그래밍해야 했는데, 이는 역전파를 수행합니다. 이상적으로는, 프레임워크가 우리가 정의할 수 있는 *어떤 식*에 대해서도 기울기를 계산할 수 있는 기능을 제공해야 합니다.

또 다른 중요한 점은 GPU나 TPU 같은 특수 연산 장치에서 계산을 수행할 수 있어야 한다는 것입니다. 딥 신경망 학습은 *매우 많은* 계산을 필요로 하며, 이를 GPU에서 병렬 처리할 수 있는 능력이 매우 중요합니다.

> ✅ '병렬 처리(parallelize)'란 여러 장치에 계산을 분산시키는 것을 의미합니다.

현재 가장 인기 있는 두 신경망 프레임워크는 TensorFlow와 PyTorch입니다. 두 프레임워크 모두 CPU와 GPU에서 텐서를 다룰 수 있는 저수준 API를 제공합니다. 저수준 API 위에는 각각 Keras와 PyTorch Lightning이라는 고수준 API도 존재합니다.

Low-Level API | TensorFlow | PyTorch
--------------|------------|---------
High-level API| Keras      | PyTorch

두 프레임워크의 **저수준 API**는 이른바 **계산 그래프(computational graph)**를 구축할 수 있게 해줍니다. 이 그래프는 주어진 입력 파라미터로 출력(보통 손실 함수)을 계산하는 방법을 정의하며, GPU가 있다면 GPU에서 계산을 수행할 수 있습니다. 이 계산 그래프를 미분하고 기울기를 계산하는 함수도 제공되어, 이를 통해 모델 파라미터를 최적화할 수 있습니다.

**고수준 API**는 신경망을 **레이어의 연속(sequence of layers)**으로 간주하여 대부분의 신경망을 훨씬 쉽게 구성할 수 있게 해줍니다. 모델 학습은 보통 데이터를 준비한 후 `fit` 함수를 호출하는 것으로 이루어집니다.

고수준 API는 많은 세부사항을 신경 쓰지 않고도 전형적인 신경망을 빠르게 구성할 수 있게 해줍니다. 반면, 저수준 API는 학습 과정을 훨씬 더 세밀하게 제어할 수 있어, 새로운 신경망 아키텍처를 다룰 때 연구 목적으로 많이 사용됩니다.

또한 두 API를 함께 사용할 수 있다는 점도 중요합니다. 예를 들어, 저수준 API로 자신만의 네트워크 레이어 아키텍처를 개발한 후, 고수준 API로 구성하고 학습하는 더 큰 네트워크 안에 사용할 수 있습니다. 또는 고수준 API로 레이어 시퀀스로 네트워크를 정의하고, 저수준 API로 직접 학습 루프를 작성해 최적화를 수행할 수도 있습니다. 두 API는 동일한 기본 개념을 공유하며, 함께 잘 작동하도록 설계되었습니다.

## Learning

이 강의에서는 PyTorch와 TensorFlow 두 프레임워크 모두에 대한 내용을 제공합니다. 원하는 프레임워크를 선택해 해당 노트북만 학습하면 됩니다. 어떤 프레임워크를 선택할지 고민된다면, 인터넷에서 **PyTorch vs. TensorFlow**에 관한 토론을 참고해 보세요. 두 프레임워크를 모두 살펴보는 것도 이해에 도움이 됩니다.

가능한 경우, 단순함을 위해 고수준 API를 사용할 예정입니다. 하지만 신경망이 어떻게 작동하는지 근본부터 이해하는 것이 중요하다고 생각하기 때문에, 처음에는 저수준 API와 텐서 작업부터 시작합니다. 빠르게 시작하고 싶거나 세부사항 학습에 많은 시간을 쓰고 싶지 않다면, 저수준 API 부분을 건너뛰고 바로 고수준 API 노트북으로 넘어가도 됩니다.

## ✍️ Exercises: Frameworks

다음 노트북에서 학습을 이어가세요:

Low-Level API | TensorFlow+Keras Notebook | PyTorch
--------------|-----------------------------|---------
High-level API| Keras                       | *PyTorch Lightning*

프레임워크를 익힌 후에는 과적합 개념을 다시 살펴봅시다.

# Overfitting

과적합은 머신러닝에서 매우 중요한 개념이며, 이를 정확히 이해하는 것이 매우 중요합니다!

다음 5개의 점(`x`로 그래프에 표시됨)을 근사하는 문제를 생각해 봅시다:

!linear | overfit
-------------------------|--------------------------
**선형 모델, 파라미터 2개** | **비선형 모델, 파라미터 7개**
학습 오차 = 5.3 | 학습 오차 = 0
검증 오차 = 5.1 | 검증 오차 = 20

* 왼쪽은 적절한 직선 근사입니다. 파라미터 수가 적당해서 모델이 점들의 분포를 잘 파악했습니다.
* 오른쪽은 모델이 너무 복잡합니다. 점이 5개뿐인데 파라미터가 7개라 모든 점을 정확히 통과하도록 조정할 수 있어 학습 오차가 0이 됩니다. 하지만 이로 인해 데이터의 올바른 패턴을 이해하지 못해 검증 오차가 매우 높아집니다.

모델의 복잡도(파라미터 수)와 학습 샘플 수 사이에 적절한 균형을 맞추는 것이 매우 중요합니다.

## Why overfitting occurs

  * 학습 데이터가 충분하지 않을 때
  * 모델이 너무 복잡할 때
  * 입력 데이터에 노이즈가 너무 많을 때

## How to detect overfitting

위 그래프에서 보듯, 과적합은 학습 오차는 매우 낮지만 검증 오차가 높은 경우에 감지할 수 있습니다. 보통 학습 중에는 학습 오차와 검증 오차가 모두 감소하다가, 어느 시점에서 검증 오차가 감소를 멈추고 증가하기 시작합니다. 이것이 과적합의 신호이며, 이 시점에서 학습을 중단하거나(또는 모델의 스냅샷을 저장하는 것이) 좋다는 표시입니다.

overfitting

## How to prevent overfitting

과적합이 발생하는 것을 확인했다면, 다음 중 하나를 시도할 수 있습니다:

 * 학습 데이터 양을 늘리기
 * 모델 복잡도를 줄이기
 * 나중에 다룰 Dropout 같은 정규화 기법 사용하기

## Overfitting and Bias-Variance Tradeoff

과적합은 통계학에서 더 일반적인 문제인 편향-분산 균형(Bias-Variance Tradeoff)의 한 사례입니다. 모델의 오차 원인을 살펴보면 두 가지 유형이 있습니다:

* **편향 오차(Bias errors)**는 알고리즘이 학습 데이터와의 관계를 제대로 포착하지 못해 발생합니다. 이는 모델이 충분히 강력하지 않을 때(**과소적합**) 나타납니다.
* **분산 오차(Variance errors)**는 모델이 의미 있는 관계 대신 입력 데이터의 노이즈를 근사할 때 발생합니다(**과적합**).

학습 과정에서 편향 오차는 감소하지만 분산 오차는 증가합니다. 과적합을 방지하기 위해서는 학습을 중단해야 하는데, 이는 수동으로(과적합을 감지했을 때) 하거나 정규화를 도입해 자동으로 할 수 있습니다.

## Conclusion

이번 강의에서는 TensorFlow와 PyTorch 두 인기 AI 프레임워크의 다양한 API 차이점과 매우 중요한 주제인 과적합에 대해 배웠습니다.

## 🚀 Challenge

동봉된 노트북 하단에 '과제(tasks)'가 있습니다. 노트북을 따라가며 과제를 완수해 보세요.

## Review & Self Study

다음 주제에 대해 스스로 조사해 보세요:

- TensorFlow
- PyTorch
- Overfitting

다음 질문에 답해 보세요:

- TensorFlow와 PyTorch의 차이점은 무엇인가요?
- 과적합과 과소적합의 차이는 무엇인가요?

## Assignment

이번 실습에서는 PyTorch 또는 TensorFlow를 사용해 단일 및 다중 레이어 완전 연결 신경망으로 두 가지 분류 문제를 해결해 보세요.

**면책 조항**:  
이 문서는 AI 번역 서비스 [Co-op Translator](https://github.com/Azure/co-op-translator)를 사용하여 번역되었습니다. 정확성을 위해 최선을 다하고 있으나, 자동 번역에는 오류나 부정확한 부분이 있을 수 있음을 유의하시기 바랍니다. 원문은 해당 언어의 원본 문서가 권위 있는 자료로 간주되어야 합니다. 중요한 정보의 경우 전문적인 인간 번역을 권장합니다. 본 번역 사용으로 인해 발생하는 오해나 잘못된 해석에 대해 당사는 책임을 지지 않습니다.