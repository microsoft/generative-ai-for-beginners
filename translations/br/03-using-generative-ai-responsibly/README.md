<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T09:26:42+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "br"
}
-->
# Usando IA Generativa de Forma Respons√°vel

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

√â f√°cil se fascinar com IA e, em particular, com IA generativa, mas √© preciso considerar como us√°-la de forma respons√°vel. Voc√™ deve pensar em coisas como garantir que o resultado seja justo, n√£o prejudicial e mais. Este cap√≠tulo tem como objetivo fornecer o contexto mencionado, o que considerar e como tomar medidas ativas para melhorar o uso da IA.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Por que voc√™ deve priorizar IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Princ√≠pios fundamentais de IA Respons√°vel e como eles se relacionam com IA Generativa.
- Como colocar esses princ√≠pios de IA Respons√°vel em pr√°tica por meio de estrat√©gia e ferramentas.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, voc√™ saber√°:

- A import√¢ncia da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quando pensar e aplicar os princ√≠pios fundamentais de IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quais ferramentas e estrat√©gias est√£o dispon√≠veis para voc√™ colocar o conceito de IA Respons√°vel em pr√°tica.

## Princ√≠pios de IA Respons√°vel

A empolga√ß√£o com IA Generativa nunca esteve t√£o alta. Essa empolga√ß√£o trouxe muitos novos desenvolvedores, aten√ß√£o e financiamento para este espa√ßo. Embora isso seja muito positivo para quem busca construir produtos e empresas usando IA Generativa, tamb√©m √© importante prosseguirmos de forma respons√°vel.

Ao longo deste curso, estamos focando na constru√ß√£o de nossa startup e nosso produto de educa√ß√£o em IA. Usaremos os princ√≠pios de IA Respons√°vel: Justi√ßa, Inclus√£o, Confiabilidade/Seguran√ßa, Seguran√ßa e Privacidade, Transpar√™ncia e Responsabilidade. Com esses princ√≠pios, exploraremos como eles se relacionam com nosso uso de IA Generativa em nossos produtos.

## Por que Priorizar IA Respons√°vel

Ao construir um produto, adotar uma abordagem centrada no ser humano, mantendo o melhor interesse do usu√°rio em mente, leva aos melhores resultados.

A singularidade da IA Generativa √© seu poder de criar respostas √∫teis, informa√ß√µes, orienta√ß√µes e conte√∫do para os usu√°rios. Isso pode ser feito sem muitos passos manuais, o que pode levar a resultados muito impressionantes. Sem planejamento e estrat√©gias adequados, isso tamb√©m pode, infelizmente, levar a resultados prejudiciais para seus usu√°rios, seu produto e a sociedade como um todo.

Vamos analisar alguns (mas n√£o todos) desses resultados potencialmente prejudiciais:

### Alucina√ß√µes

Alucina√ß√µes s√£o um termo usado para descrever quando um LLM produz conte√∫do que √© completamente sem sentido ou algo que sabemos ser factualmente errado com base em outras fontes de informa√ß√£o.

Vamos tomar como exemplo que constru√≠mos um recurso para nossa startup que permite que os alunos fa√ßam perguntas hist√≥ricas a um modelo. Um aluno faz a pergunta `Who was the sole survivor of Titanic?`

O modelo produz uma resposta como a abaixo:

Esta √© uma resposta muito confiante e completa. Infelizmente, est√° incorreta. Mesmo com uma quantidade m√≠nima de pesquisa, algu√©m descobriria que houve mais de um sobrevivente do desastre do Titanic. Para um aluno que est√° come√ßando a pesquisar este t√≥pico, esta resposta pode ser persuasiva o suficiente para n√£o ser questionada e tratada como fato. As consequ√™ncias disso podem levar o sistema de IA a ser pouco confi√°vel e impactar negativamente a reputa√ß√£o de nossa startup.

Com cada itera√ß√£o de qualquer LLM dado, vimos melhorias de desempenho em torno da minimiza√ß√£o de alucina√ß√µes. Mesmo com essa melhoria, n√≥s, como construtores de aplicativos e usu√°rios, ainda precisamos estar cientes dessas limita√ß√µes.

### Conte√∫do Prejudicial

Cobrimos na se√ß√£o anterior quando um LLM produz respostas incorretas ou sem sentido. Outro risco que precisamos estar cientes √© quando um modelo responde com conte√∫do prejudicial.

Conte√∫do prejudicial pode ser definido como:

- Fornecer instru√ß√µes ou encorajar autoles√£o ou dano a certos grupos.
- Conte√∫do odioso ou depreciativo.
- Orientar o planejamento de qualquer tipo de ataque ou atos violentos.
- Fornecer instru√ß√µes sobre como encontrar conte√∫do ilegal ou cometer atos ilegais.
- Exibir conte√∫do sexualmente expl√≠cito.

Para nossa startup, queremos garantir que temos as ferramentas e estrat√©gias certas em vigor para impedir que esse tipo de conte√∫do seja visto pelos alunos.

### Falta de Justi√ßa

Justi√ßa √© definida como ‚Äúgarantir que um sistema de IA esteja livre de preconceitos e discrimina√ß√£o e que trate todos de forma justa e igualit√°ria.‚Äù No mundo da IA Generativa, queremos garantir que vis√µes de mundo excludentes de grupos marginalizados n√£o sejam refor√ßadas pela sa√≠da do modelo.

Esses tipos de sa√≠das n√£o s√£o apenas destrutivos para construir experi√™ncias positivas de produtos para nossos usu√°rios, mas tamb√©m causam mais danos √† sociedade. Como construtores de aplicativos, devemos sempre ter em mente uma base de usu√°rios ampla e diversificada ao construir solu√ß√µes com IA Generativa.

## Como Usar IA Generativa de Forma Respons√°vel

Agora que identificamos a import√¢ncia da IA Generativa Respons√°vel, vamos analisar 4 passos que podemos tomar para construir nossas solu√ß√µes de IA de forma respons√°vel:

### Medir Danos Potenciais

Nos testes de software, testamos as a√ß√µes esperadas de um usu√°rio em um aplicativo. Da mesma forma, testar um conjunto diversificado de prompts que os usu√°rios provavelmente usar√£o √© uma boa maneira de medir danos potenciais.

Como nossa startup est√° construindo um produto educacional, seria bom preparar uma lista de prompts relacionados √† educa√ß√£o. Isso poderia ser para cobrir um determinado assunto, fatos hist√≥ricos e prompts sobre a vida estudantil.

### Mitigar Danos Potenciais

Agora √© hora de encontrar maneiras de prevenir ou limitar o dano potencial causado pelo modelo e suas respostas. Podemos analisar isso em 4 camadas diferentes:

- **Modelo**. Escolher o modelo certo para o caso de uso certo. Modelos maiores e mais complexos como o GPT-4 podem causar mais risco de conte√∫do prejudicial quando aplicados a casos de uso menores e mais espec√≠ficos. Usar seus dados de treinamento para ajuste fino tamb√©m reduz o risco de conte√∫do prejudicial.

- **Sistema de Seguran√ßa**. Um sistema de seguran√ßa √© um conjunto de ferramentas e configura√ß√µes na plataforma que serve o modelo que ajuda a mitigar danos. Um exemplo disso √© o sistema de filtragem de conte√∫do no servi√ßo Azure OpenAI. Os sistemas tamb√©m devem detectar ataques de jailbreak e atividades indesejadas como solicita√ß√µes de bots.

- **Metaprompt**. Metaprompts e grounding s√£o maneiras de direcionar ou limitar o modelo com base em certos comportamentos e informa√ß√µes. Isso pode ser usar entradas do sistema para definir certos limites do modelo. Al√©m disso, fornecer sa√≠das que s√£o mais relevantes para o escopo ou dom√≠nio do sistema.

Tamb√©m pode ser usar t√©cnicas como Gera√ß√£o Aumentada por Recupera√ß√£o (RAG) para fazer o modelo puxar informa√ß√µes apenas de uma sele√ß√£o de fontes confi√°veis. H√° uma li√ß√£o mais adiante neste curso para [construir aplicativos de busca](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Experi√™ncia do Usu√°rio**. A camada final √© onde o usu√°rio interage diretamente com o modelo por meio da interface de nosso aplicativo de alguma forma. Dessa forma, podemos projetar o UI/UX para limitar o usu√°rio nos tipos de entradas que podem enviar ao modelo, bem como texto ou imagens exibidas ao usu√°rio. Ao implantar o aplicativo de IA, tamb√©m devemos ser transparentes sobre o que nosso aplicativo de IA Generativa pode e n√£o pode fazer.

Temos uma li√ß√£o inteira dedicada a [Projetar UX para Aplica√ß√µes de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Avaliar o modelo**. Trabalhar com LLMs pode ser desafiador porque nem sempre temos controle sobre os dados com os quais o modelo foi treinado. Independentemente disso, devemos sempre avaliar o desempenho e as sa√≠das do modelo. Ainda √© importante medir a precis√£o, similaridade, fundamenta√ß√£o e relev√¢ncia da sa√≠da do modelo. Isso ajuda a fornecer transpar√™ncia e confian√ßa aos stakeholders e usu√°rios.

### Operar uma solu√ß√£o de IA Generativa Respons√°vel

Construir uma pr√°tica operacional em torno de suas aplica√ß√µes de IA √© a etapa final. Isso inclui fazer parceria com outras partes de nossa startup como Legal e Seguran√ßa para garantir que estamos em conformidade com todas as pol√≠ticas regulat√≥rias. Antes de lan√ßar, tamb√©m queremos construir planos em torno de entrega, tratamento de incidentes e rollback para evitar qualquer dano aos nossos usu√°rios ao crescer.

## Ferramentas

Embora o trabalho de desenvolver solu√ß√µes de IA Respons√°vel possa parecer muito, √© um trabalho que vale a pena o esfor√ßo. √Ä medida que a √°rea de IA Generativa cresce, mais ferramentas para ajudar os desenvolvedores a integrar responsabilidade em seus fluxos de trabalho de forma eficiente amadurecer√£o. Por exemplo, o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) pode ajudar a detectar conte√∫do e imagens prejudiciais por meio de uma solicita√ß√£o de API.

## Verifica√ß√£o de Conhecimento

Quais s√£o algumas coisas que voc√™ precisa se preocupar para garantir o uso respons√°vel de IA?

1. Que a resposta esteja correta.
2. Uso prejudicial, que a IA n√£o seja usada para fins criminosos.
3. Garantir que a IA esteja livre de preconceitos e discrimina√ß√£o.

A: 2 e 3 est√£o corretos. IA Respons√°vel ajuda voc√™ a considerar como mitigar efeitos prejudiciais e preconceitos e mais.

## üöÄ Desafio

Leia sobre [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) e veja o que voc√™ pode adotar para seu uso.

## √ìtimo Trabalho, Continue Seu Aprendizado

Ap√≥s completar esta li√ß√£o, confira nossa [cole√ß√£o de Aprendizado de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

V√° para a Li√ß√£o 4 onde veremos [Fundamentos de Engenharia de Prompt](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora busquemos precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.