<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:54:31+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "br"
}
-->
# Usando IA Generativa de Forma Respons√°vel

[![Usando IA Generativa de Forma Respons√°vel](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.br.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Clique na imagem acima para assistir ao v√≠deo desta li√ß√£o_

√â f√°cil se encantar com IA e, em especial, com IA generativa, mas √© preciso pensar em como us√°-la de forma respons√°vel. √â importante considerar aspectos como garantir que o resultado seja justo, n√£o prejudicial e muito mais. Este cap√≠tulo tem como objetivo fornecer o contexto mencionado, o que considerar e como tomar medidas ativas para melhorar o uso da IA.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Por que voc√™ deve priorizar IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Princ√≠pios fundamentais da IA Respons√°vel e como eles se relacionam com a IA Generativa.
- Como colocar esses princ√≠pios de IA Respons√°vel em pr√°tica por meio de estrat√©gias e ferramentas.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, voc√™ saber√°:

- A import√¢ncia da IA Respons√°vel ao construir aplica√ß√µes de IA Generativa.
- Quando pensar e aplicar os princ√≠pios fundamentais da IA Respons√°vel ao desenvolver aplica√ß√µes de IA Generativa.
- Quais ferramentas e estrat√©gias est√£o dispon√≠veis para voc√™ colocar o conceito de IA Respons√°vel em pr√°tica.

## Princ√≠pios da IA Respons√°vel

O entusiasmo em torno da IA Generativa nunca foi t√£o grande. Esse interesse trouxe muitos desenvolvedores, aten√ß√£o e investimentos para essa √°rea. Embora isso seja muito positivo para quem deseja criar produtos e empresas usando IA Generativa, √© fundamental que avancemos com responsabilidade.

Ao longo deste curso, estamos focando na constru√ß√£o da nossa startup e do nosso produto educacional de IA. Usaremos os princ√≠pios da IA Respons√°vel: Justi√ßa, Inclusividade, Confiabilidade/Seguran√ßa, Seguran√ßa & Privacidade, Transpar√™ncia e Responsabilidade. Com esses princ√≠pios, exploraremos como eles se relacionam com o uso da IA Generativa em nossos produtos.

## Por Que Voc√™ Deve Priorizar a IA Respons√°vel

Ao construir um produto, adotar uma abordagem centrada no ser humano, mantendo o melhor interesse do usu√°rio em mente, leva aos melhores resultados.

A singularidade da IA Generativa est√° no seu poder de criar respostas √∫teis, informa√ß√µes, orienta√ß√µes e conte√∫dos para os usu√°rios. Isso pode ser feito sem muitos passos manuais, o que pode gerar resultados muito impressionantes. Sem um planejamento e estrat√©gias adequados, infelizmente, tamb√©m pode levar a resultados prejudiciais para seus usu√°rios, seu produto e a sociedade como um todo.

Vamos analisar alguns (mas n√£o todos) desses poss√≠veis resultados prejudiciais:

### Alucina√ß√µes

Alucina√ß√µes √© um termo usado para descrever quando um LLM produz conte√∫do que √© completamente sem sentido ou algo que sabemos ser factualmente incorreto com base em outras fontes de informa√ß√£o.

Por exemplo, imagine que criamos um recurso para nossa startup que permite aos estudantes fazer perguntas hist√≥ricas a um modelo. Um estudante pergunta: `Quem foi o √∫nico sobrevivente do Titanic?`

O modelo gera uma resposta como a abaixo:

![Prompt dizendo "Quem foi o √∫nico sobrevivente do Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fonte: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Esta √© uma resposta muito confiante e detalhada. Infelizmente, est√° incorreta. Mesmo com uma pesquisa m√≠nima, descobrir√≠amos que houve mais de um sobrevivente do desastre do Titanic. Para um estudante que est√° come√ßando a pesquisar esse tema, essa resposta pode ser persuasiva o suficiente para n√£o ser questionada e ser tratada como fato. As consequ√™ncias disso podem tornar o sistema de IA pouco confi√°vel e impactar negativamente a reputa√ß√£o da nossa startup.

A cada nova vers√£o de qualquer LLM, temos visto melhorias no desempenho para minimizar alucina√ß√µes. Mesmo com essa evolu√ß√£o, n√≥s, como desenvolvedores e usu√°rios de aplica√ß√µes, precisamos continuar atentos a essas limita√ß√µes.

### Conte√∫do Prejudicial

Na se√ß√£o anterior, falamos sobre quando um LLM produz respostas incorretas ou sem sentido. Outro risco que precisamos estar atentos √© quando o modelo responde com conte√∫do prejudicial.

Conte√∫do prejudicial pode ser definido como:

- Fornecer instru√ß√µes ou incentivar autoagress√£o ou agress√£o a determinados grupos.
- Conte√∫do odioso ou depreciativo.
- Orientar o planejamento de qualquer tipo de ataque ou ato violento.
- Fornecer instru√ß√µes sobre como encontrar conte√∫do ilegal ou cometer atos ilegais.
- Exibir conte√∫do sexualmente expl√≠cito.

Para nossa startup, queremos garantir que temos as ferramentas e estrat√©gias certas para evitar que esse tipo de conte√∫do seja visto pelos estudantes.

### Falta de Justi√ßa

Justi√ßa √© definida como ‚Äúgarantir que um sistema de IA esteja livre de vieses e discrimina√ß√£o e que trate todos de forma justa e igualit√°ria.‚Äù No mundo da IA Generativa, queremos garantir que vis√µes excludentes sobre grupos marginalizados n√£o sejam refor√ßadas pela sa√≠da do modelo.

Esse tipo de resultado n√£o s√≥ prejudica a constru√ß√£o de experi√™ncias positivas para nossos usu√°rios, como tamb√©m causa danos sociais maiores. Como desenvolvedores de aplica√ß√µes, devemos sempre ter em mente uma base de usu√°rios ampla e diversa ao criar solu√ß√µes com IA Generativa.

## Como Usar IA Generativa de Forma Respons√°vel

Agora que identificamos a import√¢ncia da IA Generativa Respons√°vel, vamos ver 4 passos que podemos seguir para construir nossas solu√ß√µes de IA de forma respons√°vel:

![Ciclo de Mitiga√ß√£o](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.br.png)

### Medir Potenciais Danos

No teste de software, testamos as a√ß√µes esperadas de um usu√°rio em uma aplica√ß√£o. De forma semelhante, testar um conjunto diversificado de prompts que os usu√°rios provavelmente usar√£o √© uma boa forma de medir potenciais danos.

Como nossa startup est√° construindo um produto educacional, seria interessante preparar uma lista de prompts relacionados √† educa√ß√£o. Isso pode incluir cobrir um determinado assunto, fatos hist√≥ricos e prompts sobre a vida estudantil.

### Mitigar Potenciais Danos

Agora √© hora de encontrar maneiras de prevenir ou limitar os potenciais danos causados pelo modelo e suas respostas. Podemos analisar isso em 4 camadas diferentes:

![Camadas de Mitiga√ß√£o](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.br.png)

- **Modelo**. Escolher o modelo certo para o caso de uso correto. Modelos maiores e mais complexos, como o GPT-4, podem apresentar maior risco de gerar conte√∫do prejudicial quando aplicados a casos de uso menores e mais espec√≠ficos. Usar seus dados de treinamento para ajuste fino tamb√©m reduz o risco de conte√∫do prejudicial.

- **Sistema de Seguran√ßa**. Um sistema de seguran√ßa √© um conjunto de ferramentas e configura√ß√µes na plataforma que serve o modelo e ajuda a mitigar danos. Um exemplo disso √© o sistema de filtragem de conte√∫do no servi√ßo Azure OpenAI. Esses sistemas tamb√©m devem detectar ataques de jailbreak e atividades indesejadas, como requisi√ß√µes de bots.

- **Metaprompt**. Metaprompts e grounding s√£o formas de direcionar ou limitar o modelo com base em certos comportamentos e informa√ß√µes. Isso pode ser feito usando entradas do sistema para definir certos limites do modelo. Al√©m disso, fornecer sa√≠das mais relevantes ao escopo ou dom√≠nio do sistema.

Tamb√©m pode envolver t√©cnicas como Retrieval Augmented Generation (RAG), para que o modelo busque informa√ß√µes apenas de uma sele√ß√£o de fontes confi√°veis. H√° uma li√ß√£o mais adiante neste curso sobre [constru√ß√£o de aplica√ß√µes de busca](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Experi√™ncia do Usu√°rio**. A camada final √© onde o usu√°rio interage diretamente com o modelo por meio da interface da nossa aplica√ß√£o. Dessa forma, podemos projetar a UI/UX para limitar os tipos de entradas que o usu√°rio pode enviar ao modelo, bem como o texto ou imagens exibidos para ele. Ao lan√ßar a aplica√ß√£o de IA, tamb√©m devemos ser transparentes sobre o que nossa aplica√ß√£o de IA Generativa pode e n√£o pode fazer.

Temos uma li√ß√£o inteira dedicada a [Design de UX para Aplica√ß√µes de IA](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Avaliar o modelo**. Trabalhar com LLMs pode ser desafiador porque nem sempre temos controle sobre os dados nos quais o modelo foi treinado. Mesmo assim, devemos sempre avaliar o desempenho e as sa√≠das do modelo. √â importante medir a precis√£o, similaridade, fundamenta√ß√£o e relev√¢ncia da sa√≠da. Isso ajuda a fornecer transpar√™ncia e confian√ßa para stakeholders e usu√°rios.

### Operar uma Solu√ß√£o de IA Generativa Respons√°vel

Construir uma pr√°tica operacional em torno das suas aplica√ß√µes de IA √© a etapa final. Isso inclui parceria com outras √°reas da nossa startup, como Jur√≠dico e Seguran√ßa, para garantir conformidade com todas as pol√≠ticas regulat√≥rias. Antes do lan√ßamento, tamb√©m queremos criar planos para entrega, gerenciamento de incidentes e rollback para evitar que qualquer dano aos nossos usu√°rios se amplie.

## Ferramentas

Embora o trabalho de desenvolver solu√ß√µes de IA Respons√°vel possa parecer grande, √© um esfor√ßo que vale muito a pena. √Ä medida que a √°rea de IA Generativa cresce, mais ferramentas para ajudar desenvolvedores a integrar responsabilidade de forma eficiente em seus fluxos de trabalho v√£o amadurecer. Por exemplo, o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) pode ajudar a detectar conte√∫do e imagens prejudiciais via requisi√ß√£o API.

## Verifica√ß√£o de Conhecimento

Quais s√£o algumas coisas que voc√™ precisa considerar para garantir o uso respons√°vel da IA?

1. Que a resposta esteja correta.  
1. Uso prejudicial, que a IA n√£o seja usada para fins criminosos.  
1. Garantir que a IA esteja livre de vieses e discrimina√ß√£o.

R: 2 e 3 est√£o corretos. IA Respons√°vel ajuda voc√™ a considerar como mitigar efeitos prejudiciais, vieses e muito mais.

## üöÄ Desafio

Leia sobre o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) e veja o que voc√™ pode adotar para o seu uso.

## √ìtimo Trabalho, Continue Aprendendo

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de Aprendizado em IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

Siga para a Li√ß√£o 4, onde veremos os [Fundamentos de Engenharia de Prompt](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.