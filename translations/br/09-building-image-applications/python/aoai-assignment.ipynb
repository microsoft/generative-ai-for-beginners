{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construindo um Aplicativo de Geração de Imagens\n",
    "\n",
    "LLMs vão além da geração de texto. Também é possível gerar imagens a partir de descrições em texto. Ter imagens como uma modalidade pode ser extremamente útil em diversas áreas, como MedTech, arquitetura, turismo, desenvolvimento de jogos e muito mais. Neste capítulo, vamos explorar os dois modelos de geração de imagens mais populares: DALL-E e Midjourney.\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Nesta lição, vamos abordar:\n",
    "\n",
    "- Geração de imagens e por que ela é útil.\n",
    "- DALL-E e Midjourney: o que são e como funcionam.\n",
    "- Como você pode construir um aplicativo de geração de imagens.\n",
    "\n",
    "## Objetivos de Aprendizagem\n",
    "\n",
    "Após concluir esta lição, você será capaz de:\n",
    "\n",
    "- Construir um aplicativo de geração de imagens.\n",
    "- Definir limites para seu aplicativo com meta prompts.\n",
    "- Trabalhar com DALL-E e Midjourney.\n",
    "\n",
    "## Por que construir um aplicativo de geração de imagens?\n",
    "\n",
    "Aplicativos de geração de imagens são uma ótima maneira de explorar as capacidades da IA Generativa. Eles podem ser usados, por exemplo, para:\n",
    "\n",
    "- **Edição e síntese de imagens**. Você pode gerar imagens para diversos casos de uso, como edição e síntese de imagens.\n",
    "\n",
    "- **Aplicação em diferentes setores**. Também podem ser usados para gerar imagens para várias áreas, como MedTech, Turismo, Desenvolvimento de Jogos e muito mais.\n",
    "\n",
    "## Cenário: Edu4All\n",
    "\n",
    "Como parte desta lição, continuaremos trabalhando com nossa startup, Edu4All. Os alunos vão criar imagens para suas avaliações; quais imagens criar fica a critério dos alunos, podendo ser ilustrações para seus próprios contos de fadas, criação de novos personagens para suas histórias ou para ajudá-los a visualizar ideias e conceitos.\n",
    "\n",
    "Veja um exemplo do que os alunos da Edu4All poderiam gerar se estivessem trabalhando em sala de aula sobre monumentos:\n",
    "\n",
    "![Startup Edu4All, aula sobre monumentos, Torre Eiffel](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.br.png)\n",
    "\n",
    "usando um prompt como\n",
    "\n",
    "> \"Cachorro ao lado da Torre Eiffel ao amanhecer\"\n",
    "\n",
    "## O que são DALL-E e Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) e [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) são dois dos modelos de geração de imagens mais populares, permitindo que você use prompts para criar imagens.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Vamos começar pelo DALL-E, que é um modelo de IA Generativa que cria imagens a partir de descrições em texto.\n",
    "\n",
    "> [DALL-E é uma combinação de dois modelos, CLIP e atenção difusa](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** é um modelo que gera embeddings, que são representações numéricas de dados, a partir de imagens e textos.\n",
    "\n",
    "- **Atenção difusa** é um modelo que gera imagens a partir dos embeddings. O DALL-E é treinado em um conjunto de dados de imagens e textos e pode ser usado para criar imagens a partir de descrições em texto. Por exemplo, o DALL-E pode ser usado para gerar imagens de um gato de chapéu ou de um cachorro com moicano.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "O Midjourney funciona de forma semelhante ao DALL-E, gerando imagens a partir de prompts em texto. O Midjourney também pode ser usado para criar imagens com prompts como “um gato de chapéu” ou “um cachorro com moicano”.\n",
    "\n",
    "![Imagem gerada pelo Midjourney, pombo mecânico](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Crédito da imagem: Wikipedia, imagem gerada pelo Midjourney*\n",
    "\n",
    "## Como funcionam o DALL-E e o Midjourney\n",
    "\n",
    "Primeiro, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). O DALL-E é um modelo de IA Generativa baseado na arquitetura transformer com um *transformer autoregressivo*.\n",
    "\n",
    "Um *transformer autoregressivo* define como o modelo gera imagens a partir de descrições em texto: ele gera um pixel de cada vez e usa os pixels já gerados para criar o próximo pixel. Esse processo passa por várias camadas de uma rede neural até que a imagem esteja completa.\n",
    "\n",
    "Com esse processo, o DALL-E controla atributos, objetos, características e outros detalhes na imagem gerada. No entanto, o DALL-E 2 e 3 oferecem ainda mais controle sobre a imagem criada,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construindo seu primeiro aplicativo de geração de imagens\n",
    "\n",
    "Então, o que é necessário para criar um aplicativo de geração de imagens? Você vai precisar das seguintes bibliotecas:\n",
    "\n",
    "- **python-dotenv**, é altamente recomendado usar essa biblioteca para manter suas credenciais em um arquivo *.env*, separado do código.\n",
    "- **openai**, essa é a biblioteca que você vai usar para interagir com a API da OpenAI.\n",
    "- **pillow**, para trabalhar com imagens em Python.\n",
    "- **requests**, para facilitar o envio de requisições HTTP.\n",
    "\n",
    "\n",
    "1. Crie um arquivo *.env* com o seguinte conteúdo:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Você encontra essas informações no Portal do Azure, na seção \"Chaves e Endpoint\" do seu recurso.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Reúna as bibliotecas acima em um arquivo chamado *requirements.txt* assim:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. Em seguida, crie um ambiente virtual e instale as bibliotecas:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Para Windows, use os seguintes comandos para criar e ativar seu ambiente virtual:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Adicione o seguinte código em um arquivo chamado *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Vamos explicar esse código:\n",
    "\n",
    "- Primeiro, importamos as bibliotecas necessárias, incluindo a biblioteca OpenAI, a biblioteca dotenv, a biblioteca requests e a biblioteca Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Em seguida, carregamos as variáveis de ambiente do arquivo *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Depois disso, definimos o endpoint, a chave da API do OpenAI, a versão e o tipo.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Agora, geramos a imagem:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    O código acima retorna um objeto JSON que contém a URL da imagem gerada. Podemos usar essa URL para baixar a imagem e salvá-la em um arquivo.\n",
    "\n",
    "- Por fim, abrimos a imagem e usamos o visualizador padrão de imagens para exibi-la:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Mais detalhes sobre a geração da imagem\n",
    "\n",
    "Vamos analisar o código que gera a imagem com mais detalhes:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** é o texto usado como comando para gerar a imagem. Neste caso, estamos usando o prompt \"Coelho em cima de um cavalo, segurando um pirulito, em um campo com neblina onde crescem narcisos\".\n",
    "- **size** é o tamanho da imagem que será gerada. Neste exemplo, estamos gerando uma imagem de 1024x1024 pixels.\n",
    "- **n** é o número de imagens que serão geradas. Aqui, estamos gerando duas imagens.\n",
    "- **temperature** é um parâmetro que controla o grau de aleatoriedade do resultado de um modelo de IA generativa. O valor da temperatura vai de 0 a 1, onde 0 significa que a saída é determinística e 1 significa que a saída é aleatória. O valor padrão é 0.7.\n",
    "\n",
    "Existem mais coisas que você pode fazer com imagens, que veremos na próxima seção.\n",
    "\n",
    "## Capacidades adicionais de geração de imagens\n",
    "\n",
    "Até agora, você viu como conseguimos gerar uma imagem usando poucas linhas em Python. No entanto, há mais possibilidades com imagens.\n",
    "\n",
    "Você também pode fazer o seguinte:\n",
    "\n",
    "- **Fazer edições**. Fornecendo uma imagem existente, uma máscara e um prompt, é possível alterar uma imagem. Por exemplo, você pode adicionar algo em uma parte da imagem. Imagine a imagem do coelho: você pode adicionar um chapéu ao coelho. Para isso, basta fornecer a imagem, uma máscara (identificando a área que será alterada) e um prompt de texto dizendo o que deve ser feito.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    A imagem base teria apenas o coelho, mas a imagem final teria o chapéu no coelho.\n",
    "    \n",
    "- **Criar variações**. \n",
    "    Veja nosso [notebook do OpenAI para mais informações](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora busquemos precisão, esteja ciente de que traduções automáticas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informações críticas, recomenda-se a tradução profissional humana. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes do uso desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:15:05+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "br"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}