<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T15:59:14+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "br"
}
-->
# Explorando e comparando diferentes LLMs

[![Explorando e comparando diferentes LLMs](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.br.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Clique na imagem acima para assistir ao v√≠deo desta li√ß√£o_

Na li√ß√£o anterior, vimos como a IA Generativa est√° transformando o cen√°rio tecnol√≥gico, como os Modelos de Linguagem de Grande Escala (LLMs) funcionam e como uma empresa - como nossa startup - pode aplic√°-los em seus casos de uso e crescer! Neste cap√≠tulo, vamos comparar e contrastar diferentes tipos de modelos de linguagem de grande escala (LLMs) para entender seus pr√≥s e contras.

O pr√≥ximo passo na jornada da nossa startup √© explorar o cen√°rio atual dos LLMs e entender quais s√£o adequados para nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Diferentes tipos de LLMs no cen√°rio atual.
- Testar, iterar e comparar diferentes modelos para seu caso de uso no Azure.
- Como implantar um LLM.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, voc√™ ser√° capaz de:

- Selecionar o modelo certo para seu caso de uso.
- Entender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implantam modelos.

## Entenda os diferentes tipos de LLMs

Os LLMs podem ter v√°rias categoriza√ß√µes com base em sua arquitetura, dados de treinamento e caso de uso. Compreender essas diferen√ßas ajudar√° nossa startup a selecionar o modelo certo para o cen√°rio e entender como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM, e sua escolha depende do que voc√™ pretende usar, dos seus dados, de quanto est√° disposto a pagar e outros fatores.

Dependendo se voc√™ pretende usar os modelos para texto, √°udio, v√≠deo, gera√ß√£o de imagens e assim por diante, pode optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e fala**. Para esse prop√≥sito, modelos do tipo Whisper s√£o uma √≥tima escolha, pois s√£o de uso geral e voltados para reconhecimento de fala. Eles s√£o treinados em √°udio diversificado e podem realizar reconhecimento de fala multil√≠ngue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de imagens**. Para gera√ß√£o de imagens, DALL-E e Midjourney s√£o duas escolhas bem conhecidas. DALL-E √© oferecido pelo Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**. A maioria dos modelos √© treinada para gera√ß√£o de texto, e voc√™ tem uma grande variedade de escolhas, desde GPT-3.5 at√© GPT-4. Eles t√™m custos diferentes, sendo o GPT-4 o mais caro. Vale a pena explorar o [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais modelos melhor atendem √†s suas necessidades em termos de capacidade e custo.

- **Multimodalidade**. Se voc√™ est√° procurando lidar com m√∫ltiplos tipos de dados na entrada e sa√≠da, pode querer explorar modelos como [gpt-4 turbo com vis√£o ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - os lan√ßamentos mais recentes dos modelos OpenAI - que s√£o capazes de combinar processamento de linguagem natural com compreens√£o visual, permitindo intera√ß√µes por meio de interfaces multimodais.

Selecionar um modelo significa obter algumas capacidades b√°sicas, que podem n√£o ser suficientes. Muitas vezes, voc√™ tem dados espec√≠ficos da empresa que precisa informar ao LLM de alguma forma. Existem algumas abordagens diferentes para isso, mais sobre isso nas pr√≥ximas se√ß√µes.

### Modelos Fundamentais versus LLMs

O termo Modelo Fundamental foi [cunhado por pesquisadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que segue alguns crit√©rios, como:

- **Eles s√£o treinados usando aprendizado n√£o supervisionado ou aprendizado auto-supervisionado**, o que significa que s√£o treinados em dados multimodais n√£o rotulados e n√£o requerem anota√ß√£o ou rotulagem humana de dados para seu processo de treinamento.
- **Eles s√£o modelos muito grandes**, baseados em redes neurais muito profundas treinadas em bilh√µes de par√¢metros.
- **Eles s√£o normalmente destinados a servir como uma ‚Äòfunda√ß√£o‚Äô para outros modelos**, ou seja, podem ser usados como ponto de partida para outros modelos serem constru√≠dos sobre eles, o que pode ser feito por meio de ajuste fino.

![Modelos Fundamentais versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.br.png)

Fonte da imagem: [Essential Guide to Foundation Models and Large Language Models | por Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para esclarecer ainda mais essa distin√ß√£o, vamos usar o ChatGPT como exemplo. Para construir a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como modelo fundamental. Isso significa que a OpenAI usou alguns dados espec√≠ficos de chat para criar uma vers√£o ajustada do GPT-3.5 que foi especializada em ter um bom desempenho em cen√°rios de conversa√ß√£o, como chatbots.

![Modelo Fundamental](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.br.png)

Fonte da imagem: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos Open Source versus Propriet√°rios

Outra forma de categorizar os LLMs √© se eles s√£o open source ou propriet√°rios.

Modelos open source s√£o modelos disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. Eles s√£o frequentemente disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para os diversos casos de uso em LLMs. No entanto, nem sempre s√£o otimizados para uso em produ√ß√£o e podem n√£o ter o mesmo desempenho que modelos propriet√°rios. Al√©m disso, o financiamento para modelos open source pode ser limitado, e eles podem n√£o ser mantidos a longo prazo ou atualizados com as pesquisas mais recentes. Exemplos de modelos open source populares incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) e [LLaMA](https://llama.meta.com).

Modelos propriet√°rios s√£o modelos que pertencem a uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Esses modelos s√£o frequentemente otimizados para uso em produ√ß√£o. No entanto, n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para serem usados. Tamb√©m, os usu√°rios n√£o t√™m controle sobre os dados usados para treinar o modelo, o que significa que devem confiar no propriet√°rio do modelo para garantir o compromisso com a privacidade dos dados e o uso respons√°vel da IA. Exemplos de modelos propriet√°rios populares incluem [Modelos OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Gera√ß√£o de Imagens versus Gera√ß√£o de Texto e C√≥digo

Os LLMs tamb√©m podem ser categorizados pelo tipo de sa√≠da que geram.

Embeddings s√£o um conjunto de modelos que podem converter texto em uma forma num√©rica, chamada embedding, que √© uma representa√ß√£o num√©rica do texto de entrada. Embeddings facilitam para as m√°quinas entenderem as rela√ß√µes entre palavras ou frases e podem ser consumidos como entradas por outros modelos, como modelos de classifica√ß√£o ou modelos de agrupamento que t√™m melhor desempenho com dados num√©ricos. Modelos de embedding s√£o frequentemente usados para aprendizado por transfer√™ncia, onde um modelo √© constru√≠do para uma tarefa substituta para a qual h√° uma abund√¢ncia de dados, e ent√£o os pesos do modelo (embeddings) s√£o reutilizados para outras tarefas subsequentes. Um exemplo dessa categoria √© [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.br.png)

Modelos de gera√ß√£o de imagens s√£o modelos que geram imagens. Esses modelos s√£o frequentemente usados para edi√ß√£o de imagens, s√≠ntese de imagens e tradu√ß√£o de imagens. Modelos de gera√ß√£o de imagens s√£o frequentemente treinados em grandes conjuntos de dados de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novas imagens ou editar imagens existentes com t√©cnicas de inpainting, super-resolu√ß√£o e coloriza√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [Modelos Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Gera√ß√£o de Imagens](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.br.png)

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que geram texto ou c√≥digo. Esses modelos s√£o frequentemente usados para sumariza√ß√£o de texto, tradu√ß√£o e resposta a perguntas. Modelos de gera√ß√£o de texto s√£o frequentemente treinados em grandes conjuntos de dados de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novo texto ou responder perguntas. Modelos de gera√ß√£o de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o frequentemente treinados em grandes conjuntos de dados de c√≥digo, como GitHub, e podem ser usados para gerar novo c√≥digo ou corrigir bugs em c√≥digo existente.

![Gera√ß√£o de Texto e C√≥digo](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.br.png)

### Encoder-Decoder versus Apenas Decoder

Para falar sobre os diferentes tipos de arquiteturas de LLMs, vamos usar uma analogia.

Imagine que seu gerente lhe deu a tarefa de escrever um quiz para os alunos. Voc√™ tem dois colegas; um √© respons√°vel por criar o conte√∫do e o outro por revis√°-lo.

O criador de conte√∫do √© como um modelo Apenas Decoder, ele pode olhar para o t√≥pico e ver o que voc√™ j√° escreveu e ent√£o criar um curso com base nisso. Ele √© muito bom em escrever conte√∫do envolvente e informativo, mas n√£o √© muito bom em entender o t√≥pico e os objetivos de aprendizado. Alguns exemplos de modelos Apenas Decoder s√£o os modelos da fam√≠lia GPT, como GPT-3.

O revisor √© como um modelo Apenas Encoder, ele olha para o curso escrito e as respostas, percebendo a rela√ß√£o entre eles e entendendo o contexto, mas n√£o √© bom em gerar conte√∫do. Um exemplo de modelo Apenas Encoder seria o BERT.

Imagine que tamb√©m podemos ter algu√©m que possa criar e revisar o quiz, este √© um modelo Encoder-Decoder. Alguns exemplos seriam BART e T5.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre um servi√ßo e um modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos em Nuvem e √© frequentemente uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo e √© frequentemente um modelo fundamental, como um LLM.

Servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e geralmente mais f√°ceis de usar do que modelos, por meio de uma interface gr√°fica. No entanto, servi√ßos nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para serem usados, em troca de aproveitar os equipamentos e recursos do propriet√°rio do servi√ßo, otimizando despesas e escalando facilmente. Um exemplo de servi√ßo √© o [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano de pagamento conforme o uso, ou seja, os usu√°rios s√£o cobrados proporcionalmente ao quanto utilizam o servi√ßo. Al√©m disso, o Azure OpenAI Service oferece seguran√ßa de n√≠vel empresarial e um framework de IA respons√°vel sobre as capacidades dos modelos.

Modelos s√£o apenas a Rede Neural, com os par√¢metros, pesos e outros. Permitem que empresas os executem localmente, por√©m, seria necess√°rio comprar equipamentos, construir uma estrutura para escalar e adquirir uma licen√ßa ou usar um modelo open source. Um modelo como o LLaMA est√° dispon√≠vel para uso, exigindo poder computacional para executar o modelo.

## Como testar e iterar com diferentes modelos para entender o desempenho no Azure

Depois que nossa equipe explorou o cen√°rio atual dos LLMs e identificou alguns bons candidatos para seus cen√°rios, o pr√≥ximo passo √© test√°-los com seus dados e em sua carga de trabalho. Este √© um processo iterativo, realizado por meio de experimentos e medi√ß√µes.
A maioria dos modelos mencionados nos par√°grafos anteriores (modelos da OpenAI, modelos de c√≥digo aberto como Llama2 e transformers da Hugging Face) est√£o dispon√≠veis no [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) no [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √© uma plataforma em nuvem projetada para desenvolvedores criarem aplica√ß√µes de IA generativa e gerenciarem todo o ciclo de desenvolvimento - desde a experimenta√ß√£o at√© a avalia√ß√£o - combinando todos os servi√ßos de IA do Azure em um √∫nico hub com uma interface gr√°fica pr√°tica. O Cat√°logo de Modelos no Azure AI Studio permite ao usu√°rio:

- Encontrar o Modelo Base de interesse no cat√°logo - seja propriet√°rio ou de c√≥digo aberto, filtrando por tarefa, licen√ßa ou nome. Para melhorar a busca, os modelos est√£o organizados em cole√ß√µes, como a cole√ß√£o Azure OpenAI, cole√ß√£o Hugging Face e outras.

![Cat√°logo de modelos](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.br.png)

- Revisar o cart√£o do modelo, incluindo uma descri√ß√£o detalhada do uso pretendido e dados de treinamento, exemplos de c√≥digo e resultados de avalia√ß√£o na biblioteca interna de avalia√ß√µes.

![Cart√£o do modelo](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.br.png)

- Comparar benchmarks entre modelos e conjuntos de dados dispon√≠veis na ind√∫stria para avaliar qual atende ao cen√°rio de neg√≥cios, atrav√©s do painel [Benchmarks de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarks de modelos](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.br.png)

- Ajustar o modelo com dados de treinamento personalizados para melhorar o desempenho do modelo em uma carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e rastreamento do Azure AI Studio.

![Ajuste de modelo](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.br.png)

- Implantar o modelo pr√©-treinado original ou a vers√£o ajustada para uma infer√™ncia remota em tempo real - computa√ß√£o gerenciada - ou endpoint de API sem servidor - [pagamento conforme o uso](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - para permitir que as aplica√ß√µes o consumam.

![Implanta√ß√£o de modelo](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.br.png)

> [!NOTE]
> Nem todos os modelos no cat√°logo est√£o atualmente dispon√≠veis para ajuste e/ou implanta√ß√£o com pagamento conforme o uso. Verifique o cart√£o do modelo para detalhes sobre as capacidades e limita√ß√µes do modelo.

## Melhorando os resultados de LLM

Exploramos com nossa equipe de startup diferentes tipos de LLMs e uma plataforma em nuvem (Azure Machine Learning) que nos permite comparar diferentes modelos, avali√°-los em dados de teste, melhorar o desempenho e implant√°-los em endpoints de infer√™ncia.

Mas quando eles devem considerar ajustar um modelo em vez de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias abordagens que uma empresa pode usar para obter os resultados necess√°rios de um LLM. Voc√™ pode selecionar diferentes tipos de modelos com diferentes graus de treinamento ao implantar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens diferentes:

- **Engenharia de prompts com contexto**. A ideia √© fornecer contexto suficiente ao fazer o prompt para garantir que voc√™ obtenha as respostas necess√°rias.

- **Gera√ß√£o Aumentada por Recupera√ß√£o, RAG**. Seus dados podem estar em um banco de dados ou endpoint web, por exemplo. Para garantir que esses dados, ou um subconjunto deles, sejam inclu√≠dos no momento do prompt, voc√™ pode buscar os dados relevantes e torn√°-los parte do prompt do usu√°rio.

- **Modelo ajustado**. Aqui, voc√™ treinou o modelo adicionalmente com seus pr√≥prios dados, o que levou o modelo a ser mais preciso e responsivo √†s suas necessidades, mas pode ser caro.

![Implanta√ß√£o de LLMs](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.br.png)

Fonte da imagem: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Engenharia de Prompts com Contexto

LLMs pr√©-treinados funcionam muito bem em tarefas gerais de linguagem natural, mesmo sendo chamados com um prompt curto, como uma frase para completar ou uma pergunta ‚Äì o chamado aprendizado ‚Äúzero-shot‚Äù.

No entanto, quanto mais o usu√°rio puder enquadrar sua consulta, com uma solicita√ß√£o detalhada e exemplos ‚Äì o Contexto ‚Äì mais precisa e pr√≥xima das expectativas do usu√°rio ser√° a resposta. Nesse caso, falamos de aprendizado ‚Äúone-shot‚Äù se o prompt incluir apenas um exemplo e ‚Äúfew-shot learning‚Äù se incluir v√°rios exemplos. A engenharia de prompts com contexto √© a abordagem mais econ√¥mica para come√ßar.

### Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)

LLMs t√™m a limita√ß√£o de que s√≥ podem usar os dados que foram utilizados durante seu treinamento para gerar uma resposta. Isso significa que eles n√£o sabem nada sobre fatos que ocorreram ap√≥s seu processo de treinamento e n√£o podem acessar informa√ß√µes n√£o p√∫blicas (como dados da empresa). 

Isso pode ser superado atrav√©s do RAG, uma t√©cnica que aumenta o prompt com dados externos na forma de fragmentos de documentos, considerando os limites de comprimento do prompt. Isso √© suportado por ferramentas de banco de dados vetorial (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam os fragmentos √∫teis de fontes de dados pr√©-definidas variadas e os adicionam ao Contexto do prompt.

Essa t√©cnica √© muito √∫til quando uma empresa n√£o tem dados suficientes, tempo suficiente ou recursos para ajustar um LLM, mas ainda deseja melhorar o desempenho em uma carga de trabalho espec√≠fica e reduzir os riscos de fabrica√ß√µes, ou seja, distor√ß√µes da realidade ou conte√∫do prejudicial.

### Modelo Ajustado

O ajuste √© um processo que aproveita o aprendizado por transfer√™ncia para ‚Äòadaptar‚Äô o modelo a uma tarefa espec√≠fica ou resolver um problema espec√≠fico. Diferentemente do aprendizado few-shot e do RAG, resulta em um novo modelo sendo gerado, com pesos e vieses atualizados. Ele requer um conjunto de exemplos de treinamento consistindo em uma √∫nica entrada (o prompt) e sua sa√≠da associada (a conclus√£o). 

Essa seria a abordagem preferida se:

- **Usando modelos ajustados**. Uma empresa gostaria de usar modelos ajustados menos capazes (como modelos de incorpora√ß√£o) em vez de modelos de alto desempenho, resultando em uma solu√ß√£o mais econ√¥mica e r√°pida.

- **Considerando lat√™ncia**. A lat√™ncia √© importante para um caso de uso espec√≠fico, ent√£o n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que devem ser aprendidos pelo modelo n√£o se encaixa no limite de comprimento do prompt.

- **Mantendo-se atualizado**. Uma empresa tem muitos dados de alta qualidade e r√≥tulos de verdade base e os recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo Treinado

Treinar um LLM do zero √©, sem d√∫vida, a abordagem mais dif√≠cil e complexa de adotar, exigindo quantidades massivas de dados, recursos qualificados e poder computacional adequado. Essa op√ß√£o deve ser considerada apenas em um cen√°rio onde uma empresa tem um caso de uso espec√≠fico para o dom√≠nio e uma grande quantidade de dados centrados no dom√≠nio.

## Verifica√ß√£o de conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de conclus√£o de LLM?

1. Engenharia de prompts com contexto  
1. RAG  
1. Modelo ajustado  

A:3, se voc√™ tiver tempo, recursos e dados de alta qualidade, o ajuste √© a melhor op√ß√£o para se manter atualizado. No entanto, se voc√™ est√° buscando melhorias e n√£o tem tempo, vale considerar o RAG primeiro.

## üöÄ Desafio

Leia mais sobre como voc√™ pode [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para sua empresa.

## √ìtimo trabalho, continue aprendendo

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de aprendizado de IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA generativa!

V√° para a Li√ß√£o 3, onde veremos como [construir com IA generativa de forma respons√°vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional feita por humanos. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.