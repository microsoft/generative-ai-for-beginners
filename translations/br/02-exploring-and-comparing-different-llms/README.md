<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:23:14+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "br"
}
-->
# Explorando e comparando diferentes LLMs

[![Explorando e comparando diferentes LLMs](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.br.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Clique na imagem acima para assistir ao v√≠deo desta aula_

Na li√ß√£o anterior, vimos como a IA Generativa est√° transformando o cen√°rio tecnol√≥gico, como funcionam os Large Language Models (LLMs) e como uma empresa ‚Äî como nossa startup ‚Äî pode aplic√°-los em seus casos de uso para crescer! Neste cap√≠tulo, vamos comparar e contrastar diferentes tipos de grandes modelos de linguagem (LLMs) para entender seus pr√≥s e contras.

O pr√≥ximo passo na jornada da nossa startup √© explorar o cen√°rio atual dos LLMs e entender quais s√£o adequados para nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o abordar√°:

- Diferentes tipos de LLMs no cen√°rio atual.
- Testar, iterar e comparar diferentes modelos para seu caso de uso no Azure.
- Como implantar um LLM.

## Objetivos de Aprendizagem

Ap√≥s concluir esta li√ß√£o, voc√™ ser√° capaz de:

- Selecionar o modelo certo para seu caso de uso.
- Entender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implantam modelos.

## Entendendo os diferentes tipos de LLMs

LLMs podem ser categorizados de v√°rias formas, com base em sua arquitetura, dados de treinamento e caso de uso. Compreender essas diferen√ßas ajudar√° nossa startup a escolher o modelo certo para o cen√°rio, al√©m de entender como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM; a escolha depende do que voc√™ pretende usar, dos seus dados, do quanto est√° disposto a investir e outros fatores.

Dependendo se voc√™ pretende usar os modelos para texto, √°udio, v√≠deo, gera√ß√£o de imagens, entre outros, pode optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e fala**. Para esse prop√≥sito, modelos do tipo Whisper s√£o uma √≥tima escolha, pois s√£o de uso geral e focados em reconhecimento de fala. S√£o treinados com √°udios diversos e podem realizar reconhecimento de fala multil√≠ngue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de imagens**. Para gera√ß√£o de imagens, DALL-E e Midjourney s√£o duas op√ß√µes muito conhecidas. O DALL-E √© oferecido pelo Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**. A maioria dos modelos √© treinada para gera√ß√£o de texto, e voc√™ tem uma grande variedade de op√ß√µes, desde GPT-3.5 at√© GPT-4. Eles t√™m custos variados, sendo o GPT-4 o mais caro. Vale a pena explorar o [playground do Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais modelos atendem melhor √†s suas necessidades em termos de capacidade e custo.

- **Multimodalidade**. Se voc√™ deseja trabalhar com m√∫ltiplos tipos de dados na entrada e sa√≠da, pode considerar modelos como [gpt-4 turbo com vis√£o ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) ‚Äî os lan√ßamentos mais recentes da OpenAI ‚Äî que combinam processamento de linguagem natural com compreens√£o visual, permitindo intera√ß√µes por meio de interfaces multimodais.

Selecionar um modelo significa obter algumas capacidades b√°sicas, que podem n√£o ser suficientes. Frequentemente, voc√™ tem dados espec√≠ficos da empresa que precisa informar ao LLM de alguma forma. Existem algumas op√ß√µes para isso, que veremos nas pr√≥ximas se√ß√µes.

### Foundation Models versus LLMs

O termo Foundation Model foi [criado por pesquisadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que segue alguns crit√©rios, tais como:

- **S√£o treinados usando aprendizado n√£o supervisionado ou auto-supervisionado**, ou seja, s√£o treinados com dados multimodais n√£o rotulados, sem necessidade de anota√ß√£o humana para o processo de treinamento.
- **S√£o modelos muito grandes**, baseados em redes neurais profundas treinadas com bilh√µes de par√¢metros.
- **Normalmente servem como ‚Äòfunda√ß√£o‚Äô para outros modelos**, ou seja, podem ser usados como ponto de partida para construir outros modelos, por meio de fine-tuning.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.br.png)

Fonte da imagem: [Essential Guide to Foundation Models and Large Language Models | por Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para esclarecer melhor essa distin√ß√£o, vamos usar o ChatGPT como exemplo. Para construir a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como foundation model. Isso significa que a OpenAI usou dados espec√≠ficos de chat para criar uma vers√£o ajustada do GPT-3.5, especializada em se sair bem em cen√°rios conversacionais, como chatbots.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.br.png)

Fonte da imagem: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos Open Source versus Propriet√°rios

Outra forma de categorizar LLMs √© se s√£o open source ou propriet√°rios.

Modelos open source s√£o disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. Frequentemente, s√£o disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para diferentes casos de uso. No entanto, nem sempre s√£o otimizados para uso em produ√ß√£o e podem n√£o ter desempenho t√£o bom quanto modelos propriet√°rios. Al√©m disso, o financiamento para modelos open source pode ser limitado, e eles podem n√£o ser mantidos a longo prazo ou atualizados com as pesquisas mais recentes. Exemplos populares de modelos open source incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) e [LLaMA](https://llama.meta.com).

Modelos propriet√°rios s√£o de propriedade de uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Geralmente, s√£o otimizados para uso em produ√ß√£o. No entanto, n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, nem sempre s√£o gratuitos, podendo exigir assinatura ou pagamento para uso. Os usu√°rios tamb√©m n√£o t√™m controle sobre os dados usados para treinar o modelo, devendo confiar no propriet√°rio para garantir privacidade e uso respons√°vel da IA. Exemplos populares de modelos propriet√°rios incluem [modelos OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) e [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Gera√ß√£o de Imagens versus Gera√ß√£o de Texto e C√≥digo

LLMs tamb√©m podem ser categorizados pelo tipo de sa√≠da que geram.

Embeddings s√£o modelos que convertem texto em uma forma num√©rica, chamada embedding, que √© uma representa√ß√£o num√©rica do texto de entrada. Embeddings facilitam para as m√°quinas entenderem as rela√ß√µes entre palavras ou senten√ßas e podem ser usados como entrada para outros modelos, como classificadores ou modelos de agrupamento, que t√™m melhor desempenho com dados num√©ricos. Modelos de embedding s√£o frequentemente usados para transfer learning, onde um modelo √© constru√≠do para uma tarefa substituta com muitos dados dispon√≠veis, e depois os pesos do modelo (embeddings) s√£o reutilizados para outras tarefas. Um exemplo dessa categoria s√£o os [embeddings OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.br.png)

Modelos de gera√ß√£o de imagens s√£o modelos que criam imagens. S√£o usados para edi√ß√£o, s√≠ntese e tradu√ß√£o de imagens. Geralmente, s√£o treinados em grandes conjuntos de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem gerar imagens novas ou editar imagens existentes com t√©cnicas como inpainting, super-resolu√ß√£o e coloriza√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [modelos Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Gera√ß√£o de imagens](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.br.png)

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que produzem texto ou c√≥digo. S√£o usados para sumariza√ß√£o, tradu√ß√£o e respostas a perguntas. Modelos de texto s√£o treinados em grandes conjuntos de dados textuais, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem gerar texto novo ou responder perguntas. Modelos de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o treinados em grandes conjuntos de c√≥digo, como GitHub, e podem gerar c√≥digo novo ou corrigir bugs em c√≥digo existente.

![Gera√ß√£o de texto e c√≥digo](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.br.png)

### Encoder-Decoder versus Decoder-only

Para falar sobre os diferentes tipos de arquiteturas de LLMs, vamos usar uma analogia.

Imagine que seu gerente pediu para voc√™ criar um quiz para os alunos. Voc√™ tem dois colegas; um √© respons√°vel por criar o conte√∫do e o outro por revisar.

O criador de conte√∫do √© como um modelo Decoder-only, ele pode olhar para o tema e ver o que voc√™ j√° escreveu, e ent√£o escrever um curso baseado nisso. Eles s√£o muito bons em criar conte√∫do envolvente e informativo, mas n√£o s√£o t√£o bons em entender o tema e os objetivos de aprendizagem. Alguns exemplos de modelos Decoder s√£o os da fam√≠lia GPT, como o GPT-3.

O revisor √© como um modelo Encoder-only, ele analisa o curso escrito e as respostas, percebendo a rela√ß√£o entre eles e entendendo o contexto, mas n√£o √© bom em gerar conte√∫do. Um exemplo de modelo Encoder-only seria o BERT.

Agora, imagine que pud√©ssemos ter algu√©m que criasse e revisasse o quiz; esse √© um modelo Encoder-Decoder. Alguns exemplos s√£o BART e T5.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre servi√ßo e modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos em Nuvem, e geralmente √© uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo, e geralmente √© um foundation model, como um LLM.

Servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e geralmente s√£o mais f√°ceis de usar do que modelos, por meio de uma interface gr√°fica. No entanto, servi√ßos nem sempre s√£o gratuitos e podem exigir assinatura ou pagamento, em troca do uso dos equipamentos e recursos do provedor, otimizando custos e facilitando a escalabilidade. Um exemplo de servi√ßo √© o [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano pay-as-you-go, ou seja, os usu√°rios pagam proporcionalmente ao uso. Al√©m disso, o Azure OpenAI Service oferece seguran√ßa de n√≠vel empresarial e um framework de IA respons√°vel sobre as capacidades dos modelos.

Modelos s√£o apenas a Rede Neural, com par√¢metros, pesos e outros. Permitem que empresas rodem localmente, mas para isso precisam comprar equipamentos, montar uma estrutura para escalar e adquirir licen√ßa ou usar um modelo open source. Um modelo como o LLaMA est√° dispon√≠vel para uso, exigindo poder computacional para rodar.

## Como testar e iterar com diferentes modelos para entender o desempenho no Azure

Depois que nossa equipe explorou o cen√°rio atual dos LLMs e identificou bons candidatos para seus cen√°rios, o pr√≥ximo passo √© test√°-los com seus dados e carga de trabalho. Esse √© um processo iterativo, feito por meio de experimentos e medi√ß√µes.
A maioria dos modelos que mencionamos nos par√°grafos anteriores (modelos OpenAI, modelos open source como Llama2 e transformers do Hugging Face) est√£o dispon√≠veis no [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) no [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √© uma plataforma na nuvem projetada para desenvolvedores criarem aplica√ß√µes de IA generativa e gerenciarem todo o ciclo de vida do desenvolvimento ‚Äì desde a experimenta√ß√£o at√© a avalia√ß√£o ‚Äì combinando todos os servi√ßos de IA do Azure em um √∫nico hub com uma interface gr√°fica pr√°tica. O Cat√°logo de Modelos no Azure AI Studio permite ao usu√°rio:

- Encontrar o Modelo Base de interesse no cat√°logo ‚Äì seja propriet√°rio ou open source, filtrando por tarefa, licen√ßa ou nome. Para facilitar a busca, os modelos est√£o organizados em cole√ß√µes, como a cole√ß√£o Azure OpenAI, cole√ß√£o Hugging Face, entre outras.

![Cat√°logo de modelos](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.br.png)

- Revisar a ficha t√©cnica do modelo, incluindo uma descri√ß√£o detalhada do uso pretendido e dos dados de treinamento, exemplos de c√≥digo e resultados de avalia√ß√£o na biblioteca interna de avalia√ß√µes.

![Ficha t√©cnica do modelo](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.br.png)

- Comparar benchmarks entre modelos e conjuntos de dados dispon√≠veis no mercado para avaliar qual atende melhor ao cen√°rio de neg√≥cio, por meio do painel [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarks de modelos](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.br.png)

- Ajustar finamente o modelo com dados de treinamento personalizados para melhorar o desempenho em uma carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e rastreamento do Azure AI Studio.

![Ajuste fino do modelo](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.br.png)

- Implantar o modelo pr√©-treinado original ou a vers√£o ajustada para infer√™ncia remota em tempo real ‚Äì computa√ß√£o gerenciada ‚Äì ou endpoint de API serverless ‚Äì [pague conforme o uso](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) ‚Äì para permitir que aplica√ß√µes o consumam.

![Implanta√ß√£o do modelo](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.br.png)


> [!NOTE]
> Nem todos os modelos no cat√°logo est√£o dispon√≠veis atualmente para ajuste fino e/ou implanta√ß√£o pay-as-you-go. Verifique a ficha t√©cnica do modelo para detalhes sobre suas capacidades e limita√ß√µes.

## Melhorando os resultados de LLM

Exploramos com nossa equipe de startup diferentes tipos de LLMs e uma plataforma na nuvem (Azure Machine Learning) que nos permite comparar modelos, avali√°-los com dados de teste, melhorar o desempenho e implant√°-los em endpoints de infer√™ncia.

Mas quando considerar ajustar finamente um modelo em vez de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias estrat√©gias que uma empresa pode usar para obter os resultados desejados de um LLM. Voc√™ pode escolher diferentes tipos de modelos com variados graus de treinamento ao implantar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens:

- **Engenharia de prompt com contexto**. A ideia √© fornecer contexto suficiente no prompt para garantir que voc√™ obtenha as respostas necess√°rias.

- **Retrieval Augmented Generation, RAG**. Seus dados podem estar em um banco de dados ou endpoint web, por exemplo. Para garantir que esses dados, ou um subconjunto deles, sejam inclu√≠dos no momento do prompt, voc√™ pode buscar os dados relevantes e incorpor√°-los ao prompt do usu√°rio.

- **Modelo ajustado finamente**. Aqui, voc√™ treina o modelo adicionalmente com seus pr√≥prios dados, o que torna o modelo mais preciso e responsivo √†s suas necessidades, mas pode ser custoso.

![Implanta√ß√£o de LLMs](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.br.png)

Fonte da imagem: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Engenharia de Prompt com Contexto

LLMs pr√©-treinados funcionam muito bem em tarefas gerais de linguagem natural, mesmo quando chamados com um prompt curto, como uma frase para completar ou uma pergunta ‚Äì o chamado aprendizado ‚Äúzero-shot‚Äù.

No entanto, quanto mais o usu√°rio conseguir enquadrar sua consulta, com um pedido detalhado e exemplos ‚Äì o Contexto ‚Äì mais precisa e pr√≥xima das expectativas do usu√°rio ser√° a resposta. Nesse caso, falamos em ‚Äúone-shot‚Äù learning se o prompt incluir apenas um exemplo e ‚Äúfew-shot learning‚Äù se incluir m√∫ltiplos exemplos. Engenharia de prompt com contexto √© a abordagem mais econ√¥mica para come√ßar.

### Retrieval Augmented Generation (RAG)

LLMs t√™m a limita√ß√£o de usar apenas os dados com os quais foram treinados para gerar uma resposta. Isso significa que eles n√£o sabem nada sobre fatos ocorridos ap√≥s o treinamento e n√£o podem acessar informa√ß√µes n√£o p√∫blicas (como dados internos da empresa).  
Isso pode ser superado com RAG, uma t√©cnica que amplia o prompt com dados externos na forma de trechos de documentos, respeitando os limites de tamanho do prompt. Isso √© suportado por ferramentas de banco de dados vetoriais (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam os trechos √∫teis de v√°rias fontes de dados pr√©-definidas e os adicionam ao contexto do prompt.

Essa t√©cnica √© muito √∫til quando uma empresa n√£o tem dados suficientes, tempo ou recursos para ajustar finamente um LLM, mas ainda deseja melhorar o desempenho em uma carga de trabalho espec√≠fica e reduzir riscos de inven√ß√µes, ou seja, distor√ß√µes da realidade ou conte√∫do prejudicial.

### Modelo ajustado finamente

Ajuste fino √© um processo que aproveita o aprendizado por transfer√™ncia para ‚Äòadaptar‚Äô o modelo a uma tarefa espec√≠fica ou resolver um problema particular. Diferente do few-shot learning e do RAG, resulta na gera√ß√£o de um novo modelo, com pesos e vieses atualizados. Requer um conjunto de exemplos de treinamento consistindo de uma entrada √∫nica (o prompt) e sua sa√≠da associada (a conclus√£o).  
Essa seria a abordagem preferida se:

- **Usando modelos ajustados finamente**. Uma empresa deseja usar modelos ajustados menos potentes (como modelos de embedding) em vez de modelos de alta performance, resultando em uma solu√ß√£o mais econ√¥mica e r√°pida.

- **Considerando lat√™ncia**. A lat√™ncia √© importante para um caso de uso espec√≠fico, ent√£o n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que o modelo deveria aprender n√£o cabe no limite de tamanho do prompt.

- **Mantendo-se atualizado**. A empresa possui muitos dados de alta qualidade e r√≥tulos confi√°veis, al√©m dos recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo treinado

Treinar um LLM do zero √©, sem d√∫vida, a abordagem mais dif√≠cil e complexa, exigindo enormes quantidades de dados, recursos especializados e poder computacional adequado. Essa op√ß√£o deve ser considerada apenas em cen√°rios onde a empresa tem um caso de uso espec√≠fico de dom√≠nio e uma grande quantidade de dados centrados nesse dom√≠nio.

## Verifica√ß√£o de conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de conclus√£o de um LLM?

1. Engenharia de prompt com contexto  
1. RAG  
1. Modelo ajustado finamente

R: 3, se voc√™ tem tempo, recursos e dados de alta qualidade, o ajuste fino √© a melhor op√ß√£o para se manter atualizado. No entanto, se voc√™ quer melhorar as coisas e est√° com pouco tempo, vale a pena considerar o RAG primeiro.

## üöÄ Desafio

Leia mais sobre como voc√™ pode [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para o seu neg√≥cio.

## √ìtimo trabalho, continue seu aprendizado

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de aprendizado sobre IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

Siga para a Li√ß√£o 3, onde veremos como [construir com IA Generativa de forma respons√°vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.