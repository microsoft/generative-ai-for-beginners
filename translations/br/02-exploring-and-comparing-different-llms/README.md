<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T09:17:14+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "br"
}
-->
# Explorando e comparando diferentes LLMs

[![Explorando e comparando diferentes LLMs](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.br.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Clique na imagem acima para ver o v√≠deo desta li√ß√£o_

Na li√ß√£o anterior, vimos como a IA Generativa est√° mudando o cen√°rio tecnol√≥gico, como os Modelos de Linguagem de Grande Escala (LLMs) funcionam e como uma empresa - como nossa startup - pode aplic√°-los aos seus casos de uso e crescer! Neste cap√≠tulo, estamos buscando comparar e contrastar diferentes tipos de modelos de linguagem de grande escala (LLMs) para entender seus pr√≥s e contras.

O pr√≥ximo passo na jornada da nossa startup √© explorar o cen√°rio atual dos LLMs e entender quais s√£o adequados para o nosso caso de uso.

## Introdu√ß√£o

Esta li√ß√£o ir√° cobrir:

- Diferentes tipos de LLMs no cen√°rio atual.
- Testar, iterar e comparar diferentes modelos para o seu caso de uso no Azure.
- Como implantar um LLM.

## Objetivos de Aprendizagem

Ap√≥s completar esta li√ß√£o, voc√™ ser√° capaz de:

- Selecionar o modelo certo para o seu caso de uso.
- Entender como testar, iterar e melhorar o desempenho do seu modelo.
- Saber como as empresas implantam modelos.

## Entenda diferentes tipos de LLMs

LLMs podem ter m√∫ltiplas categoriza√ß√µes baseadas em sua arquitetura, dados de treinamento e caso de uso. Entender essas diferen√ßas ajudar√° nossa startup a selecionar o modelo certo para o cen√°rio e entender como testar, iterar e melhorar o desempenho.

Existem muitos tipos diferentes de modelos LLM, sua escolha de modelo depende do que voc√™ pretende usar, dos seus dados, de quanto est√° disposto a pagar e mais.

Dependendo se voc√™ pretende usar os modelos para texto, √°udio, v√≠deo, gera√ß√£o de imagens e assim por diante, voc√™ pode optar por um tipo diferente de modelo.

- **Reconhecimento de √°udio e fala**. Para esse prop√≥sito, modelos do tipo Whisper s√£o uma √≥tima escolha, pois s√£o de uso geral e voltados para o reconhecimento de fala. Eles s√£o treinados em √°udio diverso e podem realizar reconhecimento de fala multil√≠ngue. Saiba mais sobre [modelos do tipo Whisper aqui](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Gera√ß√£o de imagens**. Para gera√ß√£o de imagens, DALL-E e Midjourney s√£o duas escolhas muito conhecidas. DALL-E √© oferecido pela Azure OpenAI. [Leia mais sobre DALL-E aqui](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) e tamb√©m no Cap√≠tulo 9 deste curr√≠culo.

- **Gera√ß√£o de texto**. A maioria dos modelos √© treinada para gera√ß√£o de texto e voc√™ tem uma grande variedade de escolhas, de GPT-3.5 a GPT-4. Eles v√™m com diferentes custos, sendo o GPT-4 o mais caro. Vale a pena explorar o [playground do Azure OpenAI](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) para avaliar quais modelos melhor se adequam √†s suas necessidades em termos de capacidade e custo.

- **Multi-modalidade**. Se voc√™ est√° procurando lidar com m√∫ltiplos tipos de dados na entrada e sa√≠da, pode querer explorar modelos como [gpt-4 turbo com vis√£o ou gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - os lan√ßamentos mais recentes dos modelos OpenAI - que s√£o capazes de combinar processamento de linguagem natural com compreens√£o visual, permitindo intera√ß√µes atrav√©s de interfaces multi-modais.

Selecionar um modelo significa que voc√™ obt√©m algumas capacidades b√°sicas, que podem n√£o ser suficientes, no entanto. Muitas vezes voc√™ tem dados espec√≠ficos da empresa que precisa de alguma forma informar ao LLM. Existem algumas escolhas diferentes sobre como abordar isso, mais sobre isso nas pr√≥ximas se√ß√µes.

### Modelos de Funda√ß√£o versus LLMs

O termo Modelo de Funda√ß√£o foi [cunhado por pesquisadores de Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) e definido como um modelo de IA que segue alguns crit√©rios, como:

- **Eles s√£o treinados usando aprendizado n√£o supervisionado ou auto-supervisionado**, o que significa que s√£o treinados em dados multimodais n√£o rotulados, e n√£o requerem anota√ß√£o ou rotulagem humana dos dados para seu processo de treinamento.
- **Eles s√£o modelos muito grandes**, baseados em redes neurais muito profundas treinadas em bilh√µes de par√¢metros.
- **Eles s√£o normalmente destinados a servir como uma ‚Äòfunda√ß√£o‚Äô para outros modelos**, o que significa que podem ser usados como ponto de partida para outros modelos serem constru√≠dos em cima, o que pode ser feito por ajuste fino.

![Modelos de Funda√ß√£o versus LLMs](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.br.png)

Fonte da imagem: [Guia Essencial para Modelos de Funda√ß√£o e Modelos de Linguagem de Grande Escala | por Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Para esclarecer ainda mais essa distin√ß√£o, vamos usar o ChatGPT como exemplo. Para construir a primeira vers√£o do ChatGPT, um modelo chamado GPT-3.5 serviu como o modelo de funda√ß√£o. Isso significa que a OpenAI usou alguns dados espec√≠ficos de chat para criar uma vers√£o ajustada do GPT-3.5 que foi especializada em ter um bom desempenho em cen√°rios de conversa√ß√£o, como chatbots.

![Modelo de Funda√ß√£o](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.br.png)

Fonte da imagem: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modelos de C√≥digo Aberto versus Propriet√°rios

Outra maneira de categorizar LLMs √© se eles s√£o de c√≥digo aberto ou propriet√°rios.

Modelos de c√≥digo aberto s√£o modelos que s√£o disponibilizados ao p√∫blico e podem ser usados por qualquer pessoa. Eles s√£o frequentemente disponibilizados pela empresa que os criou ou pela comunidade de pesquisa. Esses modelos podem ser inspecionados, modificados e personalizados para os v√°rios casos de uso em LLMs. No entanto, eles nem sempre s√£o otimizados para uso em produ√ß√£o e podem n√£o ser t√£o perform√°ticos quanto os modelos propriet√°rios. Al√©m disso, o financiamento para modelos de c√≥digo aberto pode ser limitado, e eles podem n√£o ser mantidos a longo prazo ou podem n√£o ser atualizados com as pesquisas mais recentes. Exemplos de modelos populares de c√≥digo aberto incluem [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) e [LLaMA](https://llama.meta.com).

Modelos propriet√°rios s√£o modelos que s√£o de propriedade de uma empresa e n√£o s√£o disponibilizados ao p√∫blico. Esses modelos s√£o frequentemente otimizados para uso em produ√ß√£o. No entanto, eles n√£o podem ser inspecionados, modificados ou personalizados para diferentes casos de uso. Al√©m disso, eles nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para serem usados. Al√©m disso, os usu√°rios n√£o t√™m controle sobre os dados que s√£o usados para treinar o modelo, o que significa que devem confiar no propriet√°rio do modelo para garantir o compromisso com a privacidade dos dados e o uso respons√°vel da IA. Exemplos de modelos propriet√°rios populares incluem [modelos OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ou [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus Gera√ß√£o de Imagem versus Gera√ß√£o de Texto e C√≥digo

LLMs tamb√©m podem ser categorizados pelo tipo de sa√≠da que geram.

Embeddings s√£o um conjunto de modelos que podem converter texto em uma forma num√©rica, chamada de embedding, que √© uma representa√ß√£o num√©rica do texto de entrada. Embeddings facilitam para as m√°quinas entenderem as rela√ß√µes entre palavras ou frases e podem ser consumidos como entradas por outros modelos, como modelos de classifica√ß√£o ou modelos de agrupamento que t√™m melhor desempenho em dados num√©ricos. Modelos de embedding s√£o frequentemente usados para aprendizado por transfer√™ncia, onde um modelo √© constru√≠do para uma tarefa substituta para a qual h√° uma abund√¢ncia de dados, e ent√£o os pesos do modelo (embeddings) s√£o reutilizados para outras tarefas subsequentes. Um exemplo dessa categoria √© [embeddings da OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.br.png)

Modelos de gera√ß√£o de imagem s√£o modelos que geram imagens. Esses modelos s√£o frequentemente usados para edi√ß√£o de imagem, s√≠ntese de imagem e tradu√ß√£o de imagem. Modelos de gera√ß√£o de imagem s√£o frequentemente treinados em grandes conjuntos de dados de imagens, como [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novas imagens ou para editar imagens existentes com t√©cnicas de inpainting, super-resolu√ß√£o e coloriza√ß√£o. Exemplos incluem [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) e [modelos Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Gera√ß√£o de imagem](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.br.png)

Modelos de gera√ß√£o de texto e c√≥digo s√£o modelos que geram texto ou c√≥digo. Esses modelos s√£o frequentemente usados para sumariza√ß√£o de texto, tradu√ß√£o e resposta a perguntas. Modelos de gera√ß√£o de texto s√£o frequentemente treinados em grandes conjuntos de dados de texto, como [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), e podem ser usados para gerar novo texto ou para responder perguntas. Modelos de gera√ß√£o de c√≥digo, como [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), s√£o frequentemente treinados em grandes conjuntos de dados de c√≥digo, como o GitHub, e podem ser usados para gerar novo c√≥digo ou para corrigir bugs em c√≥digo existente.

![Gera√ß√£o de texto e c√≥digo](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.br.png)

### Encoder-Decoder versus Apenas Decoder

Para falar sobre os diferentes tipos de arquiteturas de LLMs, vamos usar uma analogia.

Imagine que seu gerente lhe deu a tarefa de escrever um quiz para os alunos. Voc√™ tem dois colegas; um √© respons√°vel por criar o conte√∫do e o outro por revis√°-lo.

O criador de conte√∫do √© como um modelo apenas Decoder, ele pode olhar para o t√≥pico e ver o que voc√™ j√° escreveu e ent√£o ele pode escrever um curso com base nisso. Eles s√£o muito bons em escrever conte√∫do envolvente e informativo, mas n√£o s√£o muito bons em entender o t√≥pico e os objetivos de aprendizado. Alguns exemplos de modelos Decoder s√£o os modelos da fam√≠lia GPT, como o GPT-3.

O revisor √© como um modelo apenas Encoder, ele olha para o curso escrito e as respostas, percebendo a rela√ß√£o entre eles e entendendo o contexto, mas n√£o √© bom em gerar conte√∫do. Um exemplo de modelo apenas Encoder seria o BERT.

Imagine que tamb√©m podemos ter algu√©m que possa criar e revisar o quiz, este √© um modelo Encoder-Decoder. Alguns exemplos seriam BART e T5.

### Servi√ßo versus Modelo

Agora, vamos falar sobre a diferen√ßa entre um servi√ßo e um modelo. Um servi√ßo √© um produto oferecido por um Provedor de Servi√ßos em Nuvem e √© frequentemente uma combina√ß√£o de modelos, dados e outros componentes. Um modelo √© o componente central de um servi√ßo e √© frequentemente um modelo de funda√ß√£o, como um LLM.

Servi√ßos s√£o frequentemente otimizados para uso em produ√ß√£o e s√£o frequentemente mais f√°ceis de usar do que modelos, via uma interface gr√°fica de usu√°rio. No entanto, os servi√ßos nem sempre est√£o dispon√≠veis gratuitamente e podem exigir uma assinatura ou pagamento para serem usados, em troca de aproveitar o equipamento e os recursos do propriet√°rio do servi√ßo, otimizando despesas e escalando facilmente. Um exemplo de servi√ßo √© o [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), que oferece um plano de tarifa conforme o uso, significando que os usu√°rios s√£o cobrados proporcionalmente ao quanto usam o servi√ßo. Al√©m disso, o Azure OpenAI Service oferece seguran√ßa de n√≠vel empresarial e um framework de IA respons√°vel em cima das capacidades dos modelos.

Modelos s√£o apenas a Rede Neural, com os par√¢metros, pesos e outros. Permitindo que empresas rodem localmente, no entanto, precisariam comprar equipamentos, construir uma estrutura para escalar e comprar uma licen√ßa ou usar um modelo de c√≥digo aberto. Um modelo como LLaMA est√° dispon√≠vel para ser usado, requerendo poder computacional para rodar o modelo.

## Como testar e iterar com diferentes modelos para entender o desempenho no Azure

Uma vez que nossa equipe tenha explorado o cen√°rio atual dos LLMs e identificado alguns bons candidatos para seus cen√°rios, o pr√≥ximo passo √© test√°-los em seus dados e em sua carga de trabalho. Este √© um processo iterativo, feito por experimentos e medidas. A maioria dos modelos que mencionamos nos par√°grafos anteriores (modelos OpenAI, modelos de c√≥digo aberto como Llama2 e transformadores Hugging Face) est√£o dispon√≠veis no [Cat√°logo de Modelos](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) no [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) √© uma plataforma em nuvem projetada para desenvolvedores constru√≠rem aplica√ß√µes de IA generativa e gerenciarem todo o ciclo de desenvolvimento - da experimenta√ß√£o √† avalia√ß√£o - combinando todos os servi√ßos de IA do Azure em um √∫nico hub com uma interface gr√°fica de usu√°rio pr√°tica. O Cat√°logo de Modelos no Azure AI Studio permite ao usu√°rio:

- Encontrar o Modelo de Funda√ß√£o de interesse no cat√°logo - seja propriet√°rio ou de c√≥digo aberto, filtrando por tarefa, licen√ßa ou nome. Para melhorar a pesquisa, os modelos s√£o organizados em cole√ß√µes, como a cole√ß√£o Azure OpenAI, cole√ß√£o Hugging Face e mais.

![Cat√°logo de Modelos](../../../translated_images/AzureAIStudioModelCatalog.e34ac207ac348d31e74246c4f91d10086444783b72bbee3658e0453918aa5d22.br.png)

- Revisar o cart√£o do modelo, incluindo uma descri√ß√£o detalhada do uso pretendido e dos dados de treinamento, exemplos de c√≥digo e resultados de avalia√ß√£o na biblioteca de avalia√ß√µes internas.

![Cart√£o do Modelo](../../../translated_images/ModelCard.8b25784bb406028655a12ea87d1ef3d52302e5d692ae4ec559c2dce7682027c7.br.png)
- Compare benchmarks entre modelos e conjuntos de dados dispon√≠veis na ind√∫stria para avaliar qual deles atende ao cen√°rio de neg√≥cios, atrav√©s do painel [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.br.png)

- Ajuste o modelo em dados de treinamento personalizados para melhorar o desempenho do modelo em uma carga de trabalho espec√≠fica, aproveitando as capacidades de experimenta√ß√£o e rastreamento do Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.br.png)

- Implante o modelo pr√©-treinado original ou a vers√£o ajustada para uma infer√™ncia remota em tempo real - computa√ß√£o gerenciada - ou endpoint de API sem servidor - [pague conforme o uso](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - para permitir que as aplica√ß√µes o consumam.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.br.png)

> [!NOTE]
> Nem todos os modelos no cat√°logo est√£o atualmente dispon√≠veis para ajuste fino e/ou implanta√ß√£o paga conforme o uso. Verifique o cart√£o do modelo para detalhes sobre as capacidades e limita√ß√µes do modelo.

## Melhorando os resultados de LLM

Exploramos com nossa equipe de startup diferentes tipos de LLMs e uma Plataforma em Nuvem (Azure Machine Learning) que nos permite comparar diferentes modelos, avali√°-los em dados de teste, melhorar o desempenho e implant√°-los em endpoints de infer√™ncia.

Mas quando eles devem considerar ajustar um modelo ao inv√©s de usar um pr√©-treinado? Existem outras abordagens para melhorar o desempenho do modelo em cargas de trabalho espec√≠ficas?

Existem v√°rias abordagens que uma empresa pode usar para obter os resultados que precisa de um LLM. Voc√™ pode selecionar diferentes tipos de modelos com diferentes graus de treinamento ao implantar um LLM em produ√ß√£o, com diferentes n√≠veis de complexidade, custo e qualidade. Aqui est√£o algumas abordagens diferentes:

- **Engenharia de prompt com contexto**. A ideia √© fornecer contexto suficiente ao fazer um prompt para garantir que voc√™ obtenha as respostas necess√°rias.

- **Gera√ß√£o Aumentada por Recupera√ß√£o, RAG**. Seus dados podem existir em um banco de dados ou endpoint web, por exemplo, para garantir que esses dados, ou um subconjunto deles, sejam inclu√≠dos no momento do prompt, voc√™ pode buscar os dados relevantes e torn√°-los parte do prompt do usu√°rio.

- **Modelo ajustado**. Aqui, voc√™ treinou o modelo mais a fundo com seus pr√≥prios dados, o que levou o modelo a ser mais preciso e responsivo √†s suas necessidades, mas pode ser caro.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.br.png)

Fonte da imagem: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Engenharia de Prompt com Contexto

LLMs pr√©-treinados funcionam muito bem em tarefas de linguagem natural generalizadas, mesmo ao serem chamados com um prompt curto, como uma frase para completar ou uma pergunta ‚Äì a chamada aprendizagem "zero-shot".

No entanto, quanto mais o usu√°rio puder enquadrar sua consulta, com um pedido detalhado e exemplos ‚Äì o Contexto ‚Äì mais precisa e pr√≥xima das expectativas do usu√°rio ser√° a resposta. Neste caso, falamos sobre aprendizagem "one-shot" se o prompt incluir apenas um exemplo e "few-shot learning" se incluir m√∫ltiplos exemplos.
A engenharia de prompt com contexto √© a abordagem mais econ√¥mica para come√ßar.

### Gera√ß√£o Aumentada por Recupera√ß√£o (RAG)

LLMs t√™m a limita√ß√£o de que s√≥ podem usar os dados que foram usados durante seu treinamento para gerar uma resposta. Isso significa que eles n√£o sabem nada sobre os fatos que aconteceram ap√≥s seu processo de treinamento, e n√£o podem acessar informa√ß√µes n√£o p√∫blicas (como dados da empresa).
Isso pode ser superado atrav√©s do RAG, uma t√©cnica que aumenta o prompt com dados externos na forma de fragmentos de documentos, considerando os limites de comprimento do prompt. Isso √© suportado por ferramentas de banco de dados vetorial (como [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) que recuperam os fragmentos √∫teis de fontes de dados variadas predefinidas e os adicionam ao Contexto do prompt.

Esta t√©cnica √© muito √∫til quando uma empresa n√£o tem dados suficientes, tempo suficiente ou recursos para ajustar um LLM, mas ainda deseja melhorar o desempenho em uma carga de trabalho espec√≠fica e reduzir os riscos de fabrica√ß√µes, ou seja, mistifica√ß√£o da realidade ou conte√∫do prejudicial.

### Modelo Ajustado

O ajuste fino √© um processo que aproveita o aprendizado por transfer√™ncia para 'adaptar' o modelo a uma tarefa downstream ou resolver um problema espec√≠fico. Diferentemente do aprendizado de poucos exemplos e RAG, resulta na gera√ß√£o de um novo modelo, com pesos e vieses atualizados. Requer um conjunto de exemplos de treinamento consistindo de uma √∫nica entrada (o prompt) e sua sa√≠da associada (a conclus√£o).
Esta seria a abordagem preferida se:

- **Usando modelos ajustados**. Uma empresa gostaria de usar modelos ajustados menos capazes (como modelos de incorpora√ß√£o) ao inv√©s de modelos de alto desempenho, resultando em uma solu√ß√£o mais econ√¥mica e r√°pida.

- **Considerando lat√™ncia**. A lat√™ncia √© importante para um caso de uso espec√≠fico, ent√£o n√£o √© poss√≠vel usar prompts muito longos ou o n√∫mero de exemplos que devem ser aprendidos pelo modelo n√£o se encaixa com o limite de comprimento do prompt.

- **Mantendo-se atualizado**. Uma empresa tem muitos dados de alta qualidade e r√≥tulos de verdade fundamental e os recursos necess√°rios para manter esses dados atualizados ao longo do tempo.

### Modelo Treinado

Treinar um LLM do zero √©, sem d√∫vida, a abordagem mais dif√≠cil e complexa de adotar, exigindo quantidades massivas de dados, recursos qualificados e poder computacional adequado. Esta op√ß√£o deve ser considerada apenas em um cen√°rio onde uma empresa tem um caso de uso espec√≠fico de dom√≠nio e uma grande quantidade de dados centrados no dom√≠nio.

## Verifica√ß√£o de conhecimento

Qual poderia ser uma boa abordagem para melhorar os resultados de conclus√£o de LLM?

1. Engenharia de prompt com contexto
1. RAG
1. Modelo ajustado

A:3, se voc√™ tem tempo, recursos e dados de alta qualidade, o ajuste fino √© a melhor op√ß√£o para se manter atualizado. No entanto, se voc√™ est√° procurando melhorar as coisas e est√° com falta de tempo, vale considerar o RAG primeiro.

## üöÄ Desafio

Leia mais sobre como voc√™ pode [usar RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) para seu neg√≥cio.

## √ìtimo trabalho, continue aprendendo

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de Aprendizado de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

V√° para a Li√ß√£o 3, onde veremos como [construir com IA Generativa de forma respons√°vel](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorit√°ria. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.