{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Construa aplicativos de geração de texto\n",
    "\n",
    "Você já viu até aqui neste curso que existem conceitos fundamentais como prompts e até uma disciplina inteira chamada \"engenharia de prompts\". Muitas ferramentas com as quais você pode interagir, como ChatGPT, Office 365, Microsoft Power Platform e outras, permitem que você use prompts para realizar tarefas.\n",
    "\n",
    "Para adicionar essa experiência a um aplicativo, é preciso entender conceitos como prompts, completions e escolher uma biblioteca para trabalhar. É exatamente isso que você vai aprender neste capítulo.\n",
    "\n",
    "## Introdução\n",
    "\n",
    "Neste capítulo, você vai:\n",
    "\n",
    "- Conhecer a biblioteca openai e seus conceitos principais.\n",
    "- Construir um app de geração de texto usando openai.\n",
    "- Entender como usar conceitos como prompt, temperatura e tokens para criar um app de geração de texto.\n",
    "\n",
    "## Objetivos de aprendizagem\n",
    "\n",
    "Ao final desta lição, você será capaz de:\n",
    "\n",
    "- Explicar o que é um app de geração de texto.\n",
    "- Construir um app de geração de texto usando openai.\n",
    "- Configurar seu app para usar mais ou menos tokens e também alterar a temperatura, para obter resultados variados.\n",
    "\n",
    "## O que é um app de geração de texto?\n",
    "\n",
    "Normalmente, quando você cria um app, ele tem algum tipo de interface como as seguintes:\n",
    "\n",
    "- Baseado em comandos. Apps de console são exemplos típicos, onde você digita um comando e ele executa uma tarefa. Por exemplo, `git` é um app baseado em comandos.\n",
    "- Interface de usuário (UI). Alguns apps têm interfaces gráficas (GUIs), onde você clica em botões, digita textos, seleciona opções e muito mais.\n",
    "\n",
    "### Apps de console e UI são limitados\n",
    "\n",
    "Compare com um app baseado em comandos, onde você digita um comando:\n",
    "\n",
    "- **É limitado**. Você não pode digitar qualquer comando, apenas os que o app suporta.\n",
    "- **Específico de linguagem**. Alguns apps suportam vários idiomas, mas por padrão o app é feito para um idioma específico, mesmo que seja possível adicionar suporte a outros idiomas.\n",
    "\n",
    "### Benefícios dos apps de geração de texto\n",
    "\n",
    "Então, como um app de geração de texto é diferente?\n",
    "\n",
    "Em um app de geração de texto, você tem mais flexibilidade, não está limitado a um conjunto de comandos ou a um idioma específico de entrada. Em vez disso, você pode usar linguagem natural para interagir com o app. Outro benefício é que você já está interagindo com uma fonte de dados treinada em um grande volume de informações, enquanto um app tradicional pode estar limitado ao que está em um banco de dados.\n",
    "\n",
    "### O que posso construir com um app de geração de texto?\n",
    "\n",
    "Há muitas possibilidades. Por exemplo:\n",
    "\n",
    "- **Um chatbot**. Um chatbot que responde perguntas sobre temas como sua empresa e seus produtos pode ser uma ótima opção.\n",
    "- **Assistente**. LLMs são ótimos para tarefas como resumir textos, extrair insights, produzir textos como currículos e muito mais.\n",
    "- **Assistente de código**. Dependendo do modelo de linguagem que você usar, é possível criar um assistente de código que te ajuda a programar. Por exemplo, você pode usar produtos como o GitHub Copilot ou o ChatGPT para te ajudar a escrever código.\n",
    "\n",
    "## Como posso começar?\n",
    "\n",
    "Bem, você precisa encontrar uma forma de integrar com um LLM, o que normalmente envolve duas abordagens:\n",
    "\n",
    "- Usar uma API. Aqui você constrói requisições web com seu prompt e recebe o texto gerado de volta.\n",
    "- Usar uma biblioteca. As bibliotecas ajudam a encapsular as chamadas de API e tornam o uso mais fácil.\n",
    "\n",
    "## Bibliotecas/SDKs\n",
    "\n",
    "Existem algumas bibliotecas bem conhecidas para trabalhar com LLMs, como:\n",
    "\n",
    "- **openai**, essa biblioteca facilita a conexão com seu modelo e o envio de prompts.\n",
    "\n",
    "Também existem bibliotecas que operam em um nível mais alto, como:\n",
    "\n",
    "- **Langchain**. O Langchain é bastante conhecido e suporta Python.\n",
    "- **Semantic Kernel**. O Semantic Kernel é uma biblioteca da Microsoft que suporta as linguagens C#, Python e Java.\n",
    "\n",
    "## Primeiro app usando o GitHub Models Playground e Azure AI Inference SDK\n",
    "\n",
    "Vamos ver como construir nosso primeiro app, quais bibliotecas são necessárias, o que é preciso e assim por diante.\n",
    "\n",
    "### O que é o GitHub Models?\n",
    "\n",
    "Bem-vindo ao [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Aqui você encontra tudo pronto para explorar diferentes modelos de IA hospedados no Azure AI, todos acessíveis por meio de um playground no GitHub ou diretamente no seu IDE favorito, gratuitamente para testar.\n",
    "\n",
    "### O que eu preciso?\n",
    "\n",
    "* Uma conta no GitHub: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Inscrever-se no GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Vamos começar!\n",
    "\n",
    "### Encontre um modelo e teste\n",
    "\n",
    "Acesse o [GitHub Models no Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Tela principal do GitHub Models mostrando uma lista de cards de modelos como Cohere, Meta llama, Mistral e modelos GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.br.png)\n",
    "\n",
    "Escolha um modelo – por exemplo, [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Aqui você verá o card do modelo. Você pode:\n",
    "* Interagir com o modelo ali mesmo, digitando uma mensagem na caixa de texto\n",
    "* Ler detalhes sobre o modelo nas abas readme, Evaluation, Transparency e License\n",
    "* Além de conferir a seção 'About' para informações de acesso ao modelo à direita\n",
    "\n",
    "![Card do modelo GPT-4o no GitHub Models](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.br.png)\n",
    "\n",
    "Mas vamos direto ao playground clicando no ['Playground' no canto superior direito](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Aqui você pode interagir com o modelo, adicionar prompts de sistema e alterar parâmetros – além de obter todo o código necessário para rodar de qualquer lugar. Disponível a partir de setembro de 2024: Python, Javascript, C# e REST.\n",
    "\n",
    "![Experiência do Playground do GitHub Models com código e linguagens exibidas](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.br.png)  \n",
    "\n",
    "### Vamos usar o modelo no nosso próprio IDE\n",
    "\n",
    "Duas opções aqui:\n",
    "1. **GitHub Codespaces** – integração direta com Codespaces e não é necessário token para começar\n",
    "2. **VS Code (ou qualquer IDE de sua preferência)** – é preciso obter um [Personal Access Token do GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "De qualquer forma, as instruções estão disponíveis no botão verde 'Get started' no canto superior direito.\n",
    "\n",
    "![Tela Get Started mostrando como acessar Codespaces ou usar um personal access token para configurar no seu próprio IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.br.png)\n",
    "\n",
    "### 1. Codespaces\n",
    "\n",
    "* Na janela 'Get started', escolha \"Run codespace\"\n",
    "* Crie um novo codespace (ou use um já existente)\n",
    "* O VS Code será aberto no seu navegador com um conjunto de notebooks de exemplo em várias linguagens para você testar\n",
    "* Execute o exemplo ```./githubmodels-app.py```.\n",
    "\n",
    "> Nota: No codespaces não é necessário definir a variável Github Token, pode pular essa etapa\n",
    "\n",
    "**Agora vá para a seção 'Gerar Texto' abaixo para continuar este exercício**\n",
    "\n",
    "### 2. VS Code (ou qualquer IDE de sua preferência)\n",
    "\n",
    "No botão verde 'Get started' você encontra todas as informações para rodar no seu IDE favorito. Este exemplo mostrará o VS Code\n",
    "\n",
    "* Selecione a linguagem e o SDK – neste exemplo, escolhemos Python e Azure AI Inference SDK\n",
    "* Crie um personal access token no GitHub. Ele fica na seção Developer Settings. Não é necessário dar permissões ao token. Lembre-se que o token será enviado para um serviço da Microsoft.\n",
    "* Crie uma variável de ambiente para armazenar seu personal access token do Github – há exemplos para bash, powershell e prompt de comando do Windows\n",
    "* Instale as dependências: ```pip install azure-ai-inference```\n",
    "* Copie o código de exemplo básico para um arquivo .py\n",
    "* Navegue até onde o código está salvo e execute o arquivo: ```python filename.py```\n",
    "\n",
    "Não se esqueça: usando o Azure AI Inference SDK, você pode experimentar facilmente diferentes modelos alterando o valor de `model_name` no código.\n",
    "\n",
    "Os seguintes modelos estão disponíveis no serviço GitHub Models a partir de setembro de 2024:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Agora vá para a seção 'Gerar Texto' abaixo para continuar este exercício**\n",
    "\n",
    "## Gerar texto com ChatCompletions\n",
    "\n",
    "A forma de gerar texto é usando a classe `ChatCompletionsClient`.\n",
    "No arquivo `samples/python/azure_ai_inference/basic.py`, na seção de resposta do código, atualize o código do papel do usuário alterando o parâmetro content para o seguinte:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Execute o arquivo atualizado para ver o resultado\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diferentes tipos de prompts, para diferentes finalidades\n",
    "\n",
    "Agora você já viu como gerar texto usando um prompt. Você até tem um programa funcionando que pode modificar e adaptar para gerar diferentes tipos de texto.\n",
    "\n",
    "Prompts podem ser usados para várias tarefas. Por exemplo:\n",
    "\n",
    "- **Gerar um tipo de texto**. Por exemplo, você pode gerar um poema, perguntas para um quiz, etc.\n",
    "- **Buscar informações**. Você pode usar prompts para procurar informações, como no exemplo: 'O que significa CORS no desenvolvimento web?'.\n",
    "- **Gerar código**. Você pode usar prompts para gerar código, por exemplo, criar uma expressão regular para validar e-mails ou até mesmo gerar um programa inteiro, como um aplicativo web.\n",
    "\n",
    "## Exercício: um gerador de receitas\n",
    "\n",
    "Imagine que você tem alguns ingredientes em casa e quer cozinhar algo. Para isso, você precisa de uma receita. Uma forma de encontrar receitas é usar um mecanismo de busca ou você pode usar um LLM para isso.\n",
    "\n",
    "Você poderia escrever um prompt assim:\n",
    "\n",
    "> \"Mostre 5 receitas de um prato com os seguintes ingredientes: frango, batatas e cenouras. Para cada receita, liste todos os ingredientes usados\"\n",
    "\n",
    "Dado o prompt acima, você pode receber uma resposta parecida com:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Esse resultado é ótimo, agora sei o que posso cozinhar. Neste ponto, algumas melhorias úteis poderiam ser:\n",
    "\n",
    "- Filtrar ingredientes que não gosto ou aos quais sou alérgico.\n",
    "- Gerar uma lista de compras, caso eu não tenha todos os ingredientes em casa.\n",
    "\n",
    "Para os casos acima, vamos adicionar um prompt extra:\n",
    "\n",
    "> \"Por favor, remova receitas com alho, pois sou alérgico, e substitua por outro ingrediente. Além disso, faça uma lista de compras para as receitas, considerando que já tenho frango, batatas e cenouras em casa.\"\n",
    "\n",
    "Agora você tem um novo resultado, que é:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Essas são suas cinco receitas, sem alho mencionado, e você também tem uma lista de compras considerando o que já tem em casa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercício - construa um gerador de receitas\n",
    "\n",
    "Agora que já exploramos um cenário, vamos escrever um código para corresponder ao cenário demonstrado. Para isso, siga estes passos:\n",
    "\n",
    "1. Use o arquivo existente como ponto de partida\n",
    "1. Crie uma variável `prompt` e altere o código de exemplo conforme abaixo:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se você rodar o código agora, deverá ver uma saída parecida com:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, seu LLM é não determinístico, então você pode obter resultados diferentes cada vez que rodar o programa.\n",
    "\n",
    "Ótimo, vamos ver como podemos melhorar as coisas. Para melhorar, queremos garantir que o código seja flexível, permitindo que os ingredientes e o número de receitas possam ser ajustados e modificados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Executar o código para um teste pode ser assim:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Melhorando com filtro e lista de compras\n",
    "\n",
    "Agora temos um app funcional capaz de gerar receitas e ele é flexível, pois depende das entradas do usuário, tanto no número de receitas quanto nos ingredientes usados.\n",
    "\n",
    "Para melhorar ainda mais, queremos adicionar o seguinte:\n",
    "\n",
    "- **Filtrar ingredientes**. Queremos poder filtrar ingredientes que não gostamos ou aos quais somos alérgicos. Para fazer essa alteração, podemos editar nosso prompt existente e adicionar uma condição de filtro ao final dele, assim:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Acima, adicionamos `{filter}` ao final do prompt e também capturamos o valor do filtro do usuário.\n",
    "\n",
    "    Um exemplo de entrada ao rodar o programa pode ser assim:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Gerar uma lista de compras**. Queremos gerar uma lista de compras, considerando o que já temos em casa.\n",
    "\n",
    "    Para essa funcionalidade, podemos tentar resolver tudo em um único prompt ou dividir em dois prompts. Vamos tentar a segunda abordagem. Aqui sugerimos adicionar um prompt adicional, mas para isso funcionar, precisamos adicionar o resultado do primeiro prompt como contexto para o segundo prompt.\n",
    "\n",
    "    Localize a parte do código que imprime o resultado do primeiro prompt e adicione o seguinte código abaixo:\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Observe o seguinte:\n",
    "\n",
    "    - Estamos construindo um novo prompt ao adicionar o resultado do primeiro prompt ao novo prompt:\n",
    "\n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Fazemos uma nova requisição, mas também considerando o número de tokens que pedimos no primeiro prompt, então desta vez dizemos que `max_tokens` é 1200. **Sobre o tamanho dos tokens**. Devemos considerar quantos tokens precisamos para gerar o texto desejado. Tokens custam dinheiro, então, sempre que possível, devemos tentar ser econômicos com a quantidade de tokens usados. Por exemplo, podemos reformular o prompt para usar menos tokens?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Rodando esse código, agora chegamos ao seguinte resultado:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Experimentando com temperature**. Temperature é algo que ainda não mencionamos, mas é um contexto importante para o funcionamento do nosso programa. Quanto maior o valor de temperature, mais aleatório será o resultado. Por outro lado, quanto menor o valor, mais previsível será a resposta. Considere se você quer variação ou não no seu resultado.\n",
    "\n",
    "   Para alterar o temperature, você pode usar o parâmetro `temperature`. Por exemplo, se quiser usar um temperature de 0.5, faça assim:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Note que, quanto mais próximo de 1.0, mais variado será o resultado.\n",
    "\n",
    "\n",
    "## Atividade\n",
    "\n",
    "Para esta atividade, você pode escolher o que construir.\n",
    "\n",
    "Aqui vão algumas sugestões:\n",
    "\n",
    "- Ajuste o app gerador de receitas para melhorá-lo ainda mais. Brinque com os valores de temperature e com os prompts para ver o que consegue criar.\n",
    "- Construa um \"companheiro de estudos\". Esse app deve ser capaz de responder perguntas sobre um tema, por exemplo Python. Você pode ter prompts como \"O que é determinado assunto em Python?\", ou um prompt que peça para mostrar código sobre um determinado tema, etc.\n",
    "- Bot de história: faça a história ganhar vida, instrua o bot a interpretar um personagem histórico e faça perguntas sobre sua vida e época.\n",
    "\n",
    "## Solução\n",
    "\n",
    "### Companheiro de estudos\n",
    "\n",
    "- \"Você é um especialista na linguagem Python\n",
    "\n",
    "    Sugira uma lição para iniciantes em Python no seguinte formato:\n",
    "    \n",
    "    Formato:\n",
    "    - conceitos:\n",
    "    - breve explicação da lição:\n",
    "    - exercício em código com soluções\"\n",
    "\n",
    "Acima está um prompt inicial, veja como você pode usá-lo e adaptá-lo ao seu gosto.\n",
    "\n",
    "### Bot de história\n",
    "\n",
    "Aqui estão alguns prompts que você pode usar:\n",
    "\n",
    "- \"Você é Abe Lincoln, fale sobre você em 3 frases e responda usando a gramática e palavras que Abe usaria\"\n",
    "- \"Você é Abe Lincoln, responda usando a gramática e palavras que Abe usaria:\n",
    "\n",
    "   Fale sobre suas maiores conquistas, em 300 palavras:\"\n",
    "\n",
    "## Checagem de conhecimento\n",
    "\n",
    "O que o conceito de temperature faz?\n",
    "\n",
    "1. Controla o quão aleatório é o resultado.\n",
    "1. Controla o tamanho da resposta.\n",
    "1. Controla quantos tokens são usados.\n",
    "\n",
    "R: 1\n",
    "\n",
    "Qual é uma boa forma de armazenar segredos como chaves de API?\n",
    "\n",
    "1. No código.\n",
    "1. Em um arquivo.\n",
    "1. Em variáveis de ambiente.\n",
    "\n",
    "R: 3, porque variáveis de ambiente não ficam no código e podem ser carregadas a partir dele.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Aviso Legal**:  \nEste documento foi traduzido utilizando o serviço de tradução por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora busquemos precisão, esteja ciente de que traduções automáticas podem conter erros ou imprecisões. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informações críticas, recomenda-se a tradução profissional humana. Não nos responsabilizamos por quaisquer mal-entendidos ou interpretações incorretas decorrentes do uso desta tradução.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T15:06:44+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "br"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}