<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T09:39:40+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "br"
}
-->
# Fundamentos da Engenharia de Prompt

## Introdu√ß√£o
Este m√≥dulo aborda conceitos e t√©cnicas essenciais para criar prompts eficazes em modelos de IA generativa. A forma como voc√™ escreve seu prompt para um LLM tamb√©m importa. Um prompt bem elaborado pode obter uma resposta de melhor qualidade. Mas o que exatamente significam termos como _prompt_ e _engenharia de prompt_? E como posso melhorar o _input_ do prompt que envio para o LLM? Estas s√£o as perguntas que tentaremos responder neste cap√≠tulo e no pr√≥ximo.

A _IA generativa_ √© capaz de criar novo conte√∫do (por exemplo, texto, imagens, √°udio, c√≥digo etc.) em resposta a solicita√ß√µes dos usu√°rios. Ela consegue isso usando _Modelos de Linguagem de Grande Porte_ como a s√©rie GPT ("Generative Pre-trained Transformer") da OpenAI, que s√£o treinados para usar linguagem natural e c√≥digo.

Os usu√°rios agora podem interagir com esses modelos usando paradigmas familiares, como chat, sem precisar de qualquer expertise t√©cnica ou treinamento. Os modelos s√£o baseados em _prompts_ - os usu√°rios enviam um texto de entrada (prompt) e recebem de volta a resposta da IA (completa√ß√£o). Eles podem ent√£o "conversar com a IA" iterativamente, em conversas de m√∫ltiplas etapas, refinando seu prompt at√© que a resposta atenda suas expectativas.

Os "prompts" agora se tornam a principal _interface de programa√ß√£o_ para aplicativos de IA generativa, dizendo aos modelos o que fazer e influenciando a qualidade das respostas retornadas. A "Engenharia de Prompt" √© um campo de estudo em r√°pido crescimento que se concentra no _design e otimiza√ß√£o_ de prompts para entregar respostas consistentes e de qualidade em escala.

## Objetivos de Aprendizagem

Nesta li√ß√£o, aprenderemos o que √© Engenharia de Prompt, por que ela importa e como podemos criar prompts mais eficazes para um determinado modelo e objetivo de aplica√ß√£o. Vamos entender os conceitos principais e as melhores pr√°ticas para engenharia de prompt - e aprender sobre um ambiente interativo de "sandbox" em Jupyter Notebooks onde podemos ver esses conceitos aplicados a exemplos reais.

Ao final desta li√ß√£o, seremos capazes de:

1. Explicar o que √© engenharia de prompt e por que ela importa.
2. Descrever os componentes de um prompt e como eles s√£o usados.
3. Aprender as melhores pr√°ticas e t√©cnicas para engenharia de prompt.
4. Aplicar as t√©cnicas aprendidas a exemplos reais, usando um endpoint da OpenAI.

## Termos-Chave

Engenharia de Prompt: A pr√°tica de projetar e refinar entradas para guiar modelos de IA na produ√ß√£o de sa√≠das desejadas.
Tokeniza√ß√£o: O processo de converter texto em unidades menores, chamadas tokens, que um modelo pode entender e processar.
LLMs Ajustados por Instru√ß√£o: Modelos de Linguagem de Grande Porte (LLMs) que foram ajustados com instru√ß√µes espec√≠ficas para melhorar a precis√£o e relev√¢ncia de suas respostas.

## Sandbox de Aprendizagem

A engenharia de prompt √© atualmente mais arte do que ci√™ncia. A melhor maneira de melhorar nossa intui√ß√£o para isso √© _praticar mais_ e adotar uma abordagem de tentativa e erro que combine expertise no dom√≠nio da aplica√ß√£o com t√©cnicas recomendadas e otimiza√ß√µes espec√≠ficas do modelo.

O Jupyter Notebook que acompanha esta li√ß√£o fornece um ambiente de _sandbox_ onde voc√™ pode experimentar o que aprende - conforme avan√ßa ou como parte do desafio de c√≥digo no final. Para executar os exerc√≠cios, voc√™ precisar√° de:

1. **Uma chave de API da Azure OpenAI** - o endpoint de servi√ßo para um LLM implantado.
2. **Um Runtime Python** - no qual o Notebook pode ser executado.
3. **Vari√°veis de Ambiente Locais** - _complete agora as etapas de [CONFIGURA√á√ÉO](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) para se preparar_.

O notebook vem com exerc√≠cios _iniciais_ - mas voc√™ √© incentivado a adicionar suas pr√≥prias se√ß√µes de _Markdown_ (descri√ß√£o) e _C√≥digo_ (solicita√ß√µes de prompt) para tentar mais exemplos ou ideias - e construir sua intui√ß√£o para design de prompt.

## Guia Ilustrado

Quer ter uma vis√£o geral do que esta li√ß√£o cobre antes de mergulhar? Confira este guia ilustrado, que d√° uma ideia dos principais t√≥picos abordados e os principais pontos para voc√™ refletir em cada um. O roteiro da li√ß√£o leva voc√™ desde a compreens√£o dos conceitos principais e desafios at√© abord√°-los com t√©cnicas de engenharia de prompt relevantes e melhores pr√°ticas. Observe que a se√ß√£o "T√©cnicas Avan√ßadas" neste guia refere-se ao conte√∫do abordado no _pr√≥ximo_ cap√≠tulo deste curr√≠culo.

## Nossa Startup

Agora, vamos falar sobre como _este t√≥pico_ se relaciona com nossa miss√£o de startup de [trazer inova√ß√£o em IA para a educa√ß√£o](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplicativos de aprendizado personalizado movidos por IA - ent√£o vamos pensar sobre como diferentes usu√°rios de nosso aplicativo podem "projetar" prompts:

- **Administradores** podem pedir √† IA para _analisar dados do curr√≠culo para identificar lacunas na cobertura_. A IA pode resumir os resultados ou visualiz√°-los com c√≥digo.
- **Educadores** podem pedir √† IA para _gerar um plano de aula para um p√∫blico-alvo e t√≥pico espec√≠fico_. A IA pode construir o plano personalizado em um formato especificado.
- **Estudantes** podem pedir √† IA para _tutori√°-los em um assunto dif√≠cil_. A IA agora pode guiar os estudantes com li√ß√µes, dicas e exemplos adaptados ao seu n√≠vel.

Isso √© apenas a ponta do iceberg. Confira [Prompts para Educa√ß√£o](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - uma biblioteca de prompts de c√≥digo aberto curada por especialistas em educa√ß√£o - para ter uma no√ß√£o mais ampla das possibilidades! _Experimente executar alguns desses prompts no sandbox ou usar o Playground da OpenAI para ver o que acontece!_

## O que √© Engenharia de Prompt?

Come√ßamos esta li√ß√£o definindo **Engenharia de Prompt** como o processo de _projetar e otimizar_ entradas de texto (prompts) para entregar respostas consistentes e de qualidade (completions) para um determinado objetivo de aplica√ß√£o e modelo. Podemos pensar nisso como um processo de 2 etapas:

- _projetar_ o prompt inicial para um determinado modelo e objetivo
- _refinar_ o prompt iterativamente para melhorar a qualidade da resposta

Este √© necessariamente um processo de tentativa e erro que requer intui√ß√£o e esfor√ßo do usu√°rio para obter resultados √≥timos. Ent√£o por que isso √© importante? Para responder a essa pergunta, primeiro precisamos entender tr√™s conceitos:

- _Tokeniza√ß√£o_ = como o modelo "v√™" o prompt
- _LLMs Base_ = como o modelo base "processa" um prompt
- _LLMs Ajustados por Instru√ß√£o_ = como o modelo pode agora ver "tarefas"

### Tokeniza√ß√£o

Um LLM v√™ prompts como uma _sequ√™ncia de tokens_ onde diferentes modelos (ou vers√µes de um modelo) podem tokenizar o mesmo prompt de maneiras diferentes. Como os LLMs s√£o treinados em tokens (e n√£o em texto bruto), a maneira como os prompts s√£o tokenizados tem um impacto direto na qualidade da resposta gerada.

Para obter uma intui√ß√£o de como a tokeniza√ß√£o funciona, experimente ferramentas como o [Tokenizador da OpenAI](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) mostrado abaixo. Copie seu prompt - e veja como ele √© convertido em tokens, prestando aten√ß√£o em como os caracteres de espa√ßo em branco e marcas de pontua√ß√£o s√£o tratados. Observe que este exemplo mostra um LLM mais antigo (GPT-3) - ent√£o tentar isso com um modelo mais recente pode produzir um resultado diferente.

### Conceito: Modelos Fundamentais

Uma vez que um prompt √© tokenizado, a fun√ß√£o principal do ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou modelo fundamental) √© prever o token naquela sequ√™ncia. Como os LLMs s√£o treinados em conjuntos de dados de texto massivos, eles t√™m uma boa no√ß√£o das rela√ß√µes estat√≠sticas entre tokens e podem fazer essa previs√£o com alguma confian√ßa. Observe que eles n√£o entendem o _significado_ das palavras no prompt ou token; eles apenas veem um padr√£o que podem "completar" com sua pr√≥xima previs√£o. Eles podem continuar prevendo a sequ√™ncia at√© serem interrompidos por interven√ß√£o do usu√°rio ou alguma condi√ß√£o pr√©-estabelecida.

Quer ver como a conclus√£o baseada em prompt funciona? Insira o prompt acima no [_Playground de Chat_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) do Azure OpenAI com as configura√ß√µes padr√£o. O sistema est√° configurado para tratar prompts como solicita√ß√µes de informa√ß√µes - ent√£o voc√™ deve ver uma conclus√£o que satisfa√ßa esse contexto.

Mas e se o usu√°rio quiser ver algo espec√≠fico que atenda a alguns crit√©rios ou objetivo de tarefa? √â aqui que os LLMs _ajustados por instru√ß√£o_ entram em cena.

### Conceito: LLMs Ajustados por Instru√ß√£o

Um [LLM Ajustado por Instru√ß√£o](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) come√ßa com o modelo fundamental e o ajusta com exemplos ou pares de entrada/sa√≠da (por exemplo, "mensagens" de m√∫ltiplas etapas) que podem conter instru√ß√µes claras - e a resposta da IA tenta seguir essa instru√ß√£o.

Isso usa t√©cnicas como Aprendizado por Refor√ßo com Feedback Humano (RLHF) que podem treinar o modelo para _seguir instru√ß√µes_ e _aprender com feedback_ para que ele produza respostas mais adequadas a aplica√ß√µes pr√°ticas e mais relevantes aos objetivos do usu√°rio.

Vamos experimentar - revise o prompt acima, mas agora altere a _mensagem do sistema_ para fornecer a seguinte instru√ß√£o como contexto:

> _Resuma o conte√∫do que voc√™ recebeu para um aluno da segunda s√©rie. Mantenha o resultado em um par√°grafo com 3-5 pontos._

Veja como o resultado agora √© ajustado para refletir o objetivo e formato desejados? Um educador agora pode usar diretamente essa resposta em seus slides para aquela turma.

## Por que precisamos de Engenharia de Prompt?

Agora que sabemos como os prompts s√£o processados pelos LLMs, vamos falar sobre _por que_ precisamos de engenharia de prompt. A resposta est√° no fato de que os LLMs atuais apresentam uma s√©rie de desafios que tornam _conclus√µes confi√°veis e consistentes_ mais dif√≠ceis de alcan√ßar sem esfor√ßo na constru√ß√£o e otimiza√ß√£o de prompts. Por exemplo:

1. **As respostas dos modelos s√£o estoc√°sticas.** O _mesmo prompt_ provavelmente produzir√° respostas diferentes com diferentes modelos ou vers√µes de modelos. E pode at√© produzir resultados diferentes com o _mesmo modelo_ em momentos diferentes. _T√©cnicas de engenharia de prompt podem nos ajudar a minimizar essas varia√ß√µes fornecendo melhores diretrizes_.

2. **Os modelos podem fabricar respostas.** Os modelos s√£o pr√©-treinados com _conjuntos de dados grandes, mas finitos_, o que significa que eles n√£o t√™m conhecimento sobre conceitos fora desse escopo de treinamento. Como resultado, eles podem produzir conclus√µes que s√£o imprecisas, imagin√°rias ou diretamente contradit√≥rias a fatos conhecidos. _T√©cnicas de engenharia de prompt ajudam os usu√°rios a identificar e mitigar essas fabrica√ß√µes, por exemplo, pedindo cita√ß√µes ou racioc√≠nio √† IA_.

3. **As capacidades dos modelos variam.** Modelos mais novos ou gera√ß√µes de modelos ter√£o capacidades mais ricas, mas tamb√©m trazem peculiaridades √∫nicas e trade-offs em custo e complexidade. _A engenharia de prompt pode nos ajudar a desenvolver melhores pr√°ticas e fluxos de trabalho que abstraem diferen√ßas e se adaptam a requisitos espec√≠ficos de modelos de maneiras escal√°veis e cont√≠nuas_.

Vamos ver isso em a√ß√£o no Playground da OpenAI ou Azure OpenAI:

- Use o mesmo prompt com diferentes implanta√ß√µes de LLM (por exemplo, OpenAI, Azure OpenAI, Hugging Face) - voc√™ viu as varia√ß√µes?
- Use o mesmo prompt repetidamente com a _mesma_ implanta√ß√£o de LLM (por exemplo, playground do Azure OpenAI) - como essas varia√ß√µes diferiram?

### Exemplo de Fabrica√ß√µes

Neste curso, usamos o termo **"fabrica√ß√£o"** para referenciar o fen√¥meno em que LLMs √†s vezes geram informa√ß√µes factualmente incorretas devido a limita√ß√µes em seu treinamento ou outras restri√ß√µes. Voc√™ tamb√©m pode ter ouvido isso referido como _"alucina√ß√µes"_ em artigos populares ou trabalhos de pesquisa. No entanto, recomendamos fortemente o uso de _"fabrica√ß√£o"_ como o termo para que n√£o antropomorfizemos acidentalmente o comportamento atribuindo uma caracter√≠stica humana a um resultado movido por m√°quina. Isso tamb√©m refor√ßa as [diretrizes de IA respons√°vel](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) do ponto de vista da terminologia, removendo termos que tamb√©m podem ser considerados ofensivos ou n√£o inclusivos em alguns contextos.

Quer ter uma ideia de como as fabrica√ß√µes funcionam? Pense em um prompt que instrua a IA a gerar conte√∫do para um t√≥pico inexistente (para garantir que n√£o seja encontrado no conjunto de dados de treinamento). Por exemplo - eu tentei este prompt:

> **Prompt:** gerar um plano de aula sobre a Guerra Marciana de 2076.

Uma pesquisa na web me mostrou que havia relatos fict√≠cios (por exemplo, s√©ries de televis√£o ou livros) sobre guerras marcianas - mas nenhum em 2076. O senso comum tamb√©m nos diz que 2076 est√° _no futuro_ e, portanto, n√£o pode estar associado a um evento real.

Ent√£o, o que acontece quando executamos este prompt com diferentes provedores de LLM?

Como esperado, cada modelo (ou vers√£o de modelo) produz respostas ligeiramente diferentes gra√ßas ao comportamento estoc√°stico e varia√ß√µes de capacidade do modelo. Por exemplo, um modelo direciona um p√∫blico de 8¬™ s√©rie, enquanto o outro assume um estudante do ensino m√©dio. Mas todos os tr√™s modelos geraram respostas que poderiam convencer um usu√°rio desinformado de que o evento era real.

T√©cnicas de engenharia de prompt como _metaprompting_ e _configura√ß√£o de temperatura_ podem reduzir fabrica√ß√µes de modelos at√© certo ponto. Novas _arquiteturas_ de engenharia de prompt tamb√©m incorporam novas ferramentas e t√©cnicas de forma cont√≠nua no fluxo de prompt, para mitigar ou reduzir alguns desses efeitos.

## Estudo de Caso: GitHub Copilot

Vamos encerrar esta se√ß√£o obtendo uma no√ß√£o de como a engenharia de prompt √© usada em solu√ß√µes do mundo real, analisando um Estudo de Caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot √© seu "Programador Pareado por IA" - ele converte prompts de texto em conclus√µes de c√≥digo e √© integrado ao seu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experi√™ncia de usu√°rio cont√≠nua. Conforme documentado na s√©rie de blogs abaixo, a vers√£o mais antiga foi baseada no modelo Codex da OpenAI - com engenheiros rapidamente percebendo a necessidade de ajustar o modelo e desenvolver melhores t√©cnicas de engenharia de prompt, para melhorar a qualidade do c√≥digo. Em julho, eles [estrearam um modelo de IA aprimorado que vai al√©m do Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugest√µes ainda mais r√°pidas.

Leia os posts em ordem, para seguir sua jornada de aprendizado.

Voc√™ tamb√©m pode navegar pelo [blog de Engenharia](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para mais posts como [este](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que mostra como esses modelos e t√©cnicas s√£o _aplicados_ para impulsionar aplica√ß√µes do mundo real.

## Constru√ß√£o de Prompt

Vimos por que a engenharia de prompt √© importante - agora vamos entender como os prompts s√£o _constru√≠dos_ para que possamos avaliar diferentes t√©cnicas para um design de prompt mais eficaz.

### Prompt B√°sico

Vamos come√ßar com o prompt b√°sico: uma entrada de texto enviada ao modelo sem outro contexto. Aqui est√° um exemplo - quando enviamos as primeiras palavras do hino nacional dos EUA para a [API de Completa√ß√£o](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) da OpenAI, ela instantaneamente _completa_ a resposta com as pr√≥ximas linhas, ilustrando o comportamento b√°sico de previs√£o.

### Prompt Complexo

Agora vamos adicionar contexto e instru√ß√µes a esse prompt b√°sico. A [API de Completa√ß√£o de Chat](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir um prompt complexo como uma cole√ß√£o de _mensagens_ com:

- Pares de entrada/sa√≠da refletindo a entrada do _usu√°rio_ e a resposta do _assistente_.
- Mensagem do sistema definindo o contexto para o comportamento ou personalidade do assistente.

A solicita√ß√£o agora est√° no formato abaixo, onde a _tokeniza√ß√£o_ captura efetivamente informa√ß√µes relevantes do contexto e da conversa. Agora, alterar o contexto do sistema pode ser t√£o impactante na qualidade das conclus√µes quanto as entradas fornecidas pelo usu√°rio.

### Prompt de Instru√ß√£o

Nos exemplos acima, o prompt do usu√°rio era uma simples consulta de texto que pode ser interpretada como uma solicita√ß√£o de informa√ß√µes. Com _prompts de instru√ß√£o_, podemos usar esse texto para especificar uma tarefa em mais detalhes, fornecendo uma melhor orienta√ß√£o √† IA. Aqui est√° um exemplo:

### Conte√∫do Principal

Nos exemplos acima, o prompt ainda era bastante aberto, permitindo que o LLM decidisse qual parte de seu conjunto de dados pr√©-treinado era relevante. Com o padr√£o de design de _conte√∫do principal_, o texto de entrada √© dividido em duas partes:

- uma instru√ß√£o (a√ß√£o)
- conte√∫do relevante (que influencia a a√ß√£o)

Aqui est√° um exemplo onde a instru√ß√£o √© "resuma isso em 2 frases".

O segmento de conte√∫do principal pode ser usado de v√°rias maneiras para impulsionar instru√ß√µes mais eficazes:

- **Exemplos** - em vez de dizer ao modelo o que fazer com uma instru√ß√£o expl√≠cita, d√™-lhe exemplos do que fazer e deixe-o inferir o padr√£o.
- **Pistas** - siga a instru√ß√£o com uma "pista" que prepare a conclus√£o, guiando o modelo para respostas mais relevantes.
- **Modelos** - s√£o 'receitas' repet√≠veis para prompts com espa√ßos reservados (vari√°veis) que podem ser personalizadas com dados para casos de uso espec√≠ficos.


Finalmente, o verdadeiro valor dos modelos est√° na capacidade de criar e publicar _bibliotecas de prompts_ para dom√≠nios de aplica√ß√£o vertical - onde o modelo de prompt agora est√° _otimizado_ para refletir o contexto ou exemplos espec√≠ficos da aplica√ß√£o que tornam as respostas mais relevantes e precisas para o p√∫blico-alvo. O reposit√≥rio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √© um √≥timo exemplo dessa abordagem, curando uma biblioteca de prompts para o dom√≠nio da educa√ß√£o com √™nfase em objetivos-chave como planejamento de aulas, design curricular, tutoria de estudantes, etc.

## Conte√∫do de Apoio

Se pensarmos na constru√ß√£o de prompts como tendo uma instru√ß√£o (tarefa) e um alvo (conte√∫do principal), ent√£o o _conte√∫do secund√°rio_ √© como um contexto adicional que fornecemos para **influenciar a sa√≠da de alguma forma**. Pode ser ajuste de par√¢metros, instru√ß√µes de formata√ß√£o, taxonomias de t√≥picos, etc., que podem ajudar o modelo a _adaptar_ sua resposta para atender aos objetivos ou expectativas desejadas do usu√°rio.

Por exemplo: Dado um cat√°logo de cursos com metadados extensivos (nome, descri√ß√£o, n√≠vel, tags de metadados, instrutor, etc.) sobre todos os cursos dispon√≠veis no curr√≠culo:

- podemos definir uma instru√ß√£o para "resumir o cat√°logo de cursos para o outono de 2023"
- podemos usar o conte√∫do principal para fornecer alguns exemplos da sa√≠da desejada
- podemos usar o conte√∫do secund√°rio para identificar as 5 principais "tags" de interesse.

Agora, o modelo pode fornecer um resumo no formato mostrado pelos poucos exemplos - mas se um resultado tiver v√°rias tags, ele pode priorizar as 5 tags identificadas no conte√∫do secund√°rio.

---

## Melhores Pr√°ticas de Prompting

Agora que sabemos como os prompts podem ser _constru√≠dos_, podemos come√ßar a pensar em como _desenh√°-los_ para refletir as melhores pr√°ticas. Podemos pensar nisso em duas partes - ter a _mentalidade_ certa e aplicar as _t√©cnicas_ corretas.

### Mentalidade de Engenharia de Prompts

A Engenharia de Prompts √© um processo de tentativa e erro, ent√£o mantenha tr√™s amplos fatores orientadores em mente:

1. **Entendimento do Dom√≠nio Importa.** A precis√£o e relev√¢ncia da resposta √© uma fun√ß√£o do _dom√≠nio_ em que essa aplica√ß√£o ou usu√°rio opera. Aplique sua intui√ß√£o e expertise no dom√≠nio para **personalizar t√©cnicas** ainda mais. Por exemplo, defina _personalidades espec√≠ficas do dom√≠nio_ em seus prompts de sistema, ou use _modelos espec√≠ficos do dom√≠nio_ em seus prompts de usu√°rio. Forne√ßa conte√∫do secund√°rio que reflita contextos espec√≠ficos do dom√≠nio, ou use _pistas e exemplos espec√≠ficos do dom√≠nio_ para guiar o modelo em dire√ß√£o a padr√µes de uso familiares.

2. **Entendimento do Modelo Importa.** Sabemos que os modelos s√£o estoc√°sticos por natureza. Mas as implementa√ß√µes de modelo tamb√©m podem variar em termos do conjunto de dados de treinamento que usam (conhecimento pr√©-treinado), as capacidades que fornecem (por exemplo, via API ou SDK) e o tipo de conte√∫do para o qual s√£o otimizados (por exemplo, c√≥digo vs. imagens vs. texto). Entenda os pontos fortes e limita√ß√µes do modelo que voc√™ est√° usando e use esse conhecimento para _priorizar tarefas_ ou construir _modelos personalizados_ que sejam otimizados para as capacidades do modelo.

3. **Itera√ß√£o & Valida√ß√£o Importam.** Os modelos est√£o evoluindo rapidamente, assim como as t√©cnicas de engenharia de prompts. Como especialista no dom√≠nio, voc√™ pode ter outro contexto ou crit√©rios para _sua_ aplica√ß√£o espec√≠fica, que podem n√£o se aplicar √† comunidade em geral. Use ferramentas e t√©cnicas de engenharia de prompts para "dar um pontap√© inicial" na constru√ß√£o de prompts, depois itere e valide os resultados usando sua pr√≥pria intui√ß√£o e expertise no dom√≠nio. Registre suas percep√ß√µes e crie uma **base de conhecimento** (por exemplo, bibliotecas de prompts) que pode ser usada como um novo ponto de partida por outros, para itera√ß√µes mais r√°pidas no futuro.

## Melhores Pr√°ticas

Agora vamos examinar as pr√°ticas recomendadas comuns que s√£o recomendadas por praticantes da [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) e [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| O que                             | Por que                                                                                                                                                                                                                                             |
| :-------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Avalie os modelos mais recentes.  | Novas gera√ß√µes de modelos provavelmente t√™m recursos e qualidade aprimorados - mas tamb√©m podem incorrer em custos mais altos. Avalie-os para impacto, depois tome decis√µes de migra√ß√£o.                                                             |
| Separe instru√ß√µes e contexto      | Verifique se seu modelo/fornecedor define _delimitadores_ para distinguir instru√ß√µes, conte√∫do principal e secund√°rio de forma mais clara. Isso pode ajudar os modelos a atribuir pesos mais precisos aos tokens.                                      |
| Seja espec√≠fico e claro           | D√™ mais detalhes sobre o contexto desejado, resultado, comprimento, formato, estilo, etc. Isso melhorar√° tanto a qualidade quanto a consist√™ncia das respostas. Capture receitas em modelos reutiliz√°veis.                                            |
| Seja descritivo, use exemplos     | Os modelos podem responder melhor a uma abordagem de "mostrar e contar". Comece com um `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an ‚Äúout‚Äù           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` valores. Volte para a [se√ß√£o de Sandbox de Aprendizado](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) para aprender como.

### Em seguida, abra o Jupyter Notebook

- Selecione o kernel de tempo de execu√ß√£o. Se estiver usando as op√ß√µes 1 ou 2, basta selecionar o kernel padr√£o Python 3.10.x fornecido pelo cont√™iner de desenvolvimento.

Voc√™ est√° pronto para executar os exerc√≠cios. Observe que n√£o h√° respostas _certas e erradas_ aqui - apenas explorando op√ß√µes por tentativa e erro e construindo intui√ß√£o sobre o que funciona para um determinado modelo e dom√≠nio de aplica√ß√£o.

_Por essa raz√£o, n√£o h√° segmentos de Solu√ß√£o de C√≥digo nesta li√ß√£o. Em vez disso, o Notebook ter√° c√©lulas de Markdown intituladas "Minha Solu√ß√£o:" que mostram um exemplo de sa√≠da para refer√™ncia._

## Verifica√ß√£o de Conhecimento

Qual das op√ß√µes a seguir √© um bom prompt seguindo algumas pr√°ticas recomendadas razo√°veis?

1. Mostre-me uma imagem de carro vermelho
2. Mostre-me uma imagem de carro vermelho da marca Volvo e modelo XC90 estacionado √† beira de um penhasco com o sol se pondo
3. Mostre-me uma imagem de carro vermelho da marca Volvo e modelo XC90

A: 2, √© o melhor prompt, pois fornece detalhes sobre "o que" e vai ao espec√≠fico (n√£o apenas qualquer carro, mas uma marca e modelo espec√≠ficos) e tamb√©m descreve o cen√°rio geral. 3 √© o pr√≥ximo melhor, pois tamb√©m cont√©m muita descri√ß√£o.

## üöÄ Desafio

Veja se voc√™ consegue aproveitar a t√©cnica de "pista" com o prompt: Complete a frase "Mostre-me uma imagem de carro vermelho da marca Volvo e ". Com o que ele responde e como voc√™ melhoraria isso?

## √ìtimo Trabalho! Continue Seu Aprendizado

Quer aprender mais sobre diferentes conceitos de Engenharia de Prompts? V√° para a [p√°gina de aprendizado cont√≠nuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar outros √≥timos recursos sobre este t√≥pico.

V√° para a Li√ß√£o 5, onde veremos [t√©cnicas avan√ßadas de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Aviso Legal**:  
Este documento foi traduzido usando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes err√¥neas decorrentes do uso desta tradu√ß√£o.