<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dcbaaae026cb50fee071e690685b5843",
  "translation_date": "2025-08-26T16:26:18+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "br"
}
-->
# Fundamentos de Engenharia de Prompt

[![Fundamentos de Engenharia de Prompt](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.br.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introdu√ß√£o
Este m√≥dulo aborda conceitos e t√©cnicas essenciais para criar prompts eficazes em modelos de IA generativa. A forma como voc√™ escreve seu prompt para um LLM tamb√©m faz diferen√ßa. Um prompt bem elaborado pode gerar respostas de melhor qualidade. Mas o que exatamente significam termos como _prompt_ e _engenharia de prompt_? E como posso melhorar o _input_ do prompt que envio para o LLM? Essas s√£o as perguntas que vamos tentar responder neste cap√≠tulo e no pr√≥ximo.

A _IA generativa_ √© capaz de criar novos conte√∫dos (por exemplo, texto, imagens, √°udio, c√≥digo etc.) em resposta a solicita√ß√µes dos usu√°rios. Ela faz isso usando _Modelos de Linguagem de Grande Escala_ como a s√©rie GPT ("Generative Pre-trained Transformer") da OpenAI, que s√£o treinados para usar linguagem natural e c√≥digo.

Agora, os usu√°rios podem interagir com esses modelos usando paradigmas familiares como chat, sem precisar de conhecimento t√©cnico ou treinamento. Os modelos s√£o _baseados em prompt_ ‚Äì os usu√°rios enviam um texto (prompt) e recebem a resposta da IA (completion). Eles podem ent√£o "conversar com a IA" de forma iterativa, em conversas de m√∫ltiplas rodadas, refinando o prompt at√© que a resposta atenda √†s suas expectativas.

Os "prompts" agora se tornam a principal _interface de programa√ß√£o_ para aplicativos de IA generativa, dizendo aos modelos o que fazer e influenciando a qualidade das respostas retornadas. "Engenharia de Prompt" √© um campo de estudo em r√°pido crescimento que foca no _design e otimiza√ß√£o_ de prompts para entregar respostas consistentes e de qualidade em escala.

## Objetivos de Aprendizagem

Nesta li√ß√£o, vamos aprender o que √© Engenharia de Prompt, por que ela √© importante e como podemos criar prompts mais eficazes para um determinado modelo e objetivo de aplica√ß√£o. Vamos entender conceitos fundamentais e boas pr√°ticas para engenharia de prompt ‚Äì e conhecer um ambiente interativo de "sandbox" em Jupyter Notebooks onde podemos ver esses conceitos aplicados em exemplos reais.

Ao final desta li√ß√£o, seremos capazes de:

1. Explicar o que √© engenharia de prompt e por que ela √© importante.
2. Descrever os componentes de um prompt e como eles s√£o usados.
3. Aprender boas pr√°ticas e t√©cnicas para engenharia de prompt.
4. Aplicar as t√©cnicas aprendidas em exemplos reais, usando um endpoint da OpenAI.

## Termos-Chave

Engenharia de Prompt: Pr√°tica de projetar e refinar entradas para guiar modelos de IA a produzirem sa√≠das desejadas.
Tokeniza√ß√£o: Processo de converter texto em unidades menores, chamadas tokens, que um modelo pode entender e processar.
LLMs Ajustados por Instru√ß√£o: Modelos de Linguagem de Grande Escala (LLMs) que foram ajustados com instru√ß√µes espec√≠ficas para melhorar a precis√£o e relev√¢ncia das respostas.

## Sandbox de Aprendizagem

A engenharia de prompt atualmente √© mais uma arte do que uma ci√™ncia. A melhor forma de aprimorar nossa intui√ß√£o sobre o tema √© _praticar mais_ e adotar uma abordagem de tentativa e erro que combine conhecimento do dom√≠nio de aplica√ß√£o com t√©cnicas recomendadas e otimiza√ß√µes espec√≠ficas do modelo.

O Jupyter Notebook que acompanha esta li√ß√£o oferece um ambiente _sandbox_ onde voc√™ pode experimentar o que aprender ‚Äì durante a li√ß√£o ou como parte do desafio de c√≥digo ao final. Para executar os exerc√≠cios, voc√™ vai precisar de:

1. **Uma chave de API do Azure OpenAI** ‚Äì o endpoint do servi√ßo para um LLM implantado.
2. **Um ambiente Python** ‚Äì onde o Notebook possa ser executado.
3. **Vari√°veis de ambiente locais** ‚Äì _complete agora os passos do [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) para se preparar_.

O notebook j√° vem com exerc√≠cios _iniciais_ ‚Äì mas voc√™ √© incentivado a adicionar suas pr√≥prias se√ß√µes de _Markdown_ (descri√ß√£o) e _C√≥digo_ (requisi√ß√µes de prompt) para testar mais exemplos ou ideias ‚Äì e desenvolver sua intui√ß√£o para o design de prompts.

## Guia Ilustrado

Quer ter uma vis√£o geral do que esta li√ß√£o cobre antes de come√ßar? Confira este guia ilustrado, que mostra os principais t√≥picos abordados e os pontos-chave para voc√™ refletir em cada um deles. O roteiro da li√ß√£o leva voc√™ do entendimento dos conceitos e desafios centrais at√© como abord√°-los com t√©cnicas e boas pr√°ticas relevantes de engenharia de prompt. Note que a se√ß√£o "T√©cnicas Avan√ßadas" neste guia se refere ao conte√∫do que ser√° abordado no _pr√≥ximo_ cap√≠tulo deste curso.

![Guia Ilustrado de Engenharia de Prompt](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.br.png)

## Nossa Startup

Agora, vamos falar sobre como _este tema_ se relaciona com a miss√£o da nossa startup de [levar inova√ß√£o em IA para a educa√ß√£o](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplica√ß√µes de _aprendizagem personalizada_ com IA ‚Äì ent√£o vamos pensar em como diferentes usu√°rios do nosso aplicativo podem "criar" prompts:

- **Administradores** podem pedir para a IA _analisar dados do curr√≠culo para identificar lacunas de cobertura_. A IA pode resumir os resultados ou visualiz√°-los com c√≥digo.
- **Educadores** podem pedir para a IA _gerar um plano de aula para um p√∫blico e tema espec√≠ficos_. A IA pode montar o plano personalizado em um formato definido.
- **Estudantes** podem pedir para a IA _ajud√°-los em uma mat√©ria dif√≠cil_. A IA pode orientar os alunos com aulas, dicas e exemplos adaptados ao seu n√≠vel.

Isso √© s√≥ o come√ßo. Confira o [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì uma biblioteca open-source de prompts curada por especialistas em educa√ß√£o ‚Äì para ter uma ideia mais ampla das possibilidades! _Experimente rodar alguns desses prompts no sandbox ou usando o OpenAI Playground para ver o que acontece!_

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve cobrir o conceito central #1.
Reforce o conceito com exemplos e refer√™ncias.

CONCEITO #1:
Engenharia de Prompt.
Defina e explique por que ela √© necess√°ria.
-->

## O que √© Engenharia de Prompt?

Come√ßamos esta li√ß√£o definindo **Engenharia de Prompt** como o processo de _criar e otimizar_ entradas de texto (prompts) para entregar respostas consistentes e de qualidade (completions) para um determinado objetivo de aplica√ß√£o e modelo. Podemos pensar nisso como um processo em 2 etapas:

- _criar_ o prompt inicial para um modelo e objetivo espec√≠ficos
- _refinar_ o prompt de forma iterativa para melhorar a qualidade da resposta

Esse √© necessariamente um processo de tentativa e erro que exige intui√ß√£o e esfor√ßo do usu√°rio para obter os melhores resultados. Mas por que isso √© importante? Para responder a essa pergunta, primeiro precisamos entender tr√™s conceitos:

- _Tokeniza√ß√£o_ = como o modelo "enxerga" o prompt
- _LLMs Base_ = como o modelo de base "processa" um prompt
- _LLMs Ajustados por Instru√ß√£o_ = como o modelo agora pode ver "tarefas"

### Tokeniza√ß√£o

Um LLM enxerga prompts como uma _sequ√™ncia de tokens_, onde diferentes modelos (ou vers√µes de um modelo) podem tokenizar o mesmo prompt de maneiras diferentes. Como os LLMs s√£o treinados em tokens (e n√£o no texto bruto), a forma como os prompts s√£o tokenizados tem impacto direto na qualidade da resposta gerada.

Para entender como a tokeniza√ß√£o funciona, experimente ferramentas como o [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) mostrado abaixo. Cole seu prompt e veja como ele √© convertido em tokens, prestando aten√ß√£o em como espa√ßos em branco e pontua√ß√µes s√£o tratados. Note que este exemplo mostra um LLM mais antigo (GPT-3) ‚Äì ent√£o testar com um modelo mais novo pode gerar um resultado diferente.

![Tokeniza√ß√£o](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.br.png)

### Conceito: Modelos de Base

Depois que um prompt √© tokenizado, a principal fun√ß√£o do ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou modelo de base) √© prever o pr√≥ximo token nessa sequ√™ncia. Como os LLMs s√£o treinados em grandes volumes de texto, eles t√™m uma boa no√ß√£o das rela√ß√µes estat√≠sticas entre tokens e conseguem fazer essa previs√£o com certa confian√ßa. Note que eles n√£o entendem o _significado_ das palavras no prompt ou token; eles apenas enxergam um padr√£o que podem "completar" com a pr√≥xima previs√£o. Eles podem continuar prevendo a sequ√™ncia at√© serem interrompidos pelo usu√°rio ou por alguma condi√ß√£o pr√©-estabelecida.

Quer ver como funciona a conclus√£o baseada em prompt? Insira o prompt acima no [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) do Azure OpenAI Studio com as configura√ß√µes padr√£o. O sistema est√° configurado para tratar prompts como solicita√ß√µes de informa√ß√£o ‚Äì ent√£o voc√™ deve ver uma resposta que atenda a esse contexto.

Mas e se o usu√°rio quiser ver algo espec√≠fico que atenda a certos crit√©rios ou objetivos de tarefa? √â a√≠ que entram os LLMs _ajustados por instru√ß√£o_.

![Conclus√£o de Chat com LLM Base](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.br.png)

### Conceito: LLMs Ajustados por Instru√ß√£o

Um [LLM Ajustado por Instru√ß√£o](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) parte do modelo de base e o ajusta com exemplos ou pares de entrada/sa√≠da (por exemplo, "mensagens" de m√∫ltiplas rodadas) que podem conter instru√ß√µes claras ‚Äì e a resposta da IA tenta seguir essa instru√ß√£o.

Isso usa t√©cnicas como Aprendizado por Refor√ßo com Feedback Humano (RLHF), que treinam o modelo para _seguir instru√ß√µes_ e _aprender com feedback_, de modo que ele produza respostas mais adequadas para aplica√ß√µes pr√°ticas e mais relevantes para os objetivos do usu√°rio.

Vamos testar ‚Äì volte ao prompt acima, mas agora altere a _mensagem do sistema_ para fornecer a seguinte instru√ß√£o como contexto:

> _Resuma o conte√∫do fornecido para um aluno do segundo ano. Mantenha o resultado em um par√°grafo com 3-5 t√≥picos em bullet points._

Veja como o resultado agora est√° ajustado para refletir o objetivo e formato desejados? Um educador pode usar essa resposta diretamente em seus slides para aquela turma.

![Conclus√£o de Chat com LLM Ajustado por Instru√ß√£o](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.br.png)

## Por que precisamos de Engenharia de Prompt?

Agora que sabemos como os prompts s√£o processados pelos LLMs, vamos falar sobre _por que_ precisamos de engenharia de prompt. A resposta est√° no fato de que os LLMs atuais apresentam v√°rios desafios que tornam _completions confi√°veis e consistentes_ mais dif√≠ceis de alcan√ßar sem investir na constru√ß√£o e otimiza√ß√£o dos prompts. Por exemplo:

1. **As respostas dos modelos s√£o estoc√°sticas.** O _mesmo prompt_ provavelmente vai gerar respostas diferentes em modelos ou vers√µes de modelos diferentes. E pode at√© gerar resultados diferentes com o _mesmo modelo_ em momentos distintos. _T√©cnicas de engenharia de prompt podem nos ajudar a minimizar essas varia√ß√µes fornecendo melhores direcionamentos_.

1. **Modelos podem fabricar respostas.** Os modelos s√£o pr√©-treinados com conjuntos de dados _grandes, mas finitos_, o que significa que n√£o t√™m conhecimento sobre conceitos fora desse escopo de treinamento. Como resultado, podem gerar respostas imprecisas, inventadas ou at√© contradit√≥rias com fatos conhecidos. _T√©cnicas de engenharia de prompt ajudam os usu√°rios a identificar e mitigar essas fabrica√ß√µes, por exemplo, pedindo cita√ß√µes ou justificativas para a IA_.

1. **As capacidades dos modelos v√£o variar.** Modelos mais novos ou gera√ß√µes diferentes ter√£o mais recursos, mas tamb√©m trazem peculiaridades e trade-offs em custo e complexidade. _A engenharia de prompt pode nos ajudar a desenvolver boas pr√°ticas e fluxos de trabalho que abstraem diferen√ßas e se adaptam a requisitos espec√≠ficos de cada modelo de forma escal√°vel e fluida_.

Vamos ver isso na pr√°tica no OpenAI ou Azure OpenAI Playground:

- Use o mesmo prompt com diferentes implanta√ß√µes de LLM (por exemplo, OpenAI, Azure OpenAI, Hugging Face) ‚Äì voc√™ percebeu as varia√ß√µes?
- Use o mesmo prompt repetidamente com a _mesma_ implanta√ß√£o de LLM (por exemplo, Azure OpenAI playground) ‚Äì como essas varia√ß√µes se comportaram?

### Exemplo de Fabrica√ß√£o

Neste curso, usamos o termo **"fabrica√ß√£o"** para nos referirmos ao fen√¥meno em que LLMs √†s vezes geram informa√ß√µes factualmente incorretas devido a limita√ß√µes no treinamento ou outras restri√ß√µes. Voc√™ tamb√©m pode ter ouvido esse fen√¥meno ser chamado de _"alucina√ß√£o"_ em artigos ou pesquisas. No entanto, recomendamos fortemente o uso do termo _"fabrica√ß√£o"_ para evitar atribuir caracter√≠sticas humanas a um resultado gerado por m√°quina. Isso tamb√©m refor√ßa as [diretrizes de IA Respons√°vel](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) do ponto de vista da terminologia, eliminando termos que podem ser considerados ofensivos ou n√£o inclusivos em alguns contextos.

Quer entender como funcionam as fabrica√ß√µes? Pense em um prompt que instrua a IA a gerar conte√∫do sobre um tema inexistente (para garantir que n√£o esteja no conjunto de treinamento). Por exemplo ‚Äì eu tentei este prompt:
> **Prompt:** crie um plano de aula sobre a Guerra Marciana de 2076.

# Plano de Aula: A Guerra Marciana de 2076

## Objetivo da Aula

Explorar os principais eventos, causas e consequ√™ncias da Guerra Marciana de 2076, incentivando os alunos a analisar o impacto desse conflito na hist√≥ria interplanet√°ria.

## Materiais Necess√°rios

- Quadro branco e marcadores
- Projetor ou tela para apresenta√ß√£o
- C√≥pias do artigo ‚ÄúA Guerra Marciana de 2076: Uma Vis√£o Geral‚Äù
- Folhas para anota√ß√µes

## Introdu√ß√£o (15 minutos)

- Apresente o contexto hist√≥rico: coloniza√ß√£o de Marte, tens√µes entre col√¥nias terrestres e marcianas.
- Explique brevemente o que foi a Guerra Marciana de 2076.
- Pergunte aos alunos o que eles j√° sabem sobre conflitos interplanet√°rios.

## Desenvolvimento (30 minutos)

### 1. Causas da Guerra

- Discuta os principais motivos que levaram ao conflito, como disputas por recursos, autonomia pol√≠tica e avan√ßos tecnol√≥gicos.
- Analise os interesses das diferentes fac√ß√µes envolvidas.

### 2. Principais Eventos

- Apresente uma linha do tempo dos acontecimentos mais importantes durante a guerra.
- Destaque batalhas decisivas, tratados e mudan√ßas de lideran√ßa.

### 3. Consequ√™ncias

- Explore os efeitos da guerra para Marte, Terra e outras col√¥nias.
- Debata as mudan√ßas sociais, pol√≠ticas e tecnol√≥gicas resultantes do conflito.

## Atividade em Grupo (20 minutos)

- Divida a turma em grupos e pe√ßa que cada um analise um aspecto da guerra (causas, eventos ou consequ√™ncias).
- Cada grupo deve apresentar suas conclus√µes para a classe.

## Discuss√£o e Reflex√£o (15 minutos)

- Promova um debate sobre como a Guerra Marciana de 2076 influenciou as rela√ß√µes interplanet√°rias.
- Incentive os alunos a pensar em poss√≠veis paralelos com conflitos hist√≥ricos da Terra.

## Avalia√ß√£o

- Solicite uma reda√ß√£o curta sobre o impacto da Guerra Marciana de 2076 na sociedade marciana.
- Avalie a participa√ß√£o nas discuss√µes e apresenta√ß√µes em grupo.

## Encerramento

- Recapitule os principais pontos da aula.
- Indique leituras complementares sobre hist√≥ria interplanet√°ria e conflitos futuros.
Uma pesquisa na web mostrou que existem relatos fict√≠cios (por exemplo, s√©ries de TV ou livros) sobre guerras em Marte ‚Äì mas nenhum em 2076. O bom senso tamb√©m nos diz que 2076 est√° _no futuro_ e, portanto, n√£o pode estar associado a um evento real.

Ent√£o, o que acontece quando executamos esse prompt com diferentes provedores de LLM?

> **Resposta 1**: OpenAI Playground (GPT-35)

![Resposta 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.br.png)

> **Resposta 2**: Azure OpenAI Playground (GPT-35)

![Resposta 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.br.png)

> **Resposta 3**: : Hugging Face Chat Playground (LLama-2)

![Resposta 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.br.png)

Como esperado, cada modelo (ou vers√£o do modelo) produz respostas um pouco diferentes devido ao comportamento estoc√°stico e varia√ß√µes de capacidade. Por exemplo, um modelo direciona a resposta para um p√∫blico de 8¬™ s√©rie, enquanto outro assume um estudante do ensino m√©dio. Mas todos os tr√™s modelos geraram respostas que poderiam convencer um usu√°rio desinformado de que o evento era real.

T√©cnicas de engenharia de prompt como _metaprompting_ e _configura√ß√£o de temperatura_ podem reduzir as fabrica√ß√µes do modelo at√© certo ponto. Novas _arquiteturas_ de engenharia de prompt tamb√©m incorporam novas ferramentas e t√©cnicas de forma transparente no fluxo do prompt, para mitigar ou reduzir alguns desses efeitos.

## Estudo de Caso: GitHub Copilot

Vamos encerrar esta se√ß√£o entendendo como a engenharia de prompt √© usada em solu√ß√µes do mundo real, analisando um Estudo de Caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

O GitHub Copilot √© seu "par de programa√ß√£o com IA" ‚Äì ele converte prompts de texto em sugest√µes de c√≥digo e √© integrado ao seu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experi√™ncia fluida. Como documentado na s√©rie de blogs abaixo, a vers√£o inicial era baseada no modelo OpenAI Codex ‚Äì com os engenheiros rapidamente percebendo a necessidade de ajustar o modelo e desenvolver melhores t√©cnicas de engenharia de prompt para melhorar a qualidade do c√≥digo. Em julho, eles [lan√ßaram um modelo de IA aprimorado que vai al√©m do Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugest√µes ainda mais r√°pidas.

Leia as postagens na ordem para acompanhar a jornada de aprendizado deles.

- **Maio 2023** | [O GitHub Copilot est√° ficando melhor em entender seu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maio 2023** | [Por dentro do GitHub: Trabalhando com os LLMs por tr√°s do GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jun 2023** | [Como escrever prompts melhores para o GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Jul 2023** | [.. GitHub Copilot vai al√©m do Codex com modelo de IA aprimorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Jul 2023** | [Guia do desenvolvedor para engenharia de prompt e LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Set 2023** | [Como construir um app empresarial com LLM: Li√ß√µes do GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Voc√™ tamb√©m pode navegar pelo [blog de Engenharia](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) deles para mais postagens como [esta aqui](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que mostra como esses modelos e t√©cnicas s√£o _aplicados_ para impulsionar aplica√ß√µes reais.

---

## Constru√ß√£o de Prompts

J√° vimos por que a engenharia de prompt √© importante ‚Äì agora vamos entender como os prompts s√£o _constru√≠dos_ para que possamos avaliar diferentes t√©cnicas para um design de prompt mais eficaz.

### Prompt B√°sico

Vamos come√ßar com o prompt b√°sico: uma entrada de texto enviada ao modelo sem nenhum outro contexto. Veja um exemplo ‚Äì quando enviamos as primeiras palavras do hino nacional dos EUA para a [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) da OpenAI, ela imediatamente _completa_ a resposta com as pr√≥ximas linhas, ilustrando o comportamento b√°sico de previs√£o.

| Prompt (Entrada)     | Completamento (Sa√≠da)                                                                                                                        |
| :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see   | Parece que voc√™ est√° come√ßando a letra de "The Star-Spangled Banner", o hino nacional dos Estados Unidos. A letra completa √© ...             |

### Prompt Complexo

Agora vamos adicionar contexto e instru√ß√µes a esse prompt b√°sico. A [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) permite construir um prompt complexo como uma cole√ß√£o de _mensagens_ com:

- Pares de entrada/sa√≠da refletindo a entrada do _usu√°rio_ e a resposta do _assistente_.
- Mensagem de sistema definindo o contexto para o comportamento ou personalidade do assistente.

A requisi√ß√£o agora tem o formato abaixo, onde a _tokeniza√ß√£o_ captura efetivamente as informa√ß√µes relevantes do contexto e da conversa. Agora, mudar o contexto do sistema pode impactar tanto a qualidade das respostas quanto as entradas fornecidas pelo usu√°rio.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt de Instru√ß√£o

Nos exemplos acima, o prompt do usu√°rio era uma consulta de texto simples que pode ser interpretada como um pedido de informa√ß√£o. Com prompts de _instru√ß√£o_, podemos usar esse texto para especificar uma tarefa com mais detalhes, fornecendo uma orienta√ß√£o melhor para a IA. Veja um exemplo:

| Prompt (Entrada)                                                                                                                                                                                                                         | Completamento (Sa√≠da)                                                                                                        | Tipo de Instru√ß√£o   |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Escreva uma descri√ß√£o da Guerra Civil                                                                                                                                                                                                   | _retornou um par√°grafo simples_                                                                                              | Simples             |
| Escreva uma descri√ß√£o da Guerra Civil. Forne√ßa datas e eventos importantes e descreva sua import√¢ncia                                                                                             | _retornou um par√°grafo seguido de uma lista de datas de eventos importantes com descri√ß√µes_                                  | Complexa            |
| Escreva uma descri√ß√£o da Guerra Civil em 1 par√°grafo. Forne√ßa 3 t√≥picos com datas importantes e sua import√¢ncia. Forne√ßa mais 3 t√≥picos com figuras hist√≥ricas e suas contribui√ß√µes. Retorne a sa√≠da como um arquivo JSON                | _retorna detalhes mais extensos em uma caixa de texto, formatados como JSON que voc√™ pode copiar e validar conforme necess√°rio_ | Complexa. Formatada.|

## Conte√∫do Prim√°rio

Nos exemplos acima, o prompt ainda era bastante aberto, permitindo que o LLM decidisse qual parte do seu conjunto de dados pr√©-treinado era relevante. Com o padr√£o de design de _conte√∫do prim√°rio_, o texto de entrada √© dividido em duas partes:

- uma instru√ß√£o (a√ß√£o)
- conte√∫do relevante (que influencia a a√ß√£o)

Veja um exemplo onde a instru√ß√£o √© "resuma isso em 2 frases".

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completamento (Sa√≠da)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa de um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registrada. Ele recebe o nome do deus romano J√∫piter.[19] Quando visto da Terra, J√∫piter pode ser brilhante o suficiente para que sua luz refletida projete sombras vis√≠veis,[20] e √© em m√©dia o terceiro objeto natural mais brilhante no c√©u noturno depois da Lua e de V√™nus. <br/> **Resuma isso em 2 frases curtas** | J√∫piter, o quinto planeta a partir do Sol, √© o maior do Sistema Solar e √© conhecido por ser um dos objetos mais brilhantes no c√©u noturno. Nomeado em homenagem ao deus romano J√∫piter, √© um gigante gasoso cuja massa √© duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. |

O segmento de conte√∫do prim√°rio pode ser usado de v√°rias formas para gerar instru√ß√µes mais eficazes:

- **Exemplos** ‚Äì em vez de dizer explicitamente ao modelo o que fazer, forne√ßa exemplos do que fazer e deixe-o inferir o padr√£o.
- **Cues (Dicas)** ‚Äì siga a instru√ß√£o com uma "dica" que prepara a resposta, guiando o modelo para respostas mais relevantes.
- **Templates (Modelos)** ‚Äì s√£o 'receitas' repet√≠veis de prompts com espa√ßos reservados (vari√°veis) que podem ser personalizados com dados para casos de uso espec√≠ficos.

Vamos explorar essas abordagens na pr√°tica.

### Usando Exemplos

Essa √© uma abordagem em que voc√™ usa o conte√∫do prim√°rio para "alimentar o modelo" com exemplos do resultado desejado para uma determinada instru√ß√£o, e deixa que ele infira o padr√£o para a sa√≠da desejada. Dependendo do n√∫mero de exemplos fornecidos, podemos ter prompting zero-shot, one-shot, few-shot etc.

O prompt agora consiste em tr√™s componentes:

- Uma descri√ß√£o da tarefa
- Alguns exemplos do resultado desejado
- O in√≠cio de um novo exemplo (que se torna uma descri√ß√£o impl√≠cita da tarefa)

| Tipo de Aprendizado | Prompt (Entrada)                                                                                                                                        | Completamento (Sa√≠da)         |
| :------------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :---------------------------- |
| Zero-shot           | "The Sun is Shining". Translate to Spanish                                                                                                              | "El Sol est√° brillando".      |
| One-shot            | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                   | "Es un d√≠a fr√≠o y ventoso".   |
| Few-shot            | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>   | Basketball                    |
|                     |                                                                                                                                                         |                               |

Note como tivemos que fornecer uma instru√ß√£o expl√≠cita ("Translate to Spanish") no prompting zero-shot, mas ela √© inferida no exemplo one-shot. O exemplo few-shot mostra como adicionar mais exemplos permite que os modelos fa√ßam infer√™ncias mais precisas sem instru√ß√µes adicionais.

### Dicas no Prompt (Prompt Cues)

Outra t√©cnica para usar o conte√∫do prim√°rio √© fornecer _dicas_ em vez de exemplos. Nesse caso, estamos dando ao modelo um empurr√£o na dire√ß√£o certa _come√ßando_ com um trecho que reflete o formato de resposta desejado. O modelo ent√£o "pega a dica" e continua nesse estilo.

| N√∫mero de Dicas | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completamento (Sa√≠da)                                                                                                                                                                                                                                                                                       |
| :-------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0               | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa de um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registrada.

**Resuma Isso**                                       | J√∫piter √© o maior planeta do nosso Sistema Solar e o quinto a partir do Sol. √â um gigante gasoso com uma massa equivalente a 1/1000 da massa do Sol, mas √© mais pesado que todos os outros planetas juntos. Civiliza√ß√µes antigas j√° conheciam J√∫piter h√° muito tempo, e ele √© facilmente vis√≠vel no c√©u noturno. |
| 1              | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da massa do Sol, mas duas vezes e meia a massa de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registrada. <br/>**Resuma Isso** <br/> O que aprendemos √© que J√∫piter | √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da massa do Sol, mas duas vezes e meia a massa de todos os outros planetas juntos. √â facilmente vis√≠vel a olho nu e conhecido desde os tempos antigos.                        |
| 2              | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa equivalente a um mil√©simo da massa do Sol, mas duas vezes e meia a massa de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e √© conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registrada. <br/>**Resuma Isso** <br/> Top 3 Fatos Que Aprendemos:         | 1. J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. <br/> 2. √â um gigante gasoso com uma massa equivalente a um mil√©simo da massa do Sol...<br/> 3. J√∫piter √© vis√≠vel a olho nu desde os tempos antigos ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Modelos de Prompt

Um modelo de prompt √© uma _receita pr√©-definida para um prompt_ que pode ser armazenada e reutilizada conforme necess√°rio, para garantir experi√™ncias de usu√°rio mais consistentes em escala. Na forma mais simples, √© apenas uma cole√ß√£o de exemplos de prompt como [este da OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que fornece tanto os componentes interativos do prompt (mensagens de usu√°rio e sistema) quanto o formato de requisi√ß√£o via API - para facilitar a reutiliza√ß√£o.

Em uma forma mais avan√ßada, como [este exemplo da LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), ele cont√©m _espa√ßos reservados_ que podem ser substitu√≠dos por dados de v√°rias fontes (entrada do usu√°rio, contexto do sistema, fontes externas de dados etc.) para gerar um prompt de forma din√¢mica. Isso permite criar uma biblioteca de prompts reutiliz√°veis que podem ser usados para garantir experi√™ncias de usu√°rio consistentes **programaticamente** em escala.

Por fim, o verdadeiro valor dos modelos est√° na capacidade de criar e publicar _bibliotecas de prompts_ para dom√≠nios de aplica√ß√£o espec√≠ficos - onde o modelo de prompt √© _otimizado_ para refletir o contexto ou exemplos do aplicativo, tornando as respostas mais relevantes e precisas para o p√∫blico-alvo. O reposit√≥rio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √© um √≥timo exemplo dessa abordagem, reunindo uma biblioteca de prompts para o setor educacional com foco em objetivos como planejamento de aulas, elabora√ß√£o de curr√≠culo, tutoria de alunos etc.

## Conte√∫do de Apoio

Se pensarmos na constru√ß√£o de prompts como tendo uma instru√ß√£o (tarefa) e um alvo (conte√∫do principal), ent√£o o _conte√∫do secund√°rio_ √© como um contexto adicional que fornecemos para **influenciar a sa√≠da de alguma forma**. Pode ser par√¢metros de ajuste, instru√ß√µes de formata√ß√£o, taxonomias de t√≥picos etc. que ajudam o modelo a _personalizar_ sua resposta para atender aos objetivos ou expectativas do usu√°rio.

Por exemplo: Dado um cat√°logo de cursos com metadados extensos (nome, descri√ß√£o, n√≠vel, tags, instrutor etc.) sobre todos os cursos dispon√≠veis no curr√≠culo:

- podemos definir uma instru√ß√£o para "resumir o cat√°logo de cursos para o semestre de Outono de 2023"
- podemos usar o conte√∫do principal para fornecer alguns exemplos do formato desejado
- podemos usar o conte√∫do secund√°rio para identificar as 5 principais "tags" de interesse.

Assim, o modelo pode fornecer um resumo no formato mostrado pelos exemplos - mas se um resultado tiver v√°rias tags, ele pode priorizar as 5 tags identificadas no conte√∫do secund√°rio.

---

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve abordar o conceito central #1.
Reforce o conceito com exemplos e refer√™ncias.

CONCEITO #3:
T√©cnicas de Engenharia de Prompt.
Quais s√£o algumas t√©cnicas b√°sicas de engenharia de prompt?
Ilustre com alguns exerc√≠cios.
-->

## Melhores Pr√°ticas de Prompt

Agora que sabemos como prompts podem ser _constru√≠dos_, podemos come√ßar a pensar em como _desenh√°-los_ para refletir as melhores pr√°ticas. Podemos pensar nisso em duas partes - ter a _mentalidade_ certa e aplicar as _t√©cnicas_ corretas.

### Mentalidade de Engenharia de Prompt

Engenharia de Prompt √© um processo de tentativa e erro, ent√£o mantenha tr√™s fatores amplos em mente:

1. **Entendimento do Dom√≠nio √© Importante.** A precis√£o e relev√¢ncia da resposta dependem do _dom√≠nio_ em que o aplicativo ou usu√°rio opera. Use sua intui√ß√£o e experi√™ncia para **personalizar t√©cnicas**. Por exemplo, defina _personalidades espec√≠ficas do dom√≠nio_ nos prompts de sistema, ou use _modelos espec√≠ficos do dom√≠nio_ nos prompts de usu√°rio. Forne√ßa conte√∫do secund√°rio que reflita contextos do dom√≠nio, ou use _dicas e exemplos espec√≠ficos_ para guiar o modelo para padr√µes de uso familiares.

2. **Entendimento do Modelo √© Importante.** Sabemos que os modelos s√£o estoc√°sticos por natureza. Mas as implementa√ß√µes tamb√©m podem variar quanto ao conjunto de dados de treinamento (conhecimento pr√©-treinado), √†s capacidades oferecidas (por exemplo, via API ou SDK) e ao tipo de conte√∫do para o qual s√£o otimizados (c√≥digo, imagens, texto etc.). Entenda os pontos fortes e limita√ß√µes do modelo que est√° usando, e use esse conhecimento para _priorizar tarefas_ ou criar _modelos personalizados_ otimizados para as capacidades do modelo.

3. **Itera√ß√£o & Valida√ß√£o s√£o Importantes.** Os modelos est√£o evoluindo rapidamente, assim como as t√©cnicas de engenharia de prompt. Como especialista no dom√≠nio, voc√™ pode ter outros contextos ou crit√©rios para _sua_ aplica√ß√£o espec√≠fica, que talvez n√£o se apliquem √† comunidade em geral. Use ferramentas e t√©cnicas de engenharia de prompt para "dar o pontap√© inicial" na constru√ß√£o do prompt, depois itere e valide os resultados usando sua pr√≥pria intui√ß√£o e experi√™ncia. Registre seus aprendizados e crie uma **base de conhecimento** (por exemplo, bibliotecas de prompts) que possa ser usada como novo ponto de partida por outros, acelerando futuras itera√ß√µes.

## Melhores Pr√°ticas

Agora vamos ver algumas pr√°ticas recomendadas por profissionais da [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) e [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| O qu√™                              | Por qu√™                                                                                                                                                                                                                                               |
| :--------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Avalie os modelos mais recentes.   | Novas gera√ß√µes de modelos tendem a ter recursos e qualidade aprimorados - mas podem ter custos maiores. Avalie o impacto e decida sobre migra√ß√£o.                                                                                                     |
| Separe instru√ß√µes e contexto       | Verifique se seu modelo/provedor define _delimitadores_ para distinguir instru√ß√µes, conte√∫do principal e secund√°rio de forma mais clara. Isso pode ajudar o modelo a atribuir pesos mais precisos aos tokens.                                         |
| Seja espec√≠fico e claro            | D√™ mais detalhes sobre o contexto desejado, resultado, tamanho, formato, estilo etc. Isso melhora tanto a qualidade quanto a consist√™ncia das respostas. Capture receitas em modelos reutiliz√°veis.                                                   |
| Seja descritivo, use exemplos      | Os modelos podem responder melhor a uma abordagem de "mostrar e contar". Comece com uma abordagem `zero-shot` (s√≥ instru√ß√£o, sem exemplos) e depois tente `few-shot` como refinamento, fornecendo alguns exemplos do resultado desejado. Use analogias. |
| Use dicas para iniciar respostas   | Direcione para o resultado desejado dando algumas palavras ou frases iniciais que o modelo pode usar como ponto de partida para a resposta.                                                                                                            |
| Reforce instru√ß√µes                 | √Äs vezes √© preciso repetir para o modelo. D√™ instru√ß√µes antes e depois do conte√∫do principal, use instru√ß√£o e dica, etc. Itere e valide para ver o que funciona.                                                                                      |
| A ordem importa                    | A ordem em que voc√™ apresenta as informa√ß√µes ao modelo pode impactar a sa√≠da, at√© nos exemplos de aprendizado, devido ao vi√©s de rec√™ncia. Teste diferentes op√ß√µes para ver o que funciona melhor.                                                    |
| D√™ uma ‚Äúsa√≠da‚Äù ao modelo           | D√™ ao modelo uma resposta de _fallback_ que ele pode fornecer se n√£o conseguir completar a tarefa por algum motivo. Isso pode reduzir as chances de respostas falsas ou inventadas.                                                                  |
|                                   |                                                                                                                                                                                                                                                      |

Como toda boa pr√°tica, lembre-se que _os resultados podem variar_ dependendo do modelo, da tarefa e do dom√≠nio. Use essas dicas como ponto de partida e itere para encontrar o que funciona melhor para voc√™. Reavalie constantemente seu processo de engenharia de prompt conforme novos modelos e ferramentas surgem, focando em escalabilidade e qualidade das respostas.

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve propor um desafio de c√≥digo, se aplic√°vel

DESAFIO:
Link para um Jupyter Notebook com apenas os coment√°rios de c√≥digo nas instru√ß√µes (se√ß√µes de c√≥digo est√£o vazias).

SOLU√á√ÉO:
Link para uma c√≥pia desse Notebook com os prompts preenchidos e executados, mostrando um exemplo de sa√≠da.
-->

## Atividade

Parab√©ns! Voc√™ chegou ao final da li√ß√£o! Agora √© hora de colocar alguns desses conceitos e t√©cnicas em pr√°tica com exemplos reais!

Para nossa atividade, vamos usar um Jupyter Notebook com exerc√≠cios que voc√™ pode completar de forma interativa. Voc√™ tamb√©m pode estender o Notebook com suas pr√≥prias c√©lulas de Markdown e C√≥digo para explorar ideias e t√©cnicas por conta pr√≥pria.

### Para come√ßar, fa√ßa um fork do reposit√≥rio, ent√£o

- (Recomendado) Inicie o GitHub Codespaces
- (Alternativamente) Clone o reposit√≥rio para seu dispositivo local e use com Docker Desktop
- (Alternativamente) Abra o Notebook no ambiente de execu√ß√£o de sua prefer√™ncia.

### Depois, configure suas vari√°veis de ambiente

- Copie o arquivo `.env.copy` da raiz do reposit√≥rio para `.env` e preencha os valores de `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` e `AZURE_OPENAI_DEPLOYMENT`. Volte √† [se√ß√£o Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) para aprender como.

### Em seguida, abra o Jupyter Notebook

- Selecione o kernel de execu√ß√£o. Se estiver usando as op√ß√µes 1 ou 2, basta selecionar o kernel padr√£o Python 3.10.x fornecido pelo dev container.

Pronto! Agora √© s√≥ rodar os exerc√≠cios. Lembre-se que n√£o h√° respostas _certas ou erradas_ aqui - o objetivo √© explorar op√ß√µes por tentativa e erro e construir intui√ß√£o sobre o que funciona para cada modelo e dom√≠nio de aplica√ß√£o.

_Por isso, n√£o h√° segmentos de Solu√ß√£o de C√≥digo nesta li√ß√£o. Em vez disso, o Notebook ter√° c√©lulas de Markdown intituladas "Minha Solu√ß√£o:" mostrando um exemplo de sa√≠da para refer√™ncia._

 <!--
MODELO DE LI√á√ÉO:
Encerre a se√ß√£o com um resumo e recursos para autoaprendizagem.
-->

## Checagem de Conhecimento

Qual dos prompts abaixo segue boas pr√°ticas recomendadas?

1. Mostre uma imagem de carro vermelho
2. Mostre uma imagem de carro vermelho da marca Volvo e modelo XC90 estacionado perto de um penhasco com o sol se pondo
3. Mostre uma imagem de carro vermelho da marca Volvo e modelo XC90

A: 2, √© o melhor prompt pois traz detalhes sobre "o qu√™" e vai al√©m (n√£o √© qualquer carro, mas uma marca e modelo espec√≠ficos) e tamb√©m descreve o cen√°rio. O 3 √© o pr√≥ximo melhor, pois tamb√©m cont√©m bastante descri√ß√£o.

## üöÄ Desafio

Veja se voc√™ consegue usar a t√©cnica de "dica" com o prompt: Complete a frase "Mostre uma imagem de carro vermelho da marca Volvo e ". O que o modelo responde, e como voc√™ melhoraria isso?

## Muito Bem! Continue Aprendendo

Quer aprender mais sobre diferentes conceitos de Engenharia de Prompt? Acesse a [p√°gina de aprendizado cont√≠nuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar outros √≥timos recursos sobre o tema.

V√° para a Li√ß√£o 5 onde veremos [t√©cnicas avan√ßadas de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Aviso Legal**:
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte oficial. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.