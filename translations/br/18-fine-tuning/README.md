<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:41:32+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "br"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.br.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Ajustando Seu LLM

Usar grandes modelos de linguagem para construir aplica√ß√µes de IA generativa traz novos desafios. Uma quest√£o fundamental √© garantir a qualidade das respostas (precis√£o e relev√¢ncia) no conte√∫do gerado pelo modelo para uma determinada solicita√ß√£o do usu√°rio. Nas li√ß√µes anteriores, discutimos t√©cnicas como engenharia de prompt e gera√ß√£o aumentada por recupera√ß√£o, que tentam resolver o problema _modificando a entrada do prompt_ para o modelo existente.

Na li√ß√£o de hoje, vamos falar sobre uma terceira t√©cnica, o **fine-tuning**, que busca resolver o desafio _re-treinando o pr√≥prio modelo_ com dados adicionais. Vamos aos detalhes.

## Objetivos de Aprendizagem

Esta li√ß√£o apresenta o conceito de fine-tuning para modelos de linguagem pr√©-treinados, explora os benef√≠cios e desafios dessa abordagem, e oferece orienta√ß√µes sobre quando e como usar o fine-tuning para melhorar o desempenho dos seus modelos de IA generativa.

Ao final desta li√ß√£o, voc√™ dever√° ser capaz de responder √†s seguintes perguntas:

- O que √© fine-tuning para modelos de linguagem?
- Quando e por que o fine-tuning √© √∫til?
- Como posso fazer fine-tuning em um modelo pr√©-treinado?
- Quais s√£o as limita√ß√µes do fine-tuning?

Pronto? Vamos come√ßar.

## Guia Ilustrado

Quer ter uma vis√£o geral do que vamos abordar antes de mergulhar no conte√∫do? Confira este guia ilustrado que descreve a jornada de aprendizado desta li√ß√£o ‚Äî desde os conceitos principais e a motiva√ß√£o para o fine-tuning, at√© o entendimento do processo e das melhores pr√°ticas para executar essa tarefa. Este √© um tema fascinante para explorar, ent√£o n√£o esque√ßa de visitar a p√°gina de [Recursos](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) para links adicionais que apoiem sua jornada de aprendizado autodirigida!

![Guia Ilustrado para Fine Tuning de Modelos de Linguagem](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.br.png)

## O que √© fine-tuning para modelos de linguagem?

Por defini√ß√£o, grandes modelos de linguagem s√£o _pr√©-treinados_ com grandes quantidades de texto provenientes de diversas fontes, incluindo a internet. Como aprendemos nas li√ß√µes anteriores, precisamos de t√©cnicas como _engenharia de prompt_ e _gera√ß√£o aumentada por recupera√ß√£o_ para melhorar a qualidade das respostas do modelo √†s perguntas do usu√°rio ("prompts").

Uma t√©cnica popular de engenharia de prompt envolve dar ao modelo mais orienta√ß√µes sobre o que se espera na resposta, seja fornecendo _instru√ß√µes_ (orienta√ß√£o expl√≠cita) ou _dando alguns exemplos_ (orienta√ß√£o impl√≠cita). Isso √© chamado de _few-shot learning_, mas tem duas limita√ß√µes:

- Os limites de tokens do modelo podem restringir o n√∫mero de exemplos que voc√™ pode fornecer, limitando a efic√°cia.
- O custo dos tokens pode tornar caro adicionar exemplos a cada prompt, limitando a flexibilidade.

Fine-tuning √© uma pr√°tica comum em sistemas de machine learning onde pegamos um modelo pr√©-treinado e o re-treinamos com novos dados para melhorar seu desempenho em uma tarefa espec√≠fica. No contexto de modelos de linguagem, podemos fazer fine-tuning no modelo pr√©-treinado _com um conjunto selecionado de exemplos para uma tarefa ou dom√≠nio espec√≠fico_ para criar um **modelo personalizado** que pode ser mais preciso e relevante para essa tarefa ou dom√≠nio. Um benef√≠cio adicional do fine-tuning √© que ele pode reduzir o n√∫mero de exemplos necess√°rios para o few-shot learning ‚Äî diminuindo o uso de tokens e os custos relacionados.

## Quando e por que devemos fazer fine-tuning em modelos?

Neste _contexto_, quando falamos de fine-tuning, estamos nos referindo ao fine-tuning **supervisionado**, onde o re-treinamento √© feito **adicionando novos dados** que n√£o faziam parte do conjunto de dados original. Isso √© diferente do fine-tuning n√£o supervisionado, onde o modelo √© re-treinado nos dados originais, mas com hiperpar√¢metros diferentes.

O ponto principal a lembrar √© que fine-tuning √© uma t√©cnica avan√ßada que requer um certo n√≠vel de expertise para alcan√ßar os resultados desejados. Se feito incorretamente, pode n√£o trazer as melhorias esperadas e at√© prejudicar o desempenho do modelo para o dom√≠nio alvo.

Ent√£o, antes de aprender "como" fazer fine-tuning em modelos de linguagem, voc√™ precisa saber "por que" deve seguir esse caminho e "quando" iniciar o processo. Comece se perguntando:

- **Caso de Uso**: Qual √© o seu _caso de uso_ para o fine-tuning? Qual aspecto do modelo pr√©-treinado atual voc√™ quer melhorar?
- **Alternativas**: Voc√™ j√° tentou _outras t√©cnicas_ para alcan√ßar os resultados desejados? Use-as para criar uma linha de base para compara√ß√£o.
  - Engenharia de prompt: Experimente t√©cnicas como few-shot prompting com exemplos de respostas relevantes. Avalie a qualidade das respostas.
  - Gera√ß√£o Aumentada por Recupera√ß√£o: Tente aumentar os prompts com resultados de consultas recuperadas ao buscar em seus dados. Avalie a qualidade das respostas.
- **Custos**: Voc√™ identificou os custos do fine-tuning?
  - Tunabilidade ‚Äî o modelo pr√©-treinado est√° dispon√≠vel para fine-tuning?
  - Esfor√ßo ‚Äî para preparar os dados de treinamento, avaliar e refinar o modelo.
  - Computa√ß√£o ‚Äî para executar os trabalhos de fine-tuning e implantar o modelo ajustado.
  - Dados ‚Äî acesso a exemplos de qualidade suficiente para impacto do fine-tuning.
- **Benef√≠cios**: Voc√™ confirmou os benef√≠cios do fine-tuning?
  - Qualidade ‚Äî o modelo ajustado superou a linha de base?
  - Custo ‚Äî ele reduz o uso de tokens simplificando os prompts?
  - Extensibilidade ‚Äî voc√™ pode reaproveitar o modelo base para novos dom√≠nios?

Respondendo a essas perguntas, voc√™ deve conseguir decidir se o fine-tuning √© a abordagem certa para seu caso de uso. Idealmente, a abordagem √© v√°lida somente se os benef√≠cios superarem os custos. Uma vez decidido seguir em frente, √© hora de pensar em _como_ fazer fine-tuning no modelo pr√©-treinado.

Quer mais insights sobre o processo de decis√£o? Assista [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Como podemos fazer fine-tuning em um modelo pr√©-treinado?

Para fazer fine-tuning em um modelo pr√©-treinado, voc√™ precisa ter:

- um modelo pr√©-treinado para ajustar
- um conjunto de dados para usar no fine-tuning
- um ambiente de treinamento para executar o trabalho de fine-tuning
- um ambiente de hospedagem para implantar o modelo ajustado

## Fine-Tuning na Pr√°tica

Os recursos a seguir oferecem tutoriais passo a passo para gui√°-lo em um exemplo real usando um modelo selecionado com um conjunto de dados curado. Para seguir esses tutoriais, voc√™ precisa de uma conta no provedor espec√≠fico, al√©m de acesso ao modelo e aos conjuntos de dados relevantes.

| Provedor    | Tutorial                                                                                                                                                                       | Descri√ß√£o                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [Como fazer fine-tuning em modelos de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)    | Aprenda a fazer fine-tuning em um `gpt-35-turbo` para um dom√≠nio espec√≠fico ("assistente de receitas") preparando os dados de treinamento, executando o trabalho de fine-tuning e usando o modelo ajustado para infer√™ncia.                                                                                                                                                                                                       |
| Azure OpenAI| [Tutorial de fine-tuning GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Aprenda a fazer fine-tuning em um modelo `gpt-35-turbo-0613` **no Azure** seguindo os passos para criar e enviar os dados de treinamento, executar o trabalho de fine-tuning, implantar e usar o novo modelo.                                                                                                                                                                                                                      |
| Hugging Face| [Fine-tuning de LLMs com Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                           | Este post no blog mostra como fazer fine-tuning em um _LLM aberto_ (ex: `CodeLlama 7B`) usando a biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) e o [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) com [datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) abertos no Hugging Face. |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ü§ó AutoTrain| [Fine-tuning de LLMs com AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                     | AutoTrain (ou AutoTrain Advanced) √© uma biblioteca Python desenvolvida pela Hugging Face que permite fine-tuning para v√°rias tarefas, incluindo ajuste fino de LLMs. AutoTrain √© uma solu√ß√£o sem c√≥digo e o fine-tuning pode ser feito na sua pr√≥pria nuvem, no Hugging Face Spaces ou localmente. Suporta interface web, CLI e treinamento via arquivos de configura√ß√£o yaml.                                                                                 |
|             |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                  |

## Exerc√≠cio

Escolha um dos tutoriais acima e siga-o. _Podemos replicar uma vers√£o desses tutoriais em Jupyter Notebooks neste reposit√≥rio apenas para refer√™ncia. Por favor, use as fontes originais diretamente para obter as vers√µes mais recentes_.

## Excelente trabalho! Continue seu aprendizado.

Ap√≥s concluir esta li√ß√£o, confira nossa [cole√ß√£o de Aprendizado em IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

Parab√©ns!! Voc√™ completou a √∫ltima li√ß√£o da s√©rie v2 deste curso! N√£o pare de aprender e construir. \*\*Confira a p√°gina de [RECURSOS](RESOURCES.md?WT.mc_id=academic-105485-koreyst) para uma lista de sugest√µes adicionais s√≥ sobre este tema.

Nossa s√©rie v1 de li√ß√µes tamb√©m foi atualizada com mais exerc√≠cios e conceitos. Ent√£o, reserve um minuto para atualizar seu conhecimento ‚Äî e por favor, [compartilhe suas d√∫vidas e feedback](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) para nos ajudar a melhorar essas li√ß√µes para a comunidade.

**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autorizada. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.