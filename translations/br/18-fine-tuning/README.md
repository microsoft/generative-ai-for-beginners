<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T17:48:25+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "br"
}
-->
[![Modelos Open Source](../../../../../translated_images/br/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Ajustando Seu LLM

Usar grandes modelos de linguagem para construir aplica√ß√µes de IA generativa traz novos desafios. Uma quest√£o chave √© garantir a qualidade da resposta (precis√£o e relev√¢ncia) no conte√∫do gerado pelo modelo para uma determinada solicita√ß√£o do usu√°rio. Em li√ß√µes anteriores, discutimos t√©cnicas como engenharia de prompts e gera√ß√£o aumentada por recupera√ß√£o que tentam resolver o problema modificando a entrada do prompt para o modelo existente.

Na li√ß√£o de hoje, discutimos uma terceira t√©cnica, **ajuste fino (fine-tuning)**, que tenta resolver o desafio ao re-treinar o pr√≥prio modelo com dados adicionais. Vamos mergulhar nos detalhes.

## Objetivos de Aprendizagem

Esta li√ß√£o introduz o conceito de ajuste fino para modelos de linguagem pr√©-treinados, explora os benef√≠cios e desafios dessa abordagem e fornece orienta√ß√µes sobre quando e como usar ajuste fino para melhorar o desempenho de seus modelos de IA generativa.

Ao final desta li√ß√£o, voc√™ dever√° ser capaz de responder √†s seguintes perguntas:

- O que √© ajuste fino para modelos de linguagem?
- Quando, e por que, o ajuste fino √© √∫til?
- Como posso ajustar finamente um modelo pr√©-treinado?
- Quais s√£o as limita√ß√µes do ajuste fino?

Pronto? Vamos come√ßar.

## Guia Ilustrado

Quer ter uma vis√£o geral do que vamos cobrir antes de come√ßar? Confira este guia ilustrado que descreve a jornada de aprendizagem para esta li√ß√£o - desde aprender os conceitos principais e motiva√ß√£o para o ajuste fino, at√© entender o processo e as melhores pr√°ticas para executar a tarefa de ajuste fino. Este √© um t√≥pico fascinante para explorar, ent√£o n√£o deixe de visitar a p√°gina de [Recursos](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) para links adicionais que apoiem sua jornada de aprendizado autodidata!

![Guia Ilustrado para Ajuste Fino de Modelos de Linguagem](../../../../../translated_images/br/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## O que √© ajuste fino para modelos de linguagem?

Por defini√ß√£o, grandes modelos de linguagem s√£o _pr√©-treinados_ em grandes quantidades de texto obtidas de diversas fontes, incluindo a internet. Como aprendemos em li√ß√µes anteriores, precisamos de t√©cnicas como _engenharia de prompt_ e _gera√ß√£o aumentada por recupera√ß√£o_ para melhorar a qualidade das respostas do modelo √†s perguntas do usu√°rio ("prompts").

Uma t√©cnica popular de engenharia de prompt √© dar mais orienta√ß√£o ao modelo sobre o que se espera na resposta, seja fornecendo _instru√ß√µes_ (orienta√ß√£o expl√≠cita) ou _dando alguns exemplos_ (orienta√ß√£o impl√≠cita). Isso √© chamado de _few-shot learning_, mas possui duas limita√ß√µes:

- Limites de tokens do modelo podem restringir o n√∫mero de exemplos que voc√™ pode fornecer e limitar a efic√°cia.
- Custos em tokens podem tornar caro adicionar exemplos em todos os prompts, limitando a flexibilidade.

Ajuste fino √© uma pr√°tica comum em sistemas de aprendizado de m√°quina onde pegamos um modelo pr√©-treinado e o re-treinamos com novos dados para melhorar seu desempenho em uma tarefa espec√≠fica. No contexto dos modelos de linguagem, podemos ajustar finamente o modelo pr√©-treinado _com um conjunto selecionado de exemplos para uma dada tarefa ou dom√≠nio de aplica√ß√£o_ para criar um **modelo personalizado** que pode ser mais preciso e relevante para essa tarefa ou dom√≠nio espec√≠fico. Um benef√≠cio adicional do ajuste fino √© que ele pode tamb√©m reduzir o n√∫mero de exemplos necess√°rios para few-shot learning - reduzindo o uso de tokens e os custos relacionados.

## Quando e por que devemos ajustar finamente os modelos?

Neste _contexto_, quando falamos de ajuste fino estamos nos referindo ao ajuste fino **supervisionado**, onde o re-treinamento √© feito **adicionando novos dados** que n√£o faziam parte do conjunto de dados original de treinamento. Isso √© diferente de uma abordagem de ajuste fino n√£o supervisionado, onde o modelo √© re-treinado sobre os dados originais, mas com hiperpar√¢metros diferentes.

O ponto principal √© que ajuste fino √© uma t√©cnica avan√ßada que requer um certo n√≠vel de especializa√ß√£o para alcan√ßar os resultados desejados. Se feito incorretamente, pode n√£o trazer as melhorias esperadas, e pode at√© degradar o desempenho do modelo para o dom√≠nio alvo.

Portanto, antes de aprender "como" ajustar finamente modelos de linguagem, voc√™ precisa saber "por que" deve seguir esse caminho, e "quando" iniciar o processo de ajuste fino. Comece fazendo a si mesmo essas perguntas:

- **Caso de Uso**: Qual √© o seu _caso de uso_ para ajuste fino? Qual aspecto do modelo pr√©-treinado atual voc√™ deseja melhorar?
- **Alternativas**: Voc√™ j√° tentou _outras t√©cnicas_ para alcan√ßar os resultados desejados? Utilize-as para criar uma base de compara√ß√£o.
  - Engenharia de prompt: Experimente t√©cnicas como few-shot prompting com exemplos relevantes de respostas. Avalie a qualidade das respostas.
  - Gera√ß√£o Aumentada por Recupera√ß√£o: Experimente aumentar os prompts com resultados de buscas em seus dados. Avalie a qualidade das respostas.
- **Custos**: Voc√™ identificou os custos do ajuste fino?
  - Capacidade de ajuste - o modelo pr√©-treinado est√° dispon√≠vel para ajuste fino?
  - Esfor√ßo - para prepara√ß√£o dos dados de treinamento, avalia√ß√£o e refinamento do modelo.
  - Computa√ß√£o - para rodar os jobs de ajuste fino e implantar o modelo ajustado
  - Dados - acesso a exemplos de qualidade suficientes para impacto do ajuste fino
- **Benef√≠cios**: Voc√™ confirmou os benef√≠cios do ajuste fino?
  - Qualidade - o modelo ajustado superou a linha de base?
  - Custo - ele reduz o uso de tokens ao simplificar os prompts?
  - Extensibilidade - voc√™ pode reutilizar o modelo base para novos dom√≠nios?

Respondendo a essas perguntas, voc√™ poder√° decidir se o ajuste fino √© a abordagem correta para seu caso de uso. Idealmente, a abordagem √© v√°lida apenas se os benef√≠cios superarem os custos. Uma vez decidido seguir adiante, √© hora de pensar _como_ voc√™ pode ajustar finamente o modelo pr√©-treinado.

Quer mais insights sobre o processo de tomada de decis√£o? Assista a [Ajustar fino ou n√£o ajustar fino](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Como podemos ajustar finamente um modelo pr√©-treinado?

Para ajustar finamente um modelo pr√©-treinado, voc√™ precisa ter:

- um modelo pr√©-treinado para ajuste fino
- um conjunto de dados para usar no ajuste fino
- um ambiente de treinamento para executar o job de ajuste fino
- um ambiente de hospedagem para implantar o modelo ajustado

## Ajuste Fino em A√ß√£o

Os recursos a seguir fornecem tutoriais passo a passo para gui√°-lo por um exemplo real usando um modelo selecionado com um conjunto de dados curado. Para seguir esses tutoriais, voc√™ precisa de uma conta no provedor espec√≠fico, juntamente com acesso ao modelo relevante e conjuntos de dados.

| Provedor    | Tutorial                                                                                                                                                                        | Descri√ß√£o                                                                                                                                                                                                                                                                                                                                                                                                                       |
| ----------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [Como ajustar finamente modelos chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)           | Aprenda a ajustar finamente um `gpt-35-turbo` para um dom√≠nio espec√≠fico ("assistente de receita") preparando dados de treinamento, executando o job de ajuste fino e usando o modelo ajustado para infer√™ncia.                                                                                                                                                                                                                  |
| Azure OpenAI| [Tutorial de ajuste fino GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst)  | Aprenda a ajustar finamente um modelo `gpt-35-turbo-0613` **no Azure** realizando os passos para criar e fazer upload dos dados de treinamento, executar o job de ajuste fino, implantar e usar o novo modelo.                                                                                                                                                                                                                 |
| Hugging Face| [Ajustando finamente LLMs com Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                         | Este post no blog mostra como ajustar finamente um _LLM aberto_ (ex: `CodeLlama 7B`) usando a biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) e o [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) com conjuntos de [dados abertos](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) no Hugging Face.|
|             |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                               |
| ü§ó AutoTrain| [Ajustando finamente LLMs com AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                    | AutoTrain (ou AutoTrain Advanced) √© uma biblioteca python desenvolvida pela Hugging Face que permite ajuste fino para muitas tarefas diferentes incluindo ajuste fino de LLMs. AutoTrain √© uma solu√ß√£o sem c√≥digo e o ajuste fino pode ser feito na sua pr√≥pria nuvem, no Hugging Face Spaces ou localmente. Suporta interface gr√°fica web, CLI e treinamento via arquivos de configura√ß√£o yaml.                                                                                       |
|             |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                               |
| ü¶• Unsloth  | [Ajustando finamente LLMs com Unsloth](https://github.com/unslothai/unsloth)                                                                                                   | Unsloth √© um framework open-source que suporta ajuste fino de LLMs e aprendizado por refor√ßo (RL). Unsloth facilita treinamento local, avalia√ß√£o e implanta√ß√£o com [notebooks prontos](https://github.com/unslothai/notebooks). Tamb√©m suporta texto para voz (TTS), BERT e modelos multimodais. Para come√ßar, leia o guia passo a passo [Fine-tuning LLMs Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                                                        |
|             |                                                                                                                                                                                 |                                                                                                                                                                                                                                                                                                                                                                                                                               |
## Tarefa

Escolha um dos tutoriais acima e siga-o. _Podemos replicar uma vers√£o desses tutoriais em Jupyter Notebooks neste reposit√≥rio apenas para refer√™ncia. Por favor, use as fontes originais diretamente para obter as vers√µes mais recentes_.

## √ìtimo Trabalho! Continue Seu Aprendizado.

Ap√≥s completar esta li√ß√£o, confira nossa [cole√ß√£o de Aprendizado de IA Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para continuar aprimorando seu conhecimento em IA Generativa!

Parab√©ns!! Voc√™ completou a li√ß√£o final da s√©rie v2 deste curso! N√£o pare de aprender e construir. \*\*Confira a p√°gina de [RECURSOS](RESOURCES.md?WT.mc_id=academic-105485-koreyst) para uma lista de sugest√µes adicionais s√≥ sobre esse t√≥pico.

Nossa s√©rie v1 de li√ß√µes tamb√©m foi atualizada com mais tarefas e conceitos. Ent√£o, reserve um minuto para relembrar seus conhecimentos - e por favor [compartilhe suas d√∫vidas e feedback](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) para nos ajudar a melhorar essas li√ß√µes para a comunidade.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o autom√°tica [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos para garantir a precis√£o, esteja ciente de que tradu√ß√µes automatizadas podem conter erros ou imprecis√µes. O documento original em seu idioma nativo deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se a tradu√ß√£o profissional humana. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->