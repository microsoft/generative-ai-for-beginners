{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिचय\n",
    "\n",
    "यो पाठमा समेटिनेछ:\n",
    "- फंक्शन कल के हो र यसको प्रयोगका क्षेत्रहरू\n",
    "- OpenAI प्रयोग गरेर फंक्शन कल कसरी बनाउने\n",
    "- फंक्शन कललाई एप्लिकेसनमा कसरी एकीकृत गर्ने\n",
    "\n",
    "## अध्ययनका उद्देश्यहरू\n",
    "\n",
    "यो पाठ पूरा गरेपछि तपाईंले जान्नुहुनेछ र बुझ्नुहुनेछ:\n",
    "\n",
    "- फंक्शन कल प्रयोग गर्ने उद्देश्य\n",
    "- OpenAI सेवा प्रयोग गरेर फंक्शन कल सेटअप गर्ने तरिका\n",
    "- तपाईंको एप्लिकेसनको प्रयोगका लागि प्रभावकारी फंक्शन कल डिजाइन गर्ने तरिका\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## फंक्शन कलहरू बुझ्दै\n",
    "\n",
    "यस पाठका लागि, हामी हाम्रो शिक्षा स्टार्टअपका लागि एउटा फिचर बनाउन चाहन्छौं जसले प्रयोगकर्ताहरूलाई च्याटबोट प्रयोग गरेर प्राविधिक कोर्सहरू खोज्न दिन्छ। हामी तिनीहरूको सीप स्तर, हालको भूमिका र चासोको प्रविधिमा आधारित कोर्सहरू सिफारिस गर्नेछौं।\n",
    "\n",
    "यसलाई पूरा गर्न हामीले यी कुराहरूको संयोजन प्रयोग गर्नेछौं:\n",
    " - `OpenAI` प्रयोगकर्ताका लागि च्याट अनुभव बनाउन\n",
    " - `Microsoft Learn Catalog API` प्रयोगकर्ताको अनुरोध अनुसार कोर्सहरू खोज्न सहयोग गर्न\n",
    " - `Function Calling` प्रयोगकर्ताको सोधाइ लिएर फंक्शनमा पठाएर API अनुरोध गर्न\n",
    "\n",
    "सुरु गर्नका लागि, हामीले किन फंक्शन कल प्रयोग गर्न चाहन्छौं भन्ने कुरा हेरौं:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT बाट नयाँ प्रतिक्रिया प्राप्त गर्नुहोस् जहाँ उसले फंक्शनको प्रतिक्रिया देख्न सक्छ\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### किन Function Calling\n",
    "\n",
    "यदि तपाईंले यस कोर्सको कुनै अन्य पाठ पूरा गर्नुभएको छ भने, तपाईंले सायद ठूलो भाषा मोडेल (LLMs) प्रयोग गर्दा कस्तो शक्ति हुन्छ भन्ने कुरा बुझ्नुभएको छ। आशा छ, तपाईंले तिनीहरूको केही सीमाहरू पनि देख्नुभएको छ।\n",
    "\n",
    "Function Calling भनेको OpenAI Service को एउटा सुविधा हो, जसले तलका चुनौतीहरू समाधान गर्नका लागि बनाइएको हो:\n",
    "\n",
    "असंगत प्रतिक्रिया ढाँचा:\n",
    "- Function calling भन्दा पहिले, ठूलो भाषा मोडेलबाट आउने प्रतिक्रियाहरू असंरचित र असंगत हुन्थे। विकासकर्ताहरूले प्रत्येक फरक-फरक नतिजा सम्हाल्न जटिल मान्यता कोड लेख्नुपर्थ्यो।\n",
    "\n",
    "बाह्य डेटा सँग सीमित एकीकरण:\n",
    "- यो सुविधाअघि, एप्लिकेशनका अन्य भागबाट डेटा च्याट सन्दर्भमा ल्याउन गाह्रो हुन्थ्यो।\n",
    "\n",
    "प्रतिक्रिया ढाँचालाई मानकीकरण गरेर र बाह्य डेटा सँग सहज एकीकरण सम्भव बनाएर, function calling ले विकास प्रक्रिया सजिलो बनाउँछ र थप मान्यता तर्कको आवश्यकता घटाउँछ।\n",
    "\n",
    "प्रयोगकर्ताहरूले \"स्टकहोमको अहिलेको मौसम कस्तो छ?\" जस्ता प्रश्नको उत्तर पाउन सक्दैनथे। यसको कारण, मोडेलहरूलाई तालिम दिइएको समयसम्मको मात्र जानकारी हुन्थ्यो।\n",
    "\n",
    "अब, तलको उदाहरण हेरौं जसले यो समस्या देखाउँछ:\n",
    "\n",
    "मानौं हामी विद्यार्थीहरूको डेटा राख्ने डाटाबेस बनाउन चाहन्छौं ताकि हामी तिनीहरूलाई उपयुक्त कोर्स सिफारिस गर्न सकौं। तल दुई जना विद्यार्थीको विवरण छ, जसमा भएका तथ्यांकहरू धेरै मिल्दोजुल्दो छन्।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हामी यो डाटा पार्स गर्न LLM मा पठाउन चाहन्छौं। यो पछि हाम्रो एप्लिकेशनमा API मा पठाउन वा डाटाबेसमा भण्डारण गर्न प्रयोग गर्न सकिन्छ।\n",
    "\n",
    "आउनुहोस्, दुईवटा उस्तै प्रॉम्प्टहरू बनाउँ, जसमा हामी LLM लाई कुन जानकारीमा चासो छ भनेर निर्देशन दिन्छौं:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हामी यो हाम्रो उत्पादनका लागि महत्त्वपूर्ण भागहरू पार्स गर्न LLM लाई पठाउन चाहन्छौं। त्यसैले हामी LLM लाई निर्देशन दिन दुईवटा उस्तै प्रॉम्प्टहरू बनाउन सक्छौं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "यी दुई प्रॉम्प्टहरू सिर्जना गरेपछि, हामी तिनीहरूलाई LLM मा `openai.ChatCompletion` प्रयोग गरेर पठाउनेछौं। हामी प्रॉम्प्टलाई `messages` भेरिएबलमा भण्डारण गर्छौं र भूमिका `user` मा तोक्छौं। यो प्रयोगकर्ताबाट च्याटबोटमा लेखिएको सन्देशको नक्कल गर्नका लागि हो।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "यद्यपि प्रॉम्प्टहरू उस्तै छन् र विवरणहरू पनि मिल्दोजुल्दो छन्, हामीले `Grades` प्रोपर्टीका विभिन्न स्वरूपहरू पाउन सक्छौं।\n",
    "\n",
    "यदि तपाईं माथिको सेल धेरै पटक चलाउनु भयो भने, स्वरूप `3.7` वा `3.7 GPA` हुन सक्छ।\n",
    "\n",
    "यो किनभने LLM ले लेखिएको प्रॉम्प्टको रूपमा असंरचित डेटा लिन्छ र असंरचित डेटा नै फर्काउँछ। हामीलाई संरचित स्वरूप चाहिन्छ ताकि यो डेटा भण्डारण गर्दा वा प्रयोग गर्दा के अपेक्षा गर्ने भन्ने थाहा होस्।\n",
    "\n",
    "फंक्शनल कलिङ प्रयोग गर्दा, हामीले संरचित डेटा फिर्ता पाउँछौं भन्ने सुनिश्चित गर्न सक्छौं। फंक्शन कलिङ प्रयोग गर्दा, LLM ले वास्तवमा कुनै फंक्शन चलाउँदैन वा कल गर्दैन। बरु, हामीले LLM लाई यसको प्रतिक्रिया दिनका लागि एउटा संरचना बनाउँछौं। त्यसपछि ती संरचित प्रतिक्रियाहरू प्रयोग गरेर हाम्रो एप्लिकेसनमा कुन फंक्शन चलाउने भन्ने थाहा पाउँछौं।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![फंक्शन कलिङ प्रवाह चित्र](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ne.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कल प्रयोग गर्ने उपयोगका केसहरू\n",
    "\n",
    "**बाह्य उपकरणहरू कल गर्ने**\n",
    "च्याटबोटहरू प्रयोगकर्ताबाट आएका प्रश्नहरूको उत्तर दिनमा निकै सक्षम छन्। फंक्शन कलको प्रयोग गरेर, च्याटबोटहरूले प्रयोगकर्ताका सन्देशहरू प्रयोग गरेर केही कार्यहरू पूरा गर्न सक्छन्। उदाहरणका लागि, विद्यार्थीले च्याटबोटलाई \"मेरो शिक्षकलाई इमेल पठाइदिनुहोस् कि मलाई यो विषयमा थप सहयोग चाहिन्छ\" भन्न सक्छ। यसले `send_email(to: string, body: string)` नामक फंक्शन कल गर्न सक्छ।\n",
    "\n",
    "**API वा डाटाबेस क्वेरीहरू बनाउने**\n",
    "प्रयोगकर्ताहरूले प्राकृतिक भाषामा जानकारी खोज्न सक्छन्, जुन फर्म्याट गरिएको क्वेरी वा API अनुरोधमा रूपान्तरण हुन्छ। यसको उदाहरणमा शिक्षकले \"पछिल्लो असाइनमेन्ट पूरा गरेका विद्यार्थीहरू को हुन्?\" भनेर सोध्न सक्छन्, जसले `get_completed(student_name: string, assignment: int, current_status: string)` नामक फंक्शन कल गर्न सक्छ।\n",
    "\n",
    "**संरचित डाटा बनाउने**\n",
    "प्रयोगकर्ताहरूले कुनै पाठको ब्लक वा CSV लिएर LLM प्रयोग गरेर त्यसबाट महत्वपूर्ण जानकारी निकाल्न सक्छन्। उदाहरणका लागि, विद्यार्थीले शान्ति सम्झौताबारेको विकिपिडिया लेखलाई AI फ्ल्यास कार्ड बनाउन रूपान्तरण गर्न सक्छ। यो `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` नामक फंक्शन प्रयोग गरेर गर्न सकिन्छ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## २. आफ्नो पहिलो फंक्शन कल बनाउने\n",
    "\n",
    "फंक्शन कल बनाउने प्रक्रिया तीन मुख्य चरणहरूमा विभाजित छ:\n",
    "१. तपाईंका फंक्शनहरूको सूची र प्रयोगकर्ताको सन्देशसहित Chat Completions API मा कल गर्नुहोस्\n",
    "२. मोडेलको प्रतिक्रिया पढ्नुहोस् र आवश्यक कार्य गर्नुहोस्, जस्तै फंक्शन वा API कल चलाउनु\n",
    "३. तपाईंको फंक्शनबाट आएको प्रतिक्रियासहित फेरि Chat Completions API मा कल गर्नुहोस्, ताकि त्यो जानकारी प्रयोग गरेर प्रयोगकर्तालाई जवाफ तयार गर्न सकियोस्।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![फंक्शन कलको प्रवाह](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ne.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कलका तत्वहरू\n",
    "\n",
    "#### प्रयोगकर्ताको इनपुट\n",
    "\n",
    "पहिलो चरणमा प्रयोगकर्ताको सन्देश तयार गर्नुपर्छ। यो सन्देशलाई तपाईंले टेक्स्ट इनपुटको मानबाट डाइनामिक रूपमा लिन सक्नुहुन्छ, वा यहाँ नै मान सेट गर्न सक्नुहुन्छ। यदि तपाईं पहिलो पटक Chat Completions API प्रयोग गर्दै हुनुहुन्छ भने, हामीले सन्देशको `role` र `content` परिभाषित गर्नुपर्छ।\n",
    "\n",
    "`role` तीन प्रकारको हुन सक्छ: `system` (नियम बनाउने), `assistant` (मोडेल), वा `user` (अन्तिम प्रयोगकर्ता)। फंक्शन कलका लागि हामी यसलाई `user` राख्नेछौं र एउटा उदाहरण प्रश्न दिनेछौं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शनहरू बनाउँदै।\n",
    "\n",
    "अब हामी एउटा फंक्शन र त्यस फंक्शनका प्यारामिटरहरू परिभाषित गर्नेछौं। यहाँ हामी `search_courses` नामको एउटा मात्र फंक्शन प्रयोग गर्नेछौं, तर तपाईंले धेरै फंक्शनहरू पनि बनाउन सक्नुहुन्छ।\n",
    "\n",
    "**महत्वपूर्ण** : फंक्शनहरू LLM को सिस्टम सन्देशमा समावेश गरिन्छन् र तपाईंको उपलब्ध टोकनको संख्यामा पनि गनिन्छ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**परिभाषाहरू**\n",
    "\n",
    "फंक्शन परिभाषा संरचनामा धेरै तहहरू हुन्छन्, प्रत्येकको आफ्नै विशेषता हुन्छ। यहाँ नेस्ट गरिएको संरचनाको विवरण छ:\n",
    "\n",
    "**शीर्ष स्तर फंक्शनका विशेषताहरू:**\n",
    "\n",
    "`name` -  त्यो फंक्शनको नाम जुन हामीले कल गर्न चाहेका छौं।\n",
    "\n",
    "`description` - यो फंक्शन कसरी काम गर्छ भन्ने विवरण हो। यहाँ स्पष्ट र विशेष हुनु महत्त्वपूर्ण छ।\n",
    "\n",
    "`parameters` - ती मानहरू र ढाँचा जसलाई तपाईंले मोडेलले आफ्नो उत्तरमा उत्पादन गरोस् भन्ने चाहनुहुन्छ\n",
    "\n",
    "**Parameters वस्तुको विशेषताहरू:**\n",
    "\n",
    "`type` -  parameters वस्तुको डेटा प्रकार (सामान्यतया \"object\")\n",
    "\n",
    "`properties` - ती विशेष मानहरूको सूची जुन मोडेलले आफ्नो उत्तरका लागि प्रयोग गर्नेछ\n",
    "\n",
    "**व्यक्तिगत Parameter का विशेषताहरू:**\n",
    "\n",
    "`name` - सम्पत्ति कुञ्जीबाट अप्रत्यक्ष रूपमा परिभाषित (जस्तै, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - यो विशेष parameter को डेटा प्रकार (जस्तै, \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - सो विशेष parameter को विवरण\n",
    "\n",
    "**वैकल्पिक विशेषताहरू:**\n",
    "\n",
    "`required` - एउटा array जसमा ती parameter हरूको सूची हुन्छ जुन फंक्शन कल पूरा गर्न आवश्यक छन्\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कल गर्ने तरिका\n",
    "फंक्शन परिभाषित गरेपछि, अब हामीले यसलाई Chat Completion API को कलमा समावेश गर्नुपर्छ। यो गर्नका लागि हामीले अनुरोधमा `functions` थप्नुपर्छ। यस अवस्थामा `functions=functions` हुन्छ।\n",
    "\n",
    "यहाँ `function_call` लाई `auto` मा सेट गर्ने विकल्प पनि छ। यसको अर्थ, प्रयोगकर्ताको सन्देशको आधारमा कुन फंक्शन कल गर्ने भन्ने निर्णय LLM ले आफैं गर्छ, हामीले छुट्टै तोक्नुपर्दैन।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हामी प्रतिक्रिया हेर्छौं र यसको ढाँचा कस्तो छ भनेर बुझौं:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "तपाईं देख्न सक्नुहुन्छ कि function को नाम बोलाइएको छ र प्रयोगकर्ताको सन्देशबाट, LLM ले function का arguments मा मिल्ने डेटा फेला पार्न सकेको छ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ३. एप्लिकेसनमा फंक्शन कलहरू एकीकृत गर्दै\n",
    "\n",
    "हामीले LLM बाट आएको फर्म्याट गरिएको प्रतिक्रिया परीक्षण गरेपछि, अब यसलाई एप्लिकेसनमा एकीकृत गर्न सक्छौं।\n",
    "\n",
    "### फ्लो व्यवस्थापन गर्दै\n",
    "\n",
    "यसलाई हाम्रो एप्लिकेसनमा एकीकृत गर्नका लागि, तलका चरणहरू अपनाऔं:\n",
    "\n",
    "पहिले, OpenAI सेवामा कल गरौं र सन्देशलाई `response_message` नामको भेरिएबलमा राखौं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हामीले त्यो फंक्शन परिभाषित गर्नेछौं जसले Microsoft Learn API लाई कल गरेर कोर्सहरूको सूची ल्याउनेछ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "एक राम्रो अभ्यासको रूपमा, हामी त्यसपछि हेर्नेछौं कि मोडेलले कुनै फंक्शन कल गर्न चाहन्छ कि चाहँदैन। त्यसपछि, हामी उपलब्ध फंक्शनहरू मध्ये कुनै एक बनाउनेछौं र त्यसलाई कल गर्न लागिएको फंक्शनसँग मिलाउनेछौं।\n",
    "\n",
    "त्यसपछि, हामी फंक्शनका आर्गुमेन्टहरू लिनेछौं र तिनीहरूलाई LLM बाट आएका आर्गुमेन्टहरूसँग मिलाउनेछौं।\n",
    "\n",
    "अन्त्यमा, हामी फंक्शन कल सन्देश र `search_courses` सन्देशबाट फर्किएका मानहरू थप्नेछौं। यसले LLM लाई प्रयोगकर्तालाई प्राकृतिक भाषामा जवाफ दिन आवश्यक सबै जानकारी दिन्छ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कोड चुनौती\n",
    "\n",
    "शानदार काम! OpenAI Function Calling को सिकाइलाई अगाडि बढाउन तपाईंले निम्न बनाउन सक्नुहुन्छ: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - फंक्शनका थप प्यारामिटरहरू जसले सिक्न चाहनेहरूलाई थप कोर्सहरू फेला पार्न मद्दत गर्न सक्छ। तपाईं यहाँ उपलब्ध API प्यारामिटरहरू फेला पार्न सक्नुहुन्छ:  \n",
    " - अर्को फंक्शन कल बनाउनुहोस् जसले सिक्न चाहनेको मातृभाषा जस्ता थप जानकारी लिन्छ  \n",
    " - जब फंक्शन कल र/वा API कलले उपयुक्त कोर्सहरू फिर्ता गर्दैन भने त्रुटि ह्यान्डलिङ बनाउनुहोस्\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nयो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छन्। मूल भाषा मा रहेको मूल दस्तावेज़लाई नै आधिकारिक स्रोत मान्नुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार हुने छैनौं।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T20:56:38+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}