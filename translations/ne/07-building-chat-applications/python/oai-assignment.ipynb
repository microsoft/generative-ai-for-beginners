{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# अध्याय ७: च्याट एप्लिकेसनहरू बनाउने\n",
    "## OpenAI API छिटो सुरु\n",
    "\n",
    "यो नोटबुक [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) बाट अनुकूलित गरिएको हो, जसमा [Azure OpenAI](notebook-azure-openai.ipynb) सेवाहरू पहुँच गर्न सकिने नोटबुकहरू समावेश छन्।\n",
    "\n",
    "Python OpenAI API ले Azure OpenAI Models सँग पनि काम गर्छ, केही परिवर्तनहरूका साथ। यहाँ फरक के छ भन्ने थप जान्नका लागि हेर्नुहोस्: [Python मा OpenAI र Azure OpenAI endpoints साट्ने तरिका](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# अवलोकन  \n",
    "\"ठूला भाषा मोडेलहरू पाठलाई पाठमा रूपान्तरण गर्ने कार्यहरू हुन्। कुनै इनपुट स्ट्रिङ पाठ दिँदा, ठूला भाषा मोडेलले त्यसपछि आउने पाठको अनुमान गर्न प्रयास गर्छ\"(1)। यो \"छिटो सुरु\" नोटबुकले प्रयोगकर्ताहरूलाई उच्च-स्तरका LLM अवधारणाहरू, AML सँग सुरु गर्न आवश्यक मुख्य प्याकेजहरू, प्रॉम्प्ट डिजाइनको हल्का परिचय, र विभिन्न प्रयोगका केही छोटा उदाहरणहरू प्रस्तुत गर्नेछ।\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## सामग्री सूची  \n",
    "\n",
    "[सारांश](../../../../07-building-chat-applications/python)  \n",
    "[OpenAI सेवा कसरी प्रयोग गर्ने](../../../../07-building-chat-applications/python)  \n",
    "[1. आफ्नो OpenAI सेवा सिर्जना गर्ने](../../../../07-building-chat-applications/python)  \n",
    "[2. स्थापना](../../../../07-building-chat-applications/python)    \n",
    "[3. प्रमाणिकरण विवरणहरू](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[प्रयोगका क्षेत्रहरू](../../../../07-building-chat-applications/python)    \n",
    "[1. पाठ संक्षेप गर्नुहोस्](../../../../07-building-chat-applications/python)  \n",
    "[2. पाठ वर्गीकरण गर्नुहोस्](../../../../07-building-chat-applications/python)  \n",
    "[3. नयाँ उत्पादन नामहरू सिर्जना गर्नुहोस्](../../../../07-building-chat-applications/python)  \n",
    "[4. वर्गीकरणकर्ता फाइन ट्युन गर्नुहोस्](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[सन्दर्भहरू](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### आफ्नो पहिलो प्रॉम्प्ट बनाउनुहोस्  \n",
    "यो छोटो अभ्यासले OpenAI मोडेलमा प्रॉम्प्टहरू पेश गर्ने आधारभूत परिचय दिनेछ, जहाँ तपाईंले \"सारांश\" जस्तो साधारण कार्य गर्नुहुन्छ।\n",
    "\n",
    "**चरणहरू**:  \n",
    "1. आफ्नो python वातावरणमा OpenAI लाइब्रेरी इन्स्टल गर्नुहोस्  \n",
    "2. सामान्य सहायक लाइब्रेरीहरू लोड गर्नुहोस् र तपाईंले बनाएको OpenAI सेवा लागि आवश्यक सुरक्षा प्रमाणिकरण सेट गर्नुहोस्  \n",
    "3. आफ्नो कार्यका लागि उपयुक्त मोडेल छान्नुहोस्  \n",
    "4. मोडेलका लागि साधारण प्रॉम्प्ट तयार गर्नुहोस्  \n",
    "5. आफ्नो अनुरोध मोडेल API मा पेश गर्नुहोस्!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ३. सही मोडेल फेला पार्नुहोस्  \n",
    "GPT-3.5-turbo वा GPT-4 मोडेलहरूले प्राकृतिक भाषा बुझ्न र उत्पन्न गर्न सक्छन्।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ४. प्रॉम्प्ट डिजाइन  \n",
    "\n",
    "\"ठूला भाषा मोडेलहरूको जादू भनेको, ठूलो मात्रामा पाठमा भविष्यवाणी त्रुटि घटाउने गरी तालिम दिँदा, मोडेलहरूले यस्ता भविष्यवाणीका लागि उपयोगी अवधारणाहरू सिक्छन्। उदाहरणका लागि, तिनीहरूले यस्ता अवधारणाहरू सिक्छन्\"(१):\n",
    "\n",
    "* कसरी हिज्जे गर्ने\n",
    "* व्याकरण कसरी काम गर्छ\n",
    "* कसरी पुनर्लेखन गर्ने\n",
    "* कसरी प्रश्नहरूको उत्तर दिने\n",
    "* कसरी संवाद गर्ने\n",
    "* धेरै भाषामा कसरी लेख्ने\n",
    "* कसरी कोड लेख्ने\n",
    "* आदि\n",
    "\n",
    "#### ठूला भाषा मोडेललाई कसरी नियन्त्रण गर्ने  \n",
    "\"ठूला भाषा मोडेलमा सबैभन्दा प्रभावशाली इनपुट भनेको पाठ प्रॉम्प्ट हो(१)।\n",
    "\n",
    "ठूला भाषा मोडेलहरूलाई केही तरिकाले आउटपुट दिन प्रॉम्प्ट गर्न सकिन्छ:\n",
    "\n",
    "निर्देशन: मोडेललाई के चाहिएको हो भनेर भनौं\n",
    "पूरा गर्नु: आफूलाई चाहिएको कुरा सुरु गरेर मोडेललाई त्यसलाई पूरा गर्न लगाउनुहोस्\n",
    "डेमो: मोडेललाई के चाहिएको हो भनेर देखाउनुहोस्, या त:\n",
    "प्रॉम्प्टमा केही उदाहरणहरू\n",
    "फाइन-ट्युनिङ तालिम डाटासेटमा सयौं वा हजारौं उदाहरणहरू\"\n",
    "\n",
    "\n",
    "\n",
    "#### प्रॉम्प्ट बनाउँदा तीन आधारभूत दिशानिर्देशहरू छन्:\n",
    "\n",
    "**देखाउनुहोस् र भन्नुहोस्**। के चाहिएको हो भन्ने कुरा निर्देशन, उदाहरण, वा दुवैको संयोजनबाट स्पष्ट पार्नुहोस्। यदि तपाईंलाई मोडेलले वस्तुहरूको सूचीलाई वर्णानुक्रममा क्रमबद्ध गर्न वा अनुच्छेदलाई भावनाका आधारमा वर्गीकरण गर्न चाहनुहुन्छ भने, उसलाई त्यही चाहिएको हो भनेर देखाउनुहोस्।\n",
    "\n",
    "**गुणस्तरीय डाटा दिनुहोस्**। यदि तपाईं वर्गीकरण बनाउने वा मोडेललाई कुनै ढाँचा पछ्याउन लगाउने प्रयास गर्दै हुनुहुन्छ भने, पर्याप्त उदाहरणहरू छन् कि छैनन् भन्ने सुनिश्चित गर्नुहोस्। तपाईंका उदाहरणहरू राम्रोसँग जाँच गर्नुहोस् — मोडेल प्रायः सामान्य हिज्जे गल्तीहरू छुट्याउन सक्ने हुन्छ र तपाईंलाई उत्तर दिन्छ, तर उसले यो जानाजानी गरिएको हो भनेर पनि मान्न सक्छ र यसले उत्तरमा असर गर्न सक्छ।\n",
    "\n",
    "**आफ्ना सेटिङहरू जाँच गर्नुहोस्।** तापक्रम (temperature) र top_p सेटिङहरूले मोडेलले उत्तर दिने क्रममा कति निर्धारणशील (deterministic) हुने भन्ने कुरा नियन्त्रण गर्छन्। यदि तपाईंले त्यस्तो उत्तर चाहनु भएको छ जहाँ एउटै सही उत्तर छ भने, यी सेटिङहरू कम राख्नुहोस्। यदि तपाईंलाई विविध उत्तरहरू चाहिएको छ भने, यी सेटिङहरू उच्च राख्न सक्नुहुन्छ। यी सेटिङहरूसँग सबैभन्दा धेरै हुने गल्ती भनेको तिनीहरूलाई \"बुद्धिमत्ता\" वा \"रचनात्मकता\" नियन्त्रण गर्ने बटन ठान्नु हो।\n",
    "\n",
    "\n",
    "स्रोत: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## पाठ संक्षेप गर्नुहोस्  \n",
    "#### चुनौती  \n",
    "पाठको अन्त्यमा 'tl;dr:' थपेर पाठलाई संक्षेप गर्नुहोस्। मोडेलले कुनै थप निर्देशन बिना नै धेरै कार्यहरू कसरी गर्न सक्छ भन्ने कुरा ध्यान दिनुहोस्। तपाईंले tl;dr भन्दा बढी वर्णनात्मक प्रॉम्प्टहरू प्रयोग गरेर मोडेलको व्यवहार परिवर्तन गर्न र आफूले चाहेको संक्षेप अनुकूल बनाउन प्रयोग गर्न सक्नुहुन्छ(3)।  \n",
    "\n",
    "हालैको अनुसन्धानले देखाएको छ कि ठूलो पाठ संग्रहमा प्रि-ट्रेनिङ गरेर र त्यसपछि विशेष कार्यमा फाइन-ट्युनिङ गर्दा धेरै NLP कार्यहरू र बेन्चमार्कहरूमा उल्लेखनीय प्रगति भएको छ। यद्यपि यो विधि सामान्यतया कार्य-निरपेक्ष संरचनामा आधारित हुन्छ, तर अझै पनि यसले हजारौं वा दशौं हजार उदाहरणहरूको कार्य-विशिष्ट फाइन-ट्युनिङ डाटासेट आवश्यक पर्छ। यसको विपरीत, मानिसहरूले सामान्यतया केही उदाहरणहरू वा साधारण निर्देशनहरूबाट नयाँ भाषा कार्य गर्न सक्छन् - जुन अहिलेका NLP प्रणालीहरूले अझै पनि गर्न गाह्रो मान्छन्। यहाँ हामी देखाउँछौं कि भाषा मोडेलहरूलाई ठूलो बनाउँदा कार्य-निरपेक्ष, थोरै उदाहरणमा आधारित प्रदर्शनमा धेरै सुधार आउँछ, कहिलेकाहीँ त अघिल्लो उत्कृष्ट फाइन-ट्युनिङ विधिहरूसँग प्रतिस्पर्धा गर्न सक्ने स्तरमा पुग्छ।\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# विभिन्न प्रयोगका लागि अभ्यासहरू  \n",
    "1. पाठ संक्षेप गर्नुहोस्  \n",
    "2. पाठ वर्गीकरण गर्नुहोस्  \n",
    "3. नयाँ उत्पादन नामहरू सिर्जना गर्नुहोस्\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## पाठ वर्गीकरण गर्नुहोस्  \n",
    "#### चुनौती  \n",
    "वर्गीकरणका लागि वस्तुहरूलाई इन्फरेन्सको समयमा दिइएका श्रेणीहरूमा वर्गीकृत गर्नुहोस्। तलको उदाहरणमा, हामीले दुवै श्रेणीहरू र वर्गीकरण गर्नुपर्ने पाठ प्रॉम्प्टमा दिएका छौं (*playground_reference)।\n",
    "\n",
    "ग्राहकको सोधपुछ: नमस्कार, मेरो ल्यापटपको किबोर्डको एउटा कुञ्जी भर्खरै बिग्रिएको छ र मलाई यसको प्रतिस्थापन चाहिन्छ:\n",
    "\n",
    "वर्गीकृत श्रेणी:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## नयाँ उत्पादन नामहरू सिर्जना गर्नुहोस्\n",
    "#### चुनौती\n",
    "उदाहरण शब्दहरूबाट उत्पादन नामहरू बनाउनुहोस्। यहाँ हामीले उत्पादनको बारेमा जानकारी समावेश गरेका छौं जसको लागि हामी नामहरू सिर्जना गर्दैछौं। हामीले चाहेको ढाँचा देखाउनका लागि यस्तै एउटा उदाहरण पनि दिएका छौं। थप रचनात्मक र अनौठो उत्तरहरूका लागि हामीले temperature मान उच्च राखेका छौं।\n",
    "\n",
    "उत्पादन विवरण: घरमै बनाउने मिल्कशेक मेकर\n",
    "बीउ शब्दहरू: छिटो, स्वस्थ, सानो।\n",
    "उत्पादन नामहरू: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "उत्पादन विवरण: जुनसुकै खुट्टाको साइजमा मिल्ने जुत्ताको जोडी।\n",
    "बीउ शब्दहरू: अनुकूल, फिट, omni-fit।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# सन्दर्भहरू  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Examples](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [GPT-3 लाई पाठ वर्गीकरणका लागि फाइन-ट्यून गर्नका लागि उत्कृष्ट अभ्यासहरू](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# थप सहायता को लागि  \n",
    "[OpenAI व्यावसायिकरण टोली](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# योगदानकर्ताहरू\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nयो दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) प्रयोग गरी अनुवाद गरिएको हो। हामी शुद्धताको लागि प्रयास गर्छौं, तर कृपया ध्यान दिनुहोस् कि स्वचालित अनुवादमा त्रुटिहरू वा अशुद्धताहरू हुन सक्छन्। मूल भाषा मा रहेको मूल दस्तावेज़लाई नै आधिकारिक स्रोत मान्नुपर्छ। महत्वपूर्ण जानकारीको लागि, व्यावसायिक मानव अनुवाद सिफारिस गरिन्छ। यस अनुवादको प्रयोगबाट उत्पन्न हुने कुनै पनि गलतफहमी वा गलत व्याख्याका लागि हामी जिम्मेवार हुने छैनौं।\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:11:18+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "ne"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}