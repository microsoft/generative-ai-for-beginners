<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2210a0466c812d9defc4df2d9a709ff9",
  "translation_date": "2026-01-18T19:26:44+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "my"
}
-->
# Retrieval Augmented Generation (RAG) and Vector Databases

[![Retrieval Augmented Generation (RAG) and Vector Databases](../../../../../translated_images/my/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

ရှာဖွေရေးအက်ပလီကေးရှင်းများ သင်ခန်းစာတွင်၊ သင်၏ကိုယ်ပိုင်ဒေတာများအား ကြီးမားသော ဘာသာစကား မော်ဒယ်များ (LLMs) ထဲတွင် ပေါင်းစည်းခြင်းကို ကောက်နုတ်လေ့လာခဲ့သည်။ ဒီသင်ခန်းစာတွင် ကျွန်တော်တို့ LLM အက်ပလီကေးရှင်းတွင် ဒေတာအခြေခံခြင်း၊ ဒီလုပ်ငန်းစဉ်၏ စက်နစ်များနှင့် ဒေတာသိုလှောင်မှု နည်းလမ်းများကို embedding နှင့် စာသားနှစ်မျိုးစလုံး အပါအဝင် နက်ရှိုင်းစွာ လေ့လာသွားမည် ဖြစ်ပါသည်။

> **ဗွီဒီယို မကြာမီ ရရှိပါမည်**

## မိတ်ဆက်

ဒီသင်ခန်းစာတွင် အောက်ပါအကြောင်းအရာများကို ဖော်ပြပါမည်-

- RAG ဖြစ်စဉ်ကို မိတ်ဆက်ခြင်း၊ ၎င်းဖြစ်စဉ်သည် အဘယ်ကြောင့် AI (အတုအယောင် အကြံပေးမှု) တွင် အသုံးပြုကြောင်းရှင်းလင်းခြင်း။

- Vector database များဘာလဲ၊ ၎င်းကို ကျွန်တော်တို့အက်ပလီကေးရှင်းအတွက် ဘယ်လိုတည်ဆောက်ရမည်။

- RAG ကို အက်ပလီကေးရှင်းထဲတွင် ဘယ်လို ပေါင်းစည်းနည်း ဉပမာ လက်တွေ့ပြသခြင်း။

## သင်ယူမှတ်မှတ်ချက်များ

ဒီသင်ခန်းစာကို ပြီးဆုံးပြီးနောက်မှာ သင်အောက်ပါ အချက်များကို လုပ်နိုင်ပါမည်-

- ဒေတာ ရှာဖွေရေးနှင့် ကိုင်တွယ်မှုတွင် RAG ၏ အားသာချက်ကို ရှင်းပြနိုင်ခြင်း။

- RAG အက်ပလီကေးရှင်း တပ်ဆင်ခြင်းနှင့် သင့်ဒေတာကို LLM နှင့် အခြေခံခြင်း။

- RAG နှင့် Vector Databases ကို LLM အက်ပလီကေးရှင်းများတွင် ထိရောက်စွာ ပေါင်းစည်းခြင်း။

## ကျွန်တော်တို့အနေဖြင့်- ကိုယ်ပိုင်ဒေတာနဲ့ ကျွန်တော်တို့၏ LLMs ကို အားဖြည့်ခြင်း

ဒီသင်ခန်းစာအတွက် ကျွန်တော်တို့ရဲ့ ပညာရေး စတားတပ်ပလပ်ဖောင်းတွင် ကိုယ်ပိုင်မှတ်စုများ ထည့်သွင်းလိုသည်။ ယင်းသို့မှသာ chatbot သည် အကြောင်းအရာအမျိုးမျိုးအပေါ် အချက်အလက်ပိုမိုရရှိနိုင်သည်။ ကျောင်းသားများသည် ကိုယ်ပိုင်မှတ်စုများ အသုံးပြု၍ ပညာမြှင့်တင်ပြီး ချဲ့ချင်သော အကြောင်းအရာများကို နားလည်မှု လွယ်ကူစေသည်။ ကျွန်တော်တို့၏ စက်ရုပ် chatbot မှ နောက်ဆုံးတွင် အသုံးပြုရန်ကျောင်းသားများအတွက် ထပ်မံလေ့ကျင့်မေးခွန်းများ၊ ပြန်လည်သုံးသပ်မှု ကတ်များနှင့် အကျဉ်းချုပ်များ ဖန်တီးနိုင်ပါသည်။ ကျွန်တော်တို့၏ ရွေးချယ်မှုများမှာ-

- `Azure OpenAI:` ကျွန်တော်တို့ chatbot ဖန်တီးရန် အသုံးပြုမည့် LLM

- `AI for beginners' lesson on Neural Networks:` ကျွန်တော်တို့၏ LLM အတွက် ခိုင်မာသော အချက်အလက်များ

- `Azure AI Search` နှင့် `Azure Cosmos DB:` Vector database များကဲ့သို့ သိုလှောင်ပြီး ရှာဖွေရေး အညွှန်းပြုရန်

## Retrieval Augmented Generation (RAG)

LLM ဖြင့် လှမ်း၍ တည်ဆောက်ထားသည့် chatbot သည် အသုံးပြုသူ၏ ချိတ်ထားချက်များအပေါ် တုံ့ပြန်ချက်များ ဖန်တီးပေးသည်။ ၎င်းသည် အပြန်အလှန် ဆက်သွယ်မှု ပြုလုပ်နိုင်ပြီး အကြောင်းအရာအမျိုးမျိုးအပေါ် ဆွေးနွေးနိုင်သော်လည်း ၎င်း၏ တုံ့ပြန်ချက်များသည် ပံ့ပိုးပေးထားသောအကြောင်းအရာနှင့် ထူထောင်သင်ကြားမှု ဒေတာအတိုင်းသာ မှန်ကန်နိုင်သည်။ ဥပမာ - GPT-4 ၏ သိရှိမှုကန့်သတ်ချက်မှာ စက်တင်ဘာ ၂၀၂၁ ဖြစ်သောကြောင့် အဲ့ဒီကြာမြင့်ချိန်ကပြီးခဲ့သော ဖြစ်ရပ်ကိစ္စများကို သိရှိမှုမရှိနိုင်ပါ။ ၎င်းမတိုင်မီ ယေဘုယျသင်ကြားမှုတွင် ကိုယ်ပိုင်မှတ်စုများ သို့မဟုတ် ကုမ္ပဏီထုတ်ကုန်လက်စွဲစာအုပ်များ စသည့် လျှို့ဝှက်ချက်များ တစ်ပါးသည့် ဒေတာများ ပါဝင်မထားပါ။

### RAG (Retrieval Augmented Generation) များ ဘယ်လို လည်ပတ်သလဲ

![drawing showing how RAGs work](../../../../../translated_images/my/how-rag-works.f5d0ff63942bd3a6.webp)

သင်၏ မှတ်စုများမှ မေးခွန်းများဖန်တီးသော chatbot တစ်ခု တည်ဆောက်လိုပါက ပညာအခြေခံ ကွန်ရက်တွင် ချိတ်ဆက်မှုပြုရမည်။ ဒီအပိုင်းမှာ RAG သည် အကူအညီပေးသည်။ RAG များသည် အောက်ပါအတိုင်း လုပ်ဆောင်ပါသည်-

- **ပညာအခြေခံ:** ရှာဖွေရေးမပြုမီ ဖိုင်များကို သွင်းယူထားပြီး အကြီးအကျယ်ဖိုင်များကို သဲထဲပိုင်းခြင်း၊ စာသား embedding ပြုလုပ်၍ ဒေတာဘေ့စ်တွင် သိမ်းဆည်းထားရန် လိုအပ်သည်။

- **အသုံးပြုသူမေးခွန်း:** အသုံးပြုသူ မေးခွန်းတစ်ခု မေးသည်။

- **ရှာဖွေရေး:** အသုံးပြုသူ မေးခွန်းမေးလျှင် တွဲဖက် embedding မော်ဒယ်က ပညာအခြေခံမှ သင့်တော်သော အချက်အလက်များ ရှာဖွေပြီး prompt ထဲတွင် ထည့်သွင်းပေးသည်။

- **တိုးမြှင့်ဖန်တီးမှု:** LLM သည် ရရှိသော ဒေတာအပေါ် အခြေခံ၍ တုံ့ပြန်ချက်များ တိုးမြှင့်ပေးသည်။ ထိုနည်းဖြင့် train ပြီးသား ဒေတာ သာမက ပေါင်းထည့်ထားသော ဒေတာ အချက်အလက်များမှလည်း တုံ့ပြန်နိုင်သည်။ ထိုသော အချက်အလက်များသည် LLM ၏ တုံ့ပြန်ချက်များကို တိုးမြှင့်စေသည်။ LLM သည် အသုံးပြုသူ၏ မေးခွန်းအတွက် ဖြေကြားချက် ပြန်လည် ပေးပို့သည်။

![drawing showing how RAGs architecture](../../../../../translated_images/my/encoder-decode.f2658c25d0eadee2.webp)

RAG များ၏ စလစ်ပုံစံမှာ transformer မော်ဒယ် နှစ်ခုဖြစ်သော encoder နှင့် decoder ပါဝင်သည်။ ဥပမာ အသုံးပြုသူမေးခွန်း မေးလျှင် စာသားကို စကားလုံးများ၏ အဓိပ္ပာယ် တိကျမှုတို့ကို ဖမ်းယူရန် vector များသို့ 'encode' လုပ်ပြီး၊ ထို vectors များကို 'decode' လုပ်ကာ စာရွက်အညွှန်းနှင့် အသုံးပြုသူမေးခွန်းအခြေခံ၍ စာသားအသစ် ဖန်တီးပေးသည်။ LLM သည် encoder-decoder မော်ဒယ်နှစ်ခုကို လက်တွေ့ အသုံးပြုသည်။

[Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) က ညွှန်ပြသော အတိုင်း RAG အသုံးပြုခြင်း အချက်အချာနှစ်မျိုးမှာ-

- **_RAG-Sequence_** မေးခွန်းအတွက် အကောင်းဆုံးဖြေကြားချက်ကို ပြောရန် ရရှိသော စာရွက်တွေကို အသုံးပြုခြင်း

- **RAG-Token** နောက်တစ်ခု token ဖန်တီးရန် စာရွက်များကို အသုံးပြု၍ ထို့အခါ ထပ်မံရယူပြီး အသုံးပြုသူမေးခွန်းကို ဖြေကြားခြင်း

### RAGs ကို ဘာကြောင့် သုံးသနည်း?

- **အချက်အလက်ပမာဏ:** ထည့်သွင်းထားသော အချက်အလက်နှင့် သက်ဆိုင်မှုရှိသော စာတမ်းများမှ ရရှိသည့် တုံ့ပြန်ချက်များသည် အချိန်မရွေး သက်ဆိုင်သူနှင့် ကျိုးကြောင်းဆီလျော်မှုရှိသည်။

- အသုံးပြုသူမေးခွန်းများကို အုပ်စုတစ်ခုထဲဝင်တဲ့ **သက်သေခံနိုင်သောဒေတာ** ဖြင့် ဖြေဆိုခြင်းကြောင့် ဖြဲချခြင်းနည်းပါးစေသည်။

- LLM တစ်ခုကို fine-tuning ပြုလုပ်ခြင်းထက် ပိုမို **ကုန်ကျစရိတ်သက်သာ**သော ပုံစံဖြစ်သည်။

## ပညာအခြေခံ ဖန်တီးခြင်း

ကျွန်တော်တို့၏ အက်ပလီကေးရှင်းသည် ကိုယ်ပိုင် Neural Network သင်ခန်းစာ အပေါ်မူတည်သည်။

### Vector Databases

Vector database တွင် သိမ်းဆည်းထားသော ဒေတာသည် ဒေတာစာရွက်များ၏ ဂဏန်းပြုပြင်ထားသော ဖော်ပြချက်များ ဖြစ်ပြီး လေ့ကျင့်သုံးနိုင်ရန် အထူးပြုထားသည်။ ဒေတာကို ဂဏန်းအဖြစ်ပြောင်းခြင်းဖြင့် ကျွန်တော်တို့ AI စနစ်၏ နားလည်မှုနှင့် ကိန်းဂဏန်းကိုင်တွယ်မှု လွယ်ကူစေပါသည်။

LLMs များတွင် အဝင် token အရေအတွက် ကန့်သတ်ချက် ရှိသည်။ ဒါကြောင့် ကျွန်တော်တို့ embedding များကို ကျစ်လစ်သပ်ရပ်အဖြစ် ခွဲထုတ်ထား၍ အသုံးပြုသူမေးခွန်းနီးပါးသော embedding များ တုံ့ပြန်ခြင်းအတွက် ပြန်လည်ရယူနိုင်သည်။ အချိုးအစား ခွဲခြားခြင်းသည် LLM ၏ token ကုန်ကျစရိတ်လည်း လျော့နည်းစေနိုင်သည်။

လူကြိုက်များသော vector database များမှာ Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant နှင့် DeepLake တို့ရှိသည်။ Azure CLI ဖြင့် Azure Cosmos DB မော်ဒယ် တည်ဆောက်နိုင်သည်-

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```


### စာသားမှ Embeddings သို့

ဒေတာသိုလှောင်မီ အရင်ဆုံး vector embeddings သို့ ပြောင်းလဲထည့်သွင်းရမည်။ အကြီးအကျယ်စာရွက်များ သို့မဟုတ် စာကြောင်းရှည်များရှိပါက မေးခွန်းများအပေါ် မူတည်၍ ခွဲခြားထားနိုင်သည်။ ခွဲခြားခြင်းကို စာကြောင်းအဆင့် သို့မဟုတ် စာပိုဒ်အဆင့် အတိုင်း ပြုလုပ်နိုင်သည်။ ခွဲခြားသော အပိုင်းများ၏ အနားတွင် စာရွက်ခေါင်းစဉ် သို့မဟုတ် ခွဲခြားခန်းမ၏ တစ်ပိုင်း စာသားထည့်သွင်းရန် ဖန်တီးနိုင်သည်။

ခွဲခြားနည်း-

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # နောက်ဆုံးပိုင်းအပိုင်းသည် အနည်းဆုံးအရှည်ကို မရောက်ရှိခဲ့ပါက၊ တစ်ချက်ထပ်ထည့်ပေးပါ။
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```


ခွဲခြားပြီးပါက သင်၏ စာသားကို embedding မော်ဒယ်များနှင့် ပြောင်းလဲနိုင်သည်။ အသုံးပြုနိုင်မည့် မော်ဒယ်များမှာ word2vec, OpenAI ၏ ada-002, Azure Computer Vision နှင့် အခြားများပါဝင်သည်။ မော်ဒယ်ရွေးချယ်မှုမှာ သင့် စကားပုံအမျိုးအစား၊ အကြောင်းအရာ (စာသား/ပုံ/သံ)၊ ဝင်ရောက်ကြည့်ရှုမှု တန်းတူမှု နှင့် embedding ထွက်ရှိမှု အရှည် အပေါ်မူတည်သည်။

OpenAI ၏ `text-embedding-ada-002` မော်ဒယ်ဖြင့် ဖန်တီးထားသောစာသား embedding ၏ ဥပမာ-

![an embedding of the word cat](../../../../../translated_images/my/cat.74cbd7946bc9ca38.webp)

## ရှာဖွေရေးနှင့် Vector ရှာဖွေရေး

အသုံးပြုသူမေးခွန်းမေးလျှင် retriever သည် မေးခွန်းကို query encoder ဖြင့် vector ပြောင်းပြီး၊ စာရွက်ရှာဖွေရေးအညွှန်းထဲတွင် သိပ်မှန်သည့် vector များကို ရှာဖွေသည်။ ပြီးနောက် input vector နှင့် စာရွက် vectors များကို စာသားသို့ ပြန်လည်ပြောင်းလဲကာ LLM အဆီသွင်းပါသည်။

### ရှာဖွေရေး

Retriever သည် ရှာဖွေရေး ညွှန်ပြချက်ကို ဖြည့်ဆည်းနိုင်မည့် စာရွက်များကို အမြန် ရှာဖွေခြင်းဖြစ်သည်။ Retriever ၏ရည်ရွယ်ချက်မှာ context ပေးရန်နှင့် LLM ကို သင့်ဒေတာအပေါ် ချိတ်ဆက်ရန် အသုံးပြုသည့် စာရွက်များ ရယူခြင်းဖြစ်သည်။

ဒေတာဘေ့စ်တွင် ရှာဖွေရေး လုပ်နည်းများမှာ-

- **Keyword search** - စာသားရှာဖွေရေးအတွက် သုံးသည်။

- **Vector search** - embedding မော်ဒယ် ဖြင့် စာရွက်များကို vector ဖော်ပြချက်သို့ ပြောင်းလဲကာ ဒီမှ semantic search (အဓိပ္ပာယ် အခြေခံရှာဖွေမှု) ကို ပြုလုပ်သည်။ retrieval တွင် အသုံးပြုသူမေးခွန်း vector အနီးဆုံး vector ဖော်ပြချက်များကို ရှာဖွေသည်။

- **Hybrid** - keyword နှင့် vector search တွဲ၍ အသုံးပြုခြင်း။

ရှာဖွေရေးအခါ မေးခွန်းနှင့် တူညီသော တုံ့ပြန်ချက် မရှိပါက ระบบ သာရရှိနိုင်သည့် အကောင်းဆုံး အချက်အလက် ပြန်ပေးပါလိမ့်မည်။ သို့သော် သင့်တော်မှု အကွာအဝေး အိမ်ခြံမြေ သတ်မှတ်ခြင်း သို့မဟုတ် hybrid စနစ် အသုံးပြုနိုင်သည်။ ဒီသင်ခန်းစာတွင် ကျွန်တော်တို့ hybrid search ကို အသုံးပြုမည်ဖြစ်ပြီး dataframe တစ်ခုတွင် အပိုင်းခွဲများ နှင့် embedding များပါဝင်သည့် ရယ်ရှာဖွေမှု အသုံးပြုမည်။

### Vector ဆွဲကြည့်မှု (Vector Similarity)

Retriever သည် ပညာအခြေခံ vector database မှ ဆွဲကြည့်၍ အလွှာဝန်းကျင်အနီးဆုံး embedding များ စနစ်တကျ ရှာဖွေရန် ကြိုးပမ်းသည်။ အသုံးပြုသူမေးခွန်း တစ်ခု embedded ဖြစ်ပြီး နှိုင်းယှဉ်သော embeddings နီးစပ်လျှင် တုံ့ပြန်ချက် ပေးသည်။ vector များ၏ ဆင်တူမှုတွက်ချက်မှု စံသတ်မှတ်ချက်မှာ cosine similarity ဖြစ်ပြီး ၎င်းသည် နှစ်ခု vector များကြားမှ ချောမွေ့မှုမြောက်သောထောင့်အပေါ် မူတည်သည်။

ကျွန်တော်တို့ တိုင်းတာနိုင်မည့် အခြားနည်းလမ်းများမှာ Euclidean distance (vector အဆုံး ပြီး အဆုံးအစိတ်အပိုင်းတို့အကြား တိုတောင်းသော လမ်းကြောင်း) နှင့် dot product (vector များရဲ့အစိတ်အပိုင်းနှစ်ခုစလုံး၏ ထုတ်ကုန် ပမာဏ စုစည်းချက်) တို့ ဖြစ်သည်။

### Search index

ရှာဖွေရေးလုပ်ဆောင်ရန်မတိုင်မီ ကျွန်တော်တို့ ပညာအခြေခံ ရှာဖွေမှုအညွှန်းကို ဖန်တီးရမည်။ အညွှန်းတွင် embedding များ သိမ်းဆည်းထားပြီး database ကြီးပေမယ့်လည်း အလျင်အမြန် အနီးဆုံး အပိုင်းများကို ရှာဖွေပါသည်။

ဒေသတွင်း၌ index ဖန်တီးသူ-

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# ရှာဖွေမှုအညွှန်းကို ဖန်တီးပါ
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# အညွှန်းကို စုံစမ်းရန်အတွက် kneighbors နည်းလမ်းကို အသုံးပြုနိုင်သည်
distances, indices = nbrs.kneighbors(embeddings)
```


### ပြန်လည်စီစစ်ခြင်း (Re-ranking)

ဒေတာဘေ့စ်ကို ကူးယူပြီးနောက် အများဆုံး သက်ဆိုင်မှုရှိသော နေရာမှ စတင် စီစဉ်ရန် လိုအပ်နိုင်သည်။ ပြန်လည်စီစဥ်ခြင်း LLM သည် ပညာရေးစနစ် များကို သုံးကာ ရှာဖွေရေးရလဒ်များကို အတိအကျဆုံး စီစဉ်ပေးသည်။ Azure AI Search သုံးစွဲထားသော semantic reranker မှတဆင့် ပြန်လည်စီစဉ်မှု ကိုယ်တိုင်း ဆောင်ရွက် ပေးပါသည်။ နီးစပ်ဆုံး အိမ်နီးချင်းများ အသုံးပြု၍ ပြန်လည်စီစဉ်မှု ဥပမာ -

```python
# အလွန်ဆင်တူသောစာတမ်းများကို ရှာဖွေပါ
distances, indices = nbrs.kneighbors([query_vector])

index = []
# အလွန်ဆင်တူသောစာတမ်းများကို မျှပေါ်ပါ
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```


## အားလုံးကို ပေါင်းစည်းခြင်း

နောက်ဆုံးတွင် ကျွန်တော်တို့၏ LLM ကို ထည့်သွင်းကာ ကိုယ်ပိုင်ဒေတာနှင့် ချိတ်ဆက်၍ တုံ့ပြန်ချက်ရရှိစေသည်။ ဥပမာအတိုင်း အသုံးပြုပြုရန်-

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # မေးခွန်းကို မေးခွန်းဗက်တာသို့ပြောင်းပါ
    query_vector = create_embeddings(user_input)

    # ဆင်တူဆုံးစာတမ်းများကို ရှာပါ
    distances, indices = nbrs.kneighbors([query_vector])

    # အကြောင်းအရာပံ့ပိုးရန် စာတမ်းများကို မေးခွန်းထဲထည့်ပါ
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # သမိုင်းရေးရာနှင့် အသုံးပြုသူအင်ပွတ်ကို ပေါင်းစပ်ပါ
    history.append(user_input)

    # စာကြောင်းအရာဝတ္ထုတစ်ခု ဖန်တီးပါ
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # တုံ့ပြန်ချက် ထုတ်လုပ်ရန် စကားပြောပြီးစီးမှုကို အသုံးပြုပါ
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```


## ကျွန်တော်တို့၏ အက်ပလီကေးရှင်းကို အကဲဖြတ်ခြင်း

### အကဲဖြတ်မှု တံဆိပ်များ

- ဖော်ပြချက်၏ ရုပ်ပိုင်းဆိုင်ရာ ပတ်သက်မှု၊ သဘာဝ၊ ပြောဆိုစနစ်နှင့် လူများကဲ့သို့ သံသယမရှိမှု

- ဒေတာအခြေခံမှု- ပြန်လည်ပြောဆိုချက်သည် စာရွက်များမှ ထွက်ရှိမှုရှိမရှိ

- သက်ဆိုင်မှု- ပြန်လည်ပြောဆိုချက်သည် မေးခွန်းနှင့် သက်ဆိုင်မှုရှိရေး

- စာပိုဒ်စာကြောင်း စနစ်တကျဖြစ်မှု

## RAG (Retrieval Augmented Generation) နှင့် Vector Databases အသုံးပြုမှု ကိစ္စရပ်များ

အက်ပလီကေးရှင်းတိုးတက်စေသော function call များ အစွမ်းထက်စွာ လုပ်ဆောင်နိုင်သည့် နေရာများမှာ-

- မေးခွန်းနှင့် ဖြေကြားခြင်း: ကုမ္ပဏီ ဒေတာကို chatbot ထဲတွင် ချိတ်ဆက်၍ ဝန်ထမ်းများ မေးခွန်းမေးနိုင်ရန်

- အကြံပြုစနစ်များ: ထူးခြားသော တန်ဖိုးများကို တွဲဖက်စနစ် တည်ဆောက်နိုင်ခြင်း (ဥပမာ- ရုပ်ရှင်များ၊ စားသောက်ဆိုင်များ အစရှိသည်)

- Chatbot ဝန်ဆောင်မှုများ: စကားပြော မှတ်တမ်းများ သိမ်းဆည်းထား၍ အသုံးပြုသူ ဒေတာအပေါ် မူတည်၍ ကိုယ်ပိုင်ပြုပြင်ထားသောစကားသံအသစ် ပြုလုပ်နိုင်ခြင်း

- ပုံရိပ် ရှာဖွေရေး: vector embedding များဖြင့် ပုံမှန်ရာတုံ့ပြန်မှုနှင့် ပုံမှန်မဟုတ်မှုစစ်ဆေးရန် အသုံးပြုခြင်း

## အနှစ်ချုပ်

RAG ၏ အခြေခံ အချက်အလက်များနှင့် ကျွန်တော်တို့၏ ဒေတာများ ကိုယ်တိုင် ထည့်သွင်းခြင်း၊ အသုံးပြုသူ မေးခွန်းနှင့် ထုတ်လွှင့်ချက် တို့ကို ဖော်ပြခဲ့သည်။ RAG ဖန်တီးမှု လွယ်ကူစေရန် Semanti Kernel, Langchain သို့မဟုတ် Autogen စသော framework များကို အသုံးပြုနိုင်ပါသည်။

## အလုပ်အပ်

Retrieval Augmented Generation (RAG) ပိုမိုလေ့လာရန်-

- သင်နှစ်သက်ရာ framework ဖြင့် အက်ပလီကေးရှင်း ရဲ့ front-end ဖန်တီးပါ။

- LangChain သို့ Semantic Kernel တစ်ခုကို အသုံးပြုပြီး သင်၏အက်ပလီကေးရှင်းကို ထပ်မံဖန်တီးပါ။

သင်ခန်းစာပြီးမြောက်ခြင်းအတွက် ဂုဏ်ယူပါသည် 👏။

## သင်ယူခြင်းသည် ဒီနေရာမှာ မရပ်ပဲ ဆက်လက်သွားပါ

ဒီသင်ခန်းစာပြီးလျှင် ကျွန်တော်တို့၏ [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ကို ကြည့်ရှုကာ Generative AI ၏ အသိပညာ ရှင်းတင်မှုကို ဆက်လက်မြှင့်တင်လိုက်ပါ!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**သတိပြုကြားကြောင်း**  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှုဖြစ်သော [Co-op Translator](https://github.com/Azure/co-op-translator) ကိုအသုံးပြုပြီး ဘာသာပြန်ထားခြင်းဖြစ်သည်။ ကျွန်ုပ်တို့သည် တိကျမှန်ကန်မှုအတွက် ကြိုးစားပေမယ့် အလိုအလျောက် ဘာသာပြန်ချက်များတွင် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ပါဝင်နိုင်ကြောင်း ကျေးဇူးပြု၍ သိရှိထားပေးပါ။ မူရင်းစာရွက်စာတမ်းကို မိဘာသာဖြင့်သာ ယုံကြည်စိတ်ချရသော အရင်းမြစ်အဖြစ်တွင် စဉ်းစားသင့်ပါသည်။ အရေးကြီးသော သတင်းအချက်အလက်များအတွက် လူ့အင်အားမှ တာဝန်ရှိသော ဘာသာပြန်ခြင်းကို အကြံပြုပါသည်။ ဤဘာသာပြန်ချက် အသုံးပြုရာမှ ဖြစ်ပေါ်လာနိုင်သည့် နားလည်မှုပြဿနာများ သို့မဟုတ် မမှန်ကန်စွာသဘောပေါက်ခြင်းများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မထမ်းဆောင်ပါ။
<!-- CO-OP TRANSLATOR DISCLAIMER END -->