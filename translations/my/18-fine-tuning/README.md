<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T19:24:16+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "my"
}
-->
[![Open Source Models](../../../../../translated_images/my/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# သင့် LLM ကို အတိပကျလေ့ကျင့်ခြင်း

ကြီးမားသောဘာသာစကားမော်ဒယ်များကို ဖန်တီးမှု AI လျှောက်လွှာများ တည်ဆောက်ရာတွင် အသုံးပြုခြင်းသည် အခက်အခဲအသစ်များကို ယူလာသည်။ အဓိကပြဿနာမှာ မူလတောင်းဆိုမှုအတွက် မော်ဒယ်က ထုတ်ပေးသောအကြောင်းအရာတွင် တုံ့ပြန်မှု အရည်အသွေး (တိကျမှုနှင့် သက်ဆိုင်မှု) ကို သေချာစေရန်ဖြစ်သည်။ ယခင်သင်ခန်းစာများတွင် မူလတည်ရှိသော မော်ဒယ်အား _prompt input ကို ပြောင်းလဲခြင်း_ လုပ်ကာ အဆင်ပြေလုပ္နည္းျဖစ္ေသာ prompt engineering ႏွင့္ retrieval-augmented generation နည္းလမ္းမ်ားကို ေဆြးေႏြးခဲ့ပါသည္။

ယနေ့ သင်ခန်းစာတွင် တတိယ နည်းလမ်းတစ်ခုဖြစ်သော **fine-tuning** ကို ဆွေးနွေးမှာဖြစ်ပြီး _နောက်ထပ်ဒေတာများဖြင့် မော်ဒယ်ကို ကိုယ့်လက်ထဲပြန်လေ့ကျင့်ခြင်း_ ဖြင့် ထိုပြဿနာကို ဖြေရှင်းရန်ကြိုးစားသည်။ အသေးစိတ်ကြည့်ရအောင်။

## သင်ယူရန် ရည်မှန်းချက်များ

ဤသင်ခန်းစာသည် အဆင့်မြှင့် ရှေ့စီးတန်း ဘာသာစကားမော်ဒယ်များအတွက် fine-tuning ဆိုသည့် အယူအဆကိုပြသပြီး, ၎င်းနည်းလမ်း၏ အကျိုးကျေးဇူးများနှင့် စိန်ခေါ်မှုများကို တင်ပြပေးပြီး၊ ဖန်တီးမှု AI မော်ဒယ်များ၏ စွမ်းဆောင်ရည်တိုးတက်ရေးအတွက် fine-tuning ကို ဘယ်အချိန်နှင့် ဘယ်လိုအသုံးပြုရမည်ကို လမ်းညွှန်ပေးသည်။

ဤသင်ခန်းစာပြီးဆုံးသည်အထိ အောက်ပါမေးခွန်းများကို ဖြေဆိုနိုင်သင့်သည် -

- ဘာသာစကားမော်ဒယ်များအတွက် fine tuning ဆိုတာ ဘာလဲ?
- ဘယ်အချိန်တွင်၊ ဘာကြောင့် fine tuning အသုံးဝင်သနည်း?
- ဘယ်လို pre-trained မော်ဒယ်တစ်ခုကို fine-tune လုပ်နိုင်မလဲ?
- fine-tuning ၏ ကန့်သတ်ချက်များက ဘာတွေရှိသနည်း?

ပြင်ဆင်ပြီးပြီလား? စတင်လိုက်ကြစို့။

## ပုံဖော်ထားသော လမ်းညွှန်

သင်တို့ မျှဝေမည့် အကြောင်းအရာအကျဉ်းချုပ်ကို ကြည့်ရှုချင်ပါသလား? ဤပုံဖော်ထားသော လမ်းညွှန်သည် fine-tuning ၏ အဓိကအယူအဆနှင့် ရည်ရွယ်ချက်များကို သင်ယူခြင်းမှ စ၍ fine-tuning လုပ်ငန်းစဉ်နှင့် အကောင်းဆုံး လေ့ကျင့်နည်းများအထိ သင်ခန်းစာတွင် လေ့လာမည့် ခရီးစဉ်ကိုဖေါ်ပြထားသည်။ ယခုခေါင်းစဉ်သည် စူးစမ်းရန် စိတ်စုံလင်သောအရာဖြစ်သဖြင့် သက်ဆိုင်ရာ လေ့လာသူကိုယ်တိုင်သင်ယူမှု ခရီးစဉ်ကို ထောက်ပံ့ရန် လင့်များပါရှိသော [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) စာမျက်နှာကို မမေ့ပါနှင့်!

![Illustrated Guide to Fine Tuning Language Models](../../../../../translated_images/my/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## ဘာသာစကားမော်ဒယ်များအတွက် fine-tuning ဆိုတာဘာလဲ?

သတ်မှတ်ချက်အရ ကြီးမားသောဘာသာစကားမော်ဒယ်များသည် အင်တာနက်အပါအဝင် မျိုးစုံသောအရင်းအမြစ်များမှ စာသားများစွာ ဖြင့် _pre-trained_ ထားကြသည်။ ယခင်သင်ခန်းစာများတွင် ကျွန်ုပ်တို့သည် မော်ဒယ်၏ တုံ့ပြန်မှုပြဿနာကို ကောင်းမွန်စေရန် _prompt engineering_ နှင့် _retrieval-augmented generation_ ကဲ့သို့သော နည်းလမ်းများ လိုအပ်ကြောင်း လေ့လာခဲ့ပါသည်။

လူကြိုက်များသော prompt engineering နည်းလမ်းတစ်ခုမှာ ဥပမာ အနည်းငယ်များ အသုံးပြုခြင်း (implicit guidance) သို့မဟုတ် _အညွှန်းများ_ (explicit guidance) ပေးကာ ကိုယ်တောင်းဆိုလိုသည့် တုံ့ပြန်မှုအတွက် မော်ဒယ်အား ပိုမိုညွှန်ပေးခြင်းဖြစ်သည်။ ယင်းကို _few-shot learning_ ဟု ခေါ်ကာ မော်ဒယ်၏ အသုံးပြုမှုနှင့် သက်ဆိုင်မှုရှိထားသော်လည်း အခက်အခဲနှစ်ခု ရှိသည်-

- မော်ဒယ်၏ token ကန့်သတ်ချက်က သင်ပေးနိုင်သော ဥပမာအရေအတွက်ကို ကန့်သတ်၍ ထိရောက်မှုကိုလည်း ကန့်သတ်နိုင်သည်။
- မော်ဒယ် token ကုန်ကျစရိတ်များကြောင့် prompt တစ်ခုချင်းစီတွင် ဥပမာများ ထည့်သွင်းရခြင်းသည် စရိတ်များပိုတက်ပြီး နည်းလမ်းပေါ်တွင် အလွယ်တကူ ပြောင်းလဲရန် ရှုပ်ထွေးစေသည်။

Fine-tuning ဆိုသည်မှာ မော်ဒယ်စနစ်များတွင် အထူးလေ့လာမှု နယ်ပယ်ဖြစ်ပြီး, pre-trained မော်ဒယ်ကို တိကျသည့် အလုပ်တစ်ခု သို့မဟုတ် လျှောက်လွှာနယ်ပယ်အတွက် ဥပမာများ စုစည်းထားသည့် ဒေတာအသစ်ဖြင့် ပြန်လေ့ကျင့်ပေးခြင်းဖြစ်သည်။ ဤလုပ်ငန်းစဉ်ဖြင့် **စိတ်ကြိုက်မော်ဒယ်**ကို ဖန်တီးနိုင်ပြီး၊ ထိုအလုပ်သို့မဟုတ် နယ်ပယ်အတွက် ပိုတိကျနှင့် သက်ဆိုင်မှုရှိခြင်း အားရှိလာနိုင်သည်။ Fine-tuning ၏ ထူးခြားချက်တစ်ခုမှာ few-shot learning အတွက် လိုအပ်သော ဥပမာအရေအတွက်လည်း လျော့နည်းသွားသည်ဟု ဆိုနိုင်ပြီး၊ token အသုံးပြုမှုနှင့် ကုန်ကျစရိတ်များလည်း လျော့နည်းစေသည်။

## ဘယ်အချိန်နှင့် ဘာကြောင့် မော်ဒယ်များကို fine-tune လုပ်သင့်သလဲ?

ဤအခြေအနေ၌ fine-tuning ဟူသည်မှာ **supervised** fine-tuning ဖြစ်ပြီး၊ မူလလေ့ကျင့်ခဲ့သော ဒေတာစနစ်တွင် မပါဝင်သည့် ဒေတာအသစ်များ ဖြင့် ပြန်လေ့လာခြင်းဖြစ်သည်။ ဤသည်မှာ မူလဒေတာပေါ်တွင် မော်ဒယ်ပြန်လေ့လာသော်လည်း hyperparameters မတူညီသော unsupervised fine-tuning နည်းပညာမှ ကွဲပြားသည်။

အဓိက ရည်မှတ်ထားသည့်အချက်မှာ fine-tuning သည် တတ်ကျွမ်းမှုအတိအကျ လိုအပ်သော နည်းကြောင်းအဆင့်မြင့်နည်းပညာဖြစ်ပြီး ရလဒ်များမမှန်ကန်ဘဲ နောက်တောင်မော်ဒယ်စွမ်းဆောင်ရည် ဆိုးကျိုးပြုနိုင်ကြောင်း သတိပြုရန်ဖြစ်သည်။

ထို့ကြောင့် ဘာသာစကားမော်ဒယ်များကို ဘယ်လို fine-tune လုပ်မလဲ မသိမီမှာ "ဘာကြောင့်" fine-tuning လုပ်သင့်သနည်း၊ "ဘယ်အချိန်" fine-tuning လုပ်စတင်သင့်သလဲကို သတိထားလေ့လာရမည်။

ကိုယ်တိုင်ကို အောက်ပါမေးခွန်းများ ဖြေကြည့်ပါ-

- **အသုံးပြုမှုမှုအမှု**: သင်၏ fine-tuning အတွက် အသုံးပြုမှုဘာလဲ? နောက်ဆုံးတွင် မိုးဒယ်သော မော်ဒယ်၏ ဘယ်ပိုင်းမှာ တိုးတက်မှုလိုလဲ?
- **လမ်းလဲနည်းများ**: ပန်းတိုင်အောင်မြင်ရေးအတွက် _အခြားနည်းစနစ်များ_ကို ကျူးလွန်သလား? ထိုနည်းများကို ငြိမ်းချမ်းရေးအတွက် ကြိုးစားပါ။
  - Prompt engineering: သုံးသပ်ခြင်းဖြင့် မည်သည့် prompt များဖြင့်ခေါ်ဆိုခြင်း၊ တုံ့ပြန်မှုအရည်အသွေးကို သုံးသပ်ပါ။
  - Retrieval Augmented Generation: သင့်ဒေတာ စုဆောင်းမှုမှ ရလာသော မေးခွန်းဖြေတောင်းမှုများဖြင့် prompt များကို တိုးမြှင့်ပြုလုပ်ပါ။ တုံ့ပြန်မှုအရည်အသွေးကို သုံးသပ်ပါ။
- **ကုန်ကျစရိတ်များ**: fine-tuning အတွက် နည်းနည်းမြင်နိုင်တဲ့ကုန်ကျစရိတ်ရှိသလား?
  - ပြင်ဆင်နိုင်မှု - pre-trained မော်ဒယ်အား fine-tuning အသုံးပြုနိုင်ပါသလား?
  - ကြိုးစားမှု - လေ့ကျင့်မှု ဒေတာပြင်ဆင်ခြင်း၊ မော်ဒယ် သုံးသပ် ပြုပြင်ခြင်းတို့အတွက်
  - တွက်ချက်မှု - fine-tuning အလုပ်များ ကို အကောင်အထည်ဖေါ်ခြင်းနှင့် fine-tune လုပ်ပြီး မော်ဒယ်ဖြန့်ချိခြင်းအတွက်
  - ဒေတာ - fine-tune လုပ်မှုအတွက် ကောင်းမွန်သော ဥပမာများ ရရှိနိုင်ခြင်း
- **အကျိုးကျေးဇူးများ**: fine-tuning အတွက် အကျိုးကျေးဇူးများကို အတည်ပြုပြီးပြီလား?
  - အရည်အသွေး - fine-tuned မော်ဒယ်သည် အခြေခံမော်ဒယ်ထက် ပိုမိုထက်မြက်ပါသလား?
  - ကုန်ကျစရိတ် - prompt များကို ရိုးရှင်းစေကာ token အသုံးပြုမှု လျော့ချပါသလား?
  - ပြန်လည်အသုံးချနိုင်မှု - အခြေခံမော်ဒယ်ကို နယ်ပယ်အသစ်များအတွက် ပြန်လည်အသုံးပြုနိုင်ပါသလား?

ဤမေးခွန်းများကို ဖြေဆိုခြင်းဖြင့် fine-tuning ကို သင့်အသုံးပြုမှုအတွက် သင့်တော်မိုက်မိုက်ဖြစ်သည်ဟု ဆုံးဖြတ်နိုင်မည်ဖြစ်သည်။ အကောင်းဆုံး နည်းလမ်းမှာ အကျိုးကျေးဇူးများသည် ကုန်ကျစရိတ်ထက်ပို များလျှင်သာ ထိရောက်သည်။ ဆုံးဖြတ်ပြီးပါက pre-trained မော်ဒယ်ကို _ဘယ်လို_ fine-tune လုပ်မလဲ ဆိုသောအကြောင်းအရာကို ထပ်မံစဉ်းစားရန်ရှိသည်။

ဆုံးဖြတ်မှုလုပ်ရာတွင် ပိုမိုအသေးစိတ်အကြံပေးချက်များလိုပါသလား? [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs) ကို ကြည့်ရှုပါ။

## pre-trained မော်ဒယ်တစ်ခုကို ဘယ်လို fine-tune လုပ်နိုင်မလဲ?

pre-trained မော်ဒယ်တစ်ခုကို fine-tune လုပ်ရန် သင့်တွင် လိုအပ်သည် -

- fine-tune လုပ်ရန် pre-trained မော်ဒယ်
- fine-tune အတွက် အသုံးပြုမည့် dataset
- fine-tuning အလုပ်ကို လုပ်ဆောင်ရန် သင်ကြားရေးပတ်ဝန်းကျင်
- fine-tuned မော်ဒယ်ကို တပ်ဆင်ရန် hosting ပတ်ဝန်းကျင်

## Fine-Tuning လုပ်ဆောင်သည့်နည်းလမ်း

အောက်ပါအရင်းအမြစ်များတွင်ရွေးချယ်ထားသည့် မော်ဒယ်နှင့် ချွတ်ချွတ်ရွေးချယ်ထားသော dataset ဖြင့် ဘာသာစကားမော်ဒယ်ကို အသုံးပြု၍ တကယ့် ဥပမာတစ်ခု အဆင့်ချင်းဆင့် လေးနက်စွာ လေ့လာနိုင်ရန် သရုပ်ပြသင်ကြားမှုများ ပါဝင်သည်။ ဤသင်ကြားမှုများကို လေ့လာရန် သတ်မှတ်ထားသော ပံ့ပိုးသူတွင် အကောင့်ရှိရန်နှင့် သက်ဆိုင်ရာ မော်ဒယ်များနှင့် ဒေတာများအား ဝင်ရောက်အသုံးပြုခွင့်ရှိရမည်။

| ပံ့ပိုးသူ       | သင်ခန်းစာ                                                                                                                                                                    | ဖော်ပြချက်                                                                                                                                                                                                                                                                                                                                                                                                            |
| -------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI          | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                 | တိကျသော နယ်ပယ် ("recipe assistant") အတွက် `gpt-35-turbo` ကို fine-tune လုပ်ရန် သင်ကြားမှု ဒေတာပြင်ဆင်ခြင်း၊ fine-tuning အလုပ်လုပ်ခြင်းနှင့် fine-tuned မော်ဒယ်ကို inference အတွက် အသုံးပြုခြင်းကို လေ့လာပါ။                                                                                                                                                                   |
| Azure OpenAI    | [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Azure ပေါ်တွင် fine-tune ပြုလုပ်ခြင်း အတွက် `gpt-35-turbo-0613` မော်ဒယ်ကို လေ့လာခြင်း။ သင်ကြားမှု ဒေတာဖန်တီးခြင်း၊ အပ်လုတ်လုပ်ခြင်း၊ fine-tuning အလုပ်စတင်ခြင်း နှင့် မော်ဒယ်အသစ် ကို ဘာသာရပ်တင်ခြင်းများကို လေ့လာစေသည်။                                                                                                                                                               |
| Hugging Face   | [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | ဒီဘလော့ဂ်ပို့စ်သည် _open LLM_ (ဥပမာ: `CodeLlama 7B`) ကို [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) သုံး၍၊ [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) နည်းလမ်းဖြင့် လေ့လာမှု ဒေတာများကို သုံး၍ fine-tune လုပ်ခြင်းကို လမ်းညွှန်သည်။ |
|                |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                       |
| 🤗 AutoTrain   | [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                        | AutoTrain (သို့) AutoTrain Advanced သည် Hugging Face မှ ဖန်တီးထားသော python library ဖြစ်ပြီး LLM fine-tuning အပါအဝင် အလုပ်အမျိုးမျိုးအတွက် finetuning လုပ်နိုင်သည်။ AutoTrain သည် နမူနာမရှိသည့် ဖြေရှင်းချက်ဖြစ်ပြီး သင့်ကိုယ်ပိုင် cloud, Hugging Face Spaces သို့မဟုတ် ဒေသတွင်းတွင် လုပ်ငန်းစဉ်များ ပြုလုပ်နိုင်ပါသည်။ web GUI, CLI နှင့် yaml config ဖိုင်များဖြင့်လည်း စီမံနိုင်သည်။        |
|                |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                       |
| 🦥 Unsloth     | [Fine-tuning LLMs with Unsloth](https://github.com/unslothai/unsloth)                                                                                                       | Unsloth သည် open-source framework ဖြစ်ပြီး LLM fine-tuning နှင့် reinforcement learning (RL) ကို ထောက်ပံ့ပေးသည်။ သင်၏ ဒေသတွင်း ထိရောက်ပြီးသော အသုံးပြု နည်းလမ်းများ (notebooks) ဖြင့် လေ့ကျင့်ခြင်း၊ စစ်ဆေးခြင်းနှင့် တင်ပို့ခြင်းများ လွယ်ကူစေသည်။ TTS, BERT နှင့် မော်ဒယ်ပေါင်းစပ်များကိုလည်း ထောက်ပံ့ပေးသည်။ စတင်ရန် [Fine-tuning LLMs Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide) လမ်းညွှန်ကို ဖတ်ပါ။ |
|                |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                       |
## အလုပ်အမှု

အထက်ဖော်ပြထားသည့် သင်ခန်းစာများတွင် တစ်ခုကို ရွေးချယ်ပြီး လမ်းညွှန်အတိုင်း လေ့လာပါ။ _Jupyter Notebooks တွင် ဤသင်ခန်းစာများ၏ မူရင်းအမျိုးအစားကို မိတ္တူပြုလုပ်နိုင်သေးသည်။ နောက်ဆုံးဗားရှင်းများ အတွက် မူရင်းရင်းမြစ်များကို တိုက်ရိုက်အသုံးပြုရန် ကျေးဇူးပြု၍ မေ့လျော့ပါနှင့်_။

## ကောင်းမွန်သော လုပ်ဆောင်မှု! သင်ယူမှုကို ဆက်လက်လုပ်ဆောင်ပါ။

ဤသင်ခန်းစာပြီးဆုံးပြီးနောက် [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ကိုကြည့်ခြင်းဖြင့် သင့် Generative AI အသိပညာကို အဆင့်မြှင့်ဆက်လက်မြှင့်တင်နိုင်ပါသည်။

ဝမ်းမြောက်ပါသည်!! သင်သည် ဤသင်တန်း၏ v2 မျိုးစုံသင်ခန်းစာတိုင်းကို အပြီးသတ်လိုက်ပါပြီ! သင်ယူခြင်းနှင့် ဖန်တီးခြင်းကို ရပ်တန့်မထားပါနှင့်။ \*\*ယခုခေါင်းစဉ်အတွက် တိုးထွားသော အကြံပြုချက်များကို ကြည့်ရန် [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) စာမျက်နှာကို ကြည့်ရှုပါ။

ကျွန်တော်တို့၏ v1 သင်ခန်းစာစီးရီး တွင်လည်း ပိုမိုသော လုပ်ငန်းများနှင့် အယူအဆများဖြင့် ပြင်ဆင်ထားသည်။ ထို့ကြောင့် သင့် အသိပညာကို ပြန်လည် သန့်ရှင်းရန် အချိန်ယူပြီး [သင့်မေးခွန်းများနှင့် တုံ့ပြန်ချက်များကို မျှဝေပါ](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst)၊ ဤသင်ခန်းစာများကို အသိုင်းအဝန်းအတွက် ပိုမိုတိုးတက်အောင် ကူညီပါ။

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**အသိပေးချက်**  
ဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှန်ကန်မှုအတွက် ကြိုးပမ်းနေသော်လည်း၊ အလိုအလျောက်ဘာသာပြန်မှုများတွင် အမှားများ သို့မဟုတ် မှန်ကန်မှုမရှိမှုများ ဖြစ်ပေါ်နိုင်ကြောင်း သတိပြုပါရန် မေတ္တာရပ်ခံအပ်ပါသည်။ မူလစာရွက်စာတမ်းကို မူလဘာသာဖြင့်သာ ယုံကြည်အားထားသင့်ပါသည်။ အရေးကြီးသောသတင်းအချက်အလက်များအတွက် လူ့ဘာသာပြန်လုပ်ငန်းရှင်မှ ဘာသာပြန်ခြင်းကို အကြံပြုပါသည်။ ဤဘာသာပြန်ချက်သုံးစွဲရာတွင် ဖြစ်ပေါ်လာနိုင်သည့် နားလည်မှားယွင်းမှုများ သို့မဟုတ် မမှန်ကန်မှုများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။
<!-- CO-OP TRANSLATOR DISCLAIMER END -->