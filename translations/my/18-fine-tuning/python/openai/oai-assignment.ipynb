{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI မော်ဒယ်များကို Fine Tuning ပြုလုပ်ခြင်း\n",
    "\n",
    "ဒီ notebook ကို Open AI ရဲ့ [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) လမ်းညွှန်ချက်အရ ရေးသားထားပါတယ်။\n",
    "\n",
    "Fine-tuning ဆိုတာ သင့်ရဲ့ application အတွက် foundation model တစ်ခုကို ထပ်မံလိုအပ်တဲ့ data နဲ့ context တွေဖြင့် ပြန်လည်လေ့ကျင့်ခြင်းဖြစ်ပြီး၊ အထူးသဖြင့် သတ်မှတ်ထားတဲ့ use case သို့မဟုတ် scenario အတွက် ပိုမိုကောင်းမွန်စေပါတယ်။ _few shot learning_ နဲ့ _retrieval augmented generation_ လို prompt engineering နည်းလမ်းတွေကလည်း default prompt ကို သက်ဆိုင်ရာ data တွေနဲ့ တိုးတက်အောင်လုပ်နိုင်ပေမယ့်၊ ဒီနည်းလမ်းတွေမှာ သုံးမယ့် foundation model ရဲ့ max token window size ကန့်သတ်ချက်ရှိပါတယ်။\n",
    "\n",
    "Fine-tuning နဲ့ဆိုရင်တော့ မော်ဒယ်ကိုလိုအပ်တဲ့ data တွေနဲ့ တကယ့်ကို ပြန်လည်လေ့ကျင့်တာဖြစ်လို့ (max token window ထဲမှာ မတင်နိုင်တဲ့ ဥပမာတွေကိုပါ သုံးနိုင်ပါတယ်) - နောက်ထပ် _custom_ မော်ဒယ်တစ်ခုကို deploy လုပ်နိုင်ပါတယ်။ ဒီ custom မော်ဒယ်မှာတော့ inference အချိန်မှာ ဥပမာတွေ ထပ်မပေးရတော့ပါဘူး။ ဒါကြောင့် prompt design ကို ပိုမိုထိရောက်စေသလို (token window ကို အခြားအရာတွေအတွက် ပိုအသုံးချနိုင်ပါတယ်)၊ တစ်ချို့အခါမှာတော့ ကုန်ကျစရိတ်ကိုပါ လျှော့ချနိုင်ပါတယ် (inference အချိန်မှာ မော်ဒယ်ကို ပို့ရမယ့် token အရေအတွက် လျှော့နည်းသွားလို့)။\n",
    "\n",
    "Fine tuning လုပ်ရာမှာ လုပ်ဆောင်ရမယ့် လေးဆင့်ရှိပါတယ် -\n",
    "1. လေ့ကျင့်မယ့် data ကို ပြင်ဆင်ပြီး upload လုပ်ပါ။\n",
    "1. Training job ကို run လုပ်ပြီး fine-tuned model ရယူပါ။\n",
    "1. Fine-tuned model ကို အရည်အသွေးအတွက် စစ်ဆေးပြီး တိုးတက်အောင် ပြန်လုပ်ပါ။\n",
    "1. စိတ်တိုင်းကျလာတဲ့အခါ Fine-tuned model ကို inference အတွက် deploy လုပ်ပါ။\n",
    "\n",
    "Foundation model အားလုံးမှာ Fine-tuning ကို မပံ့ပိုးနိုင်ပါဘူး - နောက်ဆုံးအချက်အလက်အတွက် [OpenAI documentation](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) ကိုကြည့်ပါ။ Fine-tuned model တစ်ခုကို ထပ်မံ Fine-tune လုပ်နိုင်ပါသေးတယ်။ ဒီသင်ခန်းစာမှာတော့ Fine-tuning အတွက် `gpt-35-turbo` ကို foundation model အဖြစ် သုံးသွားမှာပါ။\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၁.၁ - သင့်ဒေတာအစုကို ပြင်ဆင်ပါ\n",
    "\n",
    "အခု ကျွန်တော်တို့ Periodic Table ထဲက ဓာတုဒြပ်စင်တစ်ခုအကြောင်း မေးခွန်းတွေကို limerick နဲ့ ဖြေပြပေးနိုင်တဲ့ chatbot တစ်ခု တည်ဆောက်မယ်။ ဒီလွယ်လွယ်ကူကူ လမ်းညွှန်ထဲမှာတော့ မော်ဒယ်ကို သင်ကြားဖို့အတွက် ရှာဖွေထားတဲ့ data format ကို ပြသပေးနိုင်တဲ့ နမူနာအဖြေ အနည်းငယ်ပါဝင်တဲ့ dataset တစ်ခုသာ ပြုလုပ်သွားမှာပါ။ လက်တွေ့အသုံးပြုမယ့်အခါမှာတော့ နမူနာအဖြေများစွာပါဝင်တဲ့ dataset တစ်ခုလိုအပ်ပါလိမ့်မယ်။ သင့် application domain အတွက် သင့်တော်တဲ့ open dataset တစ်ခုရှိတယ်ဆိုရင်လည်း အဲဒီ dataset ကို အသုံးပြုနိုင်ပါတယ်၊ ဒါမှမဟုတ် format ပြောင်းပြီး fine-tuning အတွက် အသုံးပြုနိုင်ပါတယ်။\n",
    "\n",
    "ဒီ tutorial မှာတော့ `gpt-35-turbo` ကို အခြေခံပြီး တစ်ကြိမ်တည်းဖြေတဲ့ (single-turn) chat completion ကို ရည်ရွယ်ထားတာမို့ [အကြံပြုထားတဲ့ format](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) ကို အသုံးပြုပြီး OpenAI chat completion လိုအပ်ချက်တွေကို ပြသနိုင်တဲ့ နမူနာတွေ ပြုလုပ်နိုင်ပါတယ်။ မေးခွန်းအကြိမ်ကြီးဖြေတဲ့ (multi-turn) conversation ကို မျှော်လင့်တယ်ဆိုရင်တော့ [multi-turn example format](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) ကို အသုံးပြုရပါမယ်၊ ဒီမှာတော့ `weight` parameter ပါဝင်ပြီး fine-tuning လုပ်တဲ့အခါ ဘယ် message တွေကို အသုံးပြု/မပြုသင့်တာကို ပြောပြနိုင်ပါတယ်။\n",
    "\n",
    "ဒီ tutorial မှာတော့ ပိုမိုလွယ်ကူတဲ့ single-turn format ကို သုံးသွားမှာပါ။ ဒေတာတွေက [jsonl format](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) နဲ့ တစ်ကြောင်းမှာ record တစ်ခုစီပါဝင်ပါတယ်၊ record တစ်ခုစီက JSON format နဲ့ ရေးထားတဲ့ object တစ်ခုပါ။ အောက်က နမူနာမှာ record ၂ ခုကို ပြထားပါတယ် - နောက်ထပ် နမူနာ ၁၀ ခုလုံးကို [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) မှာ ကြည့်နိုင်ပါတယ်။ **မှတ်ချက်** - record တစ်ခုစီကို တစ်ကြောင်းတည်းမှာရေးရပါမယ် (JSON file တစ်ခုလို ကြောင်းခွဲရေးတာမျိုး မလုပ်ရပါ)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "လက်တွေ့အသုံးပြုမယ့်အခါမှာတော့ အရည်အသွေးကောင်းတဲ့ရလဒ်ရဖို့ နမူနာအရေအတွက် များများလိုအပ်ပါတယ် - အဖြေ quality နဲ့ fine-tuning လုပ်ဖို့ ကြာချိန်/ကုန်ကျစရိတ်ကြားမှာ tradeoff ရှိပါတယ်။ ဒီ tutorial မှာတော့ fine-tuning လုပ်တဲ့ လုပ်ငန်းစဉ်ကို မြန်မြန်လုပ်ပြနိုင်ဖို့ နမူနာနည်းနည်းနဲ့ သုံးထားတာပါ။ ပိုမိုရှုပ်ထွေးတဲ့ fine-tuning tutorial အတွက် [OpenAI Cookbook နမူနာ](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) ကိုလည်း ကြည့်နိုင်ပါတယ်။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၁.၂ သင့်ဒေတာအစုကို တင်ပါ\n",
    "\n",
    "Files API ကို အသုံးပြုပြီး ဒေတာကို တင်ပါ [ဤနေရာတွင် ဖော်ပြထားသည့်အတိုင်း](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file)။ ဤကုဒ်ကို အသုံးပြုရန် မတိုင်မီ အောက်ပါအဆင့်များကို ပြီးစီးထားရပါမည် -\n",
    " - `openai` Python package ကို တပ်ဆင်ပြီးဖြစ်ရမည် (နောက်ဆုံးအင်္ဂါရပ်များအတွက် ဗားရှင်း >=0.28.0 ကို အသုံးပြုပါ)\n",
    " - သင့် OpenAI API key ကို `OPENAI_API_KEY` environment variable အဖြစ် သတ်မှတ်ပြီးဖြစ်ရမည်\n",
    "ပိုမိုသိရှိလိုပါက သင်တန်းအတွက် ပံ့ပိုးထားသော [တပ်ဆင်ခြင်း လမ်းညွှန်](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) ကို ကြည့်ပါ။\n",
    "\n",
    "ယခု သင့်ရဲ့ ဒေသခံ JSONL ဖိုင်မှ တင်ရန်ဖိုင်တစ်ခု ဖန်တီးရန် ကုဒ်ကို လည်ပတ်ပါ။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၂.၁ - SDK ကို အသုံးပြု၍ Fine-tuning အလုပ်ကို ဖန်တီးခြင်း\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၂.၂ - အလုပ်အခြေအနေကို စစ်ဆေးခြင်း\n",
    "\n",
    "`client.fine_tuning.jobs` API ကို အသုံးပြု၍ ပြုလုပ်နိုင်သောအရာများမှာ အောက်ပါအတိုင်းဖြစ်သည် -\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - နောက်ဆုံး fine-tuning အလုပ် n ခုကို စာရင်းပြုစုသည်\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - သတ်မှတ်ထားသော fine-tuning အလုပ်တစ်ခု၏ အသေးစိတ်အချက်အလက်များကို ရယူသည်\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - fine-tuning အလုပ်တစ်ခုကို ပယ်ဖျက်သည်\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - အလုပ်တစ်ခုမှ အဖြစ်အပျက်များ n ခုအထိ စာရင်းပြုစုသည်\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "ဤလုပ်ငန်းစဉ်၏ ပထမဆုံးအဆင့်မှာ _လေ့ကျင့်သည့်ဖိုင်ကို စစ်ဆေးခြင်း_ ဖြစ်ပြီး၊ ဒေတာသည် မှန်ကန်သောဖော်မတ်ဖြစ်ကြောင်း သေချာစေရန်ဖြစ်သည်။\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၂.၃ - ဖြစ်စဉ်တိုးတက်မှုကို စောင့်ကြည့်ရန် အဖြစ်အပျက်များကို မှတ်တမ်းတင်ပါ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၂.၄ - OpenAI ဒက်ရှ်ဘုတ်တွင် အခြေအနေကို ကြည့်ရှုပါ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "သင်သည် OpenAI ဝက်ဘ်ဆိုက်သို့ သွားရောက်ကြည့်ရှု၍ _Fine-tuning_ အပိုင်းတွင်လည်း အခြေအနေကိုကြည့်ရှုနိုင်ပါသည်။ ဤနေရာတွင် လက်ရှိလုပ်ဆောင်နေသော အလုပ်၏အခြေအနေကိုကြည့်ရှုနိုင်သလို၊ ယခင်လုပ်ဆောင်ခဲ့သော အလုပ်များ၏ မှတ်တမ်းများကိုလည်း ကြည့်ရှုနိုင်ပါသည်။ ဤ screenshot တွင် ယခင်လုပ်ဆောင်မှုတစ်ခု မအောင်မြင်ခဲ့ပြီး၊ ဒုတိယအကြိမ်မှာ အောင်မြင်ခဲ့သည်ကို တွေ့နိုင်ပါသည်။ နောက်ခံအနေနဲ့ ပြောရရင်၊ ပထမအကြိမ်မှာ JSON ဖိုင်ထဲမှာ မှားယွင်းစွာ ဖော်ပြထားတဲ့ မှတ်တမ်းတွေကြောင့် ဖြစ်ပေါ်ခဲ့တာပါ - ပြင်ဆင်ပြီးနောက် ဒုတိယအကြိမ်မှာ အောင်မြင်စွာ ပြီးမြောက်သွားပြီး မော်ဒယ်ကို အသုံးပြုနိုင်အောင် ဖြစ်လာခဲ့ပါတယ်။\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.my.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "သင်သည် visual dashboard တွင် အောက်သို့ scroll လုပ်ခြင်းဖြင့်လည်း status messages နှင့် metrics များကို ကြည့်ရှုနိုင်ပါသည်-\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.my.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.my.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၃.၁ - ID ကို ရယူခြင်းနှင့် Fine-Tuned မော်ဒယ်ကို ကုဒ်ထဲမှာ စမ်းသပ်ကြည့်ခြင်း\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### အဆင့် ၃.၂ - Playground တွင် Fine-Tuned Model ကို Load လုပ်ပြီး စမ်းသပ်ခြင်း\n",
    "\n",
    "ယခု Fine-tuned model ကို စမ်းသပ်ရန် နည်းလမ်းနှစ်ခုရှိသည်။ ပထမနည်းမှာ Playground ကို သွားပြီး Models drop-down မှာ သင့် Fine-tuned model ကို ရွေးချယ်နိုင်သည်။ နောက်ထပ်နည်းတစ်ခုကတော့ Fine-tuning panel (အထက်ပါ screenshot တွင်ပြထားသည်) မှာ \"Playground\" ကိုနှိပ်ခြင်းဖြင့် _နှိုင်းယှဉ်ကြည့်နိုင်သော_ view ကို ဖွင့်ပေးမည်ဖြစ်ပြီး၊ foundation model နဲ့ fine-tuned model နှစ်ခုလုံးကို တစ်ပြိုင်နက်တည်း မြင်နိုင်သဖြင့် အလွယ်တကူ စမ်းသပ်နိုင်သည်။\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.my.png)\n",
    "\n",
    "သင့် training data တွင်သုံးထားသော system context ကို ဖြည့်ပြီး စမ်းသပ်မည့်မေးခွန်းကို ထည့်ပေးပါ။ နှစ်ဖက်လုံးတွင် context နဲ့ မေးခွန်းတူညီစွာ ပြသထားသည်ကို တွေ့ရမည်။ နှိုင်းယှဉ်မှုကို run လုပ်ပြီးနောက် output များအကြား ကွာခြားချက်ကို မြင်နိုင်ပါလိမ့်မည်။ _Fine-tuned model သည် သင်ပေးထားသော ဥပမာများအတိုင်း format ကိုလိုက်နာပြီး ဖြေကြားပေးသော်လည်း foundation model သည် system prompt ကိုသာလိုက်နာသည်ကို သတိပြုကြည့်ပါ_။\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.my.png)\n",
    "\n",
    "နှိုင်းယှဉ်မှုတွင် model တစ်ခုချင်းစီအတွက် token အရေအတွက်နှင့် inference အတွက် ကြာချိန်ကိုလည်း ပြသပေးသည်ကို တွေ့ရမည်။ **ဤဥပမာသည် လုပ်ငန်းစဉ်ကို ပြသရန်သာ ရည်ရွယ်ထားသော်လည်း တကယ့်လောကအတွက် dataset သို့မဟုတ် အခြေအနေတစ်ခုကို မဖော်ပြပါ**။ နှစ်ခုလုံးတွင် token အရေအတွက်တူညီသော်လည်း (system context နဲ့ user prompt တူညီသည်) fine-tuned model (custom model) သည် inference အတွက် ပိုကြာသည်ကို တွေ့နိုင်သည်။\n",
    "\n",
    "တကယ့်လောကအခြေအနေများတွင် ဤလို ဥပမာလေးများမသုံးတော့ဘဲ တကယ့် data (ဥပမာ- ဖောက်သည်ဝန်ဆောင်မှုအတွက် ပစ္စည်းစာရင်း) များဖြင့် fine-tune လုပ်မည်ဖြစ်ပြီး၊ ဖြေကြားမှုအရည်အသွေးက ပိုမိုရှင်းလင်းစွာ ထင်ရှားလာမည်။ ထိုအခြေအနေတွင် foundation model ဖြင့် တူညီသော ဖြေကြားမှုအရည်အသွေးရရှိရန် custom prompt engineering ပိုမိုလုပ်ရမည်ဖြစ်ပြီး၊ ထို့ကြောင့် token အသုံးအများနှင့် inference processing time တိုးလာနိုင်သည်။ _ဤအရာကို စမ်းသပ်လိုပါက OpenAI Cookbook ထဲရှိ fine-tuning ဥပမာများကို ကြည့်ပြီး စတင်နိုင်သည်_။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**သတိပြုရန်**:\nဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှန်ကန်မှုအတွက် ကြိုးစားနေသော်လည်း၊ အလိုအလျောက် ဘာသာပြန်ချက်များတွင် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းဘာသာဖြင့် ရေးသားထားသော စာရွက်စာတမ်းကို အာဏာတရားရှိသော ရင်းမြစ်အဖြစ် ယူဆသင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်များ၏ ဝန်ဆောင်မှုကို အသုံးပြုရန် အကြံပြုပါသည်။ ဤဘာသာပြန်ချက်ကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာသော နားလည်မှုမှားခြင်း သို့မဟုတ် အနားလည်အမှားများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:59:11+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "my"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}