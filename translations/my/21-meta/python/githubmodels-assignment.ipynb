{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meta မိသားစု မော်ဒယ်များဖြင့် တည်ဆောက်ခြင်း\n",
    "\n",
    "## မိတ်ဆက်\n",
    "\n",
    "ဒီသင်ခန်းစာမှာ -\n",
    "\n",
    "- Meta မိသားစုရဲ့ အဓိက မော်ဒယ် ၂ မျိုး - Llama 3.1 နဲ့ Llama 3.2 ကို လေ့လာသွားမှာပါ\n",
    "- မော်ဒယ်တစ်ခုချင်းစီအတွက် အသုံးပြုနိုင်တဲ့ အခြေအနေများနဲ့ သုံးစွဲနည်းများကို နားလည်သွားမယ်\n",
    "- မော်ဒယ်တစ်ခုချင်းစီရဲ့ ထူးခြားချက်တွေကို ပြသပေးမယ့် ကုဒ်နမူနာ\n",
    "\n",
    "## Meta မိသားစု မော်ဒယ်များ\n",
    "\n",
    "ဒီသင်ခန်းစာမှာတော့ Meta မိသားစု (Llama Herd) ထဲက မော်ဒယ် ၂ မျိုး - Llama 3.1 နဲ့ Llama 3.2 ကို လေ့လာသွားမှာပါ\n",
    "\n",
    "ဒီမော်ဒယ်တွေက မတူညီတဲ့ ဗားရှင်းအမျိုးအစားတွေနဲ့ ရနိုင်ပြီး Github Model marketplace မှာ ရရှိနိုင်ပါတယ်။ Github Models ကို အသုံးပြုပြီး [AI မော်ဒယ်တွေနဲ့ ပရိုတိုတိုက် တည်ဆောက်နည်း](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst) ကို ဒီမှာ အသေးစိတ်ကြည့်နိုင်ပါတယ်။\n",
    "\n",
    "မော်ဒယ် ဗားရှင်းအမျိုးအစားများ -\n",
    "- Llama 3.1 - 70B Instruct\n",
    "- Llama 3.1 - 405B Instruct\n",
    "- Llama 3.2 - 11B Vision Instruct\n",
    "- Llama 3.2 - 90B Vision Instruct\n",
    "\n",
    "*မှတ်ချက် - Llama 3 ကိုလည်း Github Models မှာ ရနိုင်ပေမယ့် ဒီသင်ခန်းစာမှာတော့ မဖော်ပြပါ*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "Parameters ၄၀၅ ဘီလီယံရှိတဲ့ Llama 3.1 ဟာ open source LLM အမျိုးအစားထဲမှာ ပါဝင်ပါတယ်။\n",
    "\n",
    "ဒီမော်ဒယ်က Llama 3 ရဲ့ ယခင်ထုတ်လွှင့်မှုကို အဆင့်မြှင့်တင်ပေးထားပြီး -\n",
    "\n",
    "- ပိုကြီးတဲ့ context window - ၁၂၈,၀၀၀ token (128k tokens) ကို ၈,၀၀၀ token (8k tokens) နဲ့ နှိုင်းယှဉ်နိုင်ပါတယ်။\n",
    "- ပိုကြီးတဲ့ Max Output Tokens - ၄,၀၉၆ ကို ၂,၀၄၈ နဲ့ နှိုင်းယှဉ်နိုင်ပါတယ်။\n",
    "- ဘာသာစကားစုံ ပိုမိုကောင်းမွန်တဲ့ ထောက်ပံ့မှု - လေ့ကျင့်သည့် token ပိုများလာတာကြောင့်\n",
    "\n",
    "ဒါကြောင့် Llama 3.1 ဟာ GenAI applications တည်ဆောက်ရာမှာ ပိုမိုရှုပ်ထွေးတဲ့ အသုံးပြုမှုများကို ကိုင်တွယ်နိုင်စေပါတယ်။ ဥပမာ -\n",
    "\n",
    "- Native Function Calling - LLM workflow အပြင်မှာရှိတဲ့ tools နဲ့ functions တွေကို ခေါ်သုံးနိုင်စွမ်း\n",
    "- RAG Performance ပိုကောင်းလာခြင်း - context window ပိုကြီးလာတာကြောင့်\n",
    "- Synthetic Data Generation - fine-tuning လုပ်တဲ့အခါလိုအပ်တဲ့ အကျိုးရှိတဲ့ data တွေကို ဖန်တီးနိုင်စွမ်း\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### မူရင်း Function ခေါ်ယူခြင်း\n",
    "\n",
    "Llama 3.1 ကို function သို့မဟုတ် tool ခေါ်ယူမှုများကို ပိုမိုထိရောက်စွာ ဆောင်ရွက်နိုင်အောင် ပြင်ဆင်တိုးတက်အောင်လုပ်ထားသည်။ ထို့အပြင်၊ ဒီမော်ဒယ်မှာ အသုံးပြုသူရဲ့ prompt အပေါ်မူတည်ပြီး အသုံးပြုဖို့လိုအပ်တယ်လို့ သတ်မှတ်နိုင်တဲ့ တစ်ချို့ built-in tool နှစ်ခုပါဝင်ပါတယ်။ ဒီ tool နှစ်ခုကတော့ -\n",
    "\n",
    "- **Brave Search** - Web search လုပ်ခြင်းအားဖြင့် မိုးလေဝသလို နောက်ဆုံးရသတင်းအချက်အလက်များ ရယူနိုင်သည်။\n",
    "- **Wolfram Alpha** - ပိုမိုရှုပ်ထွေးသော သင်္ချာတွက်ချက်မှုများအတွက် အသုံးပြုနိုင်ပြီး ကိုယ်တိုင် function မရေးရအောင် ကူညီပေးနိုင်သည်။\n",
    "\n",
    "သင့်ရဲ့ ကိုယ်ပိုင် custom tool များကိုလည်း LLM က ခေါ်ယူနိုင်အောင် ဖန်တီးနိုင်သည်။\n",
    "\n",
    "အောက်ပါ code ဥပမာတွင် -\n",
    "\n",
    "- အသုံးပြုနိုင်သော tool များ (brave_search, wolfram_alpha) ကို system prompt ထဲမှာ သတ်မှတ်ထားသည်။\n",
    "- တစ်မြို့မှာ မိုးလေဝသအကြောင်း မေးသော user prompt တစ်ခု ပို့သည်။\n",
    "- LLM ကတော့ Brave Search tool ကို ခေါ်ယူတဲ့ tool call ဖြင့် တုံ့ပြန်ပေးမည်၊ ဥပမာ - `<|python_tag|>brave_search.call(query=\"Stockholm weather\")` ဆိုသလို ဖြစ်ပါလိမ့်မည်။\n",
    "\n",
    "*မှတ်ချက် - ဤဥပမာသည် tool call ကိုသာ ပြုလုပ်သည်။ ရလဒ်ကို ရယူလိုပါက Brave API စာမျက်နှာတွင် အခမဲ့အကောင့်ဖွင့်ပြီး function ကို ကိုယ်တိုင် သတ်မှတ်ရန် လိုအပ်ပါသည်*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2\n",
    "\n",
    "Llama 3.1 မှာ LLM ဖြစ်ပေမယ့် တစ်ခုကန့်သတ်ချက်ရှိတယ်။ အဲဒါကတော့ မူလတန်းအမျိုးမျိုးကို အသုံးပြုနိုင်မှုပါ။ ဥပမာ၊ ပုံတွေကို prompt အနေနဲ့ အသုံးပြုပြီး တုံ့ပြန်ချက်တွေ ပေးနိုင်တာ။ ဒီစွမ်းရည်က Llama 3.2 ရဲ့ အဓိကအင်္ဂါရပ်တွေထဲက တစ်ခုပါ။ အောက်ပါအင်္ဂါရပ်တွေပါဝင်ပါတယ် -\n",
    "\n",
    "- Multimodality - စာသားနဲ့ ပုံ prompt နှစ်မျိုးလုံးကို သုံးသပ်နိုင်တဲ့စွမ်းရည်ရှိတယ်\n",
    "- Small to Medium size variations (11B နဲ့ 90B) - ဒီအမျိုးအစားတွေက တပ်ဆင်မှုအတွက် လိုအပ်ချက်အမျိုးမျိုးကို ဖြည့်ဆည်းနိုင်စေတယ်\n",
    "- Text-only variations (1B နဲ့ 3B) - ဒီအမျိုးအစားတွေက model ကို edge / mobile device တွေမှာ တပ်ဆင်နိုင်ပြီး latency နည်းနည်းနဲ့ အသုံးပြုနိုင်စေတယ်\n",
    "\n",
    "Multimodal support က open source model လောကမှာ တစ်ဆင့်ကြီးတိုးတက်မှုတစ်ခုပါ။ အောက်မှာပါတဲ့ code ဥပမာက ပုံနဲ့ စာ prompt နှစ်မျိုးလုံးကို အသုံးပြုပြီး Llama 3.2 90B မှ ပုံအကြောင်းသုံးသပ်ချက်ရယူတာပါ။\n",
    "\n",
    "### Multimodal Support with Llama 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## သင်ယူမှုက ဒီမှာတင် မပြီးသေးပါ၊ ခရီးကို ဆက်လက်တက်ကြွပါ\n",
    "\n",
    "ဒီသင်ခန်းစာကို ပြီးဆုံးပြီးရင်၊ သင့်ရဲ့ Generative AI အသိပညာကို ဆက်လက်တိုးတက်အောင် [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ကိုလည်း သွားကြည့်ပါ။\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**သတိပြုရန်**:\nဤစာရွက်စာတမ်းကို AI ဘာသာပြန်ဝန်ဆောင်မှု [Co-op Translator](https://github.com/Azure/co-op-translator) ကို အသုံးပြု၍ ဘာသာပြန်ထားပါသည်။ ကျွန်ုပ်တို့သည် တိကျမှန်ကန်မှုအတွက် ကြိုးစားနေသော်လည်း၊ အလိုအလျောက်ဘာသာပြန်ခြင်းတွင် အမှားများ သို့မဟုတ် မမှန်ကန်မှုများ ပါဝင်နိုင်သည်ကို သတိပြုပါ။ မူရင်းစာရွက်စာတမ်းကို မူလဘာသာဖြင့်သာ အာဏာတရားရှိသော အရင်းအမြစ်အဖြစ် ယူဆသင့်ပါသည်။ အရေးကြီးသော အချက်အလက်များအတွက် လူ့ဘာသာပြန်ပညာရှင်များ၏ ဝန်ဆောင်မှုကို အသုံးပြုရန် အကြံပြုပါသည်။ ဤဘာသာပြန်ချက်ကို အသုံးပြုခြင်းမှ ဖြစ်ပေါ်လာနိုင်သော နားလည်မှုမှားခြင်း သို့မဟုတ် အနားယူမှားခြင်းများအတွက် ကျွန်ုပ်တို့သည် တာဝန်မယူပါ။\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:50:29+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "my"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}