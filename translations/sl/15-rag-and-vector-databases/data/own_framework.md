<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-05-20T02:28:29+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "sl"
}
-->
# Uvod v nevronske mreÅ¾e. VeÄplastni perceptron

V prejÅ¡njem razdelku ste spoznali najpreprostejÅ¡i model nevronske mreÅ¾e - enoplastni perceptron, linearen model za dvoplastno klasifikacijo.

V tem razdelku bomo ta model razÅ¡irili v bolj prilagodljiv okvir, ki nam bo omogoÄil:

* izvajanje **veÄplastne klasifikacije** poleg dvoplastne
* reÅ¡evanje **regresijskih problemov** poleg klasifikacije
* loÄevanje razredov, ki niso linearno loÄljivi

Razvili bomo tudi svoj modularni okvir v Pythonu, ki nam bo omogoÄil konstrukcijo razliÄnih arhitektur nevronskih mreÅ¾.

## Formalizacija strojnega uÄenja

ZaÄnimo z formalizacijo problema strojnega uÄenja. Predpostavimo, da imamo uÄni podatkovni niz **X** z oznakami **Y**, in potrebujemo zgraditi model *f*, ki bo podajal najbolj natanÄne napovedi. Kakovost napovedi merimo z **funkcijo izgube** â„’. Pogosto uporabljene funkcije izgube so:

* Pri regresijskem problemu, ko moramo napovedati Å¡tevilo, lahko uporabimo **absolutno napako** âˆ‘<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, ali **kvadratno napako** âˆ‘<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Pri klasifikaciji uporabljamo **0-1 izgubo** (ki je v bistvu enaka **natanÄnosti** modela), ali **logistiÄno izgubo**.

Pri enoplastnem perceptronu je bila funkcija *f* definirana kot linearna funkcija *f(x)=wx+b* (tu je *w* matrica uteÅ¾i, *x* je vektor vhodnih znaÄilnosti, in *b* je vektor pristranskosti). Pri razliÄnih arhitekturah nevronskih mreÅ¾ lahko ta funkcija dobi bolj zapleteno obliko.

> Pri klasifikaciji je pogosto zaÅ¾eleno, da dobimo verjetnosti ustreznih razredov kot izhod mreÅ¾e. Za pretvorbo poljubnih Å¡tevilk v verjetnosti (npr. za normalizacijo izhoda) pogosto uporabljamo **softmax** funkcijo Ïƒ, in funkcija *f* postane *f(x)=Ïƒ(wx+b)*

V zgornji definiciji *f* sta *w* in *b* imenovana **parametra** Î¸=âŸ¨*w,b*âŸ©. Glede na podatkovni niz âŸ¨**X**,**Y**âŸ© lahko izraÄunamo skupno napako na celotnem podatkovnem nizu kot funkcijo parametrov Î¸.

> âœ… **Cilj treniranja nevronske mreÅ¾e je zmanjÅ¡ati napako s spreminjanjem parametrov Î¸**

## Optimizacija s spustom po gradientu

Obstaja dobro znana metoda optimizacije funkcij, imenovana **spust po gradientu**. Ideja je, da lahko izraÄunamo odvod (v veÄdimenzionalnem primeru imenovan **gradient**) funkcije izgube glede na parametre, in spreminjamo parametre tako, da se napaka zmanjÅ¡a. To lahko formaliziramo takole:

* Inicializiramo parametre z nekimi nakljuÄnimi vrednostmi w<sup>(0)</sup>, b<sup>(0)</sup>
* VeÄkrat ponovimo naslednji korak:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚b

Med treniranjem naj bi bili koraki optimizacije izraÄunani ob upoÅ¡tevanju celotnega podatkovnega niza (spomnite se, da se izguba izraÄuna kot vsota skozi vse uÄne vzorce). V resniÄnem Å¾ivljenju pa vzamemo majhne dele podatkovnega niza, imenovane **minibatches**, in izraÄunamo gradient na podlagi podniza podatkov. Ker je podniz vsakokrat nakljuÄno izbran, je taka metoda imenovana **stohastiÄni spust po gradientu** (SGD).

## VeÄplastni perceptroni in povratno razÅ¡irjanje

Enoplastna mreÅ¾a, kot smo videli zgoraj, je sposobna klasificirati linearno loÄljive razrede. Za izgradnjo bogatejÅ¡ega modela lahko kombiniramo veÄ plasti mreÅ¾e. MatematiÄno bi to pomenilo, da ima funkcija *f* bolj zapleteno obliko, in bo izraÄunana v veÄ korakih:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Î±(z<sub>1</sub>)+b<sub>2</sub>
* f = Ïƒ(z<sub>2</sub>)

Tu je Î± **ne-linearna aktivacijska funkcija**, Ïƒ je softmax funkcija, in parametri Î¸=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Algoritem spusta po gradientu ostane enak, vendar bo teÅ¾je izraÄunati gradiente. Glede na pravilo veriÅ¾ne diferenciacije lahko izraÄunamo odvode kot:

* âˆ‚â„’/âˆ‚w<sub>2</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚w<sub>2</sub>)
* âˆ‚â„’/âˆ‚w<sub>1</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚Î±)(âˆ‚Î±/âˆ‚z<sub>1</sub>)(âˆ‚z<sub>1</sub>/âˆ‚w<sub>1</sub>)

> âœ… Pravilo veriÅ¾ne diferenciacije se uporablja za izraÄun odvoda funkcije izgube glede na parametre.

UpoÅ¡tevajte, da je levi del vseh teh izrazov enak, zato lahko uÄinkovito izraÄunamo odvode, zaÄenÅ¡i z funkcijo izgube in gremo "nazaj" skozi raÄunski graf. Tako se metoda treniranja veÄplastnega perceptrona imenuje **povratno razÅ¡irjanje**, ali 'backprop'.

## ZakljuÄek

V tej lekciji smo zgradili svojo knjiÅ¾nico nevronskih mreÅ¾ in jo uporabili za preprosto dvodimenzionalno klasifikacijsko nalogo.

## ğŸš€ Izziv

V priloÅ¾eni beleÅ¾nici boste implementirali svoj okvir za gradnjo in treniranje veÄplastnih perceptronov. Videli boste podrobnosti delovanja sodobnih nevronskih mreÅ¾.

Nadaljujte v beleÅ¾nici OwnFramework in jo predelajte.

## Pregled & Samostojno uÄenje

Povratno razÅ¡irjanje je pogost algoritem, uporabljen v AI in ML, vreden podrobnejÅ¡ega Å¡tudija.

## Naloga

V tem laboratoriju morate uporabiti okvir, ki ste ga zgradili v tej lekciji, za reÅ¡evanje klasifikacije roÄno pisanih Å¡tevilk MNIST.

* Navodila
* BeleÅ¾nica

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve AI za prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas prosimo, da upoÅ¡tevate, da avtomatizirani prevodi lahko vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za kljuÄne informacije se priporoÄa profesionalni prevod s strani Äloveka. Ne odgovarjamo za morebitne nesporazume ali napaÄne razlage, ki bi nastale zaradi uporabe tega prevoda.