<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "59021c5f419d3feda19075910a74280a",
  "translation_date": "2025-07-09T17:01:52+00:00",
  "source_file": "15-rag-and-vector-databases/data/perceptron.md",
  "language_code": "sl"
}
-->
# Uvod v nevronske mreÅ¾e: Perceptron

Eden prvih poskusov implementacije neÄesa podobnega sodobni nevronski mreÅ¾i je leta 1957 izvedel Frank Rosenblatt iz Cornell Aeronautical Laboratory. Å lo je za strojno implementacijo z imenom "Mark-1", zasnovano za prepoznavanje osnovnih geometrijskih likov, kot so trikotniki, kvadrati in krogi.

|      |      |
|--------------|-----------|
|<img src='images/Rosenblatt-wikipedia.jpg' alt='Frank Rosenblatt'/> | <img src='images/Mark_I_perceptron_wikipedia.jpg' alt='The Mark 1 Perceptron' />|

> Slike iz Wikipedije

Vhodna slika je bila predstavljena z mreÅ¾o 20x20 fotocelic, tako da je nevronska mreÅ¾a imela 400 vhodov in en binarni izhod. Preprosta mreÅ¾a je vsebovala en nevron, imenovan tudi **enota pragovne logike**. TeÅ¾e v nevronski mreÅ¾i so delovale kot potenciometri, ki so zahtevali roÄno nastavitev med fazo uÄenja.

> âœ… Potenciometer je naprava, ki uporabniku omogoÄa prilagajanje upornosti v vezju.

> The New York Times je takrat o perceptronu zapisal: *zarodek elektronskega raÄunalnika, za katerega [Navy] priÄakuje, da bo lahko hodil, govoril, videl, pisal, se razmnoÅ¾eval in bil zavedajoÄ svojega obstoja.*

## Model perceptrona

Predpostavimo, da imamo v naÅ¡em modelu N znaÄilnosti, v tem primeru je vhodni vektor velikosti N. Perceptron je model **binarne klasifikacije**, kar pomeni, da lahko razlikuje med dvema razredoma vhodnih podatkov. Predpostavili bomo, da je za vsak vhodni vektor x izhod naÅ¡ega perceptrona bodisi +1 ali -1, odvisno od razreda. Izhod se izraÄuna po formuli:

y(x) = f(w<sup>T</sup>x)

kjer je f stopniÄasta aktivacijska funkcija

## UÄenje perceptrona

Za uÄenje perceptrona moramo najti vektor uteÅ¾i w, ki pravilno klasificira veÄino vrednosti, torej povzroÄi najmanjÅ¡o **napako**. Ta napaka je definirana z **perceptronovim kriterijem** na naslednji naÄin:

E(w) = -âˆ‘w<sup>T</sup>x<sub>i</sub>t<sub>i</sub>

kjer:

* se vsota izraÄuna za tiste uÄne podatke i, ki so napaÄno klasificirani
* x<sub>i</sub> so vhodni podatki, t<sub>i</sub> pa je bodisi -1 ali +1 za negativne oziroma pozitivne primere.

Ta kriterij obravnavamo kot funkcijo uteÅ¾i w, ki jo Å¾elimo minimizirati. Pogosto se uporablja metoda, imenovana **gradientni spust**, pri kateri zaÄnemo z zaÄetnimi uteÅ¾mi w<sup>(0)</sup> in nato pri vsakem koraku posodobimo uteÅ¾i po formuli:

w<sup>(t+1)</sup> = w<sup>(t)</sup> - Î·âˆ‡E(w)

Tu je Î· t.i. **hitrost uÄenja**, âˆ‡E(w) pa predstavlja **gradient** funkcije E. Ko izraÄunamo gradient, dobimo:

w<sup>(t+1)</sup> = w<sup>(t)</sup> + âˆ‘Î·x<sub>i</sub>t<sub>i</sub>

Algoritem v Pythonu izgleda takole:

```python
def train(positive_examples, negative_examples, num_iterations = 100, eta = 1):

    weights = [0,0,0] # Initialize weights (almost randomly :)
        
    for i in range(num_iterations):
        pos = random.choice(positive_examples)
        neg = random.choice(negative_examples)

        z = np.dot(pos, weights) # compute perceptron output
        if z < 0: # positive example classified as negative
            weights = weights + eta*weights.shape

        z  = np.dot(neg, weights)
        if z >= 0: # negative example classified as positive
            weights = weights - eta*weights.shape

    return weights
```

## ZakljuÄek

V tej lekciji ste spoznali perceptron, ki je model binarne klasifikacije, in kako ga nauÄiti z uporabo vektorja uteÅ¾i.

## ğŸš€ Izziv

ÄŒe Å¾elite poskusiti zgraditi svoj perceptron, preizkusite ta laboratorij na Microsoft Learn, ki uporablja Azure ML designer.

## Pregled in samostojno uÄenje

Da vidite, kako lahko perceptron uporabimo za reÅ¡evanje preprostih in tudi resniÄnih problemov ter nadaljujete z uÄenjem, pojdite na Perceptron zvezek.

Tukaj je tudi zanimiv Älanek o perceptronih.

## Naloga

V tej lekciji smo implementirali perceptron za nalogo binarne klasifikacije in ga uporabili za razvrÅ¡Äanje med dvema roÄno napisanima Å¡tevilkama. V tej laboratorijski nalogi morate popolnoma reÅ¡iti problem klasifikacije Å¡tevilk, torej doloÄiti, katera Å¡tevilka najbolj ustreza dani sliki.

* Navodila
* Zvezek

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za avtomatski prevod AI [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas opozarjamo, da lahko avtomatski prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za kljuÄne informacije priporoÄamo strokovni ÄloveÅ¡ki prevod. Za morebitna nesporazume ali napaÄne interpretacije, ki izhajajo iz uporabe tega prevoda, ne odgovarjamo.