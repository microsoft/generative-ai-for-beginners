<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T09:04:57+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "sl"
}
-->
# Odgovorna uporaba generativne umetne inteligence

[![Using Generative AI Responsibly](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.sl.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite na zgornjo sliko za ogled videa te lekcije_

Generativna umetna inteligenca je lahko zelo fascinantna, a pomembno je, da razmislite, kako jo boste uporabljali odgovorno. Treba je upoÅ¡tevati, kako zagotoviti, da so rezultati praviÄni, neÅ¡kodljivi in Å¡e veÄ. Ta poglavje vam bo ponudilo kontekst, na kaj morate biti pozorni in kako lahko aktivno izboljÅ¡ate svojo uporabo AI.

## Uvod

V tej lekciji bomo obravnavali:

- Zakaj je pri razvoju aplikacij z generativno AI pomembno dati prednost odgovorni uporabi AI.
- Osnovna naÄela odgovorne AI in kako se povezujejo z generativno AI.
- Kako ta naÄela odgovorne AI uresniÄiti v praksi s strategijo in orodji.

## Cilji uÄenja

Po zakljuÄku te lekcije boste razumeli:

- Pomen odgovorne AI pri razvoju aplikacij z generativno AI.
- Kdaj razmiÅ¡ljati o osnovnih naÄelih odgovorne AI in jih uporabljati pri razvoju generativnih AI aplikacij.
- Katere strategije in orodja so vam na voljo za uresniÄevanje koncepta odgovorne AI.

## NaÄela odgovorne AI

NavduÅ¡enje nad generativno AI Å¡e nikoli ni bilo veÄje. To navduÅ¡enje je pritegnilo veliko novih razvijalcev, pozornosti in financiranja na tem podroÄju. ÄŒeprav je to zelo pozitivno za vse, ki Å¾elijo graditi izdelke in podjetja z generativno AI, je prav tako pomembno, da pri tem ravnamo odgovorno.

V tem teÄaju se osredotoÄamo na gradnjo naÅ¡ega startupa in naÅ¡ega izobraÅ¾evalnega AI izdelka. Uporabili bomo naÄela odgovorne AI: praviÄnost, vkljuÄevanje, zanesljivost/varnost, varnost in zasebnost, preglednost ter odgovornost. S temi naÄeli bomo raziskali, kako se povezujejo z uporabo generativne AI v naÅ¡ih izdelkih.

## Zakaj dati prednost odgovorni AI

Pri razvoju izdelka je najboljÅ¡i pristop osredotoÄenost na Äloveka, kjer imate v mislih najboljÅ¡e interese uporabnika.

Edinstvenost generativne AI je njena moÄ ustvarjanja koristnih odgovorov, informacij, navodil in vsebin za uporabnike. To lahko doseÅ¾e brez veliko roÄnih korakov, kar lahko privede do zelo impresivnih rezultatov. Brez ustreznega naÄrtovanja in strategij pa lahko Å¾al povzroÄi tudi Å¡kodljive posledice za vaÅ¡e uporabnike, izdelek in druÅ¾bo kot celoto.

Oglejmo si nekaj (a ne vseh) teh potencialno Å¡kodljivih rezultatov:

### Halucinacije

Halucinacije so izraz, ki opisuje, ko LLM ustvari vsebino, ki je popolnoma nesmiselna ali pa je dejansko napaÄna glede na druge vire informacij.

Na primer, Äe razvijemo funkcijo za naÅ¡ startup, ki Å¡tudentom omogoÄa postavljanje zgodovinskih vpraÅ¡anj modelu. Å tudent vpraÅ¡a: `Kdo je bil edini preÅ¾iveli Titanika?`

Model odgovori, kot je prikazano spodaj:

![Prompt saying "Who was the sole survivor of the Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Vir: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

To je zelo samozavesten in podroben odgovor. Na Å¾alost je napaÄen. Å½e z minimalnim raziskovanjem bi ugotovili, da je bilo veÄ preÅ¾ivelih katastrofe Titanika. Za Å¡tudenta, ki Å¡ele zaÄenja raziskovati to temo, je ta odgovor lahko dovolj prepriÄljiv, da ga ne postavi pod vpraÅ¡aj in ga obravnava kot dejstvo. Posledice tega so lahko nezanesljivost AI sistema in negativni vpliv na ugled naÅ¡ega startupa.

Z vsako novo razliÄico LLM smo opazili izboljÅ¡ave pri zmanjÅ¡evanju halucinacij. Kljub temu pa moramo kot razvijalci in uporabniki ostati zavedni teh omejitev.

### Å kodljiva vsebina

V prejÅ¡njem delu smo obravnavali, ko LLM ustvari napaÄne ali nesmiselne odgovore. Drugo tveganje, na katerega moramo biti pozorni, je, ko model odgovori s Å¡kodljivo vsebino.

Å kodljivo vsebino lahko opredelimo kot:

- Navodila ali spodbujanje samopoÅ¡kodovanja ali Å¡kode doloÄenim skupinam.
- SovraÅ¾no ali poniÅ¾ujoÄo vsebino.
- NaÄrtovanje napadov ali nasilnih dejanj.
- Navodila, kako najti nezakonito vsebino ali storiti nezakonita dejanja.
- Prikazovanje spolno eksplicitne vsebine.

Za naÅ¡ startup Å¾elimo zagotoviti, da imamo ustrezna orodja in strategije, ki prepreÄujejo, da bi Å¡tudenti videli tovrstno vsebino.

### Pomanjkanje praviÄnosti

PraviÄnost pomeni â€zagotoviti, da je AI sistem prost predsodkov in diskriminacije ter da vse obravnava praviÄno in enako.â€œ V svetu generativne AI Å¾elimo zagotoviti, da model ne krepi izkljuÄujoÄih pogledov na marginalizirane skupine.

TakÅ¡ni izpisi niso le Å¡kodljivi za ustvarjanje pozitivnih uporabniÅ¡kih izkuÅ¡enj, ampak povzroÄajo tudi dodatno druÅ¾beno Å¡kodo. Kot razvijalci aplikacij moramo vedno imeti v mislih Å¡iroko in raznoliko bazo uporabnikov pri razvoju reÅ¡itev z generativno AI.

## Kako odgovorno uporabljati generativno AI

Zdaj, ko smo prepoznali pomen odgovorne generativne AI, poglejmo 4 korake, ki jih lahko naredimo za odgovorno gradnjo AI reÅ¡itev:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.sl.png)

### Merjenje potencialnih Å¡kod

Pri testiranju programske opreme preverjamo priÄakovane akcije uporabnika v aplikaciji. Podobno je testiranje razliÄnih vrst vpraÅ¡anj, ki jih bodo uporabniki najverjetneje postavljali, dober naÄin za merjenje potencialne Å¡kode.

Ker naÅ¡ startup razvija izobraÅ¾evalni izdelek, je smiselno pripraviti seznam izobraÅ¾evalno povezanih vpraÅ¡anj. To lahko vkljuÄuje doloÄeno temo, zgodovinske dejstva in vpraÅ¡anja o Å¡tudentskem Å¾ivljenju.

### Omejevanje potencialnih Å¡kod

ÄŒas je, da poiÅ¡Äemo naÄine, kako prepreÄiti ali omejiti morebitno Å¡kodo, ki jo lahko povzroÄi model in njegovi odgovori. To lahko obravnavamo na 4 razliÄnih nivojih:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.sl.png)

- **Model**. Izbira pravega modela za pravi primer uporabe. VeÄji in bolj kompleksni modeli, kot je GPT-4, lahko predstavljajo veÄje tveganje za Å¡kodljivo vsebino, Äe jih uporabimo za manjÅ¡e in bolj specifiÄne primere. Uporaba lastnih podatkov za dodatno usposabljanje zmanjÅ¡a tveganje Å¡kodljive vsebine.

- **Varnostni sistem**. Varnostni sistem je niz orodij in nastavitev na platformi, ki streÅ¾e model, in pomaga omejiti Å¡kodo. Primer tega je sistem filtriranja vsebin na storitvi Azure OpenAI. Sistemi morajo zaznavati tudi poskuse zaobidenja varnosti (jailbreak) in nezaÅ¾eleno aktivnost, kot so zahteve botov.

- **Metaprompt**. Metaprompti in utemeljitev so naÄini, kako lahko usmerjamo ali omejujemo model glede na doloÄena vedenja in informacije. To lahko vkljuÄuje sistemske vnose, ki doloÄajo meje modela, ter zagotavljanje izhodov, ki so bolj relevantni za obseg ali podroÄje sistema.

Lahko vkljuÄuje tudi tehnike, kot je Retrieval Augmented Generation (RAG), kjer model Ärpa informacije samo iz izbranih zaupanja vrednih virov. V kasnejÅ¡i lekciji tega teÄaja je [gradnja iskalnih aplikacij](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **UporabniÅ¡ka izkuÅ¡nja**. Zadnji nivo je, kjer uporabnik neposredno komunicira z modelom preko vmesnika naÅ¡e aplikacije. Tukaj lahko oblikujemo UI/UX tako, da omejimo vrste vhodov, ki jih lahko uporabnik poÅ¡lje modelu, kot tudi besedilo ali slike, prikazane uporabniku. Pri uvajanju AI aplikacije moramo biti tudi transparentni glede tega, kaj naÅ¡a generativna AI aplikacija zna in Äesa ne.

Za to imamo celotno lekcijo namenjeno [oblikovanju UX za AI aplikacije](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Ocena modela**. Delo z LLM je lahko zahtevno, saj nimamo vedno nadzora nad podatki, na katerih je bil model usposobljen. Kljub temu moramo vedno ocenjevati zmogljivost in izhode modela. Pomembno je meriti natanÄnost, podobnost, utemeljenost in relevantnost izhoda. To pomaga zagotoviti preglednost in zaupanje deleÅ¾nikom in uporabnikom.

### Upravljanje odgovorne generativne AI reÅ¡itve

Vzpostavitev operativnih praks okoli vaÅ¡ih AI aplikacij je zadnja faza. To vkljuÄuje sodelovanje z drugimi oddelki v naÅ¡em startupu, kot so pravni in varnostni, da zagotovimo skladnost z vsemi regulativnimi zahtevami. Pred lansiranjem Å¾elimo pripraviti tudi naÄrte za dostavo, obravnavo incidentov in povrnitev sprememb, da prepreÄimo Å¡kodo uporabnikom.

## Orodja

ÄŒeprav se razvoj odgovornih AI reÅ¡itev morda zdi zahtevno, je delo vredno truda. Ker podroÄje generativne AI raste, bodo na voljo vedno boljÅ¡a orodja, ki bodo razvijalcem pomagala uÄinkovito vkljuÄevati odgovornost v svoje delovne procese. Na primer, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) lahko preko API zahteve zazna Å¡kodljivo vsebino in slike.

## Preverjanje znanja

Kaj morate upoÅ¡tevati, da zagotovite odgovorno uporabo AI?

1. Da je odgovor pravilen.  
1. Da AI ni uporabljena za kriminalne namene.  
1. Da je AI prost predsodkov in diskriminacije.

Odgovor: Pravilna sta 2 in 3. Odgovorna AI vam pomaga razmisliti, kako omejiti Å¡kodljive uÄinke, predsodke in Å¡e veÄ.

## ğŸš€ Izziv

Preberite si o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) in preverite, kaj lahko uporabite za svojo uporabo.

## OdliÄno delo, nadaljujte z uÄenjem

Po zakljuÄku te lekcije si oglejte naÅ¡o [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) in nadgradite svoje znanje o generativni AI!

Pojdite na Lekcijo 4, kjer bomo obravnavali [osnove oblikovanja promptov](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo AI prevajalske storitve [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas opozarjamo, da avtomatizirani prevodi lahko vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za kljuÄne informacije priporoÄamo strokovni ÄloveÅ¡ki prevod. Nismo odgovorni za morebitna nesporazume ali napaÄne interpretacije, ki izhajajo iz uporabe tega prevoda.