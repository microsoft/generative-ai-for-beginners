{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradnja z modeli iz družine Meta\n",
    "\n",
    "## Uvod\n",
    "\n",
    "V tej lekciji bomo obravnavali:\n",
    "\n",
    "- Raziskovanje dveh glavnih modelov iz družine Meta – Llama 3.1 in Llama 3.2\n",
    "- Razumevanje primerov uporabe in scenarijev za vsak model\n",
    "- Primer kode, ki prikazuje edinstvene lastnosti vsakega modela\n",
    "\n",
    "## Družina modelov Meta\n",
    "\n",
    "V tej lekciji bomo raziskali 2 modela iz družine Meta oziroma \"Llama Herd\" – Llama 3.1 in Llama 3.2\n",
    "\n",
    "Ti modeli so na voljo v različnih različicah in jih najdete na tržnici Github Model. Več informacij o uporabi Github Models za [prototipiranje z AI modeli](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "Različice modelov:\n",
    "- Llama 3.1 – 70B Instruct\n",
    "- Llama 3.1 – 405B Instruct\n",
    "- Llama 3.2 – 11B Vision Instruct\n",
    "- Llama 3.2 – 90B Vision Instruct\n",
    "\n",
    "*Opomba: Llama 3 je prav tako na voljo na Github Models, vendar v tej lekciji ne bo obravnavana*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "S 405 milijardami parametrov Llama 3.1 spada v kategorijo odprtokodnih LLM-jev.\n",
    "\n",
    "Ta model je nadgradnja prejšnje različice Llama 3 in prinaša:\n",
    "\n",
    "- Večje kontekstno okno – 128k žetonov v primerjavi z 8k žetoni\n",
    "- Večje največje število izhodnih žetonov – 4096 v primerjavi z 2048\n",
    "- Boljša podpora za več jezikov – zaradi večjega števila učnih žetonov\n",
    "\n",
    "To omogoča, da Llama 3.1 obvladuje bolj zahtevne primere uporabe pri razvoju GenAI aplikacij, vključno z:\n",
    "- Izvorno klicanje funkcij – možnost klicanja zunanjih orodij in funkcij izven LLM delovnega toka\n",
    "- Boljša RAG zmogljivost – zaradi večjega kontekstnega okna\n",
    "- Generiranje sintetičnih podatkov – možnost ustvarjanja učinkovitih podatkov za naloge, kot je fino prilagajanje\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klicanje izvornih funkcij\n",
    "\n",
    "Llama 3.1 je bila dodatno izurjena, da je bolj učinkovita pri klicanju funkcij ali orodij. Ima tudi dve vgrajeni orodji, ki jih model lahko prepozna kot potrebna glede na uporabniški poziv. Ta orodja sta:\n",
    "\n",
    "- **Brave Search** – Uporablja se lahko za pridobivanje najnovejših informacij, kot je vreme, z iskanjem po spletu\n",
    "- **Wolfram Alpha** – Uporablja se lahko za bolj zapletene matematične izračune, tako da ni treba pisati lastnih funkcij.\n",
    "\n",
    "Lahko pa ustvarite tudi svoja orodja, ki jih lahko LLM pokliče.\n",
    "\n",
    "V spodnjem primeru kode:\n",
    "\n",
    "- V sistemskem pozivu določimo razpoložljiva orodja (brave_search, wolfram_alpha).\n",
    "- Pošljemo uporabniški poziv, ki sprašuje po vremenu v določenem mestu.\n",
    "- LLM bo odgovoril s klicem orodja Brave Search, ki bo izgledal takole: `<|python_tag|>brave_search.call(query=\"Stockholm weather\")`\n",
    "\n",
    "*Opomba: Ta primer izvede le klic orodja. Če želite pridobiti rezultate, si morate ustvariti brezplačen račun na strani Brave API in definirati samo funkcijo.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Llama 3.2\n",
    "\n",
    "Kljub temu, da je LLM, ima Llama 3.1 eno omejitev – multimodalnost. To pomeni, da ne zna uporabljati različnih vrst vhodov, kot so slike, kot pozive in podajati odgovore. Ta sposobnost je ena glavnih novosti v Llama 3.2. Med novimi funkcijami so:\n",
    "\n",
    "- Multimodalnost – omogoča ocenjevanje tako besedilnih kot slikovnih pozivov\n",
    "- Različice od majhnih do srednje velikih (11B in 90B) – to omogoča prilagodljive možnosti uporabe,\n",
    "- Samo besedilne različice (1B in 3B) – to omogoča uporabo modela na robnih / mobilnih napravah in zagotavlja nizko zakasnitev\n",
    "\n",
    "Podpora za multimodalnost predstavlja velik korak v svetu odprtokodnih modelov. Spodnji primer kode sprejme tako sliko kot besedilni poziv, da pridobi analizo slike iz Llama 3.2 90B.\n",
    "\n",
    "### Podpora za multimodalnost z Llama 3.2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Učenje se tukaj ne konča, nadaljujte svojo pot\n",
    "\n",
    "Ko zaključite to lekcijo, si oglejte našo [zbirko za učenje generativne umetne inteligence](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) in še naprej nadgrajujte svoje znanje o generativni umetni inteligenci!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Omejitev odgovornosti**:  \nTa dokument je bil preveden z uporabo storitve za strojno prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da se zavedate, da lahko samodejni prevodi vsebujejo napake ali netočnosti. Izvirni dokument v svojem maternem jeziku naj velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-08-25T22:50:01+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "sl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}