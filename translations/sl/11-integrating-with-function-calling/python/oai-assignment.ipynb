{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uvod\n",
    "\n",
    "V tej lekciji bomo obravnavali:\n",
    "- Kaj je klic funkcije in kje ga uporabljamo\n",
    "- Kako ustvariti klic funkcije z OpenAI\n",
    "- Kako vključiti klic funkcije v aplikacijo\n",
    "\n",
    "## Cilji učenja\n",
    "\n",
    "Po zaključku te lekcije boste znali in razumeli:\n",
    "\n",
    "- Namen uporabe klica funkcije\n",
    "- Nastavitev klica funkcije z uporabo storitve OpenAI\n",
    "- Oblikovanje učinkovitih klicev funkcij za potrebe vaše aplikacije\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Razumevanje klicev funkcij\n",
    "\n",
    "V tej lekciji želimo razviti funkcijo za naš izobraževalni startup, ki uporabnikom omogoča, da s pomočjo klepetalnega robota poiščejo tehnične tečaje. Priporočili bomo tečaje, ki ustrezajo njihovi ravni znanja, trenutni vlogi in tehnologiji, ki jih zanima.\n",
    "\n",
    "Za izvedbo bomo uporabili kombinacijo:\n",
    " - `OpenAI` za ustvarjanje klepetalne izkušnje za uporabnika\n",
    " - `Microsoft Learn Catalog API` za pomoč uporabnikom pri iskanju tečajev glede na njihove zahteve\n",
    " - `Function Calling` za sprejem uporabniškega vprašanja in pošiljanje funkciji, ki izvede zahtevo na API.\n",
    "\n",
    "Za začetek si poglejmo, zakaj sploh želimo uporabiti klic funkcije:\n",
    "\n",
    "print(\"Sporočila v naslednji zahtevi:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # pridobimo nov odgovor od GPT, kjer lahko vidi odgovor funkcije\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zakaj klicanje funkcij\n",
    "\n",
    "Če ste opravili katero koli drugo lekcijo v tem tečaju, verjetno že razumete, kako zmogljivi so veliki jezikovni modeli (LLM). Upamo, da ste opazili tudi nekatere njihove omejitve.\n",
    "\n",
    "Klicanje funkcij je funkcionalnost storitve OpenAI, ki je namenjena reševanju naslednjih izzivov:\n",
    "\n",
    "Nedosledno oblikovanje odgovorov:\n",
    "- Pred uvedbo klicanja funkcij so bili odgovori velikih jezikovnih modelov neurejeni in nedosledni. Razvijalci so morali pisati zapleteno kodo za preverjanje, da so lahko obravnavali vsako variacijo izhoda.\n",
    "\n",
    "Omejena povezava z zunanjimi podatki:\n",
    "- Pred to funkcijo je bilo težko vključiti podatke iz drugih delov aplikacije v kontekst pogovora.\n",
    "\n",
    "S standardizacijo oblikovanja odgovorov in enostavno povezavo z zunanjimi podatki klicanje funkcij poenostavi razvoj in zmanjša potrebo po dodatni logiki za preverjanje.\n",
    "\n",
    "Uporabniki niso mogli dobiti odgovorov, kot je \"Kakšno je trenutno vreme v Stockholmu?\". To je zato, ker so bili modeli omejeni na čas, ko so bili podatki naučeni.\n",
    "\n",
    "Poglejmo si spodnji primer, ki ponazarja to težavo:\n",
    "\n",
    "Recimo, da želimo ustvariti bazo podatkov o študentih, da bi jim lahko predlagali ustrezen tečaj. Spodaj sta dva opisa študentov, ki sta si po podatkih zelo podobna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Želimo to poslati LLM-u, da obdela podatke. To lahko kasneje uporabimo v naši aplikaciji, da to pošljemo API-ju ali shranimo v bazo podatkov.\n",
    "\n",
    "Ustvarimo dva enaka poziva, s katerima LLM-u natančno povemo, katere informacije nas zanimajo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Želimo to poslati LLM-ju, da razčleni dele, ki so pomembni za naš izdelek. Tako lahko ustvarimo dva enaka poziva za navodila LLM-ju:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po ustvarjanju teh dveh pozivov jih bomo poslali LLM z uporabo `openai.ChatCompletion`. Poziv shranimo v spremenljivko `messages` in vlogi dodelimo `user`. To je zato, da posnemamo sporočilo uporabnika, ki je napisano klepetalnemu robotu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj lahko pošljemo obe zahtevi LLM-ju in preučimo odziv, ki ga prejmemo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Čeprav so pozivi enaki in so opisi podobni, lahko dobimo različne formate lastnosti `Grades`.\n",
    "\n",
    "Če zgornjo celico zaženete večkrat, je lahko format `3.7` ali `3.7 GPA`.\n",
    "\n",
    "To se zgodi zato, ker LLM prejme neorganizirane podatke v obliki napisanega poziva in prav tako vrne neorganizirane podatke. Potrebujemo strukturiran format, da vemo, kaj pričakovati pri shranjevanju ali uporabi teh podatkov.\n",
    "\n",
    "Z uporabo funkcijskega klicanja lahko zagotovimo, da prejmemo nazaj strukturirane podatke. Pri uporabi funkcijskega klicanja LLM dejansko ne kliče ali izvaja nobenih funkcij. Namesto tega ustvarimo strukturo, ki ji LLM sledi pri svojih odgovorih. Te strukturirane odgovore nato uporabimo, da vemo, katero funkcijo naj zaženemo v naših aplikacijah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram poteka klicanja funkcije](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.sl.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeri uporabe klicev funkcij\n",
    "\n",
    "**Klicanje zunanjih orodij**  \n",
    "Klepetalni roboti so odlični pri odgovarjanju na vprašanja uporabnikov. S pomočjo klicev funkcij lahko klepetalni roboti uporabijo sporočila uporabnikov za opravljanje določenih nalog. Na primer, študent lahko klepetalnega robota prosi: \"Pošlji e-pošto mojemu profesorju in mu sporoči, da potrebujem več pomoči pri tej temi.\" To lahko sproži klic funkcije `send_email(to: string, body: string)`\n",
    "\n",
    "**Ustvarjanje API ali podatkovnih poizvedb**  \n",
    "Uporabniki lahko poiščejo informacije z uporabo naravnega jezika, ki se nato pretvori v ustrezno poizvedbo ali API zahtevo. Primer tega je učitelj, ki vpraša: \"Kateri študenti so oddali zadnjo nalogo?\" in s tem sproži funkcijo z imenom `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Ustvarjanje strukturiranih podatkov**  \n",
    "Uporabniki lahko vzamejo besedilo ali CSV in uporabijo LLM za izluščitev pomembnih informacij. Na primer, študent lahko pretvori članek iz Wikipedije o mirovnih sporazumih v AI učne kartice. To lahko stori s funkcijo `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ustvarjanje vašega prvega klica funkcije\n",
    "\n",
    "Postopek ustvarjanja klica funkcije vključuje 3 glavne korake:\n",
    "1. Klicanje Chat Completions API s seznamom vaših funkcij in sporočilom uporabnika\n",
    "2. Preberite odgovor modela, da izvedete dejanje, npr. izvedete funkcijo ali API klic\n",
    "3. Ponovno pokličite Chat Completions API z odgovorom vaše funkcije, da uporabite te informacije za ustvarjanje odgovora uporabniku.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Potek klica funkcije](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.sl.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementi klica funkcije\n",
    "\n",
    "#### Uporabnikov vnos\n",
    "\n",
    "Prvi korak je ustvariti sporočilo uporabnika. To lahko dinamično določite z vrednostjo iz besedilnega vnosa ali pa vrednost določite tukaj. Če prvič uporabljate API Chat Completions, moramo določiti `role` in `content` sporočila.\n",
    "\n",
    "`role` je lahko `system` (določanje pravil), `assistant` (model) ali `user` (končni uporabnik). Za klic funkcije bomo to nastavili kot `user` in dodali primer vprašanja.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ustvarjanje funkcij.\n",
    "\n",
    "Nato bomo definirali funkcijo in njene parametre. Tukaj bomo uporabili samo eno funkcijo z imenom `search_courses`, lahko pa ustvarite več funkcij.\n",
    "\n",
    "**Pomembno** : Funkcije so vključene v sistemsko sporočilo za LLM in bodo štele v skupno število razpoložljivih žetonov, ki jih imate na voljo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definicije**\n",
    "\n",
    "Struktura definicije funkcije ima več nivojev, vsak s svojimi lastnostmi. Tukaj je razčlenitev gnezdene strukture:\n",
    "\n",
    "**Lastnosti funkcije na najvišji ravni:**\n",
    "\n",
    "`name` - Ime funkcije, ki jo želimo poklicati.\n",
    "\n",
    "`description` - Opis, kako funkcija deluje. Tukaj je pomembno, da ste natančni in jasni.\n",
    "\n",
    "`parameters` - Seznam vrednosti in format, ki jih želite, da jih model ustvari v svojem odgovoru.\n",
    "\n",
    "**Lastnosti objekta Parameters:**\n",
    "\n",
    "`type` - Podatkovni tip objekta parameters (običajno \"object\")\n",
    "\n",
    "`properties` - Seznam specifičnih vrednosti, ki jih bo model uporabil za svoj odgovor\n",
    "\n",
    "**Lastnosti posameznega parametra:**\n",
    "\n",
    "`name` - Posredno določeno s ključem lastnosti (npr. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Podatkovni tip tega določenega parametra (npr. \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Opis določenega parametra\n",
    "\n",
    "**Neobvezne lastnosti:**\n",
    "\n",
    "`required` - Polje, ki navaja, kateri parametri so obvezni, da se klic funkcije lahko izvede\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klic funkcije\n",
    "Ko smo definirali funkcijo, jo moramo zdaj vključiti v klic Chat Completion API-ja. To naredimo tako, da v zahtevo dodamo `functions`. V tem primeru `functions=functions`.\n",
    "\n",
    "Obstaja tudi možnost, da nastavite `function_call` na `auto`. To pomeni, da bomo LLM-ju prepustili odločitev, katero funkcijo naj pokliče glede na uporabnikovo sporočilo, namesto da bi to določili sami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj si oglejmo odgovor in preverimo, kako je oblikovan:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Vidite lahko, da je ime funkcije poklicano in da je LLM iz uporabnikovega sporočila uspel najti podatke, ki ustrezajo argumentom funkcije.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integracija klicev funkcij v aplikacijo.\n",
    "\n",
    "Ko smo preizkusili formatiran odgovor iz LLM, ga lahko zdaj vključimo v aplikacijo.\n",
    "\n",
    "### Upravljanje poteka\n",
    "\n",
    "Da to vključimo v našo aplikacijo, sledimo naslednjim korakom:\n",
    "\n",
    "Najprej izvedemo klic do OpenAI storitev in shranimo sporočilo v spremenljivko z imenom `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj bomo definirali funkcijo, ki bo poklicala Microsoft Learn API za pridobitev seznama tečajev:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kot dobra praksa bomo najprej preverili, ali želi model poklicati funkcijo. Nato bomo ustvarili eno izmed razpoložljivih funkcij in jo povezali s funkcijo, ki je bila poklicana.\n",
    "Nato bomo argumente funkcije preslikali na argumente iz LLM.\n",
    "\n",
    "Na koncu bomo sporočilu o klicu funkcije dodali še vrednosti, ki jih je vrnilo sporočilo `search_courses`. To LLM-ju zagotovi vse potrebne informacije,\n",
    "da lahko uporabniku odgovori v naravnem jeziku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izziv s kodo\n",
    "\n",
    "Odlično opravljeno! Če želite nadaljevati z učenjem o OpenAI Function Calling, lahko ustvarite: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Več parametrov funkcije, ki lahko pomagajo uporabnikom najti več tečajev. Razpoložljive parametre API-ja najdete tukaj:\n",
    " - Ustvarite še en klic funkcije, ki upošteva več informacij o uporabniku, na primer njegov materni jezik\n",
    " - Dodajte obravnavo napak, kadar klic funkcije in/ali API-ja ne vrne nobenega ustreznega tečaja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Omejitev odgovornosti**:  \nTa dokument je bil preveden z uporabo storitve za strojno prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da se zavedate, da lahko samodejni prevodi vsebujejo napake ali netočnosti. Izvirni dokument v svojem izvirnem jeziku naj velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazume ali napačne razlage, ki bi nastale zaradi uporabe tega prevoda.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:24:02+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "sl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}