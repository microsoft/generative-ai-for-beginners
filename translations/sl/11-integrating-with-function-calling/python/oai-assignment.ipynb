{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uvod\n",
    "\n",
    "Ta lekcija bo zajemala:\n",
    "- Kaj je klic funkcije in njene uporabe\n",
    "- Kako ustvariti klic funkcije z uporabo OpenAI\n",
    "- Kako integrirati klic funkcije v aplikacijo\n",
    "\n",
    "## Cilji učenja\n",
    "\n",
    "Po zaključku te lekcije boste znali in razumeli:\n",
    "\n",
    "- Namen uporabe klica funkcije\n",
    "- Nastavitev klica funkcije z uporabo OpenAI storitve\n",
    "- Oblikovanje učinkovitih klicev funkcij za uporabo v vaši aplikaciji\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Razumevanje klicev funkcij\n",
    "\n",
    "Za to lekcijo želimo zgraditi funkcijo za naš izobraževalni startup, ki uporabnikom omogoča uporabo klepetalnega robota za iskanje tehničnih tečajev. Priporočali bomo tečaje, ki ustrezajo njihovi ravni znanja, trenutni vlogi in tehnologiji, ki jih zanima.\n",
    "\n",
    "Za dokončanje bomo uporabili kombinacijo:\n",
    " - `OpenAI` za ustvarjanje klepetalnega doživetja za uporabnika\n",
    " - `Microsoft Learn Catalog API` za pomoč uporabnikom pri iskanju tečajev na podlagi njihove zahteve\n",
    " - `Function Calling` za prevzem uporabnikovega poizvedbe in pošiljanje funkciji za izvedbo API zahteve.\n",
    "\n",
    "Za začetek si poglejmo, zakaj bi sploh želeli uporabiti klic funkcije:\n",
    "\n",
    "print(\"Sporočila v naslednjem zahtevku:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # pridobi nov odgovor od GPT, kjer lahko vidi odgovor funkcije\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zakaj klic funkcij\n",
    "\n",
    "Če ste opravili katero koli drugo lekcijo v tem tečaju, verjetno razumete moč uporabe velikih jezikovnih modelov (LLM). Upamo, da lahko vidite tudi nekatere njihove omejitve.\n",
    "\n",
    "Klic funkcij je funkcija storitve OpenAI, zasnovana za reševanje naslednjih izzivov:\n",
    "\n",
    "Nekonsistentno oblikovanje odgovorov:\n",
    "- Pred uvedbo klica funkcij so bili odgovori velikega jezikovnega modela nestrukturirani in nekonsistentni. Razvijalci so morali pisati zapleteno kodo za preverjanje, da so obravnavali vsako različico izhoda.\n",
    "\n",
    "Omejena integracija z zunanjimi podatki:\n",
    "- Pred to funkcijo je bilo težko vključiti podatke iz drugih delov aplikacije v kontekst klepeta.\n",
    "\n",
    "S standardizacijo oblik odgovorov in omogočanjem nemotene integracije z zunanjimi podatki klic funkcij poenostavi razvoj in zmanjša potrebo po dodatni logiki preverjanja.\n",
    "\n",
    "Uporabniki niso mogli dobiti odgovorov, kot je \"Kakšno je trenutno vreme v Stockholmu?\". To je zato, ker so bili modeli omejeni na čas, ko so bili podatki usposobljeni.\n",
    "\n",
    "Poglejmo spodnji primer, ki ponazarja ta problem:\n",
    "\n",
    "Recimo, da želimo ustvariti bazo podatkov o študentih, da jim lahko predlagamo pravi tečaj. Spodaj imamo dva opisa študentov, ki sta zelo podobna v podatkih, ki jih vsebujeta.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Želimo to poslati LLM-ju, da obdela podatke. To lahko kasneje uporabimo v naši aplikaciji za pošiljanje na API ali shranjevanje v podatkovno bazo.\n",
    "\n",
    "Ustvarimo dva enaka poziva, v katerih LLM-ju naročimo, katere informacije nas zanimajo:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Želimo to poslati LLM-ju, da razčleni dele, ki so pomembni za naš izdelek. Tako lahko ustvarimo dva enaka poziva za usmerjanje LLM-ja:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po ustvarjanju teh dveh pozivov jih bomo poslali LLM z uporabo `openai.ChatCompletion`. Poziv shranimo v spremenljivko `messages` in dodelimo vlogo `user`. To je, da posnemamo sporočilo uporabnika, ki ga piše chatbotu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj lahko pošljemo oba zahtevka LLM-ju in pregledamo odgovor, ki ga prejmemo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Čeprav so pozivi enaki in so opisi podobni, lahko dobimo različne formate lastnosti `Grades`.\n",
    "\n",
    "Če zgornjo celico zaženete večkrat, je lahko format `3.7` ali `3.7 GPA`.\n",
    "\n",
    "To je zato, ker LLM vzame nestrukturirane podatke v obliki napisanega poziva in vrne tudi nestrukturirane podatke. Potrebujemo strukturiran format, da vemo, kaj pričakovati pri shranjevanju ali uporabi teh podatkov.\n",
    "\n",
    "Z uporabo funkcijskega klica lahko zagotovimo, da prejmemo nazaj strukturirane podatke. Pri uporabi funkcijskega klica LLM dejansko ne kliče ali izvaja nobenih funkcij. Namesto tega ustvarimo strukturo, ki jo LLM sledi za svoje odgovore. Nato te strukturirane odgovore uporabimo, da vemo, katero funkcijo naj zaženemo v naših aplikacijah.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram poteka klica funkcije](../../../../translated_images/sl/Function-Flow.083875364af4f4bb.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nato lahko vzamemo, kar funkcija vrne, in to pošljemo nazaj LLM-ju. LLM bo nato odgovoril z uporabo naravnega jezika, da odgovori na uporabnikovo vprašanje.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Primeri uporabe klicev funkcij\n",
    "\n",
    "**Klicanje zunanjih orodij**  \n",
    "Chatboti so odlični pri zagotavljanju odgovorov na vprašanja uporabnikov. Z uporabo klicev funkcij lahko chatboti uporabijo sporočila uporabnikov za izvedbo določenih nalog. Na primer, študent lahko prosi chatbota: \"Pošlji e-pošto mojemu inštruktorju, da potrebujem več pomoči pri tem predmetu\". To lahko sproži klic funkcije `send_email(to: string, body: string)`.\n",
    "\n",
    "**Ustvarjanje API ali poizvedb v bazi podatkov**  \n",
    "Uporabniki lahko najdejo informacije z uporabo naravnega jezika, ki se pretvori v oblikovano poizvedbo ali API zahtevo. Primer tega je učitelj, ki vpraša: \"Kdo so študenti, ki so opravili zadnjo nalogo\", kar lahko sproži klic funkcije z imenom `get_completed(student_name: string, assignment: int, current_status: string)`.\n",
    "\n",
    "**Ustvarjanje strukturiranih podatkov**  \n",
    "Uporabniki lahko vzamejo blok besedila ali CSV in uporabijo LLM za izvleček pomembnih informacij iz njega. Na primer, študent lahko pretvori Wikipedijin članek o mirovnih sporazumih v AI kartice za učenje. To se lahko izvede z uporabo funkcije `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ustvarjanje vašega prvega klica funkcije\n",
    "\n",
    "Postopek ustvarjanja klica funkcije vključuje 3 glavne korake:  \n",
    "1. Klic API-ja Chat Completions z seznamom vaših funkcij in uporabniškim sporočilom  \n",
    "2. Branje odziva modela za izvedbo dejanja, npr. izvedbo funkcije ali klica API-ja  \n",
    "3. Izvedba še enega klica API-ja Chat Completions z odzivom vaše funkcije, da uporabite te informacije za ustvarjanje odgovora uporabniku.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Potek klica funkcije](../../../../translated_images/sl/LLM-Flow.3285ed8caf4796d7.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementi klica funkcije \n",
    "\n",
    "#### Vnos uporabnika \n",
    "\n",
    "Prvi korak je ustvariti uporabniško sporočilo. To je mogoče dinamično dodeliti z vrednostjo besedilnega vnosa ali pa lahko tukaj dodelite vrednost. Če je to vaš prvič, da delate z API-jem za Chat Completions, moramo definirati `role` in `content` sporočila. \n",
    "\n",
    "`role` je lahko bodisi `system` (ustvarjanje pravil), `assistant` (model) ali `user` (končni uporabnik). Za klic funkcije bomo to dodelili kot `user` in primer vprašanja. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ustvarjanje funkcij.\n",
    "\n",
    "Nato bomo definirali funkcijo in parametre te funkcije. Tukaj bomo uporabili samo eno funkcijo, imenovano `search_courses`, vendar lahko ustvarite več funkcij.\n",
    "\n",
    "**Pomembno** : Funkcije so vključene v sistemsko sporočilo za LLM in bodo vključene v količino razpoložljivih žetonov, ki jih imate na voljo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definicije** \n",
    "\n",
    "Struktura definicije funkcije ima več nivojev, vsak s svojimi lastnostmi. Tukaj je razčlenitev gnezdene strukture:\n",
    "\n",
    "**Lastnosti funkcije na najvišji ravni:**\n",
    "\n",
    "`name` - Ime funkcije, ki jo želimo poklicati. \n",
    "\n",
    "`description` - To je opis, kako funkcija deluje. Pomembno je, da je tukaj specifičen in jasen. \n",
    "\n",
    "`parameters` - Seznam vrednosti in formata, ki jih želite, da model ustvari v svojem odgovoru. \n",
    "\n",
    "**Lastnosti objekta parametrov:**\n",
    "\n",
    "`type` - Podatkovni tip objekta parametrov (običajno \"object\")\n",
    "\n",
    "`properties` - Seznam specifičnih vrednosti, ki jih bo model uporabil za svoj odgovor. \n",
    "\n",
    "**Lastnosti posameznega parametra:**\n",
    "\n",
    "`name` - Implicitno določen s ključem lastnosti (npr. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Podatkovni tip tega specifičnega parametra (npr. \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Opis specifičnega parametra. \n",
    "\n",
    "**Neobvezne lastnosti:**\n",
    "\n",
    "`required` - Polje, ki navaja, kateri parametri so potrebni za uspešno izvedbo klica funkcije. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Klic funkcije  \n",
    "Po definiranju funkcije jo moramo zdaj vključiti v klic API-ja za Chat Completion. To naredimo tako, da v zahtevo dodamo `functions`. V tem primeru `functions=functions`.  \n",
    "\n",
    "Obstaja tudi možnost nastavitve `function_call` na `auto`. To pomeni, da bomo pustili LLM, da odloči, katera funkcija naj bo poklicana na podlagi uporabnikovega sporočila, namesto da bi jo določili sami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj si poglejmo odgovor in kako je oblikovan:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Lahko vidite, da je ime funkcije poklicano in iz uporabnikovega sporočila je LLM uspel najti podatke, ki ustrezajo argumentom funkcije.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integracija klicev funkcij v aplikacijo. \n",
    "\n",
    "\n",
    "Ko smo preizkusili oblikovan odgovor iz LLM, ga lahko zdaj integriramo v aplikacijo. \n",
    "\n",
    "### Upravljanje poteka \n",
    "\n",
    "Za integracijo tega v našo aplikacijo naredimo naslednje korake: \n",
    "\n",
    "Najprej izvedimo klic na OpenAI storitve in sporočilo shranimo v spremenljivko z imenom `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj bomo definirali funkcijo, ki bo poklicala Microsoft Learn API za pridobitev seznama tečajev:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kot najboljšo prakso bomo nato preverili, ali model želi poklicati funkcijo. Po tem bomo ustvarili eno od razpoložljivih funkcij in jo ujemali s funkcijo, ki se kliče.  \n",
    "Nato bomo vzeli argumente funkcije in jih preslikali na argumente iz LLM.\n",
    "\n",
    "Na koncu bomo dodali sporočilo o klicu funkcije in vrednosti, ki jih je vrnilo sporočilo `search_courses`. To LLM-ju zagotovi vse informacije, ki jih potrebuje za \n",
    "odziv uporabniku v naravnem jeziku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zdaj bomo poslali posodobljeno sporočilo LLM, da bomo prejeli odgovor v naravnem jeziku namesto odgovora v obliki JSON API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Izziv s kodo\n",
    "\n",
    "Odlično delo! Za nadaljevanje učenja o klicanju funkcij OpenAI lahko ustvarite: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Več parametrov funkcije, ki lahko pomagajo učencem najti več tečajev. Na voljo API parametre lahko najdete tukaj:  \n",
    " - Ustvarite še en klic funkcije, ki od učenca zahteva več informacij, na primer njihov materni jezik  \n",
    " - Ustvarite obravnavo napak, ko klic funkcije in/ali klic API ne vrne nobenih ustreznih tečajev  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Omejitev odgovornosti**:\nTa dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas opozarjamo, da avtomatizirani prevodi lahko vsebujejo napake ali netočnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Za morebitna nesporazume ali napačne interpretacije, ki izhajajo iz uporabe tega prevoda, ne odgovarjamo.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T11:49:33+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "sl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}