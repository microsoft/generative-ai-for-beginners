<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T16:29:33+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "sl"
}
-->
# Osnove naÄrtovanja pozivov

## Uvod
Ta modul zajema osnovne koncepte in tehnike za ustvarjanje uÄinkovitih pozivov v generativnih AI modelih. NaÄin, kako napiÅ¡ete svoj poziv LLM, je pomemben. Skrbno oblikovan poziv lahko doseÅ¾e boljÅ¡o kakovost odgovora. Kaj pa pravzaprav pomenijo izrazi, kot sta _poziv_ in _naÄrtovanje pozivov_? In kako izboljÅ¡am poziv _vnos_, ki ga poÅ¡ljem LLM? To so vpraÅ¡anja, na katera bomo poskuÅ¡ali odgovoriti v tem poglavju in naslednjem.

_Generativna AI_ je sposobna ustvariti novo vsebino (npr. besedilo, slike, zvok, kodo itd.) kot odziv na zahteve uporabnikov. To dosega z uporabo _Velikih jezikovnih modelov_ kot je serija OpenAI GPT ("Generativni predhodno usposobljeni transformator"), ki so usposobljeni za uporabo naravnega jezika in kode.

Uporabniki lahko zdaj komunicirajo s temi modeli s pomoÄjo znanih paradigmov, kot je klepet, brez potrebe po tehniÄnem znanju ali usposabljanju. Modeli so _na osnovi pozivov_ - uporabniki poÅ¡ljejo besedilni vnos (poziv) in prejmejo AI odgovor (dokonÄanje). Nato lahko "klepetajo z AI" iterativno, v veÄ zavojih pogovorov, izpopolnjujejo svoj poziv, dokler odgovor ne ustreza njihovim priÄakovanjem.

"Pozivi" zdaj postanejo primarni _programski vmesnik_ za generativne AI aplikacije, ki modelom povedo, kaj naj storijo in vplivajo na kakovost vrnjenih odgovorov. "NaÄrtovanje pozivov" je hitro rastoÄe podroÄje Å¡tudija, ki se osredotoÄa na _oblikovanje in optimizacijo_ pozivov za zagotavljanje doslednih in kakovostnih odgovorov v velikem obsegu.

## Cilji uÄenja

V tej lekciji se nauÄimo, kaj je naÄrtovanje pozivov, zakaj je pomembno, in kako lahko oblikujemo bolj uÄinkovite pozive za doloÄen model in cilj aplikacije. Razumeli bomo osnovne koncepte in najboljÅ¡e prakse za naÄrtovanje pozivov - ter se seznanili z interaktivnim okoljem "sandbox" v Jupyter Notebooks, kjer lahko te koncepte vidimo v resniÄnih primerih.

Do konca te lekcije bomo sposobni:

1. Pojasniti, kaj je naÄrtovanje pozivov in zakaj je pomembno.
2. Opisati komponente poziva in kako se uporabljajo.
3. NauÄiti se najboljÅ¡ih praks in tehnik za naÄrtovanje pozivov.
4. Uporabiti nauÄene tehnike na resniÄnih primerih, z uporabo OpenAI endpointa.

## KljuÄni izrazi

NaÄrtovanje pozivov: Praksa oblikovanja in izpopolnjevanja vnosov za usmerjanje AI modelov k ustvarjanju Å¾elenih rezultatov.
Tokenizacija: Proces pretvorbe besedila v manjÅ¡e enote, imenovane tokeni, ki jih model lahko razume in obdela.
LLM-ji uglaÅ¡eni z navodili: Veliki jezikovni modeli (LLM-ji), ki so bili fino uglaÅ¡eni s specifiÄnimi navodili za izboljÅ¡anje natanÄnosti in ustreznosti njihovih odgovorov.

## Sandbox za uÄenje

NaÄrtovanje pozivov je trenutno bolj umetnost kot znanost. NajboljÅ¡i naÄin za izboljÅ¡anje naÅ¡e intuicije za to je, da _veÄ vadimo_ in sprejmemo pristop poskusov in napak, ki zdruÅ¾uje strokovno znanje na podroÄju aplikacij z priporoÄljivimi tehnikami in modelno specifiÄnimi optimizacijami.

Jupyter Notebook, ki spremlja to lekcijo, zagotavlja _sandbox_ okolje, kjer lahko preizkusite, kar se nauÄite - med uÄenjem ali kot del kode izziva na koncu. Za izvedbo vaj boste potrebovali:

1. **Azure OpenAI API kljuÄ** - storitveni endpoint za uveden LLM.
2. **Python Runtime** - v katerem se lahko izvede Notebook.
3. **Lokalne okoljske spremenljivke** - _izpolnite korake [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst), da se pripravite_.

Notebook vsebuje _zaÄetne_ vaje - vendar ste spodbujeni, da dodate svoje _Markdown_ (opis) in _Code_ (zahteve za poziv) sekcije, da preizkusite veÄ primerov ali idej - in zgradite svojo intuicijo za oblikovanje pozivov.

## Ilustrirani vodnik

Å½elite dobiti celotno sliko o tem, kaj ta lekcija zajema, preden se potopite vanjo? Oglejte si ta ilustrirani vodnik, ki vam daje obÄutek glavnih tem, ki jih zajema, in kljuÄne zakljuÄke, o katerih lahko razmislite v vsakem od njih. NaÄrt lekcije vas vodi od razumevanja osnovnih konceptov in izzivov do njihovega naslavljanja z ustreznimi tehnikami naÄrtovanja pozivov in najboljÅ¡imi praksami. UpoÅ¡tevajte, da se oddelek "Napredne tehnike" v tem vodniku nanaÅ¡a na vsebino, zajeto v _naslednjem_ poglavju tega kurikuluma.

## NaÅ¡ startup

Zdaj pa se pogovorimo o tem, kako _ta tema_ se nanaÅ¡a na naÅ¡o startup misijo [prinaÅ¡anja AI inovacij v izobraÅ¾evanje](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Å½elimo zgraditi AI-poganjane aplikacije za _personalizirano uÄenje_ - zato razmislimo, kako razliÄni uporabniki naÅ¡e aplikacije lahko "oblikujejo" pozive:

- **Administratorji** bi lahko prosili AI, da _analizira podatke o kurikulu, da identificira vrzeli v pokritosti_. AI lahko povzame rezultate ali jih vizualizira s kodo.
- **IzobraÅ¾evalci** bi lahko prosili AI, da _ustvari naÄrt lekcije za ciljno obÄinstvo in temo_. AI lahko zgradi personaliziran naÄrt v doloÄenem formatu.
- **Å tudenti** bi lahko prosili AI, da _jih pouÄuje v teÅ¾ki temi_. AI lahko zdaj vodi Å¡tudente z lekcijami, namigi in primeri, prilagojenimi njihovi ravni.

To je le vrh ledene gore. Oglejte si [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - odprtokodno knjiÅ¾nico pozivov, ki jo kurirajo izobraÅ¾evalni strokovnjaki - da dobite Å¡irÅ¡i obÄutek moÅ¾nosti! _Preizkusite nekaj teh pozivov v sandboxu ali z uporabo OpenAI Playground, da vidite, kaj se zgodi!_

## Kaj je naÄrtovanje pozivov?

To lekcijo smo zaÄeli z definiranjem **naÄrtovanja pozivov** kot procesa _oblikovanja in optimizacije_ besedilnih vnosov (pozivov) za zagotavljanje doslednih in kakovostnih odgovorov (dokonÄanj) za doloÄen cilj aplikacije in model. To lahko mislimo kot 2-stopenjski proces:

- _oblikovanje_ zaÄetnega poziva za doloÄen model in cilj
- _izpopolnjevanje_ poziva iterativno za izboljÅ¡anje kakovosti odgovora

To je nujno proces poskusov in napak, ki zahteva intuicijo uporabnika in trud za dosego optimalnih rezultatov. Zakaj je to pomembno? Da odgovorimo na to vpraÅ¡anje, moramo najprej razumeti tri koncepte:

- _Tokenizacija_ = kako model "vidi" poziv
- _Osnovni LLM-ji_ = kako temeljni model "procesira" poziv
- _LLM-ji uglaÅ¡eni z navodili_ = kako model lahko zdaj vidi "naloge"

### Tokenizacija

LLM vidi pozive kot _zaporedje tokenov_, kjer lahko razliÄni modeli (ali razliÄice modela) tokenizirajo isti poziv na razliÄne naÄine. Ker so LLM-ji usposobljeni na tokenih (in ne na surovem besedilu), naÄin, kako se pozivi tokenizirajo, neposredno vpliva na kakovost generiranega odgovora.

Da dobite intuicijo, kako tokenizacija deluje, preizkusite orodja, kot je [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst), prikazano spodaj. Kopirajte svoj poziv - in si oglejte, kako se pretvori v tokene, pri Äemer bodite pozorni, kako se obravnavajo znaki praznega prostora in loÄila. UpoÅ¡tevajte, da ta primer prikazuje starejÅ¡i LLM (GPT-3) - zato lahko poskus s novejÅ¡im modelom povzroÄi drugaÄen rezultat.

### Koncept: Temeljni modeli

Ko je poziv tokeniziran, je primarna funkcija ["Osnovnega LLM-ja"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ali temeljnega modela) napovedovanje tokena v tem zaporedju. Ker so LLM-ji usposobljeni na ogromnih besedilnih zbirkah podatkov, imajo dober obÄutek za statistiÄne odnose med tokeni in lahko to napoved naredijo z doloÄeno stopnjo zaupanja. UpoÅ¡tevajte, da ne razumejo _pomena_ besed v pozivu ali tokenu; vidijo le vzorec, ki ga lahko "dokonÄajo" z naslednjo napovedjo. Lahko nadaljujejo napovedovanje zaporedja, dokler ga ne prekine uporabniÅ¡ki poseg ali neka predhodno doloÄena pogoj.

Å½elite videti, kako deluje dokonÄanje na osnovi pozivov? Vnesite zgornji poziv v Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) z privzetimi nastavitvami. Sistem je konfiguriran tako, da obravnava pozive kot zahteve za informacije - zato bi morali videti dokonÄanje, ki ustreza temu kontekstu.

Kaj pa, Äe bi uporabnik Å¾elel videti nekaj specifiÄnega, kar ustreza nekaterim merilom ali ciljem naloge? Tukaj pridejo v poÅ¡tev _LLM-ji uglaÅ¡eni z navodili_.

### Koncept: LLM-ji uglaÅ¡eni z navodili

[LLM uglaÅ¡en z navodili](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zaÄne s temeljnim modelom in ga fino uglaÅ¡uje z zgledi ali pari vhod/izhod (npr. veÄzavojnimi "sporoÄili"), ki lahko vsebujejo jasna navodila - in odgovor AI poskuÅ¡a slediti tem navodilom.

To uporablja tehnike, kot je krepitev uÄenja s povratnimi informacijami uporabnikov (RLHF), ki lahko model usposobi za _sledenje navodilom_ in _uÄenje iz povratnih informacij_, tako da ustvarja odgovore, ki so bolj primerni za praktiÄne aplikacije in bolj relevantni za cilje uporabnikov.

Poskusimo - ponovno preglejte zgornji poziv, vendar zdaj spremenite _sistemsko sporoÄilo_, da zagotovite naslednje navodilo kot kontekst:

> _Povzemite vsebino, ki vam je dana, za uÄenca drugega razreda. Rezultat naj bo en odstavek s 3-5 toÄkami._

Vidite, kako je rezultat zdaj uglaÅ¡en, da odraÅ¾a Å¾eleni cilj in format? IzobraÅ¾evalec lahko zdaj neposredno uporabi ta odgovor v svojih diapozitivih za to razred.

## Zakaj potrebujemo naÄrtovanje pozivov?

Zdaj, ko vemo, kako pozive obdelujejo LLM-ji, se pogovorimo o _zakaj_ potrebujemo naÄrtovanje pozivov. Odgovor leÅ¾i v dejstvu, da trenutni LLM-ji postavljajo Å¡tevilne izzive, zaradi katerih je _zanesljivo in dosledno dokonÄanje_ teÅ¾je doseÄi brez truda pri konstrukciji in optimizaciji pozivov. Na primer:

1. **Odgovori modela so stohastiÄni.** _Isti poziv_ bo verjetno ustvaril razliÄne odgovore z razliÄnimi modeli ali razliÄicami modela. In lahko celo ustvari razliÄne rezultate z _istim modelom_ ob razliÄnih Äasih. _Tehnike naÄrtovanja pozivov nam lahko pomagajo zmanjÅ¡ati te variacije z zagotavljanjem boljÅ¡ih varoval_.

2. **Modeli lahko izmiÅ¡ljajo odgovore.** Modeli so predhodno usposobljeni z _velikimi, a konÄnimi_ zbirkami podatkov, kar pomeni, da jim primanjkuje znanja o konceptih zunaj tega obsega usposabljanja. PoslediÄno lahko ustvarijo dokonÄanja, ki so netoÄna, izmiÅ¡ljena ali neposredno nasprotujoÄa znanim dejstvom. _Tehnike naÄrtovanja pozivov pomagajo uporabnikom prepoznati in omiliti takÅ¡ne izmiÅ¡ljotine, npr. z zahtevanjem AI za citate ali razloge_.

3. **ZmoÅ¾nosti modelov se bodo razlikovale.** NovejÅ¡i modeli ali generacije modelov bodo imeli bogatejÅ¡e zmoÅ¾nosti, vendar bodo prinesli tudi edinstvene posebnosti in kompromise v stroÅ¡kih in kompleksnosti. _NaÄrtovanje pozivov nam lahko pomaga razviti najboljÅ¡e prakse in delovne tokove, ki abstrahirajo razlike in se prilagajajo specifiÄnim zahtevam modela na skalabilne, brezhibne naÄine_.

Poglejmo to v akciji v OpenAI ali Azure OpenAI Playground:

- Uporabite isti poziv z razliÄnimi LLM uvedbami (npr. OpenAI, Azure OpenAI, Hugging Face) - ste opazili variacije?
- Uporabite isti poziv veÄkrat z _istim_ LLM uvedbo (npr. Azure OpenAI playground) - kako so se te variacije razlikovale?

### Primer izmiÅ¡ljotin

V tem teÄaju uporabljamo izraz **"izmiÅ¡ljotina"** za opis pojava, kjer LLM-ji vÄasih ustvarijo dejansko napaÄne informacije zaradi omejitev v njihovem usposabljanju ali drugih omejitev. Morda ste to sliÅ¡ali tudi kot _"halucinacije"_ v popularnih Älankih ali raziskovalnih prispevkih. Vendar moÄno priporoÄamo uporabo izraza _"izmiÅ¡ljotina"_ kot izraza, da ne bi nenamerno antropomorfizirali vedenja z pripisovanjem ÄloveÅ¡ke lastnosti rezultatu, ki ga poganja stroj. To tudi krepi [smernice za odgovorno AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) z vidika terminologije, odstranjuje izraze, ki bi jih lahko v nekaterih kontekstih obravnavali kot Å¾aljive ali neinkluzivne.

Å½elite dobiti obÄutek, kako izmiÅ¡ljotine delujejo? Pomislite na poziv, ki AI naroÄa, naj ustvari vsebino za neobstojeÄo temo (da se prepriÄate, da ni v usposobitvenem naboru podatkov). Na primer - poskusil sem ta poziv:

> **Poziv:** ustvarite naÄrt lekcije o Marsovski vojni leta 2076.

Spletno iskanje mi je pokazalo, da so obstajali izmiÅ¡ljeni raÄuni (npr. televizijske serije ali knjige) o Marsovskih vojnah - vendar nobena leta 2076. Zdrava pamet nam tudi pove, da je leto 2076 _v prihodnosti_ in zato ne more biti povezano z resniÄnim dogodkom.

Kaj se zgodi, ko zaÅ¾enemo ta poziv z razliÄnimi LLM ponudniki?

> **Odgovor 1**: OpenAI Playground (GPT-35)

> **Odgovor 2**: Azure OpenAI Playground (GPT-35)

> **Odgovor 3**: Hugging Face Chat Playground (LLama-2)

Kot priÄakovano, vsak model (ali razliÄica modela) ustvari nekoliko razliÄne odgovore zaradi stohastiÄnega vedenja in variacij zmoÅ¾nosti modela. Na primer, en model cilja na obÄinstvo 8. razreda, medtem ko drugi predvideva srednjeÅ¡olskega uÄenca. Vendar so vsi trije modeli ustvarili odgovore, ki bi lahko prepriÄali neinformiranega uporabnika, da je dogodek resniÄen.

Tehnike naÄrtovanja pozivov, kot sta _metaprompting_ in _konfiguracija temperature_, lahko do neke mere zmanjÅ¡ajo izmiÅ¡ljotine modelov. Nove arhitekture naÄrtovanja pozivov prav tako vkljuÄujejo nova orodja in tehnike brezhibno v tok poziva, da omilijo ali zmanjÅ¡ajo nekatere od teh uÄinkov.

## Å tudija primera: GitHub Copilot

ZakljuÄimo ta oddelek z obÄutkom, kako se naÄrtovanje pozivov uporablja v resniÄnih reÅ¡itvah, tako da
KonÄno, prava vrednost predlog je v sposobnosti ustvarjanja in objavljanja _knjiÅ¾nic predlog_ za vertikalna podroÄja uporabe - kjer je predloga sedaj _optimizirana_ tako, da odraÅ¾a specifiÄen kontekst ali primere, ki naredijo odgovore bolj relevantne in natanÄne za ciljno obÄinstvo. Repozitorij [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) je odliÄen primer tega pristopa, saj zbira knjiÅ¾nico predlog za izobraÅ¾evalno podroÄje s poudarkom na kljuÄnih ciljih, kot so naÄrtovanje lekcij, oblikovanje kurikuluma, mentorstvo Å¡tudentov itd.

## Podporna vsebina

ÄŒe razmiÅ¡ljamo o konstrukciji predlog kot o navodilu (nalogi) in cilju (primarni vsebini), potem je _sekundarna vsebina_ kot dodatni kontekst, ki ga zagotovimo za **vplivanje na izhod na nek naÄin**. Lahko gre za prilagoditvene parametre, navodila za oblikovanje, taksonomije tem itd., ki lahko pomagajo modelu _prilagoditi_ svoj odgovor, da ustreza Å¾elenim ciljem ali priÄakovanjem uporabnika.

Na primer: Glede na katalog teÄajev z obseÅ¾nimi metapodatki (ime, opis, raven, oznake metapodatkov, inÅ¡truktor itd.) o vseh razpoloÅ¾ljivih teÄajih v kurikulumu:

- lahko definiramo navodilo za "povzetek kataloga teÄajev za jesen 2023"
- lahko uporabimo primarno vsebino, da zagotovimo nekaj primerov Å¾elenega izhoda
- lahko uporabimo sekundarno vsebino, da identificiramo top 5 "oznak" zanimanja.

Sedaj lahko model zagotovi povzetek v formatu, ki ga prikazujejo primeri - vendar Äe rezultat vsebuje veÄ oznak, lahko prioritizira 5 oznak, identificiranih v sekundarni vsebini.

## NajboljÅ¡e prakse pri oblikovanju predlog

Sedaj, ko vemo, kako lahko predloge _konstrukcijsko_, lahko zaÄnemo razmiÅ¡ljati o tem, kako jih _oblikovati_, da odraÅ¾ajo najboljÅ¡e prakse. O tem lahko razmiÅ¡ljamo v dveh delih - imeti pravo _miselnost_ in uporabiti prave _tehnike_.

### Miselnost pri oblikovanju predlog

Oblikovanje predlog je proces poskusov in napak, zato imejte v mislih tri Å¡iroke vodilne dejavnike:

1. **Razumevanje domene je pomembno.** NatanÄnost in relevantnost odgovora sta odvisni od _domene_, v kateri aplikacija ali uporabnik deluje. Uporabite svojo intuicijo in strokovno znanje na podroÄju domene za **nadaljnje prilagajanje tehnik**. Na primer, definirajte _specifiÄne osebnosti domene_ v svojih sistemskih predlogah ali uporabite _specifiÄne predloge domene_ v svojih uporabniÅ¡kih predlogah. Zagotovite sekundarno vsebino, ki odraÅ¾a kontekste specifiÄne za domeno, ali uporabite _namige in primere specifiÄne za domeno_, da usmerite model k znanim vzorcem uporabe.

2. **Razumevanje modela je pomembno.** Vemo, da so modeli po naravi stohastiÄni. Toda implementacije modelov se lahko razlikujejo tudi glede na podatkovne nize, ki jih uporabljajo za usposabljanje (predhodno znanje), sposobnosti, ki jih zagotavljajo (npr. preko API ali SDK) in vrsto vsebine, za katero so optimizirani (npr. koda proti slikam proti besedilu). Razumite prednosti in omejitve modela, ki ga uporabljate, in uporabite to znanje za _prioritizacijo nalog_ ali gradnjo _prilagojenih predlog_, ki so optimizirane za sposobnosti modela.

3. **Iteracija in validacija sta pomembni.** Modeli se hitro razvijajo, prav tako tudi tehnike za oblikovanje predlog. Kot strokovnjak na podroÄju domene lahko imate drug kontekst ali merila za _vaÅ¡o_ specifiÄno aplikacijo, ki morda ne veljajo za Å¡irÅ¡o skupnost. Uporabite orodja in tehnike za oblikovanje predlog, da "zaÄnete" konstrukcijo predlog, nato iterirajte in validirajte rezultate z uporabo lastne intuicije in strokovnega znanja na podroÄju domene. ZabeleÅ¾ite svoje vpoglede in ustvarite **bazo znanja** (npr. knjiÅ¾nice predlog), ki jo lahko drugi uporabijo kot novo izhodiÅ¡Äe za hitrejÅ¡e iteracije v prihodnosti.

## NajboljÅ¡e prakse

Sedaj si poglejmo pogoste najboljÅ¡e prakse, ki jih priporoÄajo praktiki [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) in [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Kaj                                | Zakaj                                                                                                                                                                                                                                               |
| :--------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Ocenite najnovejÅ¡e modele.         | Nove generacije modelov verjetno ponujajo izboljÅ¡ane funkcije in kakovost - vendar lahko povzroÄijo tudi viÅ¡je stroÅ¡ke. Ocenite jih za vpliv, nato sprejmite odloÄitve o migraciji.                                                                 |
| LoÄite navodila in kontekst        | Preverite, ali vaÅ¡ model/ponudnik definira _mejnike_ za jasnejÅ¡e loÄevanje navodil, primarne in sekundarne vsebine. To lahko pomaga modelom natanÄneje dodeliti uteÅ¾i tokenom.                                                                         |
| Bodite specifiÄni in jasni         | Podajte veÄ podrobnosti o Å¾elenem kontekstu, izidu, dolÅ¾ini, formatu, slogu itd. To bo izboljÅ¡alo tako kakovost kot doslednost odgovorov. Zajemite recepte v ponovno uporabnih predlogah.                                                             |
| Bodite opisni, uporabite primere   | Modeli se lahko bolje odzovejo na pristop "pokaÅ¾i in povej". ZaÄnite z `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an â€œoutâ€           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` vrednostmi. Vrnite se na [odsek UÄilnica za uÄenje](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), da se nauÄite, kako.

### Nato odprite zvezek Jupyter

- Izberite jedro izvajanja. ÄŒe uporabljate moÅ¾nosti 1 ali 2, preprosto izberite privzeto jedro Python 3.10.x, ki ga zagotavlja razvojna posoda.

Pripravljeni ste za izvajanje vaj. UpoÅ¡tevajte, da tukaj ni _pravih in napaÄnih_ odgovorov - samo raziskovanje moÅ¾nosti s poskusi in napakami ter gradnja intuicije za to, kaj deluje za doloÄen model in podroÄje uporabe.

_Zaradi tega v tej lekciji ni segmentov z reÅ¡itvami kode. Namesto tega bo zvezek imel Markdown celice z naslovom "Moja reÅ¡itev:", ki prikazuje en primer izhoda za referenco._

## Preverjanje znanja

Kateri od naslednjih je dobra predloga, ki sledi nekaterim razumnim najboljÅ¡im praksam?

1. PokaÅ¾i mi sliko rdeÄega avtomobila
2. PokaÅ¾i mi sliko rdeÄega avtomobila znamke Volvo in modela XC90, parkiranega ob peÄini ob sonÄnem zahodu
3. PokaÅ¾i mi sliko rdeÄega avtomobila znamke Volvo in modela XC90

A: 2, to je najboljÅ¡a predloga, saj nudi podrobnosti o "Äem" in gre v specifiÄnosti (ne samo kateri koli avto, ampak doloÄena znamka in model) in prav tako opisuje celoten kontekst. 3 je naslednja najboljÅ¡a, saj vsebuje veliko opisov.

## ğŸš€ Izziv

Preverite, ali lahko izkoristite tehniko "namiga" s predlogo: DokonÄajte stavek "PokaÅ¾i mi sliko rdeÄega avtomobila znamke Volvo in ". Kaj odgovori, in kako bi ga izboljÅ¡ali?

## OdliÄno delo! Nadaljujte z uÄenjem

Å½elite izvedeti veÄ o razliÄnih konceptih oblikovanja predlog? ObiÅ¡Äite [stran za nadaljnje uÄenje](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), kjer boste naÅ¡li druge odliÄne vire o tej temi.

Pojdite na Lekcijo 5, kjer bomo pogledali [napredne tehnike oblikovanja predlog](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas opozarjamo, da lahko avtomatizirani prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za kritiÄne informacije se priporoÄa profesionalni prevod s strani Äloveka. Ne prevzemamo odgovornosti za morebitna nesporazumevanja ali napaÄne razlage, ki izhajajo iz uporabe tega prevoda.