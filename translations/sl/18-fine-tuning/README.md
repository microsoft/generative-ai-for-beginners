<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-18T01:44:17+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "sl"
}
-->
[![Odprtokodni modeli](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.sl.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Prilagajanje va코ega LLM

Uporaba velikih jezikovnih modelov za gradnjo aplikacij generativne umetne inteligence prina코a nove izzive. Klju캜no vpra코anje je zagotavljanje kakovosti odgovorov (natan캜nost in ustreznost) v vsebini, ki jo model ustvari za dolo캜eno zahtevo uporabnika. V prej코njih lekcijah smo obravnavali tehnike, kot sta oblikovanje pozivov in generacija, podprta z iskanjem, ki posku코ata re코iti te쬬vo z _modifikacijo vhodnega poziva_ obstoje캜ega modela.

V dana코nji lekciji bomo obravnavali tretjo tehniko, **prilagajanje**, ki posku코a re코iti izziv z _ponovnim u캜enjem samega modela_ z dodatnimi podatki. Poglobimo se v podrobnosti.

## Cilji u캜enja

Ta lekcija uvaja koncept prilagajanja za vnaprej nau캜ene jezikovne modele, raziskuje prednosti in izzive tega pristopa ter ponuja smernice o tem, kdaj in kako uporabiti prilagajanje za izbolj코anje zmogljivosti va코ih generativnih AI modelov.

Na koncu te lekcije boste lahko odgovorili na naslednja vpra코anja:

- Kaj je prilagajanje jezikovnih modelov?
- Kdaj in zakaj je prilagajanje koristno?
- Kako lahko prilagodim vnaprej nau캜en model?
- Kak코ne so omejitve prilagajanja?

Pripravljeni? Za캜nimo.

## Ilustrirani vodi캜

콯elite dobiti celotno sliko o tem, kaj bomo obravnavali, preden se poglobimo? Oglejte si ta ilustrirani vodi캜, ki opisuje u캜ni proces za to lekcijo - od u캜enja osnovnih konceptov in motivacije za prilagajanje do razumevanja procesa in najbolj코ih praks za izvedbo naloge prilagajanja. To je fascinantna tema za raziskovanje, zato ne pozabite preveriti strani [Viri](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) za dodatne povezave, ki podpirajo va코o samostojno u캜no pot!

![Ilustrirani vodi캜 za prilagajanje jezikovnih modelov](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.sl.png)

## Kaj je prilagajanje jezikovnih modelov?

Po definiciji so veliki jezikovni modeli _vnaprej nau캜eni_ na velikih koli캜inah besedil, pridobljenih iz razli캜nih virov, vklju캜no z internetom. Kot smo se nau캜ili v prej코njih lekcijah, potrebujemo tehnike, kot sta _oblikovanje pozivov_ in _generacija, podprta z iskanjem_, da izbolj코amo kakovost odgovorov modela na vpra코anja uporabnika ("pozive").

Priljubljena tehnika oblikovanja pozivov vklju캜uje dajanje modelu ve캜 navodil o tem, kaj se pri캜akuje v odgovoru, bodisi z zagotavljanjem _navodil_ (izrecna navodila) bodisi _z nekaj primeri_ (implicitna navodila). To se imenuje _u캜enje z nekaj primeri_, vendar ima dve omejitvi:

- Omejitve 코tevila tokenov modela lahko omejijo 코tevilo primerov, ki jih lahko podate, in s tem u캜inkovitost.
- Stro코ki tokenov modela lahko podra쬴jo dodajanje primerov k vsakemu pozivu in omejijo prilagodljivost.

Prilagajanje je obi캜ajna praksa v sistemih strojnega u캜enja, kjer vzamemo vnaprej nau캜en model in ga ponovno nau캜imo z novimi podatki, da izbolj코amo njegovo zmogljivost pri dolo캜eni nalogi. V kontekstu jezikovnih modelov lahko vnaprej nau캜en model prilagodimo _z izbranim naborom primerov za dolo캜eno nalogo ali aplikacijsko podro캜je_, da ustvarimo **prilagojen model**, ki je lahko bolj natan캜en in ustrezen za to specifi캜no nalogo ali podro캜je. Stranska korist prilagajanja je, da lahko zmanj코a 코tevilo potrebnih primerov za u캜enje z nekaj primeri - kar zmanj코a uporabo tokenov in s tem povezane stro코ke.

## Kdaj in zakaj bi morali prilagoditi modele?

V _tem_ kontekstu, ko govorimo o prilagajanju, mislimo na **nadzorovano** prilagajanje, kjer se ponovno u캜enje izvaja z **dodajanjem novih podatkov**, ki niso bili del prvotnega nabora podatkov za u캜enje. To se razlikuje od nenadzorovanega pristopa prilagajanja, kjer se model ponovno nau캜i na prvotnih podatkih, vendar z razli캜nimi hiperparametri.

Klju캜no je, da si zapomnite, da je prilagajanje napredna tehnika, ki zahteva dolo캜eno raven strokovnosti za dosego 쬰lenih rezultatov. 캛e je izvedeno nepravilno, morda ne bo prineslo pri캜akovanih izbolj코av in lahko celo poslab코a zmogljivost modela za va코e ciljno podro캜je.

Torej, preden se nau캜ite "kako" prilagoditi jezikovne modele, morate vedeti "zakaj" bi se odlo캜ili za to pot in "kdaj" za캜eti proces prilagajanja. Za캜nite z zastavljanjem teh vpra코anj:

- **Uporaba**: Kak코en je va코 _namen uporabe_ prilagajanja? Kateri vidik trenutnega vnaprej nau캜enega modela 쬰lite izbolj코ati?
- **Alternativne mo쬹osti**: Ste poskusili _druge tehnike_ za dosego 쬰lenih rezultatov? Uporabite jih za ustvarjanje izhodi코캜 za primerjavo.
  - Oblikovanje pozivov: Poskusite tehnike, kot je u캜enje z nekaj primeri, z ustreznimi primeri odgovorov na pozive. Ocenite kakovost odgovorov.
  - Generacija, podprta z iskanjem: Poskusite dopolniti pozive z rezultati iskanja v va코ih podatkih. Ocenite kakovost odgovorov.
- **Stro코ki**: Ste identificirali stro코ke prilagajanja?
  - Prilagodljivost - ali je vnaprej nau캜en model na voljo za prilagajanje?
  - Trud - za pripravo podatkov za u캜enje, ocenjevanje in izbolj코anje modela.
  - Ra캜unalni코ka mo캜 - za izvajanje nalog prilagajanja in uvajanje prilagojenega modela.
  - Podatki - dostop do zadostnega 코tevila kakovostnih primerov za vpliv prilagajanja.
- **Koristi**: Ste potrdili koristi prilagajanja?
  - Kakovost - ali je prilagojen model presegel izhodi코캜ne rezultate?
  - Stro코ki - ali zmanj코uje uporabo tokenov z enostavnej코imi pozivi?
  - Raz코irljivost - ali lahko osnovni model uporabite za nova podro캜ja?

Z odgovori na ta vpra코anja bi morali biti sposobni odlo캜iti, ali je prilagajanje prava pot za va코 namen uporabe. Idealno je, da je pristop veljaven le, 캜e koristi presegajo stro코ke. Ko se odlo캜ite za nadaljevanje, je 캜as, da razmislite o tem, _kako_ lahko prilagodite vnaprej nau캜en model.

콯elite pridobiti ve캜 vpogleda v proces odlo캜anja? Oglejte si [Prilagoditi ali ne prilagoditi](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kako lahko prilagodimo vnaprej nau캜en model?

Za prilagajanje vnaprej nau캜enega modela potrebujete:

- vnaprej nau캜en model za prilagajanje
- nabor podatkov za prilagajanje
- okolje za u캜enje za izvajanje naloge prilagajanja
- gostiteljsko okolje za uvajanje prilagojenega modela

## Prilagajanje v praksi

Naslednji viri ponujajo korak za korakom vadnice, ki vas vodijo skozi resni캜en primer uporabe izbranega modela z izbranim naborom podatkov. Za izvedbo teh vadnic potrebujete ra캜un pri dolo캜enem ponudniku, skupaj z dostopom do ustreznega modela in naborov podatkov.

| Ponudnik     | Vadnica                                                                                                                                                                       | Opis                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Kako prilagoditi klepetalne modele](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)         | Nau캜ite se prilagoditi `gpt-35-turbo` za dolo캜eno podro캜je ("pomo캜nik za recepte") z pripravo podatkov za u캜enje, izvajanjem naloge prilagajanja in uporabo prilagojenega modela za sklepanje.                                                                                                                                                                                                                                              |
| Azure OpenAI | [Vadnica za prilagajanje GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Nau캜ite se prilagoditi model `gpt-35-turbo-0613` **na Azure** z izvedbo korakov za ustvarjanje in nalaganje podatkov za u캜enje ter izvajanje naloge prilagajanja. Uvedite in uporabite nov model.                                                                                                                                                                                                                                                                 |
| Hugging Face | [Prilagajanje LLM-jev s Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | Ta blog objava vas vodi skozi prilagajanje _odprtega LLM_ (npr. `CodeLlama 7B`) z uporabo knji쬹ice [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) in [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) z odprtimi [nabori podatkov](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 游뱅 AutoTrain | [Prilagajanje LLM-jev z AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                        | AutoTrain (ali AutoTrain Advanced) je knji쬹ica za Python, ki jo je razvil Hugging Face in omogo캜a prilagajanje za 코tevilne razli캜ne naloge, vklju캜no s prilagajanjem LLM. AutoTrain je re코itev brez kode, prilagajanje pa je mogo캜e izvesti v va코em oblaku, na Hugging Face Spaces ali lokalno. Podpira tako spletni GUI, CLI kot tudi u캜enje prek konfiguracijskih datotek yaml.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Naloga

Izberite eno od zgornjih vadnic in jo preu캜ite. _Morda bomo replicirali razli캜ico teh vadnic v Jupyter Notebooks v tem repozitoriju samo za referenco. Prosimo, da za najnovej코e razli캜ice neposredno uporabite izvirne vire_.

## Odli캜no delo! Nadaljujte z u캜enjem.

Po zaklju캜ku te lekcije si oglejte na코o [Zbirko u캜enja o generativni umetni inteligenci](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), da 코e naprej nadgrajujete svoje znanje o generativni umetni inteligenci!

캛estitke!! Zaklju캜ili ste zadnjo lekcijo iz serije v2 tega te캜aja! Ne prenehajte se u캜iti in ustvarjati. \*\*Oglejte si stran [VIRI](RESOURCES.md?WT.mc_id=academic-105485-koreyst) za seznam dodatnih predlogov za to temo.

Na코a serija lekcij v1 je bila prav tako posodobljena z ve캜 nalogami in koncepti. Zato si vzemite trenutek za osve쬴tev svojega znanja - in prosimo, [delite svoja vpra코anja in povratne informacije](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), da nam pomagate izbolj코ati te lekcije za skupnost.

---

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za prevajanje AI [Co-op Translator](https://github.com/Azure/co-op-translator). 캛eprav si prizadevamo za natan캜nost, vas prosimo, da upo코tevate, da lahko avtomatizirani prevodi vsebujejo napake ali neto캜nosti. Izvirni dokument v njegovem maternem jeziku naj se 코teje za avtoritativni vir. Za klju캜ne informacije priporo캜amo profesionalni 캜love코ki prevod. Ne odgovarjamo za morebitne nesporazume ali napa캜ne razlage, ki izhajajo iz uporabe tega prevoda.