<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:51:21+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "sl"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.sl.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Prilagajanje vaÅ¡ega LLM

Uporaba velikih jezikovnih modelov za gradnjo generativnih AI aplikacij prinaÅ¡a nove izzive. KljuÄno vpraÅ¡anje je zagotavljanje kakovosti odgovorov (natanÄnost in relevantnost) v vsebini, ki jo model ustvari za doloÄen uporabniÅ¡ki zahtevek. V prejÅ¡njih lekcijah smo obravnavali tehnike, kot sta prompt engineering in retrieval-augmented generation, ki poskuÅ¡ajo reÅ¡iti problem z _modifikacijo vhodnega poziva_ obstojeÄemu modelu.

V danaÅ¡nji lekciji bomo predstavili tretjo tehniko, **fine-tuning** (prilagajanje), ki skuÅ¡a izziv reÅ¡iti z _ponovnim uÄenjem samega modela_ z dodatnimi podatki. Poglejmo podrobnosti.

## Cilji uÄenja

Ta lekcija uvaja koncept prilagajanja za vnaprej nauÄene jezikovne modele, raziskuje prednosti in izzive tega pristopa ter ponuja navodila, kdaj in kako uporabiti prilagajanje za izboljÅ¡anje zmogljivosti vaÅ¡ih generativnih AI modelov.

Na koncu te lekcije boste znali odgovoriti na naslednja vpraÅ¡anja:

- Kaj je prilagajanje jezikovnih modelov?
- Kdaj in zakaj je prilagajanje koristno?
- Kako lahko prilagodim vnaprej nauÄen model?
- KakÅ¡ne so omejitve prilagajanja?

Ste pripravljeni? ZaÄnimo.

## Ilustriran vodiÄ

Å½elite dobiti celoten pregled vsebine, preden se poglobimo? Oglejte si ta ilustriran vodiÄ, ki opisuje uÄno pot za to lekcijo â€“ od spoznavanja osnovnih pojmov in motivacije za prilagajanje do razumevanja procesa in najboljÅ¡ih praks za izvedbo naloge prilagajanja. To je zanimiva tema za raziskovanje, zato ne pozabite obiskati strani [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) za dodatne povezave, ki podpirajo vaÅ¡e samostojno uÄenje!

![Illustrated Guide to Fine Tuning Language Models](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.sl.png)

## Kaj je prilagajanje jezikovnih modelov?

Veliki jezikovni modeli so po definiciji _vnaprej nauÄeni_ na velikih koliÄinah besedil, pridobljenih iz razliÄnih virov, vkljuÄno z internetom. Kot smo se nauÄili v prejÅ¡njih lekcijah, potrebujemo tehnike, kot sta _prompt engineering_ in _retrieval-augmented generation_, da izboljÅ¡amo kakovost odgovorov modela na uporabnikova vpraÅ¡anja ("prompte").

Priljubljena tehnika prompt engineeringa vkljuÄuje, da modelu damo veÄ navodil o tem, kaj naj priÄakuje v odgovoru, bodisi z zagotavljanjem _navodil_ (izrecna usmeritev) ali _z nekaj primeri_ (implicitna usmeritev). To imenujemo _few-shot learning_, vendar ima dve omejitvi:

- Omejitve Å¡tevila tokenov modela lahko omejijo Å¡tevilo primerov, ki jih lahko podate, in s tem uÄinkovitost.
- StroÅ¡ki tokenov modela lahko povzroÄijo, da je dodajanje primerov vsakemu pozivu drago, kar omejuje prilagodljivost.

Prilagajanje je pogosta praksa v sistemih strojnega uÄenja, kjer vzamemo vnaprej nauÄen model in ga ponovno nauÄimo z novimi podatki, da izboljÅ¡amo njegovo zmogljivost za doloÄen opravek. V kontekstu jezikovnih modelov lahko prilagodimo vnaprej nauÄen model _z izbranim naborom primerov za doloÄen opravek ali podroÄje uporabe_, da ustvarimo **prilagojen model**, ki je lahko natanÄnejÅ¡i in bolj relevanten za ta specifiÄni opravek ali podroÄje. Dodatna prednost prilagajanja je, da lahko zmanjÅ¡a Å¡tevilo primerov, potrebnih za few-shot uÄenje â€“ s tem zmanjÅ¡a uporabo tokenov in povezane stroÅ¡ke.

## Kdaj in zakaj prilagajati modele?

V _tem_ kontekstu, ko govorimo o prilagajanju, mislimo na **nadzorovano** prilagajanje, kjer se ponovno uÄenje izvaja z **dodajanjem novih podatkov**, ki niso bili del izvornega uÄnega nabora. To se razlikuje od nenadzorovanega prilagajanja, kjer se model ponovno uÄi na izvornih podatkih, vendar z drugaÄnimi hiperparametri.

KljuÄno je, da je prilagajanje napredna tehnika, ki zahteva doloÄeno raven strokovnega znanja, da doseÅ¾emo Å¾elene rezultate. ÄŒe je izvedeno nepravilno, morda ne bo prineslo priÄakovanih izboljÅ¡av in lahko celo poslabÅ¡a zmogljivost modela za vaÅ¡e ciljno podroÄje.

Zato, preden se nauÄite "kako" prilagoditi jezikovne modele, morate vedeti "zakaj" bi se tega lotili in "kdaj" zaÄeti postopek prilagajanja. ZaÄnite z zastavljanjem naslednjih vpraÅ¡anj:

- **UporabniÅ¡ki primer**: KakÅ¡en je vaÅ¡ _uporabniÅ¡ki primer_ za prilagajanje? Kateri vidik trenutnega vnaprej nauÄenega modela Å¾elite izboljÅ¡ati?
- **Alternativne moÅ¾nosti**: Ste Å¾e poskusili _druge tehnike_ za dosego Å¾elenih rezultatov? Uporabite jih za ustvarjanje osnovne primerjave.
  - Prompt engineering: Poskusite tehnike, kot je few-shot prompting z relevantnimi primeri odgovorov. Ocenite kakovost odgovorov.
  - Retrieval Augmented Generation: Poskusite dopolniti pozive z rezultati iskanja v vaÅ¡ih podatkih. Ocenite kakovost odgovorov.
- **StroÅ¡ki**: Ste ocenili stroÅ¡ke prilagajanja?
  - Prilagodljivost â€“ ali je vnaprej nauÄeni model na voljo za prilagajanje?
  - Napor â€“ za pripravo uÄnih podatkov, ocenjevanje in izboljÅ¡evanje modela.
  - RaÄunska moÄ â€“ za izvajanje prilagajanja in nameÅ¡Äanje prilagojenega modela.
  - Podatki â€“ dostop do dovolj kakovostnih primerov za vpliv prilagajanja.
- **Koristi**: Ste potrdili koristi prilagajanja?
  - Kakovost â€“ ali je prilagojeni model presegel osnovno razliÄico?
  - StroÅ¡ki â€“ ali zmanjÅ¡a uporabo tokenov z enostavnejÅ¡imi pozivi?
  - RazÅ¡irljivost â€“ ali lahko osnovni model uporabite za nova podroÄja?

Z odgovori na ta vpraÅ¡anja boste laÅ¾je odloÄili, ali je prilagajanje prava pot za vaÅ¡ primer uporabe. Idealno je, da je pristop smiseln le, Äe koristi pretehtajo stroÅ¡ke. Ko se odloÄite za nadaljevanje, je Äas, da razmislite o tem, _kako_ lahko prilagodite vnaprej nauÄen model.

Å½elite veÄ vpogledov v proces odloÄanja? Oglejte si [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kako lahko prilagodimo vnaprej nauÄen model?

Za prilagajanje vnaprej nauÄenega modela potrebujete:

- vnaprej nauÄen model za prilagajanje
- podatkovni niz za prilagajanje
- uÄni okolje za izvajanje prilagajanja
- gostiteljsko okolje za nameÅ¡Äanje prilagojenega modela

## Prilagajanje v praksi

Naslednji viri ponujajo korak-po-korak vodiÄe, ki vas vodijo skozi resniÄen primer z izbranim modelom in izbranim podatkovnim nizom. Za delo z temi vodiÄi potrebujete raÄun pri doloÄenem ponudniku ter dostop do ustreznega modela in podatkovnih nizov.

| Ponudnik    | VodiÄ                                                                                                                                                                        | Opis                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ----------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)             | NauÄite se prilagoditi `gpt-35-turbo` za specifiÄno podroÄje ("pomoÄnik za recepte") z pripravo uÄnih podatkov, izvajanjem prilagajanja in uporabo prilagojenega modela za napovedovanje.                                                                                                                                                                                                                                   |
| Azure OpenAI| [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | NauÄite se prilagoditi model `gpt-35-turbo-0613` **na Azure** z ustvarjanjem in nalaganjem uÄnih podatkov, izvajanjem prilagajanja, nameÅ¡Äanjem in uporabo novega modela.                                                                                                                                                                                                                                                    |
| Hugging Face| [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                            | Ta blog vodi skozi prilagajanje _odprtega LLM_ (npr. `CodeLlama 7B`) z uporabo knjiÅ¾nice [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) in [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) ter odprtih [podatkovnih nizov](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|             |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ğŸ¤— AutoTrain| [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                      | AutoTrain (ali AutoTrain Advanced) je Python knjiÅ¾nica, ki jo je razvila Hugging Face in omogoÄa prilagajanje za razliÄne naloge, vkljuÄno s prilagajanjem LLM. AutoTrain je reÅ¡itev brez kode, prilagajanje pa je moÅ¾no v vaÅ¡i lastni oblaku, na Hugging Face Spaces ali lokalno. Podpira spletni vmesnik, CLI in uÄenje preko yaml konfiguracijskih datotek.                                                                                 |
|             |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                 |

## Naloga

Izberite enega od zgornjih vodiÄev in ga preglejte. _Morda bomo razliÄico teh vodiÄev vkljuÄili v Jupyter zvezke v tem repozitoriju samo za referenco. Za najnovejÅ¡e razliÄice uporabite izvirne vire._

## OdliÄno delo! Nadaljujte z uÄenjem.

Po zakljuÄku te lekcije si oglejte naÅ¡o [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), da Å¡e naprej nadgrajujete svoje znanje o generativni AI!

ÄŒestitke!! ZakljuÄili ste zadnjo lekcijo iz serije v2 tega teÄaja! Ne prenehajte z uÄenjem in ustvarjanjem. \*\*Oglejte si stran [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) za seznam dodatnih priporoÄil prav za to temo.

NaÅ¡a serija lekcij v1 je prav tako posodobljena z veÄ nalogami in koncepti. Vzemite si trenutek za osveÅ¾itev znanja â€“ in prosimo, [delite svoja vpraÅ¡anja in povratne informacije](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), da nam pomagate izboljÅ¡ati te lekcije za skupnost.

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za avtomatski prevod AI [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas opozarjamo, da lahko avtomatski prevodi vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za pomembne informacije priporoÄamo strokovni ÄloveÅ¡ki prevod. Za morebitna nesporazume ali napaÄne interpretacije, ki izhajajo iz uporabe tega prevoda, ne odgovarjamo.