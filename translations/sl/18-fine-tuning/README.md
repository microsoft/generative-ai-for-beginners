[![Open Source Models](../../../translated_images/sl/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Prilagajanje vaÅ¡ega LLM

Uporaba velikih jezikovnih modelov za gradnjo generativnih AI aplikacij prinaÅ¡a nove izzive. KljuÄna teÅ¾ava je zagotavljanje kakovosti odziva (natanÄnost in relevantnost) v vsebini, ki jo model ustvari za doloÄeno uporabniÅ¡ko zahtevo. V prejÅ¡njih lekcijah smo obravnavali tehnike, kot sta inÅ¾eniring pozivov in generiranje z iskanjem, ki poskuÅ¡ajo reÅ¡iti problem z _spreminjanjem vhodnega poziva_ obstojeÄemu modelu.

V danaÅ¡nji lekciji obravnavamo tretjo tehniko, **prilagajanje (fine-tuning)**, ki poskuÅ¡a reÅ¡iti izziv z _ponovnim treniranjem samega modela_ z dodatnimi podatki. Poglejmo podrobnosti.

## Cilji uÄenja

Ta lekcija uvaja koncept prilagajanja predhodno usposobljenih jezikovnih modelov, raziskuje prednosti in izzive tega pristopa ter daje navodila, kdaj in kako uporabiti prilagajanje za izboljÅ¡anje delovanja vaÅ¡ih generativnih AI modelov.

Do konca te lekcije bi morali znati odgovoriti na naslednja vpraÅ¡anja:

- Kaj je prilagajanje za jezikovne modele?
- Kdaj in zakaj je prilagajanje uporabno?
- Kako lahko prilagodim predhodno usposobljen model?
- KakÅ¡ne so omejitve prilagajanja?

Pripravljeni? ZaÄnimo.

## Ilustriran vodiÄ

Å½elite dobiti celoten pregled tega, kar bomo obravnavali, preden se poglobimo? Oglejte si ta ilustrirani vodiÄ, ki opisuje uÄni proces za to lekcijo - od spoznavanja osnovnih konceptov in motivacije za prilagajanje do razumevanja postopka in najboljÅ¡ih praks za izvedbo naloge prilagajanja. To je zanimiva tema za raziskovanje, zato ne pozabite preveriti tudi strani [Viri](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) za dodatne povezave, ki podpirajo vaÅ¡e samostojno uÄenje!

![Illustrated Guide to Fine Tuning Language Models](../../../translated_images/sl/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Kaj je prilagajanje za jezikovne modele?

Veliki jezikovni modeli so po definiciji _predhodno usposobljeni_ na velikih koliÄinah besedil, pridobljenih iz razliÄnih virov, vkljuÄno z internetom. Kot smo se nauÄili v prejÅ¡njih lekcijah, potrebujemo tehnike, kot so _inÅ¾eniring pozivov_ in _generiranje z iskanjem_, da izboljÅ¡amo kakovost odzivov modela na vpraÅ¡anja uporabnikov ("pozive").

Priljubljena tehnika inÅ¾eniringa pozivov vkljuÄuje dajanje veÄ usmeritev modelu glede priÄakovanega odgovora bodisi z zagotavljanjem _navodil_ (izrecno vodstvo) ali _dajanjem nekaj primerov_ (implicitno vodstvo). To imenujemo _uÄenje z nekaj primeri_ (few-shot learning), vendar ima dve omejitvi:

- Omejitve Å¡tevila modelnih tokenov lahko omejijo Å¡tevilo primerov, ki jih lahko podate, in omejijo uÄinkovitost.
- StroÅ¡ki modelnih tokenov lahko naredijo drago dodajanje primerov v vsak poziv in omejijo prilagodljivost.

Prilagajanje je obiÄajna praksa v strojno-uÄnih sistemih, kjer vzamemo predhodno usposobljen model in ga ponovno treniramo z novimi podatki za izboljÅ¡anje njegove uÄinkovitosti pri doloÄeni nalogi. V kontekstu jezikovnih modelov lahko prilagodimo predhodno usposobljen model _z izbranimi primeri za doloÄeno nalogo ali domeno uporabe_, da ustvarimo **prilagojen model**, ki je lahko natanÄnejÅ¡i in bolj relevanten za to specifiÄno nalogo ali domeno. Dodaten plus prilagajanja je, da lahko zmanjÅ¡a tudi Å¡tevilo primerov, potrebnih za uÄenje z nekaj primeri - s tem zmanjÅ¡a porabo tokenov in povezane stroÅ¡ke.

## Kdaj in zakaj prilagajati modele?

V _tem_ kontekstu, ko govorimo o prilagajanju, mislimo na **nadzorovano** prilagajanje, kjer se ponovno treniranje izvaja z **dodajanjem novih podatkov**, ki niso bili del izvornega nabora za uÄenje. To se razlikuje od nenadzorovanega pristopa, kjer se model ponovno trenira na izvirnih podatkih, a z drugimi hiperparametri.

KljuÄno je razumeti, da je prilagajanje napredna tehnika, ki zahteva doloÄeno stopnjo strokovnega znanja za dosego Å¾elenih rezultatov. ÄŒe se izvede nepravilno, morda ne bo prinesla priÄakovanih izboljÅ¡av, lahko pa celo poslabÅ¡a delovanje modela za vaÅ¡o ciljno domeno.

Zato, preden se nauÄite "kako" prilagajati jezikovne modele, morate vedeti "zakaj" bi morali izbrati to pot, in "kdaj" zaÄeti proces prilagajanja. ZaÄnite z vpraÅ¡anji:

- **Primer uporabe**: KakÅ¡en je vaÅ¡ _primer uporabe_ za prilagajanje? Kateri vidik sedanjega predhodno usposobljenega modela Å¾elite izboljÅ¡ati?
- **Alternative**: Ste poskusili _druge tehnike_ za dosego Å¾elenih rezultatov? Uporabite jih za ustvarjanje osnovne primerjave.
  - InÅ¾eniring pozivov: Poskusite tehnike, kot je uÄenje z nekaj primeri s primeri ustreznih odzivov na pozive. Ocenite kakovost odzivov.
  - Generiranje z iskanjem: Poskusite dopolniti pozive z rezultati iskanja med vaÅ¡imi podatki. Ocenite kakovost odzivov.
- **StroÅ¡ki**: Ste doloÄili stroÅ¡ke za prilagajanje?
  - Prilagodljivost â€“ ali je predhodno usposobljen model na voljo za prilagajanje?
  - Napor â€“ za pripravo uÄnih podatkov, ocenjevanje in izpopolnjevanje modela.
  - RaÄunske zmogljivosti â€“ za izvajanje prilagajanja in nameÅ¡Äanje prilagojenega modela.
  - Podatki â€“ dostop do dovolj kakovostnih primerov za uÄinek prilagajanja.
- **Koristi**: Ste potrdili koristi prilagajanja?
  - Kakovost â€“ ali je prilagojeni model presegel osnovo?
  - StroÅ¡ki â€“ ali zmanjÅ¡a porabo tokenov s poenostavitvijo pozivov?
  - RazÅ¡irljivost â€“ ali lahko osnovni model ponovno uporabite za nove domene?

Z odgovori na ta vpraÅ¡anja bi morali vedeti, ali je prilagajanje prava pot za vaÅ¡ primer uporabe. Idealno je, da je ta pristop veljaven le, Äe koristi pretehta stroÅ¡ke. Ko se odloÄite za nadaljevanje, je Äas, da razmislite, _kako_ prilagoditi predhodno usposobljen model.

Å½elite veÄ vpogledov v proces odloÄanja? Oglejte si [Prilagoditi ali ne prilagoditi](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kako lahko prilagodimo predhodno usposobljen model?

Za prilagajanje predhodno usposobljenega modela potrebujete:

- predhodno usposobljen model za prilagajanje
- podatkovni niz za prilagajanje
- okolje za usposabljanje za izvajanje naloge prilagajanja
- gostiteljsko okolje za nameÅ¡Äanje prilagojenega modela

## Prilagajanje v akciji

Naslednji viri ponujajo korak-po-korak vadnice, ki vas vodijo skozi resniÄen primer z izbranim modelom in izbranim naborom podatkov. Za delo z vajami potrebujete raÄun pri doloÄenem ponudniku ter dostop do ustreznega modela in podatkovnih nizov.

| Ponudnik     | VodiÄ                                                                                                                                                                        | Opis                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Kako prilagoditi klepetalne modele](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)       | NauÄite se prilagoditi `gpt-35-turbo` za specifiÄno domeno ("pomoÄnik za recepte") s pripravo podatkov za uÄenje, izvedbo prilagajanja in uporabo prilagojenega modela za sklepanje.                                                                                                                                                                                                                                       |
| Azure OpenAI | [Vadnica za prilagajanje GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | NauÄite se prilagoditi model `gpt-35-turbo-0613` **na Azure** z ustvarjanjem in nalaganjem uÄnih podatkov, izvajanjem prilagajanja, nameÅ¡Äanjem in uporabo novega modela.                                                                                                                                                                                                                                                   |
| Hugging Face | [Prilagajanje LLM z Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | Ta blog vodi vas skozi prilagajanje odprtega LLM (npr. `CodeLlama 7B`) z uporabo knjiÅ¾nice [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) in [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) z odprtimi [nabori podatkov](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ğŸ¤— AutoTrain | [Prilagajanje LLM z AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                        | AutoTrain (ali AutoTrain Advanced) je python knjiÅ¾nica, ki jo je razvil Hugging Face in omogoÄa prilagajanje za razliÄne naloge, vkljuÄno s prilagajanjem LLM. AutoTrain je reÅ¡itev brez kodiranja, prilagajanje pa je moÅ¾no v vaÅ¡em oblaku, na Hugging Face Spaces ali lokalno. Podpira spletni GUI, CLI in uÄenje preko yaml konfiguracijskih datotek.                                                                     |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ğŸ¦¥ Unsloth  | [Prilagajanje LLM z Unsloth](https://github.com/unslothai/unsloth)                                                                        | Unsloth je odprtokodni okvir za podporo prilagajanja LLM in okrepljenega uÄenja (RL). Poenostavlja lokalno usposabljanje, ocenjevanje in nameÅ¡Äanje z uporabo pripravljenih [zvezkov](https://github.com/unslothai/notebooks). Podpira tudi pretvorbo besedila v govor (TTS), BERT in multimodalne modele. Za zaÄetek preberite njihov korak-po-korak [Vodnik za prilagajanje LLM](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).  |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
## Naloga

Izberite eno od zgornjih vadnic in jo preglejte. _Morda bomo v tej repozitoriji podvojili verzijo teh vadnic v Jupyter zvezkih zgolj za referenco. Za najnovejÅ¡e verzije uporabljajte prosim originalne vire._

## OdliÄno delo! Nadaljujte z uÄenjem.

Po zakljuÄku te lekcije si oglejte naÅ¡o [Zbirko za uÄenje generativne AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), da nadaljujete z nadgrajevanjem znanja generativne AI!

ÄŒestitamo!! ZakljuÄili ste zadnjo lekcijo iz serije v2 tega teÄaja! Ne prenehajte z uÄenjem in ustvarjanjem. \*\*Oglejte si stran [VIRI](RESOURCES.md?WT.mc_id=academic-105485-koreyst) za seznam dodatnih predlogov za to temo.

NaÅ¡a serija v1 lekcij je prav tako posodobljena z veÄ nalogami in koncepti. Vzemite si trenutek, da osveÅ¾ite svoje znanje â€“ in prosimo, [delite svoja vpraÅ¡anja in povratne informacije](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), da pomagamo izboljÅ¡ati te lekcije za skupnost.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Izjava o omejitvi odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve za avtomatski prevod AI [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, upoÅ¡tevajte, da lahko avtomatski prevodi vsebujejo napake ali nedoslednosti. Izvirni dokument v njegovem izvorno jeziku velja za avtoritativni vir. Za pomembne informacije priporoÄamo strokoven ÄloveÅ¡ki prevod. Ne odgovarjamo za morebitna nesporazume ali napaÄne interpretacije, ki izhajajo iz uporabe tega prevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->