{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prilagajanje modelov Open AI\n",
    "\n",
    "Ta zvezek temelji na trenutnih navodilih, ki jih najdete v dokumentaciji [Prilagajanje](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) Open AI.\n",
    "\n",
    "Prilagajanje izboljša zmogljivost osnovnih modelov za vašo aplikacijo z dodatnim učenjem na dodatnih podatkih in kontekstu, ki je pomemben za določen primer uporabe ali scenarij. Upoštevajte, da tehnike oblikovanja pozivov, kot sta _few shot learning_ in _retrieval augmented generation_, omogočajo izboljšanje privzetega poziva z ustreznimi podatki za izboljšanje kakovosti. Vendar pa so ti pristopi omejeni z največjo velikostjo okna za število tokenov ciljanega osnovnega modela.\n",
    "\n",
    "S prilagajanjem dejansko ponovno učimo model z zahtevanimi podatki (kar nam omogoča uporabo veliko več primerov, kot jih lahko sprejme največje okno za število tokenov) - in uvajamo _prilagojeno_ različico modela, ki ne potrebuje več primerov med izvajanjem. To ne le izboljša učinkovitost oblikovanja poziva (imamo večjo prilagodljivost pri uporabi okna za število tokenov za druge stvari), ampak potencialno tudi zniža stroške (z zmanjšanjem števila tokenov, ki jih moramo poslati modelu med izvajanjem).\n",
    "\n",
    "Prilagajanje ima 4 korake:\n",
    "1. Pripravite učne podatke in jih naložite.\n",
    "1. Zaženite učno nalogo, da dobite prilagojen model.\n",
    "1. Ocenite prilagojeni model in ponavljajte za izboljšanje kakovosti.\n",
    "1. Uvedite prilagojeni model za izvajanje, ko ste zadovoljni.\n",
    "\n",
    "Upoštevajte, da ne podpirajo vsi osnovni modeli prilagajanja - [preverite dokumentacijo OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) za najnovejše informacije. Prav tako lahko prilagodite že prej prilagojen model. V tem vodiču bomo kot ciljni osnovni model za prilagajanje uporabili `gpt-35-turbo`. \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 1.1: Pripravite svoj nabor podatkov\n",
    "\n",
    "Zgradimo klepetalnega robota, ki vam pomaga razumeti periodni sistem elementov tako, da odgovarja na vprašanja o elementu z limeriko. V _tem_ preprostem vodiču bomo ustvarili le nabor podatkov za usposabljanje modela z nekaj primeri odgovorov, ki prikazujejo pričakovani format podatkov. V resničnem primeru uporabe bi morali ustvariti nabor podatkov z veliko več primeri. Prav tako boste morda lahko uporabili odprt nabor podatkov (za vaše področje uporabe), če obstaja, in ga preoblikovali za uporabo pri fino nastavitvi.\n",
    "\n",
    "Ker se osredotočamo na `gpt-35-turbo` in iščemo enkratni odgovor (zaključek klepeta), lahko ustvarimo primere z uporabo [tega predlaganega formata](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), ki odraža zahteve OpenAI za zaključke klepeta. Če pričakujete večkratno pogovorno vsebino, bi uporabili [format primerov za večkratne pogovore](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), ki vključuje parameter `weight` za označevanje, katere sporočila naj se uporabljajo (ali ne) v postopku fino nastavitve.\n",
    "\n",
    "Za naš vodič bomo uporabili preprostejši format enkratnega odgovora. Podatki so v [jsonl formatu](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) z enim zapisom na vrstico, vsak predstavljen kot objekt v JSON obliki. Spodnji odlomek prikazuje 2 zapisa kot primer - glejte [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) za celoten vzorec (10 primerov), ki ga bomo uporabili za naš vodič fino nastavitve. **Opomba:** Vsak zapis _mora_ biti definiran v eni sami vrstici (ne razdeljen čez več vrstic, kot je običajno v formatirani JSON datoteki)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "V resničnem primeru uporabe boste potrebovali veliko večji nabor primerov za dobre rezultate - kompromis bo med kakovostjo odgovorov in časom/stroški fino nastavitve. Uporabljamo majhen nabor, da lahko hitro zaključimo fino nastavitev in prikažemo postopek. Glejte [ta primer iz OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) za bolj zapleten vodič fino nastavitve.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 1.2 Naložite svoj nabor podatkov\n",
    "\n",
    "Naložite podatke z uporabo Files API [kot je opisano tukaj](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Upoštevajte, da morate za zagon te kode najprej opraviti naslednje korake:\n",
    " - Namestiti Python paket `openai` (poskrbite, da uporabljate različico >=0.28.0 za najnovejše funkcije)\n",
    " - Nastaviti okoljsko spremenljivko `OPENAI_API_KEY` na vaš OpenAI API ključ\n",
    "Za več informacij si oglejte [vodnik za nastavitev](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), ki je na voljo za tečaj.\n",
    "\n",
    "Zdaj zaženite kodo, da ustvarite datoteko za nalaganje iz vaše lokalne JSONL datoteke.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 2.1: Ustvarite nalogo za fino nastavljanje z SDK-jem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 2.2: Preverite stanje naloge\n",
    "\n",
    "Tukaj je nekaj stvari, ki jih lahko naredite z API-jem `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Prikaži zadnjih n nalog za fino nastavljanje\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Pridobi podrobnosti o določeni nalogi za fino nastavljanje\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Prekliči nalogo za fino nastavljanje\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Prikaži do n dogodkov iz naloge\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Prvi korak procesa je _preverjanje veljavnosti datoteke za učenje_, da se zagotovi, da so podatki v pravilni obliki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 2.3: Spremljajte dogodke za nadzor napredka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 2.4: Ogled statusa v nadzorni plošči OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status si lahko ogledate tudi tako, da obiščete spletno stran OpenAI in raziščete razdelek _Fine-tuning_ na platformi. Ta vam bo prikazal status trenutnega opravila in vam omogočil tudi sledenje zgodovine preteklih izvedb opravil. Na tem posnetku zaslona lahko vidite, da je prejšnja izvedba spodletela, druga pa je bila uspešna. Za kontekst, to se je zgodilo, ko je prva izvedba uporabila JSON datoteko z nepravilno oblikovanimi zapisi – ko je bilo to popravljeno, je druga izvedba uspešno zaključila in model naredila na voljo za uporabo.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/sl/fine-tuned-model-status.563271727bf7bfba.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statusna sporočila in metrike si lahko ogledate tudi tako, da se v vizualni nadzorni plošči pomaknete še nižje, kot je prikazano:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/sl/fine-tuned-messages-panel.4ed0c2da5ea1313b.png) |  ![Metrics](../../../../../translated_images/sl/fine-tuned-metrics-panel.700d7e4995a65229.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 3.1: Pridobite ID in preizkusite fino nastavljeni model v kodi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 3.2: Naložite in preizkusite fino nastavljeni model v Playgroundu\n",
    "\n",
    "Zdaj lahko fino nastavljeni model preizkusite na dva načina. Najprej lahko obiščete Playground in v spustnem meniju Models izberete vaš novo fino nastavljeni model med ponujenimi možnostmi. Druga možnost je uporaba možnosti \"Playground\", prikazane v panelu Fine-tuning (glejte posnetek zaslona zgoraj), ki za hitro oceno zažene naslednji _primerjalni_ pogled, ki prikazuje osnovno in fino nastavljeno različico modela ena ob drugi.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/sl/fine-tuned-playground-compare.56e06f0ad8922016.png)\n",
    "\n",
    "Preprosto vnesite sistemski kontekst, uporabljen v vaših učnih podatkih, in podajte vaše testno vprašanje. Opazili boste, da se obe strani posodobita z enakim kontekstom in vprašanjem. Zaženite primerjavo in videli boste razliko v izhodih med njima. _Opazite, kako fino nastavljeni model oblikuje odgovor v formatu, ki ste ga navedli v svojih primerih, medtem ko osnovni model preprosto sledi sistemskemu pozivu_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/sl/fine-tuned-playground-launch.5a26495c983c6350.png)\n",
    "\n",
    "Opazili boste, da primerjava prav tako prikazuje število tokenov za vsak model in čas, potreben za inferenco. **Ta specifični primer je poenostavljen in namenjen prikazu procesa, ne pa dejanskemu odražanju resničnega nabora podatkov ali scenarija**. Morda boste opazili, da oba vzorca prikazujeta enako število tokenov (sistemski kontekst in uporabniški poziv sta enaka), pri čemer fino nastavljeni model potrebuje več časa za inferenco (prilagojeni model).\n",
    "\n",
    "V resničnih scenarijih ne boste uporabljali takšnega preprostega primera, ampak boste fino nastavljali na resničnih podatkih (npr. katalog izdelkov za podporo strankam), kjer bo kakovost odgovora veliko bolj očitna. V _tem_ kontekstu bo za dosego enakovredne kakovosti odgovora z osnovnim modelom potrebna bolj prilagojena inženiring pozivov, kar bo povečalo uporabo tokenov in potencialno tudi čas obdelave za inferenco. _Za preizkus si oglejte primere fino nastavljanja v OpenAI Cookbook, da začnete._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Omejitev odgovornosti**:\nTa dokument je bil preveden z uporabo storitve za prevajanje z umetno inteligenco [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas opozarjamo, da avtomatizirani prevodi lahko vsebujejo napake ali netočnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Za morebitna nesporazume ali napačne interpretacije, ki izhajajo iz uporabe tega prevoda, ne odgovarjamo.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:50:11+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "sl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}