{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fino uravnavanje Open AI modelov\n",
    "\n",
    "Ta zvezek temelji na trenutnih navodilih iz dokumentacije [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) podjetja Open AI.\n",
    "\n",
    "Fino uravnavanje izboljša delovanje osnovnih modelov za vašo aplikacijo tako, da jih ponovno izurite z dodatnimi podatki in kontekstom, ki so pomembni za vaš primer uporabe ali scenarij. Upoštevajte, da tehnike oblikovanja pozivov, kot sta _few shot learning_ in _retrieval augmented generation_, omogočajo izboljšanje privzetega poziva z ustreznimi podatki za boljšo kakovost. Vendar pa so te metode omejene z največjo velikostjo okna za žetone, ki jo podpira izbrani osnovni model.\n",
    "\n",
    "S finim uravnavanjem dejansko ponovno izurimo sam model z zahtevanimi podatki (kar nam omogoča uporabo veliko več primerov, kot jih lahko vključimo v največje okno za žetone) in uvedemo _prilagojeno_ različico modela, ki pri sklepanju ne potrebuje več primerov. To ne le izboljša učinkovitost oblikovanja pozivov (imamo več svobode pri uporabi okna za žetone za druge stvari), ampak lahko tudi zmanjša stroške (ker moramo modelu ob sklepanju poslati manj žetonov).\n",
    "\n",
    "Fino uravnavanje poteka v 4 korakih:\n",
    "1. Pripravite učne podatke in jih naložite.\n",
    "1. Zaženite učno opravilo in pridobite fino uravnan model.\n",
    "1. Ocenite fino uravnan model in po potrebi izboljšajte kakovost.\n",
    "1. Ko ste zadovoljni, uvedite fino uravnan model za sklepanja.\n",
    "\n",
    "Upoštevajte, da vsi osnovni modeli ne podpirajo finega uravnavanja – [preverite dokumentacijo OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) za najnovejše informacije. Prav tako lahko fino uravnate že prej fino uravnan model. V tej vadnici bomo za fino uravnavanje uporabili model `gpt-35-turbo` kot naš osnovni model.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 1.1: Pripravite svoj podatkovni niz\n",
    "\n",
    "Zgradimo klepetalnika, ki vam pomaga razumeti periodni sistem elementov tako, da na vprašanja o elementu odgovarja z limerikom. V _tem_ preprostem vodiču bomo ustvarili podatkovni niz za učenje modela z nekaj vzorčnimi primeri odgovorov, ki prikazujejo pričakovano obliko podatkov. V resnični uporabi bi morali pripraviti podatkovni niz z veliko več primeri. Če obstaja odprt podatkovni niz (za vaše področje uporabe), ga lahko uporabite in preoblikujete za uporabo pri dodatnem učenju.\n",
    "\n",
    "Ker se osredotočamo na `gpt-35-turbo` in želimo enkratni odgovor (chat completion), lahko pripravimo primere po [tem predlaganem formatu](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), ki ustreza zahtevam za OpenAI chat completion. Če pričakujete večkrožni pogovor, uporabite [format za večkrožne primere](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), ki vključuje parameter `weight` za označevanje, katere sporočila naj se uporabijo (ali ne) pri dodatnem učenju.\n",
    "\n",
    "Za ta vodič bomo uporabili enostavnejši enokrožni format. Podatki so v [jsonl formatu](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst), kjer je vsak zapis v eni vrstici, predstavljen kot objekt v JSON obliki. Spodnji izsek prikazuje 2 zapisa kot primer – celoten vzorčni niz (10 primerov), ki ga bomo uporabili za naš vodič o dodatnem učenju, si lahko ogledate v [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl). **Opomba:** Vsak zapis _mora_ biti zapisan v eni vrstici (ne razdeljen čez več vrstic, kot je običajno v formatiranih JSON datotekah)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "V resnični uporabi boste za dobre rezultate potrebovali veliko večji nabor primerov – kompromis je med kakovostjo odgovorov in časom/stroški dodatnega učenja. Uporabljamo majhen nabor, da lahko hitro zaključimo postopek in ga prikažemo. Za bolj zahteven vodič o dodatnem učenju si oglejte [ta primer iz OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 1.2 Naložite svoj podatkovni niz\n",
    "\n",
    "Podatke naložite z uporabo Files API [kot je opisano tukaj](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Upoštevajte, da morate pred zagonom te kode najprej opraviti naslednje korake:\n",
    " - Namestiti morate Python paket `openai` (prepričajte se, da uporabljate različico >=0.28.0 zaradi najnovejših funkcij)\n",
    " - Nastaviti morate okoljsko spremenljivko `OPENAI_API_KEY` na vaš OpenAI API ključ\n",
    "Za več informacij si oglejte [navodila za nastavitev](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), ki so priložena temu tečaju.\n",
    "\n",
    "Sedaj zaženite kodo, da ustvarite datoteko za nalaganje iz vaše lokalne JSONL datoteke.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 2.1: Ustvarite nalogo za fino nastavljanje s pomočjo SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 2.2: Preverite stanje opravila\n",
    "\n",
    "Tukaj je nekaj stvari, ki jih lahko naredite z API-jem `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Prikaže zadnjih n opravil za fino nastavljanje\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Pridobi podrobnosti določenega opravila za fino nastavljanje\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Prekliči opravilo za fino nastavljanje\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Prikaže do n dogodkov iz opravila\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Prvi korak v postopku je _preverjanje učne datoteke_, da zagotovite, da so podatki v pravilni obliki.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 2.3: Spremljajte dogodke za nadzor napredka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 2.4: Oglejte si stanje na nadzorni plošči OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Status lahko preverite tudi tako, da obiščete spletno stran OpenAI in raziščete razdelek _Fine-tuning_ na platformi. Tam boste videli status trenutne naloge in lahko spremljate zgodovino preteklih izvajanj. Na tem posnetku zaslona lahko vidite, da je prejšnje izvajanje spodletelo, drugo pa je bilo uspešno. Za boljše razumevanje: do tega je prišlo, ker je bila pri prvem zagonu uporabljena JSON datoteka z napačno oblikovanimi zapisi – ko je bila napaka odpravljena, je drugi zagon uspešno zaključen in model je postal na voljo za uporabo.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.sl.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statusna sporočila in metrike si lahko ogledate tudi tako, da se pomaknete nižje po vizualni nadzorni plošči, kot je prikazano:\n",
    "\n",
    "| Sporočila | Metrike |\n",
    "|:---|:---|\n",
    "| ![Sporočila](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.sl.png) |  ![Metrike](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.sl.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 3.1: Pridobite ID in preizkusite fino nastavljeni model v kodi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 3.2: Naložite in preizkusite fino prilagojen model v Playgroundu\n",
    "\n",
    "Fino prilagojen model lahko zdaj preizkusite na dva načina. Prvi način je, da obiščete Playground in v spustnem meniju Models izberete svoj novo fino prilagojen model med ponujenimi možnostmi. Druga možnost je, da uporabite možnost \"Playground\", ki je prikazana v plošči za fino prilagajanje (glejte zgornji posnetek zaslona), kar odpre _primerjalni_ pogled, kjer sta osnovni in fino prilagojeni model prikazana drug ob drugem za hitro oceno.\n",
    "\n",
    "Preprosto vnesite sistemski kontekst, ki ste ga uporabili v svojih učnih podatkih, in dodajte svoje testno vprašanje. Opazili boste, da se na obeh straneh posodobita enak kontekst in vprašanje. Zaženite primerjavo in videli boste razliko v izhodih med obema modeloma. _Opazite, kako fino prilagojeni model oblikuje odgovor v formatu, ki ste ga določili v svojih primerih, medtem ko osnovni model zgolj sledi sistemskemu pozivu_.\n",
    "\n",
    "Opazili boste tudi, da primerjava prikaže število žetonov za vsak model in čas, potreben za sklepanje. **Ta primer je zelo poenostavljen in je namenjen prikazu postopka, ne pa odražanju resničnega nabora podatkov ali scenarija**. Morda boste opazili, da imata oba primera enako število žetonov (sistemski kontekst in uporabniški poziv sta enaka), pri čemer fino prilagojeni model za sklepanje porabi več časa (ker gre za prilagojen model).\n",
    "\n",
    "V resničnih primerih ne boste uporabljali takšnega preprostega primera, temveč boste model fino prilagajali na resničnih podatkih (npr. katalog izdelkov za podporo strankam), kjer bo kakovost odgovora veliko bolj očitna. V _takšnem_ kontekstu boste za enakovredno kakovost odgovora z osnovnim modelom potrebovali več prilagajanja pozivov, kar bo povečalo porabo žetonov in verjetno tudi čas obdelave za sklepanje. _Če želite to preizkusiti, si oglejte primere fine-tuninga v OpenAI Cookbook in začnite._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Omejitev odgovornosti**:  \nTa dokument je bil preveden z uporabo storitve za strojno prevajanje [Co-op Translator](https://github.com/Azure/co-op-translator). Čeprav si prizadevamo za natančnost, vas prosimo, da se zavedate, da lahko samodejni prevodi vsebujejo napake ali netočnosti. Izvirni dokument v svojem izvirnem jeziku naj velja za avtoritativni vir. Za ključne informacije priporočamo strokovni človeški prevod. Ne prevzemamo odgovornosti za morebitna nesporazume ali napačne razlage, ki bi izhajale iz uporabe tega prevoda.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:58:15+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "sl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}