<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:42:52+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "sl"
}
-->
# RaziÅ¡Äite in primerjajte razliÄne LLM-je

[![RaziÅ¡Äite in primerjajte razliÄne LLM-je](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.sl.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite na zgornjo sliko za ogled videa te lekcije_

V prejÅ¡nji lekciji smo videli, kako Generativna AI spreminja tehnoloÅ¡ki svet, kako delujejo Large Language Models (LLM) in kako jih lahko podjetje â€“ kot je naÅ¡ startup â€“ uporabi za svoje primere uporabe in raste! V tem poglavju bomo primerjali in kontrastirali razliÄne vrste velikih jezikovnih modelov (LLM), da bi razumeli njihove prednosti in slabosti.

Naslednji korak na poti naÅ¡ega startupa je raziskati trenutno stanje LLM-jev in ugotoviti, kateri so primerni za naÅ¡ primer uporabe.

## Uvod

Ta lekcija bo zajemala:

- RazliÄne vrste LLM-jev v trenutnem okolju.
- Testiranje, iteriranje in primerjanje razliÄnih modelov za vaÅ¡ primer uporabe v Azure.
- Kako namestiti LLM.

## Cilji uÄenja

Po zakljuÄku te lekcije boste znali:

- Izbrati pravi model za vaÅ¡ primer uporabe.
- Razumeti, kako testirati, iterirati in izboljÅ¡ati zmogljivost vaÅ¡ega modela.
- Vedeti, kako podjetja nameÅ¡Äajo modele.

## Razumevanje razliÄnih vrst LLM-jev

LLM-je lahko razvrstimo na veÄ naÄinov glede na njihovo arhitekturo, podatke za uÄenje in primer uporabe. Razumevanje teh razlik bo naÅ¡emu startupu pomagalo izbrati pravi model za doloÄen scenarij ter razumeti, kako testirati, iterirati in izboljÅ¡ati zmogljivost.

Obstaja veliko razliÄnih vrst LLM modelov, izbira modela pa je odvisna od tega, za kaj jih Å¾elite uporabiti, vaÅ¡ih podatkov, koliko ste pripravljeni plaÄati in Å¡e veÄ.

Glede na to, ali Å¾elite modele uporabiti za besedilo, zvok, video, generiranje slik in podobno, boste morda izbrali drugaÄen tip modela.

- **Prepoznavanje zvoka in govora**. Za ta namen so Whisper modeli odliÄna izbira, saj so sploÅ¡no uporabni in namenjeni prepoznavanju govora. Usposobljeni so na raznolikih zvoÄnih posnetkih in lahko izvajajo veÄjeziÄno prepoznavanje govora. VeÄ o [Whisper modelih tukaj](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generiranje slik**. Za generiranje slik sta DALL-E in Midjourney dve zelo znani izbiri. DALL-E je na voljo preko Azure OpenAI. [Preberite veÄ o DALL-E tukaj](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) in tudi v 9. poglavju tega uÄnega naÄrta.

- **Generiranje besedila**. VeÄina modelov je usposobljenih za generiranje besedila in imate Å¡irok izbor od GPT-3.5 do GPT-4. Ti modeli imajo razliÄne stroÅ¡ke, pri Äemer je GPT-4 najdraÅ¾ji. Vredno je preizkusiti [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), da ocenite, kateri modeli najbolje ustrezajo vaÅ¡im potrebam glede zmogljivosti in stroÅ¡kov.

- **VeÄmodalnost**. ÄŒe Å¾elite obdelovati veÄ vrst podatkov na vhodu in izhodu, si oglejte modele, kot so [gpt-4 turbo z vidom ali gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) â€“ najnovejÅ¡e izdaje OpenAI modelov â€“ ki zdruÅ¾ujejo obdelavo naravnega jezika z vizualnim razumevanjem in omogoÄajo interakcije preko veÄmodalnih vmesnikov.

Izbira modela pomeni, da dobite osnovne zmogljivosti, ki pa morda ne bodo zadostovale. Pogosto imate podatke, specifiÄne za podjetje, o katerih morate LLM-ju nekako sporoÄiti. Obstaja nekaj razliÄnih pristopov, o katerih bomo veÄ povedali v naslednjih razdelkih.

### Foundation modeli proti LLM-jem

Izraz Foundation Model so [skovali raziskovalci s Stanforda](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) in ga definirali kot AI model, ki izpolnjuje doloÄene kriterije, kot so:

- **Usposobljeni so z ne-nadzorovanim ali samonadzorovanim uÄenjem**, kar pomeni, da so usposobljeni na neoznaÄenih veÄmodalnih podatkih in ne potrebujejo roÄnega oznaÄevanja podatkov za proces uÄenja.
- **So zelo veliki modeli**, ki temeljijo na zelo globokih nevronskih mreÅ¾ah, usposobljenih na milijardah parametrov.
- **ObiÄajno so namenjeni kot â€˜osnovaâ€™ za druge modele**, kar pomeni, da jih lahko uporabimo kot izhodiÅ¡Äe za gradnjo drugih modelov, kar se lahko naredi z dodatnim prilagajanjem (fine-tuningom).

![Foundation modeli proti LLM-jem](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.sl.png)

Vir slike: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Za boljÅ¡o razlago si vzemimo primer ChatGPT. Za izdelavo prve razliÄice ChatGPT je model GPT-3.5 sluÅ¾il kot foundation model. To pomeni, da je OpenAI uporabil nekaj podatkov, specifiÄnih za klepet, da je ustvaril prilagojeno razliÄico GPT-3.5, specializirano za dobro delovanje v pogovornih scenarijih, kot so chatbot-i.

![Foundation model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.sl.png)

Vir slike: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Odprtokodni proti lastniÅ¡kim modelom

Drugi naÄin razvrstitve LLM-jev je, ali so odprtokodni ali lastniÅ¡ki.

Odprtokodni modeli so modeli, ki so javno dostopni in jih lahko uporablja kdorkoli. Pogosto jih objavi podjetje, ki jih je ustvarilo, ali raziskovalna skupnost. Ti modeli so dovoljeni za pregledovanje, spreminjanje in prilagajanje za razliÄne primere uporabe LLM-jev. Vendar pa niso vedno optimizirani za produkcijsko uporabo in morda niso tako zmogljivi kot lastniÅ¡ki modeli. Poleg tega je financiranje odprtokodnih modelov lahko omejeno, zato morda niso vzdrÅ¾evani dolgoroÄno ali posodobljeni z najnovejÅ¡imi raziskavami. Primeri priljubljenih odprtokodnih modelov so [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) in [LLaMA](https://llama.meta.com).

LastniÅ¡ki modeli so modeli, ki so v lasti podjetja in niso javno dostopni. Ti modeli so pogosto optimizirani za produkcijsko uporabo. Vendar jih ni dovoljeno pregledovati, spreminjati ali prilagajati za razliÄne primere uporabe. Poleg tega niso vedno brezplaÄni in lahko zahtevajo naroÄnino ali plaÄilo za uporabo. Uporabniki nimajo nadzora nad podatki, ki se uporabljajo za usposabljanje modela, zato morajo lastniku modela zaupati, da bo spoÅ¡toval zasebnost podatkov in odgovorno uporabo AI. Primeri priljubljenih lastniÅ¡kih modelov so [OpenAI modeli](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ali [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding proti generiranju slik proti generiranju besedila in kode

LLM-je lahko razvrstimo tudi glede na izhod, ki ga ustvarjajo.

Embedding modeli so tisti, ki lahko pretvorijo besedilo v numeriÄno obliko, imenovano embedding, kar je numeriÄna predstavitev vhodnega besedila. Embeddingi olajÅ¡ajo strojno razumevanje odnosov med besedami ali stavki in jih lahko uporabljajo drugi modeli, kot so klasifikacijski ali gruÄevalni modeli, ki bolje delujejo z numeriÄnimi podatki. Embedding modeli se pogosto uporabljajo za prenosno uÄenje, kjer se model zgradi za nadomestno nalogo, za katero je na voljo veliko podatkov, nato pa se uteÅ¾i modela (embeddingi) ponovno uporabijo za druge naloge. Primer te kategorije so [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.sl.png)

Modeli za generiranje slik so modeli, ki ustvarjajo slike. Pogosto se uporabljajo za urejanje slik, sintezo slik in prevajanje slik. Ti modeli so pogosto usposobljeni na velikih zbirkah slik, kot je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), in se lahko uporabljajo za ustvarjanje novih slik ali urejanje obstojeÄih s tehnikami, kot so inpainting, super-resolucija in koloriranje. Primeri so [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) in [Stable Diffusion modeli](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generiranje slik](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.sl.png)

Modeli za generiranje besedila in kode so modeli, ki ustvarjajo besedilo ali kodo. Pogosto se uporabljajo za povzemanje besedil, prevajanje in odgovarjanje na vpraÅ¡anja. Modeli za generiranje besedila so pogosto usposobljeni na velikih zbirkah besedil, kot je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), in se lahko uporabljajo za ustvarjanje novega besedila ali odgovarjanje na vpraÅ¡anja. Modeli za generiranje kode, kot je [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), so pogosto usposobljeni na velikih zbirkah kode, kot je GitHub, in se lahko uporabljajo za ustvarjanje nove kode ali odpravljanje napak v obstojeÄi kodi.

![Generiranje besedila in kode](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.sl.png)

### Encoder-Decoder proti samo Decoder

Za razlago razliÄnih arhitektur LLM-jev uporabimo primerjavo.

Predstavljajte si, da vam je vaÅ¡ nadrejeni dal nalogo, da pripravite kviz za Å¡tudente. Imate dva sodelavca; eden skrbi za ustvarjanje vsebine, drugi pa za pregled.

Ustvarjalec vsebine je kot model samo z Decoderjem, lahko pogleda temo in vidi, kaj ste Å¾e napisali, nato pa na podlagi tega napiÅ¡e teÄaj. So zelo dobri pri pisanju zanimive in informativne vsebine, vendar niso najboljÅ¡i pri razumevanju teme in uÄnih ciljev. Nekateri primeri Decoder modelov so GPT druÅ¾ina modelov, kot je GPT-3.

Pregledovalec je kot model samo z Encoderjem, pregleda napisani teÄaj in odgovore, opazi povezave med njimi in razume kontekst, vendar ni dober pri ustvarjanju vsebine. Primer modela samo z Encoderjem je BERT.

Predstavljajte si, da imamo nekoga, ki lahko hkrati ustvarja in pregleduje kviz, to je model Encoder-Decoder. Nekateri primeri so BART in T5.

### Storitev proti modelu

Zdaj pa o razlikah med storitvijo in modelom. Storitev je produkt, ki ga ponuja ponudnik oblaÄnih storitev in je pogosto kombinacija modelov, podatkov in drugih komponent. Model je osrednji del storitve in je pogosto foundation model, kot je LLM.

Storitev je pogosto optimizirana za produkcijsko uporabo in je obiÄajno laÅ¾ja za uporabo kot modeli, preko grafiÄnega uporabniÅ¡kega vmesnika. Vendar storitve niso vedno brezplaÄne in lahko zahtevajo naroÄnino ali plaÄilo za uporabo, v zameno za uporabo opreme in virov lastnika storitve, optimizacijo stroÅ¡kov in enostavno skaliranje. Primer storitve je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), ki ponuja plaÄilo po porabi, kar pomeni, da uporabniki plaÄajo sorazmerno z uporabo storitve. Poleg tega Azure OpenAI Service nudi varnost na ravni podjetja in okvir za odgovorno uporabo AI, ki temelji na zmogljivostih modelov.

Modeli so zgolj nevronske mreÅ¾e s parametri, uteÅ¾mi in drugimi elementi. Podjetjem omogoÄajo lokalno izvajanje, vendar bi morali kupiti opremo, zgraditi infrastrukturo za skaliranje in kupiti licenco ali uporabiti odprtokodni model. Model, kot je LLaMA, je na voljo za uporabo, vendar zahteva raÄunsko moÄ za zagon modela.

## Kako testirati in iterirati z razliÄnimi modeli za razumevanje zmogljivosti v Azure

Ko je naÅ¡a ekipa raziskala trenutno stanje LLM-jev in izbrala nekaj primernih kandidatov za svoje scenarije, je naslednji korak testiranje na njihovih podatkih in delovnih obremenitvah. To je iterativen proces, ki poteka preko eksperimentov in meritev.
VeÄina modelov, ki smo jih omenili v prejÅ¡njih odstavkih (OpenAI modeli, odprtokodni modeli, kot je Llama2, in Hugging Face transformatorji), je na voljo v [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) v [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je oblaÄna platforma, namenjena razvijalcem za ustvarjanje generativnih AI aplikacij in upravljanje celotnega razvojnega cikla â€“ od eksperimentiranja do ocenjevanja â€“ s povezovanjem vseh Azure AI storitev v eno samo srediÅ¡Äe z uporabniku prijaznim grafiÄnim vmesnikom. Model Catalog v Azure AI Studio omogoÄa uporabniku:

- Iskanje ustreznega Foundation Modela v katalogu â€“ bodisi lastniÅ¡kega ali odprtokodnega, z moÅ¾nostjo filtriranja po nalogi, licenci ali imenu. Za laÅ¾je iskanje so modeli organizirani v zbirke, kot so Azure OpenAI zbirka, Hugging Face zbirka in druge.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.sl.png)

- Pregled modelne kartice, ki vkljuÄuje podroben opis predvidene uporabe in uÄnih podatkov, primere kode ter rezultate ocenjevanja v interni knjiÅ¾nici ocen.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.sl.png)

- Primerjavo merilnikov uspeÅ¡nosti med modeli in podatkovnimi nizi, ki so na voljo v industriji, da se oceni, kateri model najbolj ustreza poslovnemu scenariju, preko [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) okna.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.sl.png)

- Prilagoditev modela na lastnih uÄnih podatkih za izboljÅ¡anje zmogljivosti modela pri specifiÄni nalogi, z uporabo moÅ¾nosti eksperimentiranja in sledenja v Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.sl.png)

- Namestitev originalnega predhodno usposobljenega modela ali prilagojene razliÄice na oddaljeni realnoÄasovni inferenÄni streÅ¾nik â€“ upravljan raÄunalniÅ¡ki sistem â€“ ali brezstreÅ¾ni API konektor â€“ [plaÄilo po porabi](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) â€“ da aplikacije lahko uporabljajo model.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.sl.png)


> [!NOTE]
> Ne vsi modeli v katalogu so trenutno na voljo za prilagajanje (fine-tuning) in/ali namestitev s plaÄilom po porabi. Za podrobnosti o zmogljivostih in omejitvah modela preverite modelno kartico.

## IzboljÅ¡evanje rezultatov LLM

Z naÅ¡o startup ekipo smo preizkusili razliÄne vrste LLM-jev in oblaÄno platformo (Azure Machine Learning), ki nam omogoÄa primerjavo razliÄnih modelov, njihovo ocenjevanje na testnih podatkih, izboljÅ¡anje zmogljivosti in namestitev na inferenÄne konÄne toÄke.

Kdaj pa naj razmislijo o prilagoditvi modela (fine-tuning) namesto uporabe predhodno usposobljenega? Ali obstajajo Å¡e drugi pristopi za izboljÅ¡anje zmogljivosti modela pri specifiÄnih nalogah?

Podjetje lahko uporabi veÄ pristopov, da doseÅ¾e Å¾elene rezultate z LLM. Pri uvajanju LLM v produkcijo lahko izberete razliÄne vrste modelov z razliÄnimi stopnjami usposobljenosti, z razliÄnimi zahtevami glede kompleksnosti, stroÅ¡kov in kakovosti. Tukaj je nekaj razliÄnih pristopov:

- **Prompt inÅ¾eniring s kontekstom**. Ideja je, da ob pozivu zagotovite dovolj konteksta, da dobite Å¾elene odgovore.

- **Retrieval Augmented Generation, RAG**. VaÅ¡i podatki so lahko shranjeni v podatkovni bazi ali na spletni konÄni toÄki, na primer, zato lahko za zagotovitev, da so ti podatki ali njihov del vkljuÄeni ob pozivu, pridobite ustrezne podatke in jih vkljuÄite v poziv uporabnika.

- **Prilagojen model (fine-tuned model)**. Tukaj model dodatno usposobite na lastnih podatkih, kar pripelje do natanÄnejÅ¡ih in bolj odzivnih rezultatov, vendar je lahko draÅ¾je.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.sl.png)

Vir slike: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt inÅ¾eniring s kontekstom

Predhodno usposobljeni LLM-ji zelo dobro delujejo pri sploÅ¡nih nalogah naravnega jezika, tudi Äe jih pokliÄemo z kratkim pozivom, kot je stavek za dopolnitev ali vpraÅ¡anje â€“ t.i. â€œzero-shotâ€ uÄenje.

Vendar pa, Äim bolj lahko uporabnik oblikuje svoj poizvedbo z natanÄnim zahtevkom in primeri â€“ torej s kontekstom â€“ tem bolj natanÄen in bliÅ¾ji priÄakovanjem bo odgovor. V tem primeru govorimo o â€œone-shotâ€ uÄenju, Äe poziv vsebuje le en primer, in â€œfew-shotâ€ uÄenju, Äe vsebuje veÄ primerov.
Prompt inÅ¾eniring s kontekstom je najbolj stroÅ¡kovno uÄinkovit pristop za zaÄetek.

### Retrieval Augmented Generation (RAG)

LLM-ji imajo omejitev, da lahko za generiranje odgovora uporabijo le podatke, ki so bili uporabljeni med njihovim usposabljanjem. To pomeni, da ne poznajo dejstev, ki so se zgodila po njihovem usposabljanju, in nimajo dostopa do ne-javnih informacij (kot so podatki podjetja).
To omejitev lahko premagamo z RAG, tehniko, ki poziv dopolni z zunanjimi podatki v obliki delov dokumentov, ob upoÅ¡tevanju omejitev dolÅ¾ine poziva. To omogoÄajo orodja za vektorsko iskanje (kot je [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), ki pridobijo uporabne dele iz razliÄnih vnaprej doloÄenih virov podatkov in jih dodajo v kontekst poziva.

Ta tehnika je zelo uporabna, kadar podjetje nima dovolj podatkov, Äasa ali virov za prilagoditev LLM, a vseeno Å¾eli izboljÅ¡ati zmogljivost pri specifiÄni nalogi in zmanjÅ¡ati tveganja za izmiÅ¡ljanje dejstev ali Å¡kodljivo vsebino.

### Prilagojen model (fine-tuned model)

Prilagajanje modela je proces, ki uporablja prenosno uÄenje za â€˜prilagoditevâ€™ modela na specifiÄno nalogo ali reÅ¡itev doloÄenega problema. V nasprotju z few-shot uÄenjem in RAG, ta proces ustvari nov model z posodobljenimi uteÅ¾mi in pristranskostmi. Potrebuje nabor uÄnih primerov, ki vsebujejo posamezen vhod (poziv) in pripadajoÄi izhod (doplnitev).
To je priporoÄljiv pristop, Äe:

- **Uporabljate prilagojene modele**. Podjetje Å¾eli uporabljati prilagojene manj zmogljive modele (kot so embedding modeli) namesto zmogljivih modelov, kar prinaÅ¡a bolj stroÅ¡kovno uÄinkovito in hitrejÅ¡o reÅ¡itev.

- **UpoÅ¡tevate zakasnitev (latenco)**. Latenca je pomembna za doloÄen primer uporabe, zato ni mogoÄe uporabiti zelo dolgih pozivov ali Å¡tevila primerov, ki jih mora model usvojiti, ne ustreza omejitvi dolÅ¾ine poziva.

- **Ostajate posodobljeni**. Podjetje ima veliko kakovostnih podatkov in oznak resniÄnih stanj ter vire za vzdrÅ¾evanje teh podatkov aÅ¾urnih skozi Äas.

### Usposobljen model

Usposabljanje LLM-ja iz niÄ je nedvomno najzahtevnejÅ¡i in najbolj kompleksen pristop, ki zahteva ogromne koliÄine podatkov, usposobljene vire in ustrezno raÄunalniÅ¡ko moÄ. To moÅ¾nost je smiselno upoÅ¡tevati le, Äe ima podjetje domeno-specifiÄen primer uporabe in veliko koliÄino podatkov, osredotoÄenih na to domeno.

## Preverjanje znanja

Kateri pristop bi bil dober za izboljÅ¡anje rezultatov dopolnjevanja LLM?

1. Prompt inÅ¾eniring s kontekstom  
1. RAG  
1. Prilagojen model  

Odgovor: 3, Äe imate Äas, vire in kakovostne podatke, je prilagajanje boljÅ¡a izbira za ostati posodobljen. Vendar, Äe Å¾elite izboljÅ¡ati rezultate in vam primanjkuje Äasa, je vredno najprej razmisliti o RAG.

## ğŸš€ Izziv

Preberite veÄ o tem, kako lahko [uporabite RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) za vaÅ¡e podjetje.

## OdliÄno delo, nadaljujte z uÄenjem

Po zakljuÄku te lekcije si oglejte naÅ¡o [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) in nadaljujte z nadgrajevanjem svojega znanja o generativni umetni inteligenci!

Pojdite na Lekcijo 3, kjer bomo pogledali, kako [graditi z generativno AI odgovorno](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo AI prevajalske storitve [Co-op Translator](https://github.com/Azure/co-op-translator). ÄŒeprav si prizadevamo za natanÄnost, vas opozarjamo, da avtomatizirani prevodi lahko vsebujejo napake ali netoÄnosti. Izvirni dokument v njegovem izvirnem jeziku velja za avtoritativni vir. Za kljuÄne informacije priporoÄamo strokovni ÄloveÅ¡ki prevod. Za morebitna nesporazume ali napaÄne interpretacije, ki izhajajo iz uporabe tega prevoda, ne odgovarjamo.