<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:28:06+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "sl"
}
-->
# Raziskovanje in primerjava razli캜nih LLM-jev

[![Raziskovanje in primerjava razli캜nih LLM-jev](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.sl.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite zgornjo sliko za ogled videa te lekcije_

V prej코nji lekciji smo videli, kako Generativna umetna inteligenca spreminja tehnolo코ko pokrajino, kako delujejo Veliki jezikovni modeli (LLM-ji) in kako jih lahko podjetje - kot na코 startup - uporabi za svoje primere uporabe in rast! V tem poglavju bomo primerjali in kontrastirali razli캜ne vrste velikih jezikovnih modelov (LLM-jev), da bi razumeli njihove prednosti in slabosti.

Naslednji korak na poti na코ega startupa je raziskovanje trenutne pokrajine LLM-jev in razumevanje, kateri so primerni za na코 primer uporabe.

## Uvod

Ta lekcija bo pokrivala:

- Razli캜ne vrste LLM-jev v trenutni pokrajini.
- Testiranje, iteracijo in primerjavo razli캜nih modelov za va코 primer uporabe v Azure.
- Kako uvesti LLM.

## Cilji u캜enja

Po zaklju캜ku te lekcije boste sposobni:

- Izbrati pravi model za va코 primer uporabe.
- Razumeti, kako testirati, iterirati in izbolj코ati delovanje va코ega modela.
- Vedeti, kako podjetja uvajajo modele.

## Razumevanje razli캜nih vrst LLM-jev

LLM-ji imajo lahko ve캜 kategorij glede na njihovo arhitekturo, podatke za usposabljanje in primer uporabe. Razumevanje teh razlik bo na코emu startupu pomagalo izbrati pravi model za scenarij in razumeti, kako testirati, iterirati in izbolj코ati delovanje.

Obstaja veliko razli캜nih vrst LLM modelov, va코a izbira modela pa je odvisna od tega, za kaj jih 쬰lite uporabiti, va코ih podatkov, koliko ste pripravljeni pla캜ati in ve캜.

Glede na to, ali nameravate modele uporabljati za besedilo, zvok, video, generiranje slik in tako naprej, se lahko odlo캜ite za druga캜no vrsto modela.

- **Prepoznavanje zvoka in govora**. Za ta namen so modeli tipa Whisper odli캜na izbira, saj so splo코no namenjeni in usmerjeni na prepoznavanje govora. Usposobljeni so na raznolikem zvoku in lahko izvajajo ve캜jezi캜no prepoznavanje govora. Ve캜 o modelih tipa Whisper preberite [tukaj](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generiranje slik**. Za generiranje slik sta DALL-E in Midjourney dve zelo znani izbiri. DALL-E ponuja Azure OpenAI. [Preberite ve캜 o DALL-E tukaj](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) in tudi v 9. poglavju tega kurikuluma.

- **Generiranje besedila**. Ve캜ina modelov je usposobljena za generiranje besedila in imate veliko izbiro od GPT-3.5 do GPT-4. Prihajajo z razli캜nimi stro코ki, pri 캜emer je GPT-4 najdra쬵i. Vredno je preveriti [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), da ocenite, kateri modeli najbolj ustrezajo va코im potrebam glede na sposobnosti in stro코ke.

- **Ve캜modalnost**. 캛e 쬰lite obravnavati ve캜 vrst podatkov na vhodu in izhodu, si lahko ogledate modele, kot so [gpt-4 turbo z vizijo ali gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - najnovej코e izdaje modelov OpenAI - ki so sposobni kombinirati obdelavo naravnega jezika z vizualnim razumevanjem, kar omogo캜a interakcije prek ve캜modalnih vmesnikov.

Izbira modela pomeni, da dobite nekaj osnovnih sposobnosti, ki pa morda ne bodo dovolj. Pogosto imate podjetju specifi캜ne podatke, o katerih morate LLM nekako obvestiti. Obstaja nekaj razli캜nih mo쬹osti, kako pristopiti k temu, ve캜 o tem v prihajajo캜ih odsekih.

### Temeljni modeli v primerjavi z LLM-ji

Izraz Temeljni model so [skovali raziskovalci na Stanfordu](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) in ga definirali kot AI model, ki sledi nekaterim merilom, kot so:

- **Usposobljeni so z nesuperviziranim u캜enjem ali samosuperviziranim u캜enjem**, kar pomeni, da so usposobljeni na nelabeliranih ve캜modalnih podatkih in ne potrebujejo 캜love코kega ozna캜evanja ali labeliranja podatkov za svoj proces usposabljanja.
- **So zelo veliki modeli**, ki temeljijo na zelo globokih nevronskih mre쬬h, usposobljenih na milijardah parametrov.
- **Obi캜ajno so namenjeni slu쬴ti kot 'temelj' za druge modele**, kar pomeni, da jih je mogo캜e uporabiti kot izhodi코캜e za gradnjo drugih modelov, kar se lahko izvede z natan캜nim prilagajanjem.

![Temeljni modeli v primerjavi z LLM-ji](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.sl.png)

Vir slike: [Essential Guide to Foundation Models and Large Language Models | avtor Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Da bi dodatno pojasnili to razliko, vzemimo ChatGPT kot primer. Za izgradnjo prve razli캜ice ChatGPT je model GPT-3.5 slu쬴l kot temeljni model. To pomeni, da je OpenAI uporabil nekaj podatkov, specifi캜nih za klepet, da je ustvaril prilagojeno razli캜ico GPT-3.5, ki je bila specializirana za dobro delovanje v konverzacijskih scenarijih, kot so klepetalni roboti.

![Temeljni model](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.sl.png)

Vir slike: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Odprtokodni v primerjavi s Proprietarnimi modeli

Drug na캜in za kategorizacijo LLM-jev je, ali so odprtokodni ali proprietarni.

Odprtokodni modeli so modeli, ki so na voljo javnosti in jih lahko uporablja kdorkoli. Pogosto so na voljo s strani podjetja, ki jih je ustvarilo, ali raziskovalne skupnosti. Ti modeli so dovoljeni za pregledovanje, spreminjanje in prilagajanje za razli캜ne primere uporabe v LLM-jev. Vendar pa niso vedno optimizirani za uporabo v produkciji in morda niso tako zmogljivi kot proprietarni modeli. Poleg tega je financiranje odprtokodnih modelov lahko omejeno in morda niso vzdr쬰vani dolgoro캜no ali posodobljeni z najnovej코imi raziskavami. Primeri priljubljenih odprtokodnih modelov vklju캜ujejo [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) in [LLaMA](https://llama.meta.com).

Proprietarni modeli so modeli, ki so v lasti podjetja in niso na voljo javnosti. Ti modeli so pogosto optimizirani za uporabo v produkciji. Vendar pa jih ni dovoljeno pregledovati, spreminjati ali prilagajati za razli캜ne primere uporabe. Poleg tega niso vedno na voljo brezpla캜no in lahko zahtevajo naro캜nino ali pla캜ilo za uporabo. Uporabniki prav tako nimajo nadzora nad podatki, ki se uporabljajo za usposabljanje modela, kar pomeni, da morajo zaupati lastniku modela, da zagotovi zavezanost k varovanju podatkov in odgovorni uporabi AI. Primeri priljubljenih proprietarnih modelov vklju캜ujejo [OpenAI modele](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ali [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Vdelava v primerjavi z Generiranjem slik v primerjavi z Generiranjem besedila in kode

LLM-ji se lahko kategorizirajo tudi glede na izhod, ki ga ustvarjajo.

Vdelave so niz modelov, ki lahko pretvorijo besedilo v numeri캜no obliko, imenovano vdelava, ki je numeri캜na predstavitev vhodnega besedila. Vdelave olaj코ajo strojem razumevanje odnosov med besedami ali stavki in jih lahko zau쬴jejo kot vhodi drugi modeli, kot so klasifikacijski modeli ali modeli za zdru쬰vanje, ki imajo bolj코e delovanje na numeri캜nih podatkih. Modeli vdelav se pogosto uporabljajo za prenosno u캜enje, kjer je model zgrajen za nadomestno nalogo, za katero je na voljo veliko podatkov, nato pa se ute쬴 modela (vdelave) ponovno uporabijo za druge naloge navzdol. Primer te kategorije je [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Vdelava](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.sl.png)

Modeli za generiranje slik so modeli, ki ustvarjajo slike. Ti modeli se pogosto uporabljajo za urejanje slik, sintezo slik in prevajanje slik. Modeli za generiranje slik so pogosto usposobljeni na velikih zbirkah podatkov slik, kot je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), in se lahko uporabljajo za ustvarjanje novih slik ali urejanje obstoje캜ih slik s tehnikami, kot so inpainting, super-resolucija in barvanje. Primeri vklju캜ujejo [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) in [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generiranje slik](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.sl.png)

Modeli za generiranje besedila in kode so modeli, ki ustvarjajo besedilo ali kodo. Ti modeli se pogosto uporabljajo za povzemanje besedila, prevajanje in odgovarjanje na vpra코anja. Modeli za generiranje besedila so pogosto usposobljeni na velikih zbirkah podatkov besedila, kot je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), in se lahko uporabljajo za ustvarjanje novega besedila ali odgovarjanje na vpra코anja. Modeli za generiranje kode, kot je [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), so pogosto usposobljeni na velikih zbirkah podatkov kode, kot je GitHub, in se lahko uporabljajo za ustvarjanje nove kode ali odpravljanje napak v obstoje캜i kodi.

![Generiranje besedila in kode](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.sl.png)

### Enkoder-Dekoder v primerjavi z Dekoder-samo

Za pogovor o razli캜nih vrstah arhitektur LLM-jev uporabimo analogijo.

Predstavljajte si, da vam je va코 vodja dal nalogo pisanja kviza za 코tudente. Imate dva sodelavca; eden je odgovoren za ustvarjanje vsebine, drugi pa za pregledovanje.

Ustvarjalec vsebine je kot model samo Dekoder, lahko pogleda temo in vidi, kaj ste 쬰 napisali, nato pa lahko napi코e te캜aj na podlagi tega. So zelo dobri pri pisanju privla캜ne in informativne vsebine, vendar niso zelo dobri pri razumevanju teme in u캜nih ciljev. Nekateri primeri modelov Dekoder so modeli dru쬴ne GPT, kot je GPT-3.

Recenzent je kot model samo Enkoder, pogleda te캜aj, ki je napisan, in odgovore, opazi odnos med njimi in razume kontekst, vendar ni dober pri generiranju vsebine. Primer modela samo Enkoder bi bil BERT.

Predstavljajte si, da imamo lahko nekoga, ki bi lahko ustvaril in pregledal kviz, to je model Enkoder-Dekoder. Nekateri primeri bi bili BART in T5.

### Storitev v primerjavi z Modelom

Zdaj pa se pogovorimo o razliki med storitvijo in modelom. Storitev je izdelek, ki ga ponuja ponudnik obla캜nih storitev in je pogosto kombinacija modelov, podatkov in drugih komponent. Model je osrednja komponenta storitve in je pogosto temeljni model, kot je LLM.

Storitve so pogosto optimizirane za uporabo v produkciji in so pogosto la쬵e za uporabo kot modeli, preko grafi캜nega uporabni코kega vmesnika. Vendar pa storitve niso vedno na voljo brezpla캜no in lahko zahtevajo naro캜nino ali pla캜ilo za uporabo, v zameno za uporabo opreme in virov lastnika storitve, optimizacijo stro코kov in enostavno skaliranje. Primer storitve je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), ki ponuja na캜rt pla캜ila po porabi, kar pomeni, da so uporabniki zara캜unani sorazmerno s tem, koliko uporabljajo storitev. Poleg tega Azure OpenAI Service ponuja varnost na ravni podjetja in okvir za odgovorno AI na vrhu zmogljivosti modelov.

Modeli so le nevronska mre쬬, z parametri, ute쬸i in drugimi. Podjetjem omogo캜ajo lokalno izvajanje, vendar bi morali kupiti opremo, zgraditi strukturo za skaliranje in kupiti licenco ali uporabiti odprtokodni model. Model, kot je LLaMA, je na voljo za uporabo, kar zahteva ra캜unalni코ko mo캜 za izvajanje modela.

## Kako testirati in iterirati z razli캜nimi modeli za razumevanje delovanja na Azure

Ko je na코a ekipa raziskala trenutno pokrajino LLM-jev in identificirala nekaj dobrih kandidatov za svoje scenarije, je naslednji korak testiranje na njihovih podatkih in na njihovem delovnem nalogu. To je iterativni proces, ki se izvaja z eksperimenti in meritvami.
Ve캜ina modelov, ki smo jih omenili v prej코njih odstavkih (OpenAI modeli, odprtokodni modeli, kot je Llama2, in Hugging Face transformerji), so na voljo v [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) v [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je obla캜na platforma, zasnovana za razvijalce za gradnjo generativnih AI aplikacij in upravljanje celotnega 쬴vljenjskega cikla razvoja - od eksperimentiranja do ocenjevanja - z zdru쬰vanjem vseh Azure AI storitev v en sam hub s priro캜nim GUI. Katalog modelov v Azure AI Studio omogo캜a uporabniku:

- Poi코캜ite temeljni model, ki vas zanima, v katalogu - bodisi proprietarni ali odprtokodni, filtriranje po nalogi, licenci ali imenu. Za izbolj코anje iskalnosti so modeli organizirani v zbirke, kot so zbirka Azure OpenAI, zbirka Hugging Face in ve캜.

![Katalog modelov](../../../translated_images/AzureAIStudioModelCatalog.e34ac207ac348d31e74246c4f91d10086444783b72bbee3658e0453918aa5d22.sl.png)

- Preglejte kartico modela, vklju캜no s podrobnim opisom nameravane uporabe in podatkov za usposabljanje, vzorci kode in rezultati ocenjevanja na interni knji쬹ici ocenjevanja.

![Kartica modela](../../../translated_images/ModelCard.8b25784bb406028655a12ea87d1ef3d52302e5d692ae4ec559c2dce7682027c7.sl.png)
- Primerjajte merila med modeli in nabori podatkov, ki so na voljo v industriji, da ocenite, kateri ustreza poslovnemu scenariju, prek podokna [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Merila modelov](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.sl.png)

- Prilagodite model s prilagojenimi podatki za usposabljanje, da izbolj코ate delovanje modela pri dolo캜eni delovni obremenitvi, z izkori코캜anjem eksperimentiranja in zmo쬹osti sledenja v Azure AI Studio.

![Prilagajanje modela](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.sl.png)

- Namestite izvirni predhodno usposobljeni model ali prilagojeno razli캜ico na oddaljeno to캜ko za inferenco v realnem 캜asu - upravljano ra캜unalni코tvo - ali brezstre쬹i API konec - [pla캜aj po uporabi](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - da omogo캜ite aplikacijam njegovo uporabo.

![Namestitev modela](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.sl.png)

> [!NOTE]
> Vsi modeli v katalogu trenutno niso na voljo za prilagajanje in/ali namestitev po sistemu pla캜aj po uporabi. Preverite kartico modela za podrobnosti o zmogljivostih in omejitvah modela.

## Izbolj코anje rezultatov LLM

Z na코o startup ekipo smo raziskali razli캜ne vrste LLM-jev in platformo v oblaku (Azure Machine Learning), ki nam omogo캜a primerjavo razli캜nih modelov, njihovo ocenjevanje na testnih podatkih, izbolj코anje zmogljivosti in namestitev na to캜ke za inferenco.

Kdaj pa naj razmislijo o prilagoditvi modela namesto uporabe predhodno usposobljenega? Ali obstajajo drugi pristopi za izbolj코anje delovanja modela pri specifi캜nih delovnih obremenitvah?

Obstaja ve캜 pristopov, ki jih podjetje lahko uporabi za dosego 쬰lenih rezultatov z LLM-jem. Pri uvajanju LLM-ja v proizvodnjo lahko izberete razli캜ne vrste modelov z razli캜nimi stopnjami usposabljanja, z razli캜nimi stopnjami kompleksnosti, stro코kov in kakovosti. Tukaj je nekaj razli캜nih pristopov:

- **In쬰niring pozivov s kontekstom**. Ideja je zagotoviti dovolj konteksta, ko postavite poziv, da zagotovite, da dobite odgovore, ki jih potrebujete.

- **Pridobivanje z obogateno generacijo, RAG**. Va코i podatki lahko obstajajo v podatkovni bazi ali spletnem koncu, na primer, da zagotovite, da so ti podatki ali njihov podnabor vklju캜eni ob 캜asu pozivanja, lahko pridobite ustrezne podatke in jih vklju캜ite v uporabnikov poziv.

- **Prilagojen model**. Tukaj ste model dodatno usposobili na lastnih podatkih, kar je pripeljalo do tega, da je model bolj natan캜en in odziven na va코e potrebe, vendar je lahko drag.

![Namestitev LLM-jev](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.sl.png)

Vir slike: [맚irje na캜ini, kako podjetja uvajajo LLM-je | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### In쬰niring pozivov s kontekstom

Predhodno usposobljeni LLM-ji delujejo zelo dobro pri splo코nih nalogah naravnega jezika, tudi 캜e jih pokli캜ete s kratkim pozivom, kot je stavek za dokon캜anje ali vpra코anje - tako imenovano "zero-shot" u캜enje.

Vendar, bolj ko lahko uporabnik oblikuje svoje vpra코anje, z natan캜no zahtevo in primeri - Kontekst - bolj natan캜en in bli쬵e uporabnikovim pri캜akovanjem bo odgovor. V tem primeru govorimo o "one-shot" u캜enju, 캜e poziv vklju캜uje samo en primer, in "few-shot u캜enju", 캜e vklju캜uje ve캜 primerov.
In쬰niring pozivov s kontekstom je najbolj stro코kovno u캜inkovit pristop za za캜etek.

### Pridobivanje z obogateno generacijo (RAG)

LLM-ji imajo omejitev, da lahko uporabijo samo podatke, ki so bili uporabljeni med njihovim usposabljanjem za ustvarjanje odgovora. To pomeni, da ne vedo ni캜esar o dejstvih, ki so se zgodila po njihovem usposabljanju, in ne morejo dostopati do ne-javnih informacij (kot so podatki podjetja).
To je mogo캜e premagati z RAG, tehniko, ki obogati poziv z zunanjimi podatki v obliki delov dokumentov, ob upo코tevanju omejitev dol쬴ne poziva. To podpirajo orodja za vektorsko bazo podatkov (kot je [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), ki pridobijo uporabne dele iz razli캜nih vnaprej dolo캜enih virov podatkov in jih dodajo v kontekst poziva.

Ta tehnika je zelo uporabna, ko podjetje nima dovolj podatkov, 캜asa ali sredstev za prilagoditev LLM-ja, a 코e vedno 쬰li izbolj코ati zmogljivost pri dolo캜eni delovni obremenitvi in zmanj코ati tveganje izmi코ljotin, tj. mistifikacije resni캜nosti ali 코kodljive vsebine.

### Prilagojen model

Prilagajanje je proces, ki izkori코캜a prenosno u캜enje za 'prilagoditev' modela na nalogo navzdol ali za re코evanje specifi캜nega problema. Razli캜no od "few-shot" u캜enja in RAG, rezultira v novem modelu, ki je ustvarjen, s posodobljenimi ute쬸i in pristranskostmi. Zahteva niz primerov za usposabljanje, ki sestojijo iz enega vnosa (poziv) in njegovega povezanega izhoda (dokon캜anje).
To bi bil prednostni pristop, 캜e:

- **Uporaba prilagojenih modelov**. Podjetje bi 쬰lelo uporabiti prilagojene manj sposobne modele (kot so vgradni modeli) namesto visokozmogljivih modelov, kar bi rezultiralo v bolj stro코kovno u캜inkoviti in hitri re코itvi.

- **Upo코tevanje latence**. Latenca je pomembna za specifi캜en primer uporabe, zato ni mogo캜e uporabiti zelo dolgih pozivov ali 코tevila primerov, ki jih je treba nau캜iti iz modela, ne ustreza omejitvi dol쬴ne poziva.

- **Ohranjanje a쬿rnosti**. Podjetje ima veliko visokokakovostnih podatkov in resni캜nih etiket ter sredstva, potrebna za vzdr쬰vanje teh podatkov a쬿rnih skozi 캜as.

### Usposobljen model

Usposabljanje LLM-ja iz ni캜 je brez dvoma najte쬵i in najbolj kompleksen pristop za sprejetje, ki zahteva ogromne koli캜ine podatkov, usposobljene vire in ustrezno ra캜unalni코ko mo캜. Ta mo쬹ost bi morala biti upo코tevana samo v scenariju, kjer ima podjetje primer uporabe, specifi캜en za domeno, in veliko koli캜ino podatkov, osredoto캜enih na domeno.

## Preverjanje znanja

Kaj bi lahko bil dober pristop za izbolj코anje rezultatov dokon캜anja LLM?

1. In쬰niring pozivov s kontekstom
1. RAG
1. Prilagojen model

A:3, 캜e imate 캜as in sredstva ter visokokakovostne podatke, je prilagajanje bolj코a mo쬹ost za ohranjanje a쬿rnosti. Vendar, 캜e razmi코ljate o izbolj코anju stvari in vam primanjkuje 캜asa, je vredno najprej razmisliti o RAG.

## 游 Izziv

Preberite ve캜 o tem, kako lahko [uporabite RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) za svoje podjetje.

## Odli캜no delo, nadaljujte z u캜enjem

Po zaklju캜ku te lekcije si oglejte na코o [kolekcijo za u캜enje Generativne AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), da 코e naprej izbolj코ujete svoje znanje o Generativni AI!

Odpravite se na Lekcijo 3, kjer bomo pogledali, kako [graditi z Generativno AI odgovorno](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Omejitev odgovornosti**:  
Ta dokument je bil preveden z uporabo storitve AI prevajanja [Co-op Translator](https://github.com/Azure/co-op-translator). 캛eprav si prizadevamo za natan캜nost, vas opozarjamo, da lahko avtomatizirani prevodi vsebujejo napake ali neto캜nosti. Izvirni dokument v njegovem maternem jeziku je treba obravnavati kot avtoritativni vir. Za kriti캜ne informacije se priporo캜a profesionalni 캜love코ki prevod. Ne odgovarjamo za morebitna nesporazumevanja ali napa캜ne razlage, ki izhajajo iz uporabe tega prevoda.