{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# اوپن اے آئی ماڈلز کی فائن ٹیوننگ\n",
    "\n",
    "یہ نوٹ بک اوپن اے آئی کی [فائن ٹیوننگ](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) دستاویزات میں فراہم کردہ موجودہ رہنمائی کی بنیاد پر ہے۔\n",
    "\n",
    "فائن ٹیوننگ آپ کی درخواست کے لیے فاؤنڈیشن ماڈلز کی کارکردگی کو بہتر بناتی ہے، اسے اضافی ڈیٹا اور مخصوص استعمال کے کیس یا منظرنامے سے متعلق سیاق و سباق کے ساتھ دوبارہ تربیت دے کر۔ نوٹ کریں کہ پرامپٹ انجینئرنگ تکنیکیں جیسے _few shot learning_ اور _retrieval augmented generation_ آپ کو معیار کو بہتر بنانے کے لیے متعلقہ ڈیٹا کے ساتھ ڈیفالٹ پرامپٹ کو بڑھانے کی اجازت دیتی ہیں۔ تاہم، یہ طریقے ہدف شدہ فاؤنڈیشن ماڈل کی زیادہ سے زیادہ ٹوکن ونڈو سائز تک محدود ہیں۔\n",
    "\n",
    "فائن ٹیوننگ کے ذریعے، ہم مؤثر طریقے سے ماڈل کو خود مطلوبہ ڈیٹا کے ساتھ دوبارہ تربیت دے رہے ہیں (جو ہمیں زیادہ مثالیں استعمال کرنے کی اجازت دیتا ہے جو زیادہ سے زیادہ ٹوکن ونڈو میں فٹ نہیں ہو سکتیں) - اور ماڈل کا ایک _حسب ضرورت_ ورژن تعینات کر رہے ہیں جسے انفرنس کے وقت مثالیں فراہم کرنے کی ضرورت نہیں ہوتی۔ یہ نہ صرف ہمارے پرامپٹ ڈیزائن کی مؤثریت کو بہتر بناتا ہے (ہم ٹوکن ونڈو کو دیگر چیزوں کے لیے زیادہ لچک کے ساتھ استعمال کر سکتے ہیں) بلکہ ممکنہ طور پر ہمارے اخراجات کو بھی کم کرتا ہے (انفرنس کے وقت ماڈل کو بھیجے جانے والے ٹوکنز کی تعداد کو کم کر کے)۔\n",
    "\n",
    "فائن ٹیوننگ کے 4 مراحل ہیں:\n",
    "1. تربیتی ڈیٹا تیار کریں اور اسے اپ لوڈ کریں۔\n",
    "1. فائن ٹیونڈ ماڈل حاصل کرنے کے لیے تربیتی کام چلائیں۔\n",
    "1. فائن ٹیونڈ ماڈل کا جائزہ لیں اور معیار کے لیے دوبارہ کوشش کریں۔\n",
    "1. جب مطمئن ہوں تو فائن ٹیونڈ ماڈل کو انفرنس کے لیے تعینات کریں۔\n",
    "\n",
    "نوٹ کریں کہ تمام فاؤنڈیشن ماڈلز فائن ٹیوننگ کی حمایت نہیں کرتے - تازہ ترین معلومات کے لیے [اوپن اے آئی دستاویزات](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) چیک کریں۔ آپ پہلے سے فائن ٹیونڈ ماڈل کو بھی دوبارہ فائن ٹیون کر سکتے ہیں۔ اس ٹیوٹوریل میں، ہم `gpt-35-turbo` کو فائن ٹیوننگ کے لیے اپنے ہدف فاؤنڈیشن ماڈل کے طور پر استعمال کریں گے۔\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### مرحلہ 1.1: اپنا ڈیٹا سیٹ تیار کریں\n",
    "\n",
    "آئیے ایک چیٹ بوٹ بنائیں جو آپ کو عناصر کی پیریوڈک ٹیبل کو سمجھنے میں مدد دے جو ایک عنصر کے بارے میں سوالات کے جواب ایک لیمریک کے ذریعے دیتا ہے۔ اس _سادہ_ ٹیوٹوریل میں، ہم صرف ایک ڈیٹا سیٹ بنائیں گے تاکہ ماڈل کو چند نمونہ جوابات کے ساتھ تربیت دی جا سکے جو ڈیٹا کے متوقع فارمیٹ کو ظاہر کرتے ہیں۔ حقیقی دنیا کے استعمال کے معاملے میں، آپ کو بہت زیادہ مثالوں کے ساتھ ایک ڈیٹا سیٹ تیار کرنے کی ضرورت ہوگی۔ آپ ایک کھلا ڈیٹا سیٹ بھی استعمال کر سکتے ہیں (اپنے درخواست کے دائرہ کار کے لیے) اگر کوئی موجود ہو، اور اسے فائن ٹیوننگ کے لیے دوبارہ فارمیٹ کر سکتے ہیں۔\n",
    "\n",
    "چونکہ ہم `gpt-35-turbo` پر توجہ مرکوز کر رہے ہیں اور ایک سنگل ٹرن جواب (چیٹ کمپلیشن) کی تلاش میں ہیں، ہم [اس تجویز کردہ فارمیٹ](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) کا استعمال کرتے ہوئے مثالیں بنا سکتے ہیں جو OpenAI چیٹ کمپلیشن کی ضروریات کی عکاسی کرتا ہے۔ اگر آپ کثیر ٹرن بات چیت کا مواد توقع کرتے ہیں، تو آپ [کثیر ٹرن مثال فارمیٹ](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) استعمال کریں گے جس میں `weight` پیرامیٹر شامل ہوتا ہے تاکہ یہ اشارہ کیا جا سکے کہ کون سے پیغامات فائن ٹیوننگ کے عمل میں استعمال ہونے چاہئیں (یا نہیں)۔\n",
    "\n",
    "ہم یہاں اپنے ٹیوٹوریل کے لیے آسان سنگل ٹرن فارمیٹ استعمال کریں گے۔ ڈیٹا [jsonl فارمیٹ](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) میں ہے جس میں ہر لائن پر 1 ریکارڈ ہوتا ہے، ہر ایک JSON فارمیٹڈ آبجیکٹ کی صورت میں پیش کیا جاتا ہے۔ نیچے دیا گیا ٹکڑا 2 ریکارڈز کو بطور نمونہ دکھاتا ہے - مکمل نمونہ سیٹ (10 مثالیں) کے لیے [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) دیکھیں جو ہم اپنے فائن ٹیوننگ ٹیوٹوریل کے لیے استعمال کریں گے۔ **نوٹ:** ہر ریکارڈ _ضرور_ ایک ہی لائن میں تعریف کیا جانا چاہیے (فارمیٹ شدہ JSON فائل کی طرح لائنوں میں تقسیم نہیں کیا جانا چاہیے)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "حقیقی دنیا کے استعمال کے معاملے میں آپ کو اچھے نتائج کے لیے بہت زیادہ مثالوں کا سیٹ درکار ہوگا - اس کا توازن جوابات کے معیار اور فائن ٹیوننگ کے وقت/لاگت کے درمیان ہوگا۔ ہم ایک چھوٹا سیٹ استعمال کر رہے ہیں تاکہ ہم فائن ٹیوننگ کو جلد مکمل کر سکیں اور عمل کی وضاحت کر سکیں۔ مزید پیچیدہ فائن ٹیوننگ ٹیوٹوریل کے لیے [اس OpenAI کک بک کی مثال](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) دیکھیں۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### مرحلہ 1.2 اپنا ڈیٹا سیٹ اپ لوڈ کریں\n",
    "\n",
    "ڈیٹا کو فائلز API کا استعمال کرتے ہوئے اپ لوڈ کریں [جیسا کہ یہاں بیان کیا گیا ہے](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file)۔ نوٹ کریں کہ اس کوڈ کو چلانے کے لیے، آپ کو پہلے درج ذیل مراحل مکمل کرنے ہوں گے:\n",
    " - `openai` پائتھن پیکیج انسٹال کیا ہوا ہو (یقینی بنائیں کہ آپ ورژن >=0.28.0 استعمال کر رہے ہیں تاکہ تازہ ترین خصوصیات دستیاب ہوں)\n",
    " - `OPENAI_API_KEY` ماحول کی متغیر کو اپنے OpenAI API کلید پر سیٹ کیا ہوا ہو\n",
    "مزید جاننے کے لیے، کورس کے لیے فراہم کردہ [سیٹ اپ گائیڈ](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) دیکھیں۔\n",
    "\n",
    "اب، اپنے مقامی JSONL فائل سے اپ لوڈ کے لیے فائل بنانے کے لیے کوڈ چلائیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### مرحلہ 2.1: SDK کے ساتھ Fine-tuning جاب بنائیں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### مرحلہ 2.2: کام کی حیثیت چیک کریں\n",
    "\n",
    "یہاں کچھ چیزیں ہیں جو آپ `client.fine_tuning.jobs` API کے ساتھ کر سکتے ہیں:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - آخری n فائن ٹیوننگ کاموں کی فہرست بنائیں\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - کسی مخصوص فائن ٹیوننگ کام کی تفصیلات حاصل کریں\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - فائن ٹیوننگ کام منسوخ کریں\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - کام سے n تک واقعات کی فہرست بنائیں\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "عمل کا پہلا مرحلہ _تربیتی فائل کی تصدیق_ ہے تاکہ یہ یقینی بنایا جا سکے کہ ڈیٹا صحیح فارمیٹ میں ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### مرحلہ 2.3: پیش رفت کی نگرانی کے لیے واقعات کو ٹریک کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### مرحلہ 2.4: اوپن اے آئی ڈیش بورڈ میں حیثیت دیکھیں\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "آپ اوپن اے آئی کی ویب سائٹ پر جا کر اور پلیٹ فارم کے _Fine-tuning_ سیکشن کو دریافت کر کے بھی اسٹیٹس دیکھ سکتے ہیں۔ یہ آپ کو موجودہ کام کی حالت دکھائے گا، اور آپ کو پچھلے کام کی انجام دہی کی تاریخ کو بھی ٹریک کرنے دے گا۔ اس اسکرین شاٹ میں، آپ دیکھ سکتے ہیں کہ پچھلی انجام دہی ناکام ہوئی، اور دوسری بار چلانے میں کامیابی حاصل ہوئی۔ سیاق و سباق کے لیے، یہ اس وقت ہوا جب پہلی بار چلانے میں JSON فائل میں غلط فارمیٹ کیے گئے ریکارڈز استعمال ہوئے تھے - ایک بار درست ہونے کے بعد، دوسری بار چلانا کامیابی سے مکمل ہوا اور ماڈل کو استعمال کے لیے دستیاب کر دیا گیا۔ \n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ur/fine-tuned-model-status.563271727bf7bfba.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "آپ بصری ڈیش بورڈ میں نیچے مزید سکرول کر کے اسٹیٹس پیغامات اور میٹرکس بھی دیکھ سکتے ہیں جیسا کہ دکھایا گیا ہے:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/ur/fine-tuned-messages-panel.4ed0c2da5ea1313b.webp) |  ![Metrics](../../../../../translated_images/ur/fine-tuned-metrics-panel.700d7e4995a65229.webp)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### مرحلہ 3.1: کوڈ میں ID حاصل کریں اور فائن ٹیونڈ ماڈل کا ٹیسٹ کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### مرحلہ 3.2: فائن ٹونڈ ماڈل کو پلے گراؤنڈ میں لوڈ اور ٹیسٹ کریں\n",
    "\n",
    "اب آپ فائن ٹونڈ ماڈل کو دو طریقوں سے ٹیسٹ کر سکتے ہیں۔ سب سے پہلے، آپ پلے گراؤنڈ پر جا کر ماڈلز ڈراپ ڈاؤن سے اپنی نئی فائن ٹونڈ ماڈل کو منتخب کر سکتے ہیں جو اختیارات میں شامل ہے۔ دوسرا طریقہ \"Playground\" آپشن استعمال کرنا ہے جو فائن ٹوننگ پینل میں دکھایا گیا ہے (اوپر اسکرین شاٹ دیکھیں) جو درج ذیل _موازنہ_ ویو کو لانچ کرتا ہے جو بنیاد اور فائن ٹونڈ ماڈل ورژنز کو ایک ساتھ تیز جائزے کے لیے دکھاتا ہے۔\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ur/fine-tuned-playground-compare.56e06f0ad8922016.webp)\n",
    "\n",
    "بس اپنے تربیتی ڈیٹا میں استعمال ہونے والے سسٹم کانٹیکسٹ کو بھر دیں اور اپنا ٹیسٹ سوال فراہم کریں۔ آپ دیکھیں گے کہ دونوں طرف ایک ہی کانٹیکسٹ اور سوال اپ ڈیٹ ہو جاتے ہیں۔ موازنہ چلائیں اور آپ ان کے آؤٹ پٹ میں فرق دیکھیں گے۔ _نوٹ کریں کہ فائن ٹونڈ ماڈل آپ کی مثالوں میں فراہم کردہ فارمیٹ میں جواب دیتا ہے جبکہ بنیاد ماڈل صرف سسٹم پرامپٹ کی پیروی کرتا ہے_۔\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ur/fine-tuned-playground-launch.5a26495c983c6350.webp)\n",
    "\n",
    "آپ دیکھیں گے کہ موازنہ ہر ماڈل کے لیے ٹوکن کی تعداد اور انفرنس کے لیے لگنے والا وقت بھی فراہم کرتا ہے۔ **یہ مخصوص مثال ایک سادہ سی ہے جو عمل دکھانے کے لیے ہے لیکن حقیقی دنیا کے ڈیٹا سیٹ یا منظر نامے کی عکاسی نہیں کرتی**۔ آپ دیکھ سکتے ہیں کہ دونوں نمونوں میں ٹوکن کی تعداد ایک جیسی ہے (سسٹم کانٹیکسٹ اور یوزر پرامپٹ ایک جیسے ہیں) جبکہ فائن ٹونڈ ماڈل انفرنس کے لیے زیادہ وقت لیتا ہے (کسٹم ماڈل)۔\n",
    "\n",
    "حقیقی دنیا کے منظر ناموں میں، آپ اس طرح کی سادہ مثال استعمال نہیں کریں گے، بلکہ حقیقی ڈیٹا کے خلاف فائن ٹوننگ کریں گے (مثلاً، کسٹمر سروس کے لیے پروڈکٹ کیٹلاگ) جہاں جواب کی معیار زیادہ واضح ہوگی۔ _اس سیاق و سباق میں، بنیاد ماڈل کے ساتھ مساوی جواب کی معیار حاصل کرنے کے لیے زیادہ کسٹم پرامپٹ انجینئرنگ کی ضرورت ہوگی جو ٹوکن کے استعمال کو بڑھائے گی اور ممکنہ طور پر انفرنس کے لیے متعلقہ پروسیسنگ وقت کو بھی بڑھائے گی۔_ _اسے آزمانے کے لیے، OpenAI Cookbook میں فائن ٹوننگ کی مثالیں دیکھیں اور شروع کریں۔_\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**دستخطی نوٹ**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم اس بات سے آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں ہی معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر عائد نہیں ہوتی۔\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T09:04:40+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}