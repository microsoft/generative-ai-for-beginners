{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تعارف\n",
    "\n",
    "اس سبق میں شامل ہے:\n",
    "- فنکشن کالنگ کیا ہے اور اس کے استعمالات\n",
    "- Azure OpenAI کے ذریعے فنکشن کال کیسے بنائی جاتی ہے\n",
    "- فنکشن کال کو ایپلیکیشن میں کیسے شامل کیا جاتا ہے\n",
    "\n",
    "## سیکھنے کے مقاصد\n",
    "\n",
    "یہ سبق مکمل کرنے کے بعد آپ جان جائیں گے اور سمجھ جائیں گے کہ:\n",
    "\n",
    "- فنکشن کالنگ کے استعمال کا مقصد کیا ہے\n",
    "- Azure Open AI سروس کے ذریعے فنکشن کال کیسے سیٹ اپ کی جاتی ہے\n",
    "- اپنی ایپلیکیشن کے استعمال کے مطابق مؤثر فنکشن کالز کیسے ڈیزائن کی جاتی ہیں\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## فنکشن کالز کو سمجھنا\n",
    "\n",
    "اس سبق میں، ہم اپنی ایجوکیشن اسٹارٹ اپ کے لیے ایک فیچر بنانا چاہتے ہیں جس سے صارفین چیٹ بوٹ کے ذریعے ٹیکنیکل کورسز تلاش کر سکیں۔ ہم ایسے کورسز تجویز کریں گے جو ان کی مہارت کی سطح، موجودہ کردار اور دلچسپی کی ٹیکنالوجی کے مطابق ہوں۔\n",
    "\n",
    "اس مقصد کو حاصل کرنے کے لیے ہم درج ذیل چیزوں کا امتزاج استعمال کریں گے:\n",
    " - `Azure Open AI` تاکہ صارف کے لیے چیٹ کا تجربہ بنایا جا سکے\n",
    " - `Microsoft Learn Catalog API` تاکہ صارف کی درخواست کے مطابق کورسز تلاش کرنے میں مدد ملے\n",
    " - `Function Calling` تاکہ صارف کی کوئری کو لے کر اسے ایک فنکشن کے ذریعے API ریکویسٹ میں بھیجا جا سکے\n",
    "\n",
    "شروع کرنے سے پہلے، آئیے دیکھتے ہیں کہ ہم فنکشن کالنگ کیوں استعمال کرنا چاہتے ہیں:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT سے نیا جواب حاصل کریں جہاں وہ فنکشن کا جواب دیکھ سکتا ہے\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کالنگ کیوں؟\n",
    "\n",
    "اگر آپ نے اس کورس کا کوئی اور سبق مکمل کیا ہے، تو آپ شاید یہ سمجھتے ہوں گے کہ بڑے لینگویج ماڈلز (LLMs) کا استعمال کتنا طاقتور ہے۔ امید ہے کہ آپ ان کی کچھ حدود کو بھی دیکھ سکتے ہیں۔\n",
    "\n",
    "فنکشن کالنگ، ایزور اوپن اے آئی سروس کی ایک خصوصیت ہے جو درج ذیل مسائل کو حل کرنے کے لیے متعارف کرائی گئی ہے:\n",
    "1) مستقل اور ایک جیسے جواب کا فارمیٹ  \n",
    "2) چیٹ کے دوران ایپلیکیشن کے دوسرے ذرائع سے ڈیٹا استعمال کرنے کی صلاحیت\n",
    "\n",
    "فنکشن کالنگ سے پہلے، LLM سے ملنے والے جوابات غیر منظم اور غیر مستقل ہوتے تھے۔ ڈویلپرز کو ہر قسم کے جواب کو سنبھالنے کے لیے پیچیدہ ویلیڈیشن کوڈ لکھنا پڑتا تھا۔\n",
    "\n",
    "صارفین ایسے سوالات کے جواب نہیں حاصل کر سکتے تھے جیسے \"اسٹاک ہوم میں اس وقت موسم کیسا ہے؟\"۔ اس کی وجہ یہ ہے کہ ماڈلز صرف اس ڈیٹا تک محدود تھے جس پر انہیں تربیت دی گئی تھی۔\n",
    "\n",
    "آئیے نیچے دی گئی مثال دیکھتے ہیں جو اس مسئلے کو واضح کرتی ہے:\n",
    "\n",
    "فرض کریں ہم طلبہ کا ڈیٹا بیس بنانا چاہتے ہیں تاکہ ہم انہیں ان کے لیے موزوں کورس تجویز کر سکیں۔ نیچے دو طلبہ کی تفصیلات دی گئی ہیں جن میں موجود معلومات کافی ملتی جلتی ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ہم یہ ڈیٹا کسی ایل ایل ایم کو بھیجنا چاہتے ہیں تاکہ وہ اس ڈیٹا کو پارس کرے۔ بعد میں ہم اسے اپنی ایپلیکیشن میں کسی اے پی آئی کو بھیجنے یا ڈیٹا بیس میں محفوظ کرنے کے لیے استعمال کر سکتے ہیں۔\n",
    "\n",
    "آئیے دو ایک جیسے پرامپٹس بناتے ہیں جن میں ہم ایل ایل ایم کو ہدایت دیتے ہیں کہ ہمیں کس معلومات میں دلچسپی ہے:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ہم یہ ایک ایل ایل ایم کو بھیجنا چاہتے ہیں تاکہ وہ ہمارے پروڈکٹ کے لیے اہم حصوں کو تجزیہ کر سکے۔ اس لیے ہم دو ایک جیسے پرامپٹس بنا سکتے ہیں تاکہ ایل ایل ایم کو ہدایت دی جا سکے:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ان دو پرامپٹس کو بنانے کے بعد، ہم انہیں LLM کو `openai.ChatCompletion` استعمال کرتے ہوئے بھیجیں گے۔ ہم پرامپٹ کو `messages` ویری ایبل میں محفوظ کرتے ہیں اور رول کو `user` تفویض کرتے ہیں۔ اس کا مقصد یہ ہے کہ ایک صارف کی طرف سے چیٹ بوٹ کو بھیجا گیا پیغام نقل کیا جائے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم دونوں درخواستیں ایل ایل ایم کو بھیج سکتے ہیں اور جو جواب ہمیں موصول ہوتا ہے اس کا جائزہ لے سکتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگرچہ پرامپٹس ایک جیسے ہیں اور وضاحتیں بھی ملتی جلتی ہیں، لیکن ہمیں `Grades` پراپرٹی کی مختلف فارمیٹس مل سکتی ہیں۔\n",
    "\n",
    "اگر آپ اوپر والے سیل کو کئی بار چلائیں، تو فارمیٹ `3.7` یا `3.7 GPA` ہو سکتی ہے۔\n",
    "\n",
    "اس کی وجہ یہ ہے کہ LLM غیر ساختہ ڈیٹا کو تحریری پرامپٹ کی صورت میں لیتا ہے اور غیر ساختہ ڈیٹا ہی واپس کرتا ہے۔ ہمیں ایک ساختہ فارمیٹ کی ضرورت ہے تاکہ جب ہم اس ڈیٹا کو اسٹور یا استعمال کریں تو ہمیں معلوم ہو کہ کیا توقع کرنی ہے۔\n",
    "\n",
    "فنکشنل کالنگ استعمال کر کے ہم یہ یقینی بنا سکتے ہیں کہ ہمیں ساختہ ڈیٹا واپس ملے۔ فنکشن کالنگ کے دوران، LLM دراصل کوئی فنکشن کال یا چلانے کا عمل نہیں کرتا۔ اس کے بجائے، ہم LLM کے لیے ایک ساختہ خاکہ بناتے ہیں جس کی وہ اپنی جوابات میں پیروی کرے۔ پھر ہم انہی ساختہ جوابات کو استعمال کر کے اپنی ایپلیکیشنز میں یہ طے کرتے ہیں کہ کون سا فنکشن چلانا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![فنکشن کالنگ فلو ڈایاگرام](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ur.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کالز کے استعمال کے لیے استعمال کی مثالیں\n",
    "\n",
    "**بیرونی ٹولز کو کال کرنا**  \n",
    "چیٹ بوٹس صارفین کے سوالات کے جوابات دینے میں بہترین ہیں۔ فنکشن کالنگ کے ذریعے، چیٹ بوٹس صارفین کے پیغامات کو استعمال کر کے مخصوص کام انجام دے سکتے ہیں۔ مثال کے طور پر، ایک طالب علم چیٹ بوٹ سے کہہ سکتا ہے: \"میرے انسٹرکٹر کو ای میل بھیجیں کہ مجھے اس مضمون میں مزید مدد چاہیے\"۔ اس کے لیے `send_email(to: string, body: string)` فنکشن کال کی جا سکتی ہے۔\n",
    "\n",
    "**API یا ڈیٹا بیس کوئریز بنانا**  \n",
    "صارفین قدرتی زبان میں معلومات تلاش کر سکتے ہیں، جو ایک فارمیٹڈ کوئری یا API ریکویسٹ میں تبدیل ہو جاتی ہے۔ اس کی ایک مثال یہ ہو سکتی ہے کہ ایک استاد پوچھے: \"کون سے طلبہ نے آخری اسائنمنٹ مکمل کیا ہے\"، جس کے لیے `get_completed(student_name: string, assignment: int, current_status: string)` نامی فنکشن کال کی جا سکتی ہے۔\n",
    "\n",
    "**اسٹرکچرڈ ڈیٹا بنانا**  \n",
    "صارفین کسی ٹیکسٹ بلاک یا CSV کو لے کر LLM کی مدد سے اس میں سے اہم معلومات نکال سکتے ہیں۔ مثال کے طور پر، ایک طالب علم وکی پیڈیا کے کسی مضمون کو امن معاہدوں کے بارے میں لے کر AI فلیش کارڈز بنا سکتا ہے۔ یہ کام `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` فنکشن کے ذریعے کیا جا سکتا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. اپنی پہلی فنکشن کال بنانا\n",
    "\n",
    "فنکشن کال بنانے کا عمل تین اہم مراحل پر مشتمل ہے:\n",
    "1. چیٹ کمپلیشنز API کو اپنی فنکشنز کی فہرست اور یوزر کے پیغام کے ساتھ کال کرنا\n",
    "2. ماڈل کے جواب کو پڑھنا تاکہ کوئی عمل کیا جا سکے، مثلاً فنکشن یا API کال کو چلانا\n",
    "3. اپنی فنکشن کے جواب کے ساتھ دوبارہ چیٹ کمپلیشنز API کو کال کرنا تاکہ اس معلومات کو استعمال کرتے ہوئے یوزر کے لیے جواب تیار کیا جا سکے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![فنکشن کال کا بہاؤ](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ur.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کال کے عناصر\n",
    "\n",
    "#### صارف کی ان پٹ\n",
    "\n",
    "پہلا قدم یہ ہے کہ ایک صارف پیغام تیار کیا جائے۔ یہ پیغام آپ کسی ٹیکسٹ ان پٹ کی ویلیو لے کر متحرک طور پر بھی دے سکتے ہیں یا یہاں پر کوئی ویلیو مقرر کر سکتے ہیں۔ اگر آپ پہلی بار Chat Completions API کے ساتھ کام کر رہے ہیں تو ہمیں پیغام کا `role` اور `content` متعین کرنا ہوگا۔\n",
    "\n",
    "`role` تین میں سے کوئی ایک ہو سکتا ہے: `system` (قوانین بنانا)، `assistant` (ماڈل) یا `user` (آخری صارف)۔ فنکشن کالنگ کے لیے ہم اسے `user` مقرر کریں گے اور ایک مثال کے طور پر سوال دیں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشنز بنانا\n",
    "\n",
    "اب ہم ایک فنکشن اور اس کے پیرامیٹرز کو متعین کریں گے۔ یہاں ہم صرف ایک فنکشن استعمال کریں گے جس کا نام `search_courses` ہے، لیکن آپ چاہیں تو کئی فنکشنز بھی بنا سکتے ہیں۔\n",
    "\n",
    "**اہم** : فنکشنز سسٹم میسج میں LLM کو شامل کیے جاتے ہیں اور یہ آپ کے دستیاب ٹوکنز کی تعداد میں شمار ہوں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**تعریفیں**\n",
    "\n",
    "`name` - اس فنکشن کا نام جسے ہم کال کرنا چاہتے ہیں۔\n",
    "\n",
    "`description` - یہ اس بات کی وضاحت ہے کہ فنکشن کیسے کام کرتا ہے۔ یہاں واضح اور مخصوص ہونا ضروری ہے۔\n",
    "\n",
    "`parameters` - ان اقدار اور فارمیٹ کی فہرست جو آپ چاہتے ہیں کہ ماڈل اپنے جواب میں فراہم کرے۔\n",
    "\n",
    "`type` - ان پراپرٹیز کی ڈیٹا ٹائپ جس میں انہیں محفوظ کیا جائے گا۔\n",
    "\n",
    "`properties` - ان مخصوص اقدار کی فہرست جو ماڈل اپنے جواب کے لیے استعمال کرے گا۔\n",
    "\n",
    "`name` - اس پراپرٹی کا نام جو ماڈل اپنے فارمیٹڈ جواب میں استعمال کرے گا۔\n",
    "\n",
    "`type` - اس پراپرٹی کی ڈیٹا ٹائپ۔\n",
    "\n",
    "`description` - اس مخصوص پراپرٹی کی وضاحت۔\n",
    "\n",
    "**اختیاری**\n",
    "\n",
    "`required` - وہ لازمی پراپرٹی جس کے بغیر فنکشن کال مکمل نہیں ہو سکتی۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کال کرنا  \n",
    "فنکشن کو ڈیفائن کرنے کے بعد، اب ہمیں اسے چیٹ کمپلیشن API کی کال میں شامل کرنا ہے۔ یہ ہم درخواست میں `functions` شامل کر کے کرتے ہیں۔ اس مثال میں `functions=functions` لکھا گیا ہے۔\n",
    "\n",
    "ایک اور آپشن یہ ہے کہ `function_call` کو `auto` پر سیٹ کر دیا جائے۔ اس کا مطلب ہے کہ ہم LLM کو یہ فیصلہ کرنے دیں گے کہ صارف کے پیغام کی بنیاد پر کون سا فنکشن کال ہونا چاہیے، بجائے اس کے کہ ہم خود اسے منتخب کریں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب آئیے جواب کو دیکھتے ہیں اور اس کی ترتیب کو سمجھتے ہیں:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "آپ دیکھ سکتے ہیں کہ فنکشن کا نام پکارا گیا ہے اور صارف کے پیغام سے، LLM نے دلائل کے لیے ڈیٹا تلاش کر لیا ہے تاکہ فنکشن میں فٹ ہو سکے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ایپلیکیشن میں فنکشن کالز کو شامل کرنا\n",
    "\n",
    "جب ہم نے LLM سے حاصل شدہ فارمیٹڈ جواب کو آزما لیا، اب ہم اسے اپنی ایپلیکیشن میں شامل کر سکتے ہیں۔\n",
    "\n",
    "### بہاؤ کو منظم کرنا\n",
    "\n",
    "اسے اپنی ایپلیکیشن میں شامل کرنے کے لیے، آئیے درج ذیل مراحل اختیار کرتے ہیں:\n",
    "\n",
    "سب سے پہلے، آئیے Open AI سروسز کو کال کرتے ہیں اور پیغام کو `response_message` نامی ویری ایبل میں محفوظ کرتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم اس فنکشن کی تعریف کریں گے جو مائیکروسافٹ لرن اے پی آئی کو کال کرے گا تاکہ کورسز کی فہرست حاصل کی جا سکے:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ایک بہترین طریقہ کار کے طور پر، ہم سب سے پہلے دیکھیں گے کہ آیا ماڈل کسی فنکشن کو کال کرنا چاہتا ہے۔ اس کے بعد، ہم دستیاب فنکشنز میں سے ایک فنکشن بنائیں گے اور اسے اس فنکشن سے ملائیں گے جسے کال کیا جا رہا ہے۔\n",
    "پھر ہم فنکشن کے دلائل لیں گے اور انہیں LLM سے آنے والے دلائل کے ساتھ میپ کریں گے۔\n",
    "\n",
    "آخر میں، ہم فنکشن کال میسج اور وہ اقدار شامل کریں گے جو `search_courses` میسج سے واپس آئیں۔ اس سے LLM کو وہ تمام معلومات مل جاتی ہیں جن کی اسے صارف کو قدرتی زبان میں جواب دینے کے لیے ضرورت ہوتی ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## کوڈ چیلنج\n",
    "\n",
    "زبردست کام! Azure Open AI Function Calling سیکھنے کو آگے بڑھانے کے لیے آپ یہ بنا سکتے ہیں: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - فنکشن کے مزید پیرامیٹرز شامل کریں جو سیکھنے والوں کو مزید کورسز تلاش کرنے میں مدد دے سکتے ہیں۔ آپ یہاں دستیاب API پیرامیٹرز دیکھ سکتے ہیں:  \n",
    " - ایک اور فنکشن کال بنائیں جو سیکھنے والے سے مزید معلومات لے، جیسے کہ ان کی مادری زبان  \n",
    " - ایرر ہینڈلنگ شامل کریں جب فنکشن کال اور/یا API کال کوئی مناسب کورس واپس نہ کرے\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**اعلانِ دستبرداری**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کی پوری کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہے۔ اصل دستاویز کو اس کی اصل زبان میں مستند ماخذ سمجھا جانا چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ تجویز کیا جاتا ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر نہیں ہوگی۔\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T19:57:35+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}