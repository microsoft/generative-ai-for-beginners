{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تعارف\n",
    "\n",
    "اس سبق میں شامل ہے:\n",
    "- فنکشن کالنگ کیا ہے اور اس کے استعمالات\n",
    "- اوپن اے آئی کے ذریعے فنکشن کال کیسے بنائی جائے\n",
    "- فنکشن کال کو ایپلیکیشن میں کیسے شامل کیا جائے\n",
    "\n",
    "## سیکھنے کے مقاصد\n",
    "\n",
    "یہ سبق مکمل کرنے کے بعد آپ جان جائیں گے اور سمجھ جائیں گے کہ:\n",
    "\n",
    "- فنکشن کالنگ کے استعمال کا مقصد کیا ہے\n",
    "- اوپن اے آئی سروس کے ذریعے فنکشن کال سیٹ اپ کرنا\n",
    "- اپنی ایپلیکیشن کے استعمال کے مطابق مؤثر فنکشن کالز ڈیزائن کرنا\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## فنکشن کالز کو سمجھنا\n",
    "\n",
    "اس سبق میں، ہم اپنی ایجوکیشن اسٹارٹ اپ کے لیے ایک فیچر بنانا چاہتے ہیں جس سے صارفین چیٹ بوٹ کے ذریعے ٹیکنیکل کورسز تلاش کر سکیں۔ ہم ایسے کورسز تجویز کریں گے جو ان کی مہارت کی سطح، موجودہ کردار اور دلچسپی کی ٹیکنالوجی کے مطابق ہوں۔\n",
    "\n",
    "اس مقصد کو حاصل کرنے کے لیے ہم درج ذیل چیزوں کا امتزاج استعمال کریں گے:\n",
    " - `OpenAI` تاکہ صارف کے لیے چیٹ کا تجربہ بنایا جا سکے\n",
    " - `Microsoft Learn Catalog API` تاکہ صارف کی درخواست کے مطابق کورسز تلاش کرنے میں مدد ملے\n",
    " - `Function Calling` تاکہ صارف کی کوئری کو لے کر اسے ایک فنکشن کے ذریعے API ریکویسٹ میں بھیجا جا سکے\n",
    "\n",
    "شروع کرنے کے لیے، آئیے دیکھتے ہیں کہ ہم سب سے پہلے فنکشن کالنگ کیوں استعمال کرنا چاہتے ہیں:\n",
    "\n",
    "print(\"اگلی درخواست میں پیغامات:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT سے نیا جواب حاصل کریں جہاں وہ فنکشن کا جواب دیکھ سکتا ہے\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کالنگ کیوں؟\n",
    "\n",
    "اگر آپ نے اس کورس کا کوئی اور سبق مکمل کیا ہے، تو آپ شاید بڑے لینگویج ماڈلز (LLMs) کی طاقت کو سمجھتے ہوں گے۔ امید ہے کہ آپ ان کی کچھ حدود کو بھی دیکھ سکتے ہیں۔\n",
    "\n",
    "فنکشن کالنگ، اوپن اے آئی سروس کی ایک خصوصیت ہے جو درج ذیل مسائل کو حل کرنے کے لیے بنائی گئی ہے:\n",
    "\n",
    "غیر مستقل جواب کی فارمیٹنگ:\n",
    "- فنکشن کالنگ سے پہلے، بڑے لینگویج ماڈل سے ملنے والے جوابات غیر منظم اور غیر مستقل ہوتے تھے۔ ڈویلپرز کو ہر مختلف آؤٹ پٹ کے لیے پیچیدہ ویلیڈیشن کوڈ لکھنا پڑتا تھا۔\n",
    "\n",
    "بیرونی ڈیٹا کے ساتھ محدود انضمام:\n",
    "- اس خصوصیت سے پہلے، ایپلیکیشن کے دوسرے حصوں سے ڈیٹا کو چیٹ کے سیاق و سباق میں شامل کرنا مشکل تھا۔\n",
    "\n",
    "جواب کی فارمیٹس کو معیاری بنا کر اور بیرونی ڈیٹا کے ساتھ آسان انضمام کو ممکن بنا کر، فنکشن کالنگ ڈیولپمنٹ کو آسان بناتی ہے اور اضافی ویلیڈیشن لاجک کی ضرورت کو کم کرتی ہے۔\n",
    "\n",
    "صارفین اس طرح کے سوالات کے جوابات حاصل نہیں کر سکتے تھے جیسے \"اسٹاک ہوم میں اس وقت موسم کیسا ہے؟\"۔ اس کی وجہ یہ ہے کہ ماڈلز صرف اس وقت تک محدود تھے جب تک ان پر ڈیٹا ٹرین کیا گیا تھا۔\n",
    "\n",
    "آئیے نیچے دی گئی مثال دیکھتے ہیں جو اس مسئلے کو واضح کرتی ہے:\n",
    "\n",
    "فرض کریں ہم طلبہ کا ڈیٹا بیس بنانا چاہتے ہیں تاکہ ہم انہیں ان کے لیے موزوں کورس تجویز کر سکیں۔ نیچے ہمارے پاس دو طلبہ کی تفصیلات ہیں جو اپنے ڈیٹا میں کافی حد تک ملتی جلتی ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ہم یہ ڈیٹا کسی ایل ایل ایم کو بھیجنا چاہتے ہیں تاکہ وہ اس ڈیٹا کو پارس کرے۔ بعد میں ہم اسے اپنی ایپلیکیشن میں کسی اے پی آئی کو بھیجنے یا ڈیٹا بیس میں محفوظ کرنے کے لیے استعمال کر سکتے ہیں۔\n",
    "\n",
    "آئیے دو ایک جیسے پرامپٹس بناتے ہیں جن میں ہم ایل ایل ایم کو ہدایت دیتے ہیں کہ ہمیں کس معلومات میں دلچسپی ہے:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ہم یہ ایک ایل ایل ایم کو بھیجنا چاہتے ہیں تاکہ وہ ہمارے پروڈکٹ کے لیے اہم حصوں کو تجزیہ کر سکے۔ اس لیے ہم دو ایک جیسے پرامپٹس بنا سکتے ہیں تاکہ ایل ایل ایم کو ہدایت دی جا سکے:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ان دو پرامپٹس کو بنانے کے بعد، ہم انہیں LLM کو `openai.ChatCompletion` کے ذریعے بھیجیں گے۔ ہم پرامپٹ کو `messages` ویری ایبل میں محفوظ کرتے ہیں اور رول کو `user` تفویض کرتے ہیں۔ یہ اس لیے ہے کہ ایک صارف کی طرف سے چیٹ بوٹ کو بھیجا گیا پیغام نقل کیا جا سکے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم دونوں درخواستیں ایل ایل ایم کو بھیج سکتے ہیں اور جو جواب ہمیں موصول ہوتا ہے اس کا جائزہ لے سکتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگرچہ پرامپٹس ایک جیسے ہیں اور وضاحتیں بھی ملتی جلتی ہیں، پھر بھی ہمیں `Grades` پراپرٹی کی مختلف فارمیٹس مل سکتی ہیں۔\n",
    "\n",
    "اگر آپ اوپر والے سیل کو کئی بار چلائیں، تو فارمیٹ `3.7` یا `3.7 GPA` ہو سکتی ہے۔\n",
    "\n",
    "اس کی وجہ یہ ہے کہ LLM غیر منظم ڈیٹا کو تحریری پرامپٹ کی صورت میں لیتا ہے اور غیر منظم ڈیٹا ہی واپس کرتا ہے۔ ہمیں ایک منظم فارمیٹ کی ضرورت ہے تاکہ جب ہم یہ ڈیٹا اسٹور کریں یا استعمال کریں تو ہمیں معلوم ہو کہ کیا توقع کرنی ہے۔\n",
    "\n",
    "فنکشنل کالنگ استعمال کر کے ہم یہ یقینی بنا سکتے ہیں کہ ہمیں منظم ڈیٹا واپس ملے۔ فنکشن کالنگ استعمال کرتے وقت، LLM اصل میں کوئی فنکشن کال یا چلانے نہیں کرتا۔ اس کے بجائے، ہم LLM کے جوابات کے لیے ایک ساخت تیار کرتے ہیں جس کی وہ پیروی کرے۔ پھر ہم انہی منظم جوابات کو استعمال کرتے ہیں تاکہ اپنی ایپلیکیشنز میں کون سا فنکشن چلانا ہے، یہ جان سکیں۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![فنکشن کالنگ فلو ڈایاگرام](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ur.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کالز کے استعمال کے لیے استعمال کی مثالیں\n",
    "\n",
    "**بیرونی ٹولز کو کال کرنا**  \n",
    "چیٹ بوٹس صارفین کے سوالات کے جوابات دینے میں بہترین ہیں۔ فنکشن کالنگ کے ذریعے، چیٹ بوٹس صارفین کے پیغامات کو استعمال کر کے مخصوص کام انجام دے سکتے ہیں۔ مثال کے طور پر، ایک طالب علم چیٹ بوٹ سے کہہ سکتا ہے: \"میرے انسٹرکٹر کو ای میل بھیجیں کہ مجھے اس مضمون میں مزید مدد چاہیے\"۔ اس کے لیے `send_email(to: string, body: string)` فنکشن کال کی جا سکتی ہے۔\n",
    "\n",
    "**API یا ڈیٹا بیس کوئریز بنانا**  \n",
    "صارفین قدرتی زبان میں معلومات تلاش کر سکتے ہیں، جو ایک فارمیٹڈ کوئری یا API ریکویسٹ میں تبدیل ہو جاتی ہے۔ اس کی ایک مثال یہ ہو سکتی ہے کہ ایک استاد پوچھے: \"کون سے طلبہ نے آخری اسائنمنٹ مکمل کی ہے\"، جس کے لیے `get_completed(student_name: string, assignment: int, current_status: string)` نامی فنکشن کال کی جا سکتی ہے۔\n",
    "\n",
    "**اسٹرکچرڈ ڈیٹا بنانا**  \n",
    "صارفین کسی ٹیکسٹ بلاک یا CSV کو لے کر LLM کی مدد سے اس میں سے اہم معلومات نکال سکتے ہیں۔ مثال کے طور پر، ایک طالب علم وکی پیڈیا کے کسی مضمون کو امن معاہدوں کے بارے میں لے کر AI فلیش کارڈز بنا سکتا ہے۔ یہ کام `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` فنکشن کے ذریعے کیا جا سکتا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. اپنی پہلی فنکشن کال بنانا\n",
    "\n",
    "فنکشن کال بنانے کا عمل تین اہم مراحل پر مشتمل ہے:\n",
    "1. چیٹ کمپلیشنز API کو اپنی فنکشنز کی فہرست اور یوزر کے پیغام کے ساتھ کال کریں\n",
    "2. ماڈل کے جواب کو پڑھیں تاکہ کوئی عمل کیا جا سکے، یعنی فنکشن یا API کال کو چلائیں\n",
    "3. اپنی فنکشن کے جواب کے ساتھ دوبارہ چیٹ کمپلیشنز API کو کال کریں تاکہ اس معلومات کو استعمال کرتے ہوئے یوزر کے لیے جواب تیار کیا جا سکے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![فنکشن کال کا بہاؤ](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ur.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کال کے عناصر\n",
    "\n",
    "#### صارف کی ان پٹ\n",
    "\n",
    "پہلا قدم یہ ہے کہ ایک صارف پیغام تیار کیا جائے۔ یہ پیغام آپ کسی ٹیکسٹ ان پٹ کی ویلیو لے کر متحرک طور پر بھی دے سکتے ہیں یا یہاں پر کوئی ویلیو مقرر کر سکتے ہیں۔ اگر آپ پہلی بار Chat Completions API کے ساتھ کام کر رہے ہیں تو ہمیں پیغام کا `role` اور `content` متعین کرنا ہوگا۔\n",
    "\n",
    "`role` تین میں سے کوئی ایک ہو سکتا ہے: `system` (قوانین بنانا)، `assistant` (ماڈل) یا `user` (آخری صارف)۔ فنکشن کالنگ کے لیے ہم اسے `user` مقرر کریں گے اور ایک مثال کے طور پر سوال دیں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشنز بنانا\n",
    "\n",
    "اب ہم ایک فنکشن اور اس فنکشن کے پیرامیٹرز کو متعین کریں گے۔ یہاں ہم صرف ایک فنکشن استعمال کریں گے جس کا نام `search_courses` ہے، لیکن آپ چاہیں تو کئی فنکشنز بھی بنا سکتے ہیں۔\n",
    "\n",
    "**اہم** : فنکشنز سسٹم میسج میں LLM کو شامل کیے جاتے ہیں اور یہ آپ کے دستیاب ٹوکنز کی تعداد میں شمار ہوں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**تعریفیں**\n",
    "\n",
    "فنکشن کی تعریف کا ڈھانچہ کئی سطحوں پر مشتمل ہوتا ہے، اور ہر سطح کی اپنی خصوصیات ہوتی ہیں۔ یہاں اس اندرونی ڈھانچے کی وضاحت پیش کی جا رہی ہے:\n",
    "\n",
    "**فنکشن کی سب سے اوپر والی خصوصیات:**\n",
    "\n",
    "`name` - اس فنکشن کا نام جسے ہم کال کرنا چاہتے ہیں۔\n",
    "\n",
    "`description` - یہ اس بات کی وضاحت ہے کہ فنکشن کیسے کام کرتا ہے۔ یہاں واضح اور مخصوص ہونا ضروری ہے۔\n",
    "\n",
    "`parameters` - ان اقدار اور فارمیٹ کی فہرست جو آپ چاہتے ہیں کہ ماڈل اپنے جواب میں فراہم کرے۔\n",
    "\n",
    "**پیرامیٹرز آبجیکٹ کی خصوصیات:**\n",
    "\n",
    "`type` - پیرامیٹرز آبجیکٹ کی ڈیٹا ٹائپ (عام طور پر \"object\")\n",
    "\n",
    "`properties` - ان مخصوص اقدار کی فہرست جنہیں ماڈل اپنے جواب کے لیے استعمال کرے گا۔\n",
    "\n",
    "**ہر پیرامیٹر کی انفرادی خصوصیات:**\n",
    "\n",
    "`name` - پراپرٹی کی کلید سے خود بخود متعین ہوتا ہے (مثلاً \"role\"، \"product\"، \"level\")\n",
    "\n",
    "`type` - اس مخصوص پیرامیٹر کی ڈیٹا ٹائپ (مثلاً \"string\"، \"number\"، \"boolean\")\n",
    "\n",
    "`description` - اس مخصوص پیرامیٹر کی وضاحت\n",
    "\n",
    "**اختیاری خصوصیات:**\n",
    "\n",
    "`required` - ایک ارے جس میں وہ پیرامیٹرز شامل ہیں جو فنکشن کال مکمل کرنے کے لیے لازمی ہیں۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کال کرنا  \n",
    "فنکشن کو ڈیفائن کرنے کے بعد، اب ہمیں اسے چیٹ کمپلیشن API کی کال میں شامل کرنا ہے۔ یہ ہم درخواست میں `functions` شامل کر کے کرتے ہیں۔ اس مثال میں `functions=functions` لکھا گیا ہے۔\n",
    "\n",
    "ایک اور آپشن یہ بھی ہے کہ `function_call` کو `auto` پر سیٹ کر دیا جائے۔ اس کا مطلب یہ ہے کہ ہم LLM کو یہ فیصلہ کرنے دیں گے کہ صارف کے پیغام کی بنیاد پر کون سا فنکشن کال ہونا چاہیے، بجائے اس کے کہ ہم خود اسے منتخب کریں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب آئیے جواب کو دیکھتے ہیں اور اس کی ترتیب کو سمجھتے ہیں:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "آپ دیکھ سکتے ہیں کہ فنکشن کا نام پکارا گیا ہے اور صارف کے پیغام سے، LLM نے ڈیٹا تلاش کر کے فنکشن کے دلائل میں فٹ کر دیا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ایپلیکیشن میں فنکشن کالز کو شامل کرنا\n",
    "\n",
    "جب ہم نے LLM سے حاصل ہونے والے فارمیٹ شدہ جواب کو ٹیسٹ کر لیا ہے، اب ہم اسے اپنی ایپلیکیشن میں شامل کر سکتے ہیں۔\n",
    "\n",
    "### فلو کو منظم کرنا\n",
    "\n",
    "اسے اپنی ایپلیکیشن میں شامل کرنے کے لیے، آئیے درج ذیل اقدامات کرتے ہیں:\n",
    "\n",
    "سب سے پہلے، آئیے OpenAI سروسز کو کال کرتے ہیں اور پیغام کو `response_message` نامی ویری ایبل میں محفوظ کرتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم وہ فنکشن تعریف کریں گے جو مائیکروسافٹ لرن اے پی آئی کو کال کرے گا تاکہ کورسز کی فہرست حاصل کی جا سکے:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ایک بہترین طریقہ کار کے طور پر، ہم سب سے پہلے دیکھیں گے کہ آیا ماڈل کسی فنکشن کو کال کرنا چاہتا ہے۔ اس کے بعد، ہم دستیاب فنکشنز میں سے ایک فنکشن بنائیں گے اور اسے اس فنکشن سے ملائیں گے جسے کال کیا جا رہا ہے۔\n",
    "پھر ہم فنکشن کے دلائل لیں گے اور انہیں LLM سے آنے والے دلائل کے ساتھ میپ کریں گے۔\n",
    "\n",
    "آخر میں، ہم فنکشن کال میسج اور وہ اقدار شامل کریں گے جو `search_courses` میسج سے واپس آئیں۔ اس سے LLM کو وہ تمام معلومات مل جاتی ہیں جن کی اسے صارف کو قدرتی زبان میں جواب دینے کے لیے ضرورت ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## کوڈ چیلنج\n",
    "\n",
    "زبردست کام! OpenAI فنکشن کالنگ سیکھنے کو آگے بڑھانے کے لیے آپ یہ بنا سکتے ہیں: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - فنکشن کے مزید پیرا میٹرز شامل کریں جو سیکھنے والوں کو مزید کورسز تلاش کرنے میں مدد دے سکتے ہیں۔ دستیاب API پیرا میٹرز یہاں دیکھے جا سکتے ہیں:  \n",
    " - ایک اور فنکشن کال بنائیں جو سیکھنے والے سے مزید معلومات لے، جیسے کہ ان کی مادری زبان  \n",
    " - ایرر ہینڈلنگ شامل کریں جب فنکشن کال یا API کال کوئی مناسب کورس واپس نہ کرے\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**اعلانِ دستبرداری**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کی پوری کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہے۔ اصل دستاویز کو اس کی اصل زبان میں مستند ماخذ سمجھا جانا چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ تجویز کیا جاتا ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر نہیں ہوگی۔\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T20:46:08+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}