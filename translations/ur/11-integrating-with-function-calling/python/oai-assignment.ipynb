{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## تعارف\n",
    "\n",
    "یہ سبق درج ذیل موضوعات کا احاطہ کرے گا:\n",
    "- فنکشن کالنگ کیا ہے اور اس کے استعمال کے کیسز\n",
    "- OpenAI کا استعمال کرتے ہوئے فنکشن کال کیسے بنائیں\n",
    "- فنکشن کال کو ایک ایپلیکیشن میں کیسے ضم کریں\n",
    "\n",
    "## سیکھنے کے مقاصد\n",
    "\n",
    "اس سبق کو مکمل کرنے کے بعد آپ جانیں گے اور سمجھیں گے:\n",
    "\n",
    "- فنکشن کالنگ کے استعمال کا مقصد\n",
    "- OpenAI سروس کا استعمال کرتے ہوئے فنکشن کال سیٹ اپ کرنا\n",
    "- اپنی ایپلیکیشن کے استعمال کے کیس کے لیے مؤثر فنکشن کالز ڈیزائن کرنا\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## فنکشن کالز کو سمجھنا\n",
    "\n",
    "اس سبق کے لیے، ہم اپنی تعلیمی اسٹارٹ اپ کے لیے ایک فیچر بنانا چاہتے ہیں جو صارفین کو چیٹ بوٹ کے ذریعے تکنیکی کورسز تلاش کرنے کی اجازت دے۔ ہم ایسے کورسز کی سفارش کریں گے جو ان کی مہارت کی سطح، موجودہ کردار اور دلچسپی کی ٹیکنالوجی کے مطابق ہوں۔\n",
    "\n",
    "اسے مکمل کرنے کے لیے ہم درج ذیل کا امتزاج استعمال کریں گے:\n",
    " - `OpenAI` صارف کے لیے چیٹ کا تجربہ بنانے کے لیے\n",
    " - `Microsoft Learn Catalog API` صارفین کو ان کی درخواست کی بنیاد پر کورسز تلاش کرنے میں مدد دینے کے لیے\n",
    " - `Function Calling` صارف کی استفسار لے کر اسے ایک فنکشن کو بھیجنے کے لیے تاکہ API کی درخواست کی جا سکے۔\n",
    "\n",
    "شروع کرنے کے لیے، آئیے دیکھتے ہیں کہ ہم سب سے پہلے فنکشن کالنگ کیوں استعمال کرنا چاہیں گے:\n",
    "\n",
    "print(\"اگلی درخواست میں پیغامات:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT سے نیا جواب حاصل کریں جہاں وہ فنکشن کے جواب کو دیکھ سکتا ہے\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کالنگ کیوں\n",
    "\n",
    "اگر آپ نے اس کورس میں کوئی اور سبق مکمل کیا ہے، تو آپ شاید بڑے زبان کے ماڈلز (LLMs) کے استعمال کی طاقت کو سمجھتے ہیں۔ امید ہے کہ آپ ان کی کچھ حدود کو بھی دیکھ سکتے ہیں۔\n",
    "\n",
    "فنکشن کالنگ اوپن اے آئی سروس کی ایک خصوصیت ہے جو درج ذیل چیلنجز کو حل کرنے کے لیے ڈیزائن کی گئی ہے:\n",
    "\n",
    "غیر مستقل جواب کی فارمیٹنگ:\n",
    "- فنکشن کالنگ سے پہلے، بڑے زبان کے ماڈل سے ملنے والے جوابات غیر منظم اور غیر مستقل تھے۔ ڈویلپرز کو ہر قسم کی آؤٹ پٹ کی تبدیلی کو سنبھالنے کے لیے پیچیدہ ویلیڈیشن کوڈ لکھنا پڑتا تھا۔\n",
    "\n",
    "بیرونی ڈیٹا کے ساتھ محدود انضمام:\n",
    "- اس خصوصیت سے پہلے، ایپلیکیشن کے دوسرے حصوں سے ڈیٹا کو چیٹ کے سیاق و سباق میں شامل کرنا مشکل تھا۔\n",
    "\n",
    "جواب کے فارمیٹس کو معیاری بنا کر اور بیرونی ڈیٹا کے ساتھ بغیر رکاوٹ انضمام کو ممکن بنا کر، فنکشن کالنگ ترقی کو آسان بناتی ہے اور اضافی ویلیڈیشن لاجک کی ضرورت کو کم کرتی ہے۔\n",
    "\n",
    "صارفین ایسے سوالات کے جواب نہیں حاصل کر سکتے تھے جیسے \"اسٹاک ہوم میں موجودہ موسم کیسا ہے؟\"۔ اس کی وجہ یہ تھی کہ ماڈلز صرف اس وقت تک کے ڈیٹا تک محدود تھے جب ان کی تربیت ہوئی تھی۔\n",
    "\n",
    "آئیے نیچے دیے گئے مثال کو دیکھتے ہیں جو اس مسئلے کی وضاحت کرتی ہے:\n",
    "\n",
    "فرض کریں ہم طلباء کے ڈیٹا کا ایک ڈیٹا بیس بنانا چاہتے ہیں تاکہ ہم ان کو صحیح کورس تجویز کر سکیں۔ نیچے ہمارے پاس دو طلباء کی تفصیلات ہیں جو اپنے ڈیٹا میں بہت مشابہت رکھتی ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ہم اس کو ایک LLM کو بھیجنا چاہتے ہیں تاکہ ڈیٹا کو پارس کیا جا سکے۔ بعد میں اسے ہماری ایپلیکیشن میں استعمال کیا جا سکتا ہے تاکہ اسے API کو بھیجا جائے یا ڈیٹا بیس میں محفوظ کیا جائے۔\n",
    "\n",
    "آئیے دو ایک جیسے پرامپٹس بنائیں جن میں ہم LLM کو ہدایت دیں کہ ہمیں کس قسم کی معلومات میں دلچسپی ہے:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ہم اسے ایک LLM کو بھیجنا چاہتے ہیں تاکہ وہ ہمارے پروڈکٹ کے لیے اہم حصوں کو پارس کر سکے۔ لہٰذا ہم LLM کو ہدایت دینے کے لیے دو یکساں پرامپٹس بنا سکتے ہیں:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ان دو پرامپٹس کو بنانے کے بعد، ہم انہیں `openai.ChatCompletion` کا استعمال کرتے ہوئے LLM کو بھیجیں گے۔ ہم پرامپٹ کو `messages` متغیر میں محفوظ کرتے ہیں اور کردار کو `user` تفویض کرتے ہیں۔ یہ ایک صارف کی جانب سے چیٹ بوٹ کو بھیجے جانے والے پیغام کی نقل کرنے کے لیے ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم دونوں درخواستیں LLM کو بھیج سکتے ہیں اور جو جواب ہمیں ملتا ہے اس کا جائزہ لے سکتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگرچہ پرامپٹس ایک جیسے ہیں اور وضاحتیں ملتی جلتی ہیں، ہم `Grades` پراپرٹی کے مختلف فارمیٹس حاصل کر سکتے ہیں۔\n",
    "\n",
    "اگر آپ اوپر والا سیل کئی بار چلائیں، تو فارمیٹ `3.7` یا `3.7 GPA` ہو سکتا ہے۔\n",
    "\n",
    "یہ اس لیے ہے کیونکہ LLM غیر منظم ڈیٹا کو تحریری پرامپٹ کی شکل میں لیتا ہے اور غیر منظم ڈیٹا ہی واپس کرتا ہے۔ ہمیں ایک منظم فارمیٹ کی ضرورت ہے تاکہ ہمیں معلوم ہو کہ اس ڈیٹا کو ذخیرہ کرتے یا استعمال کرتے وقت کیا توقع رکھنی ہے۔\n",
    "\n",
    "فنکشنل کالنگ استعمال کرنے سے ہم یقینی بنا سکتے ہیں کہ ہمیں منظم ڈیٹا واپس ملے۔ فنکشن کالنگ استعمال کرتے وقت، LLM درحقیقت کوئی فنکشن کال یا رن نہیں کرتا۔ اس کے بجائے، ہم LLM کے لیے ایک ڈھانچہ بناتے ہیں تاکہ وہ اپنی جوابات کے لیے اس کی پیروی کرے۔ پھر ہم ان منظم جوابات کو استعمال کرتے ہیں تاکہ معلوم ہو سکے کہ ہماری ایپلیکیشنز میں کون سا فنکشن چلانا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![فنکشن کالنگ فلو ڈایاگرام](../../../../translated_images/Function-Flow.083875364af4f4bb.ur.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "پھر ہم فنکشن سے واپس آنے والی چیز کو لے کر اسے LLM کو بھیج سکتے ہیں۔ LLM پھر قدرتی زبان استعمال کرتے ہوئے صارف کے سوال کا جواب دے گا۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کالز کے استعمال کے کیسز\n",
    "\n",
    "**بیرونی ٹولز کو کال کرنا**  \n",
    "چیٹ بوٹس صارفین کے سوالات کے جوابات فراہم کرنے میں بہترین ہوتے ہیں۔ فنکشن کالنگ کے ذریعے، چیٹ بوٹس صارفین کے پیغامات کو استعمال کرکے مخصوص کام مکمل کر سکتے ہیں۔ مثال کے طور پر، ایک طالب علم چیٹ بوٹ سے کہہ سکتا ہے \"میرے انسٹرکٹر کو ای میل بھیجیں کہ مجھے اس مضمون میں مزید مدد کی ضرورت ہے\"۔ یہ `send_email(to: string, body: string)` فنکشن کال کر سکتا ہے۔\n",
    "\n",
    "**API یا ڈیٹا بیس کی کوئریز بنانا**  \n",
    "صارفین قدرتی زبان استعمال کرکے معلومات تلاش کر سکتے ہیں جو ایک فارمیٹ شدہ کوئری یا API درخواست میں تبدیل ہو جاتی ہے۔ اس کی ایک مثال ایک استاد ہو سکتا ہے جو پوچھتا ہے \"وہ کون سے طلباء ہیں جنہوں نے آخری اسائنمنٹ مکمل کی ہے\" جو `get_completed(student_name: string, assignment: int, current_status: string)` نامی فنکشن کو کال کر سکتا ہے۔\n",
    "\n",
    "**منظم شدہ ڈیٹا بنانا**  \n",
    "صارفین ایک متن یا CSV بلاک لے کر LLM کی مدد سے اس سے اہم معلومات نکال سکتے ہیں۔ مثال کے طور پر، ایک طالب علم امن معاہدوں کے بارے میں ویکیپیڈیا آرٹیکل کو AI فلیش کارڈز بنانے کے لیے تبدیل کر سکتا ہے۔ یہ `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` نامی فنکشن کے ذریعے کیا جا سکتا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. اپنا پہلا فنکشن کال بنانا\n",
    "\n",
    "فنکشن کال بنانے کا عمل 3 اہم مراحل پر مشتمل ہے:  \n",
    "1. اپنی فنکشنز کی فہرست اور صارف کا پیغام لے کر Chat Completions API کو کال کرنا  \n",
    "2. ماڈل کے جواب کو پڑھنا تاکہ کوئی عمل انجام دیا جا سکے یعنی فنکشن یا API کال کو چلانا  \n",
    "3. اپنے فنکشن کے جواب کے ساتھ Chat Completions API کو دوبارہ کال کرنا تاکہ اس معلومات کو استعمال کرتے ہوئے صارف کو جواب بنایا جا سکے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![فنکشن کال کا بہاؤ](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.ur.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کال کے عناصر\n",
    "\n",
    "#### صارف کی ان پٹ\n",
    "\n",
    "پہلا قدم صارف کا پیغام بنانا ہے۔ یہ متحرک طور پر ایک ٹیکسٹ ان پٹ کی ویلیو لے کر تفویض کیا جا سکتا ہے یا آپ یہاں ایک ویلیو تفویض کر سکتے ہیں۔ اگر یہ آپ کی پہلی بار ہے کہ آپ Chat Completions API کے ساتھ کام کر رہے ہیں، تو ہمیں پیغام کے `role` اور `content` کی تعریف کرنی ہوگی۔\n",
    "\n",
    "`role` یا تو `system` (قواعد بنانے والا)، `assistant` (ماڈل) یا `user` (آخری صارف) ہو سکتا ہے۔ فنکشن کالنگ کے لیے، ہم اسے `user` کے طور پر تفویض کریں گے اور ایک مثال سوال دیں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشنز بنانا۔\n",
    "\n",
    "اگلے مرحلے میں ہم ایک فنکشن اور اس فنکشن کے پیرامیٹرز کی تعریف کریں گے۔ یہاں ہم صرف ایک فنکشن استعمال کریں گے جسے `search_courses` کہا جاتا ہے، لیکن آپ متعدد فنکشنز بھی بنا سکتے ہیں۔\n",
    "\n",
    "**اہم**: فنکشنز کو LLM کے لیے سسٹم میسج میں شامل کیا جاتا ہے اور یہ آپ کے دستیاب ٹوکنز کی مقدار میں شامل ہوں گے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**تعریفات**\n",
    "\n",
    "فنکشن کی تعریف کا ڈھانچہ کئی سطحوں پر مشتمل ہوتا ہے، ہر ایک کی اپنی خصوصیات ہوتی ہیں۔ یہاں نیسٹڈ ڈھانچے کی تفصیل دی گئی ہے:\n",
    "\n",
    "**سب سے اوپر کی سطح کے فنکشن کی خصوصیات:**\n",
    "\n",
    "`name` - اس فنکشن کا نام جسے ہم کال کرنا چاہتے ہیں۔\n",
    "\n",
    "`description` - یہ اس بات کی وضاحت ہے کہ فنکشن کیسے کام کرتا ہے۔ یہاں واضح اور مخصوص ہونا ضروری ہے۔\n",
    "\n",
    "`parameters` - اقدار اور فارمیٹ کی فہرست جو آپ ماڈل سے اپنی جواب میں پیدا کرنے کے لیے چاہتے ہیں۔\n",
    "\n",
    "**Parameters آبجیکٹ کی خصوصیات:**\n",
    "\n",
    "`type` - parameters آبجیکٹ کا ڈیٹا ٹائپ (عام طور پر \"object\")\n",
    "\n",
    "`properties` - مخصوص اقدار کی فہرست جو ماڈل اپنی جواب میں استعمال کرے گا۔\n",
    "\n",
    "**انفرادی پیرامیٹر کی خصوصیات:**\n",
    "\n",
    "`name` - پراپرٹی کی کلید کے ذریعے ضمنی طور پر متعین (مثلاً \"role\"، \"product\"، \"level\")\n",
    "\n",
    "`type` - اس مخصوص پیرامیٹر کا ڈیٹا ٹائپ (مثلاً \"string\"، \"number\"، \"boolean\")\n",
    "\n",
    "`description` - اس مخصوص پیرامیٹر کی وضاحت\n",
    "\n",
    "**اختیاری خصوصیات:**\n",
    "\n",
    "`required` - ایک ارے جو ان پیرامیٹرز کی فہرست دیتا ہے جو فنکشن کال مکمل کرنے کے لیے ضروری ہیں۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### فنکشن کال کرنا  \n",
    "فنکشن کی تعریف کرنے کے بعد، اب ہمیں اسے Chat Completion API کی کال میں شامل کرنا ہوگا۔ ہم یہ درخواست میں `functions` شامل کرکے کرتے ہیں۔ اس صورت میں `functions=functions`۔  \n",
    "\n",
    "ایک آپشن یہ بھی ہے کہ `function_call` کو `auto` پر سیٹ کیا جائے۔ اس کا مطلب ہے کہ ہم LLM کو یہ فیصلہ کرنے دیں گے کہ صارف کے پیغام کی بنیاد پر کون سا فنکشن کال کیا جانا چاہیے بجائے اس کے کہ ہم خود اسے تفویض کریں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب آئیے جواب کو دیکھتے ہیں اور دیکھتے ہیں کہ یہ کس طرح فارمیٹ کیا گیا ہے:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "آپ دیکھ سکتے ہیں کہ فنکشن کا نام کال کیا گیا ہے اور صارف کے پیغام سے، LLM نے فنکشن کے دلائل کے مطابق ڈیٹا تلاش کر لیا ہے۔\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.فنکشن کالز کو ایک ایپلیکیشن میں ضم کرنا۔\n",
    "\n",
    "\n",
    "جب ہم نے LLM سے فارمیٹ شدہ جواب کی جانچ کر لی ہے، تو اب ہم اسے ایک ایپلیکیشن میں ضم کر سکتے ہیں۔\n",
    "\n",
    "### بہاؤ کا انتظام\n",
    "\n",
    "اسے اپنی ایپلیکیشن میں ضم کرنے کے لیے، آئیے درج ذیل اقدامات کریں:\n",
    "\n",
    "سب سے پہلے، OpenAI سروسز کو کال کریں اور پیغام کو `response_message` نامی متغیر میں محفوظ کریں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم وہ فنکشن تعریف کریں گے جو Microsoft Learn API کو کال کرے گا تاکہ کورسز کی فہرست حاصل کی جا سکے:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "بطور بہترین طریقہ کار، ہم پھر دیکھیں گے کہ آیا ماڈل کسی فنکشن کو کال کرنا چاہتا ہے۔ اس کے بعد، ہم دستیاب فنکشنز میں سے ایک بنائیں گے اور اسے اس فنکشن سے ملائیں گے جسے کال کیا جا رہا ہے۔  \n",
    "پھر ہم فنکشن کے دلائل لیں گے اور انہیں LLM کے دلائل سے میپ کریں گے۔\n",
    "\n",
    "آخر میں، ہم فنکشن کال پیغام اور وہ قدریں شامل کریں گے جو `search_courses` پیغام سے واپس آئیں۔ اس سے LLM کو تمام معلومات مل جاتی ہیں جو اسے صارف کو قدرتی زبان میں جواب دینے کے لیے درکار ہوتی ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم اپ ڈیٹ شدہ پیغام کو LLM کو بھیجیں گے تاکہ ہمیں API JSON فارمیٹ شدہ جواب کی بجائے قدرتی زبان میں جواب مل سکے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## کوڈ چیلنج\n",
    "\n",
    "زبردست کام! OpenAI فنکشن کالنگ کی اپنی تعلیم جاری رکھنے کے لیے آپ یہ بنا سکتے ہیں: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    "- فنکشن کے مزید پیرامیٹرز جو سیکھنے والوں کو مزید کورسز تلاش کرنے میں مدد دے سکتے ہیں۔ آپ دستیاب API پیرامیٹرز یہاں دیکھ سکتے ہیں:  \n",
    "- ایک اور فنکشن کال بنائیں جو سیکھنے والے سے مزید معلومات لے جیسے ان کی مادری زبان  \n",
    "- جب فنکشن کال اور/یا API کال کوئی مناسب کورسز واپس نہ کرے تو ایرر ہینڈلنگ بنائیں\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**دستخطی دستبرداری**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں ہی معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر عائد نہیں ہوتی۔\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T09:03:46+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}