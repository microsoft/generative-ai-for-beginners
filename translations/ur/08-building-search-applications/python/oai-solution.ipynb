{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "مندرجہ ذیل نوٹ بکس چلانے کے لیے، اگر آپ نے ابھی تک نہیں کیا ہے، تو آپ کو .env فائل کے اندر openai کی کو `OPENAI_API_KEY` کے طور پر سیٹ کرنا ہوگا۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم ایمبیڈنگ انڈیکس کو ایک پانڈاز ڈیٹافریم میں لوڈ کرنے جا رہے ہیں۔ ایمبیڈنگ انڈیکس ایک JSON فائل میں محفوظ ہے جس کا نام `embedding_index_3m.json` ہے۔ ایمبیڈنگ انڈیکس میں ہر یوٹیوب ٹرانسکرپٹ کے ایمبیڈنگز شامل ہیں، جو اکتوبر 2023 کے آخر تک کے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اب ہم ایک فنکشن بنائیں گے جس کا نام `get_videos` ہوگا، جو کہ Embedding Index میں دی گئی تلاش کے لیے ویڈیوز تلاش کرے گا۔ یہ فنکشن وہ پانچ ویڈیوز واپس کرے گا جو تلاش سے سب سے زیادہ ملتی جلتی ہوں گی۔ یہ فنکشن اس طرح کام کرتا ہے:\n",
    "\n",
    "1. سب سے پہلے، Embedding Index کی ایک نقل تیار کی جاتی ہے۔\n",
    "2. اس کے بعد، تلاش کے لیے Embedding کو OpenAI Embedding API کی مدد سے نکالا جاتا ہے۔\n",
    "3. پھر Embedding Index میں ایک نیا کالم بنایا جاتا ہے جس کا نام `similarity` ہے۔ اس کالم میں تلاش کے Embedding اور ہر ویڈیو سیگمنٹ کے Embedding کے درمیان cosine similarity رکھی جاتی ہے۔\n",
    "4. اس کے بعد، Embedding Index کو `similarity` کالم کی بنیاد پر فلٹر کیا جاتا ہے۔ صرف وہی ویڈیوز رکھی جاتی ہیں جن کی cosine similarity کم از کم 0.75 ہو۔\n",
    "5. آخر میں، Embedding Index کو `similarity` کالم کے مطابق ترتیب دیا جاتا ہے اور سب سے اوپر والی پانچ ویڈیوز واپس کی جاتی ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "یہ فنکشن بہت سادہ ہے، یہ صرف تلاش کی گئی عبارت کے نتائج ظاہر کرتا ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. سب سے پہلے، ایمبیڈنگ انڈیکس کو ایک پانڈاز ڈیٹافریم میں لوڈ کیا جاتا ہے۔\n",
    "2. اس کے بعد، صارف سے کہا جاتا ہے کہ وہ ایک سوال درج کرے۔\n",
    "3. پھر `get_videos` فنکشن کو کال کیا جاتا ہے تاکہ ایمبیڈنگ انڈیکس میں اس سوال کے لیے تلاش کی جا سکے۔\n",
    "4. آخر میں، `display_results` فنکشن کو کال کیا جاتا ہے تاکہ نتائج صارف کو دکھائے جا سکیں۔\n",
    "5. پھر صارف سے کہا جاتا ہے کہ وہ ایک اور سوال درج کرے۔ یہ عمل اس وقت تک جاری رہتا ہے جب تک صارف `exit` نہیں لکھتا۔\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.ur.png)\n",
    "\n",
    "آپ سے سوال درج کرنے کے لیے کہا جائے گا۔ سوال لکھیں اور انٹر دبائیں۔ ایپلیکیشن آپ کو ان ویڈیوز کی فہرست دے گی جو آپ کے سوال سے متعلق ہیں۔ اس کے علاوہ، ایپلیکیشن آپ کو اس ویڈیو کے اس حصے کا لنک بھی دے گی جہاں آپ کے سوال کا جواب موجود ہے۔\n",
    "\n",
    "یہاں کچھ سوالات ہیں جنہیں آپ آزما سکتے ہیں:\n",
    "\n",
    "- Azure Machine Learning کیا ہے؟\n",
    "- کنوولوشنل نیورل نیٹ ورکس کیسے کام کرتے ہیں؟\n",
    "- نیورل نیٹ ورک کیا ہے؟\n",
    "- کیا میں Jupyter Notebooks کو Azure Machine Learning کے ساتھ استعمال کر سکتا ہوں؟\n",
    "- ONNX کیا ہے؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**اعلانِ دستبرداری**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کی پوری کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہے۔ اصل دستاویز کو اس کی اصل زبان میں مستند ماخذ سمجھا جانا چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ تجویز کیا جاتا ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر نہیں ہوگی۔\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "2c0494ceb4f5fc618a6abda0b5c09c73",
   "translation_date": "2025-08-25T18:54:21+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}