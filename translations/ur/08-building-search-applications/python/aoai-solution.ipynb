{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگر آپ نے ابھی تک نہیں کیا ہے تو درج ذیل نوٹ بکس چلانے کے لیے، آپ کو ایک ماڈل تعینات کرنا ہوگا جو `text-embedding-ada-002` کو بنیادی ماڈل کے طور پر استعمال کرتا ہو اور .env فائل کے اندر تعیناتی کا نام `AZURE_OPENAI_EMBEDDINGS_ENDPOINT` کے طور پر سیٹ کرنا ہوگا۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگلا، ہم ایمبیڈنگ انڈیکس کو پانڈاز ڈیٹا فریم میں لوڈ کرنے جا رہے ہیں۔ ایمبیڈنگ انڈیکس ایک JSON فائل میں محفوظ ہے جس کا نام `embedding_index_3m.json` ہے۔ ایمبیڈنگ انڈیکس میں ہر یوٹیوب ٹرانسکرپٹ کے ایمبیڈنگ شامل ہیں جو اکتوبر 2023 کے آخر تک کے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "اگلا، ہم ایک فنکشن بنائیں گے جسے `get_videos` کہا جائے گا جو کوئری کے لیے ایمبیڈنگ انڈیکس میں تلاش کرے گا۔ یہ فنکشن ان 5 ویڈیوز کو واپس کرے گا جو کوئری کے سب سے زیادہ مشابہ ہوں۔ فنکشن اس طرح کام کرتا ہے:\n",
    "\n",
    "1. سب سے پہلے، ایمبیڈنگ انڈیکس کی ایک کاپی بنائی جاتی ہے۔\n",
    "2. اگلا، کوئری کے لیے ایمبیڈنگ اوپن اے آئی ایمبیڈنگ API کا استعمال کرتے ہوئے حساب کی جاتی ہے۔\n",
    "3. پھر ایمبیڈنگ انڈیکس میں `similarity` نامی ایک نیا کالم بنایا جاتا ہے۔ `similarity` کالم میں کوسائن مشابہت شامل ہوتی ہے جو کوئری ایمبیڈنگ اور ہر ویڈیو سیگمنٹ کی ایمبیڈنگ کے درمیان ہوتی ہے۔\n",
    "4. اگلا، ایمبیڈنگ انڈیکس کو `similarity` کالم کی بنیاد پر فلٹر کیا جاتا ہے۔ ایمبیڈنگ انڈیکس کو صرف ان ویڈیوز تک محدود کیا جاتا ہے جن کی کوسائن مشابہت 0.75 یا اس سے زیادہ ہو۔\n",
    "5. آخر میں، ایمبیڈنگ انڈیکس کو `similarity` کالم کے مطابق ترتیب دیا جاتا ہے اور سب سے اوپر کے 5 ویڈیوز واپس کیے جاتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "یہ فنکشن بہت آسان ہے، یہ صرف تلاش کے سوال کے نتائج کو پرنٹ کرتا ہے۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. سب سے پہلے، ایمبیڈنگ انڈیکس کو پانڈاز ڈیٹافریم میں لوڈ کیا جاتا ہے۔\n",
    "2. اگلا، صارف کو ایک سوال درج کرنے کے لیے کہا جاتا ہے۔\n",
    "3. پھر `get_videos` فنکشن کو کال کیا جاتا ہے تاکہ سوال کے لیے ایمبیڈنگ انڈیکس میں تلاش کی جا سکے۔\n",
    "4. آخر میں، `display_results` فنکشن کو کال کیا جاتا ہے تاکہ نتائج صارف کو دکھائے جا سکیں۔\n",
    "5. پھر صارف کو ایک اور سوال درج کرنے کے لیے کہا جاتا ہے۔ یہ عمل اس وقت تک جاری رہتا ہے جب تک صارف `exit` درج نہ کرے۔\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.ur.png)\n",
    "\n",
    "آپ سے سوال درج کرنے کو کہا جائے گا۔ ایک سوال درج کریں اور انٹر دبائیں۔ ایپلیکیشن ایسے ویڈیوز کی فہرست واپس کرے گی جو سوال سے متعلق ہوں۔ ایپلیکیشن اس جگہ کا لنک بھی واپس کرے گی جہاں ویڈیو میں سوال کا جواب موجود ہے۔\n",
    "\n",
    "یہاں کچھ سوالات ہیں جنہیں آپ آزما سکتے ہیں:\n",
    "\n",
    "- Azure Machine Learning کیا ہے؟\n",
    "- Convolutional neural networks کیسے کام کرتے ہیں؟\n",
    "- Neural network کیا ہے؟\n",
    "- کیا میں Jupyter Notebooks کو Azure Machine Learning کے ساتھ استعمال کر سکتا ہوں؟\n",
    "- ONNX کیا ہے؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**دستخطی نوٹ**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کے لیے کوشاں ہیں، براہ کرم اس بات سے آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستیاں ہو سکتی ہیں۔ اصل دستاویز اپنی مادری زبان میں معتبر ماخذ سمجھی جانی چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر عائد نہیں ہوتی۔\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "ff5415e24294df268ec7e7a2b12af509",
   "translation_date": "2025-12-19T09:00:52+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}