<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a8b2d4bb727c877ebf9edff8623d16b9",
  "translation_date": "2025-09-06T10:11:41+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "ur"
}
-->
[![اوپن سورس ماڈلز](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.ur.png)](https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst)

## تعارف

اوپن سورس LLMs کی دنیا نہایت دلچسپ اور مسلسل ترقی پذیر ہے۔ اس سبق کا مقصد اوپن سورس ماڈلز پر گہرائی سے نظر ڈالنا ہے۔ اگر آپ یہ جاننا چاہتے ہیں کہ ملکیتی ماڈلز اوپن سورس ماڈلز کے مقابلے میں کیسے ہیں، تو ["مختلف LLMs کا جائزہ اور موازنہ" سبق](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst) دیکھیں۔ اس سبق میں فائن ٹیوننگ کے موضوع پر بھی بات کی جائے گی، لیکن اس کی مزید تفصیل ["فائن ٹیوننگ LLMs" سبق](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst) میں موجود ہے۔

## سیکھنے کے مقاصد

- اوپن سورس ماڈلز کو سمجھنا  
- اوپن سورس ماڈلز کے ساتھ کام کرنے کے فوائد کو سمجھنا  
- Hugging Face اور Azure AI Studio پر دستیاب اوپن ماڈلز کا جائزہ لینا  

## اوپن سورس ماڈلز کیا ہیں؟

اوپن سورس سافٹ ویئر نے مختلف شعبوں میں ٹیکنالوجی کی ترقی میں اہم کردار ادا کیا ہے۔ اوپن سورس انیشیٹو (OSI) نے سافٹ ویئر کو اوپن سورس کے طور پر درجہ بندی کرنے کے لیے [10 معیارات](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst) مقرر کیے ہیں۔ سورس کوڈ کو OSI کی منظور شدہ لائسنس کے تحت کھلے عام شیئر کیا جانا چاہیے۔

LLMs کی ترقی میں سافٹ ویئر کی ترقی جیسے عناصر شامل ہیں، لیکن یہ عمل بالکل ایک جیسا نہیں ہے۔ اس وجہ سے کمیونٹی میں LLMs کے سیاق و سباق میں اوپن سورس کی تعریف پر کافی بحث ہوئی ہے۔ ایک ماڈل کو روایتی اوپن سورس تعریف کے مطابق ہونے کے لیے درج ذیل معلومات عوامی طور پر دستیاب ہونی چاہئیں:

- ماڈل کو تربیت دینے کے لیے استعمال کیے گئے ڈیٹاسیٹس۔  
- مکمل ماڈل ویٹس تربیت کے حصے کے طور پر۔  
- ایویلیوایشن کوڈ۔  
- فائن ٹیوننگ کوڈ۔  
- مکمل ماڈل ویٹس اور تربیتی میٹرکس۔  

فی الحال، صرف چند ماڈلز اس معیار پر پورا اترتے ہیں۔ [OLMo ماڈل، جو Allen Institute for Artificial Intelligence (AllenAI) نے بنایا ہے](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst)، اس زمرے میں آتا ہے۔

اس سبق کے لیے، ہم ان ماڈلز کو "اوپن ماڈلز" کہیں گے کیونکہ وہ اس وقت لکھنے کے دوران مذکورہ معیار پر پورا نہیں اتر سکتے۔

## اوپن ماڈلز کے فوائد

**انتہائی حسب ضرورت** - چونکہ اوپن ماڈلز کو تفصیلی تربیتی معلومات کے ساتھ جاری کیا جاتا ہے، محققین اور ڈویلپرز ماڈل کے اندرونی حصوں میں ترمیم کر سکتے ہیں۔ یہ انتہائی مخصوص کاموں یا مطالعے کے شعبوں کے لیے فائن ٹیون کیے گئے ماڈلز بنانے کے قابل بناتا ہے۔ اس کی کچھ مثالیں کوڈ جنریشن، ریاضیاتی آپریشنز اور حیاتیات ہیں۔

**لاگت** - ان ماڈلز کو استعمال کرنے اور تعینات کرنے کی لاگت ملکیتی ماڈلز کے مقابلے میں کم ہے۔ جب جنریٹو AI ایپلیکیشنز بنائی جا رہی ہوں، تو ان ماڈلز کے ساتھ کام کرتے وقت کارکردگی بمقابلہ قیمت کا جائزہ لینا ضروری ہے۔

![ماڈل لاگت](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.ur.png)  
ماخذ: Artificial Analysis  

**لچک** - اوپن ماڈلز کے ساتھ کام کرنے سے آپ کو مختلف ماڈلز استعمال کرنے یا انہیں یکجا کرنے میں لچک ملتی ہے۔ اس کی ایک مثال [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst) ہے، جہاں صارف انٹرفیس میں براہ راست استعمال ہونے والے ماڈل کا انتخاب کر سکتا ہے:

![ماڈل منتخب کریں](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.ur.png)

## مختلف اوپن ماڈلز کا جائزہ

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst)، جو Meta نے تیار کیا ہے، ایک اوپن ماڈل ہے جو چیٹ پر مبنی ایپلیکیشنز کے لیے بہتر بنایا گیا ہے۔ یہ اس کے فائن ٹیوننگ طریقے کی وجہ سے ہے، جس میں بڑی مقدار میں مکالمہ اور انسانی تاثرات شامل تھے۔ اس طریقے کے ساتھ، ماڈل ایسے نتائج پیدا کرتا ہے جو انسانی توقعات کے مطابق زیادہ ہوتے ہیں، جو ایک بہتر صارف تجربہ فراہم کرتا ہے۔

Llama کے فائن ٹیون کیے گئے ورژنز کی کچھ مثالیں [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst) ہیں، جو جاپانی زبان میں مہارت رکھتا ہے، اور [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst)، جو بنیادی ماڈل کا ایک بہتر ورژن ہے۔

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) ایک اوپن ماڈل ہے جو اعلیٰ کارکردگی اور مؤثریت پر زور دیتا ہے۔ یہ Mixture-of-Experts طریقہ استعمال کرتا ہے، جو ماہر ماڈلز کے ایک گروپ کو ایک نظام میں یکجا کرتا ہے، جہاں ان پٹ کے مطابق مخصوص ماڈلز منتخب کیے جاتے ہیں۔ یہ کمپیوٹیشن کو زیادہ مؤثر بناتا ہے کیونکہ ماڈلز صرف ان ان پٹس کو ایڈریس کرتے ہیں جن میں وہ مہارت رکھتے ہیں۔

Mistral کے فائن ٹیون کیے گئے ورژنز کی کچھ مثالیں [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst) ہیں، جو طبی شعبے پر مرکوز ہے، اور [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst)، جو ریاضیاتی حسابات انجام دیتا ہے۔

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) ایک LLM ہے جو Technology Innovation Institute (**TII**) نے بنایا ہے۔ Falcon-40B کو 40 ارب پیرامیٹرز پر تربیت دی گئی ہے، جس نے کم کمپیوٹ بجٹ کے ساتھ GPT-3 سے بہتر کارکردگی دکھائی ہے۔ یہ FlashAttention الگورتھم اور ملٹی کوئری اٹینشن کے استعمال کی وجہ سے ہے، جو انفرنس کے وقت میموری کی ضروریات کو کم کرنے کے قابل بناتا ہے۔ اس کم انفرنس وقت کے ساتھ، Falcon-40B چیٹ ایپلیکیشنز کے لیے موزوں ہے۔

Falcon کے فائن ٹیون کیے گئے ورژنز کی کچھ مثالیں [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst) ہیں، جو اوپن ماڈلز پر مبنی ایک اسسٹنٹ ہے، اور [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst)، جو بنیادی ماڈل سے زیادہ کارکردگی فراہم کرتا ہے۔

## انتخاب کیسے کریں

اوپن ماڈل کے انتخاب کے لیے کوئی ایک جواب نہیں ہے۔ ایک اچھی شروعات Azure AI Studio کے "فلٹر بائی ٹاسک" فیچر کا استعمال ہے۔ یہ آپ کو یہ سمجھنے میں مدد دے گا کہ ماڈل کو کس قسم کے کاموں کے لیے تربیت دی گئی ہے۔ Hugging Face بھی ایک LLM لیڈر بورڈ برقرار رکھتا ہے، جو مخصوص میٹرکس کی بنیاد پر بہترین کارکردگی دکھانے والے ماڈلز کو ظاہر کرتا ہے۔

مختلف اقسام کے LLMs کا موازنہ کرنے کے لیے، [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) ایک اور بہترین ذریعہ ہے:

![ماڈل کوالٹی](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.ur.png)  
ماخذ: Artificial Analysis  

اگر آپ کسی مخصوص استعمال کے کیس پر کام کر رہے ہیں، تو اسی شعبے پر مرکوز فائن ٹیون کیے گئے ورژنز کی تلاش مؤثر ہو سکتی ہے۔ مختلف اوپن ماڈلز کے ساتھ تجربہ کرنا اور یہ دیکھنا کہ وہ آپ اور آپ کے صارفین کی توقعات کے مطابق کیسے کارکردگی دکھاتے ہیں، ایک اور اچھی مشق ہے۔

## اگلے مراحل

اوپن ماڈلز کی سب سے اچھی بات یہ ہے کہ آپ ان کے ساتھ کام کرنا جلدی شروع کر سکتے ہیں۔ [Azure AI Foundry Model Catalog](https://ai.azure.com?WT.mc_id=academic-105485-koreyst) دیکھیں، جس میں Hugging Face کا ایک مخصوص کلیکشن شامل ہے، جس میں وہ ماڈلز شامل ہیں جن پر ہم نے یہاں بات کی۔

## سیکھنے کا سفر یہاں ختم نہیں ہوتا، جاری رکھیں

اس سبق کو مکمل کرنے کے بعد، ہماری [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) دیکھیں تاکہ اپنی Generative AI کی معلومات کو مزید بہتر بنایا جا سکے!

---

**ڈسکلیمر**:  
یہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کا استعمال کرتے ہوئے ترجمہ کی گئی ہے۔ ہم درستگی کے لیے کوشش کرتے ہیں، لیکن براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا غیر درستیاں ہو سکتی ہیں۔ اصل دستاویز کو اس کی اصل زبان میں مستند ذریعہ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ کی سفارش کی جاتی ہے۔ ہم اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ذمہ دار نہیں ہیں۔