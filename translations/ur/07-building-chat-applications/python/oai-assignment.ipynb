{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# باب 7: چیٹ ایپلیکیشنز بنانا\n",
    "## اوپن اے آئی API فوری آغاز\n",
    "\n",
    "یہ نوٹ بک [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) سے لی گئی ہے، جس میں وہ نوٹ بکس شامل ہیں جو [Azure OpenAI](notebook-azure-openai.ipynb) سروسز تک رسائی دیتی ہیں۔\n",
    "\n",
    "Python OpenAI API، Azure OpenAI ماڈلز کے ساتھ بھی کام کرتا ہے، بس چند تبدیلیوں کے ساتھ۔ یہاں مزید جانیں کہ ان میں کیا فرق ہے: [Python کے ساتھ OpenAI اور Azure OpenAI اینڈ پوائنٹس کے درمیان کیسے سوئچ کریں](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# جائزہ  \n",
    "\"بڑے لینگویج ماڈلز وہ فنکشنز ہیں جو متن کو متن میں تبدیل کرتے ہیں۔ جب آپ انہیں کوئی ان پٹ ٹیکسٹ دیتے ہیں، تو یہ ماڈل اندازہ لگاتے ہیں کہ اگلا متن کیا ہو سکتا ہے\" (1)۔ یہ \"کوئیک اسٹارٹ\" نوٹ بک صارفین کو ایل ایل ایم کے اہم تصورات، اے ایم ایل کے ساتھ شروعات کے لیے بنیادی پیکیج کی ضروریات، پرامپٹ ڈیزائن کا آسان تعارف، اور مختلف استعمالات کے چند مختصر مثالوں سے روشناس کرائے گی۔\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## فہرست مضامین  \n",
    "\n",
    "[جائزہ](../../../../07-building-chat-applications/python)  \n",
    "[اوپن اے آئی سروس کیسے استعمال کریں](../../../../07-building-chat-applications/python)  \n",
    "[1. اپنی اوپن اے آئی سروس بنائیں](../../../../07-building-chat-applications/python)  \n",
    "[2. تنصیب](../../../../07-building-chat-applications/python)    \n",
    "[3. اسناد](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[استعمال کی مثالیں](../../../../07-building-chat-applications/python)    \n",
    "[1. متن کا خلاصہ بنائیں](../../../../07-building-chat-applications/python)  \n",
    "[2. متن کو درجہ بندی کریں](../../../../07-building-chat-applications/python)  \n",
    "[3. نئے پروڈکٹ کے نام تجویز کریں](../../../../07-building-chat-applications/python)  \n",
    "[4. کسی کلاسیفائر کو بہتر بنائیں](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[حوالہ جات](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### اپنا پہلا پرامپٹ بنائیں  \n",
    "یہ مختصر مشق آپ کو OpenAI ماڈل کو ایک سادہ کام \"خلاصہ نویسی\" کے لیے پرامپٹ بھیجنے کا بنیادی تعارف فراہم کرے گی۔\n",
    "\n",
    "**مراحل**:  \n",
    "1. اپنے پائتھون ماحول میں OpenAI لائبریری انسٹال کریں  \n",
    "2. معیاری ہیلپر لائبریریاں لوڈ کریں اور اپنے بنائے گئے OpenAI سروس کے لیے عام سیکیورٹی اسناد سیٹ کریں  \n",
    "3. اپنے کام کے لیے ایک ماڈل منتخب کریں  \n",
    "4. ماڈل کے لیے ایک سادہ پرامپٹ تیار کریں  \n",
    "5. اپنی درخواست ماڈل API کو بھیجیں!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. اوپن اے آئی انسٹال کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۲۔ معاون لائبریریاں درآمد کریں اور اسناد کو انسٹیٹیوٹ کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. درست ماڈل تلاش کرنا  \n",
    "GPT-3.5-turbo یا GPT-4 ماڈلز قدرتی زبان کو سمجھنے اور تخلیق کرنے کی صلاحیت رکھتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. پرامپٹ ڈیزائن  \n",
    "\n",
    "\"بڑے لینگویج ماڈلز کی جادوگری یہ ہے کہ جب انہیں بے شمار متون پر پیش گوئی کی غلطی کم کرنے کی تربیت دی جاتی ہے، تو یہ ماڈلز ایسی تصورات سیکھ لیتے ہیں جو ان پیش گوئیوں کے لیے فائدہ مند ہوتے ہیں۔ مثال کے طور پر، یہ تصورات سیکھتے ہیں جیسے\"(1):\n",
    "\n",
    "* الفاظ کی درست املا کیسے کی جائے\n",
    "* گرامر کیسے کام کرتی ہے\n",
    "* بات کو مختلف انداز میں کیسے بیان کیا جائے\n",
    "* سوالات کے جواب کیسے دیے جائیں\n",
    "* گفتگو کیسے کی جائے\n",
    "* مختلف زبانوں میں کیسے لکھا جائے\n",
    "* کوڈنگ کیسے کی جائے\n",
    "* وغیرہ\n",
    "\n",
    "#### بڑے لینگویج ماڈل کو کیسے کنٹرول کریں  \n",
    "\"بڑے لینگویج ماڈل کے تمام ان پٹس میں سب سے زیادہ اثر رکھنے والا ان پٹ ٹیکسٹ پرامپٹ ہے(1)۔\n",
    "\n",
    "بڑے لینگویج ماڈلز کو مختلف طریقوں سے آؤٹ پٹ دینے کے لیے پرامپٹ کیا جا سکتا ہے:\n",
    "\n",
    "ہدایات: ماڈل کو بتائیں کہ آپ کیا چاہتے ہیں  \n",
    "تکمیل: ماڈل کو اس چیز کا آغاز دیں جسے آپ مکمل کروانا چاہتے ہیں  \n",
    "نمائش: ماڈل کو دکھائیں کہ آپ کیا چاہتے ہیں، یا تو:  \n",
    "پرامپٹ میں چند مثالیں دے کر  \n",
    "یا تربیتی ڈیٹا سیٹ میں سینکڑوں یا ہزاروں مثالیں دے کر\"\n",
    "\n",
    "\n",
    "\n",
    "#### پرامپٹ بنانے کے تین بنیادی اصول ہیں:\n",
    "\n",
    "**دکھائیں اور بتائیں۔** واضح کریں کہ آپ کیا چاہتے ہیں، چاہے ہدایات کے ذریعے، مثالوں کے ذریعے، یا دونوں کے امتزاج سے۔ اگر آپ چاہتے ہیں کہ ماڈل اشیاء کی فہرست کو حروفِ تہجی کے مطابق ترتیب دے یا کسی پیراگراف کو جذبات کے لحاظ سے درجہ بندی کرے، تو اسے دکھائیں کہ یہی آپ چاہتے ہیں۔\n",
    "\n",
    "**معیاری ڈیٹا فراہم کریں۔** اگر آپ کوئی درجہ بند کرنے والا ماڈل بنانا چاہتے ہیں یا ماڈل کو کسی خاص انداز پر چلانا چاہتے ہیں، تو یقینی بنائیں کہ کافی مثالیں موجود ہیں۔ اپنی مثالوں کو اچھی طرح چیک کریں — ماڈل عام طور پر اتنا ذہین ہوتا ہے کہ بنیادی املا کی غلطیوں کو نظر انداز کر کے جواب دے دے، لیکن یہ بھی ممکن ہے کہ وہ اسے جان بوجھ کر سمجھ لے اور اس سے جواب پر اثر پڑے۔\n",
    "\n",
    "**اپنی سیٹنگز چیک کریں۔** temperature اور top_p سیٹنگز یہ کنٹرول کرتی ہیں کہ ماڈل جواب دیتے وقت کتنا متعین ہے۔ اگر آپ ایسا جواب چاہتے ہیں جس میں صرف ایک درست جواب ہو، تو انہیں کم رکھیں۔ اگر آپ زیادہ متنوع جوابات چاہتے ہیں، تو انہیں زیادہ رکھیں۔ سب سے عام غلطی جو لوگ ان سیٹنگز کے ساتھ کرتے ہیں وہ یہ ہے کہ انہیں \"ذہانت\" یا \"تخلیقی صلاحیت\" کے کنٹرول سمجھتے ہیں۔\n",
    "\n",
    "\n",
    "ماخذ: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### اسی کال کو دوبارہ دہرائیں، نتائج کا موازنہ کیسے کریں؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## متن کا خلاصہ کریں  \n",
    "#### چیلنج  \n",
    "متن کا خلاصہ اس طرح کریں کہ عبارت کے آخر میں 'tl;dr:' شامل کریں۔ نوٹ کریں کہ ماڈل بغیر کسی اضافی ہدایت کے کئی کام انجام دینے کی صلاحیت رکھتا ہے۔ آپ tl;dr کے بجائے مزید وضاحتی پرامپٹس آزما سکتے ہیں تاکہ ماڈل کے رویے میں تبدیلی لائیں اور اپنی مرضی کے مطابق خلاصہ حاصل کریں(3)۔\n",
    "\n",
    "حالیہ تحقیق سے یہ بات سامنے آئی ہے کہ بڑے متنی ذخیرے پر پہلے سے تربیت اور پھر مخصوص کام کے لیے فائن ٹیوننگ کرنے سے NLP کے کئی کاموں اور بینچ مارکس میں نمایاں بہتری آئی ہے۔ اگرچہ یہ طریقہ عام طور پر فن تعمیر میں کسی خاص کام سے وابستہ نہیں ہوتا، پھر بھی اس کے لیے ہزاروں یا دسیوں ہزار مثالوں پر مشتمل کام کے لحاظ سے مخصوص ڈیٹا سیٹس کی ضرورت ہوتی ہے۔ اس کے برعکس، انسان عام طور پر صرف چند مثالوں یا سادہ ہدایات سے نئی لسانی ذمہ داریاں انجام دے سکتے ہیں — جو کہ موجودہ NLP سسٹمز کے لیے اب بھی ایک بڑا چیلنج ہے۔ یہاں ہم دکھاتے ہیں کہ زبان کے ماڈلز کو بڑا کرنے سے عمومی، کم مثالوں پر مبنی کارکردگی میں نمایاں بہتری آتی ہے، اور بعض اوقات یہ پچھلے جدید ترین فائن ٹیوننگ طریقوں کے برابر بھی پہنچ جاتی ہے۔\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مختلف استعمالات کے لیے مشقیں  \n",
    "1. متن کا خلاصہ کریں  \n",
    "2. متن کو درجہ بندی کریں  \n",
    "3. نئے پروڈکٹ کے نام تجویز کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## متن کو درجہ بندی کریں  \n",
    "#### چیلنج  \n",
    "اشیاء کو ان زمروں میں تقسیم کریں جو انفیرینس کے وقت فراہم کیے گئے ہوں۔ درج ذیل مثال میں، ہم پرامپٹ میں دونوں یعنی زمرے اور درجہ بندی کے لیے متن فراہم کرتے ہیں (*playground_reference)۔\n",
    "\n",
    "کسٹمر کی درخواست: ہیلو، میرے لیپ ٹاپ کے کی بورڈ کی ایک چابی حال ہی میں ٹوٹ گئی ہے اور مجھے اس کا متبادل چاہیے:\n",
    "\n",
    "درجہ بند زمرہ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## نئے پروڈکٹ کے نام بنائیں\n",
    "#### چیلنج\n",
    "مثالی الفاظ سے پروڈکٹ کے نام تخلیق کریں۔ یہاں ہم پرامپٹ میں اس پروڈکٹ کے بارے میں معلومات شامل کرتے ہیں جس کے لیے ہم نام بنانا چاہتے ہیں۔ ہم ایک مشابہ مثال بھی فراہم کرتے ہیں تاکہ وہ انداز واضح ہو جائے جس کی ہم توقع رکھتے ہیں۔ ہم نے temperature کی ویلیو زیادہ رکھی ہے تاکہ جوابات میں جدت اور تخلیقی پن زیادہ ہو۔\n",
    "\n",
    "پروڈکٹ کی تفصیل: گھر میں ملک شیک بنانے والی مشین\n",
    "بیج الفاظ: تیز، صحت مند، کمپیکٹ۔\n",
    "پروڈکٹ کے نام: ہوم شیکر، فٹ شیکر، کوئیک شیک، شیک میکر\n",
    "\n",
    "پروڈکٹ کی تفصیل: ایسے جوتے جو ہر سائز کے پاؤں میں فٹ آ سکتے ہیں۔\n",
    "بیج الفاظ: موافق، فٹ، اومنی فٹ۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# حوالہ جات  \n",
    "- [اوپن اے آئی کُک بک](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [اوپن اے آئی اسٹوڈیو کی مثالیں](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [GPT-3 کو ٹیکسٹ کی درجہ بندی کے لیے فائن ٹیون کرنے کے بہترین طریقے](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مزید مدد کے لیے  \n",
    "[OpenAI کمرشلائزیشن ٹیم](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# معاونین\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**اعلانِ دستبرداری**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کی پوری کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہے۔ اصل دستاویز کو اس کی اصل زبان میں مستند ماخذ سمجھا جانا چاہیے۔ اہم معلومات کے لیے پیشہ ور انسانی ترجمہ تجویز کیا جاتا ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کے ہم ذمہ دار نہیں ہیں۔\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:03:32+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}