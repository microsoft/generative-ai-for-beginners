{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# باب 7: چیٹ ایپلیکیشنز بنانا\n",
    "## گٹ ہب ماڈلز API فوری آغاز\n",
    "\n",
    "یہ نوٹ بک [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) سے لی گئی ہے، جس میں وہ نوٹ بکس شامل ہیں جو [Azure OpenAI](notebook-azure-openai.ipynb) سروسز تک رسائی فراہم کرتی ہیں۔\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# جائزہ  \n",
    "\"بڑے زبان کے ماڈلز وہ فنکشنز ہیں جو متن کو متن میں تبدیل کرتے ہیں۔ جب آپ کوئی ان پٹ سٹرنگ دیتے ہیں، تو بڑا زبان ماڈل اندازہ لگاتا ہے کہ اگلا متن کیا ہوگا\"(1)۔ یہ \"کویئک اسٹارٹ\" نوٹ بک صارفین کو ایل ایل ایم کے بنیادی تصورات، اے ایم ایل کے ساتھ شروعات کرنے کے لیے ضروری پیکجز، پرامپٹ ڈیزائن کا آسان تعارف، اور مختلف استعمالات کے چند مختصر مثالوں سے روشناس کرائے گی۔\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## فہرست مضامین  \n",
    "\n",
    "[جائزہ](../../../../07-building-chat-applications/python)  \n",
    "[اوپن اے آئی سروس کا استعمال کیسے کریں](../../../../07-building-chat-applications/python)  \n",
    "[1. اپنی اوپن اے آئی سروس بنائیں](../../../../07-building-chat-applications/python)  \n",
    "[2. تنصیب](../../../../07-building-chat-applications/python)    \n",
    "[3. اسناد](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[استعمال کی مثالیں](../../../../07-building-chat-applications/python)    \n",
    "[1. متن کا خلاصہ بنائیں](../../../../07-building-chat-applications/python)  \n",
    "[2. متن کو درجہ بند کریں](../../../../07-building-chat-applications/python)  \n",
    "[3. نئے پروڈکٹ کے نام تیار کریں](../../../../07-building-chat-applications/python)  \n",
    "[4. کسی کلاسیفائر کو بہتر بنائیں](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[حوالہ جات](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### اپنا پہلا پرامپٹ بنائیں  \n",
    "یہ مختصر مشق آپ کو Github Models میں ماڈل کو پرامپٹ بھیجنے کا بنیادی تعارف فراہم کرے گی، ایک آسان کام \"خلاصہ نویسی\" کے لیے۔\n",
    "\n",
    "**مراحل**:  \n",
    "1. اگر آپ نے ابھی تک نہیں کیا تو اپنے پائتھون ماحول میں `azure-ai-inference` لائبریری انسٹال کریں۔  \n",
    "2. معیاری ہیلپر لائبریریاں لوڈ کریں اور Github Models کے لیے اسناد سیٹ کریں۔  \n",
    "3. اپنے کام کے لیے ایک ماڈل منتخب کریں  \n",
    "4. ماڈل کے لیے ایک سادہ پرامپٹ تیار کریں  \n",
    "5. اپنی درخواست ماڈل API کو بھیجیں!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. `azure-ai-inference` انسٹال کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۲۔ معاون لائبریریاں درآمد کریں اور اسناد کو انسٹیٹیوٹ کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. درست ماڈل تلاش کرنا  \n",
    "GPT-3.5-turbo یا GPT-4 ماڈلز قدرتی زبان کو سمجھنے اور تخلیق کرنے کی صلاحیت رکھتے ہیں۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. پرامپٹ ڈیزائن  \n",
    "\n",
    "\"بڑے لینگویج ماڈلز کی جادوگری یہ ہے کہ جب انہیں بے شمار متون پر اس پیش گوئی کی غلطی کو کم کرنے کی تربیت دی جاتی ہے، تو یہ ماڈلز ان پیش گوئیوں کے لیے مفید تصورات سیکھ لیتے ہیں۔ مثال کے طور پر، یہ ماڈلز یہ تصورات سیکھ لیتے ہیں کہ\"(1):\n",
    "\n",
    "* الفاظ کیسے لکھے جاتے ہیں\n",
    "* گرامر کیسے کام کرتی ہے\n",
    "* جملوں کو کس طرح مختلف انداز میں بیان کیا جا سکتا ہے\n",
    "* سوالات کے جوابات کیسے دیے جائیں\n",
    "* گفتگو کیسے کی جائے\n",
    "* مختلف زبانوں میں کیسے لکھا جائے\n",
    "* کوڈنگ کیسے کی جائے\n",
    "* وغیرہ\n",
    "\n",
    "#### بڑے لینگویج ماڈل کو کیسے کنٹرول کریں  \n",
    "\"بڑے لینگویج ماڈل کے تمام ان پٹس میں سب سے زیادہ اثرانداز ہونے والا ان پٹ ٹیکسٹ پرامپٹ ہے(1)۔\n",
    "\n",
    "بڑے لینگویج ماڈلز کو مختلف طریقوں سے آؤٹ پٹ دینے کے لیے پرامپٹ کیا جا سکتا ہے:\n",
    "\n",
    "ہدایات: ماڈل کو بتائیں کہ آپ کیا چاہتے ہیں  \n",
    "تکمیل: ماڈل کو اس چیز کا آغاز دے کر مکمل کروائیں جو آپ چاہتے ہیں  \n",
    "ڈیمونسٹریشن: ماڈل کو دکھائیں کہ آپ کیا چاہتے ہیں، یا تو:  \n",
    "پرامپٹ میں چند مثالیں دے کر  \n",
    "یا فائن ٹیوننگ ٹریننگ ڈیٹاسیٹ میں سینکڑوں یا ہزاروں مثالیں دے کر\"\n",
    "\n",
    "#### پرامپٹس بنانے کے تین بنیادی اصول ہیں:\n",
    "\n",
    "**دکھائیں اور بتائیں**۔ واضح کریں کہ آپ کیا چاہتے ہیں، چاہے وہ ہدایات کے ذریعے ہو، مثالوں کے ذریعے، یا دونوں کے امتزاج سے۔ اگر آپ چاہتے ہیں کہ ماڈل کسی فہرست کو حروف تہجی کے حساب سے ترتیب دے یا کسی پیراگراف کو جذبات کے لحاظ سے درجہ بندی کرے، تو اسے دکھائیں کہ آپ یہی چاہتے ہیں۔\n",
    "\n",
    "**معیاری ڈیٹا فراہم کریں**۔ اگر آپ کوئی کلاسیفائر بنانا چاہتے ہیں یا ماڈل کو کسی پیٹرن پر چلانا چاہتے ہیں، تو اس بات کو یقینی بنائیں کہ کافی مثالیں موجود ہوں۔ اپنی مثالوں کو اچھی طرح چیک کریں — ماڈل عموماً اتنا ذہین ہوتا ہے کہ بنیادی املا کی غلطیوں کو سمجھ سکے اور آپ کو جواب دے، لیکن یہ بھی ہو سکتا ہے کہ وہ اسے جان بوجھ کر کیا گیا سمجھے اور اس سے جواب متاثر ہو۔\n",
    "\n",
    "**اپنی سیٹنگز چیک کریں۔** temperature اور top_p سیٹنگز یہ کنٹرول کرتی ہیں کہ ماڈل جواب دیتے وقت کتنا متعین (deterministic) ہو۔ اگر آپ ایسا جواب چاہتے ہیں جس کا صرف ایک ہی درست جواب ہو، تو انہیں کم رکھیں۔ اگر آپ زیادہ متنوع جوابات چاہتے ہیں، تو انہیں زیادہ رکھیں۔ سب سے عام غلطی جو لوگ ان سیٹنگز کے ساتھ کرتے ہیں وہ یہ ہے کہ وہ انہیں \"ذہانت\" یا \"تخلیقی صلاحیت\" کے کنٹرول سمجھ لیتے ہیں۔\n",
    "\n",
    "ماخذ: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ایک ہی کال کو دوبارہ دہرائیں، نتائج کا موازنہ کیسے کریں؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## خلاصہ متن  \n",
    "#### چیلنج  \n",
    "متن کو خلاصہ کرنے کے لیے اس کے آخر میں 'tl;dr:' شامل کریں۔ دیکھیں کہ ماڈل بغیر کسی اضافی ہدایات کے کئی کام انجام دینے کی صلاحیت رکھتا ہے۔ آپ tl;dr سے زیادہ وضاحتی پرامپٹس آزما سکتے ہیں تاکہ ماڈل کے رویے میں تبدیلی لائیں اور اپنی مرضی کے مطابق خلاصہ حاصل کریں(3)۔\n",
    "\n",
    "حالیہ تحقیق سے یہ بات سامنے آئی ہے کہ بڑے متنی ذخیرے پر پہلے سے تربیت اور پھر مخصوص کام کے لیے فائن ٹیوننگ کرنے سے NLP کے کئی کاموں اور بینچ مارکس میں نمایاں بہتری آئی ہے۔ اگرچہ یہ طریقہ عام طور پر فن تعمیر میں کام سے غیر متعلق ہوتا ہے، پھر بھی اس میں ہزاروں یا دسیوں ہزاروں مثالوں پر مشتمل کام کے لحاظ سے مخصوص ڈیٹا سیٹس کی ضرورت ہوتی ہے۔ اس کے برعکس، انسان عام طور پر صرف چند مثالوں یا سادہ ہدایات سے نئی زبان کا کام انجام دے سکتے ہیں — جو کہ موجودہ NLP سسٹمز کے لیے اب بھی ایک بڑا چیلنج ہے۔ یہاں ہم دکھاتے ہیں کہ زبان کے ماڈلز کو بڑا کرنے سے کام سے غیر متعلق، کم مثالوں پر مبنی کارکردگی میں نمایاں بہتری آتی ہے، اور بعض اوقات یہ پچھلے جدید ترین فائن ٹیوننگ طریقوں کے برابر بھی پہنچ جاتی ہے۔\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مختلف استعمالات کے لیے مشقیں  \n",
    "1. متن کا خلاصہ کریں  \n",
    "2. متن کو درجہ بندی کریں  \n",
    "3. نئے پروڈکٹ کے نام تجویز کریں\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## متن کو درجہ بندی کریں  \n",
    "#### چیلنج  \n",
    "اشیاء کو ان زمروں میں تقسیم کریں جو انفیرینس کے وقت فراہم کیے گئے ہوں۔ درج ذیل مثال میں، ہم پرامپٹ میں زمرے اور درجہ بندی کے لیے متن دونوں فراہم کرتے ہیں (*playground_reference)۔\n",
    "\n",
    "کسٹمر کی درخواست: ہیلو، میرے لیپ ٹاپ کے کی بورڈ کی ایک چابی حال ہی میں ٹوٹ گئی ہے اور مجھے اس کا متبادل چاہیے:\n",
    "\n",
    "درجہ بند زمرہ:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## نئے پروڈکٹ کے نام بنائیں\n",
    "#### چیلنج\n",
    "مثالی الفاظ سے پروڈکٹ کے نام تخلیق کریں۔ یہاں ہم پرامپٹ میں اس پروڈکٹ کے بارے میں معلومات شامل کرتے ہیں جس کے لیے ہم نام بنانا چاہتے ہیں۔ ہم ایک ملتا جلتا مثال بھی فراہم کرتے ہیں تاکہ وہ انداز واضح ہو جائے جو ہم چاہتے ہیں۔ ہم نے temperature ویلیو بھی زیادہ رکھی ہے تاکہ جوابات میں جدت اور تخلیقی پن زیادہ ہو۔\n",
    "\n",
    "پروڈکٹ کی تفصیل: ایک گھریلو ملک شیک بنانے والی مشین\n",
    "بیج الفاظ: تیز، صحت مند، کمپیکٹ۔\n",
    "پروڈکٹ کے نام: ہوم شیکر، فٹ شیکر، کوئیک شیک، شیک میکر\n",
    "\n",
    "پروڈکٹ کی تفصیل: ایک ایسا جوتا جو ہر سائز کے پاؤں میں فٹ آ جائے۔\n",
    "بیج الفاظ: ایڈاپٹیبل، فٹ، اومنی-فٹ۔\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# حوالہ جات  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Examples](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [GPT-3 کو ٹیکسٹ کی درجہ بندی کے لیے فائن ٹیون کرنے کے بہترین طریقے](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مزید مدد کے لیے  \n",
    "[OpenAI کمرشلائزیشن ٹیم](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# معاونین\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**اعلانِ دستبرداری**:  \nیہ دستاویز AI ترجمہ سروس [Co-op Translator](https://github.com/Azure/co-op-translator) کے ذریعے ترجمہ کی گئی ہے۔ اگرچہ ہم درستگی کی پوری کوشش کرتے ہیں، براہ کرم آگاہ رہیں کہ خودکار ترجمے میں غلطیاں یا عدم درستگی ہو سکتی ہے۔ اصل دستاویز کو اس کی اصل زبان میں مستند ماخذ سمجھا جانا چاہیے۔ اہم معلومات کے لیے، پیشہ ور انسانی ترجمہ تجویز کیا جاتا ہے۔ اس ترجمے کے استعمال سے پیدا ہونے والی کسی بھی غلط فہمی یا غلط تشریح کی ذمہ داری ہم پر نہیں ہوگی۔\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:23:51+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "ur"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}