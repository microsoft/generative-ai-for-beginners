<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-10-11T11:25:49+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "et"
}
-->
# Generatiivse tehisintellekti vastutustundlik kasutamine

[![Generatiivse tehisintellekti vastutustundlik kasutamine](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.et.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _KlÃµpsa Ã¼laloleval pildil, et vaadata selle Ãµppetunni videot_

Tehisintellekt, eriti generatiivne tehisintellekt, vÃµib olla vÃ¤ga pÃµnev, kuid oluline on mÃµelda, kuidas seda vastutustundlikult kasutada. Tuleb arvestada nÃ¤iteks sellega, kuidas tagada, et vÃ¤ljund oleks Ãµiglane, mitte kahjulik ja palju muud. See peatÃ¼kk annab teile vajaliku konteksti, mida arvestada ja kuidas astuda aktiivseid samme oma tehisintellekti kasutamise parandamiseks.

## Sissejuhatus

Selles ÃµppetÃ¼kis kÃ¤sitletakse:

- Miks peaksite generatiivse tehisintellekti rakenduste loomisel eelistama vastutustundlikku tehisintellekti.
- Vastutustundliku tehisintellekti pÃµhiprintsiipe ja nende seost generatiivse tehisintellektiga.
- Kuidas neid vastutustundliku tehisintellekti pÃµhimÃµtteid strateegia ja tÃ¶Ã¶riistade abil praktikas rakendada.

## Ã•ppimise eesmÃ¤rgid

PÃ¤rast selle Ãµppetunni lÃ¤bimist teate:

- Vastutustundliku tehisintellekti olulisust generatiivse tehisintellekti rakenduste loomisel.
- Millal mÃµelda ja rakendada vastutustundliku tehisintellekti pÃµhiprintsiipe generatiivse tehisintellekti rakenduste loomisel.
- Millised tÃ¶Ã¶riistad ja strateegiad on teile kÃ¤ttesaadavad vastutustundliku tehisintellekti kontseptsiooni rakendamiseks.

## Vastutustundliku tehisintellekti pÃµhimÃµtted

Generatiivse tehisintellekti populaarsus pole kunagi olnud suurem. See populaarsus on toonud sellesse valdkonda palju uusi arendajaid, tÃ¤helepanu ja rahastust. Kuigi see on vÃ¤ga positiivne kÃµigile, kes soovivad generatiivse tehisintellekti abil tooteid ja ettevÃµtteid luua, on oluline tegutseda vastutustundlikult.

Selle kursuse jooksul keskendume oma idufirma ja tehisintellekti haridustootega tÃ¶Ã¶tamisele. Kasutame vastutustundliku tehisintellekti pÃµhimÃµtteid: Ãµiglus, kaasatus, usaldusvÃ¤Ã¤rsus/turvalisus, turvalisus ja privaatsus, lÃ¤bipaistvus ja vastutus. Nende pÃµhimÃµtete abil uurime, kuidas need seostuvad generatiivse tehisintellekti kasutamisega meie toodetes.

## Miks peaksite eelistama vastutustundlikku tehisintellekti

Toote loomisel viib parimate tulemusteni inimkeskne lÃ¤henemine, kus peetakse silmas kasutaja parimaid huve.

Generatiivse tehisintellekti ainulaadsus seisneb selle vÃµimes luua kasutajatele kasulikke vastuseid, teavet, juhiseid ja sisu. Seda saab teha ilma paljude manuaalsete sammudeta, mis vÃµib viia vÃ¤ga muljetavaldavate tulemusteni. Ilma korraliku planeerimise ja strateegiateta vÃµib see kahjuks viia ka kahjulike tulemusteni teie kasutajate, toote ja kogu Ã¼hiskonna jaoks.

Vaatame mÃµningaid (kuid mitte kÃµiki) vÃµimalikke kahjulikke tulemusi:

### Hallutsinatsioonid

Hallutsinatsioonid on termin, mida kasutatakse kirjeldamaks olukorda, kus suur keelemudel (LLM) toodab sisu, mis on kas tÃ¤iesti mÃµttetu vÃµi faktuaalselt vale teistele allikatele tuginedes.

NÃ¤iteks kui loome oma idufirmale funktsiooni, mis vÃµimaldab Ãµpilastel esitada mudelile ajaloolisi kÃ¼simusi. Ã•pilane kÃ¼sib: `Kes oli Titanicu ainus ellujÃ¤Ã¤nu?`

Mudel annab vastuse, nÃ¤iteks jÃ¤rgmise:

![KÃ¼simus "Kes oli Titanicu ainus ellujÃ¤Ã¤nu"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Allikas: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

See on vÃ¤ga enesekindel ja pÃµhjalik vastus. Kahjuks on see vale. Isegi minimaalne uurimistÃ¶Ã¶ nÃ¤itaks, et Titanicu katastroofist oli rohkem kui Ã¼ks ellujÃ¤Ã¤nu. Ã•pilase jaoks, kes alles alustab selle teema uurimist, vÃµib see vastus olla piisavalt veenev, et seda mitte kahtluse alla seada ja vÃµtta seda faktina. Selle tagajÃ¤rjeks vÃµib olla tehisintellekti sÃ¼steemi ebausaldusvÃ¤Ã¤rsus ja meie idufirma maine kahjustamine.

Iga uue LLM-i versiooniga oleme nÃ¤inud edusamme hallutsinatsioonide minimeerimisel. Isegi nende edusammude juures peame rakenduste loojate ja kasutajatena olema nende piirangutest teadlikud.

### Kahjulik sisu

Eelmises osas kÃ¤sitlesime olukordi, kus LLM toodab valesid vÃµi mÃµttetuid vastuseid. Teine risk, millest peame teadlikud olema, on olukorrad, kus mudel vastab kahjuliku sisuga.

Kahjulik sisu vÃµib olla:

- Juhiste andmine vÃµi enesevigastamise vÃµi teatud rÃ¼hmade kahjustamise julgustamine.
- Vihkav vÃµi alandav sisu.
- RÃ¼nnakute vÃµi vÃ¤givaldsete tegude planeerimise juhendamine.
- Juhiste andmine, kuidas leida ebaseaduslikku sisu vÃµi toime panna ebaseaduslikke tegusid.
- Seksuaalselt selgesÃµnalise sisu kuvamine.

Meie idufirma jaoks tahame veenduda, et meil on olemas Ãµiged tÃ¶Ã¶riistad ja strateegiad, et takistada sellise sisu jÃµudmist Ãµpilasteni.

### EbaÃµiglus

Ã•iglust defineeritakse kui â€œtagamist, et tehisintellekti sÃ¼steem on vaba eelarvamustest ja diskrimineerimisest ning kohtleb kÃµiki Ãµiglaselt ja vÃµrdselt.â€ Generatiivse tehisintellekti maailmas tahame tagada, et mudeli vÃ¤ljund ei tugevdaks marginaliseeritud rÃ¼hmade vÃ¤listavaid maailmavaateid.

Sellised vÃ¤ljundid ei kahjusta mitte ainult meie kasutajate jaoks positiivsete tootmiskogemuste loomist, vaid pÃµhjustavad ka tÃ¤iendavat kahju Ã¼hiskonnale. Rakenduste loojatena peaksime alati arvestama laia ja mitmekesise kasutajaskonnaga, kui loome lahendusi generatiivse tehisintellekti abil.

## Kuidas kasutada generatiivset tehisintellekti vastutustundlikult

NÃ¼Ã¼d, kui oleme tuvastanud vastutustundliku generatiivse tehisintellekti olulisuse, vaatame nelja sammu, mida saame astuda, et ehitada oma tehisintellekti lahendusi vastutustundlikult:

![Leevendamise tsÃ¼kkel](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.et.png)

### MÃµÃµda vÃµimalikke kahjusid

Tarkvara testimisel testime kasutaja eeldatavaid tegevusi rakenduses. Samamoodi on hea viis vÃµimalike kahjude mÃµÃµtmiseks testida mitmekesist komplekti kÃ¼simusi, mida kasutajad tÃµenÃ¤oliselt esitavad.

Kuna meie idufirma ehitab haridustoodet, oleks hea koostada nimekiri haridusega seotud kÃ¼simustest. See vÃµiks hÃµlmata teatud teemasid, ajaloolisi fakte ja kÃ¼simusi Ãµpilaselu kohta.

### Leevenda vÃµimalikke kahjusid

NÃ¼Ã¼d on aeg leida viise, kuidas saaksime mudeli ja selle vastuste pÃµhjustatud kahjusid ennetada vÃµi piirata. Seda saab vaadelda neljal erineval tasandil:

![Leevendamise kihid](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.et.png)

- **Mudel**. Ã•ige mudeli valimine Ãµige kasutusjuhtumi jaoks. Suuremad ja keerukamad mudelid, nagu GPT-4, vÃµivad vÃ¤iksemate ja spetsiifilisemate kasutusjuhtumite korral pÃµhjustada suuremat kahjuliku sisu riski. Oma treeningandmete kasutamine mudeli peenhÃ¤Ã¤lestamiseks vÃ¤hendab samuti kahjuliku sisu riski.

- **TurvasÃ¼steem**. TurvasÃ¼steem on mudelit teenindava platvormi tÃ¶Ã¶riistade ja konfiguratsioonide kogum, mis aitab kahjusid leevendada. NÃ¤iteks on olemas Azure OpenAI teenuse sisu filtreerimise sÃ¼steem. SÃ¼steemid peaksid tuvastama ka jailbreak-rÃ¼nnakuid ja soovimatut tegevust, nÃ¤iteks botide pÃ¤ringuid.

- **Metaprompt**. Metapromptid ja maandamine on viisid, kuidas saame mudelit teatud kÃ¤itumise ja teabe pÃµhjal suunata vÃµi piirata. See vÃµib tÃ¤hendada sÃ¼steemi sisendite kasutamist mudeli teatud piiride mÃ¤Ã¤ratlemiseks. Lisaks vÃµib see tÃ¤hendada vÃ¤ljundite pakkumist, mis on sÃ¼steemi ulatuse vÃµi domeeniga rohkem seotud.

Samuti vÃµib see tÃ¤hendada selliste tehnikate kasutamist nagu Retrieval Augmented Generation (RAG), et mudel tÃµmbaks teavet ainult valitud usaldusvÃ¤Ã¤rsetest allikatest. Selle kursuse hilisemas osas on Ãµppetund [otsingurakenduste loomisest](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Kasutajakogemus**. Viimane kiht on koht, kus kasutaja suhtleb mudeliga otse meie rakenduse liidese kaudu. Sel viisil saame kujundada kasutajaliidese/UX-i nii, et see piiraks kasutajat mudelile saadetavate sisendite tÃ¼Ã¼pide osas, samuti teksti vÃµi pilte, mida kasutajale kuvatakse. Tehisintellekti rakendust juurutades peame olema ka lÃ¤bipaistvad selle osas, mida meie generatiivne tehisintellekti rakendus suudab ja mida mitte.

Meil on terve Ãµppetund pÃ¼hendatud [tehisintellekti rakenduste kasutajakogemuse kujundamisele](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Mudelihindamine**. Suurte keelemudelitega tÃ¶Ã¶tamine vÃµib olla keeruline, kuna me ei oma alati kontrolli mudeli treenimiseks kasutatud andmete Ã¼le. Sellest hoolimata peaksime alati hindama mudeli jÃµudlust ja vÃ¤ljundeid. Oluline on mÃµÃµta mudeli tÃ¤psust, sarnasust, pÃµhjendatust ja vÃ¤ljundi asjakohasust. See aitab pakkuda lÃ¤bipaistvust ja usaldust sidusrÃ¼hmadele ja kasutajatele.

### Vastutustundliku generatiivse tehisintellekti lahenduse haldamine

Tehisintellekti rakenduste Ã¼mber operatiivse praktika loomine on viimane etapp. See hÃµlmab koostÃ¶Ã¶d teiste meie idufirma osakondadega, nagu juriidiline ja turvalisus, et tagada vastavus kÃµigile regulatiivsetele nÃµuetele. Enne kÃ¤ivitamist tahame koostada ka plaanid tarnimise, intsidentide kÃ¤sitlemise ja tagasivÃµtmise kohta, et vÃ¤ltida meie kasutajatele kahju tekitamist.

## TÃ¶Ã¶riistad

Kuigi vastutustundlike tehisintellekti lahenduste vÃ¤ljatÃ¶Ã¶tamine vÃµib tunduda keeruline, on see tÃ¶Ã¶ vaeva vÃ¤Ã¤rt. Kuna generatiivse tehisintellekti valdkond kasvab, arenevad ka tÃ¶Ã¶riistad, mis aitavad arendajatel tÃµhusalt integreerida vastutustundlikkust oma tÃ¶Ã¶voogudesse. NÃ¤iteks [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) aitab API-pÃ¤ringute kaudu tuvastada kahjulikku sisu ja pilte.

## Teadmiste kontroll

Millistele asjadele peate tÃ¤helepanu pÃ¶Ã¶rama, et tagada tehisintellekti vastutustundlik kasutamine?

1. Et vastus oleks Ãµige.  
2. Kahjulik kasutus, et tehisintellekti ei kasutataks kuritegelikel eesmÃ¤rkidel.  
3. Tagada, et tehisintellekt oleks vaba eelarvamustest ja diskrimineerimisest.  

V: 2 ja 3 on Ãµiged. Vastutustundlik tehisintellekt aitab teil kaaluda, kuidas kahjulikke mÃµjusid ja eelarvamusi leevendada ning palju muud.

## ğŸš€ VÃ¤ljakutse

Lugege [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) kohta ja vaadake, mida saate oma kasutuse jaoks rakendada.

## SuurepÃ¤rane tÃ¶Ã¶, jÃ¤tkake Ãµppimist

PÃ¤rast selle Ãµppetunni lÃ¤bimist tutvuge meie [Generatiivse tehisintellekti Ãµppekollektsiooniga](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et jÃ¤tkata oma teadmiste tÃ¤iendamist generatiivse tehisintellekti vallas!

Liikuge edasi 4. Ãµppetundi, kus vaatleme [Prompt Engineeringu aluseid](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

---

**LahtiÃ¼tlus**:  
See dokument on tÃµlgitud AI tÃµlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi pÃ¼Ã¼ame tagada tÃ¤psust, palume arvestada, et automaatsed tÃµlked vÃµivad sisaldada vigu vÃµi ebatÃ¤psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtÃµlget. Me ei vastuta selle tÃµlke kasutamisest tulenevate arusaamatuste vÃµi valesti tÃµlgenduste eest.