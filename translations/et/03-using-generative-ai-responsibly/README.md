<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-18T02:51:18+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "et"
}
-->
# Generatiivse tehisintellekti vastutustundlik kasutamine

[![Generatiivse tehisintellekti vastutustundlik kasutamine](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.et.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _KlÃµpsa Ã¼laloleval pildil, et vaadata selle Ãµppetunni videot_

Tehisintellekt, eriti generatiivne tehisintellekt, vÃµib olla vÃ¤ga pÃµnev, kuid oluline on mÃµelda, kuidas seda vastutustundlikult kasutada. Tuleb arvestada nÃ¤iteks sellega, kuidas tagada, et tulemused oleksid Ãµiglased, mitte kahjulikud ja palju muud. See peatÃ¼kk annab konteksti, mida arvestada ja kuidas astuda aktiivseid samme tehisintellekti kasutamise parandamiseks.

## Sissejuhatus

Selles Ãµppetunnis kÃ¤sitletakse:

- Miks peaks eelistama vastutustundlikku tehisintellekti generatiivse tehisintellekti rakenduste loomisel.
- Vastutustundliku tehisintellekti pÃµhimÃµtteid ja nende seost generatiivse tehisintellektiga.
- Kuidas rakendada vastutustundliku tehisintellekti pÃµhimÃµtteid strateegia ja tÃ¶Ã¶riistade abil.

## Ã•ppeeesmÃ¤rgid

PÃ¤rast selle Ãµppetunni lÃ¤bimist tead:

- Miks on vastutustundlik tehisintellekt oluline generatiivse tehisintellekti rakenduste loomisel.
- Millal mÃµelda ja rakendada vastutustundliku tehisintellekti pÃµhimÃµtteid generatiivse tehisintellekti rakenduste loomisel.
- Millised tÃ¶Ã¶riistad ja strateegiad on saadaval, et rakendada vastutustundliku tehisintellekti kontseptsiooni.

## Vastutustundliku tehisintellekti pÃµhimÃµtted

Generatiivse tehisintellekti populaarsus on saavutanud enneolematu taseme. See huvi on toonud valdkonda palju uusi arendajaid, tÃ¤helepanu ja rahastust. Kuigi see on vÃ¤ga positiivne kÃµigile, kes soovivad generatiivse tehisintellekti abil tooteid ja ettevÃµtteid luua, on oluline tegutseda vastutustundlikult.

Selle kursuse jooksul keskendume oma idufirma ja tehisintellekti haridustoodete loomisele. Kasutame vastutustundliku tehisintellekti pÃµhimÃµtteid: Ãµiglus, kaasatus, usaldusvÃ¤Ã¤rsus/turvalisus, turvalisus ja privaatsus, lÃ¤bipaistvus ja vastutus. Nende pÃµhimÃµtete abil uurime, kuidas need seostuvad generatiivse tehisintellekti kasutamisega meie toodetes.

## Miks peaks eelistama vastutustundlikku tehisintellekti

Toote loomisel viib inimkeskne lÃ¤henemine, kus arvestatakse kasutaja huvidega, parimate tulemusteni.

Generatiivse tehisintellekti unikaalsus seisneb selle vÃµimes luua kasulikke vastuseid, teavet, juhiseid ja sisu kasutajatele. Seda saab teha ilma paljude kÃ¤sitsi tehtavate sammudeta, mis vÃµib viia vÃ¤ga muljetavaldavate tulemusteni. Ilma korraliku planeerimise ja strateegiateta vÃµib see kahjuks viia ka kahjulike tulemusteni kasutajate, toote ja Ã¼hiskonna jaoks tervikuna.

Vaatame mÃµningaid (kuid mitte kÃµiki) potentsiaalselt kahjulikke tulemusi:

### Hallutsinatsioonid

Hallutsinatsioonid on termin, mida kasutatakse, et kirjeldada olukorda, kus LLM (suur keelemudel) genereerib sisu, mis on kas tÃ¤iesti mÃµttetu vÃµi faktuaalselt vale teiste infoallikate pÃµhjal.

NÃ¤iteks loome oma idufirmale funktsiooni, mis vÃµimaldab Ãµpilastel esitada ajaloolisi kÃ¼simusi mudelile. Ã•pilane kÃ¼sib: `Kes oli Titanic'u ainus ellujÃ¤Ã¤nu?`

Mudel genereerib vastuse, nagu allpool nÃ¤idatud:

![KÃ¼simus "Kes oli Titanic'u ainus ellujÃ¤Ã¤nu"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Allikas: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

See on vÃ¤ga enesekindel ja pÃµhjalik vastus. Kahjuks on see vale. Isegi minimaalne uurimistÃ¶Ã¶ nÃ¤itaks, et Titanic'u katastroofist oli rohkem kui Ã¼ks ellujÃ¤Ã¤nu. Ã•pilase jaoks, kes alles alustab selle teema uurimist, vÃµib see vastus olla piisavalt veenev, et seda mitte kahtluse alla seada ja vÃµtta faktina. Selle tagajÃ¤rjed vÃµivad muuta tehisintellekti sÃ¼steemi ebausaldusvÃ¤Ã¤rseks ja kahjustada meie idufirma mainet.

Iga LLM-i iteratsiooniga oleme nÃ¤inud paranemist hallutsinatsioonide minimeerimisel. Isegi selle paranemise korral peame rakenduste loojate ja kasutajatena olema teadlikud nendest piirangutest.

### Kahjulik sisu

Eelmises osas kÃ¤sitlesime olukorda, kus LLM genereerib valesid vÃµi mÃµttetuid vastuseid. Teine risk, mida peame arvestama, on olukord, kus mudel vastab kahjuliku sisuga.

Kahjulik sisu vÃµib olla:

- Juhiste andmine vÃµi julgustamine enesevigastamiseks vÃµi kahju tekitamiseks teatud gruppidele.
- Vihkav vÃµi alandav sisu.
- Juhendamine rÃ¼nnakute vÃµi vÃ¤givallategude planeerimiseks.
- Juhiste andmine ebaseadusliku sisu leidmiseks vÃµi ebaseaduslike tegude sooritamiseks.
- Seksuaalselt eksplitsiitse sisu kuvamine.

Meie idufirma jaoks tahame tagada, et meil oleks Ãµiged tÃ¶Ã¶riistad ja strateegiad, et takistada sellise sisu jÃµudmist Ãµpilasteni.

### Ã•igluse puudumine

Ã•iglus tÃ¤hendab, et tehisintellekti sÃ¼steem on vaba eelarvamustest ja diskrimineerimisest ning kohtleb kÃµiki Ãµiglaselt ja vÃµrdselt. Generatiivse tehisintellekti maailmas tahame tagada, et mudeli vÃ¤ljund ei tugevdaks marginaliseeritud gruppide vÃ¤listavaid maailmavaateid.

Sellised vÃ¤ljundid ei ole ainult destruktiivsed positiivsete tootekogemuste loomisel meie kasutajatele, vaid pÃµhjustavad ka tÃ¤iendavat kahju Ã¼hiskonnale. Rakenduste loojatena peaksime alati arvestama laia ja mitmekesise kasutajaskonnaga, kui loome lahendusi generatiivse tehisintellektiga.

## Kuidas kasutada generatiivset tehisintellekti vastutustundlikult

NÃ¼Ã¼d, kui oleme tuvastanud vastutustundliku generatiivse tehisintellekti olulisuse, vaatame 4 sammu, mida saame teha, et ehitada oma tehisintellekti lahendusi vastutustundlikult:

![Leevendamise tsÃ¼kkel](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.et.png)

### Potentsiaalsete kahjude hindamine

Tarkvara testimisel testime kasutaja eeldatavaid tegevusi rakenduses. Samamoodi on hea testida mitmekesist valikut pÃ¤ringuid, mida kasutajad tÃµenÃ¤oliselt kasutavad, et hinnata potentsiaalset kahju.

Kuna meie idufirma ehitab haridustoodet, oleks hea koostada nimekiri haridusega seotud pÃ¤ringutest. See vÃµiks hÃµlmata teatud teemat, ajaloolisi fakte ja pÃ¤ringuid Ãµpilaste elust.

### Potentsiaalsete kahjude leevendamine

NÃ¼Ã¼d on aeg leida viise, kuidas mudeli ja selle vastuste pÃµhjustatud kahju ennetada vÃµi piirata. Seda saab vaadelda neljal erineval tasandil:

![Leevendamise kihid](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.et.png)

- **Mudel**. Ã•ige mudeli valimine Ãµige kasutusjuhtumi jaoks. Suuremad ja keerukamad mudelid, nagu GPT-4, vÃµivad pÃµhjustada suuremat kahjuliku sisu riski, kui neid rakendatakse vÃ¤iksemates ja spetsiifilisemates kasutusjuhtumites. Oma treeningandmete kasutamine peenhÃ¤Ã¤lestamiseks vÃ¤hendab samuti kahjuliku sisu riski.

- **TurvasÃ¼steem**. TurvasÃ¼steem on tÃ¶Ã¶riistade ja konfiguratsioonide komplekt platvormil, mis teenindab mudelit ja aitab kahju leevendada. NÃ¤iteks Azure OpenAI teenuse sisufiltreerimissÃ¼steem. SÃ¼steemid peaksid tuvastama ka jailbreak-rÃ¼nnakuid ja soovimatut tegevust, nagu robotite pÃ¤ringud.

- **Metaprompt**. Metapromptid ja maandamine on viisid, kuidas saame mudelit suunata vÃµi piirata teatud kÃ¤itumise ja teabe pÃµhjal. See vÃµib olla sÃ¼steemi sisendite kasutamine mudeli teatud piirangute mÃ¤Ã¤ratlemiseks. Lisaks pakkudes vÃ¤ljundeid, mis on sÃ¼steemi ulatuse vÃµi valdkonnaga rohkem seotud.

Samuti vÃµib kasutada tehnikaid, nagu Retrieval Augmented Generation (RAG), et mudel tÃµmbaks teavet ainult valitud usaldusvÃ¤Ã¤rsetest allikatest. Selle kursuse hilisemas osas on Ãµppetund [otsingurakenduste loomise kohta](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Kasutajakogemus**. Viimane kiht on koht, kus kasutaja suhtleb mudeliga otse meie rakenduse liidese kaudu. Sel viisil saame kujundada UI/UX-i, et piirata kasutajat mudelile saadetavate sisendite tÃ¼Ã¼pide osas, samuti teksti vÃµi pilte, mida kasutajale kuvatakse. Tehisintellekti rakenduse juurutamisel peame olema ka lÃ¤bipaistvad selle osas, mida meie generatiivne tehisintellekti rakendus suudab ja mida mitte.

Meil on terve Ãµppetund pÃ¼hendatud [AI rakenduste UX-i kujundamisele](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Mudeli hindamine**. LLM-idega tÃ¶Ã¶tamine vÃµib olla keeruline, kuna meil ei ole alati kontrolli mudeli treeningandmete Ã¼le. Sellegipoolest peaksime alati hindama mudeli jÃµudlust ja vÃ¤ljundeid. Oluline on mÃµÃµta mudeli tÃ¤psust, sarnasust, maandatust ja vÃ¤ljundi asjakohasust. See aitab pakkuda lÃ¤bipaistvust ja usaldust sidusrÃ¼hmadele ja kasutajatele.

### Vastutustundliku generatiivse tehisintellekti lahenduse haldamine

Tehisintellekti rakenduste Ã¼mber operatiivse praktika loomine on viimane etapp. See hÃµlmab koostÃ¶Ã¶d meie idufirma teiste osadega, nagu juriidiline ja turvalisus, et tagada vastavus kÃµigile regulatiivsetele poliitikatele. Enne kÃ¤ivitamist tahame koostada ka plaanid tarnimise, intsidentide kÃ¤sitlemise ja tagasipÃ¶Ã¶ramise kohta, et vÃ¤ltida kahju meie kasutajatele.

## TÃ¶Ã¶riistad

Kuigi vastutustundlike tehisintellekti lahenduste arendamine vÃµib tunduda mahukas, on see tÃ¶Ã¶ vaeva vÃ¤Ã¤rt. Generatiivse tehisintellekti valdkonna kasvades kÃ¼psevad ka tÃ¶Ã¶riistad, mis aitavad arendajatel vastutustundlikkust tÃµhusalt oma tÃ¶Ã¶voogudesse integreerida. NÃ¤iteks [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) aitab tuvastada kahjulikku sisu ja pilte API pÃ¤ringu kaudu.

## Teadmiste kontroll

Millised asjad on olulised, et tagada vastutustundlik tehisintellekti kasutamine?

1. Et vastus oleks Ãµige.
1. Kahjulik kasutamine, et tehisintellekti ei kasutataks kuritegelikel eesmÃ¤rkidel.
1. Tagamine, et tehisintellekt oleks vaba eelarvamustest ja diskrimineerimisest.

A: 2 ja 3 on Ãµiged. Vastutustundlik tehisintellekt aitab kaaluda, kuidas kahjulikke mÃµjusid ja eelarvamusi leevendada ja palju muud.

## ğŸš€ VÃ¤ljakutse

Loe [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) kohta ja vaata, mida saad oma kasutuses rakendada.

## SuurepÃ¤rane tÃ¶Ã¶, jÃ¤tka Ãµppimist

PÃ¤rast selle Ãµppetunni lÃ¤bimist vaata meie [Generatiivse tehisintellekti Ãµppekollektsiooni](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et jÃ¤tkata generatiivse tehisintellekti teadmiste arendamist!

Liigu edasi 4. Ãµppetundi, kus vaatame [Prompt Engineering Fundamentals](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

---

**LahtiÃ¼tlus**:  
See dokument on tÃµlgitud AI tÃµlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi pÃ¼Ã¼ame tagada tÃ¤psust, palume arvestada, et automaatsed tÃµlked vÃµivad sisaldada vigu vÃµi ebatÃ¤psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimtÃµlget. Me ei vastuta arusaamatuste vÃµi valesti tÃµlgenduste eest, mis vÃµivad tekkida selle tÃµlke kasutamise tÃµttu.