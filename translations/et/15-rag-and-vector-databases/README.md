<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b4b0266fbadbba7ded891b6485adc66d",
  "translation_date": "2025-10-18T02:52:08+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "et"
}
-->
# Andmete t√§iendatud genereerimine (RAG) ja vektoriandmebaasid

[![Andmete t√§iendatud genereerimine (RAG) ja vektoriandmebaasid](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.et.png)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Otsingurakenduste √µppetunnis √µppisime l√ºhidalt, kuidas integreerida oma andmeid suurtesse keelemudelitesse (LLM). Selles √µppetunnis s√ºveneme rohkem andmete sidumise kontseptsioonidesse LLM-i rakenduses, protsessi mehhanismidesse ja andmete salvestamise meetoditesse, sealhulgas nii sisukirjeldustesse kui ka tekstidesse.

> **Video tulekul peagi**

## Sissejuhatus

Selles √µppetunnis k√§sitleme j√§rgmist:

- Sissejuhatus RAG-i, mis see on ja miks seda tehisintellektis kasutatakse.

- Arusaamine, mis on vektoriandmebaasid, ja √ºhe loomine meie rakenduse jaoks.

- Praktiline n√§ide, kuidas integreerida RAG rakendusse.

## √ïpieesm√§rgid

P√§rast selle √µppetunni l√§bimist suudad:

- Selgitada RAG-i olulisust andmete otsimisel ja t√∂√∂tlemisel.

- Seadistada RAG-i rakendust ja siduda oma andmed LLM-iga.

- T√µhusalt integreerida RAG-i ja vektoriandmebaase LLM-i rakendustesse.

## Meie stsenaarium: LLM-i t√§iustamine oma andmetega

Selles √µppetunnis soovime lisada oma m√§rkmed hariduse idufirmasse, mis v√µimaldab vestlusrobotil saada rohkem teavet erinevate teemade kohta. Kasutades meie m√§rkmeid, saavad √µppijad paremini √µppida ja erinevaid teemasid m√µista, mis muudab eksamiteks valmistumise lihtsamaks. Stsenaariumi loomiseks kasutame:

- `Azure OpenAI:` LLM-i, mida kasutame vestlusroboti loomiseks

- `AI algajatele m√µeldud √µppetund n√§rviv√µrkudest:` see on andmestik, millele me oma LLM-i p√µhistame

- `Azure AI Search` ja `Azure Cosmos DB:` vektoriandmebaas, kuhu salvestame oma andmed ja loome otsinguindeksi

Kasutajad saavad oma m√§rkmetest luua harjutusteste, kordamiskaarte ja kokkuv√µtteid. Alustamiseks vaatame, mis on RAG ja kuidas see t√∂√∂tab:

## Andmete t√§iendatud genereerimine (RAG)

LLM-i poolt juhitud vestlusrobot t√∂√∂tleb kasutaja sisendeid, et genereerida vastuseid. See on loodud interaktiivseks ja suhtleb kasutajatega mitmesugustel teemadel. Kuid selle vastused on piiratud antud konteksti ja algse treeningandmestikuga. N√§iteks GPT-4 teadmiste piirang on september 2021, mis t√§hendab, et tal puuduvad teadmised p√§rast seda perioodi toimunud s√ºndmustest. Lisaks ei sisalda LLM-i treeningandmestik konfidentsiaalset teavet, nagu isiklikud m√§rkmed v√µi ettev√µtte tootek√§siraamat.

### Kuidas RAG (Andmete t√§iendatud genereerimine) t√∂√∂tab

![joonis, mis n√§itab, kuidas RAG t√∂√∂tab](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.et.png)

Oletame, et soovite juurutada vestlusrobotit, mis loob teie m√§rkmetest teste, siis vajate √ºhendust teadmistebaasiga. Siin tuleb appi RAG. RAG t√∂√∂tab j√§rgmiselt:

- **Teadmistebaas:** Enne otsingut tuleb dokumendid sisestada ja eelt√∂√∂delda, tavaliselt jagades suured dokumendid v√§iksemateks osadeks, muutes need tekstisisukirjeldusteks ja salvestades andmebaasi.

- **Kasutaja p√§ring:** Kasutaja esitab k√ºsimuse.

- **Otsing:** Kui kasutaja esitab k√ºsimuse, otsib sisukirjelduste mudel meie teadmistebaasist asjakohast teavet, et pakkuda rohkem konteksti, mis lisatakse sisendile.

- **T√§iendatud genereerimine:** LLM t√§iustab oma vastust leitud andmete p√µhjal. See v√µimaldab genereeritud vastusel p√µhineda mitte ainult eelnevalt treenitud andmetel, vaid ka lisatud konteksti asjakohasel teabel. Leitud andmeid kasutatakse LLM-i vastuste t√§iendamiseks. Seej√§rel tagastab LLM vastuse kasutaja k√ºsimusele.

![joonis, mis n√§itab RAG arhitektuuri](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.et.png)

RAG-i arhitektuur on rakendatud transformeerijate abil, mis koosnevad kahest osast: kodeerija ja dekodeerija. N√§iteks kui kasutaja esitab k√ºsimuse, kodeeritakse sisendtekst vektoriteks, mis h√µlmavad s√µnade t√§hendust, ja vektorid dekodeeritakse meie dokumendi indeksisse, et genereerida kasutaja p√§ringu p√µhjal uus tekst. LLM kasutab nii kodeerija-dekodeerija mudelit, et genereerida v√§ljund.

Kaks l√§henemisviisi RAG-i rakendamisel vastavalt ettepanekule: [Andmete t√§iendatud genereerimine teadmiste intensiivsete NLP (loomuliku keele t√∂√∂tlemise tarkvara) √ºlesannete jaoks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) on:

- **_RAG-Sequence_** kasutab leitud dokumente, et ennustada parimat v√µimalikku vastust kasutaja p√§ringule.

- **RAG-Token** kasutab dokumente j√§rgmise m√§rgi genereerimiseks ja seej√§rel otsib neid, et vastata kasutaja p√§ringule.

### Miks kasutada RAG-i?

- **Teabe rikkus:** tagab, et tekstivastused on ajakohased ja asjakohased. Seega parandab see domeenispetsiifiliste √ºlesannete t√§itmist, p√§√§sedes juurde sisemisele teadmistebaasile.

- V√§hendab v√§ljam√µeldisi, kasutades **kontrollitavat teavet** teadmistebaasis, et pakkuda konteksti kasutaja p√§ringutele.

- See on **kulut√µhus**, kuna need on √∂konoomsemad v√µrreldes LLM-i peenh√§√§lestamisega.

## Teadmistebaasi loomine

Meie rakendus p√µhineb meie isiklikel andmetel, st AI algajate √µppekava n√§rviv√µrkude √µppetunnil.

### Vektoriandmebaasid

Vektoriandmebaas, erinevalt traditsioonilistest andmebaasidest, on spetsialiseerunud andmebaas, mis on loodud sisukirjelduste salvestamiseks, haldamiseks ja otsimiseks. See salvestab dokumentide numbrilisi esitlusi. Andmete jagamine numbrilisteks sisukirjeldusteks muudab meie AI s√ºsteemile andmete m√µistmise ja t√∂√∂tlemise lihtsamaks.

Salvestame oma sisukirjeldused vektoriandmebaasidesse, kuna LLM-idel on piirang sisendina aktsepteeritavate m√§rkide arvule. Kuna te ei saa kogu sisukirjeldust LLM-ile edastada, peame need jagama osadeks ja kui kasutaja esitab k√ºsimuse, tagastatakse sisukirjeldused, mis on k√ºsimusega k√µige sarnasemad, koos sisendiga. Osadeks jagamine v√§hendab ka kulusid LLM-i kaudu edastatavate m√§rkide arvu osas.

M√µned populaarsed vektoriandmebaasid on Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Azure Cosmos DB mudeli saab luua Azure CLI abil j√§rgmise k√§suga:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist sisukirjeldusteni

Enne andmete salvestamist peame need teisendama vektori sisukirjeldusteks, enne kui need andmebaasi salvestatakse. Kui t√∂√∂tate suurte dokumentide v√µi pikkade tekstidega, saate need jagada osadeks vastavalt oodatavatele p√§ringutele. Osadeks jagamine v√µib toimuda lause tasemel v√µi l√µigu tasemel. Kuna osadeks jagamine tuletab t√§hendusi √ºmbritsevatest s√µnadest, saate osale lisada m√µne muu konteksti, n√§iteks dokumendi pealkirja v√µi lisada osa ette v√µi taha teksti. Andmeid saab osadeks jagada j√§rgmiselt:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Kui andmed on osadeks jagatud, saame seej√§rel teksti sisukirjeldada, kasutades erinevaid sisukirjelduste mudeleid. M√µned mudelid, mida saate kasutada, on: word2vec, ada-002 OpenAI poolt, Azure Computer Vision ja palju muud. Mudeli valik s√µltub kasutatavatest keeltest, kodeeritava sisu t√º√ºbist (tekst/pildid/audio), sisendi suurusest ja sisukirjelduse v√§ljundi pikkusest.

N√§ide sisukirjeldatud tekstist, kasutades OpenAI mudelit `text-embedding-ada-002`:
![kassi sisukirjeldus](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.et.png)

## Otsing ja vektorotsing

Kui kasutaja esitab k√ºsimuse, teisendab otsija selle vektoriks, kasutades p√§ringu kodeerijat, seej√§rel otsib meie dokumendi otsinguindeksist sisendiga seotud vektoreid. Kui see on tehtud, konverteerib see nii sisendvektori kui ka dokumendivektorid tekstiks ja edastab need LLM-ile.

### Otsing

Otsing toimub siis, kui s√ºsteem p√º√ºab kiiresti leida indeksist dokumente, mis vastavad otsingukriteeriumidele. Otsija eesm√§rk on leida dokumendid, mida kasutatakse konteksti pakkumiseks ja LLM-i sidumiseks teie andmetega.

Andmebaasis otsingut saab teha mitmel viisil, n√§iteks:

- **M√§rks√µnaotsing** - kasutatakse tekstotsinguteks.

- **Semantiline otsing** - kasutab s√µnade semantilist t√§hendust.

- **Vektorotsing** - teisendab dokumendid tekstist vektori esitluseks, kasutades sisukirjelduste mudeleid. Otsing tehakse dokumentide p√§ringuga, mille vektori esitlused on kasutaja k√ºsimusele k√µige l√§hemal.

- **H√ºbriid** - m√§rks√µna- ja vektorotsingu kombinatsioon.

Otsinguga kaasneb v√§ljakutse, kui andmebaasis pole p√§ringule sarnast vastust, siis tagastab s√ºsteem parima saadaval oleva teabe. Siiski saate kasutada taktikaid, nagu m√§√§rata maksimaalne kaugus asjakohasuse jaoks v√µi kasutada h√ºbriidotsingut, mis kombineerib nii m√§rks√µna- kui ka vektorotsingut. Selles √µppetunnis kasutame h√ºbriidotsingut, mis √ºhendab nii vektori- kui ka m√§rks√µnaotsingu. Salvestame oma andmed andmeraamistikku, mille veerud sisaldavad osasid ja sisukirjeldusi.

### Vektori sarnasus

Otsija otsib teadmistebaasist sisukirjeldusi, mis on √ºksteisele l√§hedal, l√§him naaber, kuna need on tekstid, mis on sarnased. Kui kasutaja esitab p√§ringu, sisukirjeldatakse see esmalt ja seej√§rel sobitatakse sarnaste sisukirjeldustega. √úldine m√µ√µt, mida kasutatakse erinevate vektorite sarnasuse leidmiseks, on kosinuse sarnasus, mis p√µhineb kahe vektori vahelisel nurgal.

Sarnasuse m√µ√µtmiseks v√µib kasutada ka alternatiive, nagu Eukleidese kaugus, mis on sirgjoon vektori otspunktide vahel, ja punktkorrutis, mis m√µ√µdab kahe vektori vastavate elementide korrutiste summat.

### Otsinguindeks

Otsingu tegemisel peame looma oma teadmistebaasi jaoks otsinguindeksi, enne kui otsingut teostame. Indeks salvestab meie sisukirjeldused ja suudab kiiresti leida k√µige sarnasemaid osasid isegi suures andmebaasis. Indeksi saame luua lokaalselt, kasutades:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Tulemuste j√§rjestamine

Kui olete andmebaasi p√§ringu teinud, v√µib olla vajalik tulemuste sorteerimine k√µige asjakohasemate j√§rgi. J√§rjestamise LLM kasutab masin√µpet, et parandada otsingutulemuste asjakohasust, j√§rjestades need k√µige asjakohasemate j√§rgi. Kasutades Azure AI Search'i, tehakse j√§rjestamine automaatselt semantilise j√§rjestaja abil. N√§ide, kuidas j√§rjestamine t√∂√∂tab l√§himate naabrite abil:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## K√µik kokku viimine

Viimane samm on LLM-i lisamine, et saada vastuseid, mis p√µhinevad meie andmetel. Seda saab rakendada j√§rgmiselt:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Meie rakenduse hindamine

### Hindamiskriteeriumid

- Esitatud vastuste kvaliteet, tagades, et need k√µlavad loomulikult, sujuvalt ja inimlikult.

- Andmete sidusus: hinnates, kas vastus p√§rineb esitatud dokumentidest.

- Asjakohasus: hinnates, kas vastus vastab ja on seotud esitatud k√ºsimusega.

- Sujuvus - kas vastus on grammatiliselt arusaadav.

## RAG-i (Andmete t√§iendatud genereerimine) ja vektoriandmebaaside kasutusv√µimalused

Funktsioonik√µned v√µivad teie rakendust mitmel viisil t√§iustada, n√§iteks:

- K√ºsimuste ja vastuste s√ºsteemid: oma ettev√µtte andmete sidumine vestlusega, mida t√∂√∂tajad saavad kasutada k√ºsimuste esitamiseks.

- Soovituss√ºsteemid: s√ºsteemi loomine, mis sobitab k√µige sarnasemad v√§√§rtused, n√§iteks filmid, restoranid ja palju muud.

- Vestlusrobotite teenused: saate salvestada vestluste ajalugu ja isikup√§rastada vestlust kasutaja andmete p√µhjal.

- Pildiotsing vektori sisukirjelduste p√µhjal, kasulik pildituvastuses ja anomaaliate tuvastamises.

## Kokkuv√µte

Oleme k√§sitlenud RAG-i p√µhivaldkondi, alates andmete lisamisest rakendusse kuni kasutaja p√§ringu ja v√§ljundini. RAG-i loomise lihtsustamiseks saate kasutada selliseid raamistikke nagu Semantic Kernel, Langchain v√µi Autogen.

## √úlesanne

J√§tkake oma √µppimist andmete t√§iendatud genereerimise (RAG) teemal, luues:

- Looge rakenduse esik√ºlg, kasutades endale sobivat raamistikku.

- Kasutage raamistikku, kas LangChain v√µi Semantic Kernel, ja looge oma rakendus uuesti.

Palju √µnne √µppetunni l√µpetamise puhul üëè.

## √ïppimine ei l√µpe siin, j√§tkake teekonda

P√§rast selle √µppetunni l√µpetamist vaadake meie [Generatiivse tehisintellekti √µppekollektsiooni](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste arendamist!

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algkeeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta arusaamatuste v√µi valesti t√µlgenduste eest, mis v√µivad tekkida selle t√µlke kasutamise t√µttu.