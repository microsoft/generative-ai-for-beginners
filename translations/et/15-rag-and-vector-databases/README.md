<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2861bbca91c0567ef32bc77fe054f9e",
  "translation_date": "2025-10-11T11:15:10+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "et"
}
-->
# Andmetel p√µhinev generatsioon (RAG) ja vektorp√µhised andmebaasid

[![Andmetel p√µhinev generatsioon (RAG) ja vektorp√µhised andmebaasid](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.et.png)](https://aka.ms/gen-ai-lesson15-gh?WT.mc_id=academic-105485-koreyst)

Otsingurakenduste √µppetunnis √µppisime l√ºhidalt, kuidas integreerida oma andmeid suurtesse keelemudelitesse (LLM). Selles √µppet√ºkis s√ºveneme rohkem andmete sidumise kontseptsiooni LLM-rakenduses, protsessi mehhanismidesse ja andmete salvestamise meetoditesse, sealhulgas nii sisukokkuv√µtete kui ka tekstide salvestamisse.

> **Video tuleb peagi**

## Sissejuhatus

Selles √µppet√ºkis k√§sitleme j√§rgmist:

- Sissejuhatus RAG-i, mis see on ja miks seda tehisintellektis kasutatakse.

- Arusaamine, mis on vektorp√µhised andmebaasid, ja √ºhe loomine meie rakenduse jaoks.

- Praktiline n√§ide, kuidas RAG-i rakendusse integreerida.

## √ïpieesm√§rgid

P√§rast selle √µppet√ºki l√§bimist suudad:

- Selgitada RAG-i t√§htsust andmete otsimisel ja t√∂√∂tlemisel.

- Seadistada RAG-rakendust ja siduda oma andmeid LLM-iga.

- T√µhusalt integreerida RAG-i ja vektorp√µhiseid andmebaase LLM-rakendustesse.

## Meie stsenaarium: LLM-ide t√§iustamine oma andmetega

Selles √µppet√ºkis soovime lisada oma m√§rkmeid haridusalasesse idufirmasse, mis v√µimaldab vestlusrobotil saada rohkem teavet erinevate teemade kohta. Kasutades oma m√§rkmeid, saavad √µppijad paremini √µppida ja erinevaid teemasid m√µista, mis muudab eksamiteks valmistumise lihtsamaks. Stsenaariumi loomiseks kasutame:

- `Azure OpenAI:` LLM, mida kasutame oma vestlusroboti loomiseks.

- `AI algajatele m√µeldud √µppetund n√§rviv√µrkudest:` see on andmestik, millele me oma LLM-i p√µhistame.

- `Azure AI Search` ja `Azure Cosmos DB:` vektorp√µhine andmebaas, kuhu salvestame oma andmed ja loome otsinguindeksi.

Kasutajad saavad oma m√§rkmetest luua harjutusteste, kordamiskaarte ja koostada l√ºhikokkuv√µtteid. Alustamiseks vaatame, mis on RAG ja kuidas see t√∂√∂tab:

## Andmetel p√µhinev generatsioon (RAG)

LLM-i toega vestlusrobot t√∂√∂tleb kasutaja sisendeid, et genereerida vastuseid. See on loodud interaktiivseks ja suhtleb kasutajatega erinevatel teemadel. Kuid selle vastused on piiratud antud konteksti ja algse treeningandmestikuga. N√§iteks GPT-4 teadmiste l√µppkuup√§ev on september 2021, mis t√§hendab, et tal puudub teadmine p√§rast seda perioodi toimunud s√ºndmustest. Lisaks ei sisalda LLM-ide treeningandmed konfidentsiaalset teavet, nagu isiklikud m√§rkmed v√µi ettev√µtte tootek√§siraamat.

### Kuidas RAG-id (andmetel p√µhinev generatsioon) t√∂√∂tavad

![joonis, mis n√§itab, kuidas RAG-id t√∂√∂tavad](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.et.png)

Oletame, et soovite juurutada vestlusrobotit, mis loob teie m√§rkmetest teste, siis vajate √ºhendust teadmistebaasiga. Siin tulebki appi RAG. RAG-id t√∂√∂tavad j√§rgmiselt:

- **Teadmistebaas:** Enne andmete otsimist tuleb need dokumendid sisestada ja eelt√∂√∂delda, tavaliselt jagades suured dokumendid v√§iksemateks osadeks, teisendades need tekstisisestusteks ja salvestades need andmebaasi.

- **Kasutaja p√§ring:** kasutaja esitab k√ºsimuse.

- **Otsing:** Kui kasutaja esitab k√ºsimuse, otsib sisestusmudel meie teadmistebaasist asjakohast teavet, et pakkuda rohkem konteksti, mis lisatakse sisendile.

- **T√§iendatud generatsioon:** LLM t√§iustab oma vastust saadud andmete p√µhjal. See v√µimaldab genereeritud vastusel p√µhineda mitte ainult eelnevalt treenitud andmetel, vaid ka lisatud konteksti asjakohasel teabel. Saadud andmeid kasutatakse LLM-i vastuste t√§iendamiseks. Seej√§rel tagastab LLM kasutaja k√ºsimusele vastuse.

![joonis, mis n√§itab RAG-ide arhitektuuri](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.et.png)

RAG-ide arhitektuur on rakendatud transformeerijate abil, mis koosnevad kahest osast: kodeerijast ja dekodeerijast. N√§iteks kui kasutaja esitab k√ºsimuse, kodeeritakse sisendtekst vektoriteks, mis h√µlmavad s√µnade t√§hendust, ja vektorid dekodeeritakse meie dokumendiindeksisse, et genereerida kasutaja p√§ringu p√µhjal uus tekst. LLM kasutab nii kodeerija-dekodeerija mudelit v√§ljundi genereerimiseks.

Kaks l√§henemisviisi RAG-i rakendamisel vastavalt pakutud artiklile: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) on:

- **_RAG-Sequence_** kasutab saadud dokumente, et ennustada kasutaja p√§ringule parim v√µimalik vastus.

- **RAG-Token** kasutab dokumente j√§rgmise s√µna genereerimiseks ja seej√§rel otsib vastuse kasutaja p√§ringule.

### Miks kasutada RAG-e?

- **Teabe rikkus:** tagab, et tekstivastused on ajakohased ja asjakohased. See parandab seega domeenispetsiifiliste √ºlesannete t√§itmist, p√§√§sedes ligi sisemisele teadmistebaasile.

- V√§hendab v√§ljam√µeldisi, kasutades **kontrollitavat teavet** teadmistebaasis, et pakkuda kasutaja p√§ringutele konteksti.

- See on **kuluefektiivne**, kuna on √∂konoomsem v√µrreldes LLM-i peenh√§√§lestamisega.

## Teadmistebaasi loomine

Meie rakendus p√µhineb meie isiklikel andmetel, st AI algajatele m√µeldud √µppekava n√§rviv√µrkude √µppetunnil.

### Vektorp√µhised andmebaasid

Vektorp√µhine andmebaas erineb traditsioonilistest andmebaasidest, kuna see on spetsialiseerunud andmete salvestamisele, haldamisele ja otsimisele vektorite kujul. See salvestab dokumentide numbrilised esitlused. Andmete jagamine numbrilisteks vektoriteks muudab meie AI-s√ºsteemile andmete m√µistmise ja t√∂√∂tlemise lihtsamaks.

Salvestame oma vektorid vektorp√µhisesse andmebaasi, kuna LLM-idel on piirang, kui palju m√§rke nad sisendina vastu v√µtavad. Kuna kogu vektoreid ei saa LLM-ile edastada, peame need jagama osadeks ja kui kasutaja esitab k√ºsimuse, tagastatakse vektorid, mis on k√ºsimusega k√µige sarnasemad, koos sisendiga. Osadeks jagamine v√§hendab ka LLM-i kaudu edastatavate m√§rkide arvu kulusid.

M√µned populaarsed vektorp√µhised andmebaasid on Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Azure Cosmos DB mudeli saab luua Azure CLI abil j√§rgmise k√§suga:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist vektoriteks

Enne andmete salvestamist peame need teisendama vektoriteks, et neid andmebaasis salvestada. Kui t√∂√∂tate suurte dokumentide v√µi pikkade tekstidega, saate need jagada osadeks vastavalt oodatavatele p√§ringutele. Osadeks jagamine v√µib toimuda lause v√µi l√µigu tasemel. Kuna osadeks jagamine tuletab t√§hendusi √ºmbritsevatest s√µnadest, saate osale lisada ka m√µne muu konteksti, n√§iteks dokumendi pealkirja v√µi m√µne teksti enne v√µi p√§rast osa. Andmeid saab osadeks jagada j√§rgmiselt:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Kui andmed on osadeks jagatud, saame need seej√§rel vektoriteks teisendada, kasutades erinevaid vektormudeleid. M√µned mudelid, mida saate kasutada, on: word2vec, ada-002 OpenAI poolt, Azure Computer Vision ja paljud teised. Mudeli valik s√µltub kasutatavatest keeltest, kodeeritava sisu t√º√ºbist (tekst/pildid/heli), sisendi suurusest ja vektori v√§ljundi pikkusest.

N√§ide OpenAI `text-embedding-ada-002` mudeli abil vektoriks teisendatud tekstist:
![kassi vektoriks teisendamine](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.et.png)

## Otsing ja vektorotsing

Kui kasutaja esitab k√ºsimuse, teisendab otsija selle vektoriks, kasutades p√§ringu kodeerijat, seej√§rel otsib meie dokumendiotsingu indeksist sisendiga seotud vektoreid. Kui see on tehtud, teisendab see nii sisendvektori kui ka dokumendivektorid tekstiks ja edastab need LLM-ile.

### Otsing

Otsing toimub siis, kui s√ºsteem p√º√ºab kiiresti leida indeksist dokumente, mis vastavad otsingukriteeriumidele. Otsija eesm√§rk on leida dokumendid, mida kasutatakse konteksti pakkumiseks ja LLM-i andmetega sidumiseks.

Andmebaasis otsingut saab teha mitmel viisil, n√§iteks:

- **M√§rks√µnaotsing** - kasutatakse tekstip√µhisteks otsinguteks.

- **Semantiline otsing** - kasutab s√µnade semantilist t√§hendust.

- **Vektorotsing** - teisendab dokumendid tekstist vektoriteks, kasutades vektormudeleid. Otsing toimub, p√§rides dokumente, mille vektorid on kasutaja k√ºsimusele k√µige l√§hemal.

- **H√ºbriidne** - m√§rks√µna- ja vektorotsingu kombinatsioon.

Otsinguga v√µib tekkida probleeme, kui andmebaasis pole p√§ringule sarnast vastust. Sel juhul tagastab s√ºsteem parima v√µimaliku teabe, mida nad saavad. Siiski saate kasutada selliseid taktikaid nagu m√§√§rata maksimaalne kaugus asjakohasuse jaoks v√µi kasutada h√ºbriidotsingut, mis √ºhendab nii m√§rks√µna- kui ka vektorotsingu. Selles √µppet√ºkis kasutame h√ºbriidotsingut, mis √ºhendab nii vektori- kui ka m√§rks√µnaotsingu. Salvestame oma andmed andmeraamistikku, mille veerud sisaldavad nii osasid kui ka vektoreid.

### Vektorite sarnasus

Otsija otsib teadmistebaasist vektoreid, mis on √ºksteisele l√§hedal, l√§himad naabrid, kuna need on sarnased tekstid. Kui kasutaja esitab p√§ringu, teisendatakse see esmalt vektoriks ja seej√§rel sobitatakse sarnaste vektoritega. Levinud m√µ√µdik, mida kasutatakse erinevate vektorite sarnasuse leidmiseks, on kosinuse sarnasus, mis p√µhineb kahe vektori vahelisel nurgal.

Sarnasuse m√µ√µtmiseks v√µib kasutada ka teisi alternatiive, n√§iteks Eukleidese kaugust, mis on sirgjoon vektorite otspunktide vahel, ja skalaarkorrutist, mis m√µ√µdab kahe vektori vastavate elementide korrutiste summat.

### Otsinguindeks

Otsingu tegemisel peame looma oma teadmistebaasi jaoks otsinguindeksi enne otsingu sooritamist. Indeks salvestab meie vektorid ja suudab kiiresti leida k√µige sarnasemad osad isegi suures andmebaasis. Indeksi saame luua kohapeal, kasutades:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Tulemuste √ºmberj√§rjestamine

P√§rast andmebaasi p√§ringut v√µib olla vajalik tulemuste sorteerimine k√µige asjakohasemate j√§rgi. √úmberj√§rjestamise LLM kasutab masin√µpet, et parandada otsingutulemuste asjakohasust, j√§rjestades need k√µige asjakohasemast. Azure AI Search kasutamisel toimub √ºmberj√§rjestamine automaatselt, kasutades semantilist √ºmberj√§rjestajat. N√§ide, kuidas √ºmberj√§rjestamine t√∂√∂tab l√§himate naabrite abil:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## K√µik kokku viimine

Viimane samm on LLM-i lisamine, et saada vastuseid, mis p√µhinevad meie andmetel. Seda saab rakendada j√§rgmiselt:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Meie rakenduse hindamine

### Hindamiskriteeriumid

- Antud vastuste kvaliteet, tagades, et need k√µlavad loomulikult, sujuvalt ja inimlikult.

- Andmete alusel vastamine: hinnates, kas vastus p√§rineb esitatud dokumentidest.

- Asjakohasus: hinnates, kas vastus vastab ja on seotud esitatud k√ºsimusega.

- Sujuvus - kas vastus on grammatiliselt loogiline.

## RAG-i (andmetel p√µhinev generatsioon) ja vektorp√µhiste andmebaaside kasutusv√µimalused

RAG-i ja vektorp√µhiseid andmebaase saab kasutada mitmesugustes olukordades, n√§iteks:

- K√ºsimuste ja vastuste s√ºsteemid: ettev√µtte andmete sidumine vestlusega, mida t√∂√∂tajad saavad kasutada k√ºsimuste esitamiseks.

- Soovituss√ºsteemid: s√ºsteemi loomine, mis sobitab k√µige sarnasemaid v√§√§rtusi, nt filme, restorane ja palju muud.

- Vestlusrobotite teenused: saate salvestada vestluste ajalugu ja isikup√§rastada vestlust kasutaja andmete p√µhjal.

- Piltide otsing vektorite p√µhjal, mis on kasulik pildituvastuses ja anomaaliate tuvastamises.

## Kokkuv√µte

Oleme k√§sitlenud RAG-i p√µhialuseid, alates andmete lisamisest rakendusse kuni kasutaja p√§ringu ja v√§ljundini. RAG-i loomise lihtsustamiseks saate kasutada selliseid raamistikke nagu Semantic Kernel, Langchain v√µi Autogen.

## √úlesanne

Et j√§tkata andmetel p√µhineva generatsiooni (RAG) √µppimist, saate luua:

- Looge rakenduse kasutajaliides, kasutades oma valitud raamistikku.

- Kasutage m√µnda raamistikku, n√§iteks LangChain v√µi Semantic Kernel, ja looge oma rakendus uuesti.

Palju √µnne √µppet√ºki l√µpetamise puhul üëè.

## √ïppimine ei l√µpe siin, j√§tka teekonda

P√§rast selle √µppet√ºki l√µpetamist vaadake meie [Generatiivse tehisintellekti √µppekollektsiooni](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste arendamist!

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algkeeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valede t√µlgenduste eest.