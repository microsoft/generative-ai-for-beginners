# Taastep√µhine t√§iustatud genereerimine (RAG) ja vektorandmebaasid

[![Taastep√µhine t√§iustatud genereerimine (RAG) ja vektorandmebaasid](../../../translated_images/et/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

Otsingurakenduste √µppetunnis √µppisime l√ºhidalt, kuidas integreerida oma andmeid suurtesse keelemudelitesse (LLM). Selles √µppetunnis s√ºveneme andmete sidumisse teie LLM-rakenduses, protsessi mehhaanikasse ja andmete salvestamise meetoditesse, sealhulgas nii manustesse kui tekstidesse.

> **Video tuleb peagi**

## Sissejuhatus

Selles √µppetunnis k√§sitleme j√§rgmist:

- Sissejuhatus RAG-i, mis see on ja miks seda tehisintellektis kasutatakse.

- M√µistmine, mis on vektorandmebaasid ja nende loomine meie rakenduse jaoks.

- Praktiline n√§ide, kuidas RAG-i rakendusse integreerida.

## √ïpieesm√§rgid

P√§rast selle √µppetunni l√§bimist oskad:

- Selgitada RAG-i t√§htsust andmete p√§ringus ja t√∂√∂tlemises.

- Seadistada RAG-rakendus ja siduda oma andmed LLM-iga.

- T√µhusalt integreerida RAG ja vektorandmebaasid LLM-rakendustesse.

## Meie stsenaarium: t√§iustame meie LLM-e oma andmetega

Selle √µppetunni jaoks tahame lisada oma m√§rkmed haridusstartupisse, mis v√µimaldab chatbotil saada rohkem teavet erinevate √µppeainete kohta. Kasutades olemasolevaid m√§rkmeid, saavad √µppijad paremini √µppida ja m√µista erinevaid teemasid, mis teeb eksamiteks kordamise lihtsamaks. Stsenaariumi loomiseks kasutame:

- `Azure OpenAI:` LLM, mida kasutame oma chatbot'i loomiseks

- `AI algajatele √µppetund n√§rviv√µrkudest:` see saab olema andmed, millele oma LLM-i p√µhistame

- `Azure AI Search` ja `Azure Cosmos DB:` vektorandmebaasid meie andmete salvestamiseks ja otsinguindeksi loomiseks

Kasutajad saavad oma m√§rkmetest luua harjutus√ºlesandeid, kordamiskaarte ja kokkuv√µtteid. Alustame RAG-i m√µistmisest ja toimimisest:

## Taastep√µhine t√§iustatud genereerimine (RAG)

LLM-toega chatbot t√∂√∂tleb kasutajate sisendeid, et genereerida vastuseid. See on loodud interaktiivseks ning suudab suhelda inimestega paljudel erinevatel teemadel. Selle vastused s√µltuvad aga ainult kontekstist ja p√µhikoolitusandmetest. N√§iteks GPT-4 teadmiste l√µppkuup√§ev on september 2021, mis t√§hendab, et tal puudub info selle ajaperioodi j√§rgselt toimunud s√ºndmuste kohta. Lisaks on LLM-ide treeningandmetest v√§lja j√§etud konfidentsiaalsed andmed nagu isiklikud m√§rkmed v√µi ettev√µtte tootemanuaal.

### Kuidas RAG-id (taastep√µhine t√§iustatud genereerimine) t√∂√∂tavad

![joonis, mis n√§itab kuidas RAG-id t√∂√∂tavad](../../../translated_images/et/how-rag-works.f5d0ff63942bd3a6.webp)

Oletame, et soovid juurutada chatbot‚Äôi, mis loob sinu m√§rkmetest viktoriine, vajalik on √ºhendus teadmistebaasiga. Siin tuleb m√§ngu RAG. RAG-id t√∂√∂tavad j√§rgmiselt:

- **Teadmistebaas:** Enne p√§ringut tuleb dokumendid importida ja eelt√∂√∂delda, tavaliselt l√µhestades suured dokumendid v√§iksemateks osadeks, teisendades need tekstiliseks manuseks ja salvestades andmebaasi.

- **Kasutaja p√§ring:** kasutaja esitab k√ºsimuse

- **P√§ring:** Kui kasutaja esitab k√ºsimuse, otsib manustamismudel meie teadmistebaasist asjakohast teavet, mida lisatakse vestluse konteksti.

- **T√§iustatud genereerimine:** LLM t√§iendab oma vastust p√§ringust saadud olulise teabe p√µhjal. See v√µimaldab genereeritud vastusel p√µhineda mitte ainult eelneval koolitusandmestikul, vaid ka lisatud konteksti asjakohasel informatsioonil. RAG abil tuuakse vastustesse juurde teadmisbaasi infot, mille alusel LLM kasutajale l√µpuks vastab.

![jmnis, mis n√§itab RAG arhitektuuri](../../../translated_images/et/encoder-decode.f2658c25d0eadee2.webp)

RAG arhitektuur on √ºles ehitatud transformeritele, millel on kaks osa: kodeerija ja dekodeerija. N√§iteks kui kasutaja esitab k√ºsimuse, kodeeritakse sisendtekst vektoriteks, mis haaravad s√µnade t√§henduse ning vektorid dekodeeritakse meie dokumentide indeksisse ja genereeritakse uus tekst kasutajap√§ringu p√µhjal. LLM kasutab nii kodeerija kui dekodeerija mudelit v√§ljundi loomiseks.

RAG-i rakendamisel on teadusartikli [Retrieval-Augmented Generation for Knowledge intensive NLP Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) kohaselt kaks l√§henemist:

- **_RAG-Sequence_** kasutab p√§ringus leitud dokumente, et ennustada parimat v√µimalikku vastust kasutaja k√ºsimusele

- **RAG-Token** kasutab dokumente j√§rgmise s√µna (tokeni) genereerimiseks ning seej√§rel otsib neid uuesti kasutaja p√§ringu jaoks vastuse saamiseks

### Miks kasutada RAG-e?

- **Informatiivsus:** tagab, et tekstivastused on v√§rsked ja ajakohased. Parandab seega spetsiifiliste valdkondade √ºlesannete t√§itmist, p√∂√∂rdudes sisemise teadmistebaasi poole.

- V√§hendab v√§ljam√µtlemist, kasutades **kontrollitavat teavet** teadmistebaasis, et pakkuda kasutajate p√§ringutele konteksti.

- On **kulut√µhus**, sest on odavam kui LLM-i peenh√§√§lestamine.

## Teadmistebaasi loomine

Meie rakendus p√µhineb meie isiklikel andmetel ehk AI algajatele n√§rviv√µrkude √µppetunnil.

### Vektorandmebaasid

Vektorandmebaas erinevalt traditsioonilistest andmebaasidest on spetsiaalne andmebaas vektorite salvestamiseks, haldamiseks ja otsimiseks. See hoiab dokumentide arvulisi esitlusi. Andmete lagundamine numbrilisteks manusteks teeb meie AI s√ºsteemil andmete m√µistmise ja t√∂√∂tlemise lihtsamaks.

Salvestame oma manused vektorandmebaasides, sest LLM-idel on sisendi jaoks tokenite arv piiratud. Kuna me ei saa kogu manustust korraga LLM-ile anda, tuleb see jagada t√ºkkideks ja kui kasutaja esitab p√§ringu, tagastatakse selle k√ºsimusele k√µige sarnasemad manused koos promptiga. Jagamine v√§hendab ka kulusid tokenite arvu pealt.

Populaarsed vektorandmebaasid on Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant ja DeepLake. Azure Cosmos DB mudeli saab luua Azure CLI abil j√§rgmise k√§suga:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Tekstist manusteks

Enne andmete salvestamist peame need teisendama vektormanusteks. Kui t√∂√∂tad suurte dokumentide v√µi pikkade tekstidega, saad need l√µhkuda vastavalt p√§ringutele, mida ootad. Jagamine v√µib toimuda lausetasandil v√µi l√µigutasandil. Kuna jagamine tuletab t√§henduse s√µnade √ºmber, v√µid lisada l√µikudele ka t√§iendava konteksti, n√§iteks dokumendi pealkirja v√µi teksti enne v√µi p√§rast l√µiku. N√§iteks v√µid andmed nii jagada:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # Kui viimane t√ºkk ei saavutanud minimaalset pikkust, lisa see siiski
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

P√§rast l√µikude moodustamist saame teksti kattes manustamismudelitega. M√µned mudelid, mida saad kasutada: word2vec, OpenAI ada-002, Azure Computer Vision ja paljud teised. Mudeli valik s√µltub kasutatavatest keeltest, kodeeritava sisu t√º√ºbist (tekst/pildid/audio), sisendi mahust ja katte v√§ljundi pikkusest.

N√§ide tekstimanusest OpenAI `text-embedding-ada-002` mudeli abil:
![kassi s√µna manustus](../../../translated_images/et/cat.74cbd7946bc9ca38.webp)

## P√§ringud ja vektorotsing

Kui kasutaja esitab k√ºsimuse, teisendab otsija selle p√§ringukodeerija abil vektoriks, otsib meie dokumentide otsinguindeksist sarnaseid vektoreid. P√§rast seda teisendab nii sisendi kui dokumentide vektorid tekstiks ja edastab LLM-ile.

### P√§ring

P√§ring toimub siis, kui s√ºsteem proovib kiiresti leida indeksi p√µhjal dokumente, mis vastavad otsingukriteeriumile. Otsija eesm√§rk on saada dokumente, mida kasutatakse konteksti pakkumiseks ja LLM-i andmetega sidumiseks.

Otsingut saab meie andmebaasis teha mitmel viisil:

- **M√§rks√µnaotsing** ‚Äì tekstip√µhine otsing

- **Vektorotsing** ‚Äì teisendab dokumendid tekstist vektoriesitlusteks, v√µimaldades **semantilist otsingut** s√µnade t√§henduse p√µhjal. P√§ring toimub dokumentide j√§rgi, mille vektorid on kasutaja k√ºsimusele l√§himad.

- **H√ºbriid** ‚Äì m√§rks√µna- ja vektorotsingu kombinatsioon.

V√§ljakutse on siis, kui andmebaasis pole p√§ringule sarnast vastust. Sel juhul tagastab s√ºsteem parima saadaoleva vastuse, kuid v√µid kasutada meetodeid nagu asjakohasuse maksimaalse kauguse seadistamine v√µi h√ºbriidotsing, mis √ºhendab m√µlemad otsingut√º√ºbid. Selles tunnis kasutame h√ºbriidotsingut, mis √ºhendab nii vektori- kui m√§rks√µnaotsingu. Salvestame andmed andmeraamatusse, mille veerud sisaldavad nii l√µike kui manuseid.

### Vektorsarnasus

Otsija otsib teadmistebaasist manuseid, mis asuvad teineteisele l√§hedal, s.t l√§himad naabrid, mis n√§itavad sarnaseid tekste. Kui kasutaja esitab p√§ringu, manustatakse see esmalt ja leitakse sarnased manused. Levim k√µnekeeles kasutatav m√µ√µdupuu sarnasuse hindamiseks on kosiinussarnasus, mis p√µhineb kahe vektori vahelisel nurgal.

Sarnasust saab m√µ√µta ka alternatiivide abil, nagu Eukleidese kaugus (otsejoon kahe vektori otspunktide vahel) ja punktitoodang (kahe vektori vastavate elementide korrutiste summa).

### Otsinguindeks

P√§ringu teostamiseks tuleb teadmistebaasile luua otsinguindeks. Indeks salvestab manused ja v√µimaldab isegi suures andmebaasis kiiresti leida k√µige sarnasemaid l√µike. Indeksi saab luua lokaalselt:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Loo otsinguisindeks
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# Indeksi p√§ringuks v√µite kasutada meetodit kneighbors
distances, indices = nbrs.kneighbors(embeddings)
```

### √úmberj√§rjestamine

P√§rast p√§ringu tegemist v√µib olla vaja tulemusi sorteerida asjakohasuse j√§rgi. √úmberj√§rjestav LLM kasutab masin√µpet, et parandada otsingutulemuste asjakohasust, j√§rjestades need asjakohasuse j√§rgi. Azure AI Search kasutab seda protsessi automaatselt semantilise √ºmberj√§rjestajaga. N√§ide sellest, kuidas √ºmberj√§rjestamine t√∂√∂tab l√§him naaber meetodi abil:

```python
# Leia k√µige sarnasemad dokumendid
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Tr√ºki v√§lja k√µige sarnasemad dokumendid
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## K√µik kokku

Viimane samm on lisada LLM, et saada vastuseid, mis p√µhinevad meie andmetel. Rakendame selle j√§rgmiselt:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Muuda k√ºsimus p√§ringuvektoriks
    query_vector = create_embeddings(user_input)

    # Leia k√µige sarnasemad dokumendid
    distances, indices = nbrs.kneighbors([query_vector])

    # lisa dokumendid p√§ringule konteksti pakkumiseks
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # √ºhenda ajalugu ja kasutaja sisend
    history.append(user_input)

    # loo s√µnumi objekt
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # kasuta vestluse l√µpetamist vastuse genereerimiseks
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Rakenduse hindamine

### Hindamiskriteeriumid

- Vastuste kvaliteet: veenduda, et k√µlaks loomulikult, sujuvalt ja inimlikult

- Andmete sidusus: hinnata, kas vastus p√§rineb esitatud dokumentidest

- Asjakohasus: kontrollida, kas vastus on seotud esitatud k√ºsimusega

- Sujuvus ‚Äì kas vastus on grammatiliselt m√µistlik

## RAG (taastep√µhine t√§iustatud genereerimine) ja vektorandmebaaside kasutusv√µimalused

RAG funktsionaalsus v√µib parandada sinu rakendust mitmel moel:

- K√ºsimuste ja vastuste s√ºsteemid: oma ettev√µtte andmete sidumine chatbot-iga, mida t√∂√∂tajad saavad kasutada k√ºsimuste esitamiseks.

- Soovituss√ºsteemid: s√ºsteemi loomine, mis leiab k√µige sarnasemad v√§√§rtused, nt filmid, restoranid jpm.

- Chatboti teenused: vestlusajaloo salvestamine ja vestluse isikup√§rastamine kasutajaandmete p√µhjal.

- P√µhineb vektormanustel pildiotsing, kasulik pildituvastuses ja anomaaliate avastamisel.

## Kokkuv√µte

K√§sitlesime RAG-i p√µhit√µdesid, kuidas lisada andmeid rakendusse, kasutaja p√§ringut ja v√§ljundit. RAG-i loomise lihtsustamiseks v√µid kasutada raamistikke nagu Semantic Kernel, Langchain v√µi Autogen.

## Kodut√∂√∂

J√§tkamaks oma teadmiste arendamist Retrieval Augmented Generation (RAG) valdkonnas, v√µid ehitada:

- Rakenduse kasutajaliidese raamistiku abil, mida ise valid

- Kasutada raamistikku, n√§iteks LangChain v√µi Semantic Kernel, ning taasluua oma rakendus

Palju √µnne √µppetunni l√µpetamise puhul üëè.

## √ïppimine siin ei l√µpe, j√§tka teekonda

P√§rast selle √µppetunni l√µpetamist vaata meie [Generative AI √µppimiskogu](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata generatiivse tehisintellekti teadmiste t√µstmist!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Vastutusest loobumine**:
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame t√µlke t√§psust tagada, palun arvestage, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Originaaldokument selle emakeeles on ametlik ja autoriteetne allikas. Olulise info puhul soovitatakse kasutada professionaalse inimt√µlke teenust. Me ei vastuta √ºhegi arusaamatuse v√µi valesti t√µlgendamise eest, mis v√µib sellest t√µlkest tekkida.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->