<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-18T02:54:52+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "et"
}
-->
[![Avatud l√§htekoodiga mudelid](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.et.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# LLM-i peenh√§√§lestamine

Generatiivse tehisintellekti rakenduste loomine suurte keelemudelite abil toob kaasa uusi v√§ljakutseid. Oluline probleem on tagada mudeli poolt genereeritud sisu kvaliteet (t√§psus ja asjakohasus) vastavalt kasutaja p√§ringule. Eelnevates tundides arutasime tehnikaid nagu promptide kujundamine ja otsinguga t√§iendatud genereerimine, mis p√º√ºavad probleemi lahendada _muutes olemasoleva mudeli sisendit_.

T√§nases tunnis arutame kolmandat tehnikat, **peenh√§√§lestamist**, mis p√º√ºab v√§ljakutset lahendada _mudeli enda √ºmber√µpetamisega_ t√§iendavate andmetega. Sukeldume detailidesse.

## √ïpieesm√§rgid

See tund tutvustab peenh√§√§lestamise kontseptsiooni eelnevalt treenitud keelemudelite jaoks, uurib selle l√§henemisviisi eeliseid ja v√§ljakutseid ning annab juhiseid, millal ja kuidas kasutada peenh√§√§lestamist, et parandada generatiivse tehisintellekti mudelite j√µudlust.

Tunni l√µpuks peaksid sa olema v√µimeline vastama j√§rgmistele k√ºsimustele:

- Mis on keelemudelite peenh√§√§lestamine?
- Millal ja miks on peenh√§√§lestamine kasulik?
- Kuidas saab eelnevalt treenitud mudelit peenh√§√§lestada?
- Millised on peenh√§√§lestamise piirangud?

Valmis? Alustame.

## Illustreeritud juhend

Kas tahad enne s√ºvitsi minemist saada √ºlevaate, mida me k√§sitleme? Vaata seda illustreeritud juhendit, mis kirjeldab √µpiteekonda selle tunni jaoks - alates peenh√§√§lestamise p√µhikontseptsioonide ja motivatsiooni √µppimisest kuni protsessi ja parimate praktikate m√µistmiseni peenh√§√§lestamise √ºlesande t√§itmiseks. See on p√µnev teema uurimiseks, nii et √§ra unusta vaadata [Ressursid](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) lehte, et leida lisamaterjale iseseisvaks √µppimiseks!

![Illustreeritud juhend keelemudelite peenh√§√§lestamiseks](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.et.png)

## Mis on keelemudelite peenh√§√§lestamine?

Definitsiooni j√§rgi on suured keelemudelid _eelnevalt treenitud_ suurel hulgal tekstidel, mis p√§rinevad mitmesugustest allikatest, sealhulgas internetist. Nagu oleme √µppinud eelnevates tundides, vajame selliseid tehnikaid nagu _promptide kujundamine_ ja _otsinguga t√§iendatud genereerimine_, et parandada mudeli vastuste kvaliteeti kasutaja k√ºsimustele ("promptidele").

Populaarne promptide kujundamise tehnika h√µlmab mudelile t√§iendava juhise andmist, mis selgitab, mida vastuses oodatakse, kas _instruktsioonide_ (otsene juhendamine) v√µi _m√µne n√§ite andmise_ (kaudne juhendamine) kaudu. Seda nimetatakse _few-shot √µppimiseks_, kuid sellel on kaks piirangut:

- Mudeli tokenite piirangud v√µivad piirata n√§idete arvu, mida saab anda, ja v√§hendada t√µhusust.
- Mudeli tokenite kulud v√µivad muuta kalliks n√§idete lisamise igale promptile ja piirata paindlikkust.

Peenh√§√§lestamine on masin√µppe s√ºsteemides levinud praktika, kus v√µtame eelnevalt treenitud mudeli ja treenime seda uuesti uute andmetega, et parandada selle j√µudlust konkreetse √ºlesande t√§itmisel. Keelemudelite kontekstis saame eelnevalt treenitud mudelit peenh√§√§lestada _hoolikalt valitud n√§idete kogumiga konkreetse √ºlesande v√µi rakenduse valdkonna jaoks_, et luua **kohandatud mudel**, mis v√µib olla t√§psem ja asjakohasem just selle konkreetse √ºlesande v√µi valdkonna jaoks. Peenh√§√§lestamise k√µrvalm√µju on see, et see v√µib v√§hendada n√§idete arvu, mida on vaja few-shot √µppimiseks - v√§hendades tokenite kasutust ja sellega seotud kulusid.

## Millal ja miks peaksime mudeleid peenh√§√§lestama?

Selles kontekstis, kui r√§√§gime peenh√§√§lestamisest, viitame **juhendatud** peenh√§√§lestamisele, kus √ºmber√µpe toimub **uute andmete lisamisega**, mis ei olnud osa algsest treeningandmestikust. See erineb juhendamata peenh√§√§lestamise l√§henemisest, kus mudelit treenitakse uuesti algsete andmetega, kuid erinevate h√ºperparameetritega.

Oluline on meeles pidada, et peenh√§√§lestamine on keerukas tehnika, mis n√µuab teatud tasemel asjatundlikkust, et saavutada soovitud tulemusi. Kui seda tehakse valesti, ei pruugi see anda oodatud parandusi ja v√µib isegi halvendada mudeli j√µudlust sihitud valdkonnas.

Seega, enne kui √µpid, "kuidas" keelemudeleid peenh√§√§lestada, pead teadma "miks" peaksid seda teed minema ja "millal" alustada peenh√§√§lestamise protsessi. Alusta endale j√§rgmiste k√ºsimuste esitamisest:

- **Kasutusjuht**: Mis on sinu _kasutusjuht_ peenh√§√§lestamiseks? Millist aspekti praegusest eelnevalt treenitud mudelist tahad parandada?
- **Alternatiivid**: Kas oled proovinud _teisi tehnikaid_, et saavutada soovitud tulemusi? Kasuta neid v√µrdlusalusena.
  - Promptide kujundamine: Proovi tehnikaid nagu few-shot promptimine asjakohaste vastuste n√§idetega. Hinda vastuste kvaliteeti.
  - Otsinguga t√§iendatud genereerimine: Proovi t√§iendada promte otsingutulemustega, mis on saadud sinu andmete otsingust. Hinda vastuste kvaliteeti.
- **Kulud**: Kas oled tuvastanud peenh√§√§lestamise kulud?
  - H√§√§lestatavus - kas eelnevalt treenitud mudel on peenh√§√§lestamiseks saadaval?
  - Pingutus - treeningandmete ettevalmistamiseks, mudeli hindamiseks ja t√§iendamiseks.
  - Arvutusv√µimsus - peenh√§√§lestamise t√∂√∂de k√§ivitamiseks ja peenh√§√§lestatud mudeli juurutamiseks.
  - Andmed - piisava kvaliteediga n√§idete k√§ttesaadavus peenh√§√§lestamise m√µju jaoks.
- **Eelised**: Kas oled kinnitanud peenh√§√§lestamise eelised?
  - Kvaliteet - kas peenh√§√§lestatud mudel √ºletas v√µrdlusaluse?
  - Kulud - kas see v√§hendab tokenite kasutust, lihtsustades promte?
  - Laiendatavus - kas saad baasmudelit uute valdkondade jaoks uuesti kasutada?

Neile k√ºsimustele vastates peaksid sa suutma otsustada, kas peenh√§√§lestamine on sinu kasutusjuhtumi jaoks √µige l√§henemine. Ideaalis on l√§henemine √µigustatud ainult siis, kui eelised kaaluvad √ºles kulud. Kui otsustad j√§tkata, on aeg m√µelda, _kuidas_ saad eelnevalt treenitud mudelit peenh√§√§lestada.

Tahad rohkem teavet otsustusprotsessi kohta? Vaata [Kas peenh√§√§lestada v√µi mitte peenh√§√§lestada](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kuidas saame eelnevalt treenitud mudelit peenh√§√§lestada?

Eelnevalt treenitud mudeli peenh√§√§lestamiseks on sul vaja:

- eelnevalt treenitud mudelit, mida peenh√§√§lestada
- andmestikku, mida kasutada peenh√§√§lestamiseks
- treeningkeskkonda peenh√§√§lestamise t√∂√∂ k√§ivitamiseks
- hostimiskeskkonda peenh√§√§lestatud mudeli juurutamiseks

## Peenh√§√§lestamine praktikas

J√§rgnevad ressursid pakuvad samm-sammult juhendeid, et viia l√§bi reaalne n√§ide valitud mudeli ja hoolikalt valitud andmestikuga. Nende juhendite l√§bimiseks on sul vaja konto konkreetse teenusepakkuja juures, samuti juurdep√§√§su vastavale mudelile ja andmestikele.

| Teenusepakkuja | Juhend                                                                                                                                                                       | Kirjeldus                                                                                                                                                                                                                                                                                                                                                                                                                        |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI         | [Kuidas peenh√§√§lestada vestlusmudeleid](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)     | √ïpi peenh√§√§lestama `gpt-35-turbo` konkreetse valdkonna jaoks ("retsepti assistent") treeningandmete ettevalmistamise, peenh√§√§lestamise t√∂√∂ k√§ivitamise ja peenh√§√§lestatud mudeli kasutamise kaudu.                                                                                                                                                                                                                              |
| Azure OpenAI   | [GPT 3.5 Turbo peenh√§√§lestamise juhend](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | √ïpi peenh√§√§lestama `gpt-35-turbo-0613` mudelit **Azure'is**, tehes samme treeningandmete loomiseks ja √ºleslaadimiseks, peenh√§√§lestamise t√∂√∂ k√§ivitamiseks. Juuruta ja kasuta uut mudelit.                                                                                                                                                                                                                                       |
| Hugging Face   | [LLM-ide peenh√§√§lestamine Hugging Face'iga](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                       | See blogipostitus juhendab sind peenh√§√§lestama _avatud LLM-i_ (nt `CodeLlama 7B`) kasutades [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) teeki ja [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) koos avatud [andmestikega](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) Hugging Face'is. |
|                |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ü§ó AutoTrain   | [LLM-ide peenh√§√§lestamine AutoTrain'iga](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                 | AutoTrain (v√µi AutoTrain Advanced) on Hugging Face'i poolt v√§lja t√∂√∂tatud Python teek, mis v√µimaldab peenh√§√§lestamist paljude erinevate √ºlesannete jaoks, sealhulgas LLM-i peenh√§√§lestamine. AutoTrain on koodivaba lahendus ja peenh√§√§lestamist saab teha oma pilves, Hugging Face Spaces'is v√µi lokaalselt. See toetab nii veebip√µhist GUI-d, CLI-d kui ka treenimist yaml-konfiguratsioonifailide kaudu.                           |
|                |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                  |

## √úlesanne

Vali √ºks √ºlaltoodud juhenditest ja tee see l√§bi. _V√µime nende juhendite versioone repositooriumis Jupyter Notebookides reprodutseerida ainult viitamiseks. Palun kasuta otse algallikaid, et saada k√µige uuemaid versioone_.

## Tubli t√∂√∂! J√§tka √µppimist.

P√§rast selle tunni l√µpetamist vaata meie [Generatiivse tehisintellekti √µppekollektsiooni](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste arendamist!

Palju √µnne!! Oled l√µpetanud selle kursuse v2 seeria viimase tunni! √Ñra l√µpeta √µppimist ja loomist. \*\*Vaata [RESSURSID](RESOURCES.md?WT.mc_id=academic-105485-koreyst) lehte, et leida t√§iendavaid soovitusi just selle teema kohta.

Meie v1 tundide seeria on samuti uuendatud rohkemate √ºlesannete ja kontseptsioonidega. Seega v√µta hetk, et oma teadmisi v√§rskendada - ja palun [jaga oma k√ºsimusi ja tagasisidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), et aidata meil neid tunde kogukonna jaoks paremaks muuta.

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta arusaamatuste v√µi valesti t√µlgenduste eest, mis v√µivad tekkida selle t√µlke kasutamise t√µttu.