<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T19:40:40+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "et"
}
-->
[![Open Source Models](../../../../../translated_images/et/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Oma LLM-i peenh√§√§lestamine

Suure keelemudelite kasutamine generatiivsete tehisintellekti rakenduste loomiseks toob kaasa uusi v√§ljakutseid. √úks peamisi k√ºsimusi on tagada mudeli poolt kasutaja p√§ringule genereeritud sisu vastuste kvaliteet (t√§psus ja asjakohasus). Eelnevates √µppetundides k√§sitlesime tehnikaid nagu promptide insenerit√∂√∂ ja otsingup√µhine generatsioon, mis p√º√ºavad seda probleemi lahendada _muutes mudelile sisestatavat prompti_.

Selles √µppetunnis arutleme kolmandat tehnikat, **peenh√§√§lestamist**, mis p√º√ºab v√§ljakutse lahendada _mudeli enda √ºmber√µppe_ abil t√§iendava andmestiku peal. S√ºveneme detailidesse.

## √ïpieesm√§rgid

See √µppetund tutvustab ette√µpetatud keelemudelite peenh√§√§lestamise m√µistet, uurib selle l√§henemise eeliseid ja v√§ljakutseid ning annab juhiseid, millal ja kuidas kasutada peenh√§√§lestamist oma generatiivse tehisintellekti mudelite j√µudluse parandamiseks.

Selle √µppetunni l√µpuks peaksid sa oskama vastata j√§rgmistele k√ºsimustele:

- Mis on keelemudelite peenh√§√§lestamine?
- Millal ja miks on peenh√§√§lestamine kasulik?
- Kuidas saan ette√µpetatud mudelit peenh√§√§lestada?
- Millised on peenh√§√§lestamise piirangud?

Valmis? Alustame.

## Joonistatud juhend

Tahad saada √ºlevaadet sellest, mida me √µppetunni jooksul k√§sitleme, enne kui p√µhjalikumalt s√ºveneme? Vaatle seda joonistatud juhendit, mis kirjeldab √µppeprotsessi sellest √µppetunnist ‚Äì alustades peenh√§√§lestamise p√µhim√µtetest ja motiivist kuni protsessi ja parimate tavade m√µistmiseni peenh√§√§lestamise √ºlesande l√§biviimisel. See on p√µnev uurimisvaldkond, nii et √§ra unusta vaadata ka [ressursside](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) lehte lisalinkide saamiseks iseseisva √µppimise toetuseks!

![Illustrated Guide to Fine Tuning Language Models](../../../../../translated_images/et/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Mis on keelemudelite peenh√§√§lestamine?

S√µna otseses m√µttes on suured keelemudelid _ette√µpetatud_ suurte koguste tekstiga, mis p√§rineb erinevatest allikatest, sealhulgas internetist. Nagu oleme eelnevates tundides √µppinud, vajame me selliseid tehnikaid nagu _promptide insenerit√∂√∂_ ja _otsingup√µhine generatsioon_, et parandada mudeli vastuste kvaliteeti kasutaja k√ºsimustele (‚Äûpromptidele‚Äú).

Populaarne promptide insenerit√∂√∂ tehnika on anda mudelile rohkem juhiseid selle kohta, mida vastuses oodatakse, kas jagades _juhiseid_ (selgeid suuniseid) v√µi _andmata m√µned n√§ited_ (kaudsed suunised). Seda nimetatakse _v√§heste n√§idete √µppimiseks (few-shot learning)_, kuid see on kahe piiranguga:

- Mudeli tokeni limiidid v√µivad piirata n√§idete arvu, mida saad anda, ning v√§hendada efektiivsust.
- Mudeli tokenite kulud v√µivad muuta n√§idete lisamise igale promptile kulukaks ning piirata paindlikkust.

Peenh√§√§lestamine on masin√µppes tavap√§rane praktika, kus v√µetakse ette√µpetatud mudel ja tehakse see uuesti v√§lja√µpetatud uue andmestiku peal, et parandada selle j√µudlust konkreetse √ºlesande t√§itmisel. Keelemudelite kontekstis saame peenh√§√§lestada ette√µpetatud mudeli _hoolikalt valitud n√§idiste komplektiga antud √ºlesande v√µi rakenduse valdkonna jaoks_, et luua **kohandatud mudel**, mis v√µib olla t√§psem ja asjakohasem just selle konkreetse √ºlesande v√µi valdkonna jaoks. Peenh√§√§lestamise k√µrvaline kasu on ka see, et see v√µib v√§hendada v√§heste n√§idete √µppimiseks vajalike n√§idete arvu ‚Äì v√§hendades tokeni kasutust ja sellega seotud kulusid.

## Millal ja miks peaksime malle peenh√§√§lestama?

_Just_ siin kontekstis, kui r√§√§gime peenh√§√§lestamisest, viitame me **juhendatud** peenh√§√§lestamisele, kus √ºmber√µpe toimub **uue andmestiku lisamisega**, mis ei kuulunud algse treeningandmestiku hulka. See erineb juhendamata peenh√§√§lestamisest, kus mudelit koolitatakse √ºmber algandmete peal, kuid erinevate h√ºperparameetritega.

Oluline on meeles pidada, et peenh√§√§lestamine on t√§iustatud tehnika, mis vajab eduka tulemuse saamiseks teatud oskustaset. Kui seda tehakse valesti, ei pruugi see anda oodatud paranemist ning v√µib isegi mudeli j√µudlust sihtrakenduse valdkonnas halvendada.

Seega, enne kui √µpid, "kuidas" keelemudeleid peenh√§√§lestada, pead teadma, "miks" valida see tee ja "millal" alustada peenh√§√§lestamise protsessiga. Alusta nende k√ºsimuste esitamisest endale:

- **Kasutusjuhtum**: Mis on sinu _kasutusjuhtum_ peenh√§√§lestamiseks? Millist mudeli omadust soovid parandada?
- **Alternatiivid**: Kas oled proovinud _teisi tehnikaid_ soovitud tulemuste saavutamiseks? Kasuta neid v√µrdlusp√µhja loomiseks.
  - Promptide insenerit√∂√∂: Proovi v√§heste n√§idete meetodit, lisades asjakohaseid n√§iteid promptide vastustest. Hinda vastuste kvaliteeti.
  - Otsingup√µhine generatsioon: Katseta promptide t√§iendamist otsingup√§ringutest saadud tulemustega. Hinda vastuste kvaliteeti.
- **Kulud**: Kas oled m√§√§ratlenud peenh√§√§lestamise kulud?
  - H√§√§lestatavus ‚Äì kas ette√µpetatud mudel on peenh√§√§lestamiseks saadaval?
  - Pingutus ‚Äì treeningandmete ettevalmistamine, mudeli hindamine ja t√§iustamine
  - Arvutusv√µimsus ‚Äì peenh√§√§lestamise t√∂√∂de k√§ivitamine ja peenh√§√§lestatud mudeli juurutamine
  - Andmed ‚Äì juurdep√§√§s piisava kvaliteediga n√§idetele peenh√§√§lestuse m√µju saavutamiseks
- **Kasud**: Kas oled kinnitanud peenh√§√§lestamise eelised?
  - Kvaliteet ‚Äì kas peenh√§√§lestatud mudel √ºletas v√µrdlusp√µhja?
  - Kulud ‚Äì kas see v√§hendab tokenite kasutust, lihtsustades promptide struktuuri?
  - Laiendatavus ‚Äì kas baasmodeli saab taaskasutada uutes valdkondades?

Nendele k√ºsimustele vastates peaksid oskama otsustada, kas peenh√§√§lestamine on sinu kasutusjuhtumi jaoks √µige l√§henemine. K√µige parem on valida selline lahendus, kus eelised kaaluvad √ºles kulud. Kui oled otsustanud j√§tkata, on aeg m√µelda, _kuidas_ peenh√§√§lestada ette√µpetatud mudelit.

Soovid rohkem teadmisi otsustusprotsessi kohta? Vaata [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kuidas peenh√§√§lestada ette√µpetatud mudelit?

Peenh√§√§lestamiseks vajad:

- peenh√§√§lestamiseks ette√µpetatud mudelit
- andmestikku peenh√§√§lestamiseks
- treeningkeskkonda peenh√§√§lestamise t√∂√∂ k√§ivitamiseks
- majutuskeskkonda peenh√§√§lestatud mudeli juurutamiseks

## Peenh√§√§lestamine praktikas

J√§rgmised ressursid annavad samm-sammult juhised reaalse n√§ite jaoks, kasutades valitud mudelit ja hoolikalt koostatud andmestikku. Nende √µpetustega t√∂√∂tamiseks vajad vastava teenusepakkuja kontot ning juurdep√§√§su mudelile ja andmestikule.

| Pakkuja     | √ïpetus                                                                                                                                                                        | Kirjeldus                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [How to fine-tune chat models](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)               | √ïpi peenh√§√§lestama mudelit `gpt-35-turbo` konkreetseks valdkonnaks (‚Äûretsepti assistent‚Äú) koolitusandmete ettevalmistamise, peenh√§√§lestamise t√∂√∂ teostamise ja peenh√§√§lestatud mudeli kasutamise kaudu j√§relduste tegemiseks.                                                                                                                                                                                                        |
| Azure OpenAI| [GPT 3.5 Turbo fine-tuning tutorial](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | √ïpi peenh√§√§lestama mudelit `gpt-35-turbo-0613` **Azure'i platvormil**: loo ja laadi √ºles koolitusandmed, k√§ivita peenh√§√§lestamise t√∂√∂, deployeri ning kasuta uut mudelit.                                                                                                                                                                                                                                                      |
| Hugging Face| [Fine-tuning LLMs with Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | See blogipostitus juhendab sind peenh√§√§lestama _avatud LLM-i_ (nt `CodeLlama 7B`) [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) teeki ja [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) abil, kasutades avatud [andmestikke](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) Hugging Face‚Äôis. |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ü§ó AutoTrain| [Fine-tuning LLMs with AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                        | AutoTrain (v√µi AutoTrain Advanced) on Hugging Face‚Äôi poolt v√§lja t√∂√∂tatud Python'i teek, mis v√µimaldab peenh√§√§lestamist paljude erinevate √ºlesannete jaoks, sealhulgas LLM peenh√§√§lestamine. AutoTrain on koodivaba lahendus ja peenh√§√§lestamist saab teostada oma pilves, Hugging Face Spaces‚Äôis v√µi lokaalselt. Toetab nii veebiliidest, k√§surea liidest kui koolitust yaml konfiguratsioonifailide abil.                                                                               |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ü¶• Unsloth  | [Fine-tuning LLMs with Unsloth](https://github.com/unslothai/unsloth)                                                                                                        | Unsloth on avatud l√§htekoodiga raamistik, mis toetab LLM-i peenh√§√§lestamist ja tugevdus√µpet (RL). Unsloth lihtsustab kohaliku treeningu, hindamise ja juurutamise protsessi k√§ttevalmis [notebook'ite](https://github.com/unslothai/notebooks) abil. Samuti toetab teksti k√µneks teisendust (TTS), BERT-i ja multimodaalseid mudeleid. Alustamiseks loe nende samm-sammult juhendit [Fine-tuning LLMs Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).             |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
## Kodut√∂√∂

Vali √ºks √ºlaltoodud √µpetustest ja l√§bi selle samm-sammult. _V√µimalik, et kopeerime nende √µpetuste versiooni Jupyter Notebooki faili sellesse hoidla, ainult viidetena. Palun kasuta otse algallikaid, et saada viimased versioonid_.

## V√§ga hea t√∂√∂! J√§tka √µppimist.

P√§rast selle √µppetunni l√µpetamist vaata meie [Generative AI √µppimiskogu](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste s√ºvendamist!

Palju √µnne!! Sa oled l√µpetanud selle kursuse v2 sari viimasel √µppetunnil! √Ñra peatu √µppimast ja ehitamast. \*\*Vaata [RESSURSID](RESOURCES.md?WT.mc_id=academic-105485-koreyst) lehte selle teema kohta lisasoovituste saamiseks.

Meie v1 √µppetundide sari on samuti uuendatud rohkemate kodut√∂√∂de ja m√µistetega. V√µta hetk aega oma teadmiste v√§rskendamiseks ‚Äì ja palun [jaga oma k√ºsimusi ja tagasisidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), et aidata meil neid √µppetunde kogukonna jaoks paremaks muuta.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Vastutusest loobumine**:  
See dokument on t√µlgitud tehisintellekti t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi me p√º√ºame tagada t√§psust, palun pidage meeles, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Originaaldokument selle emakeeles tuleks pidada autoriteetseks allikaks. T√§htsa teabe puhul soovitatakse kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tingitud arusaamatuste ega vale t√µlgenduste eest.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->