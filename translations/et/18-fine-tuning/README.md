<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-10-11T11:50:01+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "et"
}
-->
[![Avatud l√§htekoodiga mudelid](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.et.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# LLM-i peenh√§√§lestamine

Generatiivse tehisintellekti rakenduste loomine suurte keelemudelite abil toob kaasa uusi v√§ljakutseid. √úks peamisi probleeme on tagada vastuste kvaliteet (t√§psus ja asjakohasus), mida mudel genereerib vastuseks kasutaja p√§ringule. Eelnevates tundides arutasime tehnikaid nagu _p√µhivihjete kujundamine_ ja _otsinguga t√§iustatud genereerimine_, mis p√º√ºavad probleemi lahendada, _muutes mudeli sisendit_.

T√§nases tunnis k√§sitleme kolmandat tehnikat, **peenh√§√§lestamist**, mis p√º√ºab v√§ljakutset lahendada, _treenides mudelit uuesti_ t√§iendavate andmetega. Sukeldume detailidesse.

## √ïpieesm√§rgid

Selles tunnis tutvustatakse peenh√§√§lestamise kontseptsiooni eelnevalt treenitud keelemudelite jaoks, uuritakse selle l√§henemisviisi eeliseid ja v√§ljakutseid ning antakse juhiseid, millal ja kuidas kasutada peenh√§√§lestamist, et parandada generatiivse tehisintellekti mudelite j√µudlust.

Tunni l√µpuks peaksid sa olema v√µimeline vastama j√§rgmistele k√ºsimustele:

- Mis on keelemudelite peenh√§√§lestamine?
- Millal ja miks on peenh√§√§lestamine kasulik?
- Kuidas saab eelnevalt treenitud mudelit peenh√§√§lestada?
- Millised on peenh√§√§lestamise piirangud?

Valmis? Alustame.

## Illustreeritud juhend

Tahad enne s√ºvitsi minemist saada √ºlevaate, mida me k√§sitleme? Vaata seda illustreeritud juhendit, mis kirjeldab √µpiteekonda selles tunnis ‚Äì alates peenh√§√§lestamise p√µhikontseptsioonide ja motivatsiooni √µppimisest kuni protsessi ja parimate praktikate m√µistmiseni peenh√§√§lestamise √ºlesande t√§itmiseks. See on p√µnev teema uurimiseks, nii et √§ra unusta vaadata [Ressursid](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) lehte, et leida lisalinke, mis toetavad sinu iseseisvat √µpiteekonda!

![Illustreeritud juhend keelemudelite peenh√§√§lestamiseks](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.et.png)

## Mis on keelemudelite peenh√§√§lestamine?

Definitsiooni j√§rgi on suured keelemudelid _eelnevalt treenitud_ suurte tekstikoguste p√µhjal, mis p√§rinevad mitmesugustest allikatest, sealhulgas internetist. Nagu oleme eelnevates tundides √µppinud, vajame tehnikaid nagu _p√µhivihjete kujundamine_ ja _otsinguga t√§iustatud genereerimine_, et parandada mudeli vastuste kvaliteeti kasutaja k√ºsimustele ("vihjetele").

Populaarne p√µhivihjete kujundamise tehnika h√µlmab mudelile rohkem juhiste andmist selle kohta, mida vastuses oodatakse, kas _instruktsioonide_ (selged juhised) v√µi _m√µne n√§ite andmise_ (kaudsed juhised) kaudu. Seda nimetatakse _m√µne n√§ite √µppimiseks_ (few-shot learning), kuid sellel on kaks piirangut:

- Mudeli tokenite piirangud v√µivad piirata n√§idete arvu, mida saab anda, ja v√§hendada t√µhusust.
- Mudeli tokenite kulud v√µivad muuta kalliks n√§idete lisamise igale vihjele ja piirata paindlikkust.

Peenh√§√§lestamine on masin√µppe s√ºsteemides levinud praktika, kus v√µtame eelnevalt treenitud mudeli ja treenime seda uuesti uute andmetega, et parandada selle j√µudlust konkreetse √ºlesande puhul. Keelemudelite kontekstis saame peenh√§√§lestada eelnevalt treenitud mudelit _hoolikalt valitud n√§idete kogumiga konkreetse √ºlesande v√µi rakendusvaldkonna jaoks_, et luua **kohandatud mudel**, mis v√µib olla t√§psem ja asjakohasem selle konkreetse √ºlesande v√µi valdkonna jaoks. Peenh√§√§lestamise k√µrvalkasuks on ka see, et see v√µib v√§hendada n√§idete arvu, mida on vaja m√µne n√§ite √µppimiseks ‚Äì v√§hendades tokenite kasutust ja sellega seotud kulusid.

## Millal ja miks peaksime mudeleid peenh√§√§lestama?

_Selles_ kontekstis, kui r√§√§gime peenh√§√§lestamisest, viitame **juhendatud** peenh√§√§lestamisele, kus uuesti treenimine toimub **uute andmete lisamisega**, mis ei olnud osa algsest treeningandmestikust. See erineb juhendamata peenh√§√§lestamise l√§henemisest, kus mudelit treenitakse uuesti algsete andmete p√µhjal, kuid erinevate h√ºperparameetritega.

Peamine, mida meeles pidada, on see, et peenh√§√§lestamine on edasij√µudnud tehnika, mis n√µuab teatud tasemel ekspertiisi, et saavutada soovitud tulemusi. Kui seda tehakse valesti, ei pruugi see anda oodatud parandusi ja v√µib isegi halvendada mudeli j√µudlust sihitud valdkonnas.

Seega, enne kui √µpid "kuidas" keelemudeleid peenh√§√§lestada, pead teadma "miks" peaksid seda teed minema ja "millal" alustada peenh√§√§lestamise protsessi. Alusta nende k√ºsimuste esitamisest:

- **Kasutusjuht**: Mis on sinu _kasutusjuht_ peenh√§√§lestamiseks? Millist aspekti praegusest eelnevalt treenitud mudelist tahad parandada?
- **Alternatiivid**: Kas oled proovinud _teisi tehnikaid_, et saavutada soovitud tulemusi? Kasuta neid v√µrdlusaluse loomiseks.
  - P√µhivihjete kujundamine: Proovi tehnikaid nagu m√µne n√§ite vihjete andmine koos asjakohaste vastuste n√§idetega. Hinda vastuste kvaliteeti.
  - Otsinguga t√§iustatud genereerimine: Proovi t√§iendada vihjeid p√§ringutulemustega, mis on saadud sinu andmete otsinguga. Hinda vastuste kvaliteeti.
- **Kulud**: Kas oled tuvastanud peenh√§√§lestamise kulud?
  - H√§√§lestatavus ‚Äì kas eelnevalt treenitud mudel on peenh√§√§lestamiseks saadaval?
  - Pingutus ‚Äì treeningandmete ettevalmistamiseks, mudeli hindamiseks ja t√§iendamiseks.
  - Arvutusv√µimsus ‚Äì peenh√§√§lestamise t√∂√∂de k√§ivitamiseks ja peenh√§√§lestatud mudeli juurutamiseks.
  - Andmed ‚Äì piisava kvaliteediga n√§idete k√§ttesaadavus peenh√§√§lestamise m√µju jaoks.
- **Eelised**: Kas oled kinnitanud peenh√§√§lestamise eelised?
  - Kvaliteet ‚Äì kas peenh√§√§lestatud mudel √ºletas v√µrdlusaluse?
  - Kulud ‚Äì kas see v√§hendab tokenite kasutust, lihtsustades vihjeid?
  - Laiendatavus ‚Äì kas saad baasmudelit uute valdkondade jaoks uuesti kasutada?

Nendele k√ºsimustele vastates peaksid suutma otsustada, kas peenh√§√§lestamine on sinu kasutusjuhtumi jaoks √µige l√§henemine. Ideaalis on l√§henemine kehtiv ainult siis, kui eelised kaaluvad √ºles kulud. Kui otsustad j√§tkata, on aeg m√µelda, _kuidas_ saad eelnevalt treenitud mudelit peenh√§√§lestada.

Tahad saada rohkem teadmisi otsustusprotsessi kohta? Vaata [Kas peenh√§√§lestada v√µi mitte peenh√§√§lestada](https://www.youtube.com/watch?v=0Jo-z-MFxJs).

## Kuidas saame eelnevalt treenitud mudelit peenh√§√§lestada?

Eelnevalt treenitud mudeli peenh√§√§lestamiseks on sul vaja:

- eelnevalt treenitud mudelit, mida peenh√§√§lestada
- andmestikku, mida kasutada peenh√§√§lestamiseks
- treeningkeskkonda peenh√§√§lestamise t√∂√∂ k√§ivitamiseks
- hostimiskeskkonda peenh√§√§lestatud mudeli juurutamiseks

## Peenh√§√§lestamine praktikas

J√§rgnevad ressursid pakuvad samm-sammulisi juhendeid, mis viivad sind l√§bi reaalse n√§ite, kasutades valitud mudelit ja hoolikalt valitud andmestikku. Nende juhendite l√§bimiseks on sul vaja konto konkreetse teenusepakkuja juures, samuti juurdep√§√§su vastavale mudelile ja andmestikele.

| Teenusepakkuja | Juhend                                                                                                                                                                       | Kirjeldus                                                                                                                                                                                                                                                                                                                                                                                                                        |
| -------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI         | [Kuidas peenh√§√§lestada vestlusmudeleid](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)     | √ïpi peenh√§√§lestama `gpt-35-turbo` konkreetse valdkonna jaoks ("retsepti assistent"), valmistades ette treeningandmed, k√§ivitades peenh√§√§lestamise t√∂√∂ ja kasutades peenh√§√§lestatud mudelit j√§relduste tegemiseks.                                                                                                                                                                                                                  |
| Azure OpenAI   | [GPT 3.5 Turbo peenh√§√§lestamise juhend](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | √ïpi peenh√§√§lestama `gpt-35-turbo-0613` mudelit **Azure'is**, astudes samme treeningandmete loomiseks ja √ºleslaadimiseks, peenh√§√§lestamise t√∂√∂ k√§ivitamiseks. Juuruta ja kasuta uut mudelit.                                                                                                                                                                                                                                     |
| Hugging Face   | [LLM-ide peenh√§√§lestamine Hugging Face'iga](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                      | See blogipostitus juhendab sind _avatud LLM-i_ (nt `CodeLlama 7B`) peenh√§√§lestamisel, kasutades [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) teeki ja [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) avatud [andmestike](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) abil Hugging Face'is. |
|                |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ü§ó AutoTrain   | [LLM-ide peenh√§√§lestamine AutoTrain'iga](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                | AutoTrain (v√µi AutoTrain Advanced) on Hugging Face'i poolt arendatud Python'i teek, mis v√µimaldab peenh√§√§lestamist paljude erinevate √ºlesannete jaoks, sealhulgas LLM-i peenh√§√§lestamine. AutoTrain on koodivaba lahendus ja peenh√§√§lestamist saab teha oma pilves, Hugging Face Spaces'is v√µi lokaalselt. See toetab nii veebip√µhist GUI-d, CLI-d kui ka treenimist YAML-konfiguratsioonifailide kaudu.                                                |
|                |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                |

## √úlesanne

Vali √ºks √ºlaltoodud juhenditest ja t√∂√∂ta see l√§bi. _Me v√µime replitseerida nende juhendite versiooni Jupyter Notebookides selles repos ainult viitamiseks. Palun kasuta otse algallikaid, et saada k√µige uuemaid versioone_.

## Tubli t√∂√∂! J√§tka √µppimist.

P√§rast selle tunni l√µpetamist vaata meie [Generatiivse tehisintellekti √µppekollektsiooni](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste arendamist!

Palju √µnne!! Oled l√µpetanud selle kursuse v2 seeria viimase tunni! √Ñra l√µpeta √µppimist ja loomist. \*\*Vaata [RESSURSID](RESOURCES.md?WT.mc_id=academic-105485-koreyst) lehte, et leida t√§iendavaid soovitusi just selle teema kohta.

Meie v1 tundide seeria on samuti uuendatud rohkemate √ºlesannete ja kontseptsioonidega. V√µta hetk, et v√§rskendada oma teadmisi ‚Äì ja palun [jaga oma k√ºsimusi ja tagasisidet](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), et aidata meil neid tunde kogukonna jaoks paremaks muuta.

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valesti t√µlgenduste eest.