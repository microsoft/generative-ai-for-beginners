<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a2faf8ee7a0b851efa647a19788f1e5b",
  "translation_date": "2025-10-18T02:50:33+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "et"
}
-->
# Tehisintellekti rakenduste turvalisuse tagamine

[![Tehisintellekti rakenduste turvalisuse tagamine](../../../translated_images/13-lesson-banner.14103e36b4bbf17398b64ed2b0531f6f2c6549e7f7342f797c40bcae5a11862e.et.png)](https://youtu.be/m0vXwsx5DNg?si=TYkr936GMKz15K0L)

## Sissejuhatus

Selles √µppet√ºkis k√§sitletakse:

- Turvalisust tehisintellekti s√ºsteemide kontekstis.
- Tehisintellekti s√ºsteemide levinud riske ja ohte.
- Meetodeid ja kaalutlusi tehisintellekti s√ºsteemide turvalisuse tagamiseks.

## √ïppeeesm√§rgid

P√§rast selle √µppet√ºki l√§bimist m√µistate:

- Tehisintellekti s√ºsteemide ohte ja riske.
- Levinud meetodeid ja praktikaid tehisintellekti s√ºsteemide turvalisuse tagamiseks.
- Kuidas turvatestimine aitab v√§ltida ootamatuid tulemusi ja kasutajate usalduse v√§henemist.

## Mida t√§hendab turvalisus generatiivse tehisintellekti kontekstis?

Kuna tehisintellekti (AI) ja masin√µppe (ML) tehnoloogiad kujundavad √ºha enam meie elu, on oluline kaitsta mitte ainult klientide andmeid, vaid ka tehisintellekti s√ºsteeme endid. AI/ML kasutatakse √ºha enam k√µrge v√§√§rtusega otsustusprotsesside toetamiseks t√∂√∂stusharudes, kus vale otsus v√µib p√µhjustada t√µsiseid tagaj√§rgi.

Siin on olulised punktid, mida arvestada:

- **AI/ML m√µju**: AI/ML avaldavad m√§rkimisv√§√§rset m√µju igap√§evaelule ja seet√µttu on nende kaitsmine muutunud h√§davajalikuks.
- **Turvalisuse v√§ljakutsed**: AI/ML m√µju vajab piisavat t√§helepanu, et kaitsta AI-p√µhiseid tooteid keerukate r√ºnnakute eest, olgu need trollide v√µi organiseeritud gruppide poolt.
- **Strateegilised probleemid**: Tehnoloogiat√∂√∂stus peab proaktiivselt tegelema strateegiliste v√§ljakutsetega, et tagada pikaajaline klientide turvalisus ja andmete kaitse.

Lisaks ei suuda masin√µppe mudelid suuresti eristada pahatahtlikku sisendit ja kahjutut anomaalset andmestikku. M√§rkimisv√§√§rne osa treeningandmetest p√§rineb kureerimata, modereerimata avalikest andmestikest, mis on avatud kolmandate osapoolte panustele. R√ºndajad ei pea andmestikke kompromiteerima, kui neil on vabadus neisse panustada. Aja jooksul muutuvad madala usaldusv√§√§rsusega pahatahtlikud andmed k√µrge usaldusv√§√§rsusega usaldusv√§√§rseteks andmeteks, kui andmestruktuur/vorming j√§√§b korrektseks.

Seet√µttu on kriitiline tagada andmehoidlate terviklikkus ja kaitse, mida teie mudelid otsuste tegemiseks kasutavad.

## Tehisintellekti ohtude ja riskide m√µistmine

Tehisintellekti ja sellega seotud s√ºsteemide kontekstis on andmem√ºrgitus t√§nap√§eval k√µige olulisem turvaoht. Andmem√ºrgitus toimub siis, kui keegi tahtlikult muudab teavet, mida kasutatakse tehisintellekti treenimiseks, p√µhjustades selle eksimusi. See tuleneb standardiseeritud tuvastamis- ja leevendamismeetodite puudumisest ning meie s√µltuvusest usaldusv√§√§rsetest v√µi kureerimata avalikest andmestikest treenimiseks. Andmete terviklikkuse s√§ilitamiseks ja vigase treenimisprotsessi v√§ltimiseks on oluline j√§lgida oma andmete p√§ritolu ja p√§ritolu. Vastasel juhul kehtib vana √ºtlus "pr√ºgi sisse, pr√ºgi v√§lja", mis viib mudeli j√µudluse halvenemiseni.

Siin on n√§ited, kuidas andmem√ºrgitus v√µib teie mudeleid m√µjutada:

1. **Siltide √ºmberp√∂√∂ramine**: Kaksikklassifikatsiooni √ºlesandes p√∂√∂rab pahatahtlik isik tahtlikult v√§ikese osa treeningandmete silte. N√§iteks m√§rgistatakse kahjutud proovid pahatahtlikeks, mis viib mudeli valede seoste √µppimiseni.\
   **N√§ide**: R√§mpsposti filter klassifitseerib √µigusp√§rased e-kirjad r√§mpspostiks manipuleeritud siltide t√µttu.
2. **Omaduste m√ºrgitamine**: R√ºndaja muudab treeningandmete omadusi peenelt, et tekitada kallutatust v√µi eksitada mudelit.\
   **N√§ide**: Lisatakse ebaolulisi m√§rks√µnu tootekirjeldustesse, et manipuleerida soovituss√ºsteemidega.
3. **Andmete s√ºstimine**: Pahatahtlike andmete s√ºstimine treeningkomplekti, et m√µjutada mudeli k√§itumist.\
   **N√§ide**: V√µltsitud kasutajate arvustuste lisamine, et kallutada sentimentanal√º√ºsi tulemusi.
4. **Tagaukse r√ºnnakud**: R√ºndaja lisab treeningandmetesse varjatud mustri (tagaukse). Mudel √µpib seda mustrit √§ra tundma ja k√§itub pahatahtlikult, kui see k√§ivitatakse.\
   **N√§ide**: N√§otuvastuss√ºsteem, mis on treenitud tagauksega piltidega ja tuvastab konkreetse isiku valesti.

MITRE Corporation on loonud [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), teadmistebaasi taktikatest ja tehnikatest, mida vastased kasutavad tehisintellekti s√ºsteemide r√ºnnakutes.

> Tehisintellekti kasutamine suurendab s√ºsteemide r√ºnnatavust, mis ulatub kaugemale traditsioonilistest k√ºberr√ºnnakutest. L√µime ATLAS-i, et t√µsta teadlikkust nendest ainulaadsetest ja arenevatest haavatavustest, kuna globaalne kogukond integreerib tehisintellekti √ºha enam erinevatesse s√ºsteemidesse. ATLAS on modelleeritud MITRE ATT&CK¬Æ raamistikule ja selle taktikad, tehnikad ja protseduurid (TTP-d) t√§iendavad ATT&CK-i.

Sarnaselt MITRE ATT&CK¬Æ raamistikule, mida kasutatakse laialdaselt traditsioonilises k√ºberjulgeolekus keerukate ohuemulatsioonistsenaariumide kavandamiseks, pakub ATLAS h√µlpsasti otsitavat TTP-de komplekti, mis aitab paremini m√µista ja valmistuda uute r√ºnnakute vastu kaitsmiseks.

Lisaks on Open Web Application Security Project (OWASP) loonud "[Top 10 nimekirja](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" k√µige kriitilisematest haavatavustest rakendustes, mis kasutavad LLM-e. Nimekiri toob esile selliste ohtude riske nagu eespool mainitud andmem√ºrgitus, samuti:

- **Prompt Injection**: tehnika, kus r√ºndajad manipuleerivad suure keelemudeliga (LLM) hoolikalt koostatud sisendite kaudu, p√µhjustades selle k√§itumist v√§ljaspool kavandatud k√§itumist.
- **Tarneahela haavatavused**: komponendid ja tarkvara, mis moodustavad LLM-i kasutatavad rakendused, nagu Python moodulid v√µi v√§lised andmestikud, v√µivad ise olla kompromiteeritud, p√µhjustades ootamatuid tulemusi, kallutatust ja isegi haavatavusi alusinfrastruktuuris.
- **Liigne s√µltuvus**: LLM-id on ekslikud ja kalduvad "hallutsineerima", pakkudes ebat√§pseid v√µi ohtlikke tulemusi. Mitmel dokumenteeritud juhul on inimesed v√µtnud tulemusi t√µe p√§he, mis on viinud soovimatute negatiivsete tagaj√§rgedeni reaalses maailmas.

Microsofti pilveekspert Rod Trent on kirjutanud tasuta e-raamatu [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst), mis s√ºveneb nendesse ja teistesse arenevatesse tehisintellekti ohtudesse ning pakub ulatuslikke juhiseid nende olukordade parimaks lahendamiseks.

## Tehisintellekti s√ºsteemide ja LLM-ide turvatestimine

Tehisintellekt (AI) muudab erinevaid valdkondi ja t√∂√∂stusharusid, pakkudes uusi v√µimalusi ja kasu √ºhiskonnale. Kuid tehisintellekt toob kaasa ka olulisi v√§ljakutseid ja riske, nagu andmete privaatsus, kallutatus, selguse puudumine ja v√µimalik v√§√§rkasutus. Seet√µttu on √ºlioluline tagada, et tehisintellekti s√ºsteemid oleksid turvalised ja vastutustundlikud, j√§rgiksid eetilisi ja √µiguslikke standardeid ning oleksid usaldusv√§√§rsed kasutajate ja sidusr√ºhmade jaoks.

Turvatestimine on protsess, mille k√§igus hinnatakse tehisintellekti s√ºsteemi v√µi LLM-i turvalisust, tuvastades ja kasutades √§ra nende haavatavusi. Seda v√µivad l√§bi viia arendajad, kasutajad v√µi kolmandate osapoolte audiitorid, s√µltuvalt testimise eesm√§rgist ja ulatusest. M√µned levinumad turvatestimise meetodid tehisintellekti s√ºsteemide ja LLM-ide jaoks on:

- **Andmete puhastamine**: protsess, mille k√§igus eemaldatakse v√µi anon√º√ºmseks muudetakse tundlik v√µi privaatne teave treeningandmetest v√µi tehisintellekti s√ºsteemi v√µi LLM-i sisendist. Andmete puhastamine aitab v√§ltida andmete lekkimist ja pahatahtlikku manipuleerimist, v√§hendades konfidentsiaalse v√µi isikliku teabe avalikustamist.
- **Adversariaalne testimine**: protsess, mille k√§igus luuakse ja rakendatakse vastase n√§iteid tehisintellekti s√ºsteemi v√µi LLM-i sisendile v√µi v√§ljundile, et hinnata selle vastupidavust ja vastupanuv√µimet vastase r√ºnnakutele. Adversariaalne testimine aitab tuvastada ja leevendada tehisintellekti s√ºsteemi v√µi LLM-i haavatavusi ja n√µrkusi, mida r√ºndajad v√µivad √§ra kasutada.
- **Mudelite verifitseerimine**: protsess, mille k√§igus kontrollitakse tehisintellekti s√ºsteemi v√µi LLM-i mudeli parameetrite v√µi arhitektuuri √µigsust ja t√§ielikkust. Mudelite verifitseerimine aitab tuvastada ja ennetada mudeli vargust, tagades, et mudel on kaitstud ja autentne.
- **V√§ljundi valideerimine**: protsess, mille k√§igus valideeritakse tehisintellekti s√ºsteemi v√µi LLM-i v√§ljundi kvaliteeti ja usaldusv√§√§rsust. V√§ljundi valideerimine aitab tuvastada ja parandada pahatahtlikku manipuleerimist, tagades, et v√§ljund on j√§rjepidev ja t√§pne.

OpenAI, tehisintellekti s√ºsteemide juhtiv arendaja, on loonud _ohutuse hindamise_ programmi osana oma punase meeskonna algatusest, mille eesm√§rk on testida tehisintellekti s√ºsteemide v√§ljundit, et aidata kaasa tehisintellekti ohutusele.

> Hindamised v√µivad ulatuda lihtsatest k√ºsimuste ja vastuste testidest keerukamate simulatsioonideni. Konkreetsete n√§idetena on siin OpenAI poolt v√§lja t√∂√∂tatud hindamised, mis anal√º√ºsivad tehisintellekti k√§itumist mitmest vaatenurgast:

#### Veenvus

- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem veenda teist tehisintellekti s√ºsteemi √ºtlema salajast s√µna?
- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem veenda teist tehisintellekti s√ºsteemi annetama raha?
- [Ballot Proposal](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem m√µjutada teist tehisintellekti s√ºsteemi toetama poliitilist ettepanekut?

#### Steganograafia (varjatud s√µnumid)

- [Steganography](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem edastada salajasi s√µnumeid, ilma et teine tehisintellekti s√ºsteem neid avastaks?
- [Text Compression](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem tihendada ja dekompresseerida s√µnumeid, et v√µimaldada salajaste s√µnumite peitmist?
- [Schelling Point](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem koordineerida teise tehisintellekti s√ºsteemiga ilma otsese suhtluseta?

### Tehisintellekti turvalisus

On √ºlioluline kaitsta tehisintellekti s√ºsteeme pahatahtlike r√ºnnakute, v√§√§rkasutuse v√µi soovimatute tagaj√§rgede eest. See h√µlmab samme, mis tagavad tehisintellekti s√ºsteemide ohutuse, usaldusv√§√§rsuse ja usaldusv√§√§rsuse, n√§iteks:

- Andmete ja algoritmide turvalisuse tagamine, mida kasutatakse tehisintellekti mudelite treenimiseks ja k√§itamiseks.
- Tehisintellekti s√ºsteemide volitamata juurdep√§√§su, manipuleerimise v√µi sabotaa≈æi ennetamine.
- Kallutatuse, diskrimineerimise v√µi eetiliste probleemide tuvastamine ja leevendamine tehisintellekti s√ºsteemides.
- Tehisintellekti otsuste ja tegevuste vastutuse, l√§bipaistvuse ja selguse tagamine.
- Tehisintellekti s√ºsteemide eesm√§rkide ja v√§√§rtuste koosk√µlastamine inimeste ja √ºhiskonna omadega.

Tehisintellekti turvalisus on oluline tehisintellekti s√ºsteemide ja andmete terviklikkuse, k√§ttesaadavuse ja konfidentsiaalsuse tagamiseks. M√µned tehisintellekti turvalisuse v√§ljakutsed ja v√µimalused on:

- **V√µimalus**: Tehisintellekti integreerimine k√ºberjulgeoleku strateegiatesse, kuna see v√µib m√§ngida olulist rolli ohtude tuvastamisel ja reageerimisaja parandamisel. Tehisintellekt v√µib aidata automatiseerida ja t√§iustada k√ºberr√ºnnakute, nagu andmep√º√ºk, pahavara v√µi lunavara, tuvastamist ja leevendamist.
- **V√§ljakutse**: Tehisintellekti saab kasutada ka vastaste poolt keerukate r√ºnnakute k√§ivitamiseks, n√§iteks vale v√µi eksitava sisu genereerimiseks, kasutajate j√§ljendamiseks v√µi tehisintellekti s√ºsteemide haavatavuste √§rakasutamiseks. Seet√µttu lasub tehisintellekti arendajatel ainulaadne vastutus kujundada s√ºsteeme, mis on robustsed ja vastupidavad v√§√§rkasutuse suhtes.

### Andmekaitse

LLM-id v√µivad ohustada nende kasutatavate andmete privaatsust ja turvalisust. N√§iteks v√µivad LLM-id potentsiaalselt meelde j√§tta ja lekkida tundlikku teavet oma treeningandmetest, nagu isikunimed, aadressid, paroolid v√µi krediitkaardi numbrid. Neid v√µivad manipuleerida v√µi r√ºnnata pahatahtlikud isikud, kes soovivad √§ra kasutada nende haavatavusi v√µi kallutatust. Seet√µttu on oluline olla teadlik nendest riskidest ja v√µtta asjakohaseid meetmeid LLM-idega kasutatavate andmete kaitsmiseks. Andmete kaitsmiseks LLM-idega on mitmeid samme, mida saate v√µtta. Need sammud h√µlmavad:

- **Andmete jagamise piiramine**: Jagage LLM-idega ainult neid andmeid, mis on vajalikud ja asjakohased kavandatud eesm√§rkide saavutamiseks, ning v√§ltige tundlike, konfidentsiaalsete v√µi isiklike andmete jagamist. Kasutajad peaksid ka anon√º√ºmseks muutma v√µi kr√ºpteerima andmed, mida nad LLM-idega jagavad, n√§iteks eemaldades v√µi maskeerides mis tahes tuvastatavat teavet v√µi kasutades turvalisi suhtluskanaleid.
- **LLM-ide genereeritud andmete kontrollimine**: Kontrollige alati LLM-ide genereeritud v√§ljundi t√§psust ja kvaliteeti, et veenduda, et need ei sisalda soovimatut v√µi sobimatut teavet.
- **Andmelekkete v√µi intsidentide raporteerimine ja j√§lgimine**: Olge valvas LLM-ide kahtlaste v√µi ebanormaalsete tegevuste
Reaalse maailma ohtude j√§ljendamine on n√º√ºdseks muutunud standardseks praktikaks vastupidavate tehisintellektis√ºsteemide loomisel, kasutades sarnaseid t√∂√∂riistu, taktikaid ja protseduure, et tuvastada s√ºsteemide riske ja testida kaitsjate reageerimist.

> Tehisintellekti punase meeskonna (red teaming) praktika on arenenud laiemaks t√§henduseks: see ei h√µlma ainult turvavigade otsimist, vaid ka teiste s√ºsteemirikkumiste tuvastamist, n√§iteks potentsiaalselt kahjuliku sisu genereerimist. Tehisintellektis√ºsteemid toovad kaasa uusi riske ning punane meeskond on keskne nende uute riskide m√µistmisel, nagu n√§iteks prompt injection ja p√µhjendamata sisu loomine. - [Microsoft AI Red Team ehitab turvalisema tehisintellekti tulevikku](https://www.microsoft.com/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-105485-koreyst)

[![Juhised ja ressursid punase meeskonna jaoks](../../../translated_images/13-AI-red-team.642ed54689d7e8a4d83bdf0635768c4fd8aa41ea539d8e3ffe17514aec4b4824.et.png)]()

Allpool on toodud peamised teadmised, mis on kujundanud Microsofti tehisintellekti punase meeskonna programmi.

1. **Tehisintellekti punase meeskonna laiendatud ulatus:**
   Tehisintellekti punane meeskond h√µlmab n√º√ºd nii turvalisuse kui ka vastutustundliku tehisintellekti (RAI) tulemusi. Traditsiooniliselt keskendus punane meeskond turvalisuse aspektidele, k√§sitledes mudelit kui vektorit (nt mudeli varastamine). Kuid tehisintellektis√ºsteemid toovad kaasa uusi turvavigu (nt prompt injection, m√ºrgitamine), mis vajavad erilist t√§helepanu. Lisaks turvalisusele uurib tehisintellekti punane meeskond ka √µiglusprobleeme (nt stereot√º√ºbid) ja kahjulikku sisu (nt v√§givalla √ºlistamine). Nende probleemide varajane tuvastamine v√µimaldab kaitseinvesteeringute prioriteetide seadmist.
2. **Pahatahtlikud ja heatahtlikud rikked:**
   Tehisintellekti punane meeskond arvestab rikete v√µimalusi nii pahatahtlikust kui ka heatahtlikust vaatenurgast. N√§iteks uue Bingi punase meeskonna testimisel uurime mitte ainult seda, kuidas pahatahtlikud vastased v√µivad s√ºsteemi kahjustada, vaid ka seda, kuidas tavalised kasutajad v√µivad kokku puutuda probleemse v√µi kahjuliku sisuga. Erinevalt traditsioonilisest turvalisuse punasest meeskonnast, mis keskendub peamiselt pahatahtlikele osapooltele, arvestab tehisintellekti punane meeskond laiemat valikut isikuid ja v√µimalikke rikete stsenaariume.
3. **Tehisintellektis√ºsteemide d√ºnaamiline olemus:**
   Tehisintellekti rakendused arenevad pidevalt. Suurte keelemudelite rakendustes kohandavad arendajad s√ºsteeme vastavalt muutuvatele n√µuetele. J√§tkuv punase meeskonna t√∂√∂ tagab pideva valvsuse ja kohanemise muutuvate riskidega.

Tehisintellekti punane meeskond ei ole k√µikeh√µlmav ja seda tuleks k√§sitleda t√§iendava meetmena lisaks teistele kontrollimeetoditele, nagu [rollip√µhine juurdep√§√§sukontroll (RBAC)](https://learn.microsoft.com/azure/ai-services/openai/how-to/role-based-access-control?WT.mc_id=academic-105485-koreyst) ja terviklikud andmehalduslahendused. See on m√µeldud t√§iendama turvastrateegiat, mis keskendub turvaliste ja vastutustundlike tehisintellektilahenduste kasutamisele, arvestades privaatsust ja turvalisust ning p√º√ºdes samal ajal minimeerida kallutatust, kahjulikku sisu ja v√§√§rinformatsiooni, mis v√µivad kasutajate usaldust √µ√µnestada.

Siin on nimekiri lisalugemisest, mis aitab paremini m√µista, kuidas punane meeskond saab aidata tuvastada ja leevendada riske teie tehisintellektis√ºsteemides:

- [Punase meeskonna planeerimine suurte keelemudelite (LLM) ja nende rakenduste jaoks](https://learn.microsoft.com/azure/ai-services/openai/concepts/red-teaming?WT.mc_id=academic-105485-koreyst)
- [Mis on OpenAI Red Teaming Network?](https://openai.com/blog/red-teaming-network?WT.mc_id=academic-105485-koreyst)
- [Tehisintellekti punane meeskond - v√µtmepraktika turvalisemate ja vastutustundlikumate tehisintellektilahenduste loomiseks](https://rodtrent.substack.com/p/ai-red-teaming?WT.mc_id=academic-105485-koreyst)
- MITRE [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), teadmistebaas taktikatest ja tehnikatest, mida vastased kasutavad tehisintellektis√ºsteemide reaalsetes r√ºnnakutes.

## Teadmiste kontroll

Milline v√µiks olla hea l√§henemine andmete terviklikkuse s√§ilitamiseks ja v√§√§rkasutuse v√§ltimiseks?

1. Kasutage tugevaid rollip√µhiseid kontrollimeetmeid andmetele juurdep√§√§suks ja andmehalduseks  
1. Rakendage ja auditeerige andmete m√§rgistamist, et v√§ltida andmete vale esitamist v√µi v√§√§rkasutust  
1. Veenduge, et teie tehisintellekti infrastruktuur toetab sisufiltreerimist  

A:1, Kuigi k√µik kolm on suurep√§rased soovitused, aitab √µige andmejuurdep√§√§su√µiguste m√§√§ramine kasutajatele oluliselt v√§ltida LLM-ide kasutatavate andmete manipuleerimist ja vale esitamist.

## üöÄ V√§ljakutse

Lugege rohkem selle kohta, kuidas [hallata ja kaitsta tundlikku teavet](https://learn.microsoft.com/training/paths/purview-protect-govern-ai/?WT.mc_id=academic-105485-koreyst) tehisintellekti ajastul.

## Suurep√§rane t√∂√∂, j√§tkake √µppimist

P√§rast selle √µppetunni l√§bimist tutvuge meie [Generatiivse tehisintellekti √µppekollektsiooniga](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste arendamist!

Liikuge edasi 14. √µppetundi, kus vaatame [generatiivse tehisintellekti rakenduste eluts√ºklit](../14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud AI t√µlketeenuse [Co-op Translator](https://github.com/Azure/co-op-translator) abil. Kuigi p√º√ºame tagada t√§psust, palume arvestada, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algses keeles tuleks pidada autoriteetseks allikaks. Olulise teabe puhul soovitame kasutada professionaalset inimt√µlget. Me ei vastuta arusaamatuste v√µi valesti t√µlgenduste eest, mis v√µivad tekkida selle t√µlke kasutamise t√µttu.