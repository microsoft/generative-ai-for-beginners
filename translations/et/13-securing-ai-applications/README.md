<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "f3cac698e9eea47dd563633bd82daf8c",
  "translation_date": "2025-10-11T11:45:03+00:00",
  "source_file": "13-securing-ai-applications/README.md",
  "language_code": "et"
}
-->
# Generatiivse tehisintellekti rakenduste turvamine

[![Generatiivse tehisintellekti rakenduste turvamine](../../../translated_images/13-lesson-banner.14103e36b4bbf17398b64ed2b0531f6f2c6549e7f7342f797c40bcae5a11862e.et.png)](https://aka.ms/gen-ai-lesson13-gh?WT.mc_id=academic-105485-koreyst)

## Sissejuhatus

Selles √µppet√ºkis k√§sitletakse:

- Turvalisust tehisintellekti s√ºsteemide kontekstis.
- Tehisintellekti s√ºsteemide levinud riske ja ohte.
- Meetodeid ja kaalutlusi tehisintellekti s√ºsteemide turvamiseks.

## √ïpieesm√§rgid

P√§rast selle √µppet√ºki l√§bimist m√µistate:

- Tehisintellekti s√ºsteemide ohte ja riske.
- Levinud meetodeid ja praktikaid tehisintellekti s√ºsteemide turvamiseks.
- Kuidas turvatestimine aitab v√§ltida ootamatuid tulemusi ja kasutajate usalduse v√§henemist.

## Mida t√§hendab turvalisus generatiivse tehisintellekti kontekstis?

Kuna tehisintellekti (AI) ja masin√µppe (ML) tehnoloogiad kujundavad √ºha enam meie igap√§evaelu, on oluline kaitsta mitte ainult klientide andmeid, vaid ka tehisintellekti s√ºsteeme endid. AI/ML kasutatakse √ºha enam k√µrge v√§√§rtusega otsustusprotsesside toetamiseks t√∂√∂stusharudes, kus valed otsused v√µivad p√µhjustada t√µsiseid tagaj√§rgi.

Siin on olulised punktid, mida arvestada:

- **AI/ML m√µju**: AI/ML m√µjutavad oluliselt igap√§evaelu, mist√µttu nende kaitsmine on muutunud h√§davajalikuks.
- **Turvalisuse v√§ljakutsed**: AI/ML m√µju vajab piisavat t√§helepanu, et kaitsta AI-p√µhiseid tooteid keerukate r√ºnnakute eest, olgu need trollide v√µi organiseeritud gruppide poolt.
- **Strateegilised probleemid**: Tehnoloogiasektor peab proaktiivselt tegelema strateegiliste v√§ljakutsetega, et tagada pikaajaline klientide turvalisus ja andmete kaitse.

Lisaks ei suuda masin√µppe mudelid suuresti eristada pahatahtlikku sisendit ja kahjutut anomaalset andmestikku. M√§rkimisv√§√§rne osa treeningandmetest p√§rineb kureerimata, modereerimata avalikest andmekogumitest, mis on avatud kolmandate osapoolte panustele. R√ºndajad ei pea andmekogumeid kompromiteerima, kui neil on vabadus neisse panustada. Aja jooksul muutuvad madala usaldusv√§√§rsusega pahatahtlikud andmed k√µrge usaldusv√§√§rsusega usaldusv√§√§rseteks andmeteks, kui andmestruktuur ja vorming j√§√§vad korrektseks.

Seet√µttu on kriitiline tagada andmekogude terviklikkus ja kaitse, mida teie mudelid otsuste tegemiseks kasutavad.

## Tehisintellekti ohtude ja riskide m√µistmine

Tehisintellekti ja sellega seotud s√ºsteemide kontekstis on andmete m√ºrgitamine t√§nap√§eval k√µige olulisem turvaoht. Andmete m√ºrgitamine toimub siis, kui keegi tahtlikult muudab teavet, mida kasutatakse tehisintellekti treenimiseks, p√µhjustades selle eksimusi. See tuleneb standardiseeritud tuvastamis- ja leevendusmeetodite puudumisest ning meie s√µltuvusest usaldusv√§√§rsetest v√µi kureerimata avalikest andmekogumitest treenimiseks. Andmete terviklikkuse s√§ilitamiseks ja vigase treenimisprotsessi v√§ltimiseks on oluline j√§lgida oma andmete p√§ritolu ja p√§ritolu. Vastasel juhul kehtib vana √ºtlus "pr√ºgi sisse, pr√ºgi v√§lja", mis viib mudeli j√µudluse halvenemiseni.

Siin on n√§ited, kuidas andmete m√ºrgitamine v√µib teie mudeleid m√µjutada:

1. **Siltide √ºmberp√∂√∂ramine**: Kahesuunalise klassifitseerimise √ºlesandes p√∂√∂rab vastane tahtlikult v√§ikese osa treeningandmete silte. N√§iteks m√§rgistatakse kahjutud n√§idised pahatahtlikeks, mis viib mudeli valede seoste √µppimiseni.\
   **N√§ide**: R√§mpsposti filter klassifitseerib legitiimsed e-kirjad r√§mpspostiks manipuleeritud siltide t√µttu.
2. **Omaduste m√ºrgitamine**: R√ºndaja muudab treeningandmete omadusi peenelt, et tekitada kallutatust v√µi eksitada mudelit.\
   **N√§ide**: Lisatakse ebaolulisi m√§rks√µnu tootekirjeldustesse, et manipuleerida soovituss√ºsteemidega.
3. **Andmete s√ºstimine**: Pahatahtlike andmete lisamine treeningkogumisse, et m√µjutada mudeli k√§itumist.\
   **N√§ide**: V√µltsitud kasutajate arvustuste lisamine, et kallutada sentimentanal√º√ºsi tulemusi.
4. **Tagaukse r√ºnnakud**: Vastane lisab treeningandmetesse varjatud mustri (tagaukse). Mudel √µpib seda mustrit √§ra tundma ja k√§itub pahatahtlikult, kui muster aktiveeritakse.\
   **N√§ide**: N√§otuvastuss√ºsteem, mis on treenitud tagauksega piltidega ja tuvastab konkreetse isiku valesti.

MITRE Corporation on loonud [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), teadmistebaasi taktikatest ja tehnikatest, mida vastased kasutavad tehisintellekti s√ºsteemide reaalsetes r√ºnnakutes.

> Tehisintellekti kasutamine suurendab olemasolevate s√ºsteemide r√ºnnakupinda traditsiooniliste k√ºberr√ºnnakute k√µrval, mis toob kaasa kasvava hulga haavatavusi AI-toega s√ºsteemides. Me l√µime ATLAS-i, et t√µsta teadlikkust nendest unikaalsetest ja arenevatest haavatavustest, kuna globaalne kogukond integreerib tehisintellekti √ºha enam erinevatesse s√ºsteemidesse. ATLAS on modelleeritud MITRE ATT&CK¬Æ raamistikule ja selle taktikad, tehnikad ja protseduurid (TTP-d) t√§iendavad ATT&CK-i omasid.

Sarnaselt MITRE ATT&CK¬Æ raamistikule, mida kasutatakse laialdaselt traditsioonilises k√ºberturvalisuses arenenud ohu emulatsioonistsenaariumide kavandamiseks, pakub ATLAS h√µlpsasti otsitavat TTP-de komplekti, mis aitab paremini m√µista ja valmistuda kaitseks uute r√ºnnakute vastu.

Lisaks on Open Web Application Security Project (OWASP) loonud "[Top 10 nimekirja](https://llmtop10.com/?WT.mc_id=academic-105485-koreyst)" k√µige kriitilisematest haavatavustest rakendustes, mis kasutavad LLM-e. Nimekiri toob esile selliste ohtude riske nagu eespool mainitud andmete m√ºrgitamine ja teised, n√§iteks:

- **K√§skude s√ºstimine**: tehnika, kus r√ºndajad manipuleerivad suure keelemudeliga (LLM) hoolikalt koostatud sisendite kaudu, p√µhjustades selle k√§itumist v√§ljaspool kavandatud funktsionaalsust.
- **Tarneahela haavatavused**: komponendid ja tarkvara, mis moodustavad LLM-i kasutatavad rakendused, nagu Python moodulid v√µi v√§lised andmekogumid, v√µivad ise olla kompromiteeritud, mis viib ootamatute tulemuste, kallutatuse ja isegi infrastruktuuri haavatavusteni.
- **Liigne s√µltuvus**: LLM-id on ekslikud ja kalduvad "hallutsineerima", pakkudes ebat√§pseid v√µi ohtlikke tulemusi. Mitmel dokumenteeritud juhul on inimesed v√µtnud tulemusi t√µe p√§he, mis on viinud soovimatute negatiivsete tagaj√§rgedeni reaalses maailmas.

Microsofti pilveadvokaat Rod Trent on kirjutanud tasuta e-raamatu, [Must Learn AI Security](https://github.com/rod-trent/OpenAISecurity/tree/main/Must_Learn/Book_Version?WT.mc_id=academic-105485-koreyst), mis s√ºveneb nendesse ja teistesse arenevatesse tehisintellekti ohtudesse ning pakub ulatuslikke juhiseid, kuidas neid olukordi k√µige paremini lahendada.

## Tehisintellekti s√ºsteemide ja LLM-ide turvatestimine

Tehisintellekt (AI) muudab erinevaid valdkondi ja t√∂√∂stusharusid, pakkudes uusi v√µimalusi ja kasu √ºhiskonnale. Kuid AI toob kaasa ka olulisi v√§ljakutseid ja riske, nagu andmete privaatsus, kallutatus, selguse puudumine ja v√µimalik v√§√§rkasutus. Seet√µttu on oluline tagada, et tehisintellekti s√ºsteemid oleksid turvalised ja vastutustundlikud, j√§rgides eetilisi ja √µiguslikke standardeid ning olles usaldusv√§√§rsed kasutajate ja sidusr√ºhmade jaoks.

Turvatestimine on protsess, mille k√§igus hinnatakse tehisintellekti s√ºsteemi v√µi LLM-i turvalisust, tuvastades ja kasutades √§ra nende haavatavusi. Seda v√µivad l√§bi viia arendajad, kasutajad v√µi kolmandate osapoolte audiitorid, s√µltuvalt testimise eesm√§rgist ja ulatusest. M√µned levinumad turvatestimise meetodid tehisintellekti s√ºsteemide ja LLM-ide jaoks on:

- **Andmete puhastamine**: protsess, mille k√§igus eemaldatakse v√µi anon√º√ºmseks muudetakse tundlik v√µi privaatne teave treeningandmetest v√µi tehisintellekti s√ºsteemi v√µi LLM-i sisendist. Andmete puhastamine aitab v√§ltida andmete lekkimist ja pahatahtlikku manipuleerimist, v√§hendades konfidentsiaalsete v√µi isiklike andmete kokkupuudet.
- **Vastur√ºnnakute testimine**: protsess, mille k√§igus genereeritakse ja rakendatakse vastur√ºnnakute n√§iteid tehisintellekti s√ºsteemi v√µi LLM-i sisendile v√µi v√§ljundile, et hinnata selle vastupidavust ja vastupanuv√µimet vastur√ºnnakute vastu. Vastur√ºnnakute testimine aitab tuvastada ja leevendada tehisintellekti s√ºsteemi v√µi LLM-i haavatavusi ja n√µrkusi, mida r√ºndajad v√µivad √§ra kasutada.
- **Mudeli verifitseerimine**: protsess, mille k√§igus kontrollitakse tehisintellekti s√ºsteemi v√µi LLM-i mudeli parameetrite v√µi arhitektuuri √µigsust ja t√§ielikkust. Mudeli verifitseerimine aitab tuvastada ja ennetada mudeli varastamist, tagades, et mudel on kaitstud ja autentne.
- **V√§ljundi valideerimine**: protsess, mille k√§igus valideeritakse tehisintellekti s√ºsteemi v√µi LLM-i v√§ljundi kvaliteeti ja usaldusv√§√§rsust. V√§ljundi valideerimine aitab tuvastada ja parandada pahatahtlikku manipuleerimist, tagades, et v√§ljund on j√§rjepidev ja t√§pne.

OpenAI, tehisintellekti s√ºsteemide juhtiv arendaja, on loonud _turvalisuse hindamised_ osana oma punase meeskonna v√µrgustiku algatusest, mille eesm√§rk on testida tehisintellekti s√ºsteemide v√§ljundeid, et aidata kaasa tehisintellekti turvalisusele.

> Hindamised v√µivad ulatuda lihtsatest k√ºsimuste ja vastuste testidest keerukamate simulatsioonideni. Konkreetsete n√§idetena on siin OpenAI poolt v√§lja t√∂√∂tatud hindamised, mis anal√º√ºsivad tehisintellekti k√§itumist mitmest vaatenurgast:

#### Veenvus

- [MakeMeSay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_say/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem panna teise tehisintellekti s√ºsteemi √ºtlema salajast s√µna?
- [MakeMePay](https://github.com/openai/evals/tree/main/evals/elsuite/make_me_pay/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem veenda teist tehisintellekti s√ºsteemi annetama raha?
- [Ballot Proposal](https://github.com/openai/evals/tree/main/evals/elsuite/ballots/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem m√µjutada teise tehisintellekti s√ºsteemi toetust poliitilisele ettepanekule?

#### Steganograafia (varjatud s√µnumid)

- [Steganography](https://github.com/openai/evals/tree/main/evals/elsuite/steganography/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem edastada salajasi s√µnumeid, ilma et teine tehisintellekti s√ºsteem neid avastaks?
- [Text Compression](https://github.com/openai/evals/tree/main/evals/elsuite/text_compression/readme.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem tihendada ja dekompresseerida s√µnumeid, et v√µimaldada salajaste s√µnumite peitmist?
- [Schelling Point](https://github.com/openai/evals/blob/main/evals/elsuite/schelling_point/README.md?WT.mc_id=academic-105485-koreyst): Kui h√§sti suudab tehisintellekti s√ºsteem koordineerida teise tehisintellekti s√ºsteemiga, ilma otsese suhtluseta?

### Tehisintellekti turvalisus

On √ºlioluline kaitsta tehisintellekti s√ºsteeme pahatahtlike r√ºnnakute, v√§√§rkasutuse v√µi soovimatute tagaj√§rgede eest. See h√µlmab samme, et tagada tehisintellekti s√ºsteemide turvalisus, usaldusv√§√§rsus ja usaldusv√§√§rsus, n√§iteks:

- Andmete ja algoritmide turvamine, mida kasutatakse tehisintellekti mudelite treenimiseks ja k√§itamiseks.
- Tehisintellekti s√ºsteemide volitamata juurdep√§√§su, manipuleerimise v√µi sabotaa≈æi v√§ltimine.
- Kallutatuse, diskrimineerimise v√µi eetiliste probleemide tuvastamine ja leevendamine tehisintellekti s√ºsteemides.
- Tehisintellekti otsuste ja tegevuste vastutuse, l√§bipaistvuse ja selgitatavuse tagamine.
- Tehisintellekti s√ºsteemide eesm√§rkide ja v√§√§rtuste koosk√µlastamine inimeste ja √ºhiskonna omadega.

Tehisintellekti turvalisus on oluline tehisintellekti s√ºsteemide ja andmete terviklikkuse, k√§ttesaadavuse ja konfidentsiaalsuse tagamiseks. M√µned tehisintellekti turvalisuse v√§ljakutsed ja v√µimalused on:

- **V√µimalus**: Tehisintellekti integreerimine k√ºberturvalisuse strateegiatesse, kuna see v√µib m√§ngida olulist rolli ohtude tuvastamisel ja reageerimisaja parandamisel. Tehisintellekt aitab automatiseerida ja t√§iustada k√ºberr√ºnnakute, nagu andmep√º√ºk, pahavara v√µi lunavara, tuvastamist ja leevendamist.
- **V√§ljakutse**: Tehisintellekti v√µivad kasutada ka vastased keerukate r√ºnnakute l√§biviimiseks, n√§iteks vale v√µi eksitava sisu genereerimiseks, kasutajate j√§ljendamiseks v√µi tehisintellekti s√ºsteemide haavatavuste √§rakasutamiseks. Seet√µttu on tehisintellekti arendajatel ainulaadne vastutus luua s√ºsteeme, mis on robustsed ja vastupidavad v√§√§rkasutuse vastu.

### Andmekaitse

LLM-id v√µivad ohustada nende kasutatavate andmete privaatsust ja turvalisust. N√§iteks v√µivad LLM-id potentsiaalselt meelde j√§tta ja lekkida tundlikku teavet oma treeningandmetest, nagu isikunimed, aadressid, paroolid v√µi krediitkaardi numbrid. Neid v√µivad manipuleerida v√µi r√ºnnata pahatahtlikud osapooled, kes soovivad √§ra kasutada nende haavatavusi v√µi kallutatust. Seet√µttu on oluline olla teadlik nendest riskidest ja v√µtta asjakohaseid meetmeid LLM-idega kasutatavate andmete kaitsmiseks. On mitmeid samme, mida saate astuda LLM-idega kasutatavate andmete kaitsmiseks. Need sammud h√µlmavad:

- **Andmete jagamise piiramine**: Jagage ainult neid andmeid, mis on vajalikud ja asjakohased kavandatud eesm√§rkide jaoks, ning v√§ltige tundlike, konfidentsiaalsete v√µi isiklike andmete jagamist. Kasutajad peaksid ka anon√º√ºmseks muutma v√µi kr√ºpteerima andmed, mida nad LLM-idega jagavad, n√§iteks eemaldades v√µi maskeerides mis tahes tuvastavat teavet v√µi kasutades turvalisi suhtluskanaleid.
- **LLM-ide genereeritud andmete kontrollimine**: Kontrollige alati LLM-ide genereeritud v√§ljundi t√§psust ja kvaliteeti, et veenduda, et need ei sisalda soovimatut v√µi sobimatut teavet.
- **Andmelekkest v√µi juhtumitest teatamine ja hoiatamine**: Olge valvas LLM-ide
Reaalse maailma ohtude j√§ljendamine on n√º√ºd standardne praktika vastupidavate tehisintellektis√ºsteemide loomisel, kasutades sarnaseid t√∂√∂riistu, taktikaid ja protseduure, et tuvastada s√ºsteemide riske ja testida kaitsjate reageerimist.

> Tehisintellekti red teamingu praktika on arenenud laiemaks t√§henduseks: see ei h√µlma ainult turvavigade otsimist, vaid ka teiste s√ºsteemirikkumiste tuvastamist, nagu potentsiaalselt kahjuliku sisu genereerimine. Tehisintellektis√ºsteemid toovad kaasa uusi riske ning red teaming on oluline nende uute riskide, nagu prompt injection ja p√µhjendamata sisu loomine, m√µistmiseks. - [Microsoft AI Red Team ehitab turvalisema tehisintellekti tulevikku](https://www.microsoft.com/security/blog/2023/08/07/microsoft-ai-red-team-building-future-of-safer-ai/?WT.mc_id=academic-105485-koreyst)

[![Juhised ja ressursid red teamingu jaoks](../../../translated_images/13-AI-red-team.642ed54689d7e8a4d83bdf0635768c4fd8aa41ea539d8e3ffe17514aec4b4824.et.png)]()

Allpool on peamised teadmised, mis on kujundanud Microsofti AI Red Team programmi.

1. **AI Red Teamingu lai ulatus:**
   AI red teaming h√µlmab n√º√ºd nii turvalisust kui ka vastutustundliku tehisintellekti (RAI) tulemusi. Traditsiooniliselt keskendus red teaming turvalisuse aspektidele, k√§sitledes mudelit kui vektorit (nt mudeli varastamine). Kuid tehisintellektis√ºsteemid toovad kaasa uusi turvavigu (nt prompt injection, m√ºrgitamine), mis vajavad erilist t√§helepanu. Turvalisuse k√µrval uurib AI red teaming ka √µiglust (nt stereot√º√ºbid) ja kahjulikku sisu (nt v√§givalla √ºlistamine). Nende probleemide varajane tuvastamine v√µimaldab kaitseinvesteeringute prioriseerimist.
2. **Pahatahtlikud ja heatahtlikud rikkumised:**
   AI red teaming arvestab rikkumisi nii pahatahtlikust kui ka heatahtlikust vaatenurgast. N√§iteks uue Bingi red teamingu puhul uurime mitte ainult seda, kuidas pahatahtlikud vastased v√µivad s√ºsteemi √µ√µnestada, vaid ka seda, kuidas tavalised kasutajad v√µivad kokku puutuda probleemse v√µi kahjuliku sisuga. Erinevalt traditsioonilisest turvalisuse red teamingust, mis keskendub peamiselt pahatahtlikele osapooltele, arvestab AI red teaming laiemat valikut isikuid ja v√µimalikke rikkumisi.
3. **Tehisintellektis√ºsteemide d√ºnaamiline olemus:**
   Tehisintellekti rakendused arenevad pidevalt. Suurte keelemudelite rakendustes kohandavad arendajad end muutuvate n√µuetega. J√§tkuv red teaming tagab pideva valvsuse ja kohanemise muutuvate riskidega.

AI red teaming ei ole k√µikeh√µlmav ja seda tuleks k√§sitleda t√§iendava meetmena lisakontrollidele, nagu [rollip√µhine juurdep√§√§sukontroll (RBAC)](https://learn.microsoft.com/azure/ai-services/openai/how-to/role-based-access-control?WT.mc_id=academic-105485-koreyst) ja terviklikud andmehalduslahendused. See on m√µeldud t√§iendama turvastrateegiat, mis keskendub turvaliste ja vastutustundlike tehisintellektilahenduste kasutamisele, arvestades privaatsust ja turvalisust ning p√º√ºdes minimeerida kallutatust, kahjulikku sisu ja v√§√§rinfot, mis v√µivad kasutajate usaldust √µ√µnestada.

Siin on nimekiri lisalugemisest, mis aitab paremini m√µista, kuidas red teaming aitab tuvastada ja leevendada riske teie tehisintellektis√ºsteemides:

- [Red teamingu planeerimine suurte keelemudelite (LLM) ja nende rakenduste jaoks](https://learn.microsoft.com/azure/ai-services/openai/concepts/red-teaming?WT.mc_id=academic-105485-koreyst)
- [Mis on OpenAI Red Teaming Network?](https://openai.com/blog/red-teaming-network?WT.mc_id=academic-105485-koreyst)
- [AI Red Teaming - Oluline praktika turvalisemate ja vastutustundlikumate tehisintellektilahenduste loomiseks](https://rodtrent.substack.com/p/ai-red-teaming?WT.mc_id=academic-105485-koreyst)
- MITRE [ATLAS (Adversarial Threat Landscape for Artificial-Intelligence Systems)](https://atlas.mitre.org/?WT.mc_id=academic-105485-koreyst), teadmistebaas taktikatest ja tehnikatest, mida vastased kasutavad reaalse maailma r√ºnnakutes tehisintellektis√ºsteemide vastu.

## Teadmiste kontroll

Milline v√µiks olla hea l√§henemine andmete terviklikkuse s√§ilitamiseks ja v√§√§rkasutuse v√§ltimiseks?

1. Kasutage tugevaid rollip√µhiseid kontrollimeetmeid andmete juurdep√§√§su ja haldamise jaoks
1. Rakendage ja auditeerige andmete m√§rgistamist, et v√§ltida andmete vale esitamist v√µi v√§√§rkasutust
1. Veenduge, et teie tehisintellekti infrastruktuur toetab sisufiltreerimist

A:1, Kuigi k√µik kolm on suurep√§rased soovitused, aitab √µige andmejuurdep√§√§su√µiguste m√§√§ramine kasutajatele oluliselt v√§ltida andmete manipuleerimist ja vale esitamist, mida LLM-id kasutavad.

## üöÄ V√§ljakutse

Lugege rohkem selle kohta, kuidas [hallata ja kaitsta tundlikku teavet](https://learn.microsoft.com/training/paths/purview-protect-govern-ai/?WT.mc_id=academic-105485-koreyst) tehisintellekti ajastul.

## Suurep√§rane t√∂√∂, j√§tkake √µppimist

P√§rast selle √µppetunni l√§bimist vaadake meie [Generatiivse tehisintellekti √µppekollektsiooni](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), et j√§tkata oma generatiivse tehisintellekti teadmiste arendamist!

Liikuge edasi 14. √µppetundi, kus vaatame [Generatiivse tehisintellekti rakenduse eluts√ºklit](../14-the-generative-ai-application-lifecycle/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Lahti√ºtlus**:  
See dokument on t√µlgitud, kasutades AI t√µlketeenust [Co-op Translator](https://github.com/Azure/co-op-translator). Kuigi p√º√ºame tagada t√§psust, palun arvestage, et automaatsed t√µlked v√µivad sisaldada vigu v√µi ebat√§psusi. Algne dokument selle algkeeles tuleks lugeda autoriteetseks allikaks. Olulise teabe puhul on soovitatav kasutada professionaalset inimt√µlget. Me ei vastuta selle t√µlke kasutamisest tulenevate arusaamatuste v√µi valede t√µlgenduste eest.