{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creare un'applicazione di generazione immagini\n",
    "\n",
    "Le LLM non servono solo per generare testo. È anche possibile generare immagini a partire da descrizioni testuali. Avere le immagini come modalità può essere estremamente utile in molti settori, dalla MedTech, all’architettura, al turismo, allo sviluppo di videogiochi e molto altro. In questo capitolo, vedremo i due modelli di generazione immagini più popolari: DALL-E e Midjourney.\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questa lezione vedremo:\n",
    "\n",
    "- La generazione di immagini e perché è utile.\n",
    "- DALL-E e Midjourney: cosa sono e come funzionano.\n",
    "- Come si può costruire un’applicazione di generazione immagini.\n",
    "\n",
    "## Obiettivi di apprendimento\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "- Creare un’applicazione di generazione immagini.\n",
    "- Definire i limiti della tua applicazione con meta prompt.\n",
    "- Lavorare con DALL-E e Midjourney.\n",
    "\n",
    "## Perché creare un’applicazione di generazione immagini?\n",
    "\n",
    "Le applicazioni di generazione immagini sono un ottimo modo per esplorare le potenzialità dell’AI generativa. Possono essere utilizzate, ad esempio, per:\n",
    "\n",
    "- **Modifica e sintesi di immagini**. Puoi generare immagini per diversi casi d’uso, come l’editing o la sintesi di immagini.\n",
    "\n",
    "- **Applicazioni in diversi settori**. Possono essere usate per generare immagini in vari ambiti come MedTech, Turismo, Sviluppo di videogiochi e altro ancora.\n",
    "\n",
    "## Scenario: Edu4All\n",
    "\n",
    "In questa lezione continueremo a lavorare con la nostra startup, Edu4All. Gli studenti creeranno immagini per le loro valutazioni; quali immagini realizzare dipende da loro, ma potrebbero essere illustrazioni per una loro fiaba, la creazione di un nuovo personaggio per la loro storia, oppure per aiutarli a visualizzare idee e concetti.\n",
    "\n",
    "Ecco un esempio di cosa potrebbero generare gli studenti di Edu4All se stanno lavorando in classe sui monumenti:\n",
    "\n",
    "![Startup Edu4All, lezione sui monumenti, Torre Eiffel](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.it.png)\n",
    "\n",
    "usando un prompt come\n",
    "\n",
    "> \"Cane accanto alla Torre Eiffel nella luce del primo mattino\"\n",
    "\n",
    "## Che cosa sono DALL-E e Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) e [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) sono due dei modelli di generazione immagini più popolari e permettono di usare prompt per generare immagini.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Iniziamo da DALL-E, un modello di AI generativa che crea immagini a partire da descrizioni testuali.\n",
    "\n",
    "> [DALL-E è una combinazione di due modelli, CLIP e diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** è un modello che genera embedding, cioè rappresentazioni numeriche dei dati, sia da immagini che da testo.\n",
    "\n",
    "- **Diffused attention** è un modello che genera immagini a partire dagli embedding. DALL-E è stato addestrato su un dataset di immagini e testo e può essere usato per generare immagini da descrizioni testuali. Ad esempio, DALL-E può generare immagini di un gatto con un cappello o di un cane con la cresta.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney funziona in modo simile a DALL-E: genera immagini a partire da prompt testuali. Anche Midjourney può essere usato per creare immagini con prompt come “un gatto con un cappello” o “un cane con la cresta”.\n",
    "\n",
    "![Immagine generata da Midjourney, piccione meccanico](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Crediti immagine Wikipedia, immagine generata da Midjourney*\n",
    "\n",
    "## Come funzionano DALL-E e Midjourney\n",
    "\n",
    "Partiamo da [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E è un modello di AI generativa basato sull’architettura transformer con un *autoregressive transformer*.\n",
    "\n",
    "Un *autoregressive transformer* definisce come il modello genera immagini da descrizioni testuali: crea un pixel alla volta, poi usa i pixel già generati per produrre il successivo, passando attraverso diversi strati di una rete neurale fino a completare l’immagine.\n",
    "\n",
    "Con questo processo, DALL-E controlla attributi, oggetti, caratteristiche e altro ancora nell’immagine generata. Tuttavia, DALL-E 2 e 3 offrono un controllo ancora maggiore sull’immagine prodotta,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creare la tua prima applicazione di generazione immagini\n",
    "\n",
    "Cosa serve per costruire un'applicazione di generazione immagini? Hai bisogno delle seguenti librerie:\n",
    "\n",
    "- **python-dotenv**, è fortemente consigliato usare questa libreria per conservare le tue chiavi segrete in un file *.env* separato dal codice.\n",
    "- **openai**, questa libreria ti permette di interagire con l'API di OpenAI.\n",
    "- **pillow**, per lavorare con le immagini in Python.\n",
    "- **requests**, per facilitare le richieste HTTP.\n",
    "\n",
    "\n",
    "1. Crea un file *.env* con il seguente contenuto:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Trova queste informazioni nel Portale di Azure per la tua risorsa, nella sezione \"Chiavi ed endpoint\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Raccogli le librerie sopra elencate in un file chiamato *requirements.txt* in questo modo:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. Successivamente, crea un ambiente virtuale e installa le librerie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Per Windows, usa i seguenti comandi per creare e attivare il tuo ambiente virtuale:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Aggiungi il seguente codice in un file chiamato *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Spieghiamo questo codice:\n",
    "\n",
    "- Per prima cosa importiamo le librerie necessarie, tra cui la libreria OpenAI, dotenv, requests e Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Poi carichiamo le variabili d'ambiente dal file *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Successivamente, impostiamo l'endpoint, la chiave per l'API di OpenAI, la versione e il tipo.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Poi generiamo l'immagine:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Il codice sopra restituisce un oggetto JSON che contiene l'URL dell'immagine generata. Possiamo usare l'URL per scaricare l'immagine e salvarla su un file.\n",
    "\n",
    "- Infine, apriamo l'immagine e usiamo il visualizzatore di immagini standard per mostrarla:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Maggiori dettagli sulla generazione dell'immagine\n",
    "\n",
    "Vediamo più nel dettaglio il codice che genera l'immagine:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** è il testo che viene usato per generare l'immagine. In questo caso, stiamo usando il prompt \"Coniglietto a cavallo, con un lecca-lecca, su un prato nebbioso dove crescono narcisi\".\n",
    "- **size** è la dimensione dell'immagine generata. In questo caso, generiamo un'immagine di 1024x1024 pixel.\n",
    "- **n** è il numero di immagini generate. In questo caso, generiamo due immagini.\n",
    "- **temperature** è un parametro che controlla la casualità dell'output di un modello di AI generativa. La temperatura è un valore tra 0 e 1: 0 significa che l'output è deterministico, 1 che è casuale. Il valore predefinito è 0.7.\n",
    "\n",
    "Ci sono altre cose che puoi fare con le immagini che vedremo nella prossima sezione.\n",
    "\n",
    "## Altre funzionalità della generazione di immagini\n",
    "\n",
    "Finora hai visto come siamo riusciti a generare un'immagine con poche righe di Python. Tuttavia, ci sono altre cose che puoi fare con le immagini.\n",
    "\n",
    "Puoi anche:\n",
    "\n",
    "- **Effettuare modifiche**. Fornendo un'immagine esistente, una maschera e un prompt, puoi modificare un'immagine. Ad esempio, puoi aggiungere qualcosa a una parte dell'immagine. Immagina la nostra immagine del coniglietto: puoi aggiungere un cappello al coniglio. Per farlo, basta fornire l'immagine, una maschera (che identifica la parte da modificare) e un prompt testuale che descrive cosa deve essere fatto.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    L'immagine di partenza conterrà solo il coniglio, ma l'immagine finale avrà il cappello sul coniglio.\n",
    "    \n",
    "- **Creare variazioni**. \n",
    "    Consulta il nostro [notebook OpenAI per maggiori informazioni](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:  \nQuesto documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Pur impegnandoci per garantire l’accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa deve essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale umana. Non siamo responsabili per eventuali malintesi o interpretazioni errate derivanti dall’uso di questa traduzione.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:15:32+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "it"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}