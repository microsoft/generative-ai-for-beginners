{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creare un'applicazione di generazione immagini\n",
    "\n",
    "Le LLM non servono solo per generare testo. È anche possibile generare immagini a partire da descrizioni testuali. Avere le immagini come modalità può essere estremamente utile in molti settori, dalla MedTech, all’architettura, al turismo, allo sviluppo di videogiochi e molto altro. In questo capitolo, vedremo i due modelli di generazione immagini più popolari: DALL-E e Midjourney.\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questa lezione vedremo:\n",
    "\n",
    "- La generazione di immagini e perché è utile.\n",
    "- DALL-E e Midjourney: cosa sono e come funzionano.\n",
    "- Come si può costruire un’app di generazione immagini.\n",
    "\n",
    "## Obiettivi di apprendimento\n",
    "\n",
    "Al termine di questa lezione sarai in grado di:\n",
    "\n",
    "- Creare un’applicazione per la generazione di immagini.\n",
    "- Definire i limiti della tua applicazione tramite meta prompt.\n",
    "- Lavorare con DALL-E e Midjourney.\n",
    "\n",
    "## Perché creare un’applicazione di generazione immagini?\n",
    "\n",
    "Le applicazioni di generazione immagini sono un ottimo modo per esplorare le potenzialità dell’AI generativa. Possono essere utilizzate, ad esempio, per:\n",
    "\n",
    "- **Modifica e sintesi di immagini**. Puoi generare immagini per diversi casi d’uso, come l’editing o la sintesi di immagini.\n",
    "\n",
    "- **Applicazioni in diversi settori**. Possono essere usate per generare immagini in vari ambiti come MedTech, Turismo, Sviluppo di videogiochi e altro ancora.\n",
    "\n",
    "## Scenario: Edu4All\n",
    "\n",
    "In questa lezione continueremo a lavorare con la nostra startup, Edu4All. Gli studenti creeranno immagini per le loro valutazioni; quali immagini realizzare dipende da loro, ma potrebbero essere illustrazioni per una loro fiaba, la creazione di un nuovo personaggio per la loro storia, oppure per aiutarli a visualizzare idee e concetti.\n",
    "\n",
    "Ecco un esempio di cosa potrebbero generare gli studenti di Edu4All se stanno lavorando in classe sui monumenti:\n",
    "\n",
    "![Startup Edu4All, lezione sui monumenti, Torre Eiffel](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.it.png)\n",
    "\n",
    "usando un prompt come\n",
    "\n",
    "> \"Cane accanto alla Torre Eiffel nella luce del primo mattino\"\n",
    "\n",
    "## Che cosa sono DALL-E e Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) e [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) sono due dei modelli di generazione immagini più diffusi, che permettono di usare prompt per creare immagini.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Cominciamo da DALL-E, un modello di AI generativa che crea immagini a partire da descrizioni testuali.\n",
    "\n",
    "> [DALL-E è una combinazione di due modelli, CLIP e diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** è un modello che genera embedding, cioè rappresentazioni numeriche dei dati, sia da immagini che da testo.\n",
    "\n",
    "- **Diffused attention** è un modello che genera immagini a partire dagli embedding. DALL-E è stato addestrato su un dataset di immagini e testo e può essere usato per generare immagini da descrizioni testuali. Ad esempio, DALL-E può generare immagini di un gatto con un cappello, o di un cane con la cresta.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney funziona in modo simile a DALL-E: genera immagini a partire da prompt testuali. Anche con Midjourney si possono creare immagini usando prompt come “un gatto con un cappello” o “un cane con la cresta”.\n",
    "\n",
    "![Immagine generata da Midjourney, piccione meccanico](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Crediti immagine Wikipedia, immagine generata da Midjourney*\n",
    "\n",
    "## Come funzionano DALL-E e Midjourney\n",
    "\n",
    "Partiamo da [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E è un modello di AI generativa basato sull’architettura transformer con un *autoregressive transformer*.\n",
    "\n",
    "Un *autoregressive transformer* definisce come il modello genera immagini a partire da descrizioni testuali: crea un pixel alla volta, poi usa i pixel già generati per produrre il successivo, passando attraverso diversi strati di una rete neurale fino a completare l’immagine.\n",
    "\n",
    "Con questo processo, DALL-E controlla attributi, oggetti, caratteristiche e altro ancora nell’immagine generata. Tuttavia, DALL-E 2 e 3 offrono un controllo ancora maggiore sull’immagine prodotta,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creare la tua prima applicazione di generazione immagini\n",
    "\n",
    "Cosa serve per creare un'applicazione di generazione immagini? Hai bisogno delle seguenti librerie:\n",
    "\n",
    "- **python-dotenv**, è fortemente consigliato usare questa libreria per conservare le tue chiavi segrete in un file *.env* separato dal codice.\n",
    "- **openai**, questa libreria ti permette di interagire con le API di OpenAI.\n",
    "- **pillow**, per lavorare con le immagini in Python.\n",
    "- **requests**, per facilitare le richieste HTTP.\n",
    "\n",
    "\n",
    "1. Crea un file *.env* con il seguente contenuto:\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Raccogli le librerie sopra elencate in un file chiamato *requirements.txt* in questo modo:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. Successivamente, crea un ambiente virtuale e installa le librerie:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Per Windows, usa i seguenti comandi per creare e attivare il tuo ambiente virtuale:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Aggiungi il seguente codice in un file chiamato *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Spieghiamo questo codice:\n",
    "\n",
    "- Per prima cosa importiamo le librerie di cui abbiamo bisogno, tra cui la libreria OpenAI, dotenv, requests e Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- Successivamente, creiamo l’oggetto che recupererà la chiave API dal tuo file ``.env``.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- Poi, generiamo l’immagine:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Il codice qui sopra restituisce un oggetto JSON che contiene l’URL dell’immagine generata. Possiamo usare l’URL per scaricare l’immagine e salvarla su un file.\n",
    "\n",
    "- Infine, apriamo l’immagine e la visualizziamo con il visualizzatore di immagini predefinito:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Maggiori dettagli sulla generazione dell’immagine\n",
    "\n",
    "Vediamo più nel dettaglio il codice che genera l’immagine:\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** è il testo che viene usato per generare l’immagine. In questo caso, stiamo usando il prompt \"Coniglio a cavallo, con un lecca-lecca, su un prato nebbioso dove crescono narcisi\".\n",
    "- **size** è la dimensione dell’immagine generata. In questo caso, generiamo un’immagine di 1024x1024 pixel.\n",
    "- **n** è il numero di immagini generate. In questo caso, ne generiamo due.\n",
    "\n",
    "Ci sono altre cose che puoi fare con le immagini e che vedremo nella prossima sezione.\n",
    "\n",
    "## Altre funzionalità della generazione di immagini\n",
    "\n",
    "Finora hai visto come siamo riusciti a generare un’immagine con poche righe di Python. Tuttavia, ci sono altre possibilità con le immagini.\n",
    "\n",
    "Puoi anche fare quanto segue:\n",
    "\n",
    "- **Effettuare modifiche**. Fornendo un’immagine esistente, una maschera e un prompt, puoi modificare un’immagine. Ad esempio, puoi aggiungere qualcosa in una parte dell’immagine. Immagina la nostra immagine del coniglio: puoi aggiungere un cappello al coniglio. Per farlo, basta fornire l’immagine, una maschera (che identifica la zona da modificare) e un prompt testuale che descrive cosa deve essere fatto.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    L’immagine di partenza conterrà solo il coniglio, ma l’immagine finale avrà il cappello sul coniglio.\n",
    "    \n",
    "- **Creare variazioni**. L’idea è prendere un’immagine esistente e chiedere di crearne delle variazioni. Per creare una variazione, fornisci un’immagine, un prompt testuale e un codice come questo:\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:  \nQuesto documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Pur impegnandoci per garantire l’accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa deve essere considerato la fonte autorevole. Per informazioni di carattere critico, si raccomanda una traduzione professionale umana. Non siamo responsabili per eventuali malintesi o interpretazioni errate derivanti dall’uso di questa traduzione.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:38:23+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "it"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}