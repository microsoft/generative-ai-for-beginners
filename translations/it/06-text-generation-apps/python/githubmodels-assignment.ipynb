{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crea app di generazione di testo\n",
    "\n",
    "Finora, in questo percorso hai visto che ci sono concetti fondamentali come i prompt e persino una disciplina chiamata \"prompt engineering\". Molti strumenti con cui puoi interagire, come ChatGPT, Office 365, Microsoft Power Platform e altri, ti permettono di usare i prompt per raggiungere un obiettivo.\n",
    "\n",
    "Per aggiungere questa esperienza a un'app, devi comprendere concetti come prompt, completamenti e scegliere una libreria con cui lavorare. È proprio quello che imparerai in questo capitolo.\n",
    "\n",
    "## Introduzione\n",
    "\n",
    "In questo capitolo:\n",
    "\n",
    "- Scoprirai la libreria openai e i suoi concetti principali.\n",
    "- Costruirai un'app di generazione di testo usando openai.\n",
    "- Capirai come utilizzare concetti come prompt, temperatura e token per creare un'app di generazione di testo.\n",
    "\n",
    "## Obiettivi di apprendimento\n",
    "\n",
    "Al termine di questa lezione, sarai in grado di:\n",
    "\n",
    "- Spiegare cos'è un'app di generazione di testo.\n",
    "- Creare un'app di generazione di testo usando openai.\n",
    "- Configurare la tua app per usare più o meno token e modificare la temperatura, per ottenere risultati diversi.\n",
    "\n",
    "## Cos'è un'app di generazione di testo?\n",
    "\n",
    "Normalmente, quando crei un'app, questa ha una qualche interfaccia come le seguenti:\n",
    "\n",
    "- Basata su comandi. Le app da console sono tipici esempi in cui digiti un comando e viene eseguita un'operazione. Ad esempio, `git` è un'app basata su comandi.\n",
    "- Interfaccia utente (UI). Alcune app hanno interfacce grafiche (GUI) dove puoi cliccare pulsanti, inserire testo, selezionare opzioni e altro.\n",
    "\n",
    "### Le app da console e con UI sono limitate\n",
    "\n",
    "Confronta con un'app basata su comandi dove digiti un comando:\n",
    "\n",
    "- **È limitata**. Non puoi digitare qualsiasi comando, solo quelli che l'app supporta.\n",
    "- **Lingua specifica**. Alcune app supportano molte lingue, ma di solito l'app è pensata per una lingua specifica, anche se puoi aggiungere il supporto per altre lingue.\n",
    "\n",
    "### Vantaggi delle app di generazione di testo\n",
    "\n",
    "Quindi, in cosa è diversa un'app di generazione di testo?\n",
    "\n",
    "In un'app di generazione di testo hai molta più flessibilità, non sei limitato a un set di comandi o a una lingua di input specifica. Puoi invece usare il linguaggio naturale per interagire con l'app. Un altro vantaggio è che, dato che interagisci con una fonte di dati addestrata su un vasto corpus di informazioni, un'app tradizionale potrebbe essere limitata a ciò che è presente in un database.\n",
    "\n",
    "### Cosa posso creare con un'app di generazione di testo?\n",
    "\n",
    "Le possibilità sono molte. Ad esempio:\n",
    "\n",
    "- **Un chatbot**. Un chatbot che risponde a domande su argomenti come la tua azienda e i suoi prodotti può essere una buona soluzione.\n",
    "- **Assistente**. Gli LLM sono ottimi per riassumere testi, estrarre informazioni, produrre testi come curriculum e altro ancora.\n",
    "- **Assistente al codice**. A seconda del modello linguistico che usi, puoi creare un assistente che ti aiuta a scrivere codice. Ad esempio, puoi usare prodotti come GitHub Copilot o ChatGPT per aiutarti nella scrittura del codice.\n",
    "\n",
    "## Come posso iniziare?\n",
    "\n",
    "Devi trovare un modo per integrarti con un LLM, che di solito prevede due approcci:\n",
    "\n",
    "- Usare un'API. In questo caso costruisci richieste web con il tuo prompt e ricevi il testo generato.\n",
    "- Usare una libreria. Le librerie aiutano a incapsulare le chiamate API e a renderle più semplici da usare.\n",
    "\n",
    "## Librerie/SDK\n",
    "\n",
    "Esistono alcune librerie ben note per lavorare con gli LLM, come:\n",
    "\n",
    "- **openai**, questa libreria rende facile collegarsi al tuo modello e inviare prompt.\n",
    "\n",
    "Poi ci sono librerie che operano a un livello più alto, come:\n",
    "\n",
    "- **Langchain**. Langchain è molto conosciuta e supporta Python.\n",
    "- **Semantic Kernel**. Semantic Kernel è una libreria di Microsoft che supporta C#, Python e Java.\n",
    "\n",
    "## Prima app con GitHub Models Playground e Azure AI Inference SDK\n",
    "\n",
    "Vediamo come costruire la nostra prima app, quali librerie servono, cosa è necessario e così via.\n",
    "\n",
    "### Cos'è GitHub Models?\n",
    "\n",
    "Benvenuto su [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Qui trovi tutto pronto per esplorare diversi modelli AI ospitati su Azure AI, tutti accessibili tramite un playground su GitHub o direttamente dal tuo IDE preferito, gratuitamente per provare.\n",
    "\n",
    "### Cosa mi serve?\n",
    "\n",
    "* Un account GitHub: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Iscriviti a GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Iniziamo!\n",
    "\n",
    "### Trova un modello e provalo\n",
    "\n",
    "Vai su [GitHub Models nel Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Schermata principale di GitHub Models che mostra una lista di modelli come Cohere, Meta llama, Mistral e GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.it.png)\n",
    "\n",
    "Scegli un modello - ad esempio [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Qui vedrai la scheda del modello. Puoi:\n",
    "* Interagire con il modello direttamente inserendo un messaggio nella casella di testo\n",
    "* Leggere i dettagli sul modello nei tab Readme, Evaluation, Transparency e License\n",
    "* Consultare la sezione 'About' sulla destra per le informazioni di accesso al modello\n",
    "\n",
    "![Scheda modello GPT-4o su GitHub Models](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.it.png)\n",
    "\n",
    "Ma andremo direttamente al playground cliccando sul [pulsante 'Playground' in alto a destra](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Qui puoi interagire con il modello, aggiungere prompt di sistema e modificare i parametri - ma anche ottenere tutto il codice necessario per eseguire il modello ovunque. Disponibile da settembre 2024: Python, Javascript, C# e REST.\n",
    "\n",
    "![Esperienza Playground di GitHub Models con codice e linguaggi mostrati](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.it.png)  \n",
    "\n",
    "### Usiamo il modello nel nostro IDE\n",
    "\n",
    "Due opzioni:\n",
    "1. **GitHub Codespaces** - integrazione diretta con Codespaces e nessun token necessario per iniziare\n",
    "2. **VS Code (o qualsiasi IDE preferito)** - serve ottenere un [Personal Access Token da GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "In entrambi i casi, le istruzioni sono disponibili tramite il pulsante verde 'Get started' in alto a destra.\n",
    "\n",
    "![Schermata Get Started che mostra come accedere a Codespaces o usare un personal access token per configurare nel proprio IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.it.png)\n",
    "\n",
    "### 1. Codespaces\n",
    "\n",
    "* Dalla finestra 'Get started' scegli \"Run codespace\"\n",
    "* Crea un nuovo codespace (o usane uno esistente)\n",
    "* VS Code si aprirà nel browser con una serie di notebook di esempio in vari linguaggi che puoi provare\n",
    "* Esegui l'esempio ```./githubmodels-app.py```.\n",
    "\n",
    "> Nota: In codespaces non è necessario impostare la variabile Github Token, salta questo passaggio\n",
    "\n",
    "**Ora passa alla sezione 'Genera testo' qui sotto per continuare l'esercitazione**\n",
    "\n",
    "### 2. VS Code (o qualsiasi IDE preferito)\n",
    "\n",
    "Dal pulsante verde 'Get started' trovi tutte le informazioni necessarie per eseguire nel tuo IDE preferito. Questo esempio mostra VS Code\n",
    "\n",
    "* Seleziona il linguaggio e l'SDK - in questo esempio scegliamo Python e Azure AI Inference SDK\n",
    "* Crea un personal access token su GitHub. Si trova nella sezione Developer Settings. Non è necessario assegnare permessi al token. Nota che il token verrà inviato a un servizio Microsoft.\n",
    "* Crea una variabile d'ambiente per memorizzare il tuo personal access token di Github - esempi disponibili per bash, powershell e prompt dei comandi di Windows\n",
    "* Installa le dipendenze: ```pip install azure-ai-inference```\n",
    "* Copia il codice di esempio base in un file .py\n",
    "* Vai nella cartella dove hai salvato il codice ed esegui il file: ```python filename.py```\n",
    "\n",
    "Ricorda che usando Azure AI Inference SDK puoi facilmente sperimentare con diversi modelli modificando il valore di `model_name` nel codice.\n",
    "\n",
    "I seguenti modelli sono disponibili nel servizio GitHub Models a settembre 2024:\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "**Ora passa alla sezione 'Genera testo' qui sotto per continuare l'esercitazione**\n",
    "\n",
    "## Genera testo con ChatCompletions\n",
    "\n",
    "Per generare testo si usa la classe `ChatCompletionsClient`.\n",
    "Nel file `samples/python/azure_ai_inference/basic.py`, nella sezione di risposta del codice, aggiorna il ruolo dell'utente modificando il parametro content come segue:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Esegui il file aggiornato per vedere il risultato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipi diversi di prompt, per cose diverse\n",
    "\n",
    "Ora hai visto come generare testo usando un prompt. Hai persino un programma funzionante che puoi modificare e cambiare per generare diversi tipi di testo.\n",
    "\n",
    "I prompt possono essere usati per tutti i tipi di compiti. Ad esempio:\n",
    "\n",
    "- **Generare un tipo di testo**. Ad esempio, puoi generare una poesia, domande per un quiz, ecc.\n",
    "- **Cercare informazioni**. Puoi usare i prompt per cercare informazioni come nell'esempio seguente: 'Cosa significa CORS nello sviluppo web?'.\n",
    "- **Generare codice**. Puoi usare i prompt per generare codice, ad esempio sviluppando un'espressione regolare per validare email o, perché no, generare un intero programma, come una web app?\n",
    "\n",
    "## Esercizio: un generatore di ricette\n",
    "\n",
    "Immagina di avere degli ingredienti a casa e di voler cucinare qualcosa. Per questo, ti serve una ricetta. Un modo per trovare ricette è usare un motore di ricerca oppure potresti usare un LLM.\n",
    "\n",
    "Potresti scrivere un prompt come questo:\n",
    "\n",
    "> \"Mostrami 5 ricette per un piatto con i seguenti ingredienti: pollo, patate e carote. Per ogni ricetta, elenca tutti gli ingredienti utilizzati\"\n",
    "\n",
    "Dato il prompt sopra, potresti ricevere una risposta simile a:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "Questo risultato è ottimo, ora so cosa cucinare. A questo punto, possibili miglioramenti utili potrebbero essere:\n",
    "\n",
    "- Escludere ingredienti che non mi piacciono o a cui sono allergico.\n",
    "- Creare una lista della spesa, nel caso non abbia tutti gli ingredienti a casa.\n",
    "\n",
    "Per i casi sopra, aggiungiamo un prompt aggiuntivo:\n",
    "\n",
    "> \"Per favore, rimuovi le ricette con aglio perché sono allergico e sostituiscilo con qualcos'altro. Inoltre, crea una lista della spesa per le ricette, considerando che ho già pollo, patate e carote a casa.\"\n",
    "\n",
    "Ora hai un nuovo risultato, ovvero:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Ecco le tue cinque ricette, senza aglio menzionato e hai anche una lista della spesa che tiene conto di ciò che hai già a casa.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Esercizio - crea un generatore di ricette\n",
    "\n",
    "Ora che abbiamo visto uno scenario, scriviamo del codice che corrisponda allo scenario mostrato. Per farlo, segui questi passaggi:\n",
    "\n",
    "1. Usa il file esistente come punto di partenza\n",
    "1. Crea una variabile `prompt` e modifica il codice di esempio come indicato di seguito:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ora esegui il codice, dovresti vedere un output simile a:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, il tuo LLM è non deterministico, quindi potresti ottenere risultati diversi ogni volta che esegui il programma.\n",
    "\n",
    "Ottimo, vediamo come possiamo migliorare le cose. Per migliorare la situazione, vogliamo assicurarci che il codice sia flessibile, così da poter modificare e migliorare gli ingredienti e il numero di ricette.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eseguire un test del codice potrebbe essere così:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Migliorare aggiungendo filtro e lista della spesa\n",
    "\n",
    "Ora abbiamo un'app funzionante in grado di generare ricette ed è flessibile perché si basa sugli input dell'utente, sia per il numero di ricette che per gli ingredienti utilizzati.\n",
    "\n",
    "Per migliorarla ulteriormente, vogliamo aggiungere quanto segue:\n",
    "\n",
    "- **Filtrare gli ingredienti**. Vogliamo poter escludere ingredienti che non ci piacciono o a cui siamo allergici. Per ottenere questo risultato, possiamo modificare il prompt esistente e aggiungere una condizione di filtro alla fine, in questo modo:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Qui sopra, aggiungiamo `{filter}` alla fine del prompt e catturiamo anche il valore del filtro dall'utente.\n",
    "\n",
    "    Un esempio di input per eseguire il programma ora potrebbe essere così:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Generare una lista della spesa**. Vogliamo creare una lista della spesa, tenendo conto di ciò che abbiamo già in casa.\n",
    "\n",
    "    Per questa funzionalità, potremmo provare a risolvere tutto in un unico prompt oppure suddividerlo in due prompt. Proviamo quest'ultimo approccio. Qui suggeriamo di aggiungere un prompt aggiuntivo, ma per farlo funzionare, dobbiamo aggiungere il risultato del primo prompt come contesto al secondo prompt.\n",
    "\n",
    "    Trova la parte del codice che stampa il risultato del primo prompt e aggiungi il seguente codice sotto:\n",
    "    \n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "\n",
    "    Nota quanto segue:\n",
    "\n",
    "    - Stiamo costruendo un nuovo prompt aggiungendo il risultato del primo prompt al nuovo prompt:\n",
    "    \n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Facciamo una nuova richiesta, ma considerando anche il numero di token richiesti nel primo prompt, quindi questa volta impostiamo `max_tokens` a 1200. **Una parola sulla lunghezza dei token**. Dovremmo considerare quanti token ci servono per generare il testo desiderato. I token hanno un costo, quindi dove possibile, dovremmo cercare di essere economici con il numero di token utilizzati. Ad esempio, possiamo formulare il prompt in modo da usare meno token?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Provando questo codice, otteniamo il seguente output:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Sperimentare con la temperatura**. La temperatura è qualcosa di cui non abbiamo ancora parlato, ma è un contesto importante per il funzionamento del nostro programma. Più alto è il valore della temperatura, più casuale sarà l'output. Al contrario, più basso è il valore della temperatura, più prevedibile sarà il risultato. Valuta se desideri o meno variazione nell'output.\n",
    "\n",
    "   Per modificare la temperatura, puoi usare il parametro `temperature`. Ad esempio, se vuoi usare una temperatura di 0.5, dovresti fare così:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Nota, più ci si avvicina a 1.0, più l'output sarà vario.\n",
    "\n",
    "\n",
    "## Compito\n",
    "\n",
    "Per questo compito, puoi scegliere cosa costruire.\n",
    "\n",
    "Ecco alcuni suggerimenti:\n",
    "\n",
    "- Modifica l'app generatrice di ricette per migliorarla ulteriormente. Sperimenta con i valori di temperatura e i prompt per vedere cosa riesci a ottenere.\n",
    "- Crea un \"compagno di studio\". Questa app dovrebbe essere in grado di rispondere a domande su un argomento, ad esempio Python; potresti avere prompt come \"Cos'è un certo argomento in Python?\", oppure un prompt che dice, mostrami il codice per un certo argomento, ecc.\n",
    "- Bot storico, fai rivivere la storia, istruisci il bot a interpretare un personaggio storico e fagli domande sulla sua vita e sui suoi tempi.\n",
    "\n",
    "## Soluzione\n",
    "\n",
    "### Compagno di studio\n",
    "\n",
    "- \"Sei un esperto del linguaggio Python\n",
    "\n",
    "    Suggerisci una lezione per principianti su Python nel seguente formato:\n",
    "    \n",
    "    Formato:\n",
    "    - concetti:\n",
    "    - breve spiegazione della lezione:\n",
    "    - esercizio in codice con soluzioni\"\n",
    "\n",
    "Qui sopra c'è un prompt di partenza, vedi come puoi usarlo e modificarlo a tuo piacimento.\n",
    "\n",
    "### Bot storico\n",
    "\n",
    "Ecco alcuni prompt che potresti usare:\n",
    "\n",
    "- \"Sei Abe Lincoln, parlami di te in 3 frasi e rispondi usando la grammatica e le parole che userebbe Abe\"\n",
    "- \"Sei Abe Lincoln, rispondi usando la grammatica e le parole che userebbe Abe:\n",
    "\n",
    "   Parlami delle tue più grandi conquiste, in 300 parole:\"\n",
    "\n",
    "## Verifica delle conoscenze\n",
    "\n",
    "A cosa serve il concetto di temperatura?\n",
    "\n",
    "1. Controlla quanto è casuale l'output.\n",
    "1. Controlla quanto è grande la risposta.\n",
    "1. Controlla quanti token vengono usati.\n",
    "\n",
    "R: 1\n",
    "\n",
    "Qual è un buon modo per conservare segreti come le chiavi API?\n",
    "\n",
    "1. Nel codice.\n",
    "1. In un file.\n",
    "1. In variabili d'ambiente.\n",
    "\n",
    "R: 3, perché le variabili d'ambiente non sono memorizzate nel codice e possono essere caricate dal codice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Disclaimer**:  \nQuesto documento è stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Pur impegnandoci per garantire l’accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa deve essere considerato la fonte autorevole. Per informazioni di carattere critico, si raccomanda una traduzione professionale umana. Non siamo responsabili per eventuali malintesi o interpretazioni errate derivanti dall’uso di questa traduzione.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T15:07:53+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "it"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}