<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:54:52+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "it"
}
-->
# Usare l‚ÄôAI Generativa in Modo Responsabile

[![Usare l‚ÄôAI Generativa in Modo Responsabile](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.it.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Clicca sull‚Äôimmagine sopra per vedere il video di questa lezione_

√à facile rimanere affascinati dall‚ÄôAI e in particolare dall‚ÄôAI generativa, ma √® importante riflettere su come usarla responsabilmente. Bisogna considerare aspetti come garantire che i risultati siano equi, non dannosi e altro ancora. Questo capitolo ha l‚Äôobiettivo di fornirti il contesto necessario, cosa considerare e come adottare misure attive per migliorare il tuo utilizzo dell‚ÄôAI.

## Introduzione

Questa lezione tratter√†:

- Perch√© dovresti dare priorit√† all‚ÄôAI Responsabile quando costruisci applicazioni di AI Generativa.
- I principi fondamentali dell‚ÄôAI Responsabile e come si collegano all‚ÄôAI Generativa.
- Come mettere in pratica questi principi di AI Responsabile attraverso strategie e strumenti.

## Obiettivi di Apprendimento

Al termine di questa lezione saprai:

- L‚Äôimportanza dell‚ÄôAI Responsabile nella costruzione di applicazioni di AI Generativa.
- Quando pensare e applicare i principi fondamentali dell‚ÄôAI Responsabile durante lo sviluppo di applicazioni di AI Generativa.
- Quali strumenti e strategie sono a tua disposizione per mettere in pratica il concetto di AI Responsabile.

## Principi di AI Responsabile

L‚Äôentusiasmo per l‚ÄôAI Generativa non √® mai stato cos√¨ alto. Questo entusiasmo ha portato molti nuovi sviluppatori, attenzione e finanziamenti in questo settore. Sebbene ci√≤ sia molto positivo per chiunque voglia costruire prodotti e aziende usando l‚ÄôAI Generativa, √® altrettanto importante procedere con responsabilit√†.

Durante questo corso, ci concentreremo sulla costruzione della nostra startup e del nostro prodotto educativo sull‚ÄôAI. Useremo i principi di AI Responsabile: Equit√†, Inclusivit√†, Affidabilit√†/Sicurezza, Sicurezza & Privacy, Trasparenza e Responsabilit√†. Con questi principi esploreremo come si collegano al nostro uso dell‚ÄôAI Generativa nei nostri prodotti.

## Perch√© Dovresti Dare Priorit√† all‚ÄôAI Responsabile

Quando si costruisce un prodotto, adottare un approccio centrato sull‚Äôessere umano, tenendo a mente il miglior interesse dell‚Äôutente, porta ai risultati migliori.

La particolarit√† dell‚ÄôAI Generativa √® la sua capacit√† di creare risposte utili, informazioni, indicazioni e contenuti per gli utenti. Questo pu√≤ avvenire senza molti passaggi manuali, portando a risultati molto impressionanti. Senza una pianificazione e strategie adeguate, purtroppo pu√≤ anche causare risultati dannosi per gli utenti, il prodotto e la societ√† nel suo complesso.

Vediamo alcuni (ma non tutti) di questi potenziali effetti dannosi:

### Allucinazioni

Il termine ‚Äúallucinazioni‚Äù si usa per descrivere quando un LLM produce contenuti che sono completamente insensati o che sappiamo essere fattualmente errati basandoci su altre fonti di informazione.

Prendiamo ad esempio che sviluppiamo una funzionalit√† per la nostra startup che permette agli studenti di fare domande storiche a un modello. Uno studente chiede: `Chi √® stato l‚Äôunico sopravvissuto del Titanic?`

Il modello produce una risposta come quella qui sotto:

![Prompt che dice "Chi √® stato l‚Äôunico sopravvissuto del Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Fonte: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Questa √® una risposta molto sicura e dettagliata. Purtroppo, √® sbagliata. Anche con una minima ricerca, si scoprirebbe che ci sono stati pi√π sopravvissuti al disastro del Titanic. Per uno studente che sta iniziando a informarsi su questo argomento, questa risposta pu√≤ essere abbastanza persuasiva da non essere messa in discussione e trattata come un fatto. Le conseguenze possono portare a rendere il sistema AI inaffidabile e danneggiare la reputazione della nostra startup.

Ad ogni iterazione di un LLM, abbiamo visto miglioramenti nella riduzione delle allucinazioni. Nonostante questo progresso, noi come sviluppatori e utenti dobbiamo comunque rimanere consapevoli di questi limiti.

### Contenuti Dannosi

Abbiamo visto nella sezione precedente quando un LLM produce risposte errate o insensate. Un altro rischio da tenere presente √® quando un modello risponde con contenuti dannosi.

I contenuti dannosi possono essere definiti come:

- Fornire istruzioni o incoraggiare l‚Äôautolesionismo o il danno a determinati gruppi.
- Contenuti d‚Äôodio o denigratori.
- Guidare la pianificazione di attacchi o atti violenti.
- Fornire istruzioni su come trovare contenuti illegali o commettere atti illeciti.
- Mostrare contenuti sessualmente espliciti.

Per la nostra startup, vogliamo assicurarci di avere gli strumenti e le strategie giuste per evitare che questo tipo di contenuti venga visto dagli studenti.

### Mancanza di Equit√†

L‚Äôequit√† si definisce come ‚Äúgarantire che un sistema AI sia privo di pregiudizi e discriminazioni e che tratti tutti in modo equo e uguale.‚Äù Nel mondo dell‚ÄôAI Generativa, vogliamo assicurarci che visioni escludenti di gruppi emarginati non vengano rafforzate dai risultati prodotti dal modello.

Questi tipi di output non solo sono distruttivi per costruire esperienze positive per i nostri utenti, ma causano anche danni sociali pi√π ampi. Come sviluppatori di applicazioni, dovremmo sempre tenere a mente una base utenti ampia e diversificata quando costruiamo soluzioni con l‚ÄôAI Generativa.

## Come Usare l‚ÄôAI Generativa in Modo Responsabile

Ora che abbiamo identificato l‚Äôimportanza dell‚ÄôAI Generativa Responsabile, vediamo 4 passaggi che possiamo seguire per costruire le nostre soluzioni AI in modo responsabile:

![Ciclo di mitigazione](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.it.png)

### Misurare i Potenziali Danni

Nel testing del software, testiamo le azioni previste di un utente su un‚Äôapplicazione. Allo stesso modo, testare un insieme diversificato di prompt che gli utenti probabilmente useranno √® un buon modo per misurare i potenziali danni.

Dato che la nostra startup sta costruendo un prodotto educativo, sarebbe utile preparare una lista di prompt legati all‚Äôeducazione. Questi potrebbero riguardare una certa materia, fatti storici e prompt sulla vita studentesca.

### Mitigare i Potenziali Danni

√à ora di trovare modi per prevenire o limitare i potenziali danni causati dal modello e dalle sue risposte. Possiamo considerare questo su 4 livelli differenti:

![Livelli di mitigazione](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.it.png)

- **Modello**. Scegliere il modello giusto per il caso d‚Äôuso corretto. Modelli pi√π grandi e complessi come GPT-4 possono comportare un rischio maggiore di contenuti dannosi se applicati a casi d‚Äôuso pi√π piccoli e specifici. Usare i dati di addestramento per il fine-tuning riduce anche il rischio di contenuti dannosi.

- **Sistema di Sicurezza**. Un sistema di sicurezza √® un insieme di strumenti e configurazioni sulla piattaforma che serve il modello e aiuta a mitigare i danni. Un esempio √® il sistema di filtraggio dei contenuti sul servizio Azure OpenAI. I sistemi dovrebbero anche rilevare attacchi di jailbreak e attivit√† indesiderate come richieste da bot.

- **Metaprompt**. I metaprompt e il grounding sono modi per indirizzare o limitare il modello basandosi su certi comportamenti e informazioni. Questo pu√≤ includere l‚Äôuso di input di sistema per definire certi limiti del modello. Inoltre, fornire output pi√π rilevanti rispetto all‚Äôambito o al dominio del sistema.

Pu√≤ anche significare usare tecniche come Retrieval Augmented Generation (RAG) per far s√¨ che il modello estragga informazioni solo da una selezione di fonti affidabili. C‚Äô√® una lezione pi√π avanti in questo corso su [come costruire applicazioni di ricerca](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Esperienza Utente**. L‚Äôultimo livello √® dove l‚Äôutente interagisce direttamente con il modello attraverso l‚Äôinterfaccia della nostra applicazione. In questo modo possiamo progettare l‚ÄôUI/UX per limitare il tipo di input che l‚Äôutente pu√≤ inviare al modello, cos√¨ come i testi o le immagini mostrati all‚Äôutente. Quando distribuiamo l‚Äôapplicazione AI, dobbiamo anche essere trasparenti su cosa la nostra applicazione di AI Generativa pu√≤ e non pu√≤ fare.

Abbiamo un‚Äôintera lezione dedicata a [Progettare l‚ÄôUX per Applicazioni AI](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Valutare il modello**. Lavorare con gli LLM pu√≤ essere impegnativo perch√© non sempre abbiamo il controllo sui dati con cui il modello √® stato addestrato. Tuttavia, dovremmo sempre valutare le prestazioni e gli output del modello. √à importante misurare l‚Äôaccuratezza, la somiglianza, la fondatezza e la rilevanza dell‚Äôoutput. Questo aiuta a fornire trasparenza e fiducia a stakeholder e utenti.

### Gestire una Soluzione di AI Generativa Responsabile

Costruire una pratica operativa intorno alle tue applicazioni AI √® l‚Äôultimo stadio. Questo include collaborare con altre parti della nostra startup come il reparto Legale e Sicurezza per garantire la conformit√† a tutte le normative. Prima del lancio, vogliamo anche elaborare piani per la distribuzione, la gestione degli incidenti e il rollback per prevenire danni crescenti ai nostri utenti.

## Strumenti

Anche se sviluppare soluzioni di AI Responsabile pu√≤ sembrare impegnativo, √® un lavoro che vale la pena. Man mano che il campo dell‚ÄôAI Generativa cresce, matureranno sempre pi√π strumenti per aiutare gli sviluppatori a integrare la responsabilit√† nei loro flussi di lavoro in modo efficiente. Per esempio, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) pu√≤ aiutare a rilevare contenuti e immagini dannose tramite una richiesta API.

## Verifica delle Conoscenze

Quali sono alcune cose a cui devi prestare attenzione per garantire un uso responsabile dell‚ÄôAI?

1. Che la risposta sia corretta.  
1. Uso dannoso, che l‚ÄôAI non venga usata per scopi criminali.  
1. Assicurarsi che l‚ÄôAI sia priva di pregiudizi e discriminazioni.

R: 2 e 3 sono corrette. L‚ÄôAI Responsabile ti aiuta a considerare come mitigare effetti dannosi, pregiudizi e altro.

## üöÄ Sfida

Leggi su [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) e valuta cosa puoi adottare per il tuo utilizzo.

## Ottimo Lavoro, Continua a Imparare

Dopo aver completato questa lezione, dai un‚Äôocchiata alla nostra [collezione di apprendimento sull‚ÄôAI Generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) per continuare a migliorare le tue conoscenze sull‚ÄôAI Generativa!

Passa alla Lezione 4 dove esploreremo i [Fondamenti di Prompt Engineering](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Disclaimer**:  
Questo documento √® stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Pur impegnandoci per garantire accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa deve essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un umano. Non ci assumiamo alcuna responsabilit√† per eventuali malintesi o interpretazioni errate derivanti dall‚Äôuso di questa traduzione.