<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:30:58+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "it"
}
-->
# Framework per Reti Neurali

Come abbiamo gi√† imparato, per poter addestrare reti neurali in modo efficiente dobbiamo fare due cose:

* Operare su tensori, ad esempio moltiplicare, sommare e calcolare alcune funzioni come sigmoid o softmax
* Calcolare i gradienti di tutte le espressioni, per poter eseguire l‚Äôottimizzazione tramite discesa del gradiente

Mentre la libreria `numpy` pu√≤ gestire la prima parte, abbiamo bisogno di un meccanismo per calcolare i gradienti. Nel nostro framework sviluppato nella sezione precedente abbiamo dovuto programmare manualmente tutte le funzioni derivate all‚Äôinterno del metodo `backward`, che esegue la backpropagation. Idealmente, un framework dovrebbe darci la possibilit√† di calcolare i gradienti di *qualsiasi espressione* che possiamo definire.

Un altro aspetto importante √® poter eseguire i calcoli su GPU, o su altre unit√† di calcolo specializzate, come TPU. L‚Äôaddestramento di reti neurali profonde richiede *molti* calcoli, e poter parallelizzare questi calcoli su GPU √® fondamentale.

> ‚úÖ Il termine 'parallelizzare' significa distribuire i calcoli su pi√π dispositivi.

Attualmente, i due framework neurali pi√π popolari sono: TensorFlow e PyTorch. Entrambi offrono un‚ÄôAPI a basso livello per operare con tensori sia su CPU che su GPU. Sopra l‚ÄôAPI a basso livello, esiste anche un‚ÄôAPI di livello pi√π alto, chiamata rispettivamente Keras e PyTorch Lightning.

Low-Level API | TensorFlow| PyTorch
--------------|-------------------------------------|--------------------------------
High-level API| Keras| PyTorch

Le **API a basso livello** in entrambi i framework permettono di costruire i cosiddetti **grafi computazionali**. Questo grafo definisce come calcolare l‚Äôoutput (di solito la funzione di perdita) dati i parametri di input, e pu√≤ essere eseguito su GPU, se disponibile. Ci sono funzioni per differenziare questo grafo computazionale e calcolare i gradienti, che possono poi essere usati per ottimizzare i parametri del modello.

Le **API di alto livello** considerano le reti neurali come una **sequenza di layer**, e rendono molto pi√π semplice costruire la maggior parte delle reti neurali. L‚Äôaddestramento del modello di solito richiede di preparare i dati e poi chiamare una funzione `fit` per eseguire il training.

L‚ÄôAPI di alto livello permette di costruire reti neurali tipiche molto rapidamente senza preoccuparsi di molti dettagli. Allo stesso tempo, l‚ÄôAPI a basso livello offre molto pi√π controllo sul processo di addestramento, ed √® quindi molto usata nella ricerca, quando si lavora con nuove architetture di reti neurali.

√à anche importante capire che si possono usare entrambe le API insieme, ad esempio si pu√≤ sviluppare la propria architettura di layer usando l‚ÄôAPI a basso livello, e poi usarla all‚Äôinterno di una rete pi√π grande costruita e addestrata con l‚ÄôAPI di alto livello. Oppure si pu√≤ definire una rete con l‚ÄôAPI di alto livello come sequenza di layer, e poi usare un proprio ciclo di addestramento a basso livello per eseguire l‚Äôottimizzazione. Entrambe le API condividono gli stessi concetti di base e sono progettate per funzionare bene insieme.

## Apprendimento

In questo corso offriamo la maggior parte dei contenuti sia per PyTorch che per TensorFlow. Puoi scegliere il framework che preferisci e seguire solo i notebook corrispondenti. Se non sei sicuro su quale framework scegliere, leggi alcune discussioni online riguardo **PyTorch vs. TensorFlow**. Puoi anche dare un‚Äôocchiata a entrambi i framework per capire meglio.

Quando possibile, useremo le API di alto livello per semplicit√†. Tuttavia, riteniamo importante capire come funzionano le reti neurali dalle basi, quindi all‚Äôinizio lavoreremo con l‚ÄôAPI a basso livello e i tensori. Se per√≤ vuoi partire velocemente e non vuoi perdere tempo con questi dettagli, puoi saltare direttamente ai notebook con l‚ÄôAPI di alto livello.

## ‚úçÔ∏è Esercizi: Framework

Continua il tuo apprendimento nei seguenti notebook:

Low-Level API | TensorFlow+Keras Notebook | PyTorch
--------------|-------------------------------------|--------------------------------
High-level API| Keras | *PyTorch Lightning*

Dopo aver padroneggiato i framework, riepiloghiamo il concetto di overfitting.

# Overfitting

L‚Äôoverfitting √® un concetto estremamente importante nel machine learning, ed √® fondamentale comprenderlo bene!

Considera il seguente problema di approssimare 5 punti (rappresentati da `x` nei grafici sottostanti):

!linear | overfit
-------------------------|--------------------------
**Modello lineare, 2 parametri** | **Modello non lineare, 7 parametri**
Errore di training = 5.3 | Errore di training = 0
Errore di validazione = 5.1 | Errore di validazione = 20

* A sinistra vediamo una buona approssimazione con una retta. Poich√© il numero di parametri √® adeguato, il modello coglie correttamente la distribuzione dei punti.
* A destra, il modello √® troppo potente. Poich√© abbiamo solo 5 punti e il modello ha 7 parametri, pu√≤ adattarsi in modo da passare esattamente per tutti i punti, azzerando l‚Äôerrore di training. Tuttavia, questo impedisce al modello di capire il pattern corretto dietro i dati, quindi l‚Äôerrore di validazione √® molto alto.

√à molto importante trovare un giusto equilibrio tra la complessit√† del modello (numero di parametri) e il numero di campioni di training.

## Perch√© si verifica l‚Äôoverfitting

  * Dati di training insufficienti
  * Modello troppo complesso
  * Troppo rumore nei dati di input

## Come rilevare l‚Äôoverfitting

Come si vede dal grafico sopra, l‚Äôoverfitting si pu√≤ riconoscere da un errore di training molto basso e un errore di validazione alto. Normalmente durante l‚Äôaddestramento vedremo sia l‚Äôerrore di training che quello di validazione diminuire, poi a un certo punto l‚Äôerrore di validazione potrebbe smettere di diminuire e iniziare a salire. Questo √® un segnale di overfitting, e indica che probabilmente dovremmo fermare l‚Äôaddestramento a questo punto (o almeno salvare uno snapshot del modello).

overfitting

## Come prevenire l‚Äôoverfitting

Se noti che si verifica l‚Äôoverfitting, puoi fare una delle seguenti cose:

 * Aumentare la quantit√† di dati di training
 * Ridurre la complessit√† del modello
 * Usare qualche tecnica di regolarizzazione, come Dropout, che vedremo pi√π avanti.

## Overfitting e compromesso Bias-Varianza

L‚Äôoverfitting √® in realt√† un caso di un problema pi√π generale in statistica chiamato compromesso Bias-Varianza. Se consideriamo le possibili fonti di errore nel nostro modello, possiamo distinguere due tipi di errori:

* Gli **errori di bias** sono causati dal fatto che il nostro algoritmo non riesce a catturare correttamente la relazione tra i dati di training. Questo pu√≤ succedere se il modello non √® abbastanza potente (**underfitting**).
* Gli **errori di varianza** sono causati dal fatto che il modello approssima il rumore nei dati di input invece di una relazione significativa (**overfitting**).

Durante l‚Äôaddestramento, l‚Äôerrore di bias diminuisce (man mano che il modello impara ad approssimare i dati), mentre l‚Äôerrore di varianza aumenta. √à importante fermare l‚Äôaddestramento - manualmente (quando si rileva l‚Äôoverfitting) o automaticamente (introducendo regolarizzazione) - per evitare l‚Äôoverfitting.

## Conclusione

In questa lezione hai imparato le differenze tra le varie API dei due framework AI pi√π popolari, TensorFlow e PyTorch. Inoltre, hai appreso un argomento molto importante: l‚Äôoverfitting.

## üöÄ Sfida

Nei notebook allegati troverai delle ‚Äòtask‚Äô in fondo; lavora sui notebook e completa le attivit√†.

## Revisione e Studio Autonomo

Fai qualche ricerca sui seguenti argomenti:

- TensorFlow
- PyTorch
- Overfitting

Poniti le seguenti domande:

- Qual √® la differenza tra TensorFlow e PyTorch?
- Qual √® la differenza tra overfitting e underfitting?

## Compito

In questo laboratorio ti viene chiesto di risolvere due problemi di classificazione usando reti completamente connesse a singolo e multi-strato, utilizzando PyTorch o TensorFlow.

**Disclaimer**:  
Questo documento √® stato tradotto utilizzando il servizio di traduzione automatica [Co-op Translator](https://github.com/Azure/co-op-translator). Pur impegnandoci per garantire accuratezza, si prega di notare che le traduzioni automatiche possono contenere errori o imprecisioni. Il documento originale nella sua lingua nativa deve essere considerato la fonte autorevole. Per informazioni critiche, si raccomanda una traduzione professionale effettuata da un umano. Non ci assumiamo alcuna responsabilit√† per eventuali malintesi o interpretazioni errate derivanti dall‚Äôuso di questa traduzione.