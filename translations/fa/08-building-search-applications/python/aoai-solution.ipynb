{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای اجرای نوت‌بوک‌های زیر، اگر هنوز انجام نداده‌اید، باید مدلی را که از `text-embedding-ada-002` به عنوان مدل پایه استفاده می‌کند، مستقر کنید و نام استقرار را در فایل .env به عنوان `AZURE_OPENAI_EMBEDDINGS_ENDPOINT` تنظیم کنید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در مرحله بعد، قصد داریم شاخص جاسازی را در یک دیتافریم پاندا بارگذاری کنیم. شاخص جاسازی در یک فایل JSON به نام `embedding_index_3m.json` ذخیره شده است. شاخص جاسازی شامل جاسازی‌ها برای هر یک از متن‌های یوتیوب تا اواخر اکتبر ۲۰۲۳ می‌باشد.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در مرحله بعد، ما قصد داریم تابعی به نام `get_videos` ایجاد کنیم که در شاخص جاسازی (Embedding Index) به دنبال پرس‌وجو جستجو می‌کند. این تابع ۵ ویدیوی برتر که بیشترین شباهت را به پرس‌وجو دارند، بازمی‌گرداند. عملکرد تابع به شرح زیر است:\n",
    "\n",
    "1. ابتدا یک نسخه کپی از شاخص جاسازی ایجاد می‌شود.\n",
    "2. سپس، جاسازی پرس‌وجو با استفاده از API جاسازی OpenAI محاسبه می‌شود.\n",
    "3. سپس یک ستون جدید به نام `similarity` در شاخص جاسازی ایجاد می‌شود. ستون `similarity` شامل شباهت کسینوسی بین جاسازی پرس‌وجو و جاسازی هر بخش ویدیو است.\n",
    "4. سپس شاخص جاسازی بر اساس ستون `similarity` فیلتر می‌شود. شاخص جاسازی به گونه‌ای فیلتر می‌شود که فقط ویدیوهایی که شباهت کسینوسی آنها برابر یا بیشتر از ۰.۷۵ است، شامل شوند.\n",
    "5. در نهایت، شاخص جاسازی بر اساس ستون `similarity` مرتب شده و ۵ ویدیوی برتر بازگردانده می‌شوند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این تابع بسیار ساده است، فقط نتایج جستجو را چاپ می‌کند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ابتدا، شاخص جاسازی شده در یک دیتافریم Pandas بارگذاری می‌شود.\n",
    "2. سپس از کاربر خواسته می‌شود تا یک پرس‌وجو وارد کند.\n",
    "3. سپس تابع `get_videos` برای جستجو در شاخص جاسازی شده بر اساس پرس‌وجو فراخوانی می‌شود.\n",
    "4. در نهایت، تابع `display_results` برای نمایش نتایج به کاربر فراخوانی می‌شود.\n",
    "5. سپس از کاربر خواسته می‌شود تا پرس‌وجوی دیگری وارد کند. این روند تا زمانی که کاربر `exit` را وارد کند ادامه می‌یابد.\n",
    "\n",
    "![](../../../../translated_images/fa/notebook-search.1e320b9c7fcbb0bc.webp)\n",
    "\n",
    "از شما خواسته می‌شود تا یک پرس‌وجو وارد کنید. یک پرس‌وجو وارد کرده و کلید اینتر را فشار دهید. برنامه فهرستی از ویدیوهای مرتبط با پرس‌وجو را بازمی‌گرداند. همچنین برنامه لینکی به محل پاسخ سوال در ویدیو ارائه می‌دهد.\n",
    "\n",
    "در اینجا چند پرس‌وجو برای امتحان کردن آمده است:\n",
    "\n",
    "- Azure Machine Learning چیست؟\n",
    "- شبکه‌های عصبی کانولوشنی چگونه کار می‌کنند؟\n",
    "- شبکه عصبی چیست؟\n",
    "- آیا می‌توانم از Jupyter Notebooks با Azure Machine Learning استفاده کنم؟\n",
    "- ONNX چیست؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما در تلاش برای دقت هستیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نواقصی باشند. سند اصلی به زبان بومی خود باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئول هیچ گونه سوءتفاهم یا تفسیر نادرستی که از استفاده این ترجمه ناشی شود، نیستیم.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "ff5415e24294df268ec7e7a2b12af509",
   "translation_date": "2025-12-19T08:56:22+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}