{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "برای اجرای نوت‌بوک‌های زیر، اگر تا کنون این کار را نکرده‌اید، باید کلید openai را به عنوان `OPENAI_API_KEY` در فایل .env قرار دهید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در مرحله بعد، قصد داریم ایندکس تعبیه را در یک دیتافریم پانداس بارگذاری کنیم. ایندکس تعبیه در یک فایل JSON به نام `embedding_index_3m.json` ذخیره شده است. ایندکس تعبیه شامل تعبیه‌ها برای هر یک از رونوشت‌های یوتیوب تا اواخر اکتبر ۲۰۲۳ است.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "در ادامه، قصد داریم تابعی به نام `get_videos` بسازیم که در ایندکس تعبیه (Embedding Index) به دنبال پرس‌وجو (query) جستجو می‌کند. این تابع، ۵ ویدیویی که بیشترین شباهت را به پرس‌وجو دارند، برمی‌گرداند. عملکرد این تابع به این صورت است:\n",
    "\n",
    "1. ابتدا یک کپی از ایندکس تعبیه ساخته می‌شود.\n",
    "2. سپس تعبیه (Embedding) مربوط به پرس‌وجو با استفاده از OpenAI Embedding API محاسبه می‌شود.\n",
    "3. بعد، یک ستون جدید به نام `similarity` در ایندکس تعبیه ایجاد می‌شود. ستون `similarity` شامل میزان شباهت کسینوسی بین تعبیه پرس‌وجو و تعبیه هر بخش از ویدیو است.\n",
    "4. سپس ایندکس تعبیه بر اساس ستون `similarity` فیلتر می‌شود. فقط ویدیوهایی که شباهت کسینوسی آن‌ها برابر یا بیشتر از ۰.۷۵ باشد، نگه داشته می‌شوند.\n",
    "5. در نهایت، ایندکس تعبیه بر اساس ستون `similarity` مرتب شده و ۵ ویدیوی برتر بازگردانده می‌شود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "این تابع بسیار ساده است، فقط نتایج جستجو را چاپ می‌کند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "۱. ابتدا ایندکس تعبیه‌سازی در یک دیتافریم پانداس بارگذاری می‌شود.\n",
    "۲. سپس از کاربر خواسته می‌شود یک پرس‌وجو وارد کند.\n",
    "۳. بعد تابع `get_videos` فراخوانی می‌شود تا ایندکس تعبیه‌سازی را برای پرس‌وجو جستجو کند.\n",
    "۴. در نهایت، تابع `display_results` فراخوانی می‌شود تا نتایج را به کاربر نمایش دهد.\n",
    "۵. سپس دوباره از کاربر خواسته می‌شود یک پرس‌وجوی دیگر وارد کند. این روند ادامه پیدا می‌کند تا زمانی که کاربر عبارت `exit` را وارد کند.\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.fa.png)\n",
    "\n",
    "از شما خواسته می‌شود یک پرس‌وجو وارد کنید. یک پرس‌وجو وارد کنید و اینتر بزنید. برنامه فهرستی از ویدیوهای مرتبط با پرس‌وجوی شما را نمایش می‌دهد. همچنین لینکی به بخشی از ویدیو که پاسخ سؤال شما در آن قرار دارد ارائه می‌شود.\n",
    "\n",
    "در اینجا چند نمونه پرس‌وجو برای امتحان کردن آورده شده است:\n",
    "\n",
    "- Azure Machine Learning چیست؟\n",
    "- شبکه‌های عصبی کانولوشنی چگونه کار می‌کنند؟\n",
    "- شبکه عصبی چیست؟\n",
    "- آیا می‌توانم از Jupyter Notebooks با Azure Machine Learning استفاده کنم؟\n",
    "- ONNX چیست؟\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطا یا نادقتی باشند. نسخه اصلی سند به زبان مادری آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "2c0494ceb4f5fc618a6abda0b5c09c73",
   "translation_date": "2025-08-25T18:54:05+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}