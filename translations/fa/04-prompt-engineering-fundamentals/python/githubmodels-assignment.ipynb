{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# مقدمه‌ای بر مهندسی پرامپت\n",
    "مهندسی پرامپت فرآیند طراحی و بهینه‌سازی پرامپت‌ها برای وظایف پردازش زبان طبیعی است. این کار شامل انتخاب پرامپت‌های مناسب، تنظیم پارامترهای آن‌ها و ارزیابی عملکردشان می‌شود. مهندسی پرامپت برای دستیابی به دقت و کارایی بالا در مدل‌های NLP اهمیت زیادی دارد. در این بخش، با اصول اولیه مهندسی پرامپت آشنا می‌شویم و از مدل‌های OpenAI برای بررسی بیشتر استفاده خواهیم کرد.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تمرین ۱: توکنیزاسیون\n",
    "با استفاده از tiktoken، یک توکنایزر سریع و متن‌باز از OpenAI، با مفهوم توکنیزاسیون آشنا شوید.\n",
    "برای مثال‌های بیشتر به [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) مراجعه کنید.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تمرین ۲: اعتبارسنجی تنظیم کلید Github Models\n",
    "\n",
    "کد زیر را اجرا کنید تا مطمئن شوید نقطه پایان Github Models شما به درستی تنظیم شده است. این کد فقط یک پرامپت ساده را امتحان می‌کند و نتیجه را بررسی می‌کند. ورودی `oh say can you see` باید با چیزی شبیه به `by the dawn's early light..` کامل شود.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "That line is the opening lyric of \"The Star-Spangled Banner,\" the national anthem of the United States, written by Francis Scott Key. If you'd like more information or analysis, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "def get_completion(prompt, client, model_name, temperature=1.0, max_tokens=1000, top_p=1.0):\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "        top_p=top_p\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تمرین ۳: جعل واقعیت‌ها  \n",
    "بررسی کنید چه اتفاقی می‌افتد وقتی از مدل زبانی می‌خواهید برای یک موضوعی که شاید وجود خارجی نداشته باشد یا موضوعاتی که مدل به خاطر خارج بودن از داده‌های پیش‌فرضش (مثلاً موضوعات جدیدتر) درباره‌شان اطلاعاتی ندارد، پاسخ تولید کند. ببینید اگر پرسش خود را تغییر دهید یا از مدل دیگری استفاده کنید، پاسخ چگونه تغییر می‌کند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تمرین ۴: مبتنی بر دستورالعمل  \n",
    "از متغیر \"text\" برای تعیین محتوای اصلی استفاده کنید  \n",
    "و از متغیر \"prompt\" برای ارائه یک دستور مرتبط با آن محتوای اصلی بهره ببرید.\n",
    "\n",
    "در اینجا از مدل می‌خواهیم متن را برای یک دانش‌آموز کلاس دوم خلاصه کند\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupiter is the fifth planet from the Sun and the biggest one in our Solar System. It's made of gas and is much bigger than all the other planets put together! You can see Jupiter in the night sky because it's very bright. People have noticed it for a really long time and named it after a Roman god.\n"
     ]
    }
   ],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt, client, model_name)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تمرین ۵: درخواست پیچیده  \n",
    "یک درخواست امتحان کنید که شامل پیام‌های system، user و assistant باشد  \n",
    "system زمینه دستیار را مشخص می‌کند  \n",
    "پیام‌های user و assistant زمینه مکالمه چندمرحله‌ای را فراهم می‌کنند\n",
    "\n",
    "توجه کنید که شخصیت دستیار در زمینه system به صورت \"طعنه‌آمیز\" تنظیم شده است.  \n",
    "می‌توانید زمینه شخصیتی متفاوتی امتحان کنید. یا یک سری پیام ورودی/خروجی متفاوت را امتحان کنید\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, you mean the famous 2020 World Series that wasn’t in a regular location? That was the year they played in the glamorous Arlington, Texas, at Globe Life Field.\n"
     ]
    }
   ],
   "source": [
    "response = client.complete(\n",
    "    model=model_name,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### تمرین: شهود خود را کشف کنید\n",
    "مثال‌های بالا الگوهایی را به شما نشان می‌دهند که می‌توانید برای ساختن پرامپت‌های جدید (ساده، پیچیده، دستوری و غیره) از آن‌ها استفاده کنید - سعی کنید تمرین‌های دیگری بسازید تا برخی از ایده‌هایی که درباره‌شان صحبت کردیم مثل مثال‌ها، نشانه‌ها و موارد دیگر را بیشتر بررسی کنید.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطا یا نادقتی باشند. نسخه اصلی سند به زبان مادری آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai4beg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "40586ff9e0ba4574f88e59700b9a0088",
   "translation_date": "2025-08-25T13:19:36+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/githubmodels-assignment.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}