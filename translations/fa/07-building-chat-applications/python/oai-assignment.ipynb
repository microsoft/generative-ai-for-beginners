{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# فصل ۷: ساخت برنامه‌های چت\n",
    "## شروع سریع با API اوپن‌ای‌آی\n",
    "\n",
    "این دفترچه از [مخزن نمونه‌های Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) گرفته شده است که شامل دفترچه‌هایی برای دسترسی به سرویس‌های [Azure OpenAI](notebook-azure-openai.ipynb) می‌باشد.\n",
    "\n",
    "API پایتون اوپن‌ای‌آی با مدل‌های Azure OpenAI نیز کار می‌کند، فقط با چند تغییر کوچک. برای اطلاعات بیشتر درباره تفاوت‌ها اینجا را ببینید: [چگونه بین نقطه‌های پایانی OpenAI و Azure OpenAI با پایتون جابجا شویم](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مروری کلی  \n",
    "«مدل‌های زبانی بزرگ توابعی هستند که متن را به متن نگاشت می‌کنند. وقتی یک رشته متنی به عنوان ورودی داده می‌شود، مدل زبانی بزرگ سعی می‌کند متنی را که قرار است بعد از آن بیاید پیش‌بینی کند»(1). این دفترچه «شروع سریع» کاربران را با مفاهیم سطح بالای LLM، نیازمندی‌های اصلی بسته برای شروع کار با AML، مقدمه‌ای ساده بر طراحی پرامپت و چند مثال کوتاه از کاربردهای مختلف آشنا می‌کند.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## فهرست مطالب  \n",
    "\n",
    "[مرور کلی](../../../../07-building-chat-applications/python)  \n",
    "[نحوه استفاده از سرویس OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[۱. ساخت سرویس OpenAI خودتان](../../../../07-building-chat-applications/python)  \n",
    "[۲. نصب](../../../../07-building-chat-applications/python)    \n",
    "[۳. اطلاعات ورود](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[موارد استفاده](../../../../07-building-chat-applications/python)    \n",
    "[۱. خلاصه‌سازی متن](../../../../07-building-chat-applications/python)  \n",
    "[۲. دسته‌بندی متن](../../../../07-building-chat-applications/python)  \n",
    "[۳. تولید نام‌های جدید برای محصولات](../../../../07-building-chat-applications/python)  \n",
    "[۴. بهبود یک دسته‌بند](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[مراجع](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### اولین پرامپت خود را بسازید  \n",
    "این تمرین کوتاه، مقدمه‌ای ساده برای ارسال پرامپت به یک مدل OpenAI برای انجام یک کار ساده مثل \"خلاصه‌سازی\" ارائه می‌دهد.\n",
    "\n",
    "**مراحل:**  \n",
    "1. کتابخانه OpenAI را در محیط پایتون خود نصب کنید  \n",
    "2. کتابخانه‌های کمکی استاندارد را بارگذاری کرده و اطلاعات امنیتی معمول OpenAI را برای سرویسی که ساخته‌اید تنظیم کنید  \n",
    "3. یک مدل مناسب برای کار خود انتخاب کنید  \n",
    "4. یک پرامپت ساده برای مدل بنویسید  \n",
    "5. درخواست خود را به API مدل ارسال کنید!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۱. نصب OpenAI\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۲. وارد کردن کتابخانه‌های کمکی و ایجاد اعتبارنامه‌ها\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۳. پیدا کردن مدل مناسب  \n",
    "مدل‌های GPT-3.5-turbo یا GPT-4 می‌توانند زبان طبیعی را درک کرده و تولید کنند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ۴. طراحی پرامپت\n",
    "\n",
    "«جادوی مدل‌های زبانی بزرگ این است که با آموزش دیدن برای کمینه کردن خطای پیش‌بینی روی حجم عظیمی از متن، این مدل‌ها در نهایت مفاهیمی را یاد می‌گیرند که برای این پیش‌بینی‌ها مفید هستند. برای مثال، آن‌ها مفاهیمی مانند»(۱):\n",
    "\n",
    "* چگونه املای کلمات را بنویسند\n",
    "* قواعد گرامری چگونه کار می‌کند\n",
    "* چطور پارافرایز کنند\n",
    "* چطور به سوالات پاسخ دهند\n",
    "* چطور یک مکالمه را پیش ببرند\n",
    "* چطور به زبان‌های مختلف بنویسند\n",
    "* چطور کدنویسی کنند\n",
    "* و غیره\n",
    "\n",
    "#### چگونه یک مدل زبانی بزرگ را کنترل کنیم\n",
    "«در میان تمام ورودی‌های یک مدل زبانی بزرگ، بدون شک تاثیرگذارترین آن، متن پرامپت است»(۱).\n",
    "\n",
    "مدل‌های زبانی بزرگ را می‌توان به چند روش برای تولید خروجی هدایت کرد:\n",
    "\n",
    "دستورالعمل: به مدل بگویید چه می‌خواهید  \n",
    "تکمیل: مدل را وادار کنید تا ابتدای چیزی که می‌خواهید را کامل کند  \n",
    "نمایش: به مدل نشان دهید چه می‌خواهید، با یکی از این دو روش:  \n",
    "چند مثال در پرامپت  \n",
    "صدها یا هزاران مثال در یک دیتاست آموزش فاین‌تیون شده\n",
    "\n",
    "#### سه راهنمای اصلی برای ساخت پرامپت وجود دارد:\n",
    "\n",
    "**نشان بدهید و توضیح دهید.** به وضوح مشخص کنید چه می‌خواهید، چه از طریق دستورالعمل، چه با مثال، یا ترکیبی از هر دو. اگر می‌خواهید مدل یک لیست را به ترتیب حروف الفبا مرتب کند یا یک پاراگراف را بر اساس احساسات دسته‌بندی کند، به آن نشان دهید که دقیقا همین را می‌خواهید.\n",
    "\n",
    "**داده باکیفیت ارائه دهید.** اگر می‌خواهید یک دسته‌بند بسازید یا مدل را وادار کنید از یک الگو پیروی کند، مطمئن شوید که مثال‌های کافی دارید. حتما مثال‌های خود را بازبینی کنید — مدل معمولا به اندازه کافی باهوش است که اشتباهات ساده املایی را تشخیص دهد و به شما پاسخ دهد، اما ممکن است فرض کند این اشتباهات عمدی هستند و این می‌تواند روی پاسخ تاثیر بگذارد.\n",
    "\n",
    "**تنظیمات خود را بررسی کنید.** تنظیمات temperature و top_p تعیین می‌کنند که مدل تا چه حد در تولید پاسخ قطعی عمل کند. اگر از مدل پاسخی می‌خواهید که فقط یک جواب درست دارد، بهتر است این مقادیر را پایین بگذارید. اگر به دنبال پاسخ‌های متنوع‌تر هستید، می‌توانید آن‌ها را بالاتر تنظیم کنید. رایج‌ترین اشتباه افراد در این تنظیمات این است که فکر می‌کنند این‌ها کنترل‌کننده «باهوشی» یا «خلاقیت» مدل هستند.\n",
    "\n",
    "منبع: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## خلاصه کردن متن  \n",
    "#### چالش  \n",
    "متن را با اضافه کردن «tl;dr:» در انتهای آن خلاصه کنید. توجه کنید که مدل چطور می‌تواند بدون دستورالعمل اضافی، چندین کار مختلف را انجام دهد. می‌توانید با استفاده از درخواست‌های توصیفی‌تر به جای tl;dr، رفتار مدل را تغییر دهید و خلاصه‌ای متناسب با نیازتان دریافت کنید(۳).\n",
    "\n",
    "تحقیقات اخیر نشان داده‌اند که پیش‌آموزش روی مجموعه بزرگی از متون و سپس تنظیم دقیق روی یک وظیفه خاص، پیشرفت چشمگیری در بسیاری از وظایف و معیارهای NLP ایجاد کرده است. اگرچه معماری این روش معمولاً مستقل از وظیفه است، اما همچنان به مجموعه داده‌های تنظیم دقیق وابسته به وظیفه با هزاران یا ده‌ها هزار نمونه نیاز دارد. در مقابل، انسان‌ها معمولاً می‌توانند یک وظیفه زبانی جدید را تنها با چند مثال یا دستورالعمل ساده انجام دهند؛ کاری که سیستم‌های فعلی NLP هنوز تا حد زیادی با آن مشکل دارند. در اینجا نشان می‌دهیم که افزایش مقیاس مدل‌های زبانی، عملکرد مستقل از وظیفه و چندنمونه‌ای را به طور قابل توجهی بهبود می‌بخشد و گاهی حتی با روش‌های تنظیم دقیق پیشرفته قبلی رقابت می‌کند.\n",
    "\n",
    "\n",
    "\n",
    "tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# تمرین‌ها برای چندین مورد استفاده  \n",
    "1. خلاصه کردن متن  \n",
    "2. دسته‌بندی متن  \n",
    "3. تولید نام‌های جدید برای محصولات\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## دسته‌بندی متن  \n",
    "#### چالش  \n",
    "موارد را بر اساس دسته‌هایی که هنگام استنتاج ارائه می‌شوند، دسته‌بندی کنید. در مثال زیر، هم دسته‌ها و هم متنی که باید دسته‌بندی شود را در پرامپت قرار داده‌ایم (*playground_reference).\n",
    "\n",
    "سؤال مشتری: سلام، یکی از کلیدهای کیبورد لپ‌تاپ من اخیراً خراب شده و نیاز به تعویض دارم:\n",
    "\n",
    "دسته‌بندی شده:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## تولید نام‌های جدید برای محصولات\n",
    "#### چالش\n",
    "نام‌هایی برای محصولات با استفاده از کلمات نمونه بسازید. در اینجا، اطلاعاتی درباره محصولی که قرار است برای آن نام تولید کنیم، در متن قرار داده‌ایم. همچنین یک مثال مشابه ارائه شده تا الگوی مورد نظر را نشان دهیم. مقدار دما را نیز بالا تنظیم کرده‌ایم تا پاسخ‌ها خلاقانه‌تر و متنوع‌تر باشند.\n",
    "\n",
    "توضیح محصول: دستگاه تهیه میلک‌شیک خانگی  \n",
    "کلمات کلیدی: سریع، سالم، جمع‌وجور  \n",
    "نام‌های محصول: هوم‌شیکر، فیت‌شیکر، کوئیک‌شیک، شیک‌میکر\n",
    "\n",
    "توضیح محصول: یک جفت کفش که برای هر سایز پایی مناسب است.  \n",
    "کلمات کلیدی: سازگار، فیت، اومنی‌فیت.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# منابع  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [نمونه‌های OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [بهترین روش‌ها برای تنظیم دقیق GPT-3 جهت دسته‌بندی متن](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# برای کمک بیشتر  \n",
    "[تیم تجاری‌سازی OpenAI](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مشارکت‌کنندگان\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:\nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطا یا نادقتی باشند. نسخه اصلی سند به زبان مادری آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:02:41+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}