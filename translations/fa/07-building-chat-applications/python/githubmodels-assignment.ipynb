{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# فصل ۷: ساخت برنامه‌های چت\n",
    "## شروع سریع API مدل‌های گیت‌هاب\n",
    "\n",
    "این دفترچه از [مخزن نمونه‌های Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) گرفته شده است که شامل دفترچه‌هایی برای دسترسی به سرویس‌های [Azure OpenAI](notebook-azure-openai.ipynb) می‌باشد.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مروری کلی  \n",
    "«مدل‌های زبانی بزرگ توابعی هستند که متن را به متن نگاشت می‌کنند. وقتی یک رشته متنی به عنوان ورودی داده می‌شود، مدل زبانی بزرگ سعی می‌کند متنی را که قرار است بعد از آن بیاید پیش‌بینی کند»(1). این دفترچه «شروع سریع» کاربران را با مفاهیم سطح بالای LLM، نیازمندی‌های اصلی بسته برای شروع کار با AML، مقدمه‌ای ساده بر طراحی پرامپت و چند مثال کوتاه از کاربردهای مختلف آشنا می‌کند.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## فهرست مطالب  \n",
    "\n",
    "[مروری کلی](../../../../07-building-chat-applications/python)  \n",
    "[نحوه استفاده از سرویس OpenAI](../../../../07-building-chat-applications/python)  \n",
    "[۱. ساخت سرویس OpenAI خودتان](../../../../07-building-chat-applications/python)  \n",
    "[۲. نصب](../../../../07-building-chat-applications/python)    \n",
    "[۳. اطلاعات ورود](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[موارد استفاده](../../../../07-building-chat-applications/python)    \n",
    "[۱. خلاصه‌کردن متن](../../../../07-building-chat-applications/python)  \n",
    "[۲. دسته‌بندی متن](../../../../07-building-chat-applications/python)  \n",
    "[۳. تولید نام‌های جدید برای محصول](../../../../07-building-chat-applications/python)  \n",
    "[۴. آموزش دقیق‌تر یک دسته‌بند](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[منابع](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### اولین پرامپت خود را بسازید  \n",
    "این تمرین کوتاه، مقدمه‌ای ساده برای ارسال پرامپت به یک مدل در Github Models برای یک کار ساده مثل \"خلاصه‌سازی\" ارائه می‌دهد.\n",
    "\n",
    "**مراحل**:  \n",
    "۱. اگر هنوز انجام نداده‌اید، کتابخانه `azure-ai-inference` را در محیط پایتون خود نصب کنید.  \n",
    "۲. کتابخانه‌های کمکی استاندارد را بارگذاری کرده و اعتبارنامه Github Models را تنظیم کنید.  \n",
    "۳. یک مدل مناسب برای کار خود انتخاب کنید  \n",
    "۴. یک پرامپت ساده برای مدل بسازید  \n",
    "۵. درخواست خود را به API مدل ارسال کنید!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۱. نصب `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۲. وارد کردن کتابخانه‌های کمکی و ایجاد اعتبارنامه‌ها\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### ۳. پیدا کردن مدل مناسب  \n",
    "مدل‌های GPT-3.5-turbo یا GPT-4 می‌توانند زبان طبیعی را درک کرده و تولید کنند.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## ۴. طراحی پرامپت  \n",
    "\n",
    "«جادوی مدل‌های زبانی بزرگ این است که با آموزش دیدن برای کمینه کردن خطای پیش‌بینی روی حجم عظیمی از متن، این مدل‌ها در نهایت مفاهیمی را یاد می‌گیرند که برای این پیش‌بینی‌ها مفید هستند. برای مثال، آن‌ها مفاهیمی مانند»(۱):\n",
    "\n",
    "* چگونه املای کلمات را بنویسند\n",
    "* قواعد گرامری چگونه کار می‌کند\n",
    "* چطور پارافرایز کنند\n",
    "* چطور به سوالات پاسخ دهند\n",
    "* چطور یک مکالمه را پیش ببرند\n",
    "* چطور به زبان‌های مختلف بنویسند\n",
    "* چطور کدنویسی کنند\n",
    "* و غیره\n",
    "\n",
    "#### چگونه یک مدل زبانی بزرگ را کنترل کنیم  \n",
    "«در میان تمام ورودی‌های یک مدل زبانی بزرگ، بدون شک تاثیرگذارترین آن‌ها، متن پرامپت است»(۱).\n",
    "\n",
    "مدل‌های زبانی بزرگ را می‌توان به چند روش برای تولید خروجی هدایت کرد:\n",
    "\n",
    "دستورالعمل: به مدل بگویید چه می‌خواهید  \n",
    "تکمیل: مدل را وادار کنید تا ابتدای چیزی که می‌خواهید را کامل کند  \n",
    "نمایش: به مدل نشان دهید چه می‌خواهید، با یکی از این دو روش:  \n",
    "چند مثال در پرامپت  \n",
    "صدها یا هزاران مثال در یک دیتاست آموزش فاین‌تیون شده»\n",
    "\n",
    "\n",
    "#### سه راهنمای اصلی برای ساخت پرامپت وجود دارد:\n",
    "\n",
    "**نشان بدهید و توضیح دهید.** به وضوح مشخص کنید چه می‌خواهید؛ چه با دستورالعمل، چه با مثال، یا ترکیبی از هر دو. اگر می‌خواهید مدل یک لیست را به ترتیب حروف الفبا مرتب کند یا یک پاراگراف را بر اساس احساس دسته‌بندی کند، به آن نشان دهید که دقیقا همین را می‌خواهید.\n",
    "\n",
    "**داده باکیفیت ارائه دهید.** اگر می‌خواهید یک دسته‌بند بسازید یا مدل را وادار کنید از یک الگو پیروی کند، مطمئن شوید که مثال‌های کافی دارید. حتما مثال‌های خود را بازبینی کنید — مدل معمولا آنقدر باهوش هست که اشتباهات ساده املایی را تشخیص دهد و به شما پاسخ دهد، اما ممکن است فرض کند این اشتباهات عمدی هستند و این می‌تواند روی پاسخ تاثیر بگذارد.\n",
    "\n",
    "**تنظیمات خود را بررسی کنید.** تنظیمات temperature و top_p تعیین می‌کنند که مدل تا چه حد در تولید پاسخ قطعی عمل کند. اگر از مدل پاسخی می‌خواهید که فقط یک جواب درست دارد، بهتر است این مقادیر را پایین بگذارید. اگر به دنبال پاسخ‌های متنوع‌تر هستید، می‌توانید آن‌ها را بالاتر تنظیم کنید. رایج‌ترین اشتباه افراد با این تنظیمات این است که فکر می‌کنند این‌ها کنترل‌کننده «باهوشی» یا «خلاقیت» مدل هستند.\n",
    "\n",
    "\n",
    "منبع: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## خلاصه کردن متن  \n",
    "#### چالش  \n",
    "متن را با اضافه کردن «tl;dr:» در انتهای آن خلاصه کنید. توجه کنید که مدل چطور بدون هیچ دستور اضافه‌ای می‌تواند چندین کار مختلف را انجام دهد. می‌توانید با استفاده از درخواست‌های توصیفی‌تر به جای tl;dr، رفتار مدل را تغییر دهید و خلاصه‌ای که دریافت می‌کنید را شخصی‌سازی کنید(3).\n",
    "\n",
    "تحقیقات اخیر نشان داده‌اند که پیش‌آموزش روی حجم بزرگی از متن و سپس تنظیم دقیق روی یک وظیفه خاص، پیشرفت چشمگیری در بسیاری از وظایف و معیارهای NLP ایجاد کرده است. اگرچه معماری این روش معمولاً مستقل از وظیفه است، اما همچنان به داده‌های تنظیم دقیق مخصوص هر وظیفه با هزاران یا ده‌ها هزار نمونه نیاز دارد. در مقابل، انسان‌ها معمولاً می‌توانند یک وظیفه زبانی جدید را تنها با چند مثال یا دستور ساده انجام دهند؛ چیزی که سیستم‌های NLP فعلی هنوز تا حد زیادی با آن مشکل دارند. در اینجا نشان می‌دهیم که بزرگ‌تر کردن مدل‌های زبانی، عملکرد مستقل از وظیفه و چندنمونه‌ای را به طور قابل توجهی بهبود می‌بخشد و گاهی حتی با روش‌های تنظیم دقیق پیشرفته قبلی رقابت می‌کند.\n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# تمرین‌ها برای چندین مورد استفاده  \n",
    "1. خلاصه کردن متن  \n",
    "2. دسته‌بندی متن  \n",
    "3. تولید نام‌های جدید برای محصولات\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## دسته‌بندی متن  \n",
    "#### چالش  \n",
    "موارد را بر اساس دسته‌هایی که هنگام استنتاج ارائه می‌شوند، دسته‌بندی کنید. در مثال زیر، هم دسته‌ها و هم متنی که باید دسته‌بندی شود را در پرامپت قرار داده‌ایم (*playground_reference).\n",
    "\n",
    "سؤال مشتری: سلام، یکی از کلیدهای کیبورد لپ‌تاپ من اخیراً خراب شده و نیاز به تعویض دارم:\n",
    "\n",
    "دسته‌بندی شده:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## تولید نام‌های جدید برای محصولات\n",
    "#### چالش\n",
    "نام‌هایی برای محصولات با استفاده از کلمات نمونه بسازید. در اینجا، اطلاعاتی درباره محصولی که قرار است برای آن نام تولید کنیم، در متن قرار داده‌ایم. همچنین یک مثال مشابه ارائه شده تا الگوی مورد انتظار را نشان دهیم. مقدار دما (temperature) را نیز بالا تنظیم کرده‌ایم تا پاسخ‌ها خلاقانه‌تر و متنوع‌تر باشند.\n",
    "\n",
    "توضیح محصول: دستگاه تهیه میلک‌شیک خانگی  \n",
    "کلمات کلیدی: سریع، سالم، جمع‌وجور  \n",
    "نام‌های محصول: هوم‌شیکر، فیت‌شیکر، کوئیک‌شیک، شیک‌میکر\n",
    "\n",
    "توضیح محصول: یک جفت کفش که برای هر سایز پایی مناسب است.  \n",
    "کلمات کلیدی: قابل‌انطباق، فیت، اومنی‌فیت.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# منابع  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [نمونه‌های OpenAI Studio](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [بهترین روش‌ها برای تنظیم دقیق GPT-3 جهت طبقه‌بندی متن](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# برای کمک بیشتر  \n",
    "[تیم تجاری‌سازی OpenAI](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# مشارکت‌کنندگان\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:\nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطا یا نادقتی باشند. نسخه اصلی سند به زبان مادری آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:23:02+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}