{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ساخت یک اپلیکیشن تولید تصویر\n",
    "\n",
    "مدل‌های زبانی بزرگ فقط برای تولید متن نیستند. امکان تولید تصویر از توضیحات متنی هم وجود دارد. داشتن تصاویر به عنوان یک مدالیته می‌تواند در حوزه‌های مختلفی مثل فناوری پزشکی، معماری، گردشگری، توسعه بازی و غیره بسیار مفید باشد. در این فصل، به دو مدل محبوب تولید تصویر یعنی DALL-E و Midjourney می‌پردازیم.\n",
    "\n",
    "## مقدمه\n",
    "\n",
    "در این درس، موارد زیر را بررسی خواهیم کرد:\n",
    "\n",
    "- تولید تصویر و دلایل مفید بودن آن.\n",
    "- DALL-E و Midjourney، اینکه چه هستند و چگونه کار می‌کنند.\n",
    "- چطور می‌توانید یک اپلیکیشن تولید تصویر بسازید.\n",
    "\n",
    "## اهداف یادگیری\n",
    "\n",
    "پس از پایان این درس، قادر خواهید بود:\n",
    "\n",
    "- یک اپلیکیشن تولید تصویر بسازید.\n",
    "- با استفاده از متا پرامپت‌ها، مرزهای اپلیکیشن خود را مشخص کنید.\n",
    "- با DALL-E و Midjourney کار کنید.\n",
    "\n",
    "## چرا باید یک اپلیکیشن تولید تصویر بسازیم؟\n",
    "\n",
    "اپلیکیشن‌های تولید تصویر راهی عالی برای کشف قابلیت‌های هوش مصنوعی مولد هستند. این اپلیکیشن‌ها می‌توانند برای مثال در موارد زیر استفاده شوند:\n",
    "\n",
    "- **ویرایش و ترکیب تصویر**. می‌توانید برای کاربردهای مختلف مثل ویرایش تصویر یا ترکیب تصاویر، تصویر تولید کنید.\n",
    "\n",
    "- **قابل استفاده در صنایع مختلف**. همچنین می‌توانند برای تولید تصویر در صنایع مختلفی مثل فناوری پزشکی، گردشگری، توسعه بازی و غیره به کار روند.\n",
    "\n",
    "## سناریو: Edu4All\n",
    "\n",
    "در این درس، همچنان با استارتاپ خودمان، Edu4All، کار خواهیم کرد. دانش‌آموزان تصاویر مورد نیاز برای ارزیابی‌های خود را تولید می‌کنند. اینکه چه تصاویری بسازند به خودشان بستگی دارد؛ مثلاً می‌توانند برای داستان خود تصویرسازی کنند، شخصیت جدیدی برای داستانشان بسازند یا به کمک تصویر ایده‌ها و مفاهیم خود را تجسم کنند.\n",
    "\n",
    "برای مثال، اگر دانش‌آموزان Edu4All در کلاس درباره بناهای تاریخی کار می‌کنند، می‌توانند چنین تصویری تولید کنند:\n",
    "\n",
    "![استارتاپ Edu4All، کلاس درباره بناهای تاریخی، برج ایفل](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.fa.png)\n",
    "\n",
    "با استفاده از پرامپتی مثل\n",
    "\n",
    "> \"سگی کنار برج ایفل در نور آفتاب صبح زود\"\n",
    "\n",
    "## DALL-E و Midjourney چه هستند؟\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) و [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) دو تا از محبوب‌ترین مدل‌های تولید تصویر هستند که به شما اجازه می‌دهند با استفاده از پرامپت، تصویر بسازید.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "بیایید با DALL-E شروع کنیم؛ مدلی از هوش مصنوعی مولد که تصاویر را از توضیحات متنی تولید می‌کند.\n",
    "\n",
    "> [DALL-E ترکیبی از دو مدل CLIP و diffused attention است](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP**، مدلی است که embeddingها را تولید می‌کند؛ یعنی نمایش‌های عددی از داده‌ها را از تصاویر و متن استخراج می‌کند.\n",
    "\n",
    "- **Diffused attention**، مدلی است که از embeddingها تصویر تولید می‌کند. DALL-E روی مجموعه‌ای از تصاویر و متن آموزش دیده و می‌تواند از توضیحات متنی تصویر بسازد. مثلاً DALL-E می‌تواند تصویری از گربه‌ای با کلاه یا سگی با مدل موی موهاک بسازد.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney هم مشابه DALL-E کار می‌کند و تصاویر را از پرامپت‌های متنی تولید می‌کند. با Midjourney هم می‌توانید با پرامپت‌هایی مثل «گربه‌ای با کلاه» یا «سگی با مدل موی موهاک» تصویر بسازید.\n",
    "\n",
    "![تصویر تولید شده توسط Midjourney، کبوتر مکانیکی](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*اعتبار تصویر: ویکی‌پدیا، تصویر تولید شده توسط Midjourney*\n",
    "\n",
    "## DALL-E و Midjourney چگونه کار می‌کنند\n",
    "\n",
    "ابتدا [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E یک مدل هوش مصنوعی مولد مبتنی بر معماری ترنسفورمر با *ترنسفورمر خودبازگشتی* است.\n",
    "\n",
    "*ترنسفورمر خودبازگشتی* مشخص می‌کند که مدل چگونه تصویر را از توضیحات متنی تولید می‌کند؛ به این صورت که هر بار یک پیکسل را تولید می‌کند و سپس از پیکسل‌های تولید شده برای تولید پیکسل بعدی استفاده می‌کند. این فرایند از چندین لایه شبکه عصبی عبور می‌کند تا تصویر کامل شود.\n",
    "\n",
    "با این روش، DALL-E می‌تواند ویژگی‌ها، اشیا، خصوصیات و موارد دیگر را در تصویر تولید شده کنترل کند. البته DALL-E 2 و 3 کنترل بیشتری روی تصویر نهایی دارند،\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ساخت اولین برنامه تولید تصویر\n",
    "\n",
    "پس برای ساخت یک برنامه تولید تصویر به چه چیزهایی نیاز داریم؟ به کتابخانه‌های زیر احتیاج دارید:\n",
    "\n",
    "- **python-dotenv**، شدیداً توصیه می‌شود از این کتابخانه استفاده کنید تا اطلاعات محرمانه خود را در یک فایل *.env* جدا از کد نگه دارید.\n",
    "- **openai**، این کتابخانه برای ارتباط با API اوپن‌اِی‌آی استفاده می‌شود.\n",
    "- **pillow**، برای کار با تصاویر در پایتون.\n",
    "- **requests**، برای ارسال درخواست‌های HTTP به کار می‌رود.\n",
    "\n",
    "\n",
    "1. یک فایل به نام *.env* با محتوای زیر بسازید:\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "۱. کتابخانه‌های بالا را در فایلی به نام *requirements.txt* به این صورت جمع‌آوری کنید:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "۱. حالا یک محیط مجازی بسازید و کتابخانه‌ها را نصب کنید:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> برای ویندوز، از دستورات زیر برای ساخت و فعال‌سازی محیط مجازی خود استفاده کنید:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. کد زیر را در فایلی به نام *app.py* قرار دهید:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "بیایید این کد را توضیح دهیم:\n",
    "\n",
    "- ابتدا کتابخانه‌های مورد نیاز را وارد می‌کنیم، از جمله کتابخانه OpenAI، کتابخانه dotenv، کتابخانه requests و کتابخانه Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- بعد از آن، شیء مورد نظر را می‌سازیم که کلید API را از فایل ``.env`` شما دریافت می‌کند.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- سپس تصویر را تولید می‌کنیم:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    کد بالا یک شیء JSON برمی‌گرداند که شامل آدرس اینترنتی تصویر تولید شده است. می‌توانیم این آدرس را برای دانلود تصویر و ذخیره آن در یک فایل استفاده کنیم.\n",
    "\n",
    "- در نهایت، تصویر را باز می‌کنیم و با استفاده از نمایش‌دهنده استاندارد تصاویر، آن را نمایش می‌دهیم:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### جزئیات بیشتر درباره تولید تصویر\n",
    "\n",
    "بیایید کدی که تصویر را تولید می‌کند با جزئیات بیشتری بررسی کنیم:\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**، متنی است که برای تولید تصویر استفاده می‌شود. در این مثال، از متن \"خرگوش روی اسب، در حال نگه داشتن آب‌نبات چوبی، در دشتی مه‌آلود که نرگس در آن رشد می‌کند\" استفاده شده است.\n",
    "- **size**، اندازه تصویری است که تولید می‌شود. در این مثال، تصویری با ابعاد ۱۰۲۴ در ۱۰۲۴ پیکسل تولید می‌کنیم.\n",
    "- **n**، تعداد تصاویری است که تولید می‌شوند. در این مثال، دو تصویر تولید می‌کنیم.\n",
    "\n",
    "کارهای بیشتری هم می‌توانید با تصاویر انجام دهید که در بخش بعدی به آن‌ها می‌پردازیم.\n",
    "\n",
    "## قابلیت‌های بیشتر در تولید تصویر\n",
    "\n",
    "تا اینجا دیدید که چطور توانستیم تنها با چند خط کد در پایتون یک تصویر تولید کنیم. اما کارهای بیشتری هم می‌توانید با تصاویر انجام دهید.\n",
    "\n",
    "همچنین می‌توانید کارهای زیر را انجام دهید:\n",
    "\n",
    "- **ویرایش انجام دهید**. با ارائه یک تصویر موجود، یک ماسک و یک متن راهنما (prompt)، می‌توانید تصویر را تغییر دهید. مثلاً می‌توانید چیزی به بخشی از تصویر اضافه کنید. فرض کنید تصویر خرگوش را داریم، می‌توانید یک کلاه به خرگوش اضافه کنید. برای این کار باید تصویر، یک ماسک (که بخش مورد نظر برای تغییر را مشخص می‌کند) و یک متن راهنما برای توضیح تغییر مورد نظر را ارائه دهید.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    تصویر اولیه فقط خرگوش را دارد اما تصویر نهایی کلاه را روی سر خرگوش نشان می‌دهد.\n",
    "\n",
    "- **ساخت واریانت‌ها**. ایده این است که یک تصویر موجود را بردارید و بخواهید نسخه‌های متفاوتی از آن ساخته شود. برای ساخت یک واریانت، کافی است تصویر و یک متن راهنما را ارائه دهید و کد مشابه زیر را بنویسید:\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**سلب مسئولیت**:  \nاین سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما برای دقت تلاش می‌کنیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است شامل خطا یا نادرستی باشند. نسخه اصلی سند به زبان مادری آن باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حساس، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما هیچ مسئولیتی در قبال سوءتفاهم یا تفسیر نادرست ناشی از استفاده از این ترجمه نداریم.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:31:06+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "fa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}