<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df44972d5575ea8cef3c52ee31696d04",
  "translation_date": "2025-12-19T13:04:44+00:00",
  "source_file": "14-the-generative-ai-application-lifecycle/README.md",
  "language_code": "fa"
}
-->
[![ادغام با فراخوانی تابع](../../../translated_images/fa/14-lesson-banner.066d74a31727ac12.png)](https://youtu.be/ewtQY_RJrzs?si=dyJ2bjiljH7UUHCh)

# چرخه عمر برنامه‌های هوش مصنوعی مولد

یک سؤال مهم برای همه برنامه‌های هوش مصنوعی، مرتبط بودن ویژگی‌های هوش مصنوعی است، زیرا هوش مصنوعی حوزه‌ای است که به سرعت در حال تحول است، برای اطمینان از اینکه برنامه شما مرتبط، قابل اعتماد و مقاوم باقی می‌ماند، باید به طور مداوم آن را نظارت، ارزیابی و بهبود دهید. اینجاست که چرخه عمر هوش مصنوعی مولد وارد می‌شود.

چرخه عمر هوش مصنوعی مولد چارچوبی است که شما را در مراحل توسعه، استقرار و نگهداری یک برنامه هوش مصنوعی مولد راهنمایی می‌کند. این چارچوب به شما کمک می‌کند اهداف خود را تعریف کنید، عملکرد خود را اندازه‌گیری کنید، چالش‌های خود را شناسایی کنید و راه‌حل‌های خود را پیاده‌سازی کنید. همچنین به شما کمک می‌کند برنامه خود را با استانداردهای اخلاقی و قانونی حوزه و ذینفعان خود هماهنگ کنید. با پیروی از چرخه عمر هوش مصنوعی مولد، می‌توانید اطمینان حاصل کنید که برنامه شما همیشه ارزش ارائه می‌دهد و کاربران خود را راضی نگه می‌دارد.

## مقدمه

در این فصل، شما:

- درک تغییر پارادایم از MLOps به LLMOps
- چرخه عمر LLM
- ابزارهای چرخه عمر
- متریک‌سازی و ارزیابی چرخه عمر

## درک تغییر پارادایم از MLOps به LLMOps

مدل‌های زبان بزرگ (LLM) ابزار جدیدی در زرادخانه هوش مصنوعی هستند، آن‌ها در وظایف تحلیل و تولید برای برنامه‌ها بسیار قدرتمند هستند، اما این قدرت پیامدهایی در نحوه ساده‌سازی وظایف هوش مصنوعی و یادگیری ماشین کلاسیک دارد.

با این وجود، ما به یک پارادایم جدید نیاز داریم تا این ابزار را به صورت پویا و با انگیزه‌های صحیح تطبیق دهیم. می‌توانیم برنامه‌های قدیمی‌تر هوش مصنوعی را به عنوان "برنامه‌های ML" و برنامه‌های جدیدتر هوش مصنوعی را به عنوان "برنامه‌های GenAI" یا فقط "برنامه‌های AI" دسته‌بندی کنیم، که فناوری و تکنیک‌های رایج در آن زمان را منعکس می‌کند. این تغییر روایت ما را به چندین روش تغییر می‌دهد، به مقایسه زیر نگاه کنید.

![مقایسه LLMOps و MLOps](../../../translated_images/fa/01-llmops-shift.29bc933cb3bb0080.png)

توجه کنید که در LLMOps، تمرکز بیشتری بر توسعه‌دهندگان برنامه داریم، استفاده از ادغام‌ها به عنوان نقطه کلیدی، استفاده از "مدل‌ها به عنوان سرویس" و تفکر در مورد نکات زیر برای معیارها.

- کیفیت: کیفیت پاسخ
- آسیب: هوش مصنوعی مسئولانه
- صداقت: پایه‌مندی پاسخ (معقول است؟ درست است؟)
- هزینه: بودجه راه‌حل
- تأخیر: میانگین زمان پاسخ توکن

## چرخه عمر LLM

ابتدا، برای درک چرخه عمر و تغییرات، به این اینفوگرافیک توجه کنید.

![اینفوگرافیک LLMOps](../../../translated_images/fa/02-llmops.70a942ead05a7645.png)

همانطور که ممکن است متوجه شوید، این با چرخه‌های معمول MLOps متفاوت است. LLMها نیازمندی‌های جدید زیادی دارند، مانند پرامپتینگ، تکنیک‌های مختلف برای بهبود کیفیت (تنظیم دقیق، RAG، متا-پرامپت‌ها)، ارزیابی و مسئولیت‌پذیری با هوش مصنوعی مسئول، و در نهایت معیارهای ارزیابی جدید (کیفیت، آسیب، صداقت، هزینه و تأخیر).

برای مثال، به نحوه ایده‌پردازی نگاه کنید. استفاده از مهندسی پرامپت برای آزمایش با مدل‌های مختلف LLM به منظور کشف امکانات و آزمایش اینکه آیا فرضیه‌های آن‌ها می‌تواند درست باشد.

توجه داشته باشید که این روند خطی نیست، بلکه حلقه‌های یکپارچه، تکراری و با یک چرخه کلی است.

چگونه می‌توانیم این مراحل را بررسی کنیم؟ بیایید به جزئیات ساخت چرخه عمر بپردازیم.

![جریان کاری LLMOps](../../../translated_images/fa/03-llm-stage-flows.3a1e1c401235a6cf.png)

این ممکن است کمی پیچیده به نظر برسد، ابتدا روی سه مرحله بزرگ تمرکز کنیم.

1. ایده‌پردازی/کاوش: کاوش، در اینجا می‌توانیم بر اساس نیازهای کسب‌وکار خود کاوش کنیم. نمونه‌سازی، ایجاد یک [PromptFlow](https://microsoft.github.io/promptflow/index.html?WT.mc_id=academic-105485-koreyst) و آزمایش اینکه آیا برای فرضیه ما کافی است یا خیر.
1. ساخت/تقویت: پیاده‌سازی، اکنون شروع به ارزیابی برای داده‌های بزرگ‌تر می‌کنیم، تکنیک‌هایی مانند تنظیم دقیق و RAG را پیاده‌سازی می‌کنیم تا مقاومت راه‌حل خود را بررسی کنیم. اگر کار نکرد، پیاده‌سازی مجدد، افزودن مراحل جدید در جریان یا بازسازی داده‌ها ممکن است کمک کند. پس از آزمایش جریان و مقیاس خود، اگر کار کرد و معیارهای ما را تأیید کرد، آماده مرحله بعدی است.
1. عملیاتی‌سازی: ادغام، اکنون افزودن سیستم‌های نظارت و هشدار به سیستم، استقرار و ادغام برنامه با برنامه ما.

سپس، چرخه کلی مدیریت داریم که بر امنیت، انطباق و حاکمیت تمرکز دارد.

تبریک می‌گوییم، اکنون برنامه هوش مصنوعی شما آماده اجرا و عملیاتی است. برای تجربه عملی، نگاهی به [دموی چت Contoso](https://nitya.github.io/contoso-chat/?WT.mc_id=academic-105485-koreys) بیندازید.

حالا، چه ابزارهایی می‌توانیم استفاده کنیم؟

## ابزارهای چرخه عمر

برای ابزارها، مایکروسافت پلتفرم [Azure AI](https://azure.microsoft.com/solutions/ai/?WT.mc_id=academic-105485-koreys) و [PromptFlow](https://microsoft.github.io/promptflow/index.html?WT.mc_id=academic-105485-koreyst) را فراهم می‌کند که چرخه شما را آسان برای پیاده‌سازی و آماده اجرا می‌کند.

پلتفرم [Azure AI](https://azure.microsoft.com/solutions/ai/?WT.mc_id=academic-105485-koreys) به شما امکان استفاده از [AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreys) را می‌دهد. AI Studio یک پورتال وب است که به شما امکان کاوش مدل‌ها، نمونه‌ها و ابزارها را می‌دهد. مدیریت منابع، جریان‌های توسعه UI و گزینه‌های SDK/CLI برای توسعه کد-اول را فراهم می‌کند.

![امکانات Azure AI](../../../translated_images/fa/04-azure-ai-platform.80203baf03a12fa8.png)

Azure AI به شما امکان استفاده از منابع متعدد برای مدیریت عملیات، خدمات، پروژه‌ها، جستجوی برداری و نیازهای پایگاه داده را می‌دهد.

![LLMOps با Azure AI](../../../translated_images/fa/05-llm-azure-ai-prompt.a5ce85cdbb494bdf.png)

ساخت، از اثبات مفهوم (POC) تا برنامه‌های مقیاس بزرگ با PromptFlow:

- طراحی و ساخت برنامه‌ها از VS Code، با ابزارهای بصری و عملکردی
- آزمایش و تنظیم دقیق برنامه‌ها برای هوش مصنوعی با کیفیت، به آسانی.
- استفاده از Azure AI Studio برای ادغام و تکرار با ابر، فشار و استقرار برای ادغام سریع.

![LLMOps با PromptFlow](../../../translated_images/fa/06-llm-promptflow.a183eba07a3a7fdf.png)

## عالی! یادگیری خود را ادامه دهید!

شگفت‌انگیز است، اکنون بیشتر بیاموزید که چگونه یک برنامه را ساختاربندی کنیم تا مفاهیم را با [برنامه چت Contoso](https://nitya.github.io/contoso-chat/?WT.mc_id=academic-105485-koreyst) استفاده کنیم، تا ببینید چگونه Cloud Advocacy این مفاهیم را در نمایش‌ها اضافه می‌کند. برای محتوای بیشتر، جلسه جانبی [Ignite](https://www.youtube.com/watch?v=DdOylyrTOWg) ما را بررسی کنید!

اکنون، درس ۱۵ را بررسی کنید تا بفهمید چگونه [تولید تقویت‌شده بازیابی و پایگاه‌های داده برداری](../15-rag-and-vector-databases/README.md?WT.mc_id=academic-105485-koreyst) بر هوش مصنوعی مولد تأثیر می‌گذارد و برنامه‌های جذاب‌تری بسازید!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**سلب مسئولیت**:  
این سند با استفاده از سرویس ترجمه هوش مصنوعی [Co-op Translator](https://github.com/Azure/co-op-translator) ترجمه شده است. در حالی که ما در تلاش برای دقت هستیم، لطفاً توجه داشته باشید که ترجمه‌های خودکار ممکن است حاوی خطاها یا نادرستی‌هایی باشند. سند اصلی به زبان بومی خود باید به عنوان منبع معتبر در نظر گرفته شود. برای اطلاعات حیاتی، ترجمه حرفه‌ای انسانی توصیه می‌شود. ما مسئول هیچ گونه سوءتفاهم یا تفسیر نادرستی که از استفاده این ترجمه ناشی شود، نیستیم.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->