{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## పరిచయం \n",
    "\n",
    "ఈ పాఠం కవర్ చేస్తుంది: \n",
    "- ఫంక్షన్ కాలింగ్ అంటే ఏమిటి మరియు దాని ఉపయోగాలు \n",
    "- OpenAI ఉపయోగించి ఫంక్షన్ కాల్ ఎలా సృష్టించాలి \n",
    "- ఫంక్షన్ కాల్‌ను ఒక అప్లికేషన్‌లో ఎలా సమీకరించాలి \n",
    "\n",
    "## నేర్చుకునే లక్ష్యాలు \n",
    "\n",
    "ఈ పాఠం పూర్తి చేసిన తర్వాత మీరు ఎలా చేయాలో మరియు అర్థం చేసుకుంటారు: \n",
    "\n",
    "- ఫంక్షన్ కాలింగ్ ఉపయోగించే ఉద్దేశ్యం \n",
    "- OpenAI సర్వీస్ ఉపయోగించి ఫంక్షన్ కాల్ సెటప్ చేయడం \n",
    "- మీ అప్లికేషన్ ఉపయోగానికి సమర్థవంతమైన ఫంక్షన్ కాల్స్ డిజైన్ చేయడం\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ఫంక్షన్ కాల్స్‌ను అర్థం చేసుకోవడం\n",
    "\n",
    "ఈ పాఠం కోసం, మన విద్యా స్టార్టప్ కోసం ఒక ఫీచర్‌ను నిర్మించాలనుకుంటున్నాము, ఇది వినియోగదారులు టెక్నికల్ కోర్సులను కనుగొనడానికి చాట్‌బాట్‌ను ఉపయోగించడానికి అనుమతిస్తుంది. వారి నైపుణ్య స్థాయి, ప్రస్తుత పాత్ర మరియు ఆసక్తి ఉన్న సాంకేతికతకు అనుగుణంగా కోర్సులను మేము సిఫార్సు చేస్తాము.\n",
    "\n",
    "దీనిని పూర్తి చేయడానికి మేము కింది వాటి సమ్మేళనాన్ని ఉపయోగిస్తాము:\n",
    " - వినియోగదారులకు చాట్ అనుభవాన్ని సృష్టించడానికి `OpenAI`\n",
    " - వినియోగదారుల అభ్యర్థన ఆధారంగా కోర్సులను కనుగొనడంలో సహాయపడటానికి `Microsoft Learn Catalog API`\n",
    " - వినియోగదారుల ప్రశ్నను తీసుకుని API అభ్యర్థన చేయడానికి ఫంక్షన్‌కు పంపడానికి `Function Calling`\n",
    "\n",
    "ప్రారంభించడానికి, మొదట ఫంక్షన్ కాలింగ్‌ను ఎందుకు ఉపయోగించాలనుకుంటున్నామో చూద్దాం:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT నుండి ఫంక్షన్ ప్రతిస్పందనను చూడగలిగే కొత్త ప్రతిస్పందన పొందండి\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ఫంక్షన్ కాలింగ్ ఎందుకు\n",
    "\n",
    "మీరు ఈ కోర్సులో మరేదైనా పాఠం పూర్తి చేసి ఉంటే, మీరు పెద్ద భాషా మోడల్స్ (LLMs) ఉపయోగించే శక్తిని అర్థం చేసుకున్నట్లుండవచ్చు. ఆశిస్తున్నాము మీరు వాటి కొన్ని పరిమితులను కూడా చూడగలుగుతారు.\n",
    "\n",
    "ఫంక్షన్ కాలింగ్ అనేది OpenAI సర్వీస్ యొక్క ఒక ఫీచర్, ఇది క్రింది సవాళ్లను పరిష్కరించడానికి రూపొందించబడింది:\n",
    "\n",
    "అసమంజసమైన ప్రతిస్పందన ఫార్మాటింగ్:\n",
    "- ఫంక్షన్ కాలింగ్ ముందు, పెద్ద భాషా మోడల్ నుండి వచ్చే ప్రతిస్పందనలు నిర్మాణరహితంగా మరియు అసమంజసంగా ఉండేవి. డెవలపర్లు ప్రతి వేరియేషన్‌ను నిర్వహించడానికి సంక్లిష్టమైన ధృవీకరణ కోడ్ రాయాల్సి ఉండేది.\n",
    "\n",
    "బాహ్య డేటాతో పరిమిత సమగ్రత:\n",
    "- ఈ ఫీచర్ ముందు, చాట్ సందర్భంలో అనువర్తనంలోని ఇతర భాగాల నుండి డేటాను చేర్చడం కష్టం అయింది.\n",
    "\n",
    "ప్రతిస్పందన ఫార్మాట్లను ప్రమాణీకరించడం మరియు బాహ్య డేటాతో సులభ సమగ్రతను సాధించడం ద్వారా, ఫంక్షన్ కాలింగ్ అభివృద్ధిని సులభతరం చేస్తుంది మరియు అదనపు ధృవీకరణ లాజిక్ అవసరాన్ని తగ్గిస్తుంది.\n",
    "\n",
    "వినియోగదారులు \"స్టాక్‌హోమ్‌లో ప్రస్తుత వాతావరణం ఏమిటి?\" వంటి ప్రశ్నలకు సమాధానాలు పొందలేకపోయారు. ఇది మోడల్స్ శిక్షణ పొందిన డేటా సమయానికి పరిమితం కావడం వల్ల జరిగింది.\n",
    "\n",
    "ఈ సమస్యను వివరించే క్రింది ఉదాహరణను చూద్దాం:\n",
    "\n",
    "మనం విద్యార్థుల డేటాబేస్‌ను సృష్టించి, వారికి సరైన కోర్సును సూచించాలనుకుంటే, క్రింద రెండు విద్యార్థుల వివరణలు ఉన్నాయి, అవి డేటాలో చాలా సమానంగా ఉంటాయి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మేము ఈ డేటాను పార్స్ చేయడానికి LLM కు పంపించాలని కోరుకుంటున్నాము. దీన్ని తర్వాత మా అప్లికేషన్‌లో API కి పంపడానికి లేదా డేటాబేస్‌లో నిల్వ చేయడానికి ఉపయోగించవచ్చు.\n",
    "\n",
    "మనం LLM కు మేము ఆసక్తి ఉన్న సమాచారాన్ని సూచించే రెండు సమానమైన ప్రాంప్ట్‌లను సృష్టిద్దాం:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మేము మా ఉత్పత్తికి ముఖ్యమైన భాగాలను విశ్లేషించడానికి దీన్ని ఒక LLM కు పంపాలనుకుంటున్నాము. కాబట్టి మేము LLM ను సూచించడానికి రెండు సమానమైన ప్రాంప్ట్‌లను సృష్టించవచ్చు:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఈ రెండు ప్రాంప్ట్‌లను సృష్టించిన తర్వాత, వాటిని `openai.ChatCompletion` ఉపయోగించి LLM కు పంపిస్తాము. మేము ప్రాంప్ట్‌ను `messages` వేరియబుల్‌లో నిల్వ చేస్తాము మరియు పాత్రను `user` గా కేటాయిస్తాము. ఇది యూజర్ నుండి చాట్‌బాట్‌కు సందేశం రాయబడుతున్నట్లు అనుకరించడానికి.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు మనం రెండు అభ్యర్థనలను LLM కు పంపించి, మనం పొందే ప్రతిస్పందనను పరిశీలించవచ్చు.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ప్రాంప్ట్లు ఒకటే అయినప్పటికీ మరియు వివరణలు సమానమైనప్పటికీ, `Grades` ప్రాపర్టీ యొక్క వేర్వేరు ఫార్మాట్లు రావచ్చు.\n",
    "\n",
    "మీరు పై సెల్‌ను బహుళసార్లు నడిపితే, ఫార్మాట్ `3.7` లేదా `3.7 GPA` కావచ్చు.\n",
    "\n",
    "ఇది ఎందుకంటే LLM రాసిన ప్రాంప్ట్ రూపంలో అసంఘటిత డేటాను తీసుకుని, అసంఘటిత డేటాను తిరిగి ఇస్తుంది. మనం ఒక నిర్మిత ఫార్మాట్ అవసరం, తద్వారా ఈ డేటాను నిల్వ చేయడం లేదా ఉపయోగించడం సమయంలో ఏమి ఆశించాలో తెలుసుకోవచ్చు.\n",
    "\n",
    "ఫంక్షనల్ కాలింగ్ ఉపయోగించడం ద్వారా, మనం నిర్మిత డేటాను తిరిగి పొందుతామని నిర్ధారించవచ్చు. ఫంక్షన్ కాలింగ్ ఉపయోగించినప్పుడు, LLM వాస్తవానికి ఏ ఫంక్షన్లను కాల్ చేయదు లేదా నడపదు. బదులుగా, మనం LLM తన ప్రతిస్పందనలకు అనుసరించాల్సిన నిర్మాణాన్ని సృష్టిస్తాము. ఆ తర్వాత ఆ నిర్మిత ప్రతిస్పందనలను మన అప్లికేషన్లలో ఏ ఫంక్షన్ నడపాలో తెలుసుకోవడానికి ఉపయోగిస్తాము.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ఫంక్షన్ కాలింగ్ ఫ్లో డయాగ్రామ్](../../../../translated_images/te/Function-Flow.083875364af4f4bb.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "మనం ఆ ఫంక్షన్ నుండి తిరిగి వచ్చినదాన్ని తీసుకుని దీన్ని LLMకి తిరిగి పంపవచ్చు. LLM ఆ తర్వాత సహజ భాషను ఉపయోగించి వినియోగదారుడి ప్రశ్నకు సమాధానం ఇస్తుంది.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ఫంక్షన్ కాల్స్ ఉపయోగించే సందర్భాలు\n",
    "\n",
    "**బాహ్య టూల్స్‌ను కాల్ చేయడం**  \n",
    "చాట్‌బాట్లు వినియోగదారుల ప్రశ్నలకు సమాధానాలు ఇవ్వడంలో అద్భుతంగా ఉంటాయి. ఫంక్షన్ కాలింగ్ ఉపయోగించి, చాట్‌బాట్లు వినియోగదారుల సందేశాలను ఉపయోగించి కొన్ని పనులను పూర్తి చేయవచ్చు. ఉదాహరణకు, ఒక విద్యార్థి చాట్‌బాట్‌ను అడగవచ్చు \"ఈ విషయం గురించి నాకు మరింత సహాయం కావాలి అని నా ఉపాధ్యాయుడికి ఇమెయిల్ పంపించు\". ఇది `send_email(to: string, body: string)` అనే ఫంక్షన్‌ను కాల్ చేయవచ్చు.\n",
    "\n",
    "**API లేదా డేటాబేస్ క్వెరీలను సృష్టించడం**  \n",
    "వినియోగదారులు సహజ భాషను ఉపయోగించి సమాచారాన్ని కనుగొనవచ్చు, అది ఫార్మాటెడ్ క్వెరీ లేదా API అభ్యర్థనగా మారుతుంది. ఉదాహరణకు, ఒక ఉపాధ్యాయుడు \"గత అసైన్‌మెంట్ పూర్తి చేసిన విద్యార్థులు ఎవరు?\" అని అడిగితే, అది `get_completed(student_name: string, assignment: int, current_status: string)` అనే ఫంక్షన్‌ను కాల్ చేయవచ్చు.\n",
    "\n",
    "**సంఘటిత డేటాను సృష్టించడం**  \n",
    "వినియోగదారులు ఒక టెక్స్ట్ బ్లాక్ లేదా CSV తీసుకుని LLM ఉపయోగించి ముఖ్యమైన సమాచారాన్ని తీసుకోవచ్చు. ఉదాహరణకు, ఒక విద్యార్థి శాంతి ఒప్పందాల గురించి వికీపీడియా వ్యాసాన్ని AI ఫ్లాష్ కార్డులు సృష్టించడానికి మార్చవచ్చు. ఇది `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` అనే ఫంక్షన్‌ను ఉపయోగించి చేయవచ్చు.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. మీ మొదటి ఫంక్షన్ కాల్ సృష్టించడం\n",
    "\n",
    "ఫంక్షన్ కాల్ సృష్టించే ప్రక్రియలో 3 ప్రధాన దశలు ఉంటాయి:  \n",
    "1. మీ ఫంక్షన్ల జాబితా మరియు ఒక యూజర్ సందేశంతో Chat Completions APIని కాల్ చేయడం  \n",
    "2. ఒక చర్యను నిర్వహించడానికి మోడల్ ప్రతిస్పందనను చదవడం అంటే ఫంక్షన్ లేదా API కాల్‌ను అమలు చేయడం  \n",
    "3. యూజర్‌కు ప్రతిస్పందన సృష్టించడానికి ఆ సమాచారాన్ని ఉపయోగించేందుకు మీ ఫంక్షన్ నుండి వచ్చిన ప్రతిస్పందనతో మరోసారి Chat Completions APIని కాల్ చేయడం.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ఫంక్షన్ కాల్ యొక్క ప్రవాహం](../../../../translated_images/te/LLM-Flow.3285ed8caf4796d7.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ఫంక్షన్ కాల్ యొక్క అంశాలు\n",
    "\n",
    "#### వినియోగదారుల ఇన్‌పుట్\n",
    "\n",
    "మొదటి దశ ఒక వినియోగదారు సందేశాన్ని సృష్టించడం. ఇది టెక్స్ట్ ఇన్‌పుట్ విలువను తీసుకుని డైనమిక్‌గా కేటాయించవచ్చు లేదా మీరు ఇక్కడ ఒక విలువను కేటాయించవచ్చు. మీరు Chat Completions APIతో మొదటిసారి పని చేస్తుంటే, మేము సందేశం యొక్క `role` మరియు `content` ను నిర్వచించాలి.\n",
    "\n",
    "`role` అనేది `system` (నియమాలు సృష్టించడం), `assistant` (మోడల్) లేదా `user` (చివరి వినియోగదారు) ఏదైనా కావచ్చు. ఫంక్షన్ కాలింగ్ కోసం, మేము దీన్ని `user` గా కేటాయించి ఒక ఉదాహరణ ప్రశ్నను ఇస్తాము.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ఫంక్షన్లు సృష్టించడం.\n",
    "\n",
    "తర్వాత మనం ఒక ఫంక్షన్ మరియు ఆ ఫంక్షన్ యొక్క పారామితులను నిర్వచించబోతున్నాము. ఇక్కడ మనం `search_courses` అనే ఒకే ఒక ఫంక్షన్ ఉపయోగించబోతున్నాము కానీ మీరు బహుళ ఫంక్షన్లు సృష్టించవచ్చు.\n",
    "\n",
    "**ముఖ్యమైనది** : ఫంక్షన్లు LLM కు సిస్టమ్ సందేశంలో చేర్చబడి ఉంటాయి మరియు మీరు అందుబాటులో ఉన్న టోకెన్ల పరిమాణంలో వాటి పరిమాణం కూడా ఉంటుంది.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**వ్యాఖ్యానాలు**\n",
    "\n",
    "ఫంక్షన్ నిర్వచన నిర్మాణానికి అనేక స్థాయిలు ఉంటాయి, ప్రతి స్థాయికి తన స్వంత లక్షణాలు ఉంటాయి. ఇక్కడ ఆ లోపలి నిర్మాణం యొక్క విభజన ఉంది:\n",
    "\n",
    "**అగ్రస్థాయి ఫంక్షన్ లక్షణాలు:**\n",
    "\n",
    "`name` - మేము పిలవాలనుకునే ఫంక్షన్ పేరు.\n",
    "\n",
    "`description` - ఫంక్షన్ ఎలా పనిచేస్తుందో వివరణ. ఇక్కడ స్పష్టంగా మరియు ఖచ్చితంగా ఉండటం ముఖ్యం.\n",
    "\n",
    "`parameters` - మోడల్ తన ప్రతిస్పందనలో ఉత్పత్తి చేయాలనుకునే విలువలు మరియు ఫార్మాట్ జాబితా.\n",
    "\n",
    "**పారామితులు ఆబ్జెక్ట్ లక్షణాలు:**\n",
    "\n",
    "`type` - పారామితుల ఆబ్జెక్ట్ యొక్క డేటా రకం (సాధారణంగా \"object\").\n",
    "\n",
    "`properties` - మోడల్ తన ప్రతిస్పందన కోసం ఉపయోగించే నిర్దిష్ట విలువల జాబితా.\n",
    "\n",
    "**వ్యక్తిగత పారామితి లక్షణాలు:**\n",
    "\n",
    "`name` - ప్రాపర్టీ కీ ద్వారా స్వయంచాలకంగా నిర్వచించబడింది (ఉదా: \"role\", \"product\", \"level\").\n",
    "\n",
    "`type` - ఈ నిర్దిష్ట పారామితి యొక్క డేటా రకం (ఉదా: \"string\", \"number\", \"boolean\").\n",
    "\n",
    "`description` - నిర్దిష్ట పారామితి యొక్క వివరణ.\n",
    "\n",
    "**ఐచ్ఛిక లక్షణాలు:**\n",
    "\n",
    "`required` - ఫంక్షన్ కాల్ పూర్తి కావడానికి అవసరమైన పారామితులు ఏవో జాబితా చేసే అర్రే.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ఫంక్షన్ కాల్ చేయడం  \n",
    "ఫంక్షన్ నిర్వచించిన తర్వాత, ఇప్పుడు దాన్ని Chat Completion API కాల్‌లో చేర్చాలి. దీని కోసం మనం రిక్వెస్ట్‌లో `functions` ను జోడిస్తాము. ఈ సందర్భంలో `functions=functions`.  \n",
    "\n",
    "`function_call` ను `auto` గా సెట్ చేసే ఎంపిక కూడా ఉంది. దీని అర్థం, మనం స్వయంగా ఫంక్షన్‌ను కేటాయించకుండా, యూజర్ సందేశం ఆధారంగా ఏ ఫంక్షన్ కాల్ చేయాలో LLM నిర్ణయించనుంది.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు మనం ప్రతిస్పందనను చూద్దాం మరియు అది ఎలా ఫార్మాట్ చేయబడిందో చూద్దాం:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "మీరు చూడవచ్చు, ఫంక్షన్ పేరు పిలవబడింది మరియు యూజర్ సందేశం నుండి, LLM ఆ ఫంక్షన్ ఆర్గ్యుమెంట్లకు సరిపోయే డేటాను కనుగొనగలిగింది.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ఫంక్షన్ కాల్స్‌ను అనువర్తనంలో సమీకరించడం. \n",
    "\n",
    "\n",
    "మనం LLM నుండి ఫార్మాట్ చేసిన ప్రతిస్పందనను పరీక్షించిన తర్వాత, ఇప్పుడు దీన్ని ఒక అనువర్తనంలో సమీకరించవచ్చు. \n",
    "\n",
    "### ప్రవాహాన్ని నిర్వహించడం \n",
    "\n",
    "దీనిని మన అనువర్తనంలో సమీకరించడానికి, క్రింది దశలను తీసుకుందాం: \n",
    "\n",
    "మొదట, OpenAI సేవలకు కాల్ చేసి, సందేశాన్ని `response_message` అనే వేరియబుల్‌లో నిల్వ చేయండి. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు మేము Microsoft Learn APIని పిలిచి కోర్సుల జాబితాను పొందే ఫంక్షన్‌ను నిర్వచించబోతున్నాము:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఉత్తమ ఆచరణగా, మేము ఆ మోడల్ ఫంక్షన్‌ను పిలవాలనుకుంటుందో లేదో చూడబోతున్నాము. ఆ తర్వాత, అందుబాటులో ఉన్న ఫంక్షన్లలో ఒకటిని సృష్టించి, పిలవబడుతున్న ఫంక్షన్‌కు సరిపోల్చుతాము.  \n",
    "తర్వాత, ఆ ఫంక్షన్ యొక్క ఆర్గ్యుమెంట్లను తీసుకుని వాటిని LLM నుండి వచ్చిన ఆర్గ్యుమెంట్లకు మ్యాప్ చేస్తాము.\n",
    "\n",
    "చివరగా, ఫంక్షన్ కాల్ సందేశం మరియు `search_courses` సందేశం ద్వారా తిరిగి వచ్చిన విలువలను జతచేస్తాము. ఇది LLMకి సహజ భాషలో వినియోగదారుడికి స్పందించడానికి అవసరమైన అన్ని సమాచారాన్ని అందిస్తుంది.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ఇప్పుడు మేము నవీకరించిన సందేశాన్ని LLM కు పంపబోతున్నాము, తద్వారా మేము API JSON ఫార్మాట్ చేసిన ప్రతిస్పందన కాకుండా సహజ భాషా ప్రతిస్పందనను పొందగలుగుతాము.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## కోడ్ ఛాలెంజ్\n",
    "\n",
    "అద్భుతమైన పని! OpenAI ఫంక్షన్ కాలింగ్ నేర్చుకోవడాన్ని కొనసాగించడానికి మీరు నిర్మించవచ్చు: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - నేర్చుకునేవారికి మరిన్ని కోర్సులు కనుగొనడంలో సహాయపడే ఫంక్షన్ యొక్క మరిన్ని పారామితులు. మీరు అందుబాటులో ఉన్న API పారామితులను ఇక్కడ చూడవచ్చు:  \n",
    " - నేర్చుకునేవారి స్థానిక భాష వంటి మరిన్ని సమాచారాన్ని తీసుకునే మరో ఫంక్షన్ కాల్ సృష్టించండి  \n",
    " - ఫంక్షన్ కాల్ మరియు/లేదా API కాల్ సరైన కోర్సులు తిరిగి ఇవ్వకపోతే లోపం నిర్వహణను సృష్టించండి\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**అస్పష్టత**:  \nఈ పత్రాన్ని AI అనువాద సేవ [Co-op Translator](https://github.com/Azure/co-op-translator) ఉపయోగించి అనువదించబడింది. మేము ఖచ్చితత్వానికి ప్రయత్నించినప్పటికీ, ఆటోమేటెడ్ అనువాదాల్లో పొరపాట్లు లేదా తప్పిదాలు ఉండవచ్చు. మూల పత్రం దాని స్వదేశీ భాషలో అధికారిక మూలంగా పరిగణించాలి. ముఖ్యమైన సమాచారానికి, ప్రొఫెషనల్ మానవ అనువాదం సిఫార్సు చేయబడుతుంది. ఈ అనువాదం వాడకం వల్ల కలిగే ఏవైనా అపార్థాలు లేదా తప్పుదారుల కోసం మేము బాధ్యత వహించము.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T21:15:15+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "te"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}