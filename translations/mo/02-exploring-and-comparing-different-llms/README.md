<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T13:47:28+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "mo"
}
-->
# Istera LLM dibe daftara xwe bidin

[![Istera LLM dibe daftara xwe bidin](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.mo.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Ji bo tema vÃª derse wÃªneya jor click bikin_

Di dersa berÃª de, me dÃ®t ku AI Generative Ã§awa dÃ®menÃª teknolÃ®jiyÃª diguherÃ®ne, Ã§awa ModelÃªn ZimanÃª Mezin (LLM) dixebitin Ã» Ã§awa karÃ®bar - wekÃ® startup me - dikare wan li ser kesayÃªt xwe bikar bÃ®ne Ã» mezin bibe! Di vÃª babetÃª de, em tÃªne rastÃ®n Ã» di cÃ®h de lÃªkera cÃ»re-cÃ»rÃªn modelÃªn zimanÃª mezin (LLM) da ku tÃªgihiÅŸtinÃª li ser serhildanÃªn wan Ã» zayendÃªn wan bibÃ®nin.

Gava dÃ®rokÃª ya startup me ye ku modelÃªn LLM yÃªn heyÃ® bibÃ®ne Ã» tÃªgihiÅŸtin ku kÃ®jan ji bo kesayÃªt me tÃªkildar in.

## PÃªÅŸkeftin

Ev ders tÃªne bistÃ®nin:

- CÃ»re-cÃ»rÃªn LLM yÃªn li dÃ®menÃª heyÃ®.
- BiceribÃ®n, iterate kirin Ã» modelÃªn cÃ»re-cÃ»r ji bo kesayÃªt xwe di Azure de bi hev re anÃ®n.
- Ã‡awa LLMek veguheztin.

## HedefÃªn FÃªrbÃ»nÃª

PiÅŸtÃ® ku vÃª dersÃª qedandin, hÃ»n dikarin:

- Modela rast ji bo kesayÃªt xwe hilbijÃªrin.
- TÃªgihiÅŸtin Ã§awa modela xwe biceribÃ®nin, iterate bikin, Ã» ÅŸanoya wan baÅŸ bikin.
- ZanÃ®n Ã§awa karÃ®bar modelÃªn veguhezin.

## TÃªgihiÅŸtin cÃ»re-cÃ»rÃªn LLM

LLM dikarin bi piranÃ® kategorÃ®yan li ser binyadÃª xwe, daneyÃªn fÃªrkirinÃª, Ã» kesayÃªt xwe ve bibe. TÃªgihiÅŸtin vÃª cÃ»reyÃª dÃª startup meyÃª alÃ®kar bibe ku modela rast ji bo senaryo hilbijÃªre, Ã» Ã§awa tÃªgihiÅŸtin, iterate bikin, Ã» ÅŸanoya wan baÅŸ bikin.

ModelÃªn LLM pir hene, hilbijartina modelÃª tÃªgihiÅŸtin li ser kÃ®jan karÃ®bar hÃ»n dixwazin wan bikar bÃ®nin, daneyÃªn hÃ»n, Ã§i qas hÃ»n amade ne ku tÃªvÃ® dayÃ®n Ã» zÃªdetir.

Li gorÃ® ku hÃ»n dixwazin modelÃªn ji bo nivÃ®sÃ®nÃª, dengÃª, vÃ®dyo, Ã§Ãªkirina wÃªneyÃª Ã» hwd., hÃ»n dikarin modelÃª cÃ»rÃª cuda hilbijÃªrin.

- **Deng Ã» nasnameya axaftinÃª**. Ji bo vÃª armancÃª, modelÃªn wÃ®sper ne bijareke baÅŸ in ji ber ku ew modelÃªn berfireh ne Ã» li ser nasnameya axaftinÃª diÃ§in. Ew di axaftinÃªn pirane de fÃªr dikin Ã» dikarin nasnameya axaftinÃª li zimanÃªn cÃ»rÃª cuda bikar bÃ®nin. ZÃªdetir fÃªr bibin li ser [modelÃªn wÃ®sper li vir](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Ã‡Ãªkirina wÃªneyÃª**. Ji bo Ã§Ãªkirina wÃªneyÃª, DALL-E Ã» Midjourney du bijareya pir nasname ne. DALL-E ji aliyÃª Azure OpenAI ve pÃªÅŸkÃªÅŸ dibe. [ZÃªdetir fÃªr bibin li ser DALL-E li vir](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) Ã» hwd. di Babeta 9Ãª ya vÃª dersÃª de.

- **Ã‡Ãªkirina nivÃ®sÃª**. Pir modelÃªn li ser Ã§Ãªkirina nivÃ®sÃª fÃªr dikin Ã» hÃ»n pÃªÅŸniyarÃªn pirane hene ji bo GPT-3.5 heta GPT-4. Ew bi pÃ®vanÃªn cuda tÃªvÃ® dayÃ®nÃª tÃªne pÃªÅŸkÃªÅŸ kirin Ã» GPT-4 herÃ® guherbar e. Åayeste ye ku li ser [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) binirxÃ®nin kÃ®jan modelÃªn herÃ® baÅŸ li ser pÃªÅŸniyara we tÃªne pÃªÅŸkÃªÅŸ kirin.

- **CudayÃ®ya modalan**. Heke hÃ»n dixwazin pirane modalan bi pÃªÅŸniyarÃªn cuda bikar bÃ®nin, hÃ»n dikarin modelÃªn cÃ»rÃª cuda hilbijÃªrin wekÃ® [gpt-4 turbo with vision or gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - modelÃªn OpenAI ya herÃ® dawÃ® - ku dikarin zimanÃª nÃ»Ã§eyÃª bi tÃªgihiÅŸtina wÃªneyÃª ve girÃªdan bikin, di navbera modalan bi pÃªÅŸniyarÃªn cuda de pÃªÅŸnÃ®yarkirin.

Hilbijartina modelÃª wate ye ku hÃ»n hÃ»n bÃ»yÃ®nÃªn bingehÃ®n tÃªgihiÅŸtin, lÃª di heman demÃª de ne yeter e. Pir caran hÃ»n daneyÃªn taybetÃ® yÃªn kompanya hÃ»n hene ku hÃ»n hewce ne modela LLMÃª li ser wan fÃªr bikin. Hene Ã§and jÃ® modelÃªn cuda Ã§Ãª dikin, zÃªdetir li ser vÃª di babetÃªn pÃªÅŸÃ®n de.

### ModelÃªn BingehÃ®n ji ber modelÃªn LLM

TermÃª Modela BingehÃ®n ji aliyÃª [lÃªkolÃ®nerÃªn Stanford ve hatÃ® afirandin](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) Ã» wekÃ® modelÃª AI tÃªne diyar kirin ku li gorÃ® bÃ»yerÃªn taybetÃ®, wekÃ®:

- **Ew bi fÃªrkirina bÃªyÃ® sarkÃªÅŸÃ® an fÃªrkirina bi sarkÃªÅŸÃ® fÃªr dikin**, wate ew di ser daneyÃªn bÃª niÅŸan an multi-modalan di fÃªr dikin, Ã» ew ji niÅŸanÃª an tÃªgihiÅŸtina mirovÃª hewce ne.
- **Ew modelÃªn pir mezin in**, ku li ser torÃªn nervÃªn pirenehÃ®nÃªn pirane di fÃªr dikin.
- **Ew bÃ»yerÃªn bingehÃ®n ji modelÃªn din in**, wate ew dikarin wekÃ® bingehÃ®n ji modelÃªn din tÃªne bikar anÃ®n, ku dikarin bi tune kirinÃª.

![ModelÃªn BingehÃ®n ji ber modelÃªn LLM](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.mo.png)

Ã‡avkanÃ®: [RehberÃª BingehÃ®n ji bo ModelÃªn BingehÃ®n Ã» ModelÃªn ZimanÃª Mezin | Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Ji bo zÃªdetir piÅŸtrastina vÃª cudayiyÃª, bibÃ®nin ChatGPT wekÃ® mÃ®nakÃª. Ji bo Ã§Ãªkirina berÃª ya ChatGPT, modelÃª ku GPT-3.5 wekÃ® modelÃª bingehÃ®n bikar tÃªne anÃ®n. Ev wate ye ku OpenAI daneyÃªn taybetÃ® ya sohbetÃª bikar anÃ®n ku versiyona GPT-3.5 Ã§Ãªbikin ku di senaryoyÃªn peyivÃ®nÃª de taybetÃ® bÃ».

![Modela BingehÃ®n](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.mo.png)

Ã‡avkanÃ®: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### ModelÃªn Open Source ji ber ModelÃªn TaybetÃ®

ÅopandinÃªn din yÃªn ji bo kategorÃ®kirina LLM jÃ® tÃªne bikar anÃ®n.

ModelÃªn open-source modelÃªn ne ku ji aliyÃª giÅŸtÃ® tÃªne pÃªÅŸkÃªÅŸ kirin Ã» dikarin ji aliyÃª kÃ®jan karÃ®bar bikar bÃ®nin. Ew pir caran ji aliyÃª kompanya ku ew afirandin, an ji aliyÃª civata lÃªkolÃ®neran tÃªne pÃªÅŸkÃªÅŸ kirin. Ew modelÃªn tÃªne bibÃ®nin, guherandin, Ã» ji bo kesayÃªtÃªn cÃ»re-cÃ»r tÃªne taybetandin. LÃª ew pir caran ji bo bikar anÃ®nÃª di pÃªÅŸnÃ®yarkirinÃª de ne mezin in, Ã» dikarin wekÃ® modelÃªn taybetÃ® ne performant in. PÃªÅŸniyarkirin ji bo modelÃªn open-source dikare kÃªm bibe, Ã» ew dikarin ne di meya dirÃªj de ne taybetÃ® bÃ»nin an ne di binyadÃª lÃªkolÃ®nÃªn herÃ® dawÃ® de bÃ»nin. MÃ®nakÃªn modelÃªn open-source yÃªn nasnamekÃª [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) Ã» [LLaMA](https://llama.meta.com) ne.

ModelÃªn taybetÃ® modelÃªn ne ku ji aliyÃª kompanya ku ew ne tÃªne pÃªÅŸkÃªÅŸ kirin. Ew modelÃªn pir caran ji bo bikar anÃ®nÃª di pÃªÅŸnÃ®yarkirinÃª de tÃªne taybetandin. LÃª ew ne tÃªne bibÃ®nin, guherandin, an taybetandin ji bo kesayÃªtÃªn cÃ»re-cÃ»r. Hwd., ew pir caran ne bi belaÅŸ tÃªne pÃªÅŸkÃªÅŸ kirin, Ã» dikarin xwerÃ»ya an tÃªvÃ® dayÃ®nÃª hewce bÃ»n. JÃ®, bikarhÃªner ne kontrolÃª li ser daneyÃªn ku ji bo fÃªrkirina modelÃª tÃªne bikar anÃ®n, ku wate ew hewce ne ku xwediyÃª modelÃª biÅŸopÃ®ne ku ew ji bo taybetÃ®ya daneyÃªn biÅŸopÃ®ne Ã» biÅŸopÃ®ne. MÃ®nakÃªn modelÃªn taybetÃ® yÃªn nasnamekÃª [modelÃªn OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) an [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst) ne.

### Embedding versus Ã‡Ãªkirina WÃªneyÃª versus Ã‡Ãªkirina NivÃ®sÃª Ã» Koda

LLM dikarin wekÃ® kategorÃ® li ser derketina wan tÃªne kategorÃ® kirin.

Embeddings modelÃªn ne ku dikarin nivÃ®sa teqÃ®na nÃ»merÃ®k bikar anÃ®n, ku embedding tÃªne gotin, ku wate nivÃ®sa teqÃ®na nÃ»merÃ®k ya nivÃ®sÃª tÃªne nivÃ®sandin. Embeddings dikarin biÅŸopÃ®nin ku makinÃªn tÃªgihiÅŸtin li ser peywendiyÃªn di navbera peyvÃªn an cÃ¼mleyÃªn de bikin Ã» dikarin wekÃ® derketina modelÃªn din, wekÃ® modelÃªn kategorÃ®, an modelÃªn ku ji bo dÃ®menÃªn nÃ»merÃ®k ÅŸanoyÃªn baÅŸ hene, tÃªne bikar anÃ®n. ModelÃªn embedding pir caran ji bo fÃªrkirina vegerÃ®nÃª tÃªne bikar anÃ®n, ku modelÃª wekÃ® armancÃª taybetÃ® ya modelÃª ku ji bo ew modelÃªn ku fÃªrbÃ»nÃªn teqÃ®na teqÃ®na teqÃ®na tÃªne bikar anÃ®n, Ã» paÅŸÃª giranÃªn modelÃª (embeddings) ji bo karÃ®barÃªn din tÃªne bikar anÃ®n. MÃ®nak ji vÃª kategorÃ®ye [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst) ne.

![Embedding](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.mo.png)

ModelÃªn Ã§Ãªkirina wÃªneyÃª modelÃªn ne ku wÃªneyan Ã§Ãªdikin. Ew modelÃªn pir caran ji bo guherandina wÃªneyÃª, Ã§Ãªkirina wÃªneyÃª, Ã» vegerÃ®na wÃªneyÃª tÃªne bikar anÃ®n. ModelÃªn Ã§Ãªkirina wÃªneyÃª pir caran ji bo dÃ®menÃªn mezin yÃªn wÃªneyÃª, wekÃ® [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), tÃªne fÃªr kirin, Ã» dikarin wÃªneyÃªn nÃ» Ã§Ãªbikin an wÃªneyÃªn heyÃ® biguherÃ®nin bi teknÃ®kÃªn inpainting, super-resolution, Ã» colorization. MÃ®nakÃªn hwd. [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) Ã» [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst) ne.

![Ã‡Ãªkirina WÃªneyÃª](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.mo.png)

ModelÃªn Ã§Ãªkirina nivÃ®sÃª Ã» koda modelÃªn ne ku nivÃ®s an koda Ã§Ãªdikin. Ew modelÃªn pir caran ji bo tÃªgihiÅŸtina nivÃ®sÃª, vegerÃ®n, Ã» bersivdan tÃªne bikar anÃ®n. ModelÃªn Ã§Ãªkirina nivÃ®sÃª pir caran ji bo dÃ®menÃªn mezin yÃªn nivÃ®sÃª, wekÃ® [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), tÃªne fÃªr kirin, Ã» dikarin nivÃ®sa nÃ» Ã§Ãªbikin, an bersivan bidin. ModelÃªn Ã§Ãªkirina koda, wekÃ® [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), pir caran ji bo dÃ®menÃªn mezin yÃªn koda, wekÃ® GitHub, tÃªne fÃªr kirin, Ã» dikarin koda nÃ» Ã§Ãªbikin, an Ã§ewtÃ®yan di koda heyÃ® de Ã§Ãªbikin.

![Ã‡Ãªkirina NivÃ®sÃª Ã» Koda](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.mo.png)

### Encoder-Decoder versus Encoder-only

Ji bo bÃ®ranÃ®na cÃ»rÃªn cuda yÃªn bingehÃ®nÃªn LLM, em analogiyek bikar tÃ®nin.

ImkanÃª ku serokÃª hÃ»nÃª we taskek ji bo nivÃ®sarÃªn xwendekarÃªn binivÃ®se. HÃ»n du hevkar hene; yek li ser Ã§Ãªkirina peyvÃªn li hemberÃ® wÃªne ye Ã» yÃª din li ser vegerandinÃª ye.

Ã‡ÃªkerÃª peyvÃªn di xebitandinÃª de wekÃ® modelÃª Encoder-only ye, ew dikarin tema bibÃ®nin Ã» bibÃ®nin Ã§i hÃ»n pÃªÅŸnÃ®yar kirin Ã» paÅŸÃª ew dikarin kursÃª li ser wÃªne Ã§Ãªbikin. Ew di Ã§Ãªkirina peyvÃªn girÃªdayÃ® Ã» agahdar pir baÅŸ in, lÃª ew di tÃªgihiÅŸtina tema Ã» armancÃªn fÃªrkirinÃª de ne baÅŸ in. Hene mÃ®nakÃªn modelÃªn Encoder ne modelÃªn GPT family, wekÃ® GPT-3.

RehberÃª di Ã§Ãªkirina vegerandinÃª de wekÃ® modelÃª Encoder-only ye, ew tema Ã» bersivÃªn li ser kursÃª tÃªne vegerandin, li peyvÃªn di navbera wan de tÃªgihiÅŸtin Ã» agahdar tÃªne kirin, lÃª ew di Ã§Ãªkirina peyvÃªn de ne baÅŸ in. MÃ®nak ji modelÃª Encoder-only bernameyÃª BERT ye.

ImkanÃª ku hÃ»n kesek jÃ® hene ku dikare peyvÃªn Ã§Ãªbikin Ã» vegerandin, ev modelÃª Encoder-Decoder ye. Hene mÃ®nakÃªn hwd. BART Ã» T5 ne.

### Xizmet versus Model

Niha, em bi tenÃª di navbera xizmet Ã» modelÃª de peyivÃ®n bikar anÃ®n. XizmetÃª pÃªÅŸnÃ®yarek e ku ji aliyÃª PÃªÅŸkÃªÅŸkarÃª Xizmeta Cloud tÃªne pÃªÅŸkÃªÅŸ kirin, Ã» pir caran li ser modelÃªn, daneyÃªn, Ã» hwd. tÃªne pÃªÅŸkÃªÅŸ kirin. ModelÃª bingehÃª xizmetÃª ye, Ã» pir caran modelÃª bingehÃ®n e, wekÃ® LLM.

XizmetÃªn pir caran ji bo bikar anÃ®nÃª di pÃªÅŸnÃ®yarkirinÃª de tÃªne taybetandin Ã» pir caran hÃªsan in ku tÃªne bikar anÃ®n, bi ÅŸopandina GUI. LÃª xizmetÃªn pir caran ne bi belaÅŸ tÃªne pÃªÅŸkÃªÅŸ kirin, Ã» dikarin xwerÃ»ya an tÃªvÃ® dayÃ®nÃª hewce bÃ»n, di pÃªÅŸnÃ®yarkirinÃª de biÅŸopÃ®ne. MÃ®nak ji xizmetÃª pÃª
- Bandingkan tolok ukur di seluruh model dan dataset yang tersedia di industri untuk menilai mana yang memenuhi skenario bisnis, melalui panel [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.mo.png)

- Sesuaikan model dengan data pelatihan khusus untuk meningkatkan kinerja model dalam beban kerja tertentu, dengan memanfaatkan kemampuan eksperimen dan pelacakan dari Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.mo.png)

- Sebarkan model pra-terlatih asli atau versi yang telah disesuaikan ke inferensi waktu nyata yang dikelola secara remote - komputasi terkelola - atau endpoint api tanpa server - [bayar sesuai penggunaan](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - untuk memungkinkan aplikasi menggunakannya.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.mo.png)

> [!NOTE]
> Tidak semua model dalam katalog saat ini tersedia untuk penyesuaian dan/atau penyebaran bayar sesuai penggunaan. Periksa kartu model untuk detail tentang kemampuan dan keterbatasan model.

## Meningkatkan Hasil LLM

Kami telah menjelajahi dengan tim startup kami berbagai jenis LLM dan Platform Cloud (Azure Machine Learning) yang memungkinkan kami membandingkan model yang berbeda, mengevaluasi mereka pada data uji, meningkatkan kinerja dan menyebarkannya pada endpoint inferensi.

Tetapi kapan mereka harus mempertimbangkan untuk menyempurnakan model daripada menggunakan yang pra-terlatih? Apakah ada pendekatan lain untuk meningkatkan kinerja model dalam beban kerja tertentu?

Ada beberapa pendekatan yang dapat digunakan bisnis untuk mendapatkan hasil yang mereka butuhkan dari LLM. Anda dapat memilih berbagai jenis model dengan tingkat pelatihan yang berbeda saat menyebarkan LLM dalam produksi, dengan tingkat kompleksitas, biaya, dan kualitas yang berbeda. Berikut adalah beberapa pendekatan berbeda:

- **Rekayasa prompt dengan konteks**. Idenya adalah memberikan konteks yang cukup saat Anda memberikan prompt untuk memastikan Anda mendapatkan respons yang Anda butuhkan.

- **Retrieval Augmented Generation, RAG**. Data Anda mungkin ada dalam database atau endpoint web misalnya, untuk memastikan data ini, atau subset darinya, disertakan pada saat memberikan prompt, Anda dapat mengambil data yang relevan dan menjadikannya bagian dari prompt pengguna.

- **Model yang disesuaikan**. Di sini, Anda melatih model lebih lanjut dengan data Anda sendiri yang membuat model lebih tepat dan responsif terhadap kebutuhan Anda tetapi mungkin mahal.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.mo.png)

Sumber gambar: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Rekayasa Prompt dengan Konteks

LLM yang pra-terlatih bekerja sangat baik pada tugas bahasa alami yang umum, bahkan dengan memanggil mereka dengan prompt pendek, seperti kalimat untuk diselesaikan atau pertanyaan â€“ yang disebut pembelajaran â€œzero-shotâ€.

Namun, semakin banyak pengguna dapat membingkai pertanyaan mereka, dengan permintaan dan contoh yang terperinci â€“ Konteks â€“ semakin akurat dan sesuai dengan harapan pengguna jawaban akan menjadi. Dalam kasus ini, kita berbicara tentang pembelajaran â€œone-shotâ€ jika prompt hanya mencakup satu contoh dan â€œfew-shot learningâ€ jika mencakup beberapa contoh.
Rekayasa prompt dengan konteks adalah pendekatan paling hemat biaya untuk memulai.

### Retrieval Augmented Generation (RAG)

LLM memiliki batasan bahwa mereka hanya dapat menggunakan data yang telah digunakan selama pelatihan mereka untuk menghasilkan jawaban. Ini berarti bahwa mereka tidak tahu apa pun tentang fakta yang terjadi setelah proses pelatihan mereka, dan mereka tidak dapat mengakses informasi non-publik (seperti data perusahaan).
Ini dapat diatasi melalui RAG, sebuah teknik yang memperkuat prompt dengan data eksternal dalam bentuk potongan dokumen, mempertimbangkan batas panjang prompt. Ini didukung oleh alat basis data Vector (seperti [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) yang mengambil potongan yang berguna dari berbagai sumber data yang telah ditentukan dan menambahkannya ke Konteks prompt.

Teknik ini sangat membantu ketika bisnis tidak memiliki cukup data, cukup waktu, atau sumber daya untuk menyempurnakan LLM, tetapi masih ingin meningkatkan kinerja pada beban kerja tertentu dan mengurangi risiko fabrikasi, yaitu, mistifikasi realitas atau konten berbahaya.

### Model yang Disesuaikan

Penyesuaian adalah proses yang memanfaatkan pembelajaran transfer untuk â€˜mengadaptasiâ€™ model ke tugas hilir atau untuk menyelesaikan masalah tertentu. Berbeda dari pembelajaran few-shot dan RAG, ini menghasilkan model baru yang dihasilkan, dengan bobot dan bias yang diperbarui. Ini membutuhkan serangkaian contoh pelatihan yang terdiri dari satu input (prompt) dan output terkaitnya (penyelesaian).
Ini akan menjadi pendekatan yang disukai jika:

- **Menggunakan model yang disesuaikan**. Bisnis ingin menggunakan model yang disesuaikan yang kurang mampu (seperti model embedding) daripada model berkinerja tinggi, menghasilkan solusi yang lebih hemat biaya dan cepat.

- **Mempertimbangkan latensi**. Latensi penting untuk kasus penggunaan tertentu, jadi tidak mungkin menggunakan prompt yang sangat panjang atau jumlah contoh yang harus dipelajari dari model tidak sesuai dengan batas panjang prompt.

- **Tetap up to date**. Bisnis memiliki banyak data berkualitas tinggi dan label kebenaran dasar serta sumber daya yang diperlukan untuk mempertahankan data ini tetap up to date dari waktu ke waktu.

### Model Terlatih

Melatih LLM dari awal adalah tanpa ragu pendekatan yang paling sulit dan paling kompleks untuk diadopsi, membutuhkan jumlah data yang sangat besar, sumber daya yang terampil, dan kekuatan komputasi yang tepat. Opsi ini harus dipertimbangkan hanya dalam skenario di mana bisnis memiliki kasus penggunaan khusus domain dan sejumlah besar data yang berpusat pada domain.

## Pemeriksaan Pengetahuan

Apa yang bisa menjadi pendekatan yang baik untuk meningkatkan hasil penyelesaian LLM?

1. Rekayasa prompt dengan konteks
1. RAG
1. Model yang disesuaikan

A:3, jika Anda memiliki waktu dan sumber daya serta data berkualitas tinggi, penyesuaian adalah opsi yang lebih baik untuk tetap up to date. Namun, jika Anda ingin meningkatkan hal-hal dan Anda kekurangan waktu, ada baiknya mempertimbangkan RAG terlebih dahulu.

## ğŸš€ Tantangan

Baca lebih lanjut tentang bagaimana Anda dapat [menggunakan RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) untuk bisnis Anda.

## Kerja Hebat, Lanjutkan Pembelajaran Anda

Setelah menyelesaikan pelajaran ini, lihat koleksi [Pembelajaran AI Generatif](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kami untuk terus meningkatkan pengetahuan AI Generatif Anda!

Lanjutkan ke Pelajaran 3 di mana kita akan melihat bagaimana [membangun dengan AI Generatif secara Bertanggung Jawab](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

I'm sorry, but I'm not familiar with a language called "mo." If you meant a specific language, could you please clarify or provide more details?