{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "為了運行以下筆記本，如果你還沒有設定，需要在 .env 文件中將 openai 金鑰設為 `OPENAI_API_KEY`。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下來，我們將把嵌入索引載入到 Pandas 資料框中。嵌入索引儲存在一個名為 `embedding_index_3m.json` 的 JSON 檔案中。嵌入索引包含截至 2023 年 10 月底的每個 YouTube 逐字稿的嵌入向量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接著，我們將建立一個名為 `get_videos` 的函數，用來在嵌入索引中搜尋查詢。該函數會回傳與查詢最相似的前 5 部影片。函數的運作方式如下：\n",
    "\n",
    "1. 首先，建立嵌入索引的副本。\n",
    "2. 接著，使用 OpenAI 嵌入 API 計算查詢的嵌入向量。\n",
    "3. 然後，在嵌入索引中建立一個名為 `similarity` 的新欄位。`similarity` 欄位包含查詢嵌入向量與每個影片片段嵌入向量之間的餘弦相似度。\n",
    "4. 接著，根據 `similarity` 欄位篩選嵌入索引。只保留餘弦相似度大於或等於 0.75 的影片。\n",
    "5. 最後，根據 `similarity` 欄位排序嵌入索引，並回傳前 5 部影片。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這個函數非常簡單，它只是打印出搜索查詢的結果。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 首先，將嵌入索引加載到 Pandas Dataframe 中。\n",
    "2. 接著，系統會提示用戶輸入查詢。\n",
    "3. 然後呼叫 `get_videos` 函數在嵌入索引中搜尋查詢內容。\n",
    "4. 最後呼叫 `display_results` 函數將結果顯示給用戶。\n",
    "5. 接著系統會提示用戶輸入另一個查詢。此過程會持續，直到用戶輸入 `exit`。\n",
    "\n",
    "![](../../../../translated_images/mo/notebook-search.1e320b9c7fcbb0bc.webp)\n",
    "\n",
    "系統會提示你輸入查詢。輸入查詢後按下 Enter。應用程式會返回與查詢相關的影片清單。應用程式也會返回影片中答案所在位置的連結。\n",
    "\n",
    "以下是一些可嘗試的查詢：\n",
    "\n",
    "- 甚麼是 Azure Machine Learning？\n",
    "- 卷積神經網絡如何運作？\n",
    "- 甚麼是神經網絡？\n",
    "- 我可以在 Azure Machine Learning 中使用 Jupyter Notebooks 嗎？\n",
    "- 甚麼是 ONNX？\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免責聲明**：\n本文件係使用人工智能翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我哋致力於確保準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件之母語版本應視為權威來源。對於重要資訊，建議採用專業人工翻譯。我哋對因使用本翻譯而引致之任何誤解或誤釋概不負責。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T09:10:30+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "mo"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}