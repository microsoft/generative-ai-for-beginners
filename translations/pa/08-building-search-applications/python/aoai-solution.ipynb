{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਹੇਠਾਂ ਦਿੱਤੇ ਨੋਟਬੁੱਕ ਚਲਾਉਣ ਲਈ, ਜੇਕਰ ਤੁਸੀਂ ਹਜੇ ਤੱਕ ਨਹੀਂ ਕੀਤਾ, ਤਾਂ ਤੁਹਾਨੂੰ ਇੱਕ ਮਾਡਲ ਡਿਪਲੋਇ ਕਰਨ ਦੀ ਲੋੜ ਹੈ ਜੋ `text-embedding-ada-002` ਨੂੰ ਬੇਸ ਮਾਡਲ ਵਜੋਂ ਵਰਤਦਾ ਹੈ ਅਤੇ ਡਿਪਲੋਇਮੈਂਟ ਨਾਂ .env ਫਾਈਲ ਵਿੱਚ `AZURE_OPENAI_EMBEDDINGS_ENDPOINT` ਵਜੋਂ ਸੈੱਟ ਕਰਨਾ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-05-15\"\n",
    "  )\n",
    "\n",
    "model = os.environ['AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT']\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਅਗਲੇ ਕਦਮ ਵਿੱਚ, ਅਸੀਂ Embedding Index ਨੂੰ Pandas Dataframe ਵਿੱਚ ਲੋਡ ਕਰਨ ਜਾ ਰਹੇ ਹਾਂ। Embedding Index ਇੱਕ JSON ਫਾਈਲ `embedding_index_3m.json` ਵਿੱਚ ਸਟੋਰ ਕੀਤਾ ਗਿਆ ਹੈ। Embedding Index ਵਿੱਚ ਹਰ ਇੱਕ YouTube ਟ੍ਰਾਂਸਕ੍ਰਿਪਟ ਲਈ Embeddings ਹਨ, ਜੋ ਅਕਤੂਬਰ 2023 ਦੇ ਅੰਤ ਤੱਕ ਦੇ ਹਨ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਅਗਲੇ ਕਦਮ ਵਜੋਂ, ਅਸੀਂ ਇੱਕ ਫੰਕਸ਼ਨ ਬਣਾਉਣ ਜਾ ਰਹੇ ਹਾਂ ਜਿਸਦਾ ਨਾਮ `get_videos` ਹੋਵੇਗਾ, ਜੋ ਕਿ ਕੁਐਰੀ ਲਈ Embedding Index ਵਿੱਚ ਖੋਜ ਕਰੇਗਾ। ਇਹ ਫੰਕਸ਼ਨ ਉਹ ਪੰਜ ਵੀਡੀਓਜ਼ ਵਾਪਸ ਕਰੇਗਾ ਜੋ ਕੁਐਰੀ ਨਾਲ ਸਭ ਤੋਂ ਵੱਧ ਮਿਲਦੀਆਂ ਹਨ। ਇਹ ਫੰਕਸ਼ਨ ਹੇਠਾਂ ਦਿੱਤੇ ਤਰੀਕੇ ਨਾਲ ਕੰਮ ਕਰਦਾ ਹੈ:\n",
    "\n",
    "1. ਸਭ ਤੋਂ ਪਹਿਲਾਂ, Embedding Index ਦੀ ਇੱਕ ਕਾਪੀ ਬਣਾਈ ਜਾਂਦੀ ਹੈ।\n",
    "2. ਫਿਰ, ਕੁਐਰੀ ਲਈ Embedding OpenAI Embedding API ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਕਲਕੁਲੇਟ ਕੀਤਾ ਜਾਂਦਾ ਹੈ।\n",
    "3. ਇਸ ਤੋਂ ਬਾਅਦ, Embedding Index ਵਿੱਚ ਇੱਕ ਨਵਾਂ ਕਾਲਮ ਬਣਾਇਆ ਜਾਂਦਾ ਹੈ ਜਿਸਦਾ ਨਾਮ `similarity` ਹੈ। `similarity` ਕਾਲਮ ਵਿੱਚ ਕੁਐਰੀ Embedding ਅਤੇ ਹਰ ਵੀਡੀਓ ਸੈਗਮੈਂਟ ਦੀ Embedding ਵਿਚਕਾਰ cosine similarity ਹੁੰਦੀ ਹੈ।\n",
    "4. ਫਿਰ, Embedding Index ਨੂੰ `similarity` ਕਾਲਮ ਰਾਹੀਂ ਫਿਲਟਰ ਕੀਤਾ ਜਾਂਦਾ ਹੈ। Embedding Index ਨੂੰ ਇਸ ਤਰ੍ਹਾਂ ਫਿਲਟਰ ਕੀਤਾ ਜਾਂਦਾ ਹੈ ਕਿ ਸਿਰਫ ਉਹ ਵੀਡੀਓਜ਼ ਹੀ ਸ਼ਾਮਲ ਹੋਣ ਜਿਨ੍ਹਾਂ ਦੀ cosine similarity 0.75 ਜਾਂ ਇਸ ਤੋਂ ਵੱਧ ਹੋਵੇ।\n",
    "5. ਆਖ਼ਰ ਵਿੱਚ, Embedding Index ਨੂੰ `similarity` ਕਾਲਮ ਮੁਤਾਬਕ sort ਕੀਤਾ ਜਾਂਦਾ ਹੈ ਅਤੇ ਸਭ ਤੋਂ ਉੱਤੇ ਵਾਲੀਆਂ 5 ਵੀਡੀਓਜ਼ ਵਾਪਸ ਕਰ ਦਿੱਤੀਆਂ ਜਾਂਦੀਆਂ ਹਨ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    if len(a) > len(b):\n",
    "        b = np.pad(b, (0, len(a) - len(b)), 'constant')\n",
    "    elif len(b) > len(a):\n",
    "        a = np.pad(a, (0, len(b) - len(a)), 'constant')\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਇਹ ਫੰਕਸ਼ਨ ਬਹੁਤ ਸਧਾਰਣ ਹੈ, ਇਹ ਸਿਰਫ਼ ਖੋਜ ਪ੍ਰਸ਼ਨ ਦੇ ਨਤੀਜੇ ਪ੍ਰਿੰਟ ਕਰਦਾ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ਸਭ ਤੋਂ ਪਹਿਲਾਂ, Embedding Index ਨੂੰ Pandas Dataframe ਵਿੱਚ ਲੋਡ ਕੀਤਾ ਜਾਂਦਾ ਹੈ।\n",
    "2. ਅਗਲੇ ਕਦਮ 'ਚ, ਯੂਜ਼ਰ ਨੂੰ ਇੱਕ ਕੁਇਰੀ ਦਰਜ ਕਰਨ ਲਈ ਕਿਹਾ ਜਾਂਦਾ ਹੈ।\n",
    "3. ਫਿਰ `get_videos` ਫੰਕਸ਼ਨ ਨੂੰ ਕਾਲ ਕਰਕੇ Embedding Index ਵਿੱਚੋਂ ਕੁਇਰੀ ਲਈ ਖੋਜ ਕੀਤੀ ਜਾਂਦੀ ਹੈ।\n",
    "4. ਆਖਰ ਵਿੱਚ, `display_results` ਫੰਕਸ਼ਨ ਨੂੰ ਕਾਲ ਕਰਕੇ ਨਤੀਜੇ ਯੂਜ਼ਰ ਨੂੰ ਵਿਖਾਏ ਜਾਂਦੇ ਹਨ।\n",
    "5. ਫਿਰ ਯੂਜ਼ਰ ਨੂੰ ਇੱਕ ਹੋਰ ਕੁਇਰੀ ਦਰਜ ਕਰਨ ਲਈ ਕਿਹਾ ਜਾਂਦਾ ਹੈ। ਇਹ ਪ੍ਰਕਿਰਿਆ ਤਦ ਤੱਕ ਚੱਲਦੀ ਰਹਿੰਦੀ ਹੈ ਜਦ ਤੱਕ ਯੂਜ਼ਰ `exit` ਨਹੀਂ ਲਿਖਦਾ।\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.pa.png)\n",
    "\n",
    "ਤੁਹਾਨੂੰ ਇੱਕ ਕੁਇਰੀ ਦਰਜ ਕਰਨ ਲਈ ਕਿਹਾ ਜਾਵੇਗਾ। ਆਪਣੀ ਕੁਇਰੀ ਲਿਖੋ ਅਤੇ ਐਂਟਰ ਦਬਾਓ। ਐਪਲੀਕੇਸ਼ਨ ਤੁਹਾਡੀ ਕੁਇਰੀ ਨਾਲ ਸੰਬੰਧਤ ਵੀਡੀਓਜ਼ ਦੀ ਲਿਸਟ ਵਾਪਸ ਕਰੇਗੀ। ਐਪਲੀਕੇਸ਼ਨ ਤੁਹਾਨੂੰ ਵੀਡੀਓ ਵਿੱਚ ਉਸ ਥਾਂ ਦਾ ਲਿੰਕ ਵੀ ਦੇਵੇਗੀ ਜਿੱਥੇ ਸਵਾਲ ਦਾ ਜਵਾਬ ਮਿਲਦਾ ਹੈ।\n",
    "\n",
    "ਇਹ ਕੁਝ ਉਦਾਹਰਨੀ ਕੁਇਰੀਆਂ ਹਨ, ਜੋ ਤੁਸੀਂ ਅਜ਼ਮਾਈਆਂ:\n",
    "\n",
    "- Azure Machine Learning ਕੀ ਹੈ?\n",
    "- Convolutional neural networks ਕਿਵੇਂ ਕੰਮ ਕਰਦੀਆਂ ਹਨ?\n",
    "- Neural network ਕੀ ਹੈ?\n",
    "- ਕੀ ਮੈਂ Jupyter Notebooks ਨੂੰ Azure Machine Learning ਨਾਲ ਵਰਤ ਸਕਦਾ ਹਾਂ?\n",
    "- ONNX ਕੀ ਹੈ?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ਅਸਵੀਕਰਨ**:  \nਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਅਸੀਂ ਯਥਾਸੰਭਵ ਸਹੀ ਅਨੁਵਾਦ ਕਰਨ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਪਰ ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਵਿੱਚ ਰੱਖੋ ਕਿ ਆਟੋਮੈਟਿਕ ਅਨੁਵਾਦ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਣਪੂਰੀ ਜਾਣਕਾਰੀ ਹੋ ਸਕਦੀ ਹੈ। ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੌਜੂਦ ਅਸਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਹੀ ਅਧਿਕਾਰਤ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫ਼ਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਹੋਣ ਵਾਲੀਆਂ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "32c6b8e9e87156b9c63ee62a6fd7f526",
   "translation_date": "2025-08-25T18:42:14+00:00",
   "source_file": "08-building-search-applications/python/aoai-solution.ipynb",
   "language_code": "pa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}