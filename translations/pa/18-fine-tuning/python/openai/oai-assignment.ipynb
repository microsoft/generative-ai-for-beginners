{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open AI ਮਾਡਲਾਂ ਦੀ ਫਾਈਨ ਟਿਊਨਿੰਗ\n",
    "\n",
    "ਇਹ ਨੋਟਬੁੱਕ Open AI ਵੱਲੋਂ ਦਿੱਤੀ ਗਈ [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) ਡੌਕਯੂਮੈਂਟੇਸ਼ਨ 'ਤੇ ਆਧਾਰਿਤ ਹੈ।\n",
    "\n",
    "ਫਾਈਨ-ਟਿਊਨਿੰਗ ਤੁਹਾਡੇ ਐਪਲੀਕੇਸ਼ਨ ਲਈ ਫਾਊਂਡੇਸ਼ਨ ਮਾਡਲਾਂ ਦੀ ਕਾਰਗੁਜ਼ਾਰੀ ਨੂੰ ਸੁਧਾਰਦੀ ਹੈ, ਕਿਉਂਕਿ ਇਹ ਮਾਡਲ ਨੂੰ ਵਾਧੂ ਡਾਟਾ ਅਤੇ ਉਸ ਖਾਸ ਕੇਸ ਜਾਂ ਸਨਾਰੀਓ ਨਾਲ ਸੰਬੰਧਤ ਸੰਦਰਭ ਨਾਲ ਮੁੜ-ਟ੍ਰੇਨ ਕਰਦੀ ਹੈ। ਧਿਆਨ ਦਿਓ ਕਿ ਪ੍ਰੌਂਪਟ ਇੰਜੀਨੀਅਰਿੰਗ ਤਕਨੀਕਾਂ ਜਿਵੇਂ ਕਿ _few shot learning_ ਅਤੇ _retrieval augmented generation_ ਤੁਹਾਨੂੰ ਮੂਲ ਪ੍ਰੌਂਪਟ ਵਿੱਚ ਸੰਬੰਧਤ ਡਾਟਾ ਸ਼ਾਮਲ ਕਰਕੇ ਕੁਆਲਟੀ ਵਧਾਉਣ ਦੀ ਆਗਿਆ ਦਿੰਦੀਆਂ ਹਨ। ਪਰ, ਇਹ ਤਰੀਕੇ ਟਾਰਗਟ ਕੀਤੇ ਫਾਊਂਡੇਸ਼ਨ ਮਾਡਲ ਦੀ ਵੱਧ ਤੋਂ ਵੱਧ ਟੋਕਨ ਵਿੰਡੋ ਸਾਈਜ਼ ਤੱਕ ਸੀਮਤ ਹਨ।\n",
    "\n",
    "ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨਾਲ, ਅਸੀਂ ਮਾਡਲ ਨੂੰ ਲੋੜੀਂਦੇ ਡਾਟਾ ਨਾਲ ਮੁੜ-ਟ੍ਰੇਨ ਕਰ ਰਹੇ ਹਾਂ (ਜਿਸ ਨਾਲ ਅਸੀਂ ਵੱਧ ਉਦਾਹਰਣਾਂ ਵਰਤ ਸਕਦੇ ਹਾਂ, ਜਿੰਨੀਆਂ ਕਿ ਵੱਧ ਤੋਂ ਵੱਧ ਟੋਕਨ ਵਿੰਡੋ ਵਿੱਚ ਨਹੀਂ ਆ ਸਕਦੀਆਂ) - ਅਤੇ ਇੱਕ _ਕਸਟਮ_ ਵਰਜਨ ਮਾਡਲ ਦਾ ਡਿਪਲੌਇ ਕਰਦੇ ਹਾਂ, ਜਿਸਨੂੰ ਹੁਣ ਇਨਫਰੈਂਸ ਸਮੇਂ ਉਦਾਹਰਣਾਂ ਦੀ ਲੋੜ ਨਹੀਂ ਰਹਿੰਦੀ। ਇਹ ਸਿਰਫ ਸਾਡੇ ਪ੍ਰੌਂਪਟ ਡਿਜ਼ਾਈਨ ਦੀ ਪ੍ਰਭਾਵਸ਼ੀਲਤਾ ਨੂੰ ਹੀ ਨਹੀਂ ਵਧਾਉਂਦਾ (ਸਾਨੂੰ ਟੋਕਨ ਵਿੰਡੋ ਹੋਰ ਕੰਮਾਂ ਲਈ ਵਰਤਣ ਵਿੱਚ ਵੱਧ ਲਚਕ ਮਿਲਦੀ ਹੈ) ਸਗੋਂ ਇਹ ਸਾਡੇ ਖਰਚਿਆਂ ਨੂੰ ਵੀ ਘਟਾ ਸਕਦਾ ਹੈ (ਕਿਉਂਕਿ ਇਨਫਰੈਂਸ ਸਮੇਂ ਮਾਡਲ ਨੂੰ ਭੇਜੇ ਜਾਣ ਵਾਲੇ ਟੋਕਨ ਦੀ ਗਿਣਤੀ ਘੱਟ ਜਾਂਦੀ ਹੈ)।\n",
    "\n",
    "ਫਾਈਨ ਟਿਊਨਿੰਗ ਦੇ 4 ਕਦਮ ਹਨ:\n",
    "1. ਟ੍ਰੇਨਿੰਗ ਡਾਟਾ ਤਿਆਰ ਕਰੋ ਅਤੇ ਅੱਪਲੋਡ ਕਰੋ।\n",
    "1. ਟ੍ਰੇਨਿੰਗ ਜੌਬ ਚਲਾਓ ਤਾਂ ਜੋ ਫਾਈਨ-ਟਿਊਨਡ ਮਾਡਲ ਮਿਲੇ।\n",
    "1. ਫਾਈਨ-ਟਿਊਨਡ ਮਾਡਲ ਦਾ ਮੁਲਾਂਕਣ ਕਰੋ ਅਤੇ ਕੁਆਲਟੀ ਲਈ ਦੁਹਰਾਓ।\n",
    "1. ਜਦੋਂ ਤੱਕ ਸੰਤੁਸ਼ਟ ਨਾ ਹੋਵੋ, ਫਾਈਨ-ਟਿਊਨਡ ਮਾਡਲ ਨੂੰ ਇਨਫਰੈਂਸ ਲਈ ਡਿਪਲੌਇ ਕਰੋ।\n",
    "\n",
    "ਧਿਆਨ ਦਿਓ ਕਿ ਹਰ ਫਾਊਂਡੇਸ਼ਨ ਮਾਡਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੂੰ ਸਪੋਰਟ ਨਹੀਂ ਕਰਦੇ - [OpenAI ਡੌਕਯੂਮੈਂਟੇਸ਼ਨ ਵੇਖੋ](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) ਤਾਜ਼ਾ ਜਾਣਕਾਰੀ ਲਈ। ਤੁਸੀਂ ਪਹਿਲਾਂ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਮਾਡਲ ਵੀ ਮੁੜ-ਫਾਈਨ-ਟਿਊਨ ਕਰ ਸਕਦੇ ਹੋ। ਇਸ ਟਿਊਟੋਰਿਅਲ ਵਿੱਚ, ਅਸੀਂ `gpt-35-turbo` ਨੂੰ ਆਪਣਾ ਟਾਰਗਟ ਫਾਊਂਡੇਸ਼ਨ ਮਾਡਲ ਵਜੋਂ ਫਾਈਨ-ਟਿਊਨ ਕਰਨ ਲਈ ਵਰਤਾਂਗੇ।\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 1.1: ਆਪਣਾ ਡੇਟਾ ਸੈੱਟ ਤਿਆਰ ਕਰੋ\n",
    "\n",
    "ਆਓ ਇੱਕ ਚੈਟਬੋਟ ਬਣਾਈਏ ਜੋ ਤੁਹਾਡੀ ਮਦਦ ਕਰੇ ਕਿ ਤੁਸੀਂ ਪੀਰੀਆਡਿਕ ਟੇਬਲ ਦੇ ਤੱਤਾਂ ਨੂੰ ਸਮਝ ਸਕੋ, ਜਿਸ ਵਿੱਚ ਉਹ ਕਿਸੇ ਤੱਤ ਬਾਰੇ ਸਵਾਲ ਦਾ ਜਵਾਬ ਇੱਕ ਲਾਈਮਰਿਕ ਰੂਪ ਵਿੱਚ ਦੇਵੇ। _ਇਸ_ ਸਧਾਰਣ ਟਿਊਟੋਰਿਅਲ ਵਿੱਚ, ਅਸੀਂ ਸਿਰਫ਼ ਇੱਕ ਡੇਟਾ ਸੈੱਟ ਬਣਾਵਾਂਗੇ ਜਿਸ ਨਾਲ ਮਾਡਲ ਨੂੰ ਕੁਝ ਨਮੂਨਾ ਜਵਾਬਾਂ ਦੇ ਕੇ ਟ੍ਰੇਨ ਕੀਤਾ ਜਾਵੇ, ਤਾਂ ਜੋ ਡੇਟਾ ਦੇ ਉਮੀਦਵਾਰ ਫਾਰਮੈਟ ਨੂੰ ਵਿਖਾਇਆ ਜਾ ਸਕੇ। ਅਸਲ ਜ਼ਿੰਦਗੀ ਵਿੱਚ, ਤੁਹਾਨੂੰ ਕਈ ਹੋਰ ਉਦਾਹਰਣਾਂ ਨਾਲ ਡੇਟਾ ਸੈੱਟ ਬਣਾਉਣੀ ਪਵੇਗੀ। ਜੇਕਰ ਤੁਹਾਡੇ ਐਪਲੀਕੇਸ਼ਨ ਖੇਤਰ ਲਈ ਕੋਈ ਖੁੱਲ੍ਹਾ ਡੇਟਾ ਸੈੱਟ ਮੌਜੂਦ ਹੈ, ਤਾਂ ਤੁਸੀਂ ਉਹ ਵੀ ਵਰਤ ਸਕਦੇ ਹੋ ਅਤੇ ਉਸਨੂੰ fine-tuning ਲਈ ਮੁੜ-ਫਾਰਮੈਟ ਕਰ ਸਕਦੇ ਹੋ।\n",
    "\n",
    "ਕਿਉਂਕਿ ਅਸੀਂ `gpt-35-turbo` ਉੱਤੇ ਧਿਆਨ ਕੇਂਦਰਤ ਕਰ ਰਹੇ ਹਾਂ ਅਤੇ ਇੱਕ ਸਿੰਗਲ-ਟਰਨ ਜਵਾਬ (chat completion) ਚਾਹੁੰਦੇ ਹਾਂ, ਅਸੀਂ [ਇਸ ਸੁਝਾਏ ਫਾਰਮੈਟ](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) ਅਨੁਸਾਰ ਉਦਾਹਰਣਾਂ ਤਿਆਰ ਕਰ ਸਕਦੇ ਹਾਂ, ਜੋ OpenAI chat completion ਦੀਆਂ ਲੋੜਾਂ ਨੂੰ ਦਰਸਾਉਂਦਾ ਹੈ। ਜੇਕਰ ਤੁਸੀਂ ਬਹੁ-ਟਰਨ ਗੱਲਬਾਤੀ ਸਮੱਗਰੀ ਦੀ ਉਮੀਦ ਕਰਦੇ ਹੋ, ਤਾਂ ਤੁਸੀਂ [multi-turn example format](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) ਵਰਤੋਂਗੇ, ਜਿਸ ਵਿੱਚ `weight` ਪੈਰਾਮੀਟਰ ਵੀ ਹੁੰਦਾ ਹੈ, ਜੋ ਦੱਸਦਾ ਹੈ ਕਿ fine-tuning ਦੌਰਾਨ ਕਿਹੜੇ ਸੁਨੇਹੇ ਵਰਤੇ ਜਾਣ (ਜਾਂ ਨਾ ਵਰਤੇ ਜਾਣ)।\n",
    "\n",
    "ਇੱਥੇ ਅਸੀਂ ਆਪਣੇ ਟਿਊਟੋਰਿਅਲ ਲਈ ਸਧਾਰਣ ਸਿੰਗਲ-ਟਰਨ ਫਾਰਮੈਟ ਵਰਤਾਂਗੇ। ਡੇਟਾ [jsonl ਫਾਰਮੈਟ](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) ਵਿੱਚ ਹੈ, ਜਿਸ ਵਿੱਚ ਹਰ ਲਾਈਨ ਉੱਤੇ 1 ਰਿਕਾਰਡ ਹੁੰਦਾ ਹੈ, ਅਤੇ ਹਰ ਰਿਕਾਰਡ ਇੱਕ JSON-ਫਾਰਮੈਟ ਆਬਜੈਕਟ ਵਜੋਂ ਹੁੰਦਾ ਹੈ। ਹੇਠਾਂ ਦਿੱਤਾ ਟੁਕੜਾ 2 ਨਮੂਨਾ ਰਿਕਾਰਡ ਦਿਖਾਉਂਦਾ ਹੈ - ਪੂਰਾ ਨਮੂਨਾ ਸੈੱਟ (10 ਉਦਾਹਰਣਾਂ) ਲਈ [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) ਵੇਖੋ, ਜੋ ਅਸੀਂ ਆਪਣੇ fine-tuning ਟਿਊਟੋਰਿਅਲ ਲਈ ਵਰਤਾਂਗੇ। **ਨੋਟ:** ਹਰ ਰਿਕਾਰਡ _ਇੱਕ ਹੀ ਲਾਈਨ_ ਵਿੱਚ ਹੋਣਾ ਚਾਹੀਦਾ ਹੈ (ਜਿਵੇਂ ਕਿ ਆਮ JSON ਫਾਈਲ ਵਿੱਚ ਲਾਈਨਾਂ 'ਤੇ ਵੰਡਿਆ ਨਹੀਂ ਜਾਂਦਾ)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "ਅਸਲ ਵਰਤੋਂ ਵਿੱਚ ਵਧੀਆ ਨਤੀਜਿਆਂ ਲਈ ਤੁਹਾਨੂੰ ਕਾਫੀ ਵੱਡਾ ਉਦਾਹਰਣ ਸੈੱਟ ਚਾਹੀਦਾ ਹੋਵੇਗਾ - ਇੱਥੇ ਗੁਣਵੱਤਾ ਅਤੇ fine-tuning ਦੇ ਸਮੇਂ/ਖਰਚੇ ਵਿਚਕਾਰ ਸਮਝੌਤਾ ਕਰਨਾ ਪਵੇਗਾ। ਅਸੀਂ ਛੋਟਾ ਸੈੱਟ ਇਸ ਲਈ ਵਰਤ ਰਹੇ ਹਾਂ ਤਾਂ ਜੋ fine-tuning ਦੀ ਪ੍ਰਕਿਰਿਆ ਜਲਦੀ ਦਿਖਾਈ ਜਾ ਸਕੇ। ਹੋਰ ਪੇਚੀਦੇ fine-tuning ਟਿਊਟੋਰਿਅਲ ਲਈ [ਇਹ OpenAI Cookbook example](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) ਵੇਖੋ।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 1.2 ਆਪਣਾ ਡਾਟਾਸੈੱਟ ਅੱਪਲੋਡ ਕਰੋ\n",
    "\n",
    "Files API ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਡਾਟਾ ਅੱਪਲੋਡ ਕਰੋ [ਜਿਵੇਂ ਇੱਥੇ ਵੇਰਵਾ ਦਿੱਤਾ ਗਿਆ ਹੈ](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file)। ਧਿਆਨ ਦਿਓ ਕਿ ਇਹ ਕੋਡ ਚਲਾਉਣ ਤੋਂ ਪਹਿਲਾਂ ਤੁਹਾਨੂੰ ਹੇਠਾਂ ਦਿੱਤੇ ਕਦਮ ਕਰ ਲੈਣੇ ਚਾਹੀਦੇ ਹਨ:\n",
    " - `openai` Python ਪੈਕੇਜ ਇੰਸਟਾਲ ਕੀਤਾ ਹੋਵੇ (ਯਕੀਨੀ ਬਣਾਓ ਕਿ ਤੁਸੀਂ ਵਰਜਨ >=0.28.0 ਵਰਤ ਰਹੇ ਹੋ ਤਾਂ ਜੋ ਨਵੇਂ ਫੀਚਰ ਮਿਲਣ)\n",
    " - `OPENAI_API_KEY` ਇਨਵਾਇਰਨਮੈਂਟ ਵੈਰੀਏਬਲ ਨੂੰ ਆਪਣੇ OpenAI API ਕੁੰਜੀ ਨਾਲ ਸੈੱਟ ਕੀਤਾ ਹੋਵੇ\n",
    "ਹੋਰ ਜਾਣਕਾਰੀ ਲਈ, ਕੋਰਸ ਲਈ ਦਿੱਤੇ [ਸੈਟਅੱਪ ਗਾਈਡ](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) ਨੂੰ ਵੇਖੋ।\n",
    "\n",
    "ਹੁਣ, ਆਪਣੇ ਲੋਕਲ JSONL ਫਾਈਲ ਤੋਂ ਅੱਪਲੋਡ ਲਈ ਇੱਕ ਫਾਈਲ ਬਣਾਉਣ ਲਈ ਹੇਠਾਂ ਦਿੱਤਾ ਕੋਡ ਚਲਾਓ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 2.1: SDK ਨਾਲ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਜੌਬ ਬਣਾਓ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 2.2: ਨੌਕਰੀ ਦੀ ਸਥਿਤੀ ਚੈੱਕ ਕਰੋ\n",
    "\n",
    "ਇੱਥੇ ਕੁਝ ਕੰਮ ਹਨ ਜੋ ਤੁਸੀਂ `client.fine_tuning.jobs` API ਨਾਲ ਕਰ ਸਕਦੇ ਹੋ:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - ਆਖਰੀ n ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੌਕਰੀਆਂ ਦੀ ਸੂਚੀ ਵੇਖੋ\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - ਕਿਸੇ ਖਾਸ ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੌਕਰੀ ਦੀ ਜਾਣਕਾਰੀ ਲਵੋ\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - ਫਾਈਨ-ਟਿਊਨਿੰਗ ਨੌਕਰੀ ਰੱਦ ਕਰੋ\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - ਨੌਕਰੀ ਤੋਂ n ਤੱਕ ਦੇ ਇਵੈਂਟ ਵੇਖੋ\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "ਇਸ ਪ੍ਰਕਿਰਿਆ ਦਾ ਪਹਿਲਾ ਕਦਮ _ਟ੍ਰੇਨਿੰਗ ਫਾਈਲ ਦੀ ਜਾਂਚ ਕਰਨਾ_ ਹੈ ਤਾਂ ਜੋ ਯਕੀਨੀ ਬਣਾਇਆ ਜਾ ਸਕੇ ਕਿ ਡਾਟਾ ਠੀਕ ਫਾਰਮੈਟ ਵਿੱਚ ਹੈ।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 2.3: ਤਰੱਕੀ ਦੀ ਨਿਗਰਾਨੀ ਲਈ ਇਵੈਂਟ ਟ੍ਰੈਕ ਕਰੋ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 2.4: OpenAI ਡੈਸ਼ਬੋਰਡ ਵਿੱਚ ਸਥਿਤੀ ਵੇਖੋ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਤੁਸੀਂ OpenAI ਵੈੱਬਸਾਈਟ 'ਤੇ ਜਾ ਕੇ ਅਤੇ ਪਲੇਟਫਾਰਮ ਦੇ _Fine-tuning_ ਸੈਕਸ਼ਨ ਨੂੰ ਵੇਖ ਕੇ ਵੀ ਸਥਿਤੀ ਦੇਖ ਸਕਦੇ ਹੋ। ਇੱਥੇ ਤੁਹਾਨੂੰ ਮੌਜੂਦਾ ਜੌਬ ਦੀ ਸਥਿਤੀ ਦਿਖਾਈ ਦੇਵੇਗੀ, ਅਤੇ ਤੁਸੀਂ ਪਿਛਲੇ ਜੌਬ ਚਲਾਉਣ ਦੇ ਇਤਿਹਾਸ ਨੂੰ ਵੀ ਟਰੈਕ ਕਰ ਸਕਦੇ ਹੋ। ਇਸ ਸਕ੍ਰੀਨਸ਼ਾਟ ਵਿੱਚ, ਤੁਸੀਂ ਵੇਖ ਸਕਦੇ ਹੋ ਕਿ ਪਹਿਲਾ ਚਲਾਉਣਾ ਫੇਲ੍ਹ ਹੋ ਗਿਆ ਸੀ, ਅਤੇ ਦੂਜਾ ਚਲਾਉਣਾ ਸਫਲ ਹੋ ਗਿਆ। ਪਿਛੋਕੜ ਵਜੋਂ, ਇਹ ਉਦੋਂ ਵਾਪਰਿਆ ਜਦੋਂ ਪਹਿਲੀ ਵਾਰੀ ਇੱਕ JSON ਫਾਈਲ ਵਰਤੀ ਗਈ ਸੀ ਜਿਸ ਵਿੱਚ ਰਿਕਾਰਡ ਗਲਤ ਤਰੀਕੇ ਨਾਲ ਫਾਰਮੈਟ ਕੀਤੇ ਹੋਏ ਸਨ - ਜਦੋਂ ਇਹ ਠੀਕ ਕੀਤਾ ਗਿਆ, ਦੂਜਾ ਚਲਾਉਣਾ ਸਫਲਤਾਪੂਰਵਕ ਪੂਰਾ ਹੋ ਗਿਆ ਅਤੇ ਮਾਡਲ ਵਰਤਣ ਲਈ ਉਪਲਬਧ ਹੋ ਗਿਆ।\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.pa.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ਤੁਸੀਂ ਵਿਜ਼ੂਅਲ ਡੈਸ਼ਬੋਰਡ ਵਿੱਚ ਹੇਠਾਂ ਸਕ੍ਰੋਲ ਕਰਕੇ ਸਥਿਤੀ ਸੰਦੇਸ਼ ਅਤੇ ਮੈਟਰਿਕਸ ਵੀ ਵੇਖ ਸਕਦੇ ਹੋ, ਜਿਵੇਂ ਕਿ ਦਿਖਾਇਆ ਗਿਆ ਹੈ:\n",
    "\n",
    "| ਸੰਦੇਸ਼ | ਮੈਟਰਿਕਸ |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.pa.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.pa.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 3.1: ਆਈਡੀ ਪ੍ਰਾਪਤ ਕਰੋ ਅਤੇ ਕੋਡ ਵਿੱਚ ਫਾਈਨ-ਟਿਊਨ ਕੀਤਾ ਮਾਡਲ ਟੈਸਟ ਕਰੋ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ਕਦਮ 3.2: Playground ਵਿੱਚ Fine-Tuned ਮਾਡਲ ਲੋਡ ਕਰੋ ਅਤੇ ਟੈਸਟ ਕਰੋ\n",
    "\n",
    "ਹੁਣ ਤੁਸੀਂ fine-tuned ਮਾਡਲ ਨੂੰ ਦੋ ਤਰੀਕਿਆਂ ਨਾਲ ਟੈਸਟ ਕਰ ਸਕਦੇ ਹੋ। ਪਹਿਲਾ, ਤੁਸੀਂ Playground 'ਤੇ ਜਾ ਕੇ Models drop-down ਵਿੱਚੋਂ ਆਪਣਾ ਨਵਾਂ fine-tuned ਮਾਡਲ ਚੁਣ ਸਕਦੇ ਹੋ। ਦੂਜਾ ਵਿਕਲਪ ਇਹ ਹੈ ਕਿ Fine-tuning panel ਵਿੱਚ ਦਿੱਤੇ \"Playground\" ਵਿਕਲਪ ਨੂੰ ਵਰਤੋਂ (ਉਪਰ ਦਿੱਤੇ screenshot ਵਿੱਚ ਵੇਖੋ), ਜਿਸ ਨਾਲ _comparitive_ view ਖੁਲਦੀ ਹੈ, ਜਿੱਥੇ foundation ਅਤੇ fine-tuned ਮਾਡਲ ਦੋਵੇਂ ਪਾਸੇ-ਪਾਸੇ ਦਿਖਾਈ ਦਿੰਦੇ ਹਨ, ਤਾਂ ਜੋ ਤੁਸੀਂ ਤੇਜ਼ੀ ਨਾਲ ਮੁਕਾਬਲਾ ਕਰ ਸਕੋ।\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.pa.png)\n",
    "\n",
    "ਸਿਰਫ ਉਹੀ system context ਭਰੋ ਜੋ ਤੁਸੀਂ ਆਪਣੇ training data ਵਿੱਚ ਵਰਤਿਆ ਸੀ ਅਤੇ ਆਪਣਾ test question ਦਿਓ। ਤੁਸੀਂ ਵੇਖੋਗੇ ਕਿ ਦੋਵੇਂ ਪਾਸਿਆਂ 'ਤੇ ਇੱਕੋ context ਅਤੇ question update ਹੋ ਜਾਂਦੇ ਹਨ। ਮੁਕਾਬਲਾ ਚਲਾਓ ਅਤੇ ਤੁਸੀਂ ਦੋਵੇਂ outputs ਵਿੱਚ ਅੰਤਰ ਵੇਖ ਸਕਦੇ ਹੋ। _ਧਿਆਨ ਦਿਓ ਕਿ fine-tuned ਮਾਡਲ ਤੁਹਾਡੇ ਦਿੱਤੇ format ਵਿੱਚ ਜਵਾਬ ਦਿੰਦਾ ਹੈ, ਜਦਕਿ foundation ਮਾਡਲ ਸਿਰਫ system prompt ਨੂੰ follow ਕਰਦਾ ਹੈ_।\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.pa.png)\n",
    "\n",
    "ਤੁਸੀਂ ਵੇਖੋਗੇ ਕਿ ਮੁਕਾਬਲੇ ਵਿੱਚ ਹਰ ਮਾਡਲ ਲਈ token count ਅਤੇ inference ਲਈ ਲੱਗਾ ਸਮਾਂ ਵੀ ਦਿਖਾਇਆ ਜਾਂਦਾ ਹੈ। **ਇਹ example ਸਿਰਫ process ਦਿਖਾਉਣ ਲਈ ਹੈ, ਅਸਲ dataset ਜਾਂ scenario ਨੂੰ ਨਹੀਂ ਦਰਸਾਉਂਦਾ**। ਤੁਸੀਂ ਵੇਖ ਸਕਦੇ ਹੋ ਕਿ ਦੋਵੇਂ samples ਵਿੱਚ tokens ਦੀ ਗਿਣਤੀ ਇੱਕੋ ਜਿਹੀ ਹੈ (system context ਅਤੇ user prompt ਇੱਕੋ ਹਨ), ਪਰ fine-tuned ਮਾਡਲ ਨੂੰ inference ਲਈ ਵਧੇਰੇ ਸਮਾਂ ਲੱਗਦਾ ਹੈ (custom ਮਾਡਲ ਹੋਣ ਕਰਕੇ)।\n",
    "\n",
    "ਅਸਲ ਜ਼ਿੰਦਗੀ ਵਿੱਚ, ਤੁਸੀਂ ਇਸ ਤਰ੍ਹਾਂ ਦਾ simple example ਨਹੀਂ ਵਰਤੋਂਗੇ, ਬਲਕਿ ਅਸਲ data 'ਤੇ fine-tuning ਕਰੋਗੇ (ਜਿਵੇਂ ਕਿ customer service ਲਈ product catalog), ਜਿੱਥੇ response ਦੀ quality ਵਧੀਆ ਹੋਵੇਗੀ। _ਉਸ_ context ਵਿੱਚ, foundation ਮਾਡਲ ਤੋਂ ਇੱਕੋ ਜਿਹੀ quality ਵਾਲਾ ਜਵਾਬ ਲੈਣ ਲਈ ਵਧੇਰੇ custom prompt engineering ਦੀ ਲੋੜ ਪਵੇਗੀ, ਜਿਸ ਨਾਲ token usage ਵਧੇਗੀ ਅਤੇ inference ਲਈ processing time ਵੀ ਵਧ ਸਕਦੀ ਹੈ। _ਇਹ try ਕਰਨ ਲਈ, OpenAI Cookbook ਵਿੱਚ ਦਿੱਤੇ fine-tuning examples ਵੇਖੋ ਅਤੇ ਸ਼ੁਰੂ ਕਰੋ_।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**ਅਸਵੀਕਰਨ**:  \nਇਹ ਦਸਤਾਵੇਜ਼ AI ਅਨੁਵਾਦ ਸੇਵਾ [Co-op Translator](https://github.com/Azure/co-op-translator) ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਅਨੁਵਾਦ ਕੀਤਾ ਗਿਆ ਹੈ। ਅਸੀਂ ਯਥਾਸੰਭਵ ਸਹੀ ਅਨੁਵਾਦ ਦੇਣ ਦੀ ਕੋਸ਼ਿਸ਼ ਕਰਦੇ ਹਾਂ, ਪਰ ਕਿਰਪਾ ਕਰਕੇ ਧਿਆਨ ਵਿੱਚ ਰੱਖੋ ਕਿ ਆਟੋਮੈਟਿਕ ਅਨੁਵਾਦ ਵਿੱਚ ਗਲਤੀਆਂ ਜਾਂ ਅਣਪਛਾਤੀਆਂ ਹੋ ਸਕਦੀਆਂ ਹਨ। ਮੂਲ ਭਾਸ਼ਾ ਵਿੱਚ ਮੂਲ ਦਸਤਾਵੇਜ਼ ਨੂੰ ਹੀ ਅਧਿਕਾਰਕ ਸਰੋਤ ਮੰਨਿਆ ਜਾਣਾ ਚਾਹੀਦਾ ਹੈ। ਮਹੱਤਵਪੂਰਨ ਜਾਣਕਾਰੀ ਲਈ, ਪੇਸ਼ੇਵਰ ਮਨੁੱਖੀ ਅਨੁਵਾਦ ਦੀ ਸਿਫ਼ਾਰਸ਼ ਕੀਤੀ ਜਾਂਦੀ ਹੈ। ਇਸ ਅਨੁਵਾਦ ਦੀ ਵਰਤੋਂ ਕਰਕੇ ਹੋਣ ਵਾਲੀਆਂ ਕਿਸੇ ਵੀ ਗਲਤਫਹਿਮੀ ਜਾਂ ਗਲਤ ਵਿਆਖਿਆ ਲਈ ਅਸੀਂ ਜ਼ਿੰਮੇਵਾਰ ਨਹੀਂ ਹਾਂ।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:40:32+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "pa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}