<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T22:09:40+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "ro"
}
-->
[![Modele Open Source](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.ro.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Ajustarea fin캒 a modelului LLM

Utilizarea modelelor lingvistice mari pentru a construi aplica탵ii de AI generativ vine cu noi provoc캒ri. O problem캒 cheie este asigurarea calit캒탵ii r캒spunsurilor (precizie 탳i relevan탵캒) 칥n con탵inutul generat de model pentru o cerere specific캒 a utilizatorului. 칉n lec탵iile anterioare, am discutat despre tehnici precum ingineria prompturilor 탳i generarea augmentat캒 prin recuperare, care 칥ncearc캒 s캒 rezolve problema prin _modificarea intr캒rii promptului_ 칥n modelul existent.

칉n lec탵ia de ast캒zi, discut캒m despre o a treia tehnic캒, **ajustarea fin캒**, care 칥ncearc캒 s캒 abordeze provocarea prin _reantrenarea modelului 칥nsu탳i_ cu date suplimentare. S캒 intr캒m 칥n detalii.

## Obiective de 칥nv캒탵are

Aceast캒 lec탵ie introduce conceptul de ajustare fin캒 pentru modelele lingvistice pre-antrenate, exploreaz캒 beneficiile 탳i provoc캒rile acestei abord캒ri 탳i ofer캒 칥ndrum캒ri despre c칙nd 탳i cum s캒 folosi탵i ajustarea fin캒 pentru a 칥mbun캒t캒탵i performan탵a modelelor voastre de AI generativ.

P칙n캒 la sf칙r탳itul acestei lec탵ii, ar trebui s캒 pute탵i r캒spunde la urm캒toarele 칥ntreb캒ri:

- Ce este ajustarea fin캒 pentru modelele lingvistice?
- C칙nd 탳i de ce este util캒 ajustarea fin캒?
- Cum pot ajusta fin un model pre-antrenat?
- Care sunt limit캒rile ajust캒rii fine?

Gata? S캒 칥ncepem.

## Ghid ilustrat

Dori탵i s캒 ave탵i o imagine de ansamblu a ceea ce vom acoperi 칥nainte de a intra 칥n detalii? Consulta탵i acest ghid ilustrat care descrie parcursul de 칥nv캒탵are pentru aceast캒 lec탵ie - de la 칥nv캒탵area conceptelor de baz캒 탳i motiva탵ia pentru ajustarea fin캒, p칙n캒 la 칥n탵elegerea procesului 탳i a celor mai bune practici pentru executarea sarcinii de ajustare fin캒. Este un subiect fascinant de explorat, a탳a c캒 nu uita탵i s캒 verifica탵i pagina [Resurse](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pentru linkuri suplimentare care s캒 v캒 sprijine parcursul de 칥nv캒탵are autodidact!

![Ghid ilustrat pentru ajustarea fin캒 a modelelor lingvistice](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.ro.png)

## Ce este ajustarea fin캒 pentru modelele lingvistice?

Prin defini탵ie, modelele lingvistice mari sunt _pre-antrenate_ pe cantit캒탵i mari de text provenit din surse diverse, inclusiv internetul. A탳a cum am 칥nv캒탵at 칥n lec탵iile anterioare, avem nevoie de tehnici precum _ingineria prompturilor_ 탳i _generarea augmentat캒 prin recuperare_ pentru a 칥mbun캒t캒탵i calitatea r캒spunsurilor modelului la 칥ntreb캒rile utilizatorului ("prompturi").

O tehnic캒 popular캒 de inginerie a prompturilor implic캒 oferirea modelului mai mult캒 칥ndrumare cu privire la ceea ce se a탳teapt캒 칥n r캒spuns, fie prin furnizarea de _instruc탵iuni_ (ghidare explicit캒), fie _oferindu-i c칙teva exemple_ (ghidare implicit캒). Aceasta este denumit캒 _칥nv캒탵are cu pu탵ine exemple_, dar are dou캒 limit캒ri:

- Limitele de token ale modelului pot restric탵iona num캒rul de exemple pe care le pute탵i oferi 탳i pot limita eficien탵a.
- Costurile token-urilor modelului pot face costisitor ad캒ugarea de exemple la fiecare prompt 탳i pot limita flexibilitatea.

Ajustarea fin캒 este o practic캒 comun캒 칥n sistemele de 칥nv캒탵are automat캒, unde lu캒m un model pre-antrenat 탳i 칥l reantren캒m cu date noi pentru a-i 칥mbun캒t캒탵i performan탵a pe o sarcin캒 specific캒. 칉n contextul modelelor lingvistice, putem ajusta fin modelul pre-antrenat _cu un set curat de exemple pentru o sarcin캒 sau un domeniu de aplica탵ie specific_ pentru a crea un **model personalizat** care poate fi mai precis 탳i mai relevant pentru acea sarcin캒 sau domeniu specific. Un beneficiu secundar al ajust캒rii fine este c캒 poate reduce num캒rul de exemple necesare pentru 칥nv캒탵area cu pu탵ine exemple - reduc칙nd utilizarea token-urilor 탳i costurile aferente.

## C칙nd 탳i de ce ar trebui s캒 ajust캒m fin modelele?

칉n _acest_ context, c칙nd vorbim despre ajustare fin캒, ne referim la ajustarea fin캒 **supervizat캒**, unde reantrenarea se face prin **ad캒ugarea de date noi** care nu au f캒cut parte din setul de date original de antrenament. Acest lucru este diferit de abordarea ajust캒rii fine nesupervizate, unde modelul este reantrenat pe datele originale, dar cu hiperparametri diferi탵i.

Lucrul esen탵ial de re탵inut este c캒 ajustarea fin캒 este o tehnic캒 avansat캒 care necesit캒 un anumit nivel de expertiz캒 pentru a ob탵ine rezultatele dorite. Dac캒 este realizat캒 incorect, poate s캒 nu ofere 칥mbun캒t캒탵irile a탳teptate 탳i poate chiar s캒 degradeze performan탵a modelului pentru domeniul vizat.

A탳adar, 칥nainte de a 칥nv캒탵a "cum" s캒 ajusta탵i fin modelele lingvistice, trebuie s캒 탳ti탵i "de ce" ar trebui s캒 urma탵i aceast캒 cale 탳i "c칙nd" s캒 칥ncepe탵i procesul de ajustare fin캒. 칉ncepe탵i prin a v캒 pune aceste 칥ntreb캒ri:

- **Caz de utilizare**: Care este _cazul de utilizare_ pentru ajustarea fin캒? Ce aspect al modelului pre-antrenat actual dori탵i s캒 칥mbun캒t캒탵i탵i?
- **Alternative**: A탵i 칥ncercat _alte tehnici_ pentru a ob탵ine rezultatele dorite? Folosi탵i-le pentru a crea o baz캒 de compara탵ie.
  - Ingineria prompturilor: 칉ncerca탵i tehnici precum prompturi cu pu탵ine exemple, cu exemple de r캒spunsuri relevante. Evalua탵i calitatea r캒spunsurilor.
  - Generarea augmentat캒 prin recuperare: 칉ncerca탵i s캒 augmenta탵i prompturile cu rezultate ale interog캒rilor ob탵inute prin c캒utarea datelor voastre. Evalua탵i calitatea r캒spunsurilor.
- **Costuri**: A탵i identificat costurile pentru ajustarea fin캒?
  - Ajustabilitate - este modelul pre-antrenat disponibil pentru ajustare fin캒?
  - Efort - pentru preg캒tirea datelor de antrenament, evaluarea 탳i rafinarea modelului.
  - Resurse de calcul - pentru rularea sarcinilor de ajustare fin캒 탳i implementarea modelului ajustat fin.
  - Date - acces la suficiente exemple de calitate pentru impactul ajust캒rii fine.
- **Beneficii**: A탵i confirmat beneficiile ajust캒rii fine?
  - Calitate - modelul ajustat fin a dep캒탳it baza de compara탵ie?
  - Cost - reduce utilizarea token-urilor prin simplificarea prompturilor?
  - Extensibilitate - poate fi reutilizat modelul de baz캒 pentru noi domenii?

R캒spunz칙nd la aceste 칥ntreb캒ri, ar trebui s캒 pute탵i decide dac캒 ajustarea fin캒 este abordarea potrivit캒 pentru cazul vostru de utilizare. Ideal, abordarea este valid캒 doar dac캒 beneficiile dep캒탳esc costurile. Odat캒 ce decide탵i s캒 continua탵i, este timpul s캒 v캒 g칙ndi탵i _cum_ pute탵i ajusta fin modelul pre-antrenat.

Dori탵i mai multe informa탵ii despre procesul de luare a deciziilor? Urm캒ri탵i [S캒 ajust캒m fin sau nu?](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Cum putem ajusta fin un model pre-antrenat?

Pentru a ajusta fin un model pre-antrenat, ave탵i nevoie de:

- un model pre-antrenat pentru ajustare fin캒
- un set de date pentru ajustare fin캒
- un mediu de antrenament pentru a rula sarcina de ajustare fin캒
- un mediu de g캒zduire pentru a implementa modelul ajustat fin

## Ajustarea fin캒 칥n practic캒

Urm캒toarele resurse ofer캒 tutoriale pas cu pas pentru a v캒 ghida printr-un exemplu real folosind un model selectat cu un set de date curat. Pentru a parcurge aceste tutoriale, ave탵i nevoie de un cont la furnizorul specific, 칥mpreun캒 cu acces la modelul 탳i seturile de date relevante.

| Furnizor     | Tutorial                                                                                                                                                                       | Descriere                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Cum s캒 ajusta탵i fin modelele de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)         | 칉nv캒탵a탵i s캒 ajusta탵i fin un `gpt-35-turbo` pentru un domeniu specific ("asistent de re탵ete") prin preg캒tirea datelor de antrenament, rularea sarcinii de ajustare fin캒 탳i utilizarea modelului ajustat fin pentru inferen탵캒.                                                                                                                                                                                                       |
| Azure OpenAI | [Tutorial de ajustare fin캒 GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | 칉nv캒탵a탵i s캒 ajusta탵i fin un model `gpt-35-turbo-0613` **pe Azure** parcurg칙nd pa탳ii pentru a crea 탳i 칥nc캒rca datele de antrenament, a rula sarcina de ajustare fin캒. Implementa탵i 탳i utiliza탵i noul model.                                                                                                                                                                                                                         |
| Hugging Face | [Ajustarea fin캒 a LLM-urilor cu Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                       | Acest articol de blog v캒 ghideaz캒 칥n ajustarea fin캒 a unui _LLM deschis_ (ex: `CodeLlama 7B`) folosind biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) 탳i [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) cu seturi de date deschise pe Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| 游뱅 AutoTrain | [Ajustarea fin캒 a LLM-urilor cu AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                 | AutoTrain (sau AutoTrain Advanced) este o bibliotec캒 Python dezvoltat캒 de Hugging Face care permite ajustarea fin캒 pentru multe sarcini diferite, inclusiv ajustarea fin캒 a LLM-urilor. AutoTrain este o solu탵ie f캒r캒 cod, iar ajustarea fin캒 poate fi realizat캒 칥n propriul nor, pe Hugging Face Spaces sau local. Suport캒 at칙t o interfa탵캒 web, CLI, c칙t 탳i antrenament prin fi탳iere de configurare yaml.                     |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Tem캒

Selecta탵i unul dintre tutorialele de mai sus 탳i parcurge탵i-l. _Este posibil s캒 replic캒m o versiune a acestor tutoriale 칥n Jupyter Notebooks 칥n acest depozit doar pentru referin탵캒. V캒 rug캒m s캒 folosi탵i sursele originale direct pentru a ob탵ine cele mai recente versiuni_.

## Felicit캒ri! Continua탵i s캒 칥nv캒탵a탵i.

Dup캒 ce a탵i finalizat aceast캒 lec탵ie, consulta탵i [Colec탵ia de 칥nv캒탵are AI generativ캒](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a continua s캒 v캒 dezvolta탵i cuno탳tin탵ele despre AI generativ!

Felicit캒ri!! A탵i finalizat ultima lec탵ie din seria v2 a acestui curs! Nu v캒 opri탵i din 칥nv캒탵are 탳i construire. \*\*Consulta탵i pagina [RESURSE](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pentru o list캒 de sugestii suplimentare doar pentru acest subiect.

Seria noastr캒 de lec탵ii v1 a fost, de asemenea, actualizat캒 cu mai multe teme 탳i concepte. A탳adar, lua탵i un minut pentru a v캒 re칥mprosp캒ta cuno탳tin탵ele - 탳i v캒 rug캒m s캒 [칥mp캒rt캒탳i탵i 칥ntreb캒rile 탳i feedback-ul vostru](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) pentru a ne ajuta s캒 칥mbun캒t캒탵im aceste lec탵ii pentru comunitate.

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). De탳i ne str캒duim s캒 asigur캒m acurate탵ea, v캒 rug캒m s캒 fi탵i con탳tien탵i c캒 traducerile automate pot con탵ine erori sau inexactit캒탵i. Documentul original 칥n limba sa matern캒 ar trebui considerat sursa autoritar캒. Pentru informa탵ii critice, se recomand캒 traducerea profesional캒 realizat캒 de oameni. Nu ne asum캒m responsabilitatea pentru eventualele ne칥n탵elegeri sau interpret캒ri gre탳ite care pot ap캒rea din utilizarea acestei traduceri.