<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T19:04:03+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "ro"
}
-->
[![Open Source Models](../../../../../translated_images/ro/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Ajustarea finÄƒ a LLM-ului tÄƒu

Utilizarea modelelor mari de limbaj pentru a construi aplicaÈ›ii AI generative vine cu provocÄƒri noi. O problemÄƒ esenÈ›ialÄƒ este asigurarea calitÄƒÈ›ii rÄƒspunsurilor (acurateÈ›ea È™i relevanÈ›a) Ã®n conÈ›inutul generat de model pentru o cerere specificÄƒ a utilizatorului. Ãn lecÈ›iile anterioare, am discutat tehnici precum ingineria promptului È™i generarea augmentatÄƒ prin recuperare, care Ã®ncearcÄƒ sÄƒ rezolve problema prin _modificarea inputului promptului_ cÄƒtre modelul existent.

Ãn lecÈ›ia de astÄƒzi, discutÄƒm o a treia tehnicÄƒ, **ajustarea finÄƒ**, care Ã®ncearcÄƒ sÄƒ abordeze aceastÄƒ provocare prin _reuÈ›inerea modelului Ã®n sine_ cu date suplimentare. SÄƒ trecem la detalii.

## Obiective de Ã®nvÄƒÈ›are

AceastÄƒ lecÈ›ie introduce conceptul de ajustare finÄƒ pentru modelele pre-antrenate de limbaj, exploreazÄƒ beneficiile È™i provocÄƒrile acestei abordÄƒri È™i oferÄƒ ghiduri despre cÃ¢nd È™i cum sÄƒ foloseÈ™ti ajustarea finÄƒ pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelelor tale AI generative.

La finalul acestei lecÈ›ii, ar trebui sÄƒ poÈ›i rÄƒspunde la urmÄƒtoarele Ã®ntrebÄƒri:

- Ce este ajustarea finÄƒ pentru modelele de limbaj?
- CÃ¢nd È™i de ce este utilÄƒ ajustarea finÄƒ?
- Cum pot ajusta fin un model pre-antrenat?
- Care sunt limitÄƒrile ajustÄƒrii fine?

Gata? SÄƒ Ã®ncepem.

## Ghid ilustrat

DoreÈ™ti sÄƒ ai o privire de ansamblu asupra a ceea ce vom acoperi Ã®nainte sÄƒ intrÄƒm Ã®n detalii? ConsultÄƒ acest ghid ilustrat care descrie traseul de Ã®nvÄƒÈ›are pentru aceastÄƒ lecÈ›ie â€“ de la Ã®nÈ›elegerea conceptelor cheie È™i a motivaÈ›iei pentru ajustarea finÄƒ, pÃ¢nÄƒ la Ã®nÈ›elegerea procesului È™i a celor mai bune practici pentru executarea sarcinii de ajustare finÄƒ. Este un subiect fascinant de explorat, aÈ™a cÄƒ nu uita sÄƒ verifici pagina [Resurse](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pentru linkuri suplimentare care sÄƒ susÈ›inÄƒ cÄƒlÄƒtoria ta de Ã®nvÄƒÈ›are autodirijatÄƒ!

![Ghid ilustrat pentru ajustarea finÄƒ a modelelor de limbaj](../../../../../translated_images/ro/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Ce este ajustarea finÄƒ pentru modelele de limbaj?

Prin definiÈ›ie, modelele mari de limbaj sunt _pre-antrenate_ pe cantitÄƒÈ›i mari de text provenind din surse diverse, inclusiv internetul. AÈ™a cum am Ã®nvÄƒÈ›at Ã®n lecÈ›iile anterioare, avem nevoie de tehnici ca _ingineria promptului_ È™i _generarea augmentatÄƒ prin recuperare_ pentru a Ã®mbunÄƒtÄƒÈ›i calitatea rÄƒspunsurilor modelului la Ã®ntrebÄƒrile ("promptele") utilizatorului.

O tehnicÄƒ popularÄƒ de inginerie a promptului implicÄƒ oferirea modelului mai multÄƒ Ã®ndrumare despre ce se aÈ™teaptÄƒ Ã®n rÄƒspuns fie prin furnizarea de _instrucÈ›iuni_ (ghidaj explicit), fie _oferindu-i cÃ¢teva exemple_ (ghidaj implicit). Aceasta se numeÈ™te _Ã®nvÄƒÈ›are cu puÈ›ine exemple_ (few-shot learning), dar prezintÄƒ douÄƒ limitÄƒri:

- LimitÄƒrile de tokeni ale modelului pot restricÈ›iona numÄƒrul de exemple pe care le poÈ›i oferi È™i pot limita eficienÈ›a.
- Costurile legate de tokeni pot face scumpÄƒ adÄƒugarea de exemple la fiecare prompt, limitÃ¢nd flexibilitatea.

Ajustarea finÄƒ este o practicÄƒ comunÄƒ Ã®n sistemele de Ã®nvÄƒÈ›are automatÄƒ Ã®n care preluÄƒm un model pre-antrenat È™i Ã®l reantrenÄƒm cu date noi pentru a-i Ã®mbunÄƒtÄƒÈ›i performanÈ›a pe o sarcinÄƒ specificÄƒ. Ãn contextul modelelor de limbaj, putem ajusta fin modelul pre-antrenat _cu un set selectat de exemple pentru o anumitÄƒ sarcinÄƒ sau domeniu de aplicaÈ›ie_, pentru a crea un **model personalizat** care sÄƒ fie mai precis È™i mai relevant pentru acea sarcinÄƒ sau domeniu specific. Un beneficiu suplimentar al ajustÄƒrii fine este cÄƒ aceasta poate reduce È™i numÄƒrul de exemple necesare Ã®n Ã®nvÄƒÈ›area cu puÈ›ine exemple â€“ reducÃ¢nd consumul de tokeni È™i costurile asociate.

## CÃ¢nd È™i de ce ar trebui sÄƒ ajustÄƒm fin modelele?

Ãn _acest_ context, cÃ¢nd vorbim despre ajustarea finÄƒ, ne referim la ajustarea finÄƒ **supravegheatÄƒ**, unde reantrenarea se face prin **adÄƒugarea de date noi** care nu au fÄƒcut parte din setul de date iniÈ›ial de antrenament. Aceasta diferÄƒ de o abordare neasistatÄƒ unde modelul este reantrenat pe datele originale, dar cu hiperparametri diferiÈ›i.

Aspectul cheie de reÈ›inut este cÄƒ ajustarea finÄƒ este o tehnicÄƒ avansatÄƒ care necesitÄƒ un anumit nivel de expertizÄƒ pentru a obÈ›ine rezultatele dorite. DacÄƒ este fÄƒcutÄƒ incorect, aceasta poate sÄƒ nu ofere Ã®mbunÄƒtÄƒÈ›irile aÈ™teptate È™i chiar sÄƒ degradeze performanÈ›a modelului pentru domeniul vizat.

AÈ™adar, Ã®nainte sÄƒ Ã®nveÈ›i â€cumâ€ sÄƒ ajustezi fin modelele de limbaj, trebuie sÄƒ È™tii â€de ceâ€ ar trebui sÄƒ alegi aceastÄƒ cale È™i â€cÃ¢ndâ€ sÄƒ Ã®ncepi procesul de ajustare finÄƒ. Ãncepe prin a-È›i pune urmÄƒtoarele Ã®ntrebÄƒri:

- **Cazul de utilizare**: Care este _cazul tÄƒu de utilizare_ pentru ajustarea finÄƒ? Ce aspect al modelului pre-antrenat actual vrei sÄƒ Ã®mbunÄƒtÄƒÈ›eÈ™ti?
- **Alternative**: Ai Ã®ncercat _alte tehnici_ pentru a obÈ›ine rezultatele dorite? FoloseÈ™te-le pentru a crea un punct de referinÈ›Äƒ pentru comparaÈ›ie.
  - Ingineria promptului: ÃncearcÄƒ tehnici precum few-shot prompting cu exemple relevante de rÄƒspunsuri la prompturi. EvalueazÄƒ calitatea rÄƒspunsurilor.
  - Generarea augmentatÄƒ prin recuperare: ÃncearcÄƒ sÄƒ mÄƒreÈ™ti prompturile cu rezultatele cÄƒutÄƒrilor Ã®n datele tale. EvalueazÄƒ calitatea rÄƒspunsurilor.
- **Costuri**: Ai identificat costurile pentru ajustarea finÄƒ?
  - Posibilitatea de ajustare â€“ este modelul pre-antrenat disponibil pentru ajustare finÄƒ?
  - Efort â€“ pentru pregÄƒtirea datelor de antrenament, evaluarea È™i rafinarea modelului.
  - ComputaÈ›ie â€“ pentru rularea joburilor de ajustare finÄƒ È™i pentru implementarea modelului ajustat.
  - Date â€“ acces la suficiente exemple de calitate pentru impactul ajustÄƒrii fine.
- **Beneficii**: Ai confirmat beneficiile ajustÄƒrii fine?
  - Calitate â€“ modelul ajustat fin a depÄƒÈ™it baza de referinÈ›Äƒ?
  - Cost â€“ reduce utilizarea tokenilor prin simplificarea prompturilor?
  - Extensibilitate â€“ poÈ›i reutiliza modelul de bazÄƒ pentru noi domenii?

RÄƒspunzÃ¢nd acestor Ã®ntrebÄƒri, ar trebui sÄƒ poÈ›i decide dacÄƒ ajustarea finÄƒ este abordarea potrivitÄƒ pentru cazul tÄƒu de utilizare. Ideal, abordarea este valabilÄƒ numai dacÄƒ beneficiile depÄƒÈ™esc costurile. OdatÄƒ ce decizi sÄƒ continui, este timpul sÄƒ te gÃ¢ndeÈ™ti _cum_ poÈ›i ajusta fin modelul pre-antrenat.

Vrei mai multe insight-uri despre procesul decizional? VizualizeazÄƒ [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Cum putem ajusta fin un model pre-antrenat?

Pentru a ajusta fin un model pre-antrenat, ai nevoie de:

- un model pre-antrenat pentru ajustare finÄƒ
- un set de date pentru ajustarea finÄƒ
- un mediu de antrenament pentru a rula jobul de ajustare finÄƒ
- un mediu de gÄƒzduire pentru a implementa modelul ajustat fin

## Ajustarea finÄƒ Ã®n practicÄƒ

Resursele urmÄƒtoare oferÄƒ tutoriale pas cu pas care te vor ghida printr-un exemplu real folosind un model selectat cu un set de date atent ales. Pentru a parcurge aceste tutoriale, ai nevoie de un cont la furnizorul specific, precum È™i acces la modelele È™i seturile de date relevante.

| Furnizor    | Tutorial                                                                                                                                                                      | Descriere                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ----------- | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [Cum sÄƒ ajustezi fin modelele de chat](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)         | ÃnvaÈ›Äƒ sÄƒ ajustezi fin un `gpt-35-turbo` pentru un domeniu specific (â€asistent de reÈ›eteâ€) prin pregÄƒtirea datelor de antrenament, rularea jobului de ajustare finÄƒ È™i folosirea modelului ajustat pentru inferenÈ›Äƒ.                                                                                                                                                                                                              |
| Azure OpenAI| [Tutorial de ajustare finÄƒ GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | ÃnvaÈ›Äƒ sÄƒ ajustezi fin un model `gpt-35-turbo-0613` **pe Azure** parcurgÃ¢nd paÈ™i pentru crearea È™i Ã®ncÄƒrcarea datelor de antrenament, rularea jobului de ajustare finÄƒ, implementarea È™i utilizarea noului model.                                                                                                                                                                                                                    |
| Hugging Face| [Ajustarea finÄƒ a LLM-urilor cu Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                      | Acest articol explicÄƒ cum sÄƒ ajustezi fin un _LLM open source_ (ex: `CodeLlama 7B`) folosind biblioteca [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) È™i [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst), Ã®mpreunÄƒ cu seturi de date deschise ([datasets](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst)) pe Hugging Face. |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ğŸ¤— AutoTrain| [Ajustarea finÄƒ a LLM-urilor cu AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                | AutoTrain (sau AutoTrain Advanced) este o bibliotecÄƒ Python dezvoltatÄƒ de Hugging Face care permite ajustarea finÄƒ pentru multe sarcini diferite, inclusiv ajustarea finÄƒ a LLM-urilor. AutoTrain este o soluÈ›ie fÄƒrÄƒ cod È™i ajustarea finÄƒ poate fi fÄƒcutÄƒ Ã®n propriul tÄƒu cloud, pe Hugging Face Spaces sau local. SuportÄƒ interfaÈ›Äƒ web GUI, CLI È™i antrenament prin fiÈ™iere de configurare yaml.                                                    |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ğŸ¦¥ Unsloth | [Ajustarea finÄƒ a LLM-urilor cu Unsloth](https://github.com/unslothai/unsloth)                                                                                                  | Unsloth este un cadru open-source ce sprijinÄƒ ajustarea finÄƒ a LLM-urilor È™i Ã®nvÄƒÈ›area prin Ã®ntÄƒrire (RL). Unsloth simplificÄƒ antrenamentul local, evaluarea È™i implementarea cu [notebook-uri](https://github.com/unslothai/notebooks) gata de folosit. SuportÄƒ de asemenea text-Ã®n-voce (TTS), BERT È™i modele multimodale. Pentru a Ã®ncepe, citeÈ™te ghidul lor pas cu pas [Fine-tuning LLMs Guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).     |
|             |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
## TemÄƒ

SelecteazÄƒ unul dintre tutorialele de mai sus È™i parcurge-l. _Este posibil sÄƒ replicÄƒm o versiune a acestor tutoriale Ã®n Jupyter Notebooks Ã®n acest depozit doar pentru referinÈ›Äƒ. Te rugÄƒm sÄƒ foloseÈ™ti sursele originale direct pentru a obÈ›ine cele mai recente versiuni_.

## Ai fÄƒcut o treabÄƒ grozavÄƒ! ContinuÄƒ sÄƒ Ã®nveÈ›i.

DupÄƒ ce ai terminat aceastÄƒ lecÈ›ie, consultÄƒ colecÈ›ia noastrÄƒ de [ÃnvÄƒÈ›are AI Generativ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a continua sÄƒ-È›i creÈ™ti cunoÈ™tinÈ›ele despre AI Generativ!

FelicitÄƒri!! Ai finalizat lecÈ›ia finalÄƒ din seria v2 a acestui curs! Nu te opri din a Ã®nvÄƒÈ›a È™i a construi. \*\*Vezi pagina [RESURSE](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pentru o listÄƒ de sugestii suplimentare doar pentru acest subiect.

Seria noastrÄƒ v1 de lecÈ›ii a fost de asemenea actualizatÄƒ cu mai multe teme È™i concepte. AÈ™adar ia-È›i un minut pentru a-È›i reÃ®mprospÄƒta cunoÈ™tinÈ›ele â€“ È™i te rugÄƒm [Ã®mpÄƒrtÄƒÈ™eÈ™te Ã®ntrebÄƒrile È™i feedback-ul tÄƒu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) pentru a ne ajuta sÄƒ Ã®mbunÄƒtÄƒÈ›im aceste lecÈ›ii pentru comunitate.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Declinare de responsabilitate**:
Acest document a fost tradus folosind serviciul de traducere automatÄƒ AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim pentru acurateÈ›e, vÄƒ rugÄƒm sÄƒ reÈ›ineÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa nativÄƒ trebuie considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un traducÄƒtor uman. Nu ne asumÄƒm rÄƒspunderea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite care pot rezulta din utilizarea acestei traduceri.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->