{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ajustarea fină a modelelor Open AI\n",
    "\n",
    "Acest caiet este bazat pe ghidul actual furnizat în documentația [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) de la Open AI.\n",
    "\n",
    "Ajustarea fină îmbunătățește performanța modelelor fundamentale pentru aplicația ta prin reantrenarea acestora cu date suplimentare și context relevant pentru acel caz de utilizare sau scenariu specific. Reține că tehnicile de inginerie a promptului precum _few shot learning_ și _retrieval augmented generation_ îți permit să îmbunătățești promptul implicit cu date relevante pentru a crește calitatea. Totuși, aceste abordări sunt limitate de dimensiunea maximă a ferestrei de tokeni a modelului fundamental vizat.\n",
    "\n",
    "Prin ajustarea fină, practic reantrenăm modelul în sine cu datele necesare (permițându-ne să folosim mult mai multe exemple decât pot încăpea în fereastra maximă de tokeni) - și implementăm o versiune _personalizată_ a modelului care nu mai are nevoie să primească exemple la momentul inferenței. Acest lucru nu doar că îmbunătățește eficacitatea designului promptului nostru (avem mai multă flexibilitate în utilizarea ferestrei de tokeni pentru alte lucruri), dar potențial îmbunătățește și costurile noastre (prin reducerea numărului de tokeni pe care trebuie să îi trimitem modelului la inferență).\n",
    "\n",
    "Ajustarea fină are 4 pași:\n",
    "1. Pregătește datele de antrenament și încarcă-le.\n",
    "1. Rulează jobul de antrenament pentru a obține un model ajustat fin.\n",
    "1. Evaluează modelul ajustat fin și iterează pentru calitate.\n",
    "1. Implementează modelul ajustat fin pentru inferență când ești mulțumit.\n",
    "\n",
    "Reține că nu toate modelele fundamentale suportă ajustarea fină - [verifică documentația OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) pentru cele mai recente informații. De asemenea, poți ajusta fin un model care a fost deja ajustat fin anterior. În acest tutorial, vom folosi `gpt-35-turbo` ca model fundamental țintă pentru ajustarea fină.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasul 1.1: Pregătiți-vă setul de date\n",
    "\n",
    "Să construim un chatbot care să vă ajute să înțelegeți tabelul periodic al elementelor răspunzând la întrebări despre un element printr-un limerick. În _acest_ tutorial simplu, vom crea doar un set de date pentru a antrena modelul cu câteva exemple de răspunsuri care arată formatul așteptat al datelor. Într-un caz real, ar trebui să creați un set de date cu mult mai multe exemple. De asemenea, este posibil să puteți folosi un set de date deschis (pentru domeniul aplicației dvs.) dacă există unul, și să îl reformatați pentru utilizarea în fine-tuning.\n",
    "\n",
    "Deoarece ne concentrăm pe `gpt-35-turbo` și căutăm un răspuns într-un singur tur (completare chat), putem crea exemple folosind [acest format sugerat](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) care reflectă cerințele completării chat OpenAI. Dacă vă așteptați la conținut conversațional multi-tur, ați folosi [formatul de exemplu multi-tur](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) care include un parametru `weight` pentru a semnala care mesaje ar trebui folosite (sau nu) în procesul de fine-tuning.\n",
    "\n",
    "Vom folosi formatul mai simplu, cu un singur tur, pentru tutorialul nostru aici. Datele sunt în [format jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) cu 1 înregistrare pe linie, fiecare reprezentată ca un obiect JSON formatat. Fragmentul de mai jos arată 2 înregistrări ca exemplu - vedeți [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) pentru setul complet de exemple (10 exemple) pe care îl vom folosi pentru tutorialul de fine-tuning. **Notă:** Fiecare înregistrare _trebuie_ definită într-o singură linie (nu împărțită pe mai multe linii, așa cum este tipic într-un fișier JSON formatat)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "Într-un caz real, veți avea nevoie de un set mult mai mare de exemple pentru rezultate bune - compromisul va fi între calitatea răspunsurilor și timpul/costurile pentru fine-tuning. Folosim un set mic pentru a putea finaliza rapid fine-tuning-ul și a ilustra procesul. Consultați [acest exemplu din OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) pentru un tutorial de fine-tuning mai complex.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pasul 1.2 Încarcă Setul de Date\n",
    "\n",
    "Încarcă datele folosind API-ul Files [așa cum este descris aici](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Reține că pentru a rula acest cod, trebuie să fi făcut următorii pași mai întâi:\n",
    " - Ai instalat pachetul Python `openai` (asigură-te că folosești o versiune >=0.28.0 pentru cele mai noi funcționalități)\n",
    " - Ai setat variabila de mediu `OPENAI_API_KEY` cu cheia ta API OpenAI\n",
    "Pentru a afla mai multe, vezi [Ghidul de configurare](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) oferit pentru curs.\n",
    "\n",
    "Acum, rulează codul pentru a crea un fișier pentru încărcare din fișierul tău local JSONL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pasul 2.1: Creează jobul de ajustare fină cu SDK-ul\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pasul 2.2: Verifică starea jobului\n",
    "\n",
    "Iată câteva lucruri pe care le poți face cu API-ul `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Listează ultimele n joburi de fine-tuning\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Obține detalii despre un job specific de fine-tuning\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Anulează un job de fine-tuning\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Listează până la n evenimente din job\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Primul pas al procesului este _validarea fișierului de antrenament_ pentru a te asigura că datele sunt în formatul corect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pasul 2.3: Urmărirea evenimentelor pentru monitorizarea progresului\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pasul 2.4: Vizualizează starea în Panoul de control OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De asemenea, puteți vizualiza starea accesând site-ul OpenAI și explorând secțiunea _Fine-tuning_ a platformei. Aceasta vă va arăta starea jobului curent și vă va permite să urmăriți istoricul execuțiilor anterioare ale joburilor. În această captură de ecran, puteți vedea că execuția anterioară a eșuat, iar a doua rulare a reușit. Pentru context, acest lucru s-a întâmplat când prima rulare a folosit un fișier JSON cu înregistrări formatate incorect - odată corectat, a doua rulare s-a finalizat cu succes și a făcut modelul disponibil pentru utilizare.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ro/fine-tuned-model-status.563271727bf7bfba.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De asemenea, puteți vizualiza mesajele de stare și metricile derulând mai jos în tabloul de bord vizual, așa cum este prezentat:\n",
    "\n",
    "| Mesaje | Metrici |\n",
    "|:---|:---|\n",
    "| ![Mesaje](../../../../../translated_images/ro/fine-tuned-messages-panel.4ed0c2da5ea1313b.webp) |  ![Metrici](../../../../../translated_images/ro/fine-tuned-metrics-panel.700d7e4995a65229.webp)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pasul 3.1: Obțineți ID-ul și testați modelul ajustat în cod\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Pasul 3.2: Încarcă și testează modelul ajustat în Playground\n",
    "\n",
    "Acum poți testa modelul ajustat în două moduri. Mai întâi, poți vizita Playground și folosi meniul derulant Models pentru a selecta modelul tău nou ajustat din opțiunile listate. Cealaltă opțiune este să folosești opțiunea \"Playground\" afișată în panoul Fine-tuning (vezi captura de ecran de mai sus) care lansează următoarea vizualizare _comparativă_ ce arată versiunile modelului de bază și a celui ajustat unul lângă altul pentru o evaluare rapidă.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ro/fine-tuned-playground-compare.56e06f0ad8922016.webp)\n",
    "\n",
    "Completează pur și simplu contextul sistemului folosit în datele tale de antrenament și oferă întrebarea ta de test. Vei observa că ambele părți sunt actualizate cu același context și întrebare. Rulează comparația și vei vedea diferența în răspunsurile dintre ele. _Observă cum modelul ajustat redă răspunsul în formatul pe care l-ai furnizat în exemplele tale, în timp ce modelul de bază urmează pur și simplu promptul sistemului_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/ro/fine-tuned-playground-launch.5a26495c983c6350.webp)\n",
    "\n",
    "Vei observa că comparația oferă și numărul de tokeni pentru fiecare model, precum și timpul necesar pentru inferență. **Acest exemplu specific este unul simplist menit să arate procesul, dar nu reflectă un set de date sau un scenariu real**. Poți observa că ambele mostre arată același număr de tokeni (contextul sistemului și promptul utilizatorului sunt identice), iar modelul ajustat necesită mai mult timp pentru inferență (model personalizat).\n",
    "\n",
    "În scenarii reale, nu vei folosi un exemplu simplu ca acesta, ci vei face ajustări pe date reale (de exemplu, catalog de produse pentru serviciul clienți) unde calitatea răspunsului va fi mult mai evidentă. În _acel_ context, obținerea unei calități echivalente a răspunsului cu modelul de bază va necesita o inginerie de prompt personalizată mai complexă, ceea ce va crește utilizarea tokenilor și, potențial, timpul de procesare pentru inferență. _Pentru a încerca acest lucru, consultă exemplele de fine-tuning din OpenAI Cookbook pentru a începe._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Declinare de responsabilitate**:  \nAcest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa nativă trebuie considerat sursa autorizată. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm responsabilitatea pentru eventualele neînțelegeri sau interpretări greșite rezultate din utilizarea acestei traduceri.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:32:22+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "ro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}