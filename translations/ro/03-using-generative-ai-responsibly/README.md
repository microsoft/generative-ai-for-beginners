<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T09:03:04+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "ro"
}
-->
# Folosirea responsabilÄƒ a AI generativ

[![Using Generative AI Responsibly](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.ro.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Click pe imaginea de mai sus pentru a viziona videoclipul acestei lecÈ›ii_

Este uÈ™or sÄƒ fii fascinat de AI È™i Ã®n special de AI generativ, dar trebuie sÄƒ iei Ã®n considerare cum sÄƒ Ã®l foloseÈ™ti responsabil. Trebuie sÄƒ te gÃ¢ndeÈ™ti la aspecte precum asigurarea faptului cÄƒ rezultatul este corect, nepericulos È™i altele. Acest capitol Ã®È™i propune sÄƒ Ã®È›i ofere contextul menÈ›ionat, ce trebuie sÄƒ iei Ã®n calcul È™i cum sÄƒ iei mÄƒsuri active pentru a-È›i Ã®mbunÄƒtÄƒÈ›i utilizarea AI.

## Introducere

AceastÄƒ lecÈ›ie va acoperi:

- De ce ar trebui sÄƒ prioritizezi Responsible AI atunci cÃ¢nd construieÈ™ti aplicaÈ›ii Generative AI.
- Principiile de bazÄƒ ale Responsible AI È™i cum se raporteazÄƒ acestea la Generative AI.
- Cum sÄƒ pui Ã®n practicÄƒ aceste principii Responsible AI prin strategie È™i unelte.

## Obiective de Ã®nvÄƒÈ›are

DupÄƒ ce vei finaliza aceastÄƒ lecÈ›ie vei È™ti:

- ImportanÈ›a Responsible AI cÃ¢nd construieÈ™ti aplicaÈ›ii Generative AI.
- CÃ¢nd sÄƒ gÃ¢ndeÈ™ti È™i sÄƒ aplici principiile de bazÄƒ Responsible AI Ã®n dezvoltarea aplicaÈ›iilor Generative AI.
- Ce unelte È™i strategii ai la dispoziÈ›ie pentru a pune Ã®n practicÄƒ conceptul de Responsible AI.

## Principiile Responsible AI

Entuziasmul pentru Generative AI nu a fost niciodatÄƒ mai mare. Acest entuziasm a atras mulÈ›i dezvoltatori noi, atenÈ›ie È™i finanÈ›are Ã®n acest domeniu. DeÈ™i acest lucru este foarte pozitiv pentru oricine doreÈ™te sÄƒ construiascÄƒ produse È™i companii folosind Generative AI, este la fel de important sÄƒ procedÄƒm responsabil.

Pe parcursul acestui curs, ne concentrÄƒm pe construirea startup-ului nostru È™i a produsului nostru educaÈ›ional AI. Vom folosi principiile Responsible AI: Echitate, Incluziune, Fiabilitate/SiguranÈ›Äƒ, Securitate & ConfidenÈ›ialitate, TransparenÈ›Äƒ È™i Responsabilitate. Cu aceste principii, vom explora cum se raporteazÄƒ ele la utilizarea Generative AI Ã®n produsele noastre.

## De ce ar trebui sÄƒ prioritizezi Responsible AI

Atunci cÃ¢nd construieÈ™ti un produs, abordarea centratÄƒ pe om, avÃ¢nd Ã®n vedere interesul utilizatorului, conduce la cele mai bune rezultate.

Unicitatea Generative AI constÄƒ Ã®n puterea sa de a crea rÄƒspunsuri utile, informaÈ›ii, ghidare È™i conÈ›inut pentru utilizatori. Acest lucru se poate face fÄƒrÄƒ multe etape manuale, ceea ce poate duce la rezultate foarte impresionante. FÄƒrÄƒ o planificare È™i strategii adecvate, din pÄƒcate, poate duce È™i la rezultate dÄƒunÄƒtoare pentru utilizatorii tÄƒi, produsul tÄƒu È™i societate Ã®n ansamblu.

SÄƒ analizÄƒm cÃ¢teva (dar nu toate) dintre aceste rezultate potenÈ›ial dÄƒunÄƒtoare:

### HalucinaÈ›ii

HalucinaÈ›iile sunt un termen folosit pentru a descrie situaÈ›iile Ã®n care un LLM produce conÈ›inut care este fie complet lipsit de sens, fie ceva ce È™tim cÄƒ este factual greÈ™it pe baza altor surse de informaÈ›ii.

SÄƒ luÄƒm exemplul Ã®n care construim o funcÈ›ie pentru startup-ul nostru care permite studenÈ›ilor sÄƒ punÄƒ Ã®ntrebÄƒri istorice unui model. Un student Ã®ntreabÄƒ: `Cine a fost singurul supravieÈ›uitor al Titanicului?`

Modelul produce un rÄƒspuns precum cel de mai jos:

![Prompt saying "Who was the sole survivor of the Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Sursa: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Acesta este un rÄƒspuns foarte sigur È™i detaliat. Din pÄƒcate, este incorect. Chiar È™i cu o cercetare minimÄƒ, s-ar descoperi cÄƒ au existat mai mulÈ›i supravieÈ›uitori ai dezastrului de pe Titanic. Pentru un student care abia Ã®ncepe sÄƒ cerceteze acest subiect, acest rÄƒspuns poate fi suficient de convingÄƒtor pentru a nu fi pus sub semnul Ã®ntrebÄƒrii È™i tratat ca un fapt. ConsecinÈ›ele pot duce la faptul cÄƒ sistemul AI devine nesigur È™i afecteazÄƒ negativ reputaÈ›ia startup-ului nostru.

Cu fiecare iteraÈ›ie a oricÄƒrui LLM, am observat Ã®mbunÄƒtÄƒÈ›iri Ã®n performanÈ›Äƒ Ã®n ceea ce priveÈ™te minimizarea halucinaÈ›iilor. Chiar È™i cu aceastÄƒ Ã®mbunÄƒtÄƒÈ›ire, noi, ca dezvoltatori de aplicaÈ›ii È™i utilizatori, trebuie sÄƒ rÄƒmÃ¢nem conÈ™tienÈ›i de aceste limitÄƒri.

### ConÈ›inut dÄƒunÄƒtor

Am discutat Ã®n secÈ›iunea anterioarÄƒ despre situaÈ›iile Ã®n care un LLM produce rÄƒspunsuri incorecte sau lipsite de sens. Un alt risc de care trebuie sÄƒ fim conÈ™tienÈ›i este atunci cÃ¢nd un model rÄƒspunde cu conÈ›inut dÄƒunÄƒtor.

ConÈ›inutul dÄƒunÄƒtor poate fi definit ca:

- Oferirea de instrucÈ›iuni sau Ã®ncurajarea auto-vÄƒtÄƒmÄƒrii sau a vÄƒtÄƒmÄƒrii anumitor grupuri.
- ConÈ›inut plin de urÄƒ sau degradant.
- Ghidarea planificÄƒrii oricÄƒrui tip de atac sau acte violente.
- Oferirea de instrucÈ›iuni despre cum sÄƒ gÄƒseÈ™ti conÈ›inut ilegal sau sÄƒ comiÈ›i acte ilegale.
- AfiÈ™area de conÈ›inut sexual explicit.

Pentru startup-ul nostru, vrem sÄƒ ne asigurÄƒm cÄƒ avem uneltele È™i strategiile potrivite pentru a preveni ca acest tip de conÈ›inut sÄƒ fie vÄƒzut de studenÈ›i.

### Lipsa echitÄƒÈ›ii

Echitatea este definitÄƒ ca â€asigurarea cÄƒ un sistem AI este liber de prejudecÄƒÈ›i È™i discriminare È™i cÄƒ trateazÄƒ pe toatÄƒ lumea corect È™i egal.â€ Ãn lumea Generative AI, vrem sÄƒ ne asigurÄƒm cÄƒ viziunile excluzive asupra lumii ale grupurilor marginalizate nu sunt Ã®ntÄƒrite prin rezultatele modelului.

Acest tip de rezultate nu doar cÄƒ distrug experienÈ›ele pozitive ale produsului pentru utilizatorii noÈ™tri, dar cauzeazÄƒ È™i daune suplimentare societÄƒÈ›ii. Ca dezvoltatori de aplicaÈ›ii, ar trebui sÄƒ avem mereu Ã®n vedere o bazÄƒ largÄƒ È™i diversÄƒ de utilizatori atunci cÃ¢nd construim soluÈ›ii cu Generative AI.

## Cum sÄƒ foloseÈ™ti Generative AI responsabil

Acum cÄƒ am identificat importanÈ›a Responsible Generative AI, sÄƒ vedem 4 paÈ™i pe care Ã®i putem urma pentru a construi soluÈ›iile AI responsabil:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.ro.png)

### MÄƒsoarÄƒ potenÈ›ialele daune

Ãn testarea software, testÄƒm acÈ›iunile aÈ™teptate ale unui utilizator Ã®ntr-o aplicaÈ›ie. Ãn mod similar, testarea unui set divers de prompturi pe care utilizatorii sunt cel mai probabil sÄƒ le foloseascÄƒ este o metodÄƒ bunÄƒ de a mÄƒsura potenÈ›ialele daune.

Deoarece startup-ul nostru construieÈ™te un produs educaÈ›ional, ar fi bine sÄƒ pregÄƒtim o listÄƒ de prompturi legate de educaÈ›ie. Acestea ar putea acoperi un anumit subiect, fapte istorice È™i prompturi despre viaÈ›a studenÈ›eascÄƒ.

### AtenueazÄƒ potenÈ›ialele daune

Este momentul sÄƒ gÄƒsim modalitÄƒÈ›i prin care sÄƒ prevenim sau sÄƒ limitÄƒm potenÈ›ialele daune cauzate de model È™i rÄƒspunsurile sale. Putem privi acest lucru pe 4 niveluri diferite:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.ro.png)

- **Modelul**. Alegerea modelului potrivit pentru cazul de utilizare potrivit. Modelele mai mari È™i mai complexe, precum GPT-4, pot prezenta un risc mai mare de conÈ›inut dÄƒunÄƒtor atunci cÃ¢nd sunt aplicate Ã®n cazuri de utilizare mai mici È™i mai specifice. Folosirea datelor tale de antrenament pentru fine-tuning reduce, de asemenea, riscul de conÈ›inut dÄƒunÄƒtor.

- **Sistemul de siguranÈ›Äƒ**. Un sistem de siguranÈ›Äƒ este un set de unelte È™i configuraÈ›ii pe platforma care deserveÈ™te modelul È™i care ajutÄƒ la atenuarea daunelor. Un exemplu este sistemul de filtrare a conÈ›inutului din serviciul Azure OpenAI. Sistemele ar trebui sÄƒ detecteze È™i atacurile de tip jailbreak È™i activitÄƒÈ›ile nedorite, cum ar fi cererile venite de la boÈ›i.

- **Metaprompt**. Metaprompturile È™i grounding-ul sunt modalitÄƒÈ›i prin care putem direcÈ›iona sau limita modelul pe baza anumitor comportamente È™i informaÈ›ii. Acest lucru poate Ã®nsemna folosirea inputurilor de sistem pentru a defini anumite limite ale modelului. Ãn plus, oferirea de rezultate mai relevante pentru domeniul sau aria sistemului.

Poate include È™i folosirea tehnicilor precum Retrieval Augmented Generation (RAG) pentru ca modelul sÄƒ extragÄƒ informaÈ›ii doar dintr-o selecÈ›ie de surse de Ã®ncredere. ExistÄƒ o lecÈ›ie mai tÃ¢rziu Ã®n acest curs despre [construirea aplicaÈ›iilor de cÄƒutare](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **ExperienÈ›a utilizatorului**. Ultimul nivel este acela Ã®n care utilizatorul interacÈ›ioneazÄƒ direct cu modelul prin interfaÈ›a aplicaÈ›iei noastre. Astfel, putem proiecta UI/UX pentru a limita tipurile de inputuri pe care utilizatorul le poate trimite modelului, precum È™i textele sau imaginile afiÈ™ate utilizatorului. CÃ¢nd lansÄƒm aplicaÈ›ia AI, trebuie sÄƒ fim transparenÈ›i Ã®n privinÈ›a a ceea ce aplicaÈ›ia noastrÄƒ Generative AI poate È™i nu poate face.

Avem o lecÈ›ie dedicatÄƒ Ã®n Ã®ntregime [ProiectÄƒrii UX pentru aplicaÈ›ii AI](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluarea modelului**. Lucrul cu LLM-urile poate fi provocator deoarece nu avem Ã®ntotdeauna control asupra datelor pe care modelul a fost antrenat. Cu toate acestea, ar trebui sÄƒ evaluÄƒm Ã®ntotdeauna performanÈ›a È™i rezultatele modelului. Este important sÄƒ mÄƒsurÄƒm acurateÈ›ea modelului, similaritatea, fundamentarea È™i relevanÈ›a outputului. Acest lucru ajutÄƒ la oferirea de transparenÈ›Äƒ È™i Ã®ncredere pÄƒrÈ›ilor interesate È™i utilizatorilor.

### Operarea unei soluÈ›ii Responsible Generative AI

Construirea unei practici operaÈ›ionale Ã®n jurul aplicaÈ›iilor tale AI este etapa finalÄƒ. Aceasta include colaborarea cu alte departamente din startup-ul nostru, cum ar fi Legal È™i Securitate, pentru a ne asigura cÄƒ respectÄƒm toate politicile de reglementare. Ãnainte de lansare, vrem sÄƒ construim planuri legate de livrare, gestionarea incidentelor È™i revenirea la o versiune anterioarÄƒ pentru a preveni orice daunÄƒ Ã®n creÈ™tere pentru utilizatorii noÈ™tri.

## Unelte

DeÈ™i munca de a dezvolta soluÈ›ii Responsible AI poate pÄƒrea multÄƒ, este o muncÄƒ care meritÄƒ efortul. Pe mÄƒsurÄƒ ce domeniul Generative AI creÈ™te, vor apÄƒrea tot mai multe unelte care sÄƒ ajute dezvoltatorii sÄƒ integreze responsabilitatea eficient Ã®n fluxurile lor de lucru. De exemplu, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) poate ajuta la detectarea conÈ›inutului È™i imaginilor dÄƒunÄƒtoare printr-o cerere API.

## Verificare cunoÈ™tinÈ›e

Care sunt cÃ¢teva lucruri de care trebuie sÄƒ È›ii cont pentru a asigura o utilizare responsabilÄƒ a AI?

1. Ca rÄƒspunsul sÄƒ fie corect.
1. Utilizarea dÄƒunÄƒtoare, ca AI sÄƒ nu fie folosit Ã®n scopuri criminale.
1. Asigurarea cÄƒ AI este liber de prejudecÄƒÈ›i È™i discriminare.

RÄƒspuns: 2 È™i 3 sunt corecte. Responsible AI te ajutÄƒ sÄƒ iei Ã®n calcul cum sÄƒ atenuezi efectele dÄƒunÄƒtoare, prejudecÄƒÈ›ile È™i altele.

## ğŸš€ Provocare

CiteÈ™te despre [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) È™i vezi ce poÈ›i adopta pentru utilizarea ta.

## FelicitÄƒri, continuÄƒ sÄƒ Ã®nveÈ›i

DupÄƒ ce ai terminat aceastÄƒ lecÈ›ie, consultÄƒ colecÈ›ia noastrÄƒ de Ã®nvÄƒÈ›are [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a-È›i continua dezvoltarea cunoÈ™tinÈ›elor despre Generative AI!

Mergi la LecÈ›ia 4 unde vom explora [Fundamentele ingineriei prompturilor](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim pentru acurateÈ›e, vÄƒ rugÄƒm sÄƒ reÈ›ineÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa nativÄƒ trebuie considerat sursa autorizatÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm rÄƒspunderea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite rezultate din utilizarea acestei traduceri.