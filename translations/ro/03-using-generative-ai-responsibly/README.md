<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-17T22:06:14+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "ro"
}
-->
# Utilizarea AI Generativ Ã®n mod responsabil

[![Utilizarea AI Generativ Ã®n mod responsabil](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.ro.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _FaceÈ›i clic pe imaginea de mai sus pentru a viziona videoclipul acestei lecÈ›ii_

Este uÈ™or sÄƒ fii fascinat de AI È™i, Ã®n special, de AI generativ, dar trebuie sÄƒ te gÃ¢ndeÈ™ti cum sÄƒ Ã®l foloseÈ™ti Ã®n mod responsabil. Trebuie sÄƒ iei Ã®n considerare aspecte precum asigurarea cÄƒ rezultatele sunt corecte, non-nocive È™i multe altele. Acest capitol Ã®È™i propune sÄƒ Ã®È›i ofere contextul menÈ›ionat, ce sÄƒ iei Ã®n considerare È™i cum sÄƒ faci paÈ™i activi pentru a Ã®mbunÄƒtÄƒÈ›i utilizarea AI.

## Introducere

AceastÄƒ lecÈ›ie va acoperi:

- De ce ar trebui sÄƒ prioritizezi AI Responsabil atunci cÃ¢nd construieÈ™ti aplicaÈ›ii de AI Generativ.
- Principiile de bazÄƒ ale AI Responsabil È™i cum se raporteazÄƒ acestea la AI Generativ.
- Cum sÄƒ aplici aceste principii ale AI Responsabil prin strategii È™i instrumente.

## Obiective de Ã®nvÄƒÈ›are

DupÄƒ finalizarea acestei lecÈ›ii vei È™ti:

- ImportanÈ›a AI Responsabil atunci cÃ¢nd construieÈ™ti aplicaÈ›ii de AI Generativ.
- CÃ¢nd sÄƒ te gÃ¢ndeÈ™ti È™i sÄƒ aplici principiile de bazÄƒ ale AI Responsabil Ã®n construirea aplicaÈ›iilor de AI Generativ.
- Ce instrumente È™i strategii sunt disponibile pentru a pune Ã®n practicÄƒ conceptul de AI Responsabil.

## Principiile AI Responsabil

Entuziasmul pentru AI Generativ nu a fost niciodatÄƒ mai mare. Acest entuziasm a atras mulÈ›i dezvoltatori noi, atenÈ›ie È™i finanÈ›are Ã®n acest domeniu. DeÈ™i acest lucru este foarte pozitiv pentru oricine doreÈ™te sÄƒ construiascÄƒ produse È™i companii folosind AI Generativ, este, de asemenea, important sÄƒ procedÄƒm responsabil.

Pe parcursul acestui curs, ne concentrÄƒm pe construirea startup-ului nostru È™i a produsului nostru educaÈ›ional bazat pe AI. Vom folosi principiile AI Responsabil: Echitate, Incluziune, Fiabilitate/SiguranÈ›Äƒ, Securitate È™i ConfidenÈ›ialitate, TransparenÈ›Äƒ È™i Responsabilitate. Cu ajutorul acestor principii, vom explora cum se raporteazÄƒ acestea la utilizarea AI Generativ Ã®n produsele noastre.

## De ce ar trebui sÄƒ prioritizezi AI Responsabil

Atunci cÃ¢nd construieÈ™ti un produs, adoptarea unei abordÄƒri centrate pe om, avÃ¢nd Ã®n vedere interesul cel mai bun al utilizatorului, duce la cele mai bune rezultate.

Unicitatea AI Generativ constÄƒ Ã®n puterea sa de a crea rÄƒspunsuri utile, informaÈ›ii, Ã®ndrumÄƒri È™i conÈ›inut pentru utilizatori. Acest lucru poate fi realizat fÄƒrÄƒ prea mulÈ›i paÈ™i manuali, ceea ce poate duce la rezultate foarte impresionante. FÄƒrÄƒ o planificare È™i strategii adecvate, acest lucru poate, din pÄƒcate, sÄƒ ducÄƒ È™i la rezultate nocive pentru utilizatori, produsul tÄƒu È™i societatea Ã®n ansamblu.

SÄƒ analizÄƒm cÃ¢teva (dar nu toate) dintre aceste rezultate potenÈ›ial nocive:

### HalucinaÈ›ii

HalucinaÈ›iile sunt un termen folosit pentru a descrie momentul Ã®n care un LLM produce conÈ›inut care este fie complet lipsit de sens, fie ceva ce È™tim cÄƒ este greÈ™it din punct de vedere factual, bazat pe alte surse de informaÈ›ii.

SÄƒ luÄƒm, de exemplu, cazul Ã®n care construim o funcÈ›ie pentru startup-ul nostru care permite studenÈ›ilor sÄƒ punÄƒ Ã®ntrebÄƒri istorice unui model. Un student Ã®ntreabÄƒ: `Cine a fost singurul supravieÈ›uitor al Titanicului?`

Modelul produce un rÄƒspuns precum cel de mai jos:

![Prompt care spune "Cine a fost singurul supravieÈ›uitor al Titanicului"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Sursa: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Acesta este un rÄƒspuns foarte Ã®ncrezÄƒtor È™i detaliat. Din pÄƒcate, este incorect. Chiar È™i cu o cantitate minimÄƒ de cercetare, cineva ar descoperi cÄƒ au existat mai mulÈ›i supravieÈ›uitori ai dezastrului Titanic. Pentru un student care abia Ã®ncepe sÄƒ cerceteze acest subiect, acest rÄƒspuns poate fi suficient de convingÄƒtor Ã®ncÃ¢t sÄƒ nu fie pus la Ã®ndoialÄƒ È™i sÄƒ fie tratat ca un fapt. ConsecinÈ›ele acestui lucru pot duce la un sistem AI nesigur È™i pot afecta negativ reputaÈ›ia startup-ului nostru.

Cu fiecare iteraÈ›ie a unui LLM dat, am observat Ã®mbunÄƒtÄƒÈ›iri ale performanÈ›ei Ã®n reducerea halucinaÈ›iilor. Chiar È™i cu aceastÄƒ Ã®mbunÄƒtÄƒÈ›ire, noi, ca dezvoltatori de aplicaÈ›ii È™i utilizatori, trebuie sÄƒ rÄƒmÃ¢nem conÈ™tienÈ›i de aceste limitÄƒri.

### ConÈ›inut nociv

Am discutat Ã®n secÈ›iunea anterioarÄƒ despre momentul Ã®n care un LLM produce rÄƒspunsuri incorecte sau lipsite de sens. Un alt risc de care trebuie sÄƒ fim conÈ™tienÈ›i este atunci cÃ¢nd un model rÄƒspunde cu conÈ›inut nociv.

ConÈ›inutul nociv poate fi definit ca:

- Oferirea de instrucÈ›iuni sau Ã®ncurajarea auto-vÄƒtÄƒmÄƒrii sau vÄƒtÄƒmÄƒrii anumitor grupuri.
- ConÈ›inut ofensator sau denigrator.
- Ghidarea planificÄƒrii oricÄƒrui tip de atac sau acte violente.
- Oferirea de instrucÈ›iuni despre cum sÄƒ gÄƒseÈ™ti conÈ›inut ilegal sau sÄƒ comiÈ›i acte ilegale.
- AfiÈ™area de conÈ›inut explicit sexual.

Pentru startup-ul nostru, dorim sÄƒ ne asigurÄƒm cÄƒ avem instrumentele È™i strategiile potrivite pentru a preveni ca acest tip de conÈ›inut sÄƒ fie vÄƒzut de studenÈ›i.

### Lipsa echitÄƒÈ›ii

Echitatea este definitÄƒ ca â€asigurarea cÄƒ un sistem AI este lipsit de prejudecÄƒÈ›i È™i discriminare È™i cÄƒ trateazÄƒ pe toatÄƒ lumea Ã®n mod echitabil È™i egal.â€ Ãn lumea AI Generativ, dorim sÄƒ ne asigurÄƒm cÄƒ viziunile excluzive asupra grupurilor marginalizate nu sunt Ã®ntÄƒrite de rezultatele modelului.

Aceste tipuri de rezultate nu sunt doar distructive pentru construirea unor experienÈ›e pozitive de produs pentru utilizatorii noÈ™tri, ci cauzeazÄƒ È™i daune sociale suplimentare. Ca dezvoltatori de aplicaÈ›ii, ar trebui sÄƒ avem Ã®ntotdeauna Ã®n vedere o bazÄƒ largÄƒ È™i diversÄƒ de utilizatori atunci cÃ¢nd construim soluÈ›ii cu AI Generativ.

## Cum sÄƒ foloseÈ™ti AI Generativ Ã®n mod responsabil

Acum cÄƒ am identificat importanÈ›a AI Generativ Responsabil, sÄƒ analizÄƒm 4 paÈ™i pe care Ã®i putem face pentru a construi soluÈ›ii AI Ã®n mod responsabil:

![Ciclul de atenuare](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.ro.png)

### MÄƒsurarea riscurilor potenÈ›iale

Ãn testarea software, testÄƒm acÈ›iunile aÈ™teptate ale unui utilizator pe o aplicaÈ›ie. Ãn mod similar, testarea unui set divers de solicitÄƒri pe care utilizatorii sunt cel mai probabil sÄƒ le foloseascÄƒ este o modalitate bunÄƒ de a mÄƒsura riscurile potenÈ›iale.

Deoarece startup-ul nostru construieÈ™te un produs educaÈ›ional, ar fi bine sÄƒ pregÄƒtim o listÄƒ de solicitÄƒri legate de educaÈ›ie. Acestea ar putea acoperi un anumit subiect, fapte istorice È™i solicitÄƒri despre viaÈ›a studenÈ›ilor.

### Atenuarea riscurilor potenÈ›iale

Este momentul sÄƒ gÄƒsim modalitÄƒÈ›i prin care putem preveni sau limita riscurile potenÈ›iale cauzate de model È™i de rÄƒspunsurile acestuia. Putem privi acest aspect Ã®n 4 straturi diferite:

![Straturi de atenuare](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.ro.png)

- **Model**. Alegerea modelului potrivit pentru cazul de utilizare potrivit. Modelele mai mari È™i mai complexe, cum ar fi GPT-4, pot prezenta un risc mai mare de conÈ›inut nociv atunci cÃ¢nd sunt aplicate la cazuri de utilizare mai mici È™i mai specifice. Utilizarea datelor de antrenament pentru ajustare finÄƒ reduce, de asemenea, riscul de conÈ›inut nociv.

- **Sistem de siguranÈ›Äƒ**. Un sistem de siguranÈ›Äƒ este un set de instrumente È™i configuraÈ›ii pe platforma care serveÈ™te modelul, care ajutÄƒ la atenuarea riscurilor. Un exemplu este sistemul de filtrare a conÈ›inutului din serviciul Azure OpenAI. Sistemele ar trebui sÄƒ detecteze atacurile de tip jailbreak È™i activitÄƒÈ›ile nedorite, cum ar fi cererile de la roboÈ›i.

- **Metaprompt**. Metaprompturile È™i ancorarea sunt modalitÄƒÈ›i prin care putem direcÈ›iona sau limita modelul pe baza anumitor comportamente È™i informaÈ›ii. Acest lucru ar putea Ã®nsemna utilizarea intrÄƒrilor de sistem pentru a defini anumite limite ale modelului. Ãn plus, oferirea de rezultate mai relevante pentru domeniul sau scopul sistemului.

De asemenea, se pot folosi tehnici precum Generarea AugmentatÄƒ prin Recuperare (RAG) pentru ca modelul sÄƒ extragÄƒ informaÈ›ii doar dintr-o selecÈ›ie de surse de Ã®ncredere. ExistÄƒ o lecÈ›ie mai tÃ¢rziu Ã®n acest curs despre [construirea aplicaÈ›iilor de cÄƒutare](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **ExperienÈ›a utilizatorului**. Ultimul strat este acolo unde utilizatorul interacÈ›ioneazÄƒ direct cu modelul prin interfaÈ›a aplicaÈ›iei noastre Ã®ntr-un fel. Ãn acest fel, putem proiecta UI/UX pentru a limita utilizatorul Ã®n privinÈ›a tipurilor de intrÄƒri pe care le poate trimite modelului, precum È™i textul sau imaginile afiÈ™ate utilizatorului. CÃ¢nd implementÄƒm aplicaÈ›ia AI, trebuie sÄƒ fim transparenÈ›i cu privire la ceea ce aplicaÈ›ia noastrÄƒ AI Generativ poate È™i nu poate face.

Avem o lecÈ›ie dedicatÄƒ [ProiectÄƒrii UX pentru AplicaÈ›ii AI](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluarea modelului**. Lucrul cu LLM-uri poate fi provocator deoarece nu avem Ã®ntotdeauna control asupra datelor pe care modelul a fost antrenat. Indiferent de acest aspect, ar trebui sÄƒ evaluÄƒm Ã®ntotdeauna performanÈ›a È™i rezultatele modelului. Este important sÄƒ mÄƒsurÄƒm acurateÈ›ea, similaritatea, ancorarea È™i relevanÈ›a rezultatelor modelului. Acest lucru ajutÄƒ la oferirea de transparenÈ›Äƒ È™i Ã®ncredere pÄƒrÈ›ilor interesate È™i utilizatorilor.

### Operarea unei soluÈ›ii AI Generativ Responsabile

Construirea unei practici operaÈ›ionale Ã®n jurul aplicaÈ›iilor AI este etapa finalÄƒ. Aceasta include colaborarea cu alte pÄƒrÈ›i ale startup-ului nostru, cum ar fi departamentele juridice È™i de securitate, pentru a ne asigura cÄƒ respectÄƒm toate politicile de reglementare. Ãnainte de lansare, dorim, de asemenea, sÄƒ construim planuri legate de livrare, gestionarea incidentelor È™i revenirea la o versiune anterioarÄƒ pentru a preveni orice prejudiciu pentru utilizatorii noÈ™tri.

## Instrumente

DeÈ™i munca de dezvoltare a soluÈ›iilor AI Responsabile poate pÄƒrea multÄƒ, este o muncÄƒ bine meritatÄƒ. Pe mÄƒsurÄƒ ce domeniul AI Generativ creÈ™te, mai multe instrumente care sÄƒ ajute dezvoltatorii sÄƒ integreze eficient responsabilitatea Ã®n fluxurile lor de lucru vor evolua. De exemplu, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) poate ajuta la detectarea conÈ›inutului È™i imaginilor nocive printr-o cerere API.

## Verificarea cunoÈ™tinÈ›elor

Care sunt cÃ¢teva lucruri de care trebuie sÄƒ È›ii cont pentru a asigura utilizarea responsabilÄƒ a AI?

1. CÄƒ rÄƒspunsul este corect.  
1. Utilizarea nocivÄƒ, ca AI sÄƒ nu fie folosit pentru scopuri ilegale.  
1. Asigurarea cÄƒ AI este lipsit de prejudecÄƒÈ›i È™i discriminare.  

R: 2 È™i 3 sunt corecte. AI Responsabil te ajutÄƒ sÄƒ iei Ã®n considerare cum sÄƒ atenuezi efectele nocive È™i prejudecÄƒÈ›ile È™i multe altele.

## ğŸš€ Provocare

CiteÈ™te despre [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) È™i vezi ce poÈ›i adopta pentru utilizarea ta.

## FelicitÄƒri, continuÄƒ sÄƒ Ã®nveÈ›i

DupÄƒ ce ai finalizat aceastÄƒ lecÈ›ie, consultÄƒ [colecÈ›ia de Ã®nvÄƒÈ›are AI Generativ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a-È›i Ã®mbunÄƒtÄƒÈ›i cunoÈ™tinÈ›ele despre AI Generativ!

Mergi la LecÈ›ia 4, unde vom analiza [Fundamentele Ingineriei Prompturilor](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de oameni. Nu ne asumÄƒm responsabilitatea pentru neÃ®nÈ›elegerile sau interpretÄƒrile greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.