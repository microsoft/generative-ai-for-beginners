{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Următorul notebook a fost generat automat de GitHub Copilot Chat și este destinat doar configurării inițiale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introducere în Ingineria Prompturilor\n",
    "Ingineria prompturilor este procesul de creare și optimizare a prompturilor pentru sarcini de procesare a limbajului natural. Aceasta presupune alegerea prompturilor potrivite, ajustarea parametrilor lor și evaluarea performanței acestora. Ingineria prompturilor este esențială pentru a obține acuratețe și eficiență ridicată în modelele NLP. În această secțiune, vom explora elementele de bază ale ingineriei prompturilor folosind modelele OpenAI pentru explorare.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiul 1: Tokenizare\n",
    "Explorează tokenizarea folosind tiktoken, un tokenizer rapid open-source de la OpenAI\n",
    "Vezi [OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb?WT.mc_id=academic-105485-koreyst) pentru mai multe exemple.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXERCISE:\n",
    "# 1. Run the exercise as is first\n",
    "# 2. Change the text to any prompt input you want to use & re-run to see tokens\n",
    "\n",
    "import tiktoken\n",
    "\n",
    "# Define the prompt you want tokenized\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "# Set the model you want encoding for\n",
    "encoding = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "# Encode the text - gives you the tokens in integer form\n",
    "tokens = encoding.encode(text)\n",
    "print(tokens);\n",
    "\n",
    "# Decode the integers to see what the text versions look like\n",
    "[encoding.decode_single_token_bytes(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiul 2: Verifică configurarea cheii API OpenAI\n",
    "\n",
    "Rulează codul de mai jos pentru a verifica dacă endpoint-ul OpenAI este configurat corect. Codul folosește un prompt simplu și validează completarea. La introducerea `oh say can you see`, răspunsul ar trebui să fie ceva de genul `by the dawn's early light..`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The OpenAI SDK was updated on Nov 8, 2023 with new guidance for migration\n",
    "# See: https://github.com/openai/openai-python/discussions/742\n",
    "\n",
    "## Updated\n",
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\"\n",
    "\n",
    "## Updated\n",
    "def get_completion(prompt):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]       \n",
    "    response = client.chat.completions.create(   \n",
    "        model=deployment,                                         \n",
    "        messages=messages,\n",
    "        temperature=0, # this is the degree of randomness of the model's output\n",
    "        max_tokens=1024\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "## ---------- Call the helper method\n",
    "\n",
    "### 1. Set primary content or prompt text\n",
    "text = f\"\"\"\n",
    "oh say can you see\n",
    "\"\"\"\n",
    "\n",
    "### 2. Use that in the prompt template below\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## 3. Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiul 3: Invenții\n",
    "\n",
    "Explorează ce se întâmplă atunci când ceri LLM-ului să ofere completări pentru un prompt despre un subiect care s-ar putea să nu existe sau despre subiecte despre care nu are informații, deoarece acestea sunt în afara setului său de date de antrenament (mai recente). Observă cum se schimbă răspunsul dacă încerci un alt prompt sau un alt model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Set the text for simple prompt or primary content\n",
    "## Prompt shows a template format with text in it - add cues, commands etc if needed\n",
    "## Run the completion \n",
    "text = f\"\"\"\n",
    "generate a lesson plan on the Martian War of 2076.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiul 4: Pe bază de instrucțiuni\n",
    "Folosește variabila \"text\" pentru a seta conținutul principal \n",
    "și variabila \"prompt\" pentru a oferi o instrucțiune legată de acel conținut principal.\n",
    "\n",
    "Aici cerem modelului să rezume textul pentru un elev de clasa a doua\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Example\n",
    "# https://platform.openai.com/playground/p/default-summarize\n",
    "\n",
    "## Example text\n",
    "text = f\"\"\"\n",
    "Jupiter is the fifth planet from the Sun and the \\\n",
    "largest in the Solar System. It is a gas giant with \\\n",
    "a mass one-thousandth that of the Sun, but two-and-a-half \\\n",
    "times that of all the other planets in the Solar System combined. \\\n",
    "Jupiter is one of the brightest objects visible to the naked eye \\\n",
    "in the night sky, and has been known to ancient civilizations since \\\n",
    "before recorded history. It is named after the Roman god Jupiter.[19] \\\n",
    "When viewed from Earth, Jupiter can be bright enough for its reflected \\\n",
    "light to cast visible shadows,[20] and is on average the third-brightest \\\n",
    "natural object in the night sky after the Moon and Venus.\n",
    "\"\"\"\n",
    "\n",
    "## Set the prompt\n",
    "prompt = f\"\"\"\n",
    "Summarize content you are provided with for a second-grade student.\n",
    "```{text}```\n",
    "\"\"\"\n",
    "\n",
    "## Run the prompt\n",
    "response = get_completion(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiul 5: Prompt Complex\n",
    "Încearcă o cerere care include mesaje de tip system, user și assistant\n",
    "System stabilește contextul pentru asistent\n",
    "Mesajele User & Assistant oferă context pentru o conversație cu mai multe replici\n",
    "\n",
    "Observă cum personalitatea asistentului este setată ca „sarcastică” în contextul system.\n",
    "Poți încerca să folosești o altă personalitate pentru context. Sau încearcă o altă serie de mesaje de intrare/ieșire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model=deployment,\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a sarcastic assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Who won the world series in 2020?\"},\n",
    "        {\"role\": \"assistant\", \"content\": \"Who do you think won? The Los Angeles Dodgers of course.\"},\n",
    "        {\"role\": \"user\", \"content\": \"Where was it played?\"}\n",
    "    ]\n",
    ")\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercițiu: Explorează-ți intuiția\n",
    "Exemplele de mai sus îți oferă modele pe care le poți folosi pentru a crea noi prompturi (simple, complexe, instrucțiuni etc.) – încearcă să creezi alte exerciții pentru a explora și alte idei despre care am discutat, cum ar fi exemple, indicii și altele.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Declinarea responsabilității**:\nAcest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși depunem eforturi pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa nativă, trebuie considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de oameni. Nu ne asumăm răspunderea pentru eventuale neînțelegeri sau interpretări greșite care pot apărea din utilizarea acestei traduceri.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "coopTranslator": {
   "original_hash": "ec9eedd4f3981f097d4bd34c849cb8b6",
   "translation_date": "2025-08-25T13:49:19+00:00",
   "source_file": "04-prompt-engineering-fundamentals/python/oai-assignment.ipynb",
   "language_code": "ro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}