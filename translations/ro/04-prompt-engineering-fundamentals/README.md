<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T16:18:31+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "ro"
}
-->
# Fundamentele Ingineriei Prompturilor

## Introducere

Acest modul acoperÄƒ concepte È™i tehnici esenÈ›iale pentru crearea de prompturi eficiente Ã®n modelele AI generative. Modul Ã®n care scrii un prompt pentru un LLM conteazÄƒ. Un prompt bine construit poate obÈ›ine un rÄƒspuns de calitate mai bunÄƒ. Dar ce Ã®nseamnÄƒ exact termeni precum _prompt_ È™i _ingineria prompturilor_? È˜i cum Ã®mbunÄƒtÄƒÈ›esc _intrarea promptului_ pe care o trimit la LLM? Acestea sunt Ã®ntrebÄƒrile la care vom Ã®ncerca sÄƒ rÄƒspundem Ã®n acest capitol È™i Ã®n cel urmÄƒtor.

AI generativÄƒ este capabilÄƒ sÄƒ creeze conÈ›inut nou (de exemplu, text, imagini, audio, cod etc.) ca rÄƒspuns la cererile utilizatorilor. RealizeazÄƒ acest lucru folosind _Modele de Limbaj de Mari Dimensiuni_ precum seria GPT ("Generative Pre-trained Transformer") de la OpenAI, care sunt antrenate pentru a folosi limbajul natural È™i codul.

Utilizatorii pot interacÈ›iona acum cu aceste modele folosind paradigme familiare precum chat-ul, fÄƒrÄƒ a avea nevoie de expertizÄƒ tehnicÄƒ sau instruire. Modelele sunt bazate pe _prompturi_ - utilizatorii trimit o intrare text (prompt) È™i primesc Ã®napoi rÄƒspunsul AI (completare). Ei pot apoi "conversa cu AI" iterativ, Ã®n conversaÈ›ii pe mai multe runde, rafinÃ¢ndu-È™i promptul pÃ¢nÄƒ cÃ¢nd rÄƒspunsul corespunde aÈ™teptÄƒrilor lor.

"Prompturile" devin acum interfaÈ›a principalÄƒ de _programare_ pentru aplicaÈ›iile AI generative, spunÃ¢nd modelelor ce sÄƒ facÄƒ È™i influenÈ›Ã¢nd calitatea rÄƒspunsurilor returnate. "Ingineria Prompturilor" este un domeniu de studiu Ã®n creÈ™tere rapidÄƒ care se concentreazÄƒ pe _designul È™i optimizarea_ prompturilor pentru a livra rÄƒspunsuri consistente È™i de calitate la scarÄƒ.

## Obiectivele ÃnvÄƒÈ›Äƒrii

Ãn aceastÄƒ lecÈ›ie, Ã®nvÄƒÈ›Äƒm ce este Ingineria Prompturilor, de ce conteazÄƒ È™i cum putem crea prompturi mai eficiente pentru un model È™i un obiectiv de aplicaÈ›ie dat. Vom Ã®nÈ›elege concepte de bazÄƒ È™i bune practici pentru ingineria prompturilor - È™i vom Ã®nvÄƒÈ›a despre un mediu interactiv de tip "sandbox" Ã®n Jupyter Notebooks unde putem vedea aceste concepte aplicate la exemple reale.

PÃ¢nÄƒ la sfÃ¢rÈ™itul acestei lecÈ›ii vom putea:

1. Explica ce este ingineria prompturilor È™i de ce conteazÄƒ.
2. Descrie componentele unui prompt È™i cum sunt folosite.
3. ÃnvÄƒÈ›a bune practici È™i tehnici pentru ingineria prompturilor.
4. Aplica tehnicile Ã®nvÄƒÈ›ate la exemple reale, folosind un endpoint OpenAI.

## Termeni Cheie

Ingineria Prompturilor: Practica de a proiecta È™i rafina intrÄƒrile pentru a ghida modelele AI sÄƒ producÄƒ rezultatele dorite.
Tokenizarea: Procesul de conversie a textului Ã®n unitÄƒÈ›i mai mici, numite tokeni, pe care un model le poate Ã®nÈ›elege È™i procesa.
LLM-uri Ajustate prin InstrucÈ›iuni: Modele de Limbaj de Mari Dimensiuni (LLM-uri) care au fost ajustate cu instrucÈ›iuni specifice pentru a Ã®mbunÄƒtÄƒÈ›i acurateÈ›ea È™i relevanÈ›a rÄƒspunsurilor lor.

## Sandbox de ÃnvÄƒÈ›are

Ingineria prompturilor este Ã®n prezent mai mult o artÄƒ decÃ¢t o È™tiinÈ›Äƒ. Cea mai bunÄƒ modalitate de a ne Ã®mbunÄƒtÄƒÈ›i intuiÈ›ia pentru aceasta este sÄƒ _practicÄƒm mai mult_ È™i sÄƒ adoptÄƒm o abordare de Ã®ncercare È™i eroare care combinÄƒ expertiza Ã®n domeniul aplicaÈ›iei cu tehnicile recomandate È™i optimizÄƒrile specifice modelului.

Notebook-ul Jupyter care Ã®nsoÈ›eÈ™te aceastÄƒ lecÈ›ie oferÄƒ un mediu _sandbox_ unde poÈ›i Ã®ncerca ceea ce Ã®nveÈ›i - pe mÄƒsurÄƒ ce avansezi sau ca parte a provocÄƒrii de cod la final. Pentru a executa exerciÈ›iile, vei avea nevoie de:

1. **O cheie API Azure OpenAI** - punctul de serviciu pentru un LLM implementat.
2. **Un Runtime Python** - Ã®n care Notebook-ul poate fi executat.
3. **Variabile de Mediu Locale** - _completÄƒ acum paÈ™ii [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) pentru a te pregÄƒti_.

Notebook-ul vine cu exerciÈ›ii _de Ã®nceput_ - dar eÈ™ti Ã®ncurajat sÄƒ adaugi propriile tale secÈ›iuni de _Markdown_ (descriere) È™i _Cod_ (cereri de prompt) pentru a Ã®ncerca mai multe exemple sau idei - È™i a-È›i construi intuiÈ›ia pentru designul prompturilor.

## Ghid Ilustrat

Vrei sÄƒ obÈ›ii o imagine de ansamblu a ceea ce acoperÄƒ aceastÄƒ lecÈ›ie Ã®nainte de a te aprofunda? VerificÄƒ acest ghid ilustrat, care Ã®È›i oferÄƒ o idee despre principalele subiecte acoperite È™i concluziile cheie pentru a reflecta asupra fiecÄƒruia. Harta lecÈ›iei te duce de la Ã®nÈ›elegerea conceptelor de bazÄƒ È™i a provocÄƒrilor la abordarea lor cu tehnici È™i bune practici relevante de inginerie a prompturilor. ReÈ›ine cÄƒ secÈ›iunea "Tehnici Avansate" din acest ghid se referÄƒ la conÈ›inutul acoperit Ã®n _capitolul urmÄƒtor_ al acestui curriculum.

## Startup-ul Nostru

Acum, sÄƒ vorbim despre cum _acest subiect_ se leagÄƒ de misiunea noastrÄƒ de startup de a [aduce inovaÈ›ia AI Ã®n educaÈ›ie](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Dorim sÄƒ construim aplicaÈ›ii AI de _Ã®nvÄƒÈ›are personalizatÄƒ_ - aÈ™a cÄƒ sÄƒ ne gÃ¢ndim cum ar putea diferiÈ›i utilizatori ai aplicaÈ›iei noastre sÄƒ "proiecteze" prompturi:

- **Administratorii** ar putea cere AI sÄƒ _analizeze datele curriculumului pentru a identifica lacunele Ã®n acoperire_. AI poate rezuma rezultatele sau le poate vizualiza cu cod.
- **EducaÈ›ii** ar putea cere AI sÄƒ _genereze un plan de lecÈ›ie pentru un public È›intÄƒ È™i un subiect_. AI poate construi planul personalizat Ã®ntr-un format specificat.
- **StudenÈ›ii** ar putea cere AI sÄƒ _le ofere meditaÈ›ii Ã®ntr-un subiect dificil_. AI poate ghida acum studenÈ›ii cu lecÈ›ii, indicii È™i exemple adaptate nivelului lor.

Aceasta este doar vÃ¢rful aisbergului. VerificÄƒ [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - o bibliotecÄƒ de prompturi open-source curatÄƒ de experÈ›i Ã®n educaÈ›ie - pentru a obÈ›ine o Ã®nÈ›elegere mai largÄƒ a posibilitÄƒÈ›ilor! _ÃncearcÄƒ sÄƒ rulezi unele dintre aceste prompturi Ã®n sandbox sau folosind OpenAI Playground pentru a vedea ce se Ã®ntÃ¢mplÄƒ!_

## Ce este Ingineria Prompturilor?

Am Ã®nceput aceastÄƒ lecÈ›ie definind **Ingineria Prompturilor** ca procesul de _proiectare È™i optimizare_ a intrÄƒrilor text (prompturi) pentru a livra rÄƒspunsuri consistente È™i de calitate (completÄƒri) pentru un obiectiv de aplicaÈ›ie È™i model dat. Putem considera aceasta ca un proces Ã®n 2 paÈ™i:

- _proiectarea_ promptului iniÈ›ial pentru un model È™i un obiectiv dat
- _rafinarea_ promptului iterativ pentru a Ã®mbunÄƒtÄƒÈ›i calitatea rÄƒspunsului

Aceasta este Ã®n mod necesar un proces de Ã®ncercare È™i eroare care necesitÄƒ intuiÈ›ia È™i efortul utilizatorului pentru a obÈ›ine rezultate optime. De ce este important? Pentru a rÄƒspunde la aceastÄƒ Ã®ntrebare, trebuie mai Ã®ntÃ¢i sÄƒ Ã®nÈ›elegem trei concepte:

- _Tokenizarea_ = cum "vede" modelul promptul
- _LLM-uri de BazÄƒ_ = cum "proceseazÄƒ" modelul de bazÄƒ un prompt
- _LLM-uri Ajustate prin InstrucÈ›iuni_ = cum poate modelul sÄƒ vadÄƒ acum "sarcini"

### Tokenizarea

Un LLM vede prompturile ca o _secvenÈ›Äƒ de tokeni_ unde diferite modele (sau versiuni ale unui model) pot tokeniza acelaÈ™i prompt Ã®n moduri diferite. Deoarece LLM-urile sunt antrenate pe tokeni (È™i nu pe text brut), modul Ã®n care prompturile sunt tokenizate are un impact direct asupra calitÄƒÈ›ii rÄƒspunsului generat.

Pentru a obÈ›ine o intuiÈ›ie despre cum funcÈ›ioneazÄƒ tokenizarea, Ã®ncearcÄƒ instrumente precum [Tokenizer-ul OpenAI](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) prezentat mai jos. CopiazÄƒ-È›i promptul - È™i vezi cum este transformat Ã®n tokeni, acordÃ¢nd atenÈ›ie modului Ã®n care sunt tratate caracterele de spaÈ›iu È™i semnele de punctuaÈ›ie. ReÈ›ine cÄƒ acest exemplu aratÄƒ un LLM mai vechi (GPT-3) - aÈ™a cÄƒ Ã®ncercarea cu un model mai nou poate produce un rezultat diferit.

### Concept: Modele de BazÄƒ

OdatÄƒ ce un prompt este tokenizat, funcÈ›ia principalÄƒ a ["LLM-ului de BazÄƒ"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (sau model de bazÄƒ) este sÄƒ prezicÄƒ tokenul din acea secvenÈ›Äƒ. Deoarece LLM-urile sunt antrenate pe seturi de date masive de text, au o bunÄƒ Ã®nÈ›elegere a relaÈ›iilor statistice dintre tokeni È™i pot face acea predicÈ›ie cu un anumit nivel de Ã®ncredere. ReÈ›ine cÄƒ nu Ã®nÈ›eleg _semnificaÈ›ia_ cuvintelor din prompt sau token; vÄƒd doar un model pe care Ã®l pot "completa" cu urmÄƒtoarea lor predicÈ›ie. Pot continua sÄƒ prezicÄƒ secvenÈ›a pÃ¢nÄƒ cÃ¢nd este Ã®ntreruptÄƒ de intervenÈ›ia utilizatorului sau de o condiÈ›ie prestabilitÄƒ.

Vrei sÄƒ vezi cum funcÈ›ioneazÄƒ completarea bazatÄƒ pe prompt? Introdu promptul de mai sus Ã®n [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) din Azure OpenAI Studio cu setÄƒrile implicite. Sistemul este configurat sÄƒ trateze prompturile ca cereri de informaÈ›ii - aÈ™a cÄƒ ar trebui sÄƒ vezi o completare care satisface acest context.

Dar ce se Ã®ntÃ¢mplÄƒ dacÄƒ utilizatorul dorea sÄƒ vadÄƒ ceva specific care sÄƒ Ã®ndeplineascÄƒ anumite criterii sau un obiectiv de sarcinÄƒ? Aici intrÄƒ Ã®n joc LLM-urile _ajustate prin instrucÈ›iuni_.

### Concept: LLM-uri Ajustate prin InstrucÈ›iuni

Un [LLM Ajustat prin InstrucÈ›iuni](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) Ã®ncepe cu modelul de bazÄƒ È™i Ã®l ajusteazÄƒ fin cu exemple sau perechi de intrare/ieÈ™ire (de exemplu, "mesaje" pe mai multe runde) care pot conÈ›ine instrucÈ›iuni clare - iar rÄƒspunsul AI Ã®ncearcÄƒ sÄƒ urmeze acea instrucÈ›iune.

Acest lucru foloseÈ™te tehnici precum ÃnvÄƒÈ›area prin RecompensÄƒ cu Feedback Uman (RLHF) care pot antrena modelul sÄƒ _urmeze instrucÈ›iuni_ È™i sÄƒ _Ã®nveÈ›e din feedback_ astfel Ã®ncÃ¢t sÄƒ producÄƒ rÄƒspunsuri mai potrivite pentru aplicaÈ›ii practice È™i mai relevante pentru obiectivele utilizatorului.

SÄƒ Ã®ncercÄƒm - reviziteazÄƒ promptul de mai sus, dar acum schimbÄƒ _mesajul sistemului_ pentru a oferi urmÄƒtoarea instrucÈ›iune ca context:

> _RezumaÈ›i conÈ›inutul pe care Ã®l primiÈ›i pentru un elev de clasa a doua. PÄƒstraÈ›i rezultatul la un paragraf cu 3-5 puncte._

Vezi cum rezultatul este acum ajustat pentru a reflecta scopul È™i formatul dorit? Un educator poate acum folosi direct acest rÄƒspuns Ã®n diapozitivele pentru acea clasÄƒ.

## De ce avem nevoie de Ingineria Prompturilor?

Acum cÄƒ È™tim cum sunt procesate prompturile de cÄƒtre LLM-uri, sÄƒ vorbim despre _de ce_ avem nevoie de ingineria prompturilor. RÄƒspunsul constÄƒ Ã®n faptul cÄƒ LLM-urile actuale prezintÄƒ o serie de provocÄƒri care fac _completÄƒrile fiabile È™i consistente_ mai greu de realizat fÄƒrÄƒ a depune eforturi Ã®n construcÈ›ia È™i optimizarea prompturilor. De exemplu:

1. **RÄƒspunsurile modelului sunt stochastice.** _AcelaÈ™i prompt_ va produce probabil rÄƒspunsuri diferite cu modele sau versiuni de model diferite. È˜i poate produce chiar È™i rezultate diferite cu _acelaÈ™i model_ la momente diferite. _Tehnicile de inginerie a prompturilor ne pot ajuta sÄƒ minimizÄƒm aceste variaÈ›ii prin oferirea unor ghidaje mai bune_.

1. **Modelele pot fabrica rÄƒspunsuri.** Modelele sunt pre-antrenate cu _seturi de date mari, dar finite_, ceea ce Ã®nseamnÄƒ cÄƒ nu au cunoÈ™tinÈ›e despre concepte Ã®n afara acelui domeniu de antrenament. Drept urmare, pot produce completÄƒri care sunt inexacte, imaginare sau direct contradictorii cu faptele cunoscute. _Tehnicile de inginerie a prompturilor ajutÄƒ utilizatorii sÄƒ identifice È™i sÄƒ atenueze astfel de fabricaÈ›ii, de exemplu, prin cererea de citÄƒri sau raÈ›ionamente AI_.

1. **CapacitÄƒÈ›ile modelelor vor varia.** Modelele mai noi sau generaÈ›iile de modele vor avea capacitÄƒÈ›i mai bogate, dar vor aduce È™i particularitÄƒÈ›i unice È™i compromisuri Ã®n cost È™i complexitate. _Ingineria prompturilor ne poate ajuta sÄƒ dezvoltÄƒm bune practici È™i fluxuri de lucru care sÄƒ abstractizeze diferenÈ›ele È™i sÄƒ se adapteze la cerinÈ›ele specifice modelului Ã®n moduri scalabile È™i fÄƒrÄƒ probleme_.

SÄƒ vedem acest lucru Ã®n acÈ›iune Ã®n OpenAI sau Azure OpenAI Playground:

- FoloseÈ™te acelaÈ™i prompt cu diferite implementÄƒri LLM (de exemplu, OpenAI, Azure OpenAI, Hugging Face) - ai observat variaÈ›iile?
- FoloseÈ™te acelaÈ™i prompt Ã®n mod repetat cu aceeaÈ™i implementare LLM (de exemplu, Azure OpenAI playground) - cum au diferit aceste variaÈ›ii?

### Exemplu de FabricaÈ›ii

Ãn acest curs, folosim termenul **"fabricaÈ›ie"** pentru a face referire la fenomenul Ã®n care LLM-urile genereazÄƒ uneori informaÈ›ii factually incorecte din cauza limitÄƒrilor Ã®n antrenamentul lor sau a altor constrÃ¢ngeri. Poate ai auzit de asemenea de acest lucru referit ca _"halucinaÈ›ii"_ Ã®n articole populare sau lucrÄƒri de cercetare. Cu toate acestea, recomandÄƒm cu tÄƒrie utilizarea termenului _"fabricaÈ›ie"_ pentru a nu antropomorfiza accidental comportamentul atribuind o trÄƒsÄƒturÄƒ umanÄƒ unui rezultat generat de maÈ™inÄƒ. Acest lucru Ã®ntÄƒreÈ™te, de asemenea, [ghidurile AI Responsabile](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) din perspectiva terminologiei, eliminÃ¢nd termenii care pot fi consideraÈ›i ofensatori sau neincluzivi Ã®n unele contexte.

Vrei sÄƒ obÈ›ii o idee despre cum funcÈ›ioneazÄƒ fabricaÈ›iile? GÃ¢ndeÈ™te-te la un prompt care instruieÈ™te AI sÄƒ genereze conÈ›inut pentru un subiect inexistent (pentru a te asigura cÄƒ nu se gÄƒseÈ™te Ã®n setul de date de antrenament). De exemplu - am Ã®ncercat acest prompt:

> **Prompt:** genereazÄƒ un plan de lecÈ›ie despre RÄƒzboiul MarÈ›ian din 2076.

O cÄƒutare pe web mi-a arÄƒtat cÄƒ existau conturi fictive (de exemplu, seriale de televiziune sau cÄƒrÈ›i) despre rÄƒzboaie marÈ›iene - dar niciunul Ã®n 2076. Bunul simÈ› ne spune de asemenea cÄƒ 2076 este _Ã®n viitor_ È™i, prin urmare, nu poate fi asociat cu un eveniment real.

Deci, ce se Ã®ntÃ¢mplÄƒ cÃ¢nd rulÄƒm acest prompt cu diferiÈ›i furnizori LLM?

> **RÄƒspuns 1**: OpenAI Playground (GPT-35)

> **RÄƒspuns 2**: Azure OpenAI Playground (GPT-35)

> **RÄƒspuns 3**: : Hugging Face Chat Playground (LLama-2)

AÈ™a cum era de aÈ™teptat, fiecare model (sau versiune de model) produce rÄƒspunsuri uÈ™or diferite datoritÄƒ comportamentului stocastic È™i variaÈ›iilor de capacitate ale modelului. De exemplu, un model È›inteÈ™te un public de clasa a VIII-a, Ã®n timp ce altul presupune un elev de liceu. Dar toate cele trei modele au generat rÄƒspunsuri care ar putea convinge un utilizator neinformat cÄƒ evenimentul era real.

Tehnici de inginerie a prompturilor precum _metaprompting_ È™i _configurarea temperaturii_ pot reduce fabricaÈ›iile modelului Ã®ntr-o anumitÄƒ mÄƒsurÄƒ. Noi _arhitecturi_ de inginerie a prompturilor Ã®ncorporeazÄƒ de asemenea noi instrumente È™i tehnici Ã®n mod fluid Ã®n fluxul de prompturi, pentru a
Valoarea realÄƒ a È™abloanelor constÄƒ Ã®n capacitatea de a crea È™i publica _biblioteci de prompturi_ pentru domenii de aplicaÈ›ie verticale - unde È™ablonul de prompt este acum _optimizat_ pentru a reflecta contextul sau exemplele specifice aplicaÈ›iei, ceea ce face ca rÄƒspunsurile sÄƒ fie mai relevante È™i mai precise pentru publicul È›intÄƒ. Repozitoriul [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) este un exemplu excelent al acestei abordÄƒri, curÃ¢nd o bibliotecÄƒ de prompturi pentru domeniul educaÈ›iei, cu accent pe obiective cheie precum planificarea lecÈ›iilor, proiectarea curriculumului, tutoratul studenÈ›ilor etc.

## ConÈ›inut de Suport

DacÄƒ ne gÃ¢ndim la construcÈ›ia prompturilor ca avÃ¢nd o instrucÈ›iune (sarcinÄƒ) È™i un È›intÄƒ (conÈ›inut principal), atunci _conÈ›inutul secundar_ este ca un context suplimentar pe care Ã®l oferim pentru a **influenÈ›a Ã®ntr-un fel ieÈ™irea**. Poate fi ajustarea parametrilor, instrucÈ›iuni de formatare, taxonomii de subiecte etc., care pot ajuta modelul sÄƒ _adapteze_ rÄƒspunsul sÄƒu pentru a corespunde obiectivelor sau aÈ™teptÄƒrilor utilizatorului dorit.

De exemplu: AvÃ¢nd un catalog de cursuri cu metadate extinse (nume, descriere, nivel, etichete de metadate, instructor etc.) pentru toate cursurile disponibile Ã®n curriculum:

- putem defini o instrucÈ›iune pentru "a rezuma catalogul de cursuri pentru toamna 2023"
- putem folosi conÈ›inutul principal pentru a oferi cÃ¢teva exemple de ieÈ™ire doritÄƒ
- putem folosi conÈ›inutul secundar pentru a identifica primele 5 "etichete" de interes.

Acum, modelul poate oferi un rezumat Ã®n formatul arÄƒtat de cÃ¢teva exemple - dar dacÄƒ un rezultat are mai multe etichete, poate prioritiza cele 5 etichete identificate Ã®n conÈ›inutul secundar.

---

## Cele mai bune practici pentru Prompturi

Acum cÄƒ È™tim cum pot fi _construite_ prompturile, putem Ã®ncepe sÄƒ ne gÃ¢ndim cum sÄƒ le _proiectÄƒm_ pentru a reflecta cele mai bune practici. Putem gÃ¢ndi acest lucru Ã®n douÄƒ pÄƒrÈ›i - avÃ¢nd mentalitatea corectÄƒ È™i aplicÃ¢nd tehnicile potrivite.

### Mentalitatea de Inginerie a Prompturilor

Ingineria Prompturilor este un proces de Ã®ncercare È™i eroare, aÈ™a cÄƒ È›ineÈ›i cont de trei factori generali de ghidare:

1. **ÃnÈ›elegerea domeniului conteazÄƒ.** AcurateÈ›ea È™i relevanÈ›a rÄƒspunsului sunt o funcÈ›ie a _domeniului_ Ã®n care acea aplicaÈ›ie sau utilizator opereazÄƒ. AplicaÈ›i intuiÈ›ia È™i expertiza de domeniu pentru a **personaliza tehnicile** Ã®n continuare. De exemplu, definiÈ›i _personalitÄƒÈ›i specifice domeniului_ Ã®n prompturile sistemului dumneavoastrÄƒ sau folosiÈ›i _È™abloane specifice domeniului_ Ã®n prompturile utilizatorului. OferiÈ›i conÈ›inut secundar care reflectÄƒ contexte specifice domeniului sau folosiÈ›i _indicii È™i exemple specifice domeniului_ pentru a ghida modelul cÄƒtre tipare de utilizare familiare.

2. **ÃnÈ›elegerea modelului conteazÄƒ.** È˜tim cÄƒ modelele sunt stocastice prin natura lor. Dar implementÄƒrile modelelor pot varia È™i Ã®n funcÈ›ie de setul de date de antrenament pe care Ã®l folosesc (cunoÈ™tinÈ›e pre-antrenate), capacitÄƒÈ›ile pe care le oferÄƒ (de exemplu, prin API sau SDK) È™i tipul de conÈ›inut pentru care sunt optimizate (de exemplu, cod vs. imagini vs. text). ÃnÈ›elegeÈ›i punctele forte È™i limitÄƒrile modelului pe care Ã®l folosiÈ›i È™i folosiÈ›i acele cunoÈ™tinÈ›e pentru a _prioritiza sarcinile_ sau a construi _È™abloane personalizate_ care sunt optimizate pentru capacitÄƒÈ›ile modelului.

3. **IteraÈ›ia È™i validarea conteazÄƒ.** Modelele evolueazÄƒ rapid, la fel È™i tehnicile pentru ingineria prompturilor. Ca expert Ã®n domeniu, este posibil sÄƒ aveÈ›i alt context sau criterii pentru _aplicaÈ›ia dumneavoastrÄƒ specificÄƒ_, care s-ar putea sÄƒ nu se aplice comunitÄƒÈ›ii mai largi. FolosiÈ›i instrumente È™i tehnici de inginerie a prompturilor pentru a "porni" construcÈ›ia prompturilor, apoi iteraÈ›i È™i validaÈ›i rezultatele folosindu-vÄƒ propria intuiÈ›ie È™i expertizÄƒ de domeniu. ÃnregistraÈ›i-vÄƒ perspectivele È™i creaÈ›i o **bazÄƒ de cunoÈ™tinÈ›e** (de exemplu, biblioteci de prompturi) care poate fi folositÄƒ ca un nou punct de plecare de cÄƒtre alÈ›ii, pentru iteraÈ›ii mai rapide Ã®n viitor.

## Cele mai bune practici

Acum sÄƒ vedem practicile comune recomandate de practicienii [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) È™i [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Ce                              | De ce                                                                                                                                                                                                                                               |
| :------------------------------ | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| EvaluaÈ›i cele mai recente modele.       | GeneraÈ›iile noi de modele sunt susceptibile sÄƒ aibÄƒ caracteristici È™i calitate Ã®mbunÄƒtÄƒÈ›ite - dar pot genera È™i costuri mai mari. EvaluaÈ›i-le pentru impact, apoi luaÈ›i decizii de migrare.                                                                                |
| SeparaÈ›i instrucÈ›iunile È™i contextul   | VerificaÈ›i dacÄƒ modelul/furnizorul dumneavoastrÄƒ defineÈ™te _delimitatori_ pentru a distinge instrucÈ›iunile, conÈ›inutul principal È™i cel secundar mai clar. Acest lucru poate ajuta modelele sÄƒ aloce greutÄƒÈ›i mai precis la tokenuri.                                                         |
| FiÈ›i specific È™i clar             | OferiÈ›i mai multe detalii despre contextul dorit, rezultatul, lungimea, formatul, stilul etc. Acest lucru va Ã®mbunÄƒtÄƒÈ›i atÃ¢t calitatea cÃ¢t È™i consistenÈ›a rÄƒspunsurilor. CapturaÈ›i reÈ›ete Ã®n È™abloane reutilizabile.                                                          |
| FiÈ›i descriptiv, folosiÈ›i exemple      | Modelele pot rÄƒspunde mai bine la o abordare de tip "aratÄƒ È™i spune". ÃncepeÈ›i cu un `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an â€œoutâ€           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` valori. ReveniÈ›i la [SecÈ›iunea Sandbox de ÃnvÄƒÈ›are](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) pentru a Ã®nvÄƒÈ›a cum.

### Ãn continuare, deschideÈ›i Jupyter Notebook

- SelectaÈ›i nucleul de execuÈ›ie. DacÄƒ folosiÈ›i opÈ›iunile 1 sau 2, selectaÈ›i pur È™i simplu nucleul implicit Python 3.10.x furnizat de containerul de dezvoltare.

SunteÈ›i gata sÄƒ rulaÈ›i exerciÈ›iile. ReÈ›ineÈ›i cÄƒ nu existÄƒ _rÄƒspunsuri corecte È™i greÈ™ite_ aici - doar explorÃ¢nd opÈ›iunile prin Ã®ncercare È™i eroare È™i construind intuiÈ›ia pentru ceea ce funcÈ›ioneazÄƒ pentru un model È™i un domeniu de aplicaÈ›ie dat.

_Din acest motiv, nu existÄƒ segmente de SoluÈ›ii de Cod Ã®n aceastÄƒ lecÈ›ie. Ãn schimb, Notebook-ul va avea celule Markdown intitulate "SoluÈ›ia mea:" care aratÄƒ un exemplu de ieÈ™ire pentru referinÈ›Äƒ._

## Verificarea cunoÈ™tinÈ›elor

Care dintre urmÄƒtoarele este un prompt bun, urmÃ¢nd cÃ¢teva practici de bazÄƒ rezonabile?

1. AratÄƒ-mi o imagine cu o maÈ™inÄƒ roÈ™ie
2. AratÄƒ-mi o imagine cu o maÈ™inÄƒ roÈ™ie de marcÄƒ Volvo È™i model XC90 parcatÄƒ lÃ¢ngÄƒ o stÃ¢ncÄƒ cu soarele la apus
3. AratÄƒ-mi o imagine cu o maÈ™inÄƒ roÈ™ie de marcÄƒ Volvo È™i model XC90

A: 2, este cel mai bun prompt deoarece oferÄƒ detalii despre "ce" È™i intrÄƒ Ã®n specificaÈ›ii (nu doar orice maÈ™inÄƒ, ci o marcÄƒ È™i un model specific) È™i, de asemenea, descrie setarea generalÄƒ. 3 este urmÄƒtorul cel mai bun, deoarece conÈ›ine È™i o mulÈ›ime de descrieri.

## ğŸš€ Provocare

Vezi dacÄƒ poÈ›i valorifica tehnica "indiciului" cu promptul: CompleteazÄƒ propoziÈ›ia "AratÄƒ-mi o imagine cu o maÈ™inÄƒ roÈ™ie de marcÄƒ Volvo È™i ". Cu ce rÄƒspunde È™i cum ai Ã®mbunÄƒtÄƒÈ›i-o?

## MuncÄƒ excelentÄƒ! ContinuÄƒ sÄƒ Ã®nveÈ›i

Vrei sÄƒ Ã®nveÈ›i mai multe despre diferite concepte de Inginerie a Prompturilor? AcceseazÄƒ [pagina de Ã®nvÄƒÈ›are continuÄƒ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a gÄƒsi alte resurse excelente pe acest subiect.

Mergi la LecÈ›ia 5 unde vom analiza [tehnici avansate de prompturi](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea umanÄƒ profesionalÄƒ. Nu suntem responsabili pentru neÃ®nÈ›elegerile sau interpretÄƒrile greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.