<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b2651fb16bcfbc62b8e518751ed90fdb",
  "translation_date": "2025-10-17T22:03:08+00:00",
  "source_file": "05-advanced-prompts/README.md",
  "language_code": "ro"
}
-->
# Crearea de prompturi avansate

[![Crearea de prompturi avansate](../../../translated_images/05-lesson-banner.522610fd4a2cd82dbed66bb7e6fe104ed6da172e085dbb4d9100b28dc73ed435.ro.png)](https://youtu.be/BAjzkaCdRok?si=NmUIyRf7-cDgbjtt)

S캒 recapitul캒m c칙teva lucruri 칥nv캒탵ate 칥n capitolul anterior:

> _Ingineria prompturilor_ este procesul prin care **ghid캒m modelul c캒tre r캒spunsuri mai relevante** oferind instruc탵iuni sau context mai utile.

Exist캒, de asemenea, dou캒 etape 칥n scrierea prompturilor: construirea promptului, prin furnizarea unui context relevant, 탳i _optimizarea_, adic캒 modul de 칥mbun캒t캒탵ire treptat캒 a promptului.

P칙n캒 acum, avem o 칥n탵elegere de baz캒 despre cum s캒 scriem prompturi, dar trebuie s캒 aprofund캒m. 칉n acest capitol, vei trece de la testarea diferitelor prompturi la 칥n탵elegerea motivului pentru care un prompt este mai bun dec칙t altul. Vei 칥nv캒탵a cum s캒 construie탳ti prompturi urm칙nd c칙teva tehnici de baz캒 care pot fi aplicate oric캒rui LLM.

## Introducere

칉n acest capitol, vom acoperi urm캒toarele subiecte:

- Extinderea cuno탳tin탵elor despre ingineria prompturilor prin aplicarea diferitelor tehnici la prompturile tale.
- Configurarea prompturilor pentru a varia rezultatul.

## Obiective de 칥nv캒탵are

Dup캒 finalizarea acestei lec탵ii, vei putea:

- Aplica tehnici de inginerie a prompturilor care 칥mbun캒t캒탵esc rezultatul prompturilor tale.
- Realiza prompturi care sunt fie variate, fie deterministe.

## Ingineria prompturilor

Ingineria prompturilor este procesul de creare a prompturilor care vor produce rezultatul dorit. Ingineria prompturilor 칥nseamn캒 mai mult dec칙t scrierea unui text prompt. Nu este o disciplin캒 inginereasc캒, ci mai degrab캒 un set de tehnici pe care le po탵i aplica pentru a ob탵ine rezultatul dorit.

### Un exemplu de prompt

S캒 lu캒m un prompt de baz캒, cum ar fi acesta:

> Genereaz캒 10 칥ntreb캒ri despre geografie.

칉n acest prompt, aplici de fapt un set de tehnici diferite de promptare.

S캒 analiz캒m acest lucru.

- **Context**, specifici c캒 ar trebui s캒 fie despre "geografie".
- **Limitarea rezultatului**, dore탳ti s캒 nu fie mai mult de 10 칥ntreb캒ri.

### Limit캒rile prompturilor simple

Este posibil s캒 ob탵ii sau nu rezultatul dorit. 칉탵i vor fi generate 칥ntreb캒rile, dar geografia este un subiect vast 탳i este posibil s캒 nu ob탵ii ceea ce dore탳ti din urm캒toarele motive:

- **Subiect vast**, nu 탳tii dac캒 va fi despre 탵캒ri, capitale, r칙uri 탳i a탳a mai departe.
- **Format**, ce se 칥nt칙mpl캒 dac캒 doreai ca 칥ntreb캒rile s캒 fie formate 칥ntr-un anumit mod?

Dup캒 cum po탵i vedea, exist캒 multe de luat 칥n considerare atunci c칙nd creezi prompturi.

P칙n캒 acum, am v캒zut un exemplu de prompt simplu, dar AI generativ캒 este capabil캒 de mult mai mult pentru a ajuta oamenii 칥n diverse roluri 탳i industrii. S캒 explor캒m c칙teva tehnici de baz캒 칥n continuare.

### Tehnici de promptare

Mai 칥nt칙i, trebuie s캒 칥n탵elegem c캒 promptarea este o proprietate _emergent캒_ a unui LLM, ceea ce 칥nseamn캒 c캒 nu este o func탵ie 칥ncorporat캒 칥n model, ci mai degrab캒 ceva ce descoperim pe m캒sur캒 ce utiliz캒m modelul.

Exist캒 c칙teva tehnici de baz캒 pe care le putem folosi pentru a prompta un LLM. S캒 le explor캒m.

- **Promptare zero-shot**, aceasta este cea mai simpl캒 form캒 de promptare. Este un singur prompt care solicit캒 un r캒spuns de la LLM bazat exclusiv pe datele sale de antrenament.
- **Promptare few-shot**, acest tip de promptare ghideaz캒 LLM oferindu-i 1 sau mai multe exemple pe care se poate baza pentru a genera r캒spunsul.
- **Chain-of-thought**, acest tip de promptare 칥i spune LLM cum s캒 descompun캒 o problem캒 칥n pa탳i.
- **Cuno탳tin탵e generate**, pentru a 칥mbun캒t캒탵i r캒spunsul unui prompt, po탵i oferi fapte sau cuno탳tin탵e generate suplimentar promptului t캒u.
- **De la cel mai simplu la cel mai complex**, similar cu chain-of-thought, aceast캒 tehnic캒 presupune descompunerea unei probleme 칥ntr-o serie de pa탳i 탳i apoi solicitarea ca ace탳ti pa탳i s캒 fie efectua탵i 칥n ordine.
- **Auto-refinarea**, aceast캒 tehnic캒 presupune criticarea r캒spunsului LLM 탳i apoi solicitarea 칥mbun캒t캒탵irii acestuia.
- **Promptare maieutic캒**, aici dore탳ti s캒 te asiguri c캒 r캒spunsul LLM este corect 탳i 칥i ceri s캒 explice diverse p캒r탵i ale r캒spunsului. Aceasta este o form캒 de auto-refinare.

### Promptare zero-shot

Acest stil de promptare este foarte simplu, const캒 칥ntr-un singur prompt. Aceast캒 tehnic캒 este probabil ceea ce folose탳ti pe m캒sur캒 ce 칥ncepi s캒 칥nve탵i despre LLM-uri. Iat캒 un exemplu:

- Prompt: "Ce este Algebra?"
- R캒spuns: "Algebra este o ramur캒 a matematicii care studiaz캒 simbolurile matematice 탳i regulile pentru manipularea acestor simboluri."

### Promptare few-shot

Acest stil de promptare ajut캒 modelul oferindu-i c칙teva exemple 칥mpreun캒 cu cererea. Const캒 칥ntr-un singur prompt cu date suplimentare specifice sarcinii. Iat캒 un exemplu:

- Prompt: "Scrie un poem 칥n stilul lui Shakespeare. Iat캒 c칙teva exemple de sonete shakespeariene:
  Sonetul 18: 'S캒 te compar cu o zi de var캒? E탳ti mai frumos 탳i mai temperat...'
  Sonetul 116: 'S캒 nu admit impedimente 칥n c캒s캒toria min탵ilor adev캒rate. Dragostea nu este dragoste care se schimb캒 c칙nd g캒se탳te schimbare...'
  Sonetul 132: 'Ochii t캒i 칥i iubesc, 탳i ei, ca 탳i cum m캒 comp캒timesc, 탲tiind c캒 inima ta m캒 chinuie cu dispre탵,...'
  Acum, scrie un sonet despre frumuse탵ea lunii."
- R캒spuns: "Pe cer, luna str캒luce탳te bl칙nd, 칉n lumin캒 argintie ce 칥탳i arunc캒 gra탵ia,..."

Exemplele ofer캒 LLM contextul, formatul sau stilul rezultatului dorit. Ele ajut캒 modelul s캒 칥n탵eleag캒 sarcina specific캒 탳i s캒 genereze r캒spunsuri mai precise 탳i relevante.

### Chain-of-thought

Chain-of-thought este o tehnic캒 foarte interesant캒, deoarece presupune parcurgerea LLM printr-o serie de pa탳i. Ideea este s캒 instruie탳ti LLM astfel 칥nc칙t s캒 칥n탵eleag캒 cum s캒 fac캒 ceva. Ia 칥n considerare urm캒torul exemplu, cu 탳i f캒r캒 chain-of-thought:

    - Prompt: "Alice are 5 mere, arunc캒 3 mere, d캒 2 lui Bob 탳i Bob 칥i d캒 unul 칥napoi, c칙te mere are Alice?"
    - R캒spuns: 5

LLM r캒spunde cu 5, ceea ce este incorect. R캒spunsul corect este 1 m캒r, av칙nd 칥n vedere calculul (5 -3 -2 + 1 = 1).

Cum putem 칥nv캒탵a LLM s캒 fac캒 acest lucru corect?

S캒 칥ncerc캒m chain-of-thought. Aplicarea chain-of-thought 칥nseamn캒:

1. Ofer캒 LLM un exemplu similar.
1. Arat캒 calculul 탳i cum s캒-l calculeze corect.
1. Furnizeaz캒 promptul original.

Iat캒 cum:

- Prompt: "Lisa are 7 mere, arunc캒 1 m캒r, d캒 4 mere lui Bart 탳i Bart 칥i d캒 unul 칥napoi:
  7 -1 = 6
  6 -4 = 2
  2 +1 = 3  
  Alice are 5 mere, arunc캒 3 mere, d캒 2 lui Bob 탳i Bob 칥i d캒 unul 칥napoi, c칙te mere are Alice?"
  R캒spuns: 1

Observ캒 cum scriem prompturi substan탵ial mai lungi cu un alt exemplu, un calcul 탳i apoi promptul original 탳i ajungem la r캒spunsul corect 1.

Dup캒 cum po탵i vedea, chain-of-thought este o tehnic캒 foarte puternic캒.

### Cuno탳tin탵e generate

De multe ori, c칙nd dore탳ti s캒 construie탳ti un prompt, vrei s캒 o faci folosind datele propriei companii. Vrei ca o parte a promptului s캒 fie din companie, iar cealalt캒 parte s캒 fie promptul care te intereseaz캒.

Ca exemplu, iat캒 cum poate ar캒ta promptul t캒u dac캒 e탳ti 칥n domeniul asigur캒rilor:

```text
{{company}}: {{company_name}}
{{products}}:
{{products_list}}
Please suggest an insurance given the following budget and requirements:
Budget: {{budget}}
Requirements: {{requirements}}
```

Mai sus, vezi cum promptul este construit folosind un 탳ablon. 칉n 탳ablon exist캒 un num캒r de variabile, notate cu `{{variable}}`, care vor fi 칥nlocuite cu valori reale dintr-un API al companiei.

Iat캒 un exemplu de cum ar putea ar캒ta promptul odat캒 ce variabilele au fost 칥nlocuite cu con탵inut din compania ta:

```text
Insurance company: ACME Insurance
Insurance products (cost per month):
- Car, cheap, 500 USD
- Car, expensive, 1100 USD
- Home, cheap, 600 USD
- Home, expensive, 1200 USD
- Life, cheap, 100 USD

Please suggest an insurance given the following budget and requirements:
Budget: $1000
Requirements: Car, Home, and Life insurance
```

Rularea acestui prompt printr-un LLM va produce un r캒spuns ca acesta:

```output
Given the budget and requirements, we suggest the following insurance package from ACME Insurance:
- Car, cheap, 500 USD
- Home, cheap, 600 USD
- Life, cheap, 100 USD
Total cost: $1,200 USD
```

Dup캒 cum po탵i vedea, sugereaz캒 탳i asigurarea de via탵캒, ceea ce nu ar trebui. Acest rezultat indic캒 faptul c캒 trebuie s캒 optimiz캒m promptul schimb칙ndu-l pentru a fi mai clar 칥n ceea ce permite. Dup캒 c칙teva _칥ncerc캒ri 탳i erori_, ajungem la urm캒torul prompt:

```text
Insurance company: ACME Insurance
Insurance products (cost per month):
- type: Car, cheap, cost: 500 USD
- type: Car, expensive, cost: 1100 USD
- type: Home, cheap, cost: 600 USD
- type: Home, expensive, cost: 1200 USD
- type: Life, cheap, cost: 100 USD

Please suggest an insurance given the following budget and requirements:
Budget: $1000 restrict choice to types: Car, Home
```

Observ캒 cum ad캒ugarea _tipului_ 탳i _costului_ 탳i utilizarea cuv칙ntului cheie _restrict_ ajut캒 LLM s캒 칥n탵eleag캒 ce dorim.

Acum ob탵inem urm캒torul r캒spuns:

```output
Given the budget and requirements, we suggest the Car, Cheap insurance product which costs 500 USD per month.
```

Scopul acestui exemplu a fost s캒 arate c캒, de탳i folosim o tehnic캒 de baz캒 precum _cuno탳tin탵e generate_, tot trebuie s캒 optimiz캒m promptul 칥n majoritatea cazurilor pentru a ob탵ine rezultatul dorit.

### De la cel mai simplu la cel mai complex

Ideea cu promptarea de la cel mai simplu la cel mai complex este s캒 descompui o problem캒 mai mare 칥n subprobleme. 칉n acest fel, aju탵i LLM s캒 "cucereasc캒" problema mai mare. Un exemplu bun ar putea fi pentru 탳tiin탵a datelor, unde po탵i cere LLM s캒 칥mpart캒 o problem캒 astfel:

> Prompt: Cum s캒 faci 탳tiin탵캒 a datelor 칥n 5 pa탳i?

Cu asistentul AI r캒spunz칙nd astfel:

1. Colectarea datelor
1. Cur캒탵area datelor
1. Analiza datelor
1. Vizualizarea datelor
1. Prezentarea datelor

### Auto-refinarea, criticarea rezultatelor

Cu AI generativ캒 탳i LLM-uri, nu po탵i avea 칥ncredere 칥n rezultat. Trebuie s캒-l verifici. La urma urmei, LLM doar 칥탵i prezint캒 ceea ce este cel mai probabil s캒 spun캒 칥n continuare, nu ceea ce este corect. Prin urmare, o idee bun캒 este s캒 ceri LLM s캒 se critice singur, ceea ce ne duce la tehnica de auto-refinare.

Cum func탵ioneaz캒 este c캒 urmezi urm캒torii pa탳i:

1. Prompt ini탵ial care cere LLM s캒 rezolve o problem캒
1. LLM r캒spunde
1. Critici r캒spunsul 탳i ceri AI s캒-l 칥mbun캒t캒탵easc캒
1. LLM r캒spunde din nou, de data aceasta lu칙nd 칥n considerare critica 탳i suger칙nd solu탵ii pe care le-a g캒sit

Po탵i repeta acest proces de c칙te ori dore탳ti.

Iat캒 un exemplu folosind aceast캒 tehnic캒:

> Prompt: "Creeaz캒 un API Web Python cu rute pentru produse 탳i clien탵i"

R캒spuns AI:

```python
import flask
app = Flask(__name__)

@app.route('/products')
def products():
    return 'Products'

@app.route('/customers')
def customers():
    return 'Customers'
```

> Prompt: sugereaz캒 3 칥mbun캒t캒탵iri ale codului de mai sus

R캒spuns AI:

```text
Sure, here are three suggestions to improve the code:

Import the correct module: The first line should import Flask instead of flask. The correct import statement should be from flask import Flask.

Add a main function: Add a if __name__ == '__main__': block to the end of the file to run the application when the file is executed.

Use f-strings: Use f-strings to format the return statements in the route functions. For example, return 'Products' can be changed to return f'This is the {request.path} page'.
```

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/products')
def products():
    return f'This is the {request.path} page'

@app.route('/customers')
def customers():
    return f'This is the {request.path} page'

if __name__ == '__main__':
    app.run()
```

Dup캒 cum po탵i vedea, r캒spunsul AI de mai sus 칥mbun캒t캒탵e탳te primul cod sugerat datorit캒 critic캒rii primului r캒spuns.

### Promptare maieutic캒

Promptarea maieutic캒 este o tehnic캒 similar캒 cu auto-refinarea, dar este mai mult despre a cere LLM s캒 se explice. Scopul este de a reduce inconsecven탵ele 칥n rezultatul LLM pentru a te asigura c캒 ajunge la r캒spunsul corect. Fluxul de lucru de urmat este:

1. Cere LLM s캒 r캒spund캒 la o 칥ntrebare
1. Pentru fiecare parte a r캒spunsului, cere LLM s캒 o explice mai 칥n detaliu.
1. Dac캒 exist캒 inconsecven탵e, elimin캒 p캒r탵ile care sunt inconsistente.

Repet캒 pa탳ii 2 탳i 3 p칙n캒 c칙nd ai trecut prin toate p캒r탵ile 탳i e탳ti mul탵umit de r캒spuns.

Iat캒 un exemplu de prompt:

> prompt: Cum pot crea un plan de criz캒 pentru a atenua o pandemie 칥n 5 pa탳i?
> R캒spuns LLM:

```text
1. Identify the risks
1. Identify the stakeholders
1. Identify the resources
1. Identify the actions
1. Identify the communication channels
```

A identificat 5 pa탳i, dar putem determina dac캒 acest lucru este corect? S캒 cerem LLM s캒 explice fiecare pas:

> prompt: Explic캒 primul pas mai 칥n detaliu, care sunt riscurile 칥n detaliu ale unei pandemii?

```text
The risks are the following:

- Loss of life
- Loss of business
- Loss of reputation
- Loss of customers
- Loss of employees
```

칉n acest moment, dorim s캒 ne asigur캒m c캒 LLM este corect, a탳a c캒 칥i cerem s캒 explice primul risc mai 칥n detaliu 탳i sper캒m c캒 este consistent cu r캒spunsul de mai sus:

> prompt: 칉ntr-o pandemie, care este cel mai mare risc 탳i de ce?

```text
The biggest risk is loss of life because it's the most important thing to protect.
```

> Care sunt cele dou캒 cele mai mari riscuri 칥ntr-o pandemie?

```text
The two biggest risks are loss of life and loss of business.
```

칉n acest moment, LLM este consistent 탳i men탵ioneaz캒 "via탵a" 탳i "afacerea" ca fiind cele dou캒 riscuri principale. Putem continua la pasul urm캒tor 탳i s캒 ne sim탵im destul de 칥ncrez캒tori. Totu탳i, nu ar trebui s캒 avem 칥ncredere oarb캒 칥n LLM, ar trebui s캒 verific캒m 칥ntotdeauna rezultatul.

## Variaz캒 rezultatul

LLM-urile sunt prin natura lor nedeterministe, ceea ce 칥nseamn캒 c캒 vei ob탵ine rezultate diferite de fiecare dat캒 c칙nd rulezi acela탳i prompt. 칉ncearc캒 urm캒torul prompt, de exemplu:

> "Genereaz캒 cod pentru un API Web Python"

```python
# Import necessary modules
import flask
from flask import request, jsonify

# Create a Flask app
app = flask.Flask(__name__)

# Create a route for the API
@app.route('/api', methods=['GET'])
def api():
    # Get the data from the request
    data = request.args

    # Process the data
    result = process_data(data)

    # Return the result as JSON
    return jsonify(result)

# Function to process the data
def process_data(data):
    # Do something with the data
    result = data + 1

    # Return the result
    return result

# Run the app
if __name__ == '__main__':
    app.run()

```

Rularea aceluia탳i prompt din nou genereaz캒 un r캒spuns u탳or diferit:

```python
#import necessary packages
import flask
from flask import request, jsonify

#create the Flask application
app = flask.Flask(__name__)
app.config["DEBUG"] = True

#create a list of books
books = [
    {'id': 0,
     'title': 'A Fire Upon the Deep',
     'author': 'Vernor Vinge',
     'first_sentence': 'The coldsleep itself was dreamless.',
     'year_published': '1992'},
    {'id': 1,
     'title': 'The Ones Who Walk Away From Omelas',
     'author': 'Ursula K. Le Guin',
     'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.',
     'published': '1973'},
    {'id': 2,
     'title': 'Dhalgren',
     'author': 'Samuel R. Delany',
     'first_sentence': 'to wound the autumnal city.',
     'published': '1975'}
]

#create an endpoint for the API
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Books API</h1>
<p>A prototype API for retrieving books.</p>'''

#create an endpoint to return all books
@app.route('/api/v1/resources/books/all', methods=['GET'])
def api_all():
    return jsonify(books)

#create an endpoint to return a single book
@app.route('/api/v1/resources/books', methods=['GET'])
def api_id():
    #check if an ID was provided as part of the URL
    #if ID is provided, assign it to a variable
    #if no ID is provided, display an error
    if 'id' in request.args:
        id = int(request.args['id'])
    else:
        return "Error: No id field provided. Please specify an id."

    #create an empty list for our results
    results = []

    #loop through the data and match results that fit the requested ID
    #IDs are unique, but other fields might return many results
    for book in books:
        if book['id'] == id:
            results.append(book)

    #use the jsonify function from Flask to convert our list of
    #Python dictionaries to the JSON format
    return jsonify(results)

app.run()
```

> Deci, este rezultatul variat o problem캒?

Depinde de ceea ce 칥ncerci s캒 faci. Dac캒 dore탳ti un r캒spuns specific, atunci este o problem캒. Dac캒 e탳ti ok cu un rezultat variat, cum ar fi "Genereaz캒 orice 3 칥ntreb캒ri despre geografie", atunci nu este o problem캒.

### Utilizarea temperaturii pentru a varia rezultatul

Ok, deci am decis c캒 vrem s캒 limit캒m rezultatul pentru a fi mai previzibil, adic캒 mai determinist. Cum facem asta?

Temperatura este o valoare 칥ntre 0 탳i 1, unde 0 este cel mai determinist 탳i 1 este cel mai variat. Valoarea implicit캒 este 0.7. S캒 vedem ce se 칥nt칙mpl캒 cu dou캒 rul캒ri ale aceluia탳i prompt cu temperatura setat캒 la 0.1:

> "Genereaz캒 cod pentru un API Web Python"

```python
#import necessary libraries
import flask
from flask import request, jsonify

#create an instance of the Flask class
app = flask.Flask(__name__)

#create an endpoint for the API
@app.route('/api/v1/endpoint', methods=['GET'])
def api_endpoint():
    #get the request data
    data = request.get_json()

    #process the data
    result = process_data(data)

    #return the result
    return jsonify(result)

#function to process the data
def process_data(data):
    #process the data
    result = {'result': 'success'}

    #return the result
    return result

#run the Flask app
if __name__ == '__main__':
    app.run()

```

Rularea promptului din nou ne ofer캒 acest rezultat:

```python
#import necessary libraries
import flask
from flask import request, jsonify

#create a Flask app
app = flask.Flask(__name__)

#create a route for the API
@app.route('/api', methods=['GET'])
def api_call():
    #get the data from the request
    data = request.get_json()

    #process the data
    result = process_data(data)

    #return the result
    return jsonify(result)

#define the process_data function
def process_data(data):
    #do something with the data
    result = data + 1

    #return the result
    return result

#run the app
if __name__ == '__main__':
    app.run()

```

Exist캒 doar o mic캒 diferen탵캒 칥ntre aceste dou캒 rezultate. S캒 facem opusul de data aceasta, s캒 set캒m temperatura la 0.9:

```python
# Import necessary libraries
import flask
from flask import request, jsonify

# Create a Flask app
app = flask.Flask(__name__)

# Create a route for the API
@app.route('/api', methods=['GET'])
def api_call():
    # Get the data from the request
    data = request.args

    # Process the data
    result = process_data(data)

    # Return the result
    return jsonify(result)

# Function to process the data
def process_data(data):
    # Do something with the data
    result = data + 1

    # Return the result
    return result

# Run the app
if __name__ == '__main__':
    app.run()

```

탳i a doua 칥ncercare cu valoarea temperaturii setat캒 la 0.9:

```python
import flask
from flask import request, jsonify

# create the Flask app
app = flask.Flask(__name__)
app.config['DEBUG'] = True

# create some test data
books = [
    {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},
    {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},
    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}
]

# create an endpoint
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Welcome to our book API!</h1>'''

@app.route('/api/v1/resources/books

```

Dup캒 cum pute탵i vedea, rezultatele nu ar putea fi mai variate.

> Re탵ine탵i c캒 exist캒 mai mul탵i parametri pe care 칥i pute탵i modifica pentru a varia rezultatul, cum ar fi top-k, top-p, penalizarea repet캒rii, penalizarea lungimii 탳i penalizarea diversit캒탵ii, dar ace탳tia sunt 칥n afara domeniului acestui curriculum.

## Practici bune

Exist캒 multe practici pe care le pute탵i aplica pentru a ob탵ine ceea ce dori탵i. Ve탵i descoperi propriul stil pe m캒sur캒 ce utiliza탵i mai mult 탳i mai mult tehnica de prompting.

Pe l칙ng캒 tehnicile pe care le-am acoperit, exist캒 c칙teva practici bune de luat 칥n considerare atunci c칙nd formula탵i cereri pentru un LLM.

Iat캒 c칙teva practici bune de luat 칥n considerare:

- **Specifica탵i contextul**. Contextul conteaz캒, cu c칙t pute탵i specifica mai mult, cum ar fi domeniul, subiectul etc., cu at칙t mai bine.
- Limita탵i rezultatul. Dac캒 dori탵i un num캒r specific de elemente sau o lungime specific캒, specifica탵i acest lucru.
- **Specifica탵i at칙t ce, c칙t 탳i cum**. Aminti탵i-v캒 s캒 men탵iona탵i at칙t ce dori탵i, c칙t 탳i cum dori탵i, de exemplu: "Crea탵i o API Web Python cu rute pentru produse 탳i clien탵i, 칥mp캒r탵i탵i-o 칥n 3 fi탳iere".
- **Utiliza탵i 탳abloane**. Adesea, ve탵i dori s캒 칥mbog캒탵i탵i cererile cu date din compania dvs. Utiliza탵i 탳abloane pentru a face acest lucru. 탲abloanele pot avea variabile pe care le 칥nlocui탵i cu date reale.
- **Scrie탵i corect**. LLM-urile ar putea s캒 v캒 ofere un r캒spuns corect, dar dac캒 scrie탵i corect, ve탵i ob탵ine un r캒spuns mai bun.

## Tem캒

Iat캒 un cod 칥n Python care arat캒 cum s캒 construi탵i o API simpl캒 folosind Flask:

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/')
def hello():
    name = request.args.get('name', 'World')
    return f'Hello, {name}!'

if __name__ == '__main__':
    app.run()
```

Utiliza탵i un asistent AI precum GitHub Copilot sau ChatGPT 탳i aplica탵i tehnica "self-refine" pentru a 칥mbun캒t캒탵i codul.

## Solu탵ie

V캒 rug캒m s캒 칥ncerca탵i s캒 rezolva탵i tema ad캒ug칙nd cereri potrivite la cod.

> [!TIP]
> Formula탵i o cerere pentru a solicita 칥mbun캒t캒탵iri, este o idee bun캒 s캒 limita탵i num캒rul de 칥mbun캒t캒탵iri. De asemenea, pute탵i solicita 칥mbun캒t캒탵iri 칥ntr-un anumit mod, de exemplu arhitectur캒, performan탵캒, securitate etc.

[Solu탵ie](../../../05-advanced-prompts/python/aoai-solution.py)

## Verificare cuno탳tin탵e

De ce a탳 folosi prompting-ul de tip chain-of-thought? Ar캒ta탵i-mi 1 r캒spuns corect 탳i 2 r캒spunsuri incorecte.

1. Pentru a 칥nv캒탵a LLM-ul cum s캒 rezolve o problem캒.
1. B, Pentru a 칥nv캒탵a LLM-ul s캒 g캒seasc캒 erori 칥n cod.
1. C, Pentru a instrui LLM-ul s캒 vin캒 cu solu탵ii diferite.

A: 1, deoarece chain-of-thought se refer캒 la a ar캒ta LLM-ului cum s캒 rezolve o problem캒 oferindu-i o serie de pa탳i, 탳i probleme similare 탳i cum au fost rezolvate.

## 游 Provocare

Tocmai a탵i utilizat tehnica self-refine 칥n tem캒. Lua탵i orice program pe care l-a탵i construit 탳i g칙ndi탵i-v캒 la ce 칥mbun캒t캒탵iri a탵i dori s캒 aplica탵i. Acum utiliza탵i tehnica self-refine pentru a aplica modific캒rile propuse. Ce p캒rere ave탵i despre rezultat, mai bun sau mai r캒u?

## Felicit캒ri! Continua탵i s캒 칥nv캒탵a탵i

Dup캒 ce a탵i finalizat aceast캒 lec탵ie, consulta탵i [colec탵ia noastr캒 de 칥nv캒탵are despre AI generativ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a continua s캒 v캒 dezvolta탵i cuno탳tin탵ele despre AI generativ!

Merge탵i la Lec탵ia 6 unde vom aplica cuno탳tin탵ele noastre despre Prompt Engineering [construind aplica탵ii de generare de text](../06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst)

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). De탳i ne str캒duim s캒 asigur캒m acurate탵ea, v캒 rug캒m s캒 fi탵i con탳tien탵i c캒 traducerile automate pot con탵ine erori sau inexactit캒탵i. Documentul original 칥n limba sa matern캒 ar trebui considerat sursa autoritar캒. Pentru informa탵ii critice, se recomand캒 traducerea profesional캒 realizat캒 de un specialist uman. Nu ne asum캒m responsabilitatea pentru eventualele ne칥n탵elegeri sau interpret캒ri gre탳ite care pot ap캒rea din utilizarea acestei traduceri.