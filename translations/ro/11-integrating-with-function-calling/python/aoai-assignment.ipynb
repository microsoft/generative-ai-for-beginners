{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducere\n",
    "\n",
    "Această lecție va acoperi:\n",
    "- Ce este apelarea de funcții și în ce situații se folosește\n",
    "- Cum să creezi un apel de funcție folosind Azure OpenAI\n",
    "- Cum să integrezi un apel de funcție într-o aplicație\n",
    "\n",
    "## Obiective de învățare\n",
    "\n",
    "După ce vei parcurge această lecție, vei ști și vei înțelege:\n",
    "\n",
    "- Scopul utilizării apelării de funcții\n",
    "- Cum să configurezi apelarea de funcții folosind serviciul Azure Open AI\n",
    "- Cum să proiectezi apeluri de funcții eficiente pentru cazul tău de utilizare\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Înțelegerea apelurilor de funcții\n",
    "\n",
    "Pentru această lecție, vrem să dezvoltăm o funcționalitate pentru startup-ul nostru educațional care să permită utilizatorilor să folosească un chatbot pentru a găsi cursuri tehnice. Vom recomanda cursuri care se potrivesc nivelului lor de abilități, rolului actual și tehnologiei de interes.\n",
    "\n",
    "Pentru a realiza acest lucru, vom folosi o combinație de:\n",
    " - `Azure Open AI` pentru a crea o experiență de chat pentru utilizator\n",
    " - `Microsoft Learn Catalog API` pentru a ajuta utilizatorii să găsească cursuri pe baza cererii lor\n",
    " - `Function Calling` pentru a prelua întrebarea utilizatorului și a o trimite către o funcție care va face cererea către API.\n",
    "\n",
    "Pentru început, să vedem de ce am vrea să folosim apelarea funcțiilor:\n",
    "\n",
    "print(\"Mesaje în următoarea cerere:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # obține un nou răspuns de la GPT unde poate vedea răspunsul funcției\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De ce să folosești Function Calling\n",
    "\n",
    "Dacă ai parcurs deja alte lecții din acest curs, probabil că ai înțeles cât de puternice sunt modelele de limbaj de tip Large Language Models (LLMs). Sperăm că ai observat și unele dintre limitele lor.\n",
    "\n",
    "Function Calling este o funcționalitate din Azure Open AI Service care ajută la depășirea următoarelor limitări:\n",
    "1) Formatul constant al răspunsurilor\n",
    "2) Posibilitatea de a folosi date din alte surse ale unei aplicații într-un context de chat\n",
    "\n",
    "Înainte de function calling, răspunsurile generate de un LLM erau neorganizate și nu aveau un format consecvent. Dezvoltatorii trebuiau să scrie cod complex de validare pentru a se asigura că pot gestiona fiecare variantă de răspuns.\n",
    "\n",
    "Utilizatorii nu puteau primi răspunsuri de tipul „Care este vremea actuală în Stockholm?”. Asta pentru că modelele erau limitate la perioada în care au fost antrenate cu date.\n",
    "\n",
    "Hai să analizăm exemplul de mai jos care ilustrează această problemă:\n",
    "\n",
    "Să presupunem că vrem să creăm o bază de date cu informații despre studenți, ca să le putem recomanda cursul potrivit. Mai jos avem două descrieri de studenți care sunt foarte asemănătoare ca date conținute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrem să trimitem acest lucru către un LLM pentru a analiza datele. Acest lucru poate fi folosit ulterior în aplicația noastră pentru a trimite datele către o API sau pentru a le stoca într-o bază de date.\n",
    "\n",
    "Hai să creăm două prompturi identice prin care instruim LLM-ul ce informații ne interesează:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrem să trimitem acest lucru către un LLM pentru a analiza părțile care sunt importante pentru produsul nostru. Astfel, putem crea două prompturi identice pentru a instrui LLM-ul:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce creăm aceste două prompturi, le vom trimite către LLM folosind `openai.ChatCompletion`. Stocăm promptul în variabila `messages` și atribuim rolul `user`. Acest lucru este pentru a imita un mesaj de la un utilizator scris către un chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiar dacă instrucțiunile sunt aceleași și descrierile sunt similare, putem obține formate diferite pentru proprietatea `Grades`.\n",
    "\n",
    "Dacă rulezi celula de mai sus de mai multe ori, formatul poate fi `3.7` sau `3.7 GPA`.\n",
    "\n",
    "Acest lucru se întâmplă deoarece LLM-ul primește date nestructurate sub forma instrucțiunii scrise și returnează tot date nestructurate. Avem nevoie de un format structurat ca să știm la ce să ne așteptăm atunci când stocăm sau folosim aceste date.\n",
    "\n",
    "Folosind apelarea funcțională, ne putem asigura că primim date structurate înapoi. Când folosim apelarea funcțională, LLM-ul nu apelează sau rulează efectiv nicio funcție. În schimb, creăm o structură pe care LLM-ul să o urmeze pentru răspunsurile sale. Apoi folosim aceste răspunsuri structurate ca să știm ce funcție să rulăm în aplicațiile noastre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama fluxului de apelare a funcțiilor](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ro.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de utilizare pentru apelarea funcțiilor\n",
    "\n",
    "**Apelarea unor instrumente externe**  \n",
    "Chatboții sunt foarte buni la a oferi răspunsuri la întrebările utilizatorilor. Prin folosirea apelării de funcții, chatboții pot folosi mesajele utilizatorilor pentru a îndeplini anumite sarcini. De exemplu, un student poate cere chatbotului: „Trimite un email profesorului meu în care să-i spun că am nevoie de mai mult ajutor la această materie”. Acest lucru poate declanșa un apel către funcția `send_email(to: string, body: string)`\n",
    "\n",
    "**Crearea de interogări API sau către baze de date**  \n",
    "Utilizatorii pot găsi informații folosind limbaj natural, care este apoi transformat într-o interogare formatată sau o cerere API. Un exemplu ar fi un profesor care întreabă „Cine sunt studenții care au finalizat ultima temă”, ceea ce ar putea apela o funcție numită `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Crearea de date structurate**  \n",
    "Utilizatorii pot lua un bloc de text sau un fișier CSV și pot folosi LLM-ul pentru a extrage informațiile importante din acesta. De exemplu, un student poate transforma un articol de pe Wikipedia despre acorduri de pace pentru a crea fișe de învățare AI. Acest lucru se poate face folosind o funcție numită `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crearea primei tale apelări de funcție\n",
    "\n",
    "Procesul de creare a unei apelări de funcție include 3 pași principali:\n",
    "1. Apelezi API-ul Chat Completions cu o listă de funcții și un mesaj de la utilizator\n",
    "2. Citești răspunsul modelului pentru a efectua o acțiune, adică să execuți o funcție sau un apel API\n",
    "3. Faci o altă apelare către API-ul Chat Completions cu răspunsul de la funcția ta pentru a folosi acea informație la crearea unui răspuns pentru utilizator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fluxul unui apel de funcție](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ro.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemente ale unui apel de funcție\n",
    "\n",
    "#### Introducerea utilizatorului\n",
    "\n",
    "Primul pas este să creezi un mesaj de la utilizator. Acesta poate fi atribuit dinamic, preluând valoarea dintr-un câmp de text, sau poți seta o valoare aici. Dacă este prima dată când lucrezi cu API-ul Chat Completions, trebuie să definim `role` și `content` pentru mesaj.\n",
    "\n",
    "`role` poate fi fie `system` (pentru a stabili reguli), `assistant` (modelul) sau `user` (utilizatorul final). Pentru apelarea funcțiilor, vom seta acest rol ca `user` și vom folosi o întrebare exemplu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crearea funcțiilor.\n",
    "\n",
    "În continuare vom defini o funcție și parametrii acesteia. Vom folosi aici doar o funcție numită `search_courses`, dar poți crea mai multe funcții.\n",
    "\n",
    "**Important** : Funcțiile sunt incluse în mesajul de sistem către LLM și vor fi luate în calcul la numărul de tokenuri disponibile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiții**\n",
    "\n",
    "`name` - Numele funcției pe care dorim să o apelăm.\n",
    "\n",
    "`description` - Aceasta este descrierea modului în care funcționează funcția. Aici este important să fii specific și clar.\n",
    "\n",
    "`parameters` - O listă de valori și formatul pe care vrei ca modelul să le genereze în răspunsul său.\n",
    "\n",
    "\n",
    "`type` - Tipul de date în care vor fi stocate proprietățile.\n",
    "\n",
    "`properties` - Lista valorilor specifice pe care modelul le va folosi pentru răspunsul său.\n",
    "\n",
    "\n",
    "`name` - numele proprietății pe care modelul îl va folosi în răspunsul său formatat\n",
    "\n",
    "`type` - Tipul de date al acestei proprietăți\n",
    "\n",
    "`description` - Descrierea proprietății specifice\n",
    "\n",
    "\n",
    "**Opțional**\n",
    "\n",
    "`required` - proprietate necesară pentru ca apelul funcției să fie finalizat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efectuarea apelului funcției\n",
    "După ce am definit o funcție, trebuie acum să o includem în apelul către Chat Completion API. Facem acest lucru adăugând `functions` la cerere. În acest caz, `functions=functions`.\n",
    "\n",
    "Există și opțiunea de a seta `function_call` la `auto`. Asta înseamnă că vom lăsa LLM-ul să decidă ce funcție ar trebui apelată, pe baza mesajului utilizatorului, în loc să o atribuim noi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum să analizăm răspunsul și să vedem cum este formatat:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Poți observa că numele funcției este apelat și, din mesajul utilizatorului, LLM-ul a reușit să găsească datele potrivite pentru argumentele funcției.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrarea apelurilor de funcții într-o aplicație.\n",
    "\n",
    "După ce am testat răspunsul formatat de la LLM, acum putem integra acest lucru într-o aplicație.\n",
    "\n",
    "### Gestionarea fluxului\n",
    "\n",
    "Pentru a integra acest lucru în aplicația noastră, să urmăm pașii de mai jos:\n",
    "\n",
    "Mai întâi, să facem apelul către serviciile Open AI și să stocăm mesajul într-o variabilă numită `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum vom defini funcția care va apela API-ul Microsoft Learn pentru a obține o listă de cursuri:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca bună practică, vom verifica apoi dacă modelul dorește să apeleze o funcție. După aceea, vom crea una dintre funcțiile disponibile și o vom asocia cu funcția care este apelată. \n",
    "Apoi vom prelua argumentele funcției și le vom mapa la argumentele provenite de la LLM.\n",
    "\n",
    "La final, vom adăuga mesajul de apelare a funcției și valorile returnate de mesajul `search_courses`. Acest lucru oferă LLM-ului toate informațiile de care are nevoie\n",
    "pentru a răspunde utilizatorului folosind limbaj natural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provocare de cod\n",
    "\n",
    "Felicitări! Pentru a-ți continua învățarea despre Azure Open AI Function Calling, poți construi: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Mai mulți parametri ai funcției care ar putea ajuta cursanții să găsească mai multe cursuri. Poți găsi parametrii disponibili ai API-ului aici:\n",
    " - Creează o altă apelare de funcție care să preia mai multe informații de la cursant, cum ar fi limba maternă\n",
    " - Implementează gestionarea erorilor atunci când apelul funcției și/sau apelul API nu returnează niciun curs potrivit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Declinarea responsabilității**:  \nAcest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși depunem eforturi pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa nativă, trebuie considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de oameni. Nu ne asumăm răspunderea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea în urma utilizării acestei traduceri.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:30:58+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "ro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}