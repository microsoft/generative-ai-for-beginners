{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducere \n",
    "\n",
    "Această lecție va acoperi: \n",
    "- Ce este apelarea funcțiilor și cazurile lor de utilizare \n",
    "- Cum să creezi un apel de funcție folosind OpenAI \n",
    "- Cum să integrezi un apel de funcție într-o aplicație \n",
    "\n",
    "## Obiective de învățare \n",
    "\n",
    "După finalizarea acestei lecții vei ști cum să și vei înțelege: \n",
    "\n",
    "- Scopul utilizării apelării funcțiilor \n",
    "- Configurarea apelului de funcție folosind serviciul OpenAI \n",
    "- Proiectarea apelurilor de funcții eficiente pentru cazul tău de utilizare în aplicații \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Înțelegerea Apelurilor de Funcții\n",
    "\n",
    "Pentru această lecție, dorim să construim o funcționalitate pentru startup-ul nostru educațional care să permită utilizatorilor să folosească un chatbot pentru a găsi cursuri tehnice. Vom recomanda cursuri care se potrivesc nivelului lor de competență, rolului actual și tehnologiei de interes.\n",
    "\n",
    "Pentru a realiza acest lucru, vom folosi o combinație de:\n",
    " - `OpenAI` pentru a crea o experiență de chat pentru utilizator\n",
    " - `Microsoft Learn Catalog API` pentru a ajuta utilizatorii să găsească cursuri pe baza cererii utilizatorului\n",
    " - `Function Calling` pentru a prelua interogarea utilizatorului și a o trimite către o funcție care să facă cererea API.\n",
    "\n",
    "Pentru a începe, să vedem de ce am dori să folosim apelul de funcții în primul rând:\n",
    "\n",
    "print(\"Mesaje în următoarea cerere:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # obține un răspuns nou de la GPT unde poate vedea răspunsul funcției\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De ce apelarea funcțiilor\n",
    "\n",
    "Dacă ați finalizat orice altă lecție din acest curs, probabil că înțelegeți puterea utilizării modelelor mari de limbaj (LLM-uri). Sperăm că puteți vedea și unele dintre limitările lor.\n",
    "\n",
    "Apelarea funcțiilor este o caracteristică a serviciului OpenAI concepută pentru a aborda următoarele provocări:\n",
    "\n",
    "Formatare inconsistentă a răspunsurilor:\n",
    "- Înainte de apelarea funcțiilor, răspunsurile unui model mare de limbaj erau neorganizate și inconsistente. Dezvoltatorii trebuiau să scrie cod complex de validare pentru a gestiona fiecare variație a rezultatului.\n",
    "\n",
    "Integrare limitată cu date externe:\n",
    "- Înainte de această caracteristică, era dificil să se încorporeze date din alte părți ale unei aplicații într-un context de chat.\n",
    "\n",
    "Prin standardizarea formatelor de răspuns și facilitarea integrării fără probleme cu date externe, apelarea funcțiilor simplifică dezvoltarea și reduce necesitatea logicii suplimentare de validare.\n",
    "\n",
    "Utilizatorii nu puteau obține răspunsuri precum „Care este vremea actuală în Stockholm?”. Acest lucru se datorează faptului că modelele erau limitate la momentul în care datele au fost antrenate.\n",
    "\n",
    "Să analizăm exemplul de mai jos care ilustrează această problemă:\n",
    "\n",
    "Să presupunem că dorim să creăm o bază de date cu date despre studenți pentru a le putea sugera cursul potrivit. Mai jos avem două descrieri ale studenților care sunt foarte asemănătoare în datele pe care le conțin.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dorim să trimitem acest lucru către un LLM pentru a analiza datele. Acest lucru poate fi folosit ulterior în aplicația noastră pentru a trimite aceste informații către un API sau pentru a le stoca într-o bază de date.\n",
    "\n",
    "Să creăm două prompturi identice în care să instruim LLM-ul despre ce informații ne interesează:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrem să trimitem acest lucru unui LLM pentru a analiza părțile importante pentru produsul nostru. Astfel, putem crea două prompturi identice pentru a instrui LLM-ul:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce creăm aceste două prompturi, le vom trimite către LLM folosind `openai.ChatCompletion`. Stocăm promptul în variabila `messages` și atribuim rolul `user`. Acest lucru este pentru a imita un mesaj scris de un utilizator către un chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum putem trimite ambele cereri către LLM și să examinăm răspunsul pe care îl primim.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiar dacă prompturile sunt aceleași și descrierile sunt similare, putem obține formate diferite pentru proprietatea `Grades`.\n",
    "\n",
    "Dacă rulezi celula de mai sus de mai multe ori, formatul poate fi `3.7` sau `3.7 GPA`.\n",
    "\n",
    "Acest lucru se datorează faptului că LLM preia date nestructurate sub forma promptului scris și returnează, de asemenea, date nestructurate. Avem nevoie de un format structurat pentru a ști la ce să ne așteptăm atunci când stocăm sau folosim aceste date.\n",
    "\n",
    "Folosind apelarea funcțională, ne putem asigura că primim înapoi date structurate. Când folosim apelarea funcțională, LLM nu apelează sau nu rulează efectiv nicio funcție. În schimb, creăm o structură pe care LLM trebuie să o urmeze pentru răspunsurile sale. Apoi folosim acele răspunsuri structurate pentru a ști ce funcție să rulăm în aplicațiile noastre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama fluxului apelării funcției](../../../../translated_images/Function-Flow.083875364af4f4bb.ro.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Putem apoi lua ceea ce este returnat de funcție și trimite acest lucru înapoi către LLM. LLM va răspunde apoi folosind limbaj natural pentru a răspunde la întrebarea utilizatorului.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cazuri de utilizare pentru apelarea funcțiilor\n",
    "\n",
    "**Apelarea uneltelor externe**  \n",
    "Chatboții sunt excelenți în a oferi răspunsuri la întrebările utilizatorilor. Prin utilizarea apelării funcțiilor, chatboții pot folosi mesajele utilizatorilor pentru a îndeplini anumite sarcini. De exemplu, un student poate cere chatbotului să „Trimită un email instructorului meu spunând că am nevoie de mai mult ajutor cu acest subiect”. Acesta poate face un apel de funcție către `send_email(to: string, body: string)`\n",
    "\n",
    "**Crearea de interogări API sau baze de date**  \n",
    "Utilizatorii pot găsi informații folosind limbaj natural care este convertit într-o interogare formatată sau o cerere API. Un exemplu ar putea fi un profesor care solicită „Cine sunt studenții care au finalizat ultima temă” ceea ce ar putea apela o funcție numită `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Crearea de date structurate**  \n",
    "Utilizatorii pot lua un bloc de text sau CSV și pot folosi LLM pentru a extrage informații importante din acesta. De exemplu, un student poate converti un articol Wikipedia despre acorduri de pace pentru a crea fișe AI de studiu. Acest lucru se poate face folosind o funcție numită `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crearea primei apelări a funcției tale\n",
    "\n",
    "Procesul de creare a unei apelări a funcției include 3 pași principali:  \n",
    "1. Apelarea API-ului Chat Completions cu o listă a funcțiilor tale și un mesaj de la utilizator  \n",
    "2. Citirea răspunsului modelului pentru a efectua o acțiune, adică executarea unei funcții sau a unui apel API  \n",
    "3. Efectuarea unui alt apel la API-ul Chat Completions cu răspunsul funcției tale pentru a folosi acea informație în crearea unui răspuns pentru utilizator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fluxul unui apel de funcție](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.ro.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemente ale unui apel de funcție \n",
    "\n",
    "#### Intrarea utilizatorului \n",
    "\n",
    "Primul pas este să creați un mesaj de utilizator. Acesta poate fi atribuit dinamic preluând valoarea unui câmp de text sau puteți atribui o valoare aici. Dacă este prima dată când lucrați cu API-ul Chat Completions, trebuie să definim `role` și `content` ale mesajului. \n",
    "\n",
    "`role` poate fi fie `system` (crearea regulilor), `assistant` (modelul) sau `user` (utilizatorul final). Pentru apelarea funcțiilor, vom atribui acestuia valoarea `user` și o întrebare exemplu. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crearea funcțiilor.\n",
    "\n",
    "În continuare vom defini o funcție și parametrii acelei funcții. Vom folosi doar o funcție aici numită `search_courses`, dar poți crea mai multe funcții.\n",
    "\n",
    "**Important** : Funcțiile sunt incluse în mesajul sistem către LLM și vor fi incluse în cantitatea de tokeni disponibili pe care îi ai la dispoziție.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiții** \n",
    "\n",
    "Structura definiției funcției are mai multe niveluri, fiecare cu propriile proprietăți. Iată o defalcare a structurii imbricate:\n",
    "\n",
    "**Proprietăți la nivelul superior al funcției:**\n",
    "\n",
    "`name` - Numele funcției pe care dorim să o apelăm. \n",
    "\n",
    "`description` - Aceasta este descrierea modului în care funcția funcționează. Aici este important să fim specifici și clari. \n",
    "\n",
    "`parameters` - O listă de valori și formatul pe care doriți ca modelul să le producă în răspunsul său. \n",
    "\n",
    "**Proprietăți ale obiectului Parameters:**\n",
    "\n",
    "`type` - Tipul de date al obiectului parameters (de obicei \"object\")\n",
    "\n",
    "`properties` - Lista valorilor specifice pe care modelul le va folosi pentru răspunsul său. \n",
    "\n",
    "**Proprietăți individuale ale parametrilor:**\n",
    "\n",
    "`name` - Definit implicit de cheia proprietății (de exemplu, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Tipul de date al acestui parametru specific (de exemplu, \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Descrierea parametrului specific. \n",
    "\n",
    "**Proprietăți opționale:**\n",
    "\n",
    "`required` - Un tablou care listează care parametri sunt necesari pentru ca apelul funcției să fie completat. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apelarea funcției  \n",
    "După definirea unei funcții, trebuie acum să o includem în apelul către API-ul Chat Completion. Facem acest lucru adăugând `functions` la cerere. În acest caz, `functions=functions`. \n",
    "\n",
    "Există, de asemenea, o opțiune de a seta `function_call` la `auto`. Aceasta înseamnă că vom lăsa LLM să decidă ce funcție ar trebui apelată pe baza mesajului utilizatorului, în loc să o atribuim noi înșine.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum să analizăm răspunsul și să vedem cum este formatat:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Puteți observa că numele funcției este apelat și, din mesajul utilizatorului, LLM a reușit să găsească datele pentru a completa argumentele funcției.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Integrarea apelurilor funcțiilor într-o aplicație. \n",
    "\n",
    "\n",
    "După ce am testat răspunsul formatat de la LLM, acum îl putem integra într-o aplicație. \n",
    "\n",
    "### Gestionarea fluxului \n",
    "\n",
    "Pentru a integra acest lucru în aplicația noastră, să urmăm pașii următori: \n",
    "\n",
    "Mai întâi, să facem apelul către serviciile OpenAI și să stocăm mesajul într-o variabilă numită `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum vom defini funcția care va apela API-ul Microsoft Learn pentru a obține o listă de cursuri:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca o bună practică, vom vedea apoi dacă modelul dorește să apeleze o funcție. După aceea, vom crea una dintre funcțiile disponibile și o vom potrivi cu funcția care este apelată.  \n",
    "Apoi vom lua argumentele funcției și le vom mapa la argumentele din LLM.\n",
    "\n",
    "În final, vom adăuga mesajul apelului funcției și valorile care au fost returnate de mesajul `search_courses`. Acest lucru oferă LLM toate informațiile de care are nevoie pentru a răspunde utilizatorului folosind limbaj natural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum vom trimite mesajul actualizat către LLM pentru a putea primi un răspuns în limbaj natural în loc de un răspuns formatat JSON API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provocare de cod \n",
    "\n",
    "Bravo! Pentru a continua învățarea despre OpenAI Function Calling, poți construi: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst \n",
    " - Mai mulți parametri ai funcției care ar putea ajuta cursanții să găsească mai multe cursuri. Poți găsi parametrii API disponibili aici: \n",
    " - Creează un alt apel de funcție care să preia mai multe informații de la cursant, cum ar fi limba lor maternă \n",
    " - Creează gestionarea erorilor atunci când apelul funcției și/sau apelul API nu returnează niciun curs potrivit \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Declinare de responsabilitate**:  \nAcest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși ne străduim pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original în limba sa nativă trebuie considerat sursa autorizată. Pentru informații critice, se recomandă traducerea profesională realizată de un specialist uman. Nu ne asumăm răspunderea pentru eventualele neînțelegeri sau interpretări greșite rezultate din utilizarea acestei traduceri.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T11:31:34+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}