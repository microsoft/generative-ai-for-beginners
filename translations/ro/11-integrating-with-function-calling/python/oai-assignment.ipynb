{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducere\n",
    "\n",
    "Această lecție va acoperi:\n",
    "- Ce este apelarea de funcții și când se folosește\n",
    "- Cum să creezi un apel de funcție folosind OpenAI\n",
    "- Cum să integrezi un apel de funcție într-o aplicație\n",
    "\n",
    "## Obiective de învățare\n",
    "\n",
    "După ce finalizezi această lecție vei ști și vei înțelege:\n",
    "\n",
    "- Scopul utilizării apelării de funcții\n",
    "- Configurarea apelului de funcție folosind serviciul OpenAI\n",
    "- Cum să proiectezi apeluri de funcții eficiente pentru cazul de utilizare al aplicației tale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Înțelegerea apelurilor de funcții\n",
    "\n",
    "Pentru această lecție, vrem să construim o funcționalitate pentru startup-ul nostru educațional care să permită utilizatorilor să folosească un chatbot pentru a găsi cursuri tehnice. Vom recomanda cursuri care se potrivesc nivelului lor de cunoștințe, rolului actual și tehnologiei de interes.\n",
    "\n",
    "Pentru a realiza acest lucru vom folosi o combinație de:\n",
    " - `OpenAI` pentru a crea o experiență de chat pentru utilizator\n",
    " - `Microsoft Learn Catalog API` pentru a ajuta utilizatorii să găsească cursuri pe baza cererii lor\n",
    " - `Function Calling` pentru a prelua întrebarea utilizatorului și a o trimite către o funcție care face cererea către API.\n",
    "\n",
    "Ca să începem, hai să vedem de ce am vrea să folosim apelarea funcțiilor în primul rând:\n",
    "\n",
    "print(\"Mesaje în următoarea cerere:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # obține un nou răspuns de la GPT unde poate vedea răspunsul funcției\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### De ce este important Function Calling\n",
    "\n",
    "Dacă ai parcurs deja alte lecții din acest curs, probabil că ai înțeles cât de puternice sunt modelele de limbaj de tip Large Language Models (LLMs). Sperăm că ai observat și unele dintre limitele lor.\n",
    "\n",
    "Function Calling este o funcționalitate din OpenAI Service creată pentru a rezolva următoarele provocări:\n",
    "\n",
    "Formatarea inconsistentă a răspunsurilor:\n",
    "- Înainte de function calling, răspunsurile generate de un model de limbaj erau neorganizate și variabile. Dezvoltatorii erau nevoiți să scrie cod complex de validare pentru a gestiona fiecare variantă de output.\n",
    "\n",
    "Integrare limitată cu date externe:\n",
    "- Înainte de această funcție, era dificil să adaugi date din alte părți ale aplicației într-un context de chat.\n",
    "\n",
    "Prin standardizarea formatului răspunsurilor și facilitarea integrării cu date externe, function calling simplifică dezvoltarea și reduce nevoia de logică suplimentară de validare.\n",
    "\n",
    "Utilizatorii nu puteau primi răspunsuri de tipul „Care este vremea actuală în Stockholm?”. Asta pentru că modelele erau limitate la perioada în care au fost antrenate.\n",
    "\n",
    "Hai să analizăm exemplul de mai jos care ilustrează această problemă:\n",
    "\n",
    "Să presupunem că vrem să creăm o bază de date cu informații despre studenți, ca să le putem recomanda cursul potrivit. Mai jos avem două descrieri de studenți care sunt foarte asemănătoare ca date conținute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrem să trimitem acest lucru către un LLM pentru a analiza datele. Acest lucru poate fi folosit ulterior în aplicația noastră pentru a trimite datele către o API sau pentru a le stoca într-o bază de date.\n",
    "\n",
    "Hai să creăm două prompturi identice prin care instruim LLM-ul ce informații ne interesează:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vrem să trimitem acest lucru către un LLM pentru a analiza părțile care sunt importante pentru produsul nostru. Astfel, putem crea două prompturi identice pentru a instrui LLM-ul:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "După ce creăm aceste două prompturi, le vom trimite către LLM folosind `openai.ChatCompletion`. Stocăm promptul în variabila `messages` și atribuim rolul `user`. Acest lucru este pentru a imita un mesaj de la un utilizator scris către un chatbot.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chiar dacă instrucțiunile sunt aceleași și descrierile sunt similare, putem obține formate diferite pentru proprietatea `Grades`.\n",
    "\n",
    "Dacă rulezi celula de mai sus de mai multe ori, formatul poate fi `3.7` sau `3.7 GPA`.\n",
    "\n",
    "Acest lucru se întâmplă deoarece LLM-ul primește date nestructurate sub forma instrucțiunii scrise și returnează tot date nestructurate. Avem nevoie de un format structurat ca să știm la ce să ne așteptăm atunci când stocăm sau folosim aceste date.\n",
    "\n",
    "Folosind apelarea funcțională, ne putem asigura că primim date structurate înapoi. Când folosim apelarea funcțională, LLM-ul nu apelează sau rulează efectiv nicio funcție. În schimb, creăm o structură pe care LLM-ul să o urmeze pentru răspunsurile sale. Apoi folosim aceste răspunsuri structurate ca să știm ce funcție să rulăm în aplicațiile noastre.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagrama fluxului de apelare a funcției](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.ro.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exemple de utilizare pentru apelarea funcțiilor\n",
    "\n",
    "**Apelarea unor instrumente externe**  \n",
    "Chatboții sunt foarte buni la a oferi răspunsuri la întrebările utilizatorilor. Prin folosirea apelării de funcții, chatboții pot folosi mesajele utilizatorilor pentru a îndeplini anumite sarcini. De exemplu, un student poate cere chatbotului: „Trimite un email profesorului meu în care să-i spun că am nevoie de mai mult ajutor la această materie”. Acest lucru poate apela funcția `send_email(to: string, body: string)`\n",
    "\n",
    "**Crearea de interogări API sau către baze de date**  \n",
    "Utilizatorii pot găsi informații folosind limbaj natural, care este apoi transformat într-o interogare formatată sau o cerere API. Un exemplu ar fi un profesor care întreabă „Cine sunt studenții care au finalizat ultima temă”, ceea ce ar putea apela o funcție numită `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Crearea de date structurate**  \n",
    "Utilizatorii pot lua un bloc de text sau un fișier CSV și pot folosi LLM-ul pentru a extrage informațiile importante din acesta. De exemplu, un student poate transforma un articol de pe Wikipedia despre acorduri de pace pentru a crea fișe de învățare AI. Acest lucru se poate face folosind o funcție numită `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Crearea primei tale apelări de funcție\n",
    "\n",
    "Procesul de creare a unei apelări de funcție include 3 pași principali:\n",
    "1. Apelezi API-ul Chat Completions cu o listă de funcții și un mesaj de la utilizator\n",
    "2. Citești răspunsul modelului pentru a efectua o acțiune, adică să execuți o funcție sau să faci un apel API\n",
    "3. Faci o altă apelare către API-ul Chat Completions cu răspunsul de la funcția ta pentru a folosi acea informație la crearea unui răspuns pentru utilizator.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Fluxul unui apel de funcție](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.ro.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elemente ale unui apel de funcție\n",
    "\n",
    "#### Introducerea utilizatorului\n",
    "\n",
    "Primul pas este să creezi un mesaj de la utilizator. Acesta poate fi atribuit dinamic, preluând valoarea dintr-un câmp de text, sau poți seta o valoare aici. Dacă este prima dată când lucrezi cu API-ul Chat Completions, trebuie să definim `role` și `content` pentru mesaj.\n",
    "\n",
    "`role` poate fi fie `system` (pentru a stabili reguli), `assistant` (modelul) sau `user` (utilizatorul final). Pentru apelarea funcțiilor, vom seta acest rol ca `user` și vom folosi o întrebare exemplu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Crearea funcțiilor.\n",
    "\n",
    "În continuare vom defini o funcție și parametrii acesteia. Vom folosi aici doar o funcție numită `search_courses`, dar poți crea mai multe funcții.\n",
    "\n",
    "**Important** : Funcțiile sunt incluse în mesajul de sistem către LLM și vor fi luate în calcul la numărul de tokenuri disponibile.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definiții**\n",
    "\n",
    "Structura de definire a funcției are mai multe niveluri, fiecare cu propriile sale proprietăți. Iată o prezentare a structurii imbricate:\n",
    "\n",
    "**Proprietăți la nivelul superior al funcției:**\n",
    "\n",
    "`name` - Numele funcției pe care dorim să fie apelată.\n",
    "\n",
    "`description` - Aceasta este descrierea modului în care funcționează funcția. Aici este important să fii specific și clar.\n",
    "\n",
    "`parameters` - O listă de valori și formatul pe care vrei ca modelul să le genereze în răspunsul său.\n",
    "\n",
    "**Proprietăți ale obiectului Parameters:**\n",
    "\n",
    "`type` - Tipul de date al obiectului parameters (de obicei \"object\")\n",
    "\n",
    "`properties` - Lista valorilor specifice pe care modelul le va folosi pentru răspunsul său\n",
    "\n",
    "**Proprietăți individuale ale parametrilor:**\n",
    "\n",
    "`name` - Definit implicit de cheia proprietății (de exemplu, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Tipul de date al acestui parametru specific (de exemplu, \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Descrierea parametrului specific\n",
    "\n",
    "**Proprietăți opționale:**\n",
    "\n",
    "`required` - Un array care enumeră ce parametri sunt necesari pentru ca apelul funcției să fie completat\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efectuarea apelului funcției\n",
    "După ce am definit o funcție, trebuie acum să o includem în apelul către Chat Completion API. Facem acest lucru adăugând `functions` la cerere. În acest caz, `functions=functions`.\n",
    "\n",
    "Există și opțiunea de a seta `function_call` la `auto`. Asta înseamnă că vom lăsa LLM-ul să decidă ce funcție ar trebui apelată pe baza mesajului utilizatorului, în loc să o atribuim noi manual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum să analizăm răspunsul și să vedem cum este formatat:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Poți observa că numele funcției este apelat și, din mesajul utilizatorului, LLM-ul a reușit să găsească datele potrivite pentru argumentele funcției.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrarea apelurilor de funcții într-o aplicație.\n",
    "\n",
    "După ce am testat răspunsul formatat de la LLM, acum putem integra acest lucru într-o aplicație.\n",
    "\n",
    "### Gestionarea fluxului\n",
    "\n",
    "Pentru a integra acest lucru în aplicația noastră, să urmăm pașii de mai jos:\n",
    "\n",
    "Mai întâi, să facem apelul către serviciile OpenAI și să stocăm mesajul într-o variabilă numită `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acum vom defini funcția care va apela API-ul Microsoft Learn pentru a obține o listă de cursuri:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ca bună practică, vom verifica apoi dacă modelul dorește să apeleze o funcție. După aceea, vom crea una dintre funcțiile disponibile și o vom asocia cu funcția care este apelată.\n",
    "Apoi vom prelua argumentele funcției și le vom mapa la argumentele provenite de la LLM.\n",
    "\n",
    "La final, vom adăuga mesajul de apelare a funcției și valorile returnate de mesajul `search_courses`. Acest lucru oferă LLM-ului toate informațiile de care are nevoie\n",
    "pentru a răspunde utilizatorului folosind limbaj natural.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provocare de cod\n",
    "\n",
    "Foarte bine! Pentru a-ți continua învățarea despre OpenAI Function Calling poți construi: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Mai mulți parametri ai funcției care ar putea ajuta cursanții să găsească mai multe cursuri. Poți găsi parametrii disponibili ai API-ului aici:\n",
    " - Creează un alt apel de funcție care să preia mai multe informații de la cursant, cum ar fi limba lor maternă\n",
    " - Creează gestionare a erorilor atunci când apelul funcției și/sau apelul API nu returnează niciun curs potrivit\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Declinarea responsabilității**:\nAcest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). Deși depunem eforturi pentru acuratețe, vă rugăm să rețineți că traducerile automate pot conține erori sau inexactități. Documentul original, în limba sa nativă, trebuie considerat sursa autoritară. Pentru informații critice, se recomandă traducerea profesională realizată de oameni. Nu ne asumăm răspunderea pentru eventualele neînțelegeri sau interpretări greșite care pot apărea în urma utilizării acestei traduceri.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:19:50+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "ro"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}