<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:39:36+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "ro"
}
-->
# Explorarea È™i compararea diferitelor LLM-uri

[![Explorarea È™i compararea diferitelor LLM-uri](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.ro.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Click pe imaginea de mai sus pentru a viziona videoclipul acestei lecÈ›ii_

Ãn lecÈ›ia anterioarÄƒ, am vÄƒzut cum Generative AI schimbÄƒ peisajul tehnologic, cum funcÈ›ioneazÄƒ Large Language Models (LLM-uri) È™i cum o afacere â€“ precum startup-ul nostru â€“ le poate aplica Ã®n cazurile lor de utilizare pentru a creÈ™te! Ãn acest capitol, ne propunem sÄƒ comparÄƒm È™i sÄƒ evidenÈ›iem diferenÈ›ele dintre diferite tipuri de modele mari de limbaj (LLM-uri) pentru a Ã®nÈ›elege avantajele È™i dezavantajele fiecÄƒruia.

UrmÄƒtorul pas Ã®n cÄƒlÄƒtoria startup-ului nostru este explorarea peisajului actual al LLM-urilor È™i Ã®nÈ›elegerea care dintre ele sunt potrivite pentru cazul nostru de utilizare.

## Introducere

AceastÄƒ lecÈ›ie va acoperi:

- Diferitele tipuri de LLM-uri din peisajul actual.
- Testarea, iterarea È™i compararea diferitelor modele pentru cazul tÄƒu de utilizare Ã®n Azure.
- Cum sÄƒ implementezi un LLM.

## Obiective de Ã®nvÄƒÈ›are

DupÄƒ finalizarea acestei lecÈ›ii, vei putea:

- SÄƒ selectezi modelul potrivit pentru cazul tÄƒu de utilizare.
- SÄƒ Ã®nÈ›elegi cum sÄƒ testezi, sÄƒ iterezi È™i sÄƒ Ã®mbunÄƒtÄƒÈ›eÈ™ti performanÈ›a modelului tÄƒu.
- SÄƒ È™tii cum implementeazÄƒ afacerile modelele.

## ÃnÈ›elegerea diferitelor tipuri de LLM-uri

LLM-urile pot fi clasificate Ã®n mai multe moduri, Ã®n funcÈ›ie de arhitectura lor, datele de antrenament È™i cazul de utilizare. ÃnÈ›elegerea acestor diferenÈ›e ne va ajuta startup-ul sÄƒ aleagÄƒ modelul potrivit pentru scenariu È™i sÄƒ Ã®nÈ›eleagÄƒ cum sÄƒ testeze, sÄƒ itereze È™i sÄƒ Ã®mbunÄƒtÄƒÈ›eascÄƒ performanÈ›a.

ExistÄƒ multe tipuri diferite de modele LLM, iar alegerea ta depinde de scopul pentru care vrei sÄƒ le foloseÈ™ti, de datele pe care le ai, de buget È™i alÈ›i factori.

Ãn funcÈ›ie de faptul dacÄƒ vrei sÄƒ foloseÈ™ti modelele pentru text, audio, video, generare de imagini È™i aÈ™a mai departe, s-ar putea sÄƒ optezi pentru un tip diferit de model.

- **RecunoaÈ™tere audio È™i vocalÄƒ**. Pentru acest scop, modelele de tip Whisper sunt o alegere excelentÄƒ, deoarece sunt modele generale, orientate spre recunoaÈ™terea vorbirii. Sunt antrenate pe audio divers È™i pot realiza recunoaÈ™tere vocalÄƒ multilingvÄƒ. AflÄƒ mai multe despre [modelele de tip Whisper aici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generare de imagini**. Pentru generarea de imagini, DALL-E È™i Midjourney sunt douÄƒ opÈ›iuni foarte cunoscute. DALL-E este oferit prin Azure OpenAI. [CiteÈ™te mai multe despre DALL-E aici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) È™i, de asemenea, Ã®n Capitolul 9 al acestui curriculum.

- **Generare de text**. Majoritatea modelelor sunt antrenate pentru generare de text È™i ai o varietate largÄƒ de opÈ›iuni, de la GPT-3.5 la GPT-4. Acestea vin la costuri diferite, GPT-4 fiind cel mai scump. MeritÄƒ sÄƒ arunci o privire Ã®n [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pentru a evalua care modele se potrivesc cel mai bine nevoilor tale Ã®n termeni de capacitate È™i cost.

- **Multi-modalitate**. DacÄƒ doreÈ™ti sÄƒ gestionezi mai multe tipuri de date la intrare È™i ieÈ™ire, s-ar putea sÄƒ te intereseze modele precum [gpt-4 turbo cu viziune sau gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) â€“ cele mai recente lansÄƒri ale modelelor OpenAI â€“ care pot combina procesarea limbajului natural cu Ã®nÈ›elegerea vizualÄƒ, permiÈ›Ã¢nd interacÈ›iuni prin interfeÈ›e multi-modale.

Alegerea unui model Ã®nseamnÄƒ cÄƒ obÈ›ii niÈ™te capabilitÄƒÈ›i de bazÄƒ, care Ã®nsÄƒ s-ar putea sÄƒ nu fie suficiente. Deseori, ai date specifice companiei pe care trebuie sÄƒ le transmiÈ›i cumva LLM-ului. ExistÄƒ cÃ¢teva opÈ›iuni diferite pentru a aborda acest aspect, despre care vom vorbi Ã®n secÈ›iunile urmÄƒtoare.

### Modele Foundation versus LLM-uri

Termenul Foundation Model a fost [creat de cercetÄƒtorii de la Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) È™i definit ca un model AI care respectÄƒ anumite criterii, cum ar fi:

- **Sunt antrenate folosind Ã®nvÄƒÈ›are nesupravegheatÄƒ sau auto-supravegheatÄƒ**, ceea ce Ã®nseamnÄƒ cÄƒ sunt antrenate pe date multi-modale neetichetate È™i nu necesitÄƒ adnotare umanÄƒ pentru procesul de antrenament.
- **Sunt modele foarte mari**, bazate pe reÈ›ele neuronale foarte adÃ¢nci, antrenate pe miliarde de parametri.
- **Sunt de obicei destinate sÄƒ serveascÄƒ drept â€bazÄƒâ€ pentru alte modele**, adicÄƒ pot fi folosite ca punct de plecare pentru construirea altor modele, prin fine-tuning.

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.ro.png)

Sursa imaginii: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pentru a clarifica mai bine aceastÄƒ distincÈ›ie, sÄƒ luÄƒm ChatGPT ca exemplu. Pentru a construi prima versiune a ChatGPT, un model numit GPT-3.5 a servit drept foundation model. Aceasta Ã®nseamnÄƒ cÄƒ OpenAI a folosit date specifice pentru chat pentru a crea o versiune ajustatÄƒ a GPT-3.5, specializatÄƒ sÄƒ performeze bine Ã®n scenarii conversaÈ›ionale, cum ar fi chatbot-urile.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.ro.png)

Sursa imaginii: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modele Open Source versus Proprietare

O altÄƒ modalitate de a clasifica LLM-urile este dacÄƒ sunt open source sau proprietare.

Modelele open source sunt modele puse la dispoziÈ›ia publicului È™i pot fi folosite de oricine. Ele sunt adesea oferite de compania care le-a creat sau de comunitatea de cercetare. Aceste modele pot fi inspectate, modificate È™i personalizate pentru diverse cazuri de utilizare. TotuÈ™i, ele nu sunt Ã®ntotdeauna optimizate pentru utilizare Ã®n producÈ›ie È™i pot sÄƒ nu aibÄƒ performanÈ›e la fel de bune ca modelele proprietare. Ãn plus, finanÈ›area pentru modelele open source poate fi limitatÄƒ, iar acestea pot sÄƒ nu fie Ã®ntreÈ›inute pe termen lung sau actualizate cu cele mai recente cercetÄƒri. Exemple populare de modele open source includ [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) È™i [LLaMA](https://llama.meta.com).

Modelele proprietare sunt modele deÈ›inute de o companie È™i nu sunt puse la dispoziÈ›ia publicului. Aceste modele sunt adesea optimizate pentru utilizare Ã®n producÈ›ie. TotuÈ™i, ele nu pot fi inspectate, modificate sau personalizate pentru diferite cazuri de utilizare. De asemenea, nu sunt Ã®ntotdeauna disponibile gratuit È™i pot necesita abonament sau platÄƒ pentru utilizare. Utilizatorii nu au control asupra datelor folosite pentru antrenarea modelului, ceea ce Ã®nseamnÄƒ cÄƒ trebuie sÄƒ aibÄƒ Ã®ncredere Ã®n proprietarul modelului pentru a asigura respectarea confidenÈ›ialitÄƒÈ›ii datelor È™i utilizarea responsabilÄƒ a AI. Exemple populare de modele proprietare includ [modelele OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) sau [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus generare de imagini versus generare de text È™i cod

LLM-urile pot fi, de asemenea, clasificate Ã®n funcÈ›ie de tipul de output pe care Ã®l genereazÄƒ.

Embeddings sunt un set de modele care pot converti textul Ã®ntr-o formÄƒ numericÄƒ, numitÄƒ embedding, care reprezintÄƒ numeric textul de intrare. Embeddings faciliteazÄƒ Ã®nÈ›elegerea relaÈ›iilor dintre cuvinte sau propoziÈ›ii de cÄƒtre maÈ™ini È™i pot fi folosite ca input pentru alte modele, cum ar fi cele de clasificare sau de clustering, care au performanÈ›e mai bune pe date numerice. Modelele de embedding sunt adesea folosite pentru transfer learning, unde un model este construit pentru o sarcinÄƒ surrogate pentru care existÄƒ o mulÈ›ime de date, iar apoi greutÄƒÈ›ile modelului (embeddings) sunt reutilizate pentru alte sarcini ulterioare. Un exemplu din aceastÄƒ categorie este [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.ro.png)

Modelele de generare de imagini sunt modele care creeazÄƒ imagini. Acestea sunt folosite adesea pentru editare de imagini, sintezÄƒ de imagini È™i traducere de imagini. Modelele de generare de imagini sunt antrenate pe seturi mari de imagini, cum ar fi [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), È™i pot fi folosite pentru a genera imagini noi sau pentru a edita imagini existente folosind tehnici precum inpainting, super-rezoluÈ›ie È™i colorizare. Exemple includ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) È™i [modelele Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generare de imagini](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.ro.png)

Modelele de generare de text È™i cod sunt modele care genereazÄƒ text sau cod. Acestea sunt folosite adesea pentru sumarizarea textului, traducere È™i rÄƒspuns la Ã®ntrebÄƒri. Modelele de generare de text sunt antrenate pe seturi mari de texte, cum ar fi [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), È™i pot fi folosite pentru a genera text nou sau pentru a rÄƒspunde la Ã®ntrebÄƒri. Modelele de generare de cod, precum [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sunt antrenate pe seturi mari de cod, cum ar fi GitHub, È™i pot genera cod nou sau pot corecta erori Ã®n codul existent.

![Generare de text È™i cod](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.ro.png)

### Encoder-Decoder versus Decoder-only

Pentru a vorbi despre diferitele tipuri de arhitecturi ale LLM-urilor, sÄƒ folosim o analogie.

ImagineazÄƒ-È›i cÄƒ managerul tÄƒu È›i-a dat sarcina de a scrie un quiz pentru studenÈ›i. Ai doi colegi; unul se ocupÄƒ de crearea conÈ›inutului, iar celÄƒlalt de revizuirea acestuia.

Creatorul de conÈ›inut este ca un model Decoder-only, el poate vedea subiectul È™i ce ai scris deja, apoi poate scrie un curs bazat pe asta. Sunt foarte buni la a scrie conÈ›inut captivant È™i informativ, dar nu sunt foarte buni la Ã®nÈ›elegerea subiectului È™i a obiectivelor de Ã®nvÄƒÈ›are. Exemple de modele Decoder sunt modelele din familia GPT, cum ar fi GPT-3.

Revizorul este ca un model Encoder-only, el analizeazÄƒ cursul scris È™i rÄƒspunsurile, observÃ¢nd relaÈ›ia dintre ele È™i Ã®nÈ›elegÃ¢nd contextul, dar nu este bun la generarea de conÈ›inut. Un exemplu de model Encoder-only este BERT.

ImagineazÄƒ-È›i cÄƒ am putea avea pe cineva care sÄƒ creeze È™i sÄƒ revizuiascÄƒ quiz-ul, acesta este un model Encoder-Decoder. Exemple ar fi BART È™i T5.

### Serviciu versus Model

Acum, sÄƒ vorbim despre diferenÈ›a dintre un serviciu È™i un model. Un serviciu este un produs oferit de un furnizor de servicii cloud È™i este adesea o combinaÈ›ie de modele, date È™i alte componente. Un model este componenta de bazÄƒ a unui serviciu È™i este adesea un foundation model, cum ar fi un LLM.

Serviciile sunt adesea optimizate pentru utilizare Ã®n producÈ›ie È™i sunt mai uÈ™or de folosit decÃ¢t modelele, printr-o interfaÈ›Äƒ graficÄƒ. TotuÈ™i, serviciile nu sunt Ã®ntotdeauna gratuite È™i pot necesita abonament sau platÄƒ, Ã®n schimbul utilizÄƒrii echipamentelor È™i resurselor proprietarului serviciului, optimizÃ¢nd costurile È™i scalarea facilÄƒ. Un exemplu de serviciu este [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), care oferÄƒ un plan tarifar pay-as-you-go, adicÄƒ utilizatorii plÄƒtesc proporÈ›ional cu cÃ¢t folosesc serviciul. De asemenea, Azure OpenAI Service oferÄƒ securitate la nivel enterprise È™i un cadru de AI responsabil peste capabilitÄƒÈ›ile modelelor.

Modelele sunt doar reÈ›eaua neuronalÄƒ, cu parametrii, greutÄƒÈ›ile È™i altele. PermiÈ›Ã¢nd companiilor sÄƒ ruleze local, Ã®nsÄƒ ar trebui sÄƒ cumpere echipamente, sÄƒ construiascÄƒ o infrastructurÄƒ pentru scalare È™i sÄƒ cumpere o licenÈ›Äƒ sau sÄƒ foloseascÄƒ un model open source. Un model precum LLaMA este disponibil pentru utilizare, necesitÃ¢nd putere de calcul pentru a rula modelul.

## Cum sÄƒ testezi È™i sÄƒ iterezi cu diferite modele pentru a Ã®nÈ›elege performanÈ›a Ã®n Azure

OdatÄƒ ce echipa noastrÄƒ a explorat peisajul actual al LLM-urilor È™i a identificat cÃ¢È›iva candidaÈ›i buni pentru scenariile lor, urmÄƒtorul pas este sÄƒ Ã®i testeze pe datele È™i pe volumul lor de lucru. Acesta este un proces iterativ, realizat prin experimente È™i mÄƒsurÄƒtori.
Majoritatea modelelor menÈ›ionate Ã®n paragrafele anterioare (modelele OpenAI, modelele open source precum Llama2 È™i transformatoarele Hugging Face) sunt disponibile Ã®n [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) din [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) este o platformÄƒ cloud creatÄƒ pentru dezvoltatori, care le permite sÄƒ construiascÄƒ aplicaÈ›ii AI generative È™i sÄƒ gestioneze Ã®ntregul ciclu de viaÈ›Äƒ al dezvoltÄƒrii â€“ de la experimentare pÃ¢nÄƒ la evaluare â€“ combinÃ¢nd toate serviciile Azure AI Ã®ntr-un singur hub cu o interfaÈ›Äƒ graficÄƒ prietenoasÄƒ. Catalogul de modele din Azure AI Studio oferÄƒ utilizatorului posibilitatea de a:

- GÄƒsi modelul de bazÄƒ dorit Ã®n catalog â€“ fie proprietar, fie open source, filtrÃ¢nd dupÄƒ sarcinÄƒ, licenÈ›Äƒ sau nume. Pentru a facilita cÄƒutarea, modelele sunt organizate Ã®n colecÈ›ii, cum ar fi colecÈ›ia Azure OpenAI, colecÈ›ia Hugging Face È™i altele.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.ro.png)

- Consulta cardul modelului, care include o descriere detaliatÄƒ a utilizÄƒrii intenÈ›ionate È™i a datelor de antrenament, exemple de cod È™i rezultate ale evaluÄƒrilor din biblioteca internÄƒ de evaluÄƒri.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.ro.png)

- Compara benchmark-uri Ã®ntre modele È™i seturi de date disponibile Ã®n industrie pentru a evalua care se potriveÈ™te cel mai bine scenariului de afaceri, prin panoul [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.ro.png)

- Ajusta fin modelul pe date de antrenament personalizate pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului Ã®ntr-un anumit tip de sarcinÄƒ, folosind capabilitÄƒÈ›ile de experimentare È™i urmÄƒrire ale Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.ro.png)

- Implementa modelul pre-antrenat original sau versiunea ajustatÄƒ fin cÄƒtre un endpoint de inferenÈ›Äƒ Ã®n timp real â€“ fie pe un compute gestionat, fie pe un endpoint API serverless â€“ [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) â€“ pentru a permite aplicaÈ›iilor sÄƒ Ã®l consume.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.ro.png)


> [!NOTE]
> Nu toate modelele din catalog sunt disponibile Ã®n prezent pentru ajustare finÄƒ È™i/sau implementare pay-as-you-go. VerificaÈ›i cardul modelului pentru detalii despre capabilitÄƒÈ›ile È™i limitÄƒrile acestuia.

## ÃmbunÄƒtÄƒÈ›irea rezultatelor LLM

Am explorat Ã®mpreunÄƒ cu echipa noastrÄƒ de startup diferite tipuri de LLM-uri È™i o platformÄƒ cloud (Azure Machine Learning) care ne-a permis sÄƒ comparÄƒm diverse modele, sÄƒ le evaluÄƒm pe date de test, sÄƒ Ã®mbunÄƒtÄƒÈ›im performanÈ›a È™i sÄƒ le implementÄƒm pe endpoint-uri de inferenÈ›Äƒ.

Dar cÃ¢nd ar trebui sÄƒ ia Ã®n considerare ajustarea finÄƒ a unui model Ã®n loc sÄƒ foloseascÄƒ unul pre-antrenat? ExistÄƒ alte metode pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului pe sarcini specifice?

ExistÄƒ mai multe abordÄƒri pe care o afacere le poate folosi pentru a obÈ›ine rezultatele dorite de la un LLM. PoÈ›i selecta diferite tipuri de modele cu grade diferite de antrenament atunci cÃ¢nd implementezi un LLM Ã®n producÈ›ie, cu niveluri variate de complexitate, cost È™i calitate. IatÄƒ cÃ¢teva abordÄƒri diferite:

- **Prompt engineering cu context**. Ideea este sÄƒ oferi suficient context atunci cÃ¢nd formulezi promptul, pentru a te asigura cÄƒ primeÈ™ti rÄƒspunsurile dorite.

- **Retrieval Augmented Generation, RAG**. Datele tale pot exista, de exemplu, Ã®ntr-o bazÄƒ de date sau un endpoint web; pentru a te asigura cÄƒ aceste date, sau un subset al lor, sunt incluse Ã®n momentul promptului, poÈ›i prelua datele relevante È™i sÄƒ le faci parte din promptul utilizatorului.

- **Model ajustat fin**. Aici, ai antrenat modelul suplimentar pe propriile date, ceea ce face ca modelul sÄƒ fie mai precis È™i mai receptiv la nevoile tale, dar poate fi costisitor.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.ro.png)

Sursa imaginii: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering cu Context

LLM-urile pre-antrenate funcÈ›ioneazÄƒ foarte bine pe sarcini generale de limbaj natural, chiar È™i atunci cÃ¢nd sunt apelate cu un prompt scurt, cum ar fi o propoziÈ›ie de completat sau o Ã®ntrebare â€“ aÈ™a-numita Ã®nvÄƒÈ›are â€zero-shotâ€.

TotuÈ™i, cu cÃ¢t utilizatorul poate formula mai bine Ã®ntrebarea, cu o cerere detaliatÄƒ È™i exemple â€“ Contextul â€“ cu atÃ¢t rÄƒspunsul va fi mai precis È™i mai apropiat de aÈ™teptÄƒrile utilizatorului. Ãn acest caz, vorbim despre Ã®nvÄƒÈ›are â€one-shotâ€ dacÄƒ promptul include un singur exemplu È™i â€few-shot learningâ€ dacÄƒ include mai multe exemple. Prompt engineering cu context este cea mai rentabilÄƒ metodÄƒ pentru a Ã®ncepe.

### Retrieval Augmented Generation (RAG)

LLM-urile au limitarea cÄƒ pot folosi doar datele pe care au fost antrenate pentru a genera un rÄƒspuns. Asta Ã®nseamnÄƒ cÄƒ nu È™tiu nimic despre evenimentele care au avut loc dupÄƒ procesul lor de antrenament È™i nu pot accesa informaÈ›ii nepublice (cum ar fi datele companiei).
Aceasta poate fi depÄƒÈ™itÄƒ prin RAG, o tehnicÄƒ care completeazÄƒ promptul cu date externe sub formÄƒ de fragmente de documente, È›inÃ¢nd cont de limitele lungimii promptului. Aceasta este susÈ›inutÄƒ de instrumente de baze de date vectoriale (precum [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) care recupereazÄƒ fragmente utile din surse de date predefinite È™i le adaugÄƒ Ã®n Contextul promptului.

AceastÄƒ tehnicÄƒ este foarte utilÄƒ atunci cÃ¢nd o afacere nu dispune de suficiente date, timp sau resurse pentru a ajusta fin un LLM, dar doreÈ™te totuÈ™i sÄƒ Ã®mbunÄƒtÄƒÈ›eascÄƒ performanÈ›a pe o sarcinÄƒ specificÄƒ È™i sÄƒ reducÄƒ riscurile de fabricare a informaÈ›iilor, adicÄƒ mistificarea realitÄƒÈ›ii sau conÈ›inut dÄƒunÄƒtor.

### Model ajustat fin

Ajustarea finÄƒ este un proces care foloseÈ™te transferul de Ã®nvÄƒÈ›are pentru a â€adaptaâ€ modelul la o sarcinÄƒ specificÄƒ sau pentru a rezolva o problemÄƒ anume. Spre deosebire de few-shot learning È™i RAG, rezultÄƒ Ã®ntr-un model nou, cu greutÄƒÈ›i È™i bias-uri actualizate. NecesitÄƒ un set de exemple de antrenament format dintr-un input (promptul) È™i output-ul asociat (completarea).
Aceasta ar fi abordarea preferatÄƒ dacÄƒ:

- **FoloseÈ™ti modele ajustate fin**. O afacere doreÈ™te sÄƒ foloseascÄƒ modele ajustate fin, mai puÈ›in capabile (cum ar fi modelele de embedding), Ã®n locul modelelor de Ã®naltÄƒ performanÈ›Äƒ, obÈ›inÃ¢nd astfel o soluÈ›ie mai eficientÄƒ din punct de vedere al costurilor È™i mai rapidÄƒ.

- **Èšine cont de latenÈ›Äƒ**. LatenÈ›a este importantÄƒ pentru un caz de utilizare specific, deci nu este posibil sÄƒ foloseÈ™ti prompturi foarte lungi sau numÄƒrul de exemple din care modelul trebuie sÄƒ Ã®nveÈ›e nu se potriveÈ™te cu limita de lungime a promptului.

- **MenÈ›inerea la zi**. O afacere dispune de multe date de Ã®naltÄƒ calitate È™i etichete de adevÄƒr fundamental È™i resursele necesare pentru a menÈ›ine aceste date actualizate Ã®n timp.

### Model antrenat

Antrenarea unui LLM de la zero este, fÄƒrÄƒ Ã®ndoialÄƒ, cea mai dificilÄƒ È™i complexÄƒ abordare, necesitÃ¢nd cantitÄƒÈ›i masive de date, resurse calificate È™i putere computaÈ›ionalÄƒ adecvatÄƒ. AceastÄƒ opÈ›iune ar trebui luatÄƒ Ã®n considerare doar Ã®n scenarii Ã®n care o afacere are un caz de utilizare specific domeniului È™i o cantitate mare de date centrate pe domeniu.

## Verificare cunoÈ™tinÈ›e

Care ar putea fi o abordare bunÄƒ pentru a Ã®mbunÄƒtÄƒÈ›i rezultatele completÄƒrilor LLM?

1. Prompt engineering cu context  
2. RAG  
3. Model ajustat fin

RÄƒspuns: 3, dacÄƒ ai timp, resurse È™i date de Ã®naltÄƒ calitate, ajustarea finÄƒ este opÈ›iunea mai bunÄƒ pentru a rÄƒmÃ¢ne la zi. TotuÈ™i, dacÄƒ vrei sÄƒ faci Ã®mbunÄƒtÄƒÈ›iri È™i nu dispui de timp, meritÄƒ sÄƒ iei Ã®n considerare mai Ã®ntÃ¢i RAG.

## ğŸš€ Provocare

CiteÈ™te mai multe despre cum poÈ›i [folosi RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pentru afacerea ta.

## Excelent, ContinuÄƒ sÄƒ Ã®nveÈ›i

DupÄƒ ce ai terminat aceastÄƒ lecÈ›ie, consultÄƒ colecÈ›ia noastrÄƒ [Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a-È›i continua dezvoltarea cunoÈ™tinÈ›elor despre AI generativ!

Mergi la LecÈ›ia 3, unde vom vedea cum sÄƒ [construim cu Generative AI Responsabil](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim pentru acurateÈ›e, vÄƒ rugÄƒm sÄƒ reÈ›ineÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa nativÄƒ trebuie considerat sursa autorizatÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de un specialist uman. Nu ne asumÄƒm rÄƒspunderea pentru eventualele neÃ®nÈ›elegeri sau interpretÄƒri greÈ™ite rezultate din utilizarea acestei traduceri.