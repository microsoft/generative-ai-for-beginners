<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T22:07:27+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "ro"
}
-->
# Explorarea È™i compararea diferitelor LLM-uri

[![Explorarea È™i compararea diferitelor LLM-uri](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.ro.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _FaceÈ›i clic pe imaginea de mai sus pentru a viziona videoclipul acestei lecÈ›ii_

Ãn lecÈ›ia anterioarÄƒ, am vÄƒzut cum InteligenÈ›a ArtificialÄƒ GenerativÄƒ schimbÄƒ peisajul tehnologic, cum funcÈ›ioneazÄƒ Modelele de Limbaj Extins (LLM-uri) È™i cum o afacere - precum startup-ul nostru - le poate aplica Ã®n cazurile sale de utilizare È™i poate creÈ™te! Ãn acest capitol, ne propunem sÄƒ comparÄƒm È™i sÄƒ contrastÄƒm diferite tipuri de modele de limbaj extins (LLM-uri) pentru a Ã®nÈ›elege avantajele È™i dezavantajele acestora.

UrmÄƒtorul pas Ã®n cÄƒlÄƒtoria startup-ului nostru este explorarea peisajului actual al LLM-urilor È™i Ã®nÈ›elegerea celor mai potrivite pentru cazul nostru de utilizare.

## Introducere

AceastÄƒ lecÈ›ie va acoperi:

- Diferite tipuri de LLM-uri din peisajul actual.
- Testarea, iterarea È™i compararea diferitelor modele pentru cazul dvs. de utilizare Ã®n Azure.
- Cum sÄƒ implementaÈ›i un LLM.

## Obiective de Ã®nvÄƒÈ›are

DupÄƒ finalizarea acestei lecÈ›ii, veÈ›i putea:

- SÄƒ selectaÈ›i modelul potrivit pentru cazul dvs. de utilizare.
- SÄƒ Ã®nÈ›elegeÈ›i cum sÄƒ testaÈ›i, sÄƒ iteraÈ›i È™i sÄƒ Ã®mbunÄƒtÄƒÈ›iÈ›i performanÈ›a modelului dvs.
- SÄƒ È™tiÈ›i cum implementeazÄƒ companiile modelele.

## ÃnÈ›elegerea diferitelor tipuri de LLM-uri

LLM-urile pot avea multiple categorii bazate pe arhitectura lor, datele de antrenament È™i cazul de utilizare. ÃnÈ›elegerea acestor diferenÈ›e va ajuta startup-ul nostru sÄƒ selecteze modelul potrivit pentru scenariu È™i sÄƒ Ã®nÈ›eleagÄƒ cum sÄƒ testeze, sÄƒ itereze È™i sÄƒ Ã®mbunÄƒtÄƒÈ›eascÄƒ performanÈ›a.

ExistÄƒ multe tipuri diferite de modele LLM, iar alegerea modelului depinde de scopul utilizÄƒrii, de datele disponibile, de bugetul alocat È™i de alÈ›i factori.

Ãn funcÈ›ie de scopul utilizÄƒrii modelelor pentru generarea de text, audio, video, imagini È™i aÈ™a mai departe, s-ar putea sÄƒ optaÈ›i pentru un alt tip de model.

- **RecunoaÈ™terea audio È™i a vorbirii**. Pentru acest scop, modelele de tip Whisper sunt o alegere excelentÄƒ, fiind modele generaliste destinate recunoaÈ™terii vocale. Acestea sunt antrenate pe diverse tipuri de audio È™i pot efectua recunoaÈ™tere vocalÄƒ multilingvÄƒ. AflaÈ›i mai multe despre [modelele de tip Whisper aici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generarea de imagini**. Pentru generarea de imagini, DALL-E È™i Midjourney sunt douÄƒ alegeri bine cunoscute. DALL-E este oferit de Azure OpenAI. [CitiÈ›i mai multe despre DALL-E aici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) È™i, de asemenea, Ã®n Capitolul 9 al acestui curriculum.

- **Generarea de text**. Majoritatea modelelor sunt antrenate pentru generarea de text È™i aveÈ›i o varietate mare de opÈ›iuni, de la GPT-3.5 la GPT-4. Acestea au costuri diferite, GPT-4 fiind cel mai scump. MeritÄƒ sÄƒ exploraÈ›i [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pentru a evalua care modele se potrivesc cel mai bine nevoilor dvs. Ã®n termeni de capacitate È™i cost.

- **Multi-modalitate**. DacÄƒ doriÈ›i sÄƒ gestionaÈ›i mai multe tipuri de date Ã®n intrare È™i ieÈ™ire, s-ar putea sÄƒ doriÈ›i sÄƒ analizaÈ›i modele precum [gpt-4 turbo cu viziune sau gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - cele mai recente versiuni ale modelelor OpenAI - care sunt capabile sÄƒ combine procesarea limbajului natural cu Ã®nÈ›elegerea vizualÄƒ, permiÈ›Ã¢nd interacÈ›iuni prin interfeÈ›e multi-modale.

Selectarea unui model Ã®nseamnÄƒ obÈ›inerea unor capabilitÄƒÈ›i de bazÄƒ, care s-ar putea sÄƒ nu fie suficiente. Adesea, aveÈ›i date specifice companiei pe care trebuie sÄƒ le comunicaÈ›i cumva LLM-ului. ExistÄƒ cÃ¢teva opÈ›iuni diferite pentru a aborda acest aspect, mai multe despre acest subiect Ã®n secÈ›iunile urmÄƒtoare.

### Modele Fundamentale versus LLM-uri

Termenul Model Fundamental a fost [inventat de cercetÄƒtorii de la Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) È™i definit ca un model AI care respectÄƒ anumite criterii, cum ar fi:

- **Sunt antrenate folosind Ã®nvÄƒÈ›area nesupravegheatÄƒ sau Ã®nvÄƒÈ›area auto-supervizatÄƒ**, ceea ce Ã®nseamnÄƒ cÄƒ sunt antrenate pe date multimodale neetichetate È™i nu necesitÄƒ adnotÄƒri sau etichetÄƒri umane ale datelor pentru procesul lor de antrenament.
- **Sunt modele foarte mari**, bazate pe reÈ›ele neuronale foarte profunde, antrenate pe miliarde de parametri.
- **Sunt de obicei destinate sÄƒ serveascÄƒ drept â€fundamentâ€ pentru alte modele**, ceea ce Ã®nseamnÄƒ cÄƒ pot fi utilizate ca punct de plecare pentru construirea altor modele, lucru care se poate realiza prin ajustare finÄƒ.

![Modele Fundamentale versus LLM-uri](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.ro.png)

Sursa imaginii: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pentru a clarifica È™i mai mult aceastÄƒ distincÈ›ie, sÄƒ luÄƒm ChatGPT ca exemplu. Pentru a construi prima versiune a ChatGPT, un model numit GPT-3.5 a servit drept model fundamental. Aceasta Ã®nseamnÄƒ cÄƒ OpenAI a utilizat unele date specifice pentru chat pentru a crea o versiune ajustatÄƒ a GPT-3.5, specializatÄƒ Ã®n performanÈ›e bune Ã®n scenarii conversaÈ›ionale, cum ar fi chatbot-urile.

![Model Fundamental](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.ro.png)

Sursa imaginii: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modele Open Source versus Proprietare

O altÄƒ modalitate de a categoriza LLM-urile este dacÄƒ sunt open source sau proprietare.

Modelele open source sunt modele care sunt puse la dispoziÈ›ia publicului È™i pot fi utilizate de oricine. Acestea sunt adesea oferite de compania care le-a creat sau de comunitatea de cercetare. Aceste modele pot fi inspectate, modificate È™i personalizate pentru diverse cazuri de utilizare ale LLM-urilor. Cu toate acestea, ele nu sunt Ã®ntotdeauna optimizate pentru utilizarea Ã®n producÈ›ie È™i s-ar putea sÄƒ nu fie la fel de performante ca modelele proprietare. Ãn plus, finanÈ›area pentru modelele open source poate fi limitatÄƒ, iar acestea s-ar putea sÄƒ nu fie Ã®ntreÈ›inute pe termen lung sau sÄƒ nu fie actualizate cu cele mai recente cercetÄƒri. Exemple de modele open source populare includ [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) È™i [LLaMA](https://llama.meta.com).

Modelele proprietare sunt modele deÈ›inute de o companie È™i nu sunt puse la dispoziÈ›ia publicului. Aceste modele sunt adesea optimizate pentru utilizarea Ã®n producÈ›ie. Cu toate acestea, ele nu pot fi inspectate, modificate sau personalizate pentru diferite cazuri de utilizare. Ãn plus, ele nu sunt Ã®ntotdeauna disponibile gratuit È™i pot necesita un abonament sau o platÄƒ pentru utilizare. De asemenea, utilizatorii nu au control asupra datelor utilizate pentru antrenarea modelului, ceea ce Ã®nseamnÄƒ cÄƒ trebuie sÄƒ aibÄƒ Ã®ncredere Ã®n deÈ›inÄƒtorul modelului pentru a asigura respectarea confidenÈ›ialitÄƒÈ›ii datelor È™i utilizarea responsabilÄƒ a AI. Exemple de modele proprietare populare includ [Modelele OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) sau [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Ãncorporare versus Generare de imagini versus Generare de text È™i cod

LLM-urile pot fi, de asemenea, categorisite Ã®n funcÈ›ie de tipul de ieÈ™ire pe care Ã®l genereazÄƒ.

Modelele de Ã®ncorporare sunt modele care pot converti textul Ã®ntr-o formÄƒ numericÄƒ, numitÄƒ Ã®ncorporare, care reprezintÄƒ o reprezentare numericÄƒ a textului de intrare. ÃncorporÄƒrile faciliteazÄƒ Ã®nÈ›elegerea relaÈ›iilor dintre cuvinte sau propoziÈ›ii de cÄƒtre maÈ™ini È™i pot fi utilizate ca intrÄƒri pentru alte modele, cum ar fi modelele de clasificare sau de grupare care au performanÈ›e mai bune pe date numerice. Modelele de Ã®ncorporare sunt adesea utilizate pentru Ã®nvÄƒÈ›area transferului, unde un model este construit pentru o sarcinÄƒ surogat pentru care existÄƒ o abundenÈ›Äƒ de date, iar apoi greutÄƒÈ›ile modelului (Ã®ncorporÄƒrile) sunt reutilizate pentru alte sarcini ulterioare. Un exemplu din aceastÄƒ categorie este [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Ãncorporare](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.ro.png)

Modelele de generare de imagini sunt modele care genereazÄƒ imagini. Aceste modele sunt adesea utilizate pentru editarea imaginilor, sinteza imaginilor È™i traducerea imaginilor. Modelele de generare de imagini sunt adesea antrenate pe seturi mari de date de imagini, cum ar fi [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), È™i pot fi utilizate pentru a genera imagini noi sau pentru a edita imagini existente cu tehnici de inpainting, super-rezoluÈ›ie È™i colorizare. Exemple includ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) È™i [Modelele Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generare de imagini](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.ro.png)

Modelele de generare de text È™i cod sunt modele care genereazÄƒ text sau cod. Aceste modele sunt adesea utilizate pentru sumarizarea textului, traducere È™i rÄƒspuns la Ã®ntrebÄƒri. Modelele de generare de text sunt adesea antrenate pe seturi mari de date de text, cum ar fi [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), È™i pot fi utilizate pentru a genera text nou sau pentru a rÄƒspunde la Ã®ntrebÄƒri. Modelele de generare de cod, precum [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sunt adesea antrenate pe seturi mari de date de cod, cum ar fi GitHub, È™i pot fi utilizate pentru a genera cod nou sau pentru a remedia erori Ã®n codul existent.

![Generare de text È™i cod](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.ro.png)

### Encoder-Decoder versus doar Decoder

Pentru a discuta despre diferitele tipuri de arhitecturi ale LLM-urilor, sÄƒ folosim o analogie.

ImaginaÈ›i-vÄƒ cÄƒ managerul dvs. v-a dat sarcina de a scrie un test pentru studenÈ›i. AveÈ›i doi colegi; unul se ocupÄƒ de crearea conÈ›inutului, iar celÄƒlalt de revizuirea acestuia.

Creatorul de conÈ›inut este ca un model doar Decoder, poate privi subiectul È™i ceea ce aÈ›i scris deja È™i apoi poate scrie un curs pe baza acestuia. Este foarte bun la scrierea de conÈ›inut captivant È™i informativ, dar nu este foarte bun la Ã®nÈ›elegerea subiectului È™i a obiectivelor de Ã®nvÄƒÈ›are. Unele exemple de modele Decoder sunt modelele din familia GPT, cum ar fi GPT-3.

Recenzorul este ca un model doar Encoder, analizeazÄƒ cursul scris È™i rÄƒspunsurile, observÃ¢nd relaÈ›ia dintre ele È™i Ã®nÈ›elegÃ¢nd contextul, dar nu este bun la generarea de conÈ›inut. Un exemplu de model doar Encoder ar fi BERT.

ImaginaÈ›i-vÄƒ cÄƒ am putea avea pe cineva care sÄƒ poatÄƒ crea È™i revizui testul, acesta este un model Encoder-Decoder. Unele exemple ar fi BART È™i T5.

### Serviciu versus Model

Acum, sÄƒ discutÄƒm despre diferenÈ›a dintre un serviciu È™i un model. Un serviciu este un produs oferit de un furnizor de servicii cloud È™i este adesea o combinaÈ›ie de modele, date È™i alte componente. Un model este componenta de bazÄƒ a unui serviciu È™i este adesea un model fundamental, cum ar fi un LLM.

Serviciile sunt adesea optimizate pentru utilizarea Ã®n producÈ›ie È™i sunt adesea mai uÈ™or de utilizat decÃ¢t modelele, printr-o interfaÈ›Äƒ graficÄƒ. Cu toate acestea, serviciile nu sunt Ã®ntotdeauna disponibile gratuit È™i pot necesita un abonament sau o platÄƒ pentru utilizare, Ã®n schimbul utilizÄƒrii echipamentelor È™i resurselor deÈ›inÄƒtorului serviciului, optimizÃ¢nd cheltuielile È™i scalÃ¢nd uÈ™or. Un exemplu de serviciu este [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), care oferÄƒ un plan de tarifare pay-as-you-go, ceea ce Ã®nseamnÄƒ cÄƒ utilizatorii sunt taxaÈ›i proporÈ›ional cu cÃ¢t utilizeazÄƒ serviciul. De asemenea, Azure OpenAI Service oferÄƒ securitate la nivel de Ã®ntreprindere È™i un cadru de AI responsabil pe lÃ¢ngÄƒ capabilitÄƒÈ›ile modelelor.

Modelele sunt doar ReÈ›elele Neuronale, cu parametrii, greutÄƒÈ›ile È™i altele. PermiÈ›Ã¢nd companiilor sÄƒ le ruleze local, totuÈ™i, ar fi nevoie sÄƒ achiziÈ›ioneze echipamente, sÄƒ construiascÄƒ o structurÄƒ pentru scalare È™i sÄƒ cumpere o licenÈ›Äƒ sau sÄƒ utilizeze un model open source. Un model precum LLaMA este disponibil pentru utilizare, necesitÃ¢nd putere computaÈ›ionalÄƒ pentru a rula modelul.

## Cum sÄƒ testaÈ›i È™i sÄƒ iteraÈ›i cu diferite modele pentru a Ã®nÈ›elege performanÈ›a pe Azure

OdatÄƒ ce echipa noastrÄƒ a explorat peisajul actual al LLM-urilor È™i a identificat cÃ¢È›iva candidaÈ›i buni pentru scenariile lor, urmÄƒtorul pas este testarea acestora pe datele È™i sarcinile lor de lucru. Acesta este un proces iterativ, realizat prin experimente È™i mÄƒsurÄƒtori.
Majoritatea modelelor menÈ›ionate Ã®n paragrafele anterioare (modelele OpenAI, modele open source precum Llama2 È™i transformatoarele Hugging Face) sunt disponibile Ã®n [Catalogul de modele](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) din [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) este o platformÄƒ Cloud conceputÄƒ pentru dezvoltatori, care permite construirea aplicaÈ›iilor de AI generativÄƒ È™i gestionarea Ã®ntregului ciclu de dezvoltare - de la experimentare la evaluare - prin combinarea tuturor serviciilor Azure AI Ã®ntr-un singur hub cu o interfaÈ›Äƒ graficÄƒ uÈ™or de utilizat. Catalogul de modele din Azure AI Studio permite utilizatorului sÄƒ:

- GÄƒseascÄƒ modelul de bazÄƒ dorit Ã®n catalog - fie proprietar, fie open source, filtrÃ¢nd dupÄƒ sarcinÄƒ, licenÈ›Äƒ sau nume. Pentru a Ã®mbunÄƒtÄƒÈ›i cÄƒutarea, modelele sunt organizate Ã®n colecÈ›ii, precum colecÈ›ia Azure OpenAI, colecÈ›ia Hugging Face È™i altele.

![Catalog de modele](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.ro.png)

- RevizuiascÄƒ fiÈ™a modelului, inclusiv o descriere detaliatÄƒ a utilizÄƒrii intenÈ›ionate È™i a datelor de antrenament, exemple de cod È™i rezultate ale evaluÄƒrii din biblioteca internÄƒ de evaluÄƒri.

![FiÈ™a modelului](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.ro.png)

- Compare benchmark-uri Ã®ntre modele È™i seturi de date disponibile Ã®n industrie pentru a evalua care se potriveÈ™te cel mai bine scenariului de afaceri, prin panoul [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmark-uri modele](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.ro.png)

- Ajusteze modelul pe baza datelor de antrenament personalizate pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului Ã®ntr-o sarcinÄƒ specificÄƒ, utilizÃ¢nd capacitÄƒÈ›ile de experimentare È™i urmÄƒrire ale Azure AI Studio.

![Ajustarea modelului](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.ro.png)

- DesfÄƒÈ™oare modelul pre-antrenat original sau versiunea ajustatÄƒ pentru inferenÈ›Äƒ Ã®n timp real - calcul gestionat - sau endpoint API fÄƒrÄƒ server - [platÄƒ pe mÄƒsurÄƒ ce utilizezi](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - pentru a permite aplicaÈ›iilor sÄƒ Ã®l consume.

![DesfÄƒÈ™urarea modelului](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.ro.png)

> [!NOTE]
> Nu toate modelele din catalog sunt disponibile Ã®n prezent pentru ajustare È™i/sau desfÄƒÈ™urare cu platÄƒ pe mÄƒsurÄƒ ce utilizezi. VerificaÈ›i fiÈ™a modelului pentru detalii despre capacitÄƒÈ›ile È™i limitÄƒrile modelului.

## ÃmbunÄƒtÄƒÈ›irea rezultatelor LLM

Am explorat cu echipa noastrÄƒ de startup diferite tipuri de LLM-uri È™i o platformÄƒ Cloud (Azure Machine Learning) care ne permite sÄƒ comparÄƒm diferite modele, sÄƒ le evaluÄƒm pe baza datelor de testare, sÄƒ Ã®mbunÄƒtÄƒÈ›im performanÈ›a È™i sÄƒ le desfÄƒÈ™urÄƒm pe endpoint-uri de inferenÈ›Äƒ.

Dar cÃ¢nd ar trebui sÄƒ ia Ã®n considerare ajustarea unui model Ã®n loc sÄƒ utilizeze unul pre-antrenat? ExistÄƒ alte abordÄƒri pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului pe sarcini specifice?

ExistÄƒ mai multe abordÄƒri pe care o afacere le poate utiliza pentru a obÈ›ine rezultatele dorite de la un LLM. PuteÈ›i selecta diferite tipuri de modele cu diferite grade de antrenament atunci cÃ¢nd desfÄƒÈ™uraÈ›i un LLM Ã®n producÈ›ie, cu niveluri diferite de complexitate, cost È™i calitate. IatÄƒ cÃ¢teva abordÄƒri diferite:

- **Ingineria prompturilor cu context**. Ideea este sÄƒ oferiÈ›i suficient context atunci cÃ¢nd formulaÈ›i promptul pentru a vÄƒ asigura cÄƒ obÈ›ineÈ›i rÄƒspunsurile de care aveÈ›i nevoie.

- **Generare augmentatÄƒ prin recuperare, RAG**. Datele dvs. pot exista, de exemplu, Ã®ntr-o bazÄƒ de date sau pe un endpoint web. Pentru a vÄƒ asigura cÄƒ aceste date sau un subset al lor sunt incluse Ã®n momentul formulÄƒrii promptului, puteÈ›i prelua datele relevante È™i sÄƒ le includeÈ›i Ã®n promptul utilizatorului.

- **Model ajustat**. Aici, modelul este antrenat suplimentar pe datele proprii, ceea ce duce la un model mai exact È™i mai receptiv la nevoile dvs., dar poate fi costisitor.

![DesfÄƒÈ™urarea LLM-urilor](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.ro.png)

Sursa imaginii: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ingineria prompturilor cu context

LLM-urile pre-antrenate funcÈ›ioneazÄƒ foarte bine pe sarcini generale de procesare a limbajului natural, chiar È™i atunci cÃ¢nd sunt apelate cu un prompt scurt, cum ar fi o propoziÈ›ie de completat sau o Ã®ntrebare â€“ aÈ™a-numita Ã®nvÄƒÈ›are â€zero-shotâ€.

Cu toate acestea, cu cÃ¢t utilizatorul Ã®È™i poate Ã®ncadra mai bine Ã®ntrebarea, cu o cerere detaliatÄƒ È™i exemple â€“ Contextul â€“ cu atÃ¢t rÄƒspunsul va fi mai precis È™i mai apropiat de aÈ™teptÄƒrile utilizatorului. Ãn acest caz, vorbim despre Ã®nvÄƒÈ›are â€one-shotâ€ dacÄƒ promptul include doar un exemplu È™i â€few-shot learningâ€ dacÄƒ include mai multe exemple. Ingineria prompturilor cu context este cea mai rentabilÄƒ abordare pentru a Ã®ncepe.

### Generare augmentatÄƒ prin recuperare (RAG)

LLM-urile au limitarea cÄƒ pot utiliza doar datele care au fost folosite Ã®n timpul antrenamentului lor pentru a genera un rÄƒspuns. Aceasta Ã®nseamnÄƒ cÄƒ nu È™tiu nimic despre faptele care au avut loc dupÄƒ procesul lor de antrenament È™i nu pot accesa informaÈ›ii nepublice (cum ar fi datele companiei). 
Acest lucru poate fi depÄƒÈ™it prin RAG, o tehnicÄƒ care completeazÄƒ promptul cu date externe sub formÄƒ de fragmente de documente, luÃ¢nd Ã®n considerare limitele de lungime ale promptului. Aceasta este susÈ›inutÄƒ de instrumente de baze de date vectoriale (cum ar fi [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) care recupereazÄƒ fragmentele utile din surse de date predefinite È™i le adaugÄƒ la Contextul promptului.

AceastÄƒ tehnicÄƒ este foarte utilÄƒ atunci cÃ¢nd o afacere nu are suficiente date, suficient timp sau resurse pentru a ajusta un LLM, dar doreÈ™te totuÈ™i sÄƒ Ã®mbunÄƒtÄƒÈ›eascÄƒ performanÈ›a pe o sarcinÄƒ specificÄƒ È™i sÄƒ reducÄƒ riscurile de fabricare, adicÄƒ mistificarea realitÄƒÈ›ii sau conÈ›inutul dÄƒunÄƒtor.

### Model ajustat

Ajustarea este un proces care utilizeazÄƒ Ã®nvÄƒÈ›area transferului pentru a â€adaptaâ€ modelul la o sarcinÄƒ ulterioarÄƒ sau pentru a rezolva o problemÄƒ specificÄƒ. Spre deosebire de Ã®nvÄƒÈ›area few-shot È™i RAG, rezultÄƒ Ã®ntr-un model nou generat, cu greutÄƒÈ›i È™i biasuri actualizate. Acesta necesitÄƒ un set de exemple de antrenament constÃ¢nd dintr-o singurÄƒ intrare (promptul) È™i ieÈ™irea asociatÄƒ (completarea).
Aceasta ar fi abordarea preferatÄƒ dacÄƒ:

- **Utilizarea modelelor ajustate**. O afacere ar dori sÄƒ utilizeze modele ajustate mai puÈ›in capabile (cum ar fi modelele de Ã®ncorporare) Ã®n locul modelelor de Ã®naltÄƒ performanÈ›Äƒ, rezultÃ¢nd o soluÈ›ie mai rentabilÄƒ È™i rapidÄƒ.

- **Luarea Ã®n considerare a latenÈ›ei**. LatenÈ›a este importantÄƒ pentru un caz de utilizare specific, astfel Ã®ncÃ¢t nu este posibil sÄƒ se utilizeze prompturi foarte lungi sau numÄƒrul de exemple care ar trebui Ã®nvÄƒÈ›ate de model nu se Ã®ncadreazÄƒ Ã®n limita de lungime a promptului.

- **MenÈ›inerea actualizÄƒrii**. O afacere are o mulÈ›ime de date de Ã®naltÄƒ calitate È™i etichete de adevÄƒr È™i resursele necesare pentru a menÈ›ine aceste date actualizate Ã®n timp.

### Model antrenat

Antrenarea unui LLM de la zero este, fÄƒrÄƒ Ã®ndoialÄƒ, cea mai dificilÄƒ È™i cea mai complexÄƒ abordare de adoptat, necesitÃ¢nd cantitÄƒÈ›i masive de date, resurse calificate È™i putere computaÈ›ionalÄƒ adecvatÄƒ. AceastÄƒ opÈ›iune ar trebui luatÄƒ Ã®n considerare doar Ã®ntr-un scenariu Ã®n care o afacere are un caz de utilizare specific domeniului È™i o cantitate mare de date centrate pe domeniu.

## Verificarea cunoÈ™tinÈ›elor

Care ar putea fi o abordare bunÄƒ pentru a Ã®mbunÄƒtÄƒÈ›i rezultatele de completare ale LLM?

1. Ingineria prompturilor cu context  
1. RAG  
1. Model ajustat  

R: 3, dacÄƒ aveÈ›i timp, resurse È™i date de Ã®naltÄƒ calitate, ajustarea este opÈ›iunea mai bunÄƒ pentru a rÄƒmÃ¢ne actualizat. TotuÈ™i, dacÄƒ doriÈ›i sÄƒ Ã®mbunÄƒtÄƒÈ›iÈ›i lucrurile È™i nu aveÈ›i timp, meritÄƒ sÄƒ luaÈ›i Ã®n considerare mai Ã®ntÃ¢i RAG.

## ğŸš€ Provocare

CitiÈ›i mai multe despre cum puteÈ›i [utiliza RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pentru afacerea dvs.

## FelicitÄƒri, ContinuaÈ›i sÄƒ Ã®nvÄƒÈ›aÈ›i

DupÄƒ ce aÈ›i finalizat aceastÄƒ lecÈ›ie, consultaÈ›i [colecÈ›ia noastrÄƒ de Ã®nvÄƒÈ›are AI generativÄƒ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a continua sÄƒ vÄƒ dezvoltaÈ›i cunoÈ™tinÈ›ele despre AI generativÄƒ!

AccesaÈ›i LecÈ›ia 3, unde vom analiza cum sÄƒ [construim cu AI generativÄƒ Ã®n mod responsabil](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Declinare de responsabilitate**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea profesionalÄƒ realizatÄƒ de oameni. Nu ne asumÄƒm responsabilitatea pentru neÃ®nÈ›elegerile sau interpretÄƒrile greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.