<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:22:39+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "ro"
}
-->
# Explorarea È™i compararea diferitelor LLM-uri

[![Explorarea È™i compararea diferitelor LLM-uri](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.ro.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Click pe imaginea de mai sus pentru a viziona videoclipul lecÈ›iei_

Cu lecÈ›ia anterioarÄƒ, am vÄƒzut cum InteligenÈ›a ArtificialÄƒ GenerativÄƒ schimbÄƒ peisajul tehnologic, cum funcÈ›ioneazÄƒ Modelele de Limbaj de Mari Dimensiuni (LLM-uri) È™i cum o afacere - precum startup-ul nostru - le poate aplica la cazurile lor de utilizare È™i poate creÈ™te! Ãn acest capitol, ne propunem sÄƒ comparÄƒm È™i sÄƒ contrastÄƒm diferite tipuri de modele de limbaj de mari dimensiuni (LLM-uri) pentru a Ã®nÈ›elege avantajele È™i dezavantajele acestora.

UrmÄƒtorul pas Ã®n cÄƒlÄƒtoria startup-ului nostru este explorarea peisajului actual al LLM-urilor È™i Ã®nÈ›elegerea care sunt potrivite pentru cazul nostru de utilizare.

## Introducere

AceastÄƒ lecÈ›ie va acoperi:

- Diferite tipuri de LLM-uri Ã®n peisajul actual.
- Testarea, iterarea È™i compararea diferitelor modele pentru cazul tÄƒu de utilizare Ã®n Azure.
- Cum sÄƒ implementezi un LLM.

## Obiective de ÃnvÄƒÈ›are

DupÄƒ finalizarea acestei lecÈ›ii, vei putea:

- Selecta modelul potrivit pentru cazul tÄƒu de utilizare.
- ÃnÈ›elege cum sÄƒ testezi, sÄƒ iterezi È™i sÄƒ Ã®mbunÄƒtÄƒÈ›eÈ™ti performanÈ›a modelului tÄƒu.
- È˜tii cum afacerile implementeazÄƒ modele.

## ÃnÈ›elegerea diferitelor tipuri de LLM-uri

LLM-urile pot avea multiple categorisiri bazate pe arhitectura lor, datele de antrenament È™i cazul de utilizare. ÃnÈ›elegerea acestor diferenÈ›e va ajuta startup-ul nostru sÄƒ selecteze modelul potrivit pentru scenariul nostru È™i sÄƒ Ã®nÈ›eleagÄƒ cum sÄƒ testeze, sÄƒ itereze È™i sÄƒ Ã®mbunÄƒtÄƒÈ›eascÄƒ performanÈ›a.

ExistÄƒ multe tipuri diferite de modele LLM, alegerea modelului depinde de ceea ce Ã®È›i propui sÄƒ foloseÈ™ti, datele tale, cÃ¢t eÈ™ti dispus sÄƒ plÄƒteÈ™ti È™i altele.

Ãn funcÈ›ie de dacÄƒ Ã®È›i propui sÄƒ foloseÈ™ti modelele pentru generarea de text, audio, video, imagini È™i aÈ™a mai departe, ai putea opta pentru un alt tip de model.

- **RecunoaÈ™terea audio È™i a vorbirii**. Pentru acest scop, modelele de tip Whisper sunt o alegere excelentÄƒ, deoarece sunt de uz general È™i vizeazÄƒ recunoaÈ™terea vorbirii. Este antrenat pe audio diversificat È™i poate efectua recunoaÈ™terea vorbirii multilingve. AflÄƒ mai multe despre [modelele de tip Whisper aici](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generarea de imagini**. Pentru generarea de imagini, DALL-E È™i Midjourney sunt douÄƒ alegeri foarte cunoscute. DALL-E este oferit de Azure OpenAI. [CiteÈ™te mai multe despre DALL-E aici](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) È™i, de asemenea, Ã®n capitolul 9 al acestui curriculum.

- **Generarea de text**. Majoritatea modelelor sunt antrenate pentru generarea de text È™i ai o mare varietate de alegeri de la GPT-3.5 la GPT-4. Ele vin la costuri diferite, cu GPT-4 fiind cel mai scump. MeritÄƒ sÄƒ explorezi [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) pentru a evalua care modele se potrivesc cel mai bine nevoilor tale Ã®n termeni de capacitate È™i cost.

- **Multi-modalitate**. DacÄƒ doreÈ™ti sÄƒ gestionezi mai multe tipuri de date Ã®n intrare È™i ieÈ™ire, ai putea dori sÄƒ explorezi modele precum [gpt-4 turbo cu viziune sau gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - cele mai recente versiuni ale modelelor OpenAI - care sunt capabile sÄƒ combine procesarea limbajului natural cu Ã®nÈ›elegerea vizualÄƒ, permiÈ›Ã¢nd interacÈ›iuni prin interfeÈ›e multi-modale.

Selectarea unui model Ã®nseamnÄƒ cÄƒ obÈ›ii unele capacitÄƒÈ›i de bazÄƒ, care s-ar putea sÄƒ nu fie suficiente Ã®nsÄƒ. Adesea ai date specifice companiei pe care trebuie cumva sÄƒ le comunici LLM-ului. ExistÄƒ cÃ¢teva opÈ›iuni diferite despre cum sÄƒ abordezi asta, mai multe despre asta Ã®n secÈ›iunile urmÄƒtoare.

### Modele de BazÄƒ versus LLM-uri

Termenul de Model de BazÄƒ a fost [inventat de cercetÄƒtorii de la Stanford](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) È™i definit ca un model AI care urmeazÄƒ anumite criterii, cum ar fi:

- **Sunt antrenate folosind Ã®nvÄƒÈ›area nesupravegheatÄƒ sau auto-supervizatÄƒ**, ceea ce Ã®nseamnÄƒ cÄƒ sunt antrenate pe date multi-modale fÄƒrÄƒ etichete È™i nu necesitÄƒ adnotÄƒri sau etichetÄƒri umane ale datelor pentru procesul lor de antrenament.
- **Sunt modele foarte mari**, bazate pe reÈ›ele neuronale foarte profunde antrenate pe miliarde de parametri.
- **Sunt Ã®n mod normal destinate sÄƒ serveascÄƒ drept â€bazÄƒâ€ pentru alte modele**, ceea ce Ã®nseamnÄƒ cÄƒ pot fi utilizate ca punct de plecare pentru alte modele care sÄƒ fie construite pe ele, ceea ce se poate face prin ajustare finÄƒ.

![Modele de BazÄƒ versus LLM-uri](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.ro.png)

Sursa imaginii: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pentru a clarifica È™i mai mult aceastÄƒ distincÈ›ie, sÄƒ luÄƒm ChatGPT ca exemplu. Pentru a construi prima versiune a ChatGPT, un model numit GPT-3.5 a servit drept model de bazÄƒ. Acest lucru Ã®nseamnÄƒ cÄƒ OpenAI a folosit niÈ™te date specifice de chat pentru a crea o versiune ajustatÄƒ a GPT-3.5 care era specializatÄƒ Ã®n performanÈ›e bune Ã®n scenarii conversaÈ›ionale, cum ar fi chatbots.

![Model de BazÄƒ](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.ro.png)

Sursa imaginii: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Modele Open Source versus Proprietare

O altÄƒ modalitate de a categorisi LLM-urile este dacÄƒ sunt open source sau proprietare.

Modelele open-source sunt modele care sunt disponibile publicului È™i pot fi utilizate de oricine. Ele sunt adesea puse la dispoziÈ›ie de compania care le-a creat sau de comunitatea de cercetare. Aceste modele pot fi inspectate, modificate È™i personalizate pentru diversele cazuri de utilizare Ã®n LLM-uri. Cu toate acestea, ele nu sunt Ã®ntotdeauna optimizate pentru utilizarea Ã®n producÈ›ie È™i pot sÄƒ nu fie la fel de performante ca modelele proprietare. Ãn plus, finanÈ›area pentru modelele open-source poate fi limitatÄƒ È™i ele pot sÄƒ nu fie menÈ›inute pe termen lung sau sÄƒ nu fie actualizate cu cele mai recente cercetÄƒri. Exemple de modele open-source populare includ [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) È™i [LLaMA](https://llama.meta.com).

Modelele proprietare sunt modele care sunt deÈ›inute de o companie È™i nu sunt disponibile publicului. Aceste modele sunt adesea optimizate pentru utilizarea Ã®n producÈ›ie. Cu toate acestea, ele nu sunt permise sÄƒ fie inspectate, modificate sau personalizate pentru diferite cazuri de utilizare. Ãn plus, ele nu sunt Ã®ntotdeauna disponibile gratuit È™i pot necesita un abonament sau o platÄƒ pentru a fi utilizate. De asemenea, utilizatorii nu au control asupra datelor care sunt folosite pentru antrenarea modelului, ceea ce Ã®nseamnÄƒ cÄƒ ar trebui sÄƒ Ã®ncredinÈ›eze proprietarului modelului asigurarea angajamentului faÈ›Äƒ de confidenÈ›ialitatea datelor È™i utilizarea responsabilÄƒ a AI. Exemple de modele proprietare populare includ [modelele OpenAI](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) sau [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Ãncapsulare versus Generarea de Imagini versus Generarea de Text È™i Cod

LLM-urile pot fi, de asemenea, categorisite Ã®n funcÈ›ie de output-ul pe care Ã®l genereazÄƒ.

ÃncapsulÄƒrile sunt un set de modele care pot transforma textul Ã®ntr-o formÄƒ numericÄƒ, numitÄƒ Ã®ncapsulare, care este o reprezentare numericÄƒ a textului de intrare. ÃncapsulÄƒrile faciliteazÄƒ Ã®nÈ›elegerea relaÈ›iilor dintre cuvinte sau propoziÈ›ii de cÄƒtre maÈ™ini È™i pot fi consumate ca intrÄƒri de cÄƒtre alte modele, cum ar fi modelele de clasificare sau modelele de clustering care au performanÈ›e mai bune pe date numerice. Modelele de Ã®ncapsulare sunt adesea utilizate pentru Ã®nvÄƒÈ›area transferului, unde un model este construit pentru o sarcinÄƒ surogat pentru care existÄƒ o abundenÈ›Äƒ de date, È™i apoi greutÄƒÈ›ile modelului (Ã®ncapsulÄƒrile) sunt reutilizate pentru alte sarcini ulterioare. Un exemplu din aceastÄƒ categorie este [Ã®ncapsulÄƒrile OpenAI](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Ãncapsulare](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.ro.png)

Modelele de generare de imagini sunt modele care genereazÄƒ imagini. Aceste modele sunt adesea utilizate pentru editarea imaginii, sinteza imaginii È™i traducerea imaginii. Modelele de generare de imagini sunt adesea antrenate pe seturi mari de date de imagini, cum ar fi [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), È™i pot fi utilizate pentru a genera imagini noi sau pentru a edita imagini existente cu tehnici de Ã®nlocuire a pÄƒrÈ›ilor lipsÄƒ, super-rezoluÈ›ie È™i colorizare. Exemple includ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) È™i [modelele Stable Diffusion](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generarea de imagini](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.ro.png)

Modelele de generare de text È™i cod sunt modele care genereazÄƒ text sau cod. Aceste modele sunt adesea utilizate pentru sumarizarea textului, traducere È™i rÄƒspuns la Ã®ntrebÄƒri. Modelele de generare de text sunt adesea antrenate pe seturi mari de date de text, cum ar fi [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), È™i pot fi utilizate pentru a genera text nou sau pentru a rÄƒspunde la Ã®ntrebÄƒri. Modelele de generare de cod, precum [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), sunt adesea antrenate pe seturi mari de date de cod, cum ar fi GitHub, È™i pot fi utilizate pentru a genera cod nou sau pentru a repara erori Ã®n codul existent.

![Generarea de text È™i cod](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.ro.png)

### Encoder-Decoder versus doar Decoder

Pentru a discuta despre diferitele tipuri de arhitecturi ale LLM-urilor, sÄƒ folosim o analogie.

ImagineazÄƒ-È›i cÄƒ managerul tÄƒu È›i-a dat o sarcinÄƒ de a scrie un quiz pentru studenÈ›i. Ai doi colegi; unul se ocupÄƒ de crearea conÈ›inutului È™i celÄƒlalt de revizuirea acestuia.

Creatorul de conÈ›inut este ca un model doar Decoder, el poate privi subiectul È™i vedea ce ai scris deja È™i apoi poate scrie un curs pe baza acestuia. Ei sunt foarte buni la scrierea de conÈ›inut captivant È™i informativ, dar nu sunt foarte buni la Ã®nÈ›elegerea subiectului È™i a obiectivelor de Ã®nvÄƒÈ›are. Unele exemple de modele Decoder sunt modelele din familia GPT, cum ar fi GPT-3.

Revizorul este ca un model doar Encoder, el priveÈ™te cursul scris È™i rÄƒspunsurile, observÃ¢nd relaÈ›ia dintre ele È™i Ã®nÈ›elegÃ¢nd contextul, dar nu este bun la generarea de conÈ›inut. Un exemplu de model doar Encoder ar fi BERT.

ImagineazÄƒ-È›i cÄƒ putem avea pe cineva care ar putea crea È™i revizui quiz-ul, acesta este un model Encoder-Decoder. Unele exemple ar fi BART È™i T5.

### Serviciu versus Model

Acum, sÄƒ discutÄƒm despre diferenÈ›a dintre un serviciu È™i un model. Un serviciu este un produs oferit de un Furnizor de Servicii Cloud È™i este adesea o combinaÈ›ie de modele, date È™i alte componente. Un model este componenta de bazÄƒ a unui serviciu È™i este adesea un model de bazÄƒ, cum ar fi un LLM.

Serviciile sunt adesea optimizate pentru utilizarea Ã®n producÈ›ie È™i sunt adesea mai uÈ™or de utilizat decÃ¢t modelele, printr-o interfaÈ›Äƒ graficÄƒ. Cu toate acestea, serviciile nu sunt Ã®ntotdeauna disponibile gratuit È™i pot necesita un abonament sau o platÄƒ pentru a fi utilizate, Ã®n schimbul utilizÄƒrii echipamentului È™i resurselor proprietarului serviciului, optimizÃ¢nd cheltuielile È™i scalÃ¢nd uÈ™or. Un exemplu de serviciu este [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), care oferÄƒ un plan de tarifare pay-as-you-go, ceea ce Ã®nseamnÄƒ cÄƒ utilizatorii sunt taxaÈ›i proporÈ›ional cu cÃ¢t utilizeazÄƒ serviciul. De asemenea, Azure OpenAI Service oferÄƒ securitate de nivel enterprise È™i un cadru AI responsabil pe lÃ¢ngÄƒ capacitÄƒÈ›ile modelelor.

Modelele sunt doar ReÈ›eaua NeuronalÄƒ, cu parametrii, greutÄƒÈ›ile È™i altele. PermiÈ›Ã¢nd companiilor sÄƒ ruleze local, totuÈ™i, ar trebui sÄƒ cumpere echipamente, sÄƒ construiascÄƒ o structurÄƒ pentru scalare È™i sÄƒ cumpere o licenÈ›Äƒ sau sÄƒ foloseascÄƒ un model open-source. Un model precum LLaMA este disponibil pentru a fi utilizat, necesitÃ¢nd putere de calcul pentru a rula modelul.

## Cum sÄƒ testezi È™i sÄƒ iterezi cu diferite modele pentru a Ã®nÈ›elege performanÈ›a pe Azure

OdatÄƒ ce echipa noastrÄƒ a explorat peisajul actual al LLM-urilor È™i a identificat cÃ¢È›iva candidaÈ›i buni pentru scenariile lor, urmÄƒtorul pas este testarea acestora pe datele lor È™i pe sarcina lor de lucru. Acesta este un proces iterativ, realizat prin experimente È™i mÄƒsurÄƒtori.
Majoritatea modelelor menÈ›ionate Ã®n paragrafele anterioare (modele OpenAI, modele open-source precum Llama2 È™i transformatori Hugging Face) sunt disponibile Ã®n [Catalogul de Modele](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) Ã®n [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) este o PlatformÄƒ Cloud proiectatÄƒ pentru dezvoltatori pentru a construi aplicaÈ›ii de inteligenÈ›Äƒ artificialÄƒ generativÄƒ È™i pentru a gestiona Ã®ntregul ciclu de dezvoltare - de la experimentare la evaluare - combinÃ¢nd toate serviciile AI Azure Ã®ntr-un singur hub cu o interfaÈ›Äƒ graficÄƒ uÈ™or de utilizat. Catalogul de Modele Ã®n Azure AI Studio permite utilizatorului sÄƒ:

- GÄƒseascÄƒ Modelul de BazÄƒ de interes Ã®n catalog - fie proprietar sau open-source, filtrÃ¢nd dupÄƒ sarcinÄƒ, licenÈ›Äƒ sau nume. Pentru a Ã®mbunÄƒtÄƒÈ›i cÄƒutarea, modelele sunt organizate Ã®n colecÈ›ii, cum ar fi colecÈ›ia Azure OpenAI, colecÈ›ia Hugging Face È™i altele.

![Catalogul de Modele](../../../translated_images/AzureAIStudioModelCatalog.e34ac207ac348d31e74246c4f91d10086444783b72bbee3658e0453918aa5d22.ro.png)

- RevizuiascÄƒ cardul modelului, inclusiv o descriere detaliatÄƒ a utilizÄƒrii intenÈ›ionate È™i a datelor de antrenament
- ComparÄƒ benchmark-urile Ã®ntre modele È™i seturi de date disponibile Ã®n industrie pentru a evalua care dintre ele se potriveÈ™te scenariului de afaceri, prin panoul [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.ro.png)

- AjusteazÄƒ modelul pe date de antrenament personalizate pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului Ã®ntr-o sarcinÄƒ specificÄƒ, folosind capacitÄƒÈ›ile de experimentare È™i urmÄƒrire ale Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.ro.png)

- DesfÄƒÈ™oarÄƒ modelul original pre-antrenat sau versiunea ajustatÄƒ la o inferenÈ›Äƒ Ã®n timp real la distanÈ›Äƒ - computaÈ›ie gestionatÄƒ - sau la un punct de finalizare API fÄƒrÄƒ server - [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - pentru a permite aplicaÈ›iilor sÄƒ Ã®l consume.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.ro.png)

> [!NOTE]
> Nu toate modelele din catalog sunt disponibile Ã®n prezent pentru ajustare È™i/sau desfÄƒÈ™urare pay-as-you-go. VerificÄƒ cardul modelului pentru detalii despre capacitÄƒÈ›ile È™i limitÄƒrile modelului.

## ÃmbunÄƒtÄƒÈ›irea rezultatelor LLM

Am explorat cu echipa noastrÄƒ de startup diferite tipuri de LLM-uri È™i o PlatformÄƒ Cloud (Azure Machine Learning) care ne permite sÄƒ comparÄƒm diferite modele, sÄƒ le evaluÄƒm pe date de testare, sÄƒ Ã®mbunÄƒtÄƒÈ›im performanÈ›a È™i sÄƒ le desfÄƒÈ™urÄƒm pe puncte de inferenÈ›Äƒ.

Dar cÃ¢nd ar trebui sÄƒ considere ajustarea unui model Ã®n loc sÄƒ foloseascÄƒ unul pre-antrenat? ExistÄƒ alte abordÄƒri pentru a Ã®mbunÄƒtÄƒÈ›i performanÈ›a modelului Ã®n sarcini specifice?

ExistÄƒ mai multe abordÄƒri pe care o afacere le poate folosi pentru a obÈ›ine rezultatele dorite de la un LLM. PoÈ›i selecta diferite tipuri de modele cu diferite grade de antrenament atunci cÃ¢nd desfÄƒÈ™ori un LLM Ã®n producÈ›ie, cu diferite niveluri de complexitate, cost È™i calitate. IatÄƒ cÃ¢teva abordÄƒri diferite:

- **Ingineria prompturilor cu context**. Ideea este de a oferi suficient context atunci cÃ¢nd faci un prompt pentru a te asigura cÄƒ obÈ›ii rÄƒspunsurile de care ai nevoie.

- **Generarea AugmentatÄƒ prin RegÄƒsire, RAG**. Datele tale ar putea exista Ã®ntr-o bazÄƒ de date sau punct de finalizare web, de exemplu, pentru a te asigura cÄƒ aceste date, sau un subset al lor, sunt incluse la momentul promptului, poÈ›i prelua datele relevante È™i le poÈ›i face parte din promptul utilizatorului.

- **Model ajustat**. Aici, ai antrenat modelul mai departe pe datele tale, ceea ce a dus la un model mai exact È™i mai receptiv la nevoile tale, dar ar putea fi costisitor.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.ro.png)

Sursa imaginii: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Ingineria Prompturilor cu Context

LLM-urile pre-antrenate funcÈ›ioneazÄƒ foarte bine pe sarcini generalizate de limbaj natural, chiar È™i atunci cÃ¢nd sunt apelate cu un prompt scurt, cum ar fi o propoziÈ›ie de completat sau o Ã®ntrebare â€“ aÈ™a-numita Ã®nvÄƒÈ›are â€zero-shotâ€.

Cu toate acestea, cu cÃ¢t utilizatorul poate Ã®ncadra mai mult interogarea lor, cu o cerere detaliatÄƒ È™i exemple â€“ Contextul â€“ cu atÃ¢t mai precis È™i mai apropiat de aÈ™teptÄƒrile utilizatorului va fi rÄƒspunsul. Ãn acest caz, vorbim despre Ã®nvÄƒÈ›are â€one-shotâ€ dacÄƒ promptul include doar un exemplu È™i â€few-shot learningâ€ dacÄƒ include mai multe exemple.
Ingineria prompturilor cu context este cea mai eficientÄƒ abordare pentru a Ã®ncepe.

### Generarea AugmentatÄƒ prin RegÄƒsire (RAG)

LLM-urile au limitarea cÄƒ pot folosi doar datele care au fost utilizate Ã®n timpul antrenamentului lor pentru a genera un rÄƒspuns. Aceasta Ã®nseamnÄƒ cÄƒ nu È™tiu nimic despre faptele care s-au Ã®ntÃ¢mplat dupÄƒ procesul lor de antrenament È™i nu pot accesa informaÈ›ii nepublice (cum ar fi datele companiei).
Aceasta poate fi depÄƒÈ™itÄƒ prin RAG, o tehnicÄƒ care Ã®mbogÄƒÈ›eÈ™te promptul cu date externe sub formÄƒ de fragmente de documente, È›inÃ¢nd cont de limitele lungimii promptului. Aceasta este susÈ›inutÄƒ de instrumente de baze de date vectoriale (cum ar fi [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) care preiau fragmentele utile din surse de date variate predefinite È™i le adaugÄƒ la Contextul promptului.

AceastÄƒ tehnicÄƒ este foarte utilÄƒ atunci cÃ¢nd o afacere nu are suficiente date, suficient timp sau resurse pentru a ajusta un LLM, dar totuÈ™i doreÈ™te sÄƒ Ã®mbunÄƒtÄƒÈ›eascÄƒ performanÈ›a pe o sarcinÄƒ specificÄƒ È™i sÄƒ reducÄƒ riscurile de fabricaÈ›ii, adicÄƒ mistificarea realitÄƒÈ›ii sau conÈ›inut dÄƒunÄƒtor.

### Model ajustat

Ajustarea este un proces care foloseÈ™te Ã®nvÄƒÈ›area transferului pentru a â€adaptaâ€ modelul la o sarcinÄƒ ulterioarÄƒ sau pentru a rezolva o problemÄƒ specificÄƒ. Diferit de Ã®nvÄƒÈ›area few-shot È™i RAG, rezultÄƒ Ã®ntr-un model nou generat, cu greutÄƒÈ›i È™i biasuri actualizate. NecesitÄƒ un set de exemple de antrenament constÃ¢nd dintr-o singurÄƒ intrare (promptul) È™i ieÈ™irea asociatÄƒ (completarea).
Aceasta ar fi abordarea preferatÄƒ dacÄƒ:

- **Folosirea modelelor ajustate**. O afacere ar dori sÄƒ foloseascÄƒ modele ajustate mai puÈ›in capabile (cum ar fi modelele de embedding) mai degrabÄƒ decÃ¢t modele de Ã®naltÄƒ performanÈ›Äƒ, rezultÃ¢nd Ã®ntr-o soluÈ›ie mai rentabilÄƒ È™i rapidÄƒ.

- **Considerarea latenÈ›ei**. LatenÈ›a este importantÄƒ pentru un caz de utilizare specific, deci nu este posibil sÄƒ se foloseascÄƒ prompturi foarte lungi sau numÄƒrul de exemple care ar trebui Ã®nvÄƒÈ›ate de model nu se potriveÈ™te cu limita de lungime a promptului.

- **MenÈ›inerea actualizatÄƒ**. O afacere are multe date de Ã®naltÄƒ calitate È™i etichete de adevÄƒr È™i resursele necesare pentru a menÈ›ine aceste date actualizate Ã®n timp.

### Model antrenat

Antrenarea unui LLM de la zero este fÄƒrÄƒ Ã®ndoialÄƒ cea mai dificilÄƒ È™i cea mai complexÄƒ abordare de adoptat, necesitÃ¢nd cantitÄƒÈ›i masive de date, resurse calificate È™i putere computaÈ›ionalÄƒ adecvatÄƒ. AceastÄƒ opÈ›iune ar trebui consideratÄƒ doar Ã®ntr-un scenariu Ã®n care o afacere are un caz de utilizare specific domeniului È™i o cantitate mare de date centrate pe domeniu.

## Verificarea cunoÈ™tinÈ›elor

Ce ar putea fi o abordare bunÄƒ pentru a Ã®mbunÄƒtÄƒÈ›i rezultatele de completare ale LLM?

1. Ingineria prompturilor cu context
1. RAG
1. Model ajustat

A:3, dacÄƒ ai timp È™i resurse È™i date de Ã®naltÄƒ calitate, ajustarea este opÈ›iunea mai bunÄƒ pentru a rÄƒmÃ¢ne actualizat. TotuÈ™i, dacÄƒ te uiÈ›i la Ã®mbunÄƒtÄƒÈ›irea lucrurilor È™i Ã®È›i lipseÈ™te timpul, meritÄƒ sÄƒ consideri RAG mai Ã®ntÃ¢i.

## ğŸš€ Provocare

CiteÈ™te mai multe despre cum poÈ›i [folosi RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pentru afacerea ta.

## Lucru Grozav, ContinuÄƒ ÃnvÄƒÈ›area

DupÄƒ ce ai completat aceastÄƒ lecÈ›ie, verificÄƒ colecÈ›ia noastrÄƒ de [Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) pentru a continua sÄƒ Ã®È›i Ã®mbunÄƒtÄƒÈ›eÈ™ti cunoÈ™tinÈ›ele despre AI GenerativÄƒ!

Mergi la LecÈ›ia 3 unde vom analiza cum sÄƒ [construieÈ™ti cu AI GenerativÄƒ Ã®n mod Responsabil](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Declinarea responsabilitÄƒÈ›ii**:  
Acest document a fost tradus folosind serviciul de traducere AI [Co-op Translator](https://github.com/Azure/co-op-translator). DeÈ™i ne strÄƒduim sÄƒ asigurÄƒm acurateÈ›ea, vÄƒ rugÄƒm sÄƒ fiÈ›i conÈ™tienÈ›i cÄƒ traducerile automate pot conÈ›ine erori sau inexactitÄƒÈ›i. Documentul original Ã®n limba sa natalÄƒ ar trebui considerat sursa autoritarÄƒ. Pentru informaÈ›ii critice, se recomandÄƒ traducerea umanÄƒ profesionalÄƒ. Nu ne asumÄƒm rÄƒspunderea pentru neÃ®nÈ›elegerile sau interpretÄƒrile greÈ™ite care pot apÄƒrea din utilizarea acestei traduceri.