{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "নিম্নলিখিত নোটবুকগুলি চালানোর জন্য, যদি আপনি এখনও না করে থাকেন, তাহলে আপনাকে .env ফাইলে `OPENAI_API_KEY` হিসেবে openai কী সেট করতে হবে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "পরবর্তী, আমরা এমবেডিং ইনডেক্সটি একটি প্যান্ডাস ডেটাফ্রেমে লোড করব। এমবেডিং ইনডেক্সটি একটি JSON ফাইলে সংরক্ষিত আছে যার নাম `embedding_index_3m.json`। এমবেডিং ইনডেক্সে ২০২৩ সালের অক্টোবরের শেষ পর্যন্ত প্রতিটি ইউটিউব ট্রান্সক্রিপ্টের এমবেডিংস রয়েছে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "পরবর্তী ধাপে, আমরা `get_videos` নামে একটি ফাংশন তৈরি করব যা কুয়েরির জন্য এমবেডিং ইনডেক্স অনুসন্ধান করবে। ফাংশনটি কুয়েরির সাথে সবচেয়ে মিল থাকা শীর্ষ ৫টি ভিডিও ফেরত দেবে। ফাংশনটি নিম্নরূপ কাজ করে:\n",
    "\n",
    "1. প্রথমে, এমবেডিং ইনডেক্সের একটি কপি তৈরি করা হয়।\n",
    "2. এরপর, OpenAI এমবেডিং API ব্যবহার করে কুয়েরির এমবেডিং গণনা করা হয়।\n",
    "3. তারপর এমবেডিং ইনডেক্সে `similarity` নামে একটি নতুন কলাম তৈরি করা হয়। `similarity` কলামে কুয়েরি এমবেডিং এবং প্রতিটি ভিডিও সেগমেন্টের এমবেডিংয়ের মধ্যে কোসাইন সাদৃশ্য থাকে।\n",
    "4. এরপর, `similarity` কলাম দ্বারা এমবেডিং ইনডেক্স ফিল্টার করা হয়। এমবেডিং ইনডেক্স শুধুমাত্র সেই ভিডিওগুলো অন্তর্ভুক্ত করতে ফিল্টার করা হয় যাদের কোসাইন সাদৃশ্য ০.৭৫ বা তার বেশি।\n",
    "5. অবশেষে, `similarity` কলাম দ্বারা এমবেডিং ইনডেক্স সাজানো হয় এবং শীর্ষ ৫টি ভিডিও ফেরত দেওয়া হয়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এই ফাংশনটি খুবই সহজ, এটি কেবল সার্চ কুয়েরির ফলাফলগুলি প্রিন্ট করে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. প্রথমে, এমবেডিং ইনডেক্স একটি প্যান্ডাস ডেটাফ্রেমে লোড করা হয়।\n",
    "2. পরবর্তীতে, ব্যবহারকারীকে একটি প্রশ্ন প্রবেশ করার জন্য অনুরোধ করা হয়।\n",
    "3. তারপর `get_videos` ফাংশনটি কল করা হয় প্রশ্নের জন্য এমবেডিং ইনডেক্স অনুসন্ধান করতে।\n",
    "4. অবশেষে, `display_results` ফাংশনটি কল করা হয় ফলাফলগুলি ব্যবহারকারীর কাছে প্রদর্শন করতে।\n",
    "5. এরপর ব্যবহারকারীকে আবার একটি প্রশ্ন প্রবেশ করার জন্য অনুরোধ করা হয়। এই প্রক্রিয়া চলতে থাকে যতক্ষণ না ব্যবহারকারী `exit` প্রবেশ করে।\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.bn.png)\n",
    "\n",
    "আপনাকে একটি প্রশ্ন প্রবেশ করার জন্য অনুরোধ করা হবে। একটি প্রশ্ন লিখুন এবং এন্টার চাপুন। অ্যাপ্লিকেশনটি প্রশ্নের সাথে সম্পর্কিত ভিডিওগুলির একটি তালিকা প্রদান করবে। অ্যাপ্লিকেশনটি সেই ভিডিওর লিঙ্কও প্রদান করবে যেখানে প্রশ্নের উত্তর অবস্থিত।\n",
    "\n",
    "এখানে কিছু প্রশ্ন দেওয়া হলো যা আপনি চেষ্টা করতে পারেন:\n",
    "\n",
    "- Azure Machine Learning কী?\n",
    "- কনভলিউশনাল নিউরাল নেটওয়ার্কগুলি কীভাবে কাজ করে?\n",
    "- নিউরাল নেটওয়ার্ক কী?\n",
    "- আমি কি Azure Machine Learning এর সাথে Jupyter Notebooks ব্যবহার করতে পারি?\n",
    "- ONNX কী?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**অস্বীকৃতি**:  \nএই নথিটি AI অনুবাদ সেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনূদিত হয়েছে। আমরা যথাসাধ্য সঠিকতার চেষ্টা করি, তবে স্বয়ংক্রিয় অনুবাদে ত্রুটি বা অসঙ্গতি থাকতে পারে। মূল নথিটি তার নিজস্ব ভাষায়ই কর্তৃত্বপূর্ণ উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য পেশাদার মানব অনুবাদ গ্রহণ করার পরামর্শ দেওয়া হয়। এই অনুবাদের ব্যবহারে সৃষ্ট কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যার জন্য আমরা দায়ী নই।\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T09:37:31+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "bn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}