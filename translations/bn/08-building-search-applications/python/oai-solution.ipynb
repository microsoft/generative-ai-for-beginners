{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "নিম্নলিখিত নোটবুকগুলো চালানোর জন্য, যদি আপনি এখনও না করে থাকেন, তাহলে আপনাকে .env ফাইলে `OPENAI_API_KEY` হিসেবে ওপেনএআই কী সেট করতে হবে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "পরবর্তী ধাপে, আমরা এম্বেডিং ইনডেক্সটি একটি প্যান্ডাস ডেটাফ্রেমে লোড করতে যাচ্ছি। এম্বেডিং ইনডেক্সটি `embedding_index_3m.json` নামক একটি JSON ফাইলে সংরক্ষিত আছে। এম্বেডিং ইনডেক্সে ২০২৩ সালের অক্টোবর মাসের শেষ পর্যন্ত প্রতিটি ইউটিউব ট্রান্সক্রিপ্টের জন্য এম্বেডিং সংরক্ষিত আছে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এবার আমরা `get_videos` নামে একটি ফাংশন তৈরি করব, যা Embedding Index-এ প্রশ্নের জন্য অনুসন্ধান করবে। এই ফাংশনটি প্রশ্নের সাথে সবচেয়ে বেশি মিল রয়েছে এমন শীর্ষ ৫টি ভিডিও ফেরত দেবে। ফাংশনটি নিচের ধাপগুলো অনুসরণ করে কাজ করে:\n",
    "\n",
    "1. প্রথমে, Embedding Index-এর একটি কপি তৈরি করা হয়।\n",
    "2. এরপর, প্রশ্নের Embedding OpenAI Embedding API ব্যবহার করে গণনা করা হয়।\n",
    "3. তারপর Embedding Index-এ `similarity` নামে একটি নতুন কলাম তৈরি করা হয়। `similarity` কলামে প্রশ্নের Embedding এবং প্রতিটি ভিডিও সেগমেন্টের Embedding-এর মধ্যে কসাইন সাদৃশ্য (cosine similarity) রাখা হয়।\n",
    "4. এরপর, Embedding Index-কে `similarity` কলাম অনুযায়ী ফিল্টার করা হয়। Embedding Index-এ শুধুমাত্র সেই ভিডিওগুলো রাখা হয় যেগুলোর কসাইন সাদৃশ্য ০.৭৫ বা তার বেশি।\n",
    "5. সবশেষে, Embedding Index-কে `similarity` কলাম অনুযায়ী সাজানো হয় এবং শীর্ষ ৫টি ভিডিও ফেরত দেওয়া হয়।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "এই ফাংশনটি খুবই সহজ, এটি শুধু অনুসন্ধান প্রশ্নের ফলাফলগুলি মুদ্রণ করে।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "১. প্রথমে, Embedding Index একটি Pandas Dataframe-এ লোড করা হয়।\n",
    "২. এরপর, ব্যবহারকারীকে একটি কোয়েরি দিতে বলা হয়।\n",
    "৩. তারপর `get_videos` ফাংশনটি ডাকা হয় কোয়েরি অনুসন্ধানের জন্য Embedding Index-এ।\n",
    "৪. শেষে, `display_results` ফাংশনটি ডাকা হয় ব্যবহারকারীর কাছে ফলাফল দেখানোর জন্য।\n",
    "৫. এরপর ব্যবহারকারীকে আবার একটি কোয়েরি দিতে বলা হয়। এই প্রক্রিয়া চলতে থাকে যতক্ষণ না ব্যবহারকারী `exit` লিখে।\n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc1436d98ea6ee73b4b54ca47990a1c952b340a2cadf8ac1ca.bn.png)\n",
    "\n",
    "আপনাকে একটি কোয়েরি দিতে বলা হবে। একটি কোয়েরি লিখে এন্টার চাপুন। অ্যাপ্লিকেশনটি কোয়েরির সাথে সম্পর্কিত ভিডিওগুলোর একটি তালিকা দেখাবে। এছাড়াও, ভিডিওর সেই অংশের একটি লিঙ্কও দেখাবে যেখানে প্রশ্নের উত্তরটি রয়েছে।\n",
    "\n",
    "কিছু কোয়েরি উদাহরণ হিসেবে নিচে দেওয়া হলো:\n",
    "\n",
    "- Azure Machine Learning কী?\n",
    "- কনভল্যুশনাল নিউরাল নেটওয়ার্ক কীভাবে কাজ করে?\n",
    "- নিউরাল নেটওয়ার্ক কী?\n",
    "- আমি কি Azure Machine Learning-এর সাথে Jupyter Notebooks ব্যবহার করতে পারি?\n",
    "- ONNX কী?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from imput\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**দায়িত্ব অস্বীকার**:\nএই নথিটি AI অনুবাদ পরিষেবা [Co-op Translator](https://github.com/Azure/co-op-translator) ব্যবহার করে অনুবাদ করা হয়েছে। আমরা যথাসম্ভব নির্ভুল অনুবাদের চেষ্টা করি, তবে অনুগ্রহ করে মনে রাখবেন যে স্বয়ংক্রিয় অনুবাদে ভুল বা অসঙ্গতি থাকতে পারে। মূল ভাষায় রচিত নথিটিকেই চূড়ান্ত ও নির্ভরযোগ্য উৎস হিসেবে বিবেচনা করা উচিত। গুরুত্বপূর্ণ তথ্যের জন্য পেশাদার মানব অনুবাদ গ্রহণ করার পরামর্শ দেওয়া হচ্ছে। এই অনুবাদের ব্যবহারে কোনো ভুল বোঝাবুঝি বা ভুল ব্যাখ্যা হলে আমরা দায়ী থাকব না।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "2c0494ceb4f5fc618a6abda0b5c09c73",
   "translation_date": "2025-08-25T18:56:26+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "bn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}