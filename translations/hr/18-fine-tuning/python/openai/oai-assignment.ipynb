{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fino podešavanje Open AI modela\n",
    "\n",
    "Ovaj bilježnik temelji se na trenutnim uputama iz [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) dokumentacije Open AI.\n",
    "\n",
    "Fino podešavanje poboljšava performanse temeljnih modela za vašu aplikaciju ponovnim treniranjem s dodatnim podacima i kontekstom relevantnim za taj specifični slučaj upotrebe ili scenarij. Imajte na umu da tehnike inženjeringa upita poput _few shot learning_ i _retrieval augmented generation_ omogućuju vam da poboljšate zadani upit relevantnim podacima za poboljšanje kvalitete. Međutim, ti pristupi ograničeni su maksimalnom veličinom prozora tokena ciljanog temeljog modela.\n",
    "\n",
    "Fino podešavanje zapravo znači ponovno treniranje samog modela s potrebnim podacima (što nam omogućuje korištenje mnogo više primjera nego što stane u maksimalni prozor tokena) - i implementaciju _prilagođene_ verzije modela koja više ne treba primjere tijekom izvođenja. To ne samo da poboljšava učinkovitost dizajna našeg upita (imamo veću fleksibilnost u korištenju prozora tokena za druge stvari), već potencijalno i smanjuje naše troškove (smanjenjem broja tokena koje trebamo poslati modelu tijekom izvođenja).\n",
    "\n",
    "Fino podešavanje ima 4 koraka:\n",
    "1. Pripremite podatke za treniranje i učitajte ih.\n",
    "1. Pokrenite zadatak treniranja da biste dobili fino podešeni model.\n",
    "1. Procijenite fino podešeni model i iterirajte za kvalitetu.\n",
    "1. Implementirajte fino podešeni model za izvođenje kad ste zadovoljni.\n",
    "\n",
    "Imajte na umu da ne podržavaju svi temeljni modeli fino podešavanje - [provjerite OpenAI dokumentaciju](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) za najnovije informacije. Također možete fino podesiti prethodno fino podešeni model. U ovom vodiču koristit ćemo `gpt-35-turbo` kao naš ciljani temeljni model za fino podešavanje.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 1.1: Pripremite svoj skup podataka\n",
    "\n",
    "Izgradimo chatbot koji vam pomaže razumjeti periodni sustav elemenata odgovarajući na pitanja o elementu limerikom. U _ovom_ jednostavnom vodiču, samo ćemo stvoriti skup podataka za treniranje modela s nekoliko primjera odgovora koji pokazuju očekivani format podataka. U stvarnom slučaju korištenja, trebali biste stvoriti skup podataka s mnogo više primjera. Također biste mogli koristiti otvoreni skup podataka (za vašu domenu primjene) ako postoji, i preformatirati ga za upotrebu u finoj prilagodbi.\n",
    "\n",
    "Budući da se fokusiramo na `gpt-35-turbo` i tražimo odgovor u jednom koraku (chat dovršetak), možemo stvoriti primjere koristeći [ovaj predloženi format](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst) koji odražava zahtjeve OpenAI chat dovršetka. Ako očekujete višekratni razgovor, koristili biste [format primjera za višekratni razgovor](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst) koji uključuje parametar `weight` za označavanje koje poruke treba koristiti (ili ne) u procesu fino podešavanja.\n",
    "\n",
    "Za naš vodič koristit ćemo jednostavniji format s jednim korakom. Podaci su u [jsonl formatu](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) s jednim zapisom po retku, svaki predstavljen kao JSON objekt. Donji isječak prikazuje 2 zapisa kao primjer - pogledajte [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) za puni skup primjera (10 primjera) koje ćemo koristiti za naš vodič o finoj prilagodbi. **Napomena:** Svaki zapis _mora_ biti definiran u jednom retku (ne razdvajati ga preko više redaka kao što je uobičajeno u formatiranom JSON-u)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "U stvarnom slučaju korištenja trebat će vam mnogo veći skup primjera za dobre rezultate - kompromis će biti između kvalitete odgovora i vremena/troškova za fino podešavanje. Koristimo mali skup kako bismo brzo završili fino podešavanje i ilustrirali proces. Pogledajte [ovaj primjer iz OpenAI Cookbook-a](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) za složeniji vodič o finoj prilagodbi.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 1.2 Učitajte svoj skup podataka\n",
    "\n",
    "Učitajte podatke koristeći Files API [kako je opisano ovdje](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Imajte na umu da kako biste mogli pokrenuti ovaj kod, morate prvo napraviti sljedeće korake:\n",
    " - Instalirali `openai` Python paket (pazite da koristite verziju >=0.28.0 za najnovije značajke)\n",
    " - Postavili varijablu okoline `OPENAI_API_KEY` na svoj OpenAI API ključ\n",
    "Za više informacija, pogledajte [Vodič za postavljanje](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) koji je osiguran za tečaj.\n",
    "\n",
    "Sada pokrenite kod za stvaranje datoteke za učitavanje iz vaše lokalne JSONL datoteke.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 2.1: Kreirajte zadatak fino podešavanja pomoću SDK-a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 2.2: Provjerite status zadatka\n",
    "\n",
    "Evo nekoliko stvari koje možete učiniti s `client.fine_tuning.jobs` API-jem:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Prikaži posljednjih n zadataka fino podešavanja\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Dohvati detalje određenog zadatka fino podešavanja\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Otkaži zadatak fino podešavanja\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Prikaži do n događaja iz zadatka\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Prvi korak procesa je _validacija datoteke za treniranje_ kako bi se osiguralo da su podaci u ispravnom formatu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 2.3: Pratite događaje za praćenje napretka\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Korak 2.4: Pregled statusa u OpenAI nadzornoj ploči\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Također možete provjeriti status posjetom OpenAI web stranici i istraživanjem odjeljka _Fine-tuning_ na platformi. To će vam pokazati status trenutnog zadatka, kao i omogućiti praćenje povijesti prethodnih izvršenja zadataka. Na ovom snimku zaslona možete vidjeti da je prethodno izvršenje bilo neuspješno, a drugo izvršenje uspješno. Za kontekst, to se dogodilo kada je prvo izvršenje koristilo JSON datoteku s nepravilno formatiranim zapisima - nakon ispravka, drugo izvršenje je uspješno završilo i model je postao dostupan za korištenje.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/hr/fine-tuned-model-status.563271727bf7bfba.webp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Također možete pregledati poruke statusa i metrike pomicanjem prema dolje u vizualnoj nadzornoj ploči kao što je prikazano:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/hr/fine-tuned-messages-panel.4ed0c2da5ea1313b.webp) |  ![Metrics](../../../../../translated_images/hr/fine-tuned-metrics-panel.700d7e4995a65229.webp)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 3.1: Dohvati ID i testiraj fino podešeni model u kodu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Korak 3.2: Učitajte i testirajte fino podešeni model u Playgroundu\n",
    "\n",
    "Sada možete testirati fino podešeni model na dva načina. Prvo, možete posjetiti Playground i koristiti padajući izbornik Models za odabir vašeg novopodešenog modela s popisa opcija. Druga opcija je korištenje opcije \"Playground\" prikazane u panelu Fine-tuning (vidi snimku zaslona gore) koja pokreće sljedeći _usporedni_ prikaz koji prikazuje verzije osnovnog i fino podešenog modela jedna pored druge za brzu evaluaciju.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/hr/fine-tuned-playground-compare.56e06f0ad8922016.webp)\n",
    "\n",
    "Jednostavno ispunite kontekst sustava korišten u vašim podacima za treniranje i unesite svoje testno pitanje. Primijetit ćete da su obje strane ažurirane s istim kontekstom i pitanjem. Pokrenite usporedbu i vidjet ćete razliku u izlazima između njih. _Primijetite kako fino podešeni model prikazuje odgovor u formatu koji ste dali u svojim primjerima, dok osnovni model jednostavno slijedi sistemski prompt_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/hr/fine-tuned-playground-launch.5a26495c983c6350.webp)\n",
    "\n",
    "Primijetit ćete da usporedba također prikazuje broj tokena za svaki model i vrijeme potrebno za izvođenje. **Ovaj specifični primjer je pojednostavljen i služi za prikaz procesa, ali ne odražava stvarni skup podataka ili scenarij**. Možda ćete primijetiti da oba uzorka prikazuju isti broj tokena (kontekst sustava i korisnički prompt su identični), pri čemu fino podešeni model troši više vremena za izvođenje (prilagođeni model).\n",
    "\n",
    "U stvarnim scenarijima nećete koristiti ovakav jednostavan primjer, već fino podešavanje na stvarnim podacima (npr. katalog proizvoda za korisničku podršku) gdje će kvaliteta odgovora biti mnogo vidljivija. U _tom_ kontekstu, dobivanje ekvivalentne kvalitete odgovora s osnovnim modelom zahtijevat će više prilagođavanja prompta, što će povećati korištenje tokena i potencijalno vrijeme obrade za izvođenje. _Za isprobavanje, pogledajte primjere fino podešavanja u OpenAI Cookbooku za početak._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Odricanje od odgovornosti**:\nOvaj dokument je preveden korištenjem AI usluge za prevođenje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo postići točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritične informacije preporučuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakva nesporazuma ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T11:46:02+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "hr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}