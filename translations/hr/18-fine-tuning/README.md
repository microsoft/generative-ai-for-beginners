[![Open Source Models](../../../translated_images/hr/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Fino podeÅ¡avanje vaÅ¡eg LLM-a

KoriÅ¡tenje velikih jeziÄnih modela za izgradnju generativnih AI aplikacija donosi nove izazove. KljuÄno pitanje je osigurati kvalitetu odgovora (toÄnost i relevantnost) u sadrÅ¾aju koji model generira za odreÄ‘eni korisniÄki zahtjev. U prethodnim lekcijama razgovarali smo o tehnikama poput inÅ¾enjeringa promptova i generacije potpomognute dohvatom koje pokuÅ¡avaju rijeÅ¡iti problem _modificiranjem unosa prompta_ u postojeÄ‡i model.

U danaÅ¡njoj lekciji raspravljamo o treÄ‡oj tehnici, **fino podeÅ¡avanje**, koja pokuÅ¡ava rijeÅ¡iti izazov _ponovnim treniranjem samog modela_ s dodatnim podacima. Zaronimo u detalje.

## Ciljevi uÄenja

Ova lekcija uvodi koncept fino podeÅ¡avanja prethodno treniranih jeziÄnih modela, istraÅ¾uje prednosti i izazove ovog pristupa te pruÅ¾a smjernice kada i kako koristiti fino podeÅ¡avanje za poboljÅ¡anje performansi vaÅ¡ih generativnih AI modela.

Na kraju ove lekcije trebali biste moÄ‡i odgovoriti na sljedeÄ‡a pitanja:

- Å to je fino podeÅ¡avanje za jeziÄne modele?
- Kada i zaÅ¡to je fino podeÅ¡avanje korisno?
- Kako mogu fino podesiti prethodno trenirani model?
- Koja su ograniÄenja fino podeÅ¡avanja?

Spremni? Krenimo.

## Ilustrirani vodiÄ

Å½elite li dobiti cjelovitu sliku onoga Å¡to Ä‡emo pokriti prije nego Å¡to krenemo? Pogledajte ovaj ilustrirani vodiÄ koji opisuje put uÄenja za ovu lekciju â€“ od uÄenja osnovnih koncepata i motivacije za fino podeÅ¡avanje, do razumijevanja procesa i najboljih praksi za izvrÅ¡avanje zadatka fino podeÅ¡avanja. Ovo je fascinantna tema za istraÅ¾ivanje, stoga ne zaboravite provjeriti stranicu [Resursi](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) za dodatne poveznice koje Ä‡e podrÅ¾ati vaÅ¡e samostalno uÄenje!

![Illustrated Guide to Fine Tuning Language Models](../../../translated_images/hr/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Å to je fino podeÅ¡avanje za jeziÄne modele?

Prema definiciji, veliki jeziÄni modeli su _prethodno trenirani_ na velikim koliÄinama tekstova prikupljenim iz razliÄitih izvora ukljuÄujuÄ‡i internet. Kao Å¡to smo nauÄili u prethodnim lekcijama, potrebne su nam tehnike poput _inÅ¾enjeringa promptova_ i _generacije potpomognute dohvatom_ kako bismo poboljÅ¡ali kvalitetu odgovora modela na korisniÄka pitanja ("prompte").

Popularna tehnika inÅ¾enjeringa prompta ukljuÄuje davanje modelu viÅ¡e smjernica o tome Å¡to se oÄekuje u odgovoru bilo pruÅ¾anjem _uputa_ (izravnih smjernica) ili _davanjem nekoliko primjera_ (neizravnih smjernica). Ovo se naziva _uÄenje s nekoliko primjera_ (few-shot learning) ali ima dvije ograniÄenja:

- OgraniÄenja tokena modela mogu suziti broj primjera koje moÅ¾ete dati i ograniÄiti uÄinkovitost.
- TroÅ¡kovi tokena modela mogu uÄiniti skupo dodavanje primjera u svaki prompt, ograniÄavajuÄ‡i fleksibilnost.

Fino podeÅ¡avanje je uobiÄajena praksa u sustavima strojnog uÄenja gdje uzimamo prethodno trenirani model i ponovo ga treniramo s novim podacima kako bismo poboljÅ¡ali njegovu izvedbu na specifiÄnom zadatku. U kontekstu jeziÄnih modela, moÅ¾emo fino podesiti prethodno trenirani model _s paÅ¾ljivo odabranim skupom primjera za odreÄ‘eni zadatak ili domenu primjene_ kako bismo stvorili **prilagoÄ‘eni model** koji moÅ¾e biti toÄniji i relevantniji za taj specifiÄni zadatak ili domenu. Dodatna prednost fino podeÅ¡avanja je da moÅ¾e smanjiti broj primjera potreban za uÄenje s nekoliko primjera - smanjujuÄ‡i koriÅ¡tenje tokena i povezane troÅ¡kove.

## Kada i zaÅ¡to trebamo fino podeÅ¡avati modele?

U _ovom_ kontekstu, kada govorimo o fino podeÅ¡avanju, referiramo se na **supervizirano** fino podeÅ¡avanje gdje se ponovno treniranje radi **dodavanjem novih podataka** koji nisu bili dio izvornog skupa podataka za treniranje. Ovo se razlikuje od pristupa nesuperviziranog fino podeÅ¡avanja gdje se model ponovno trenira na izvornim podacima, ali s razliÄitim hiperparametrima.

KljuÄna stvar koju treba zapamtiti je da je fino podeÅ¡avanje napredna tehnika koja zahtijeva odreÄ‘enu razinu struÄnosti za postizanje Å¾eljenih rezultata. Ako se pogreÅ¡no izvede, moÅ¾da neÄ‡e donijeti oÄekivana poboljÅ¡anja, pa Äak moÅ¾e i pogorÅ¡ati izvedbu modela za vaÅ¡u ciljanu domenu.

Dakle, prije nego Å¡to nauÄite "kako" fino podesiti jeziÄne modele, morate znati "zaÅ¡to" biste trebali krenuti tim putem i "kada" zapoÄeti proces fino podeÅ¡avanja. PoÄnite tako Å¡to Ä‡ete sebi postaviti sljedeÄ‡a pitanja:

- **SluÄaj upotrebe**: Koji je vaÅ¡ _sluÄaj upotrebe_ za fino podeÅ¡avanje? Koji aspekt trenutnog prethodno treniranog modela Å¾elite poboljÅ¡ati?
- **Alternativa**: Jeste li isprobali _druge tehnike_ za postizanje Å¾eljenih rezultata? Koristite ih da stvorite osnovnu liniju za usporedbu.
  - InÅ¾enjering prompta: Isprobajte tehnike poput few-shot promptinga s primjerima relevantnih odgovora. Procijenite kvalitetu odgovora.
  - Generacija potpomognuta dohvatom: Isprobajte pojaÄavanje promptova rezultatima pretraÅ¾ivanja vaÅ¡ih podataka. Procijenite kvalitetu odgovora.
- **TroÅ¡kovi**: Jeste li identificirali troÅ¡kove za fino podeÅ¡avanje?
  - MoguÄ‡nost podeÅ¡avanja - je li prethodno trenirani model dostupan za fino podeÅ¡avanje?
  - UloÅ¾eni trud - za pripremu podataka za treniranje, procjenu i usavrÅ¡avanje modela.
  - RaÄunalna snaga - za izvoÄ‘enje poslova fino podeÅ¡avanja i implementaciju fino podeÅ¡enog modela.
  - Podaci - pristup dovoljnom broju kvalitetnih primjera za utjecaj fino podeÅ¡avanja.
- **Prednosti**: Jeste li potvrdili prednosti fino podeÅ¡avanja?
  - Kvaliteta - je li fino podeÅ¡eni model nadmaÅ¡io osnovu?
  - TroÅ¡kovi - smanjuje li koriÅ¡tenje tokena pojednostavljivanjem promptova?
  - ProÅ¡irivost - moÅ¾ete li ponovo koristiti osnovni model za nove domene?

Odgovaranjem na ova pitanja trebali biste moÄ‡i odluÄiti je li fino podeÅ¡avanje pravi pristup za vaÅ¡ sluÄaj upotrebe. Idealno, pristup je valjan samo ako prednosti premaÅ¡uju troÅ¡kove. Kad se odluÄite nastaviti, vrijeme je da razmislite o tome _kako_ moÅ¾ete fino podesiti prethodno trenirani model.

Å½elite li dobiti viÅ¡e uvida u proces donoÅ¡enja odluka? Pogledajte [Fino podeÅ¡avati ili ne fino podeÅ¡avati](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Kako moÅ¾emo fino podesiti prethodno trenirani model?

Za fino podeÅ¡avanje prethodno treniranog modela trebate imati:

- prethodno trenirani model za fino podeÅ¡avanje
- skup podataka za fino podeÅ¡avanje
- okruÅ¾enje za treniranje za izvoÄ‘enje posla fino podeÅ¡avanja
- okruÅ¾enje za hostiranje za implementaciju fino podeÅ¡enog modela

## Fino podeÅ¡avanje u praksi

SljedeÄ‡i resursi pruÅ¾aju korak-po-korak tutorijale koji vas provode kroz stvarni primjer koristeÄ‡i odabrani model s paÅ¾ljivo odabranim skupom podataka. Da biste proÅ¡li ove tutorijale, trebate raÄun kod odreÄ‘enog davatelja usluga, kao i pristup relevantnom modelu i datasetima.

| Davatelj usluge | Tutorijal                                                                                                                                                                                   | Opis                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ---------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI           | [Kako fino podesiti chat modele](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                             | NauÄite kako fino podesiti `gpt-35-turbo` za specifiÄnu domenu ("pomoÄ‡nik za recepte") pripremanjem podataka za treniranje, izvoÄ‘enjem posla fino podeÅ¡avanja te koriÅ¡tenjem fino podeÅ¡enog modela za izvoÄ‘enje.                                                                                                                                                                                                                  |
| Azure OpenAI     | [Tutorijal za fino podeÅ¡avanje GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst)          | NauÄite kako fino podesiti `gpt-35-turbo-0613` model **na Azureu** korak po korak kreiranjem i uÄitavanjem podataka za treniranje, izvoÄ‘enjem posla fino podeÅ¡avanja. Implementirajte i koristite novi model.                                                                                                                                                                                                                     |
| Hugging Face     | [Fino podeÅ¡avanje LLM-ova s Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                                        | Ovaj blog vodi vas kroz fino podeÅ¡avanje _otvorenog LLM-a_ (npr. `CodeLlama 7B`) koriÅ¡tenjem biblioteke [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) i [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) s otvorenim [datasetima](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|                  |                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ğŸ¤— AutoTrain     | [Fino podeÅ¡avanje LLM-ova s AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                                     | AutoTrain (ili AutoTrain Advanced) je python biblioteka koju je razvio Hugging Face, a koja omoguÄ‡uje fino podeÅ¡avanje za mnoge razliÄite zadatke ukljuÄujuÄ‡i fino podeÅ¡avanje LLM-ova. AutoTrain je rjeÅ¡enje bez koda koje moÅ¾e raditi u vaÅ¡em oblaku, na Hugging Face Spaces ili lokalno. PodrÅ¾ava web-based GUI, CLI i treniranje putem yaml konfiguracijskih datoteka.                                                                                 |
|                  |                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                |
| ğŸ¦¥ Unsloth       | [Fino podeÅ¡avanje LLM-ova s Unsloth](https://github.com/unslothai/unsloth)                                                                                                                     | Unsloth je open-source okvir koji podrÅ¾ava fino podeÅ¡avanje LLM-ova i uÄenje s potkrepljenjem (RL). Unsloth pojednostavljuje lokalno treniranje, evaluaciju i implementaciju uz spremne [biljeÅ¾nice](https://github.com/unslothai/notebooks). TakoÄ‘er podrÅ¾ava pretvaranje teksta u govor (TTS), BERT i multimodalne modele. Za poÄetak proÄitajte njihov korak-po-korak [VodiÄ za fino podeÅ¡avanje LLM-ova](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                                       |
|                  |                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                |
## Zadatak

Odaberite jedan od gore navedenih tutorijala i proÄ‘ite ga. _MoguÄ‡e je da Ä‡emo replicirati verziju ovih tutorijala u Jupyter biljeÅ¾nicama u ovom spremiÅ¡tu samo za referencu. Molimo koristite izvorne izvore direktno za najnovije verzije_.

## Sjajan posao! Nastavite s uÄenjem.

Nakon dovrÅ¡etka ove lekcije, pogledajte naÅ¡u [kolekciju za uÄenje generativne AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili podizati svoje znanje o generativnoj AI!

ÄŒestitamo!! ZavrÅ¡ili ste zavrÅ¡nu lekciju iz v2 serije ovog teÄaja! Nemojte prestati uÄiti i graditi. \*\*Pogledajte stranicu [RESURSĞ˜](RESOURCES.md?WT.mc_id=academic-105485-koreyst) za popis dodatnih preporuka za ovu temu.

NaÅ¡a v1 serija lekcija takoÄ‘er je aÅ¾urirana s viÅ¡e zadataka i koncepata. Pa odvojite minutu za osvjeÅ¾enje svog znanja â€“ i molimo [podijelite svoja pitanja i povratne informacije](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) kako bismo mogli poboljÅ¡ati ove lekcije za zajednicu.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Odricanje od odgovornosti**:
Ovaj dokument je preveden koriÅ¡tenjem AI usluge prevoÄ‘enja [Co-op Translator](https://github.com/Azure/co-op-translator). Iako teÅ¾imo toÄnosti, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati sluÅ¾benim i vjerodostojnim izvorom. Za vaÅ¾ne informacije preporuÄuje se struÄni prijevod od strane profesionalnih prevoditelja. Ne snosimo odgovornost za bilo kakve nerazumijevanja ili pogreÅ¡ne interpretacije koje proizlaze iz koriÅ¡tenja ovog prijevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->