<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T16:26:58+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "hr"
}
-->
# Osnove projektiranja upita

## Uvod

Ovaj modul pokriva osnovne pojmove i tehnike za stvaranje uÄinkovitih upita u generativnim AI modelima. NaÄin na koji piÅ¡ete svoj upit za LLM takoÄ‘er je vaÅ¾an. PaÅ¾ljivo osmiÅ¡ljen upit moÅ¾e postiÄ‡i bolju kvalitetu odgovora. Ali Å¡to toÄno znaÄe pojmovi poput _upit_ i _projektiranje upita_? I kako mogu poboljÅ¡ati _unos_ upita koji Å¡aljem LLM-u? To su pitanja na koja Ä‡emo pokuÅ¡ati odgovoriti u ovom i sljedeÄ‡em poglavlju.

_Generativna AI_ je sposobna stvarati novi sadrÅ¾aj (npr. tekst, slike, audio, kod itd.) kao odgovor na zahtjeve korisnika. To postiÅ¾e koristeÄ‡i _Velike JeziÄne Modele_ kao Å¡to je OpenAI-jev GPT ("Generative Pre-trained Transformer") serija, koja je trenirana za koriÅ¡tenje prirodnog jezika i koda.

Korisnici sada mogu komunicirati s ovim modelima koristeÄ‡i poznate paradigme poput chata, bez potrebe za tehniÄkim znanjem ili obukom. Modeli su _temeljeni na upitima_ - korisnici Å¡alju tekstualni unos (upit) i dobivaju AI odgovor (dovrÅ¡etak). Tada mogu "razgovarati s AI-jem" iterativno, u viÅ¡ekratnim razgovorima, usavrÅ¡avajuÄ‡i svoj upit dok odgovor ne zadovolji njihova oÄekivanja.

"Upiti" sada postaju primarno _programsko suÄelje_ za generativne AI aplikacije, govoreÄ‡i modelima Å¡to trebaju raditi i utjeÄuÄ‡i na kvalitetu vraÄ‡enih odgovora. "Projektiranje upita" je brzo rastuÄ‡e podruÄje prouÄavanja koje se fokusira na _dizajn i optimizaciju_ upita kako bi se isporuÄili dosljedni i kvalitetni odgovori u velikom obimu.

## Ciljevi uÄenja

U ovoj lekciji nauÄit Ä‡emo Å¡to je projektiranje upita, zaÅ¡to je vaÅ¾no i kako moÅ¾emo oblikovati uÄinkovitije upite za odreÄ‘eni model i cilj aplikacije. Razumjet Ä‡emo osnovne pojmove i najbolje prakse za projektiranje upita - i saznati viÅ¡e o interaktivnom okruÅ¾enju "sandbox" u Jupyter Notebooks gdje moÅ¾emo vidjeti primjenu ovih pojmova na stvarnim primjerima.

Do kraja ove lekcije moÄ‡i Ä‡emo:

1. Objasniti Å¡to je projektiranje upita i zaÅ¡to je vaÅ¾no.
2. Opisati komponente upita i kako se koriste.
3. NauÄiti najbolje prakse i tehnike za projektiranje upita.
4. Primijeniti nauÄene tehnike na stvarne primjere, koristeÄ‡i OpenAI endpoint.

## KljuÄni pojmovi

Projektiranje upita: Praksa dizajniranja i usavrÅ¡avanja unosa kako bi se AI modeli usmjerili prema proizvodnji Å¾eljenih izlaza.
Tokenizacija: Proces pretvaranja teksta u manje jedinice, nazvane tokeni, koje model moÅ¾e razumjeti i obraditi.
LLM-ovi usklaÄ‘eni s uputama: Veliki JeziÄni Modeli (LLM-ovi) koji su fino podeÅ¡eni s odreÄ‘enim uputama kako bi poboljÅ¡ali toÄnost i relevantnost svojih odgovora.

## Sandbox za uÄenje

Projektiranje upita trenutno je viÅ¡e umjetnost nego znanost. Najbolji naÄin da poboljÅ¡amo naÅ¡u intuiciju za to je _viÅ¡e vjeÅ¾bati_ i usvojiti pristup pokuÅ¡aja i pogreÅ¡aka koji kombinira struÄnost u domeni aplikacije s preporuÄenim tehnikama i optimizacijama specifiÄnim za model.

Jupyter Notebook koji prati ovu lekciju pruÅ¾a _sandbox_ okruÅ¾enje gdje moÅ¾ete isprobati ono Å¡to nauÄite - kako idete ili kao dio izazova kodiranja na kraju. Za izvoÄ‘enje vjeÅ¾bi trebat Ä‡e vam:

1. **Azure OpenAI API kljuÄ** - krajnja toÄka usluge za implementirani LLM.
2. **Python Runtime** - u kojem se Notebook moÅ¾e izvesti.
3. **Lokalne varijable okoline** - _dovrÅ¡ite korake [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) sada kako biste bili spremni_.

Notebook dolazi s _poÄetnim_ vjeÅ¾bama - ali potiÄe vas da dodate vlastite _Markdown_ (opis) i _Code_ (zahtjevi za upit) sekcije kako biste isprobali viÅ¡e primjera ili ideja - i izgradili svoju intuiciju za dizajn upita.

## Ilustrirani vodiÄ

Å½elite li dobiti opÄ‡u sliku o tome Å¡to ova lekcija pokriva prije nego Å¡to se upustite? Pogledajte ovaj ilustrirani vodiÄ koji vam daje osjeÄ‡aj za glavne teme koje se obraÄ‘uju i kljuÄne spoznaje o kojima trebate razmiÅ¡ljati u svakoj od njih. Putokaz lekcije vodi vas od razumijevanja osnovnih pojmova i izazova do njihovog rjeÅ¡avanja relevantnim tehnikama projektiranja upita i najboljim praksama. Imajte na umu da se odjeljak "Napredne tehnike" u ovom vodiÄu odnosi na sadrÅ¾aj obraÄ‘en u _sljedeÄ‡em_ poglavlju ovog kurikuluma.

## NaÅ¡ startup

Sada, razgovarajmo o tome kako se _ova tema_ odnosi na naÅ¡u misiju startupa da [donese AI inovacije u obrazovanje](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Å½elimo izgraditi AI aplikacije za _personalizirano uÄenje_ - pa razmislimo o tome kako razliÄiti korisnici naÅ¡e aplikacije mogu "dizajnirati" upite:

- **Administratori** mogu zamoliti AI da _analizira podatke kurikuluma kako bi identificirao praznine u pokrivenosti_. AI moÅ¾e saÅ¾eti rezultate ili ih vizualizirati pomoÄ‡u koda.
- **Nastavnici** mogu zamoliti AI da _generira plan lekcije za ciljanog korisnika i temu_. AI moÅ¾e izraditi personalizirani plan u specificiranom formatu.
- **UÄenici** mogu zamoliti AI da ih _poduÄava u teÅ¡kom predmetu_. AI sada moÅ¾e voditi uÄenike s lekcijama, savjetima i primjerima prilagoÄ‘enima njihovoj razini.

To je samo vrh ledenog brijega. Pogledajte [Upiti za obrazovanje](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - otvorenu biblioteku upita koju su kreirali struÄnjaci za obrazovanje - kako biste dobili Å¡iri osjeÄ‡aj za moguÄ‡nosti! _PokuÅ¡ajte pokrenuti neke od tih upita u sandboxu ili pomoÄ‡u OpenAI Playground-a da vidite Å¡to Ä‡e se dogoditi!_

## Å to je projektiranje upita?

ZapoÄeli smo ovu lekciju definiranjem **projektiranja upita** kao procesa _dizajniranja i optimizacije_ tekstualnih unosa (upita) kako bi se isporuÄili dosljedni i kvalitetni odgovori (dovrÅ¡etci) za odreÄ‘eni cilj aplikacije i model. MoÅ¾emo to zamisliti kao dvostupanjski proces:

- _dizajniranje_ poÄetnog upita za odreÄ‘eni model i cilj
- _usavrÅ¡avanje_ upita iterativno kako bi se poboljÅ¡ala kvaliteta odgovora

Ovo je nuÅ¾no proces pokuÅ¡aja i pogreÅ¡aka koji zahtijeva korisniÄku intuiciju i trud kako bi se postigli optimalni rezultati. Pa zaÅ¡to je to vaÅ¾no? Da bismo odgovorili na to pitanje, prvo moramo razumjeti tri pojma:

- _Tokenizacija_ = kako model "vidi" upit
- _Osnovni LLM-ovi_ = kako osnovni model "obraÄ‘uje" upit
- _LLM-ovi usklaÄ‘eni s uputama_ = kako model sada moÅ¾e vidjeti "zadake"

### Tokenizacija

LLM vidi upite kao _sekvencu tokena_ gdje razliÄiti modeli (ili verzije modela) mogu tokenizirati isti upit na razliÄite naÄine. BuduÄ‡i da su LLM-ovi trenirani na tokenima (a ne na sirovom tekstu), naÄin na koji se upiti tokeniziraju ima izravan utjecaj na kvalitetu generiranog odgovora.

Da biste stekli intuiciju o tome kako tokenizacija funkcionira, isprobajte alate poput [OpenAI Tokenizatora](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) prikazanog dolje. Kopirajte svoj upit - i pogledajte kako se to pretvara u tokene, obraÄ‡ajuÄ‡i paÅ¾nju na to kako se rukuje znakovima razmaka i interpunkcijskim znakovima. Imajte na umu da ovaj primjer prikazuje stariji LLM (GPT-3) - pa pokuÅ¡aj s novijim modelom moÅ¾e dati drugaÄiji rezultat.

### Koncept: Osnovni modeli

Nakon Å¡to je upit tokeniziran, primarna funkcija ["Osnovnog LLM-a"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ili Osnovnog modela) je predvidjeti token u toj sekvenci. BuduÄ‡i da su LLM-ovi trenirani na masivnim skupovima podataka, imaju dobar osjeÄ‡aj za statistiÄke odnose izmeÄ‘u tokena i mogu napraviti to predviÄ‘anje s odreÄ‘enim povjerenjem. Imajte na umu da ne razumiju _znaÄenje_ rijeÄi u upitu ili tokenu; oni samo vide uzorak koji mogu "dovrÅ¡iti" svojim sljedeÄ‡im predviÄ‘anjem. Oni mogu nastaviti predviÄ‘ati sekvencu dok ih korisnik ne prekine ili dok se ne ispuni neki unaprijed postavljeni uvjet.

Å½elite li vidjeti kako funkcionira dovrÅ¡avanje temeljeno na upitu? Unesite gornji upit u Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) s zadanim postavkama. Sustav je konfiguriran da tretira upite kao zahtjeve za informacijama - tako da biste trebali vidjeti dovrÅ¡etak koji zadovoljava ovaj kontekst.

Ali Å¡to ako korisnik Å¾eli vidjeti neÅ¡to specifiÄno Å¡to zadovoljava neke kriterije ili ciljeve zadatka? Tu na scenu stupaju LLM-ovi usklaÄ‘eni s uputama.

### Koncept: LLM-ovi usklaÄ‘eni s uputama

[LLM usklaÄ‘en s uputama](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zapoÄinje s osnovnim modelom i fino ga podeÅ¡ava s primjerima ili parovima ulaz/izlaz (npr. viÅ¡ekratnim "porukama") koji mogu sadrÅ¾avati jasne upute - i odgovor AI-ja pokuÅ¡ava slijediti tu uputu.

Ovo koristi tehnike poput uÄenja pojaÄanja s povratnim informacijama ljudi (RLHF) koje mogu trenirati model da _slijedi upute_ i _uÄi iz povratnih informacija_ kako bi proizvodio odgovore koji su bolje prilagoÄ‘eni praktiÄnim primjenama i relevantniji za korisniÄke ciljeve.

Isprobajmo - vratite se na gornji upit, ali sada promijenite _sustavsku poruku_ kako biste pruÅ¾ili sljedeÄ‡u uputu kao kontekst:

> _SaÅ¾mi sadrÅ¾aj koji ti je dostavljen za uÄenika drugog razreda. ZadrÅ¾i rezultat na jednom odlomku s 3-5 toÄaka._

Vidite li kako je rezultat sada usklaÄ‘en s Å¾eljenim ciljem i formatom? Nastavnik sada moÅ¾e izravno koristiti ovaj odgovor u svojim prezentacijama za taj razred.

## ZaÅ¡to nam je potrebno projektiranje upita?

Sada kada znamo kako LLM-ovi obraÄ‘uju upite, razgovarajmo o _zaÅ¡to_ nam je potrebno projektiranje upita. Odgovor leÅ¾i u Äinjenici da trenutni LLM-ovi postavljaju niz izazova koji oteÅ¾avaju _pouzdano i dosljedno dovrÅ¡avanje_ bez ulaganja truda u konstrukciju i optimizaciju upita. Na primjer:

1. **Odgovori modela su stohastiÄki.** _Isti upit_ vjerojatno Ä‡e proizvesti razliÄite odgovore s razliÄitim modelima ili verzijama modela. I moÅ¾e Äak proizvesti razliÄite rezultate s _istim modelom_ u razliÄitim vremenima. _Tehnike projektiranja upita mogu nam pomoÄ‡i da minimiziramo te varijacije pruÅ¾anjem boljih ograda_.

2. **Modeli mogu izmiÅ¡ljati odgovore.** Modeli su unaprijed obuÄeni s _velikim, ali konaÄnim_ skupovima podataka, Å¡to znaÄi da im nedostaje znanje o pojmovima izvan tog opsega obuke. Kao rezultat toga, mogu proizvesti dovrÅ¡etke koji su netoÄni, izmiÅ¡ljeni ili izravno proturjeÄni poznatim Äinjenicama. _Tehnike projektiranja upita pomaÅ¾u korisnicima identificirati i ublaÅ¾iti takve izmiÅ¡ljotine, npr. traÅ¾enjem AI-ja za citatima ili razlozima_.

3. **Sposobnosti modela Ä‡e varirati.** Noviji modeli ili generacije modela imat Ä‡e bogatije sposobnosti, ali takoÄ‘er donose jedinstvene hirove i kompromise u troÅ¡kovima i sloÅ¾enosti. _Projektiranje upita moÅ¾e nam pomoÄ‡i da razvijemo najbolje prakse i tijekove rada koji apstrahiraju razlike i prilagoÄ‘avaju se zahtjevima specifiÄnim za model na skalabilan, besprijekoran naÄin_.

Pogledajmo ovo u akciji u OpenAI ili Azure OpenAI Playground:

- Koristite isti upit s razliÄitim LLM implementacijama (npr. OpenAI, Azure OpenAI, Hugging Face) - jeste li vidjeli varijacije?
- Koristite isti upit viÅ¡e puta s _istom_ LLM implementacijom (npr. Azure OpenAI playground) - kako su se te varijacije razlikovale?

### Primjer izmiÅ¡ljotina

U ovom teÄaju koristimo izraz **"izmiÅ¡ljotina"** kako bismo oznaÄili fenomen gdje LLM-ovi ponekad generiraju ÄinjeniÄno netoÄne informacije zbog ograniÄenja u svojoj obuci ili drugim ograniÄenjima. MoÅ¾da ste takoÄ‘er Äuli da se to naziva _"halucinacijama"_ u popularnim Älancima ili istraÅ¾ivaÄkim radovima. MeÄ‘utim, snaÅ¾no preporuÄujemo koriÅ¡tenje izraza _"izmiÅ¡ljotina"_ kako ne bismo sluÄajno antropomorfizirali ponaÅ¡anje pripisujuÄ‡i ljudsku osobinu ishodu koji pokreÄ‡e stroj. Ovo takoÄ‘er pojaÄava [smjernice za odgovornu AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) iz perspektive terminologije, uklanjajuÄ‡i termine koji se u nekim kontekstima takoÄ‘er mogu smatrati uvredljivima ili neinkluzivnima.

Å½elite li dobiti osjeÄ‡aj kako izmiÅ¡ljotine funkcioniraju? Zamislite upit koji upuÄ‡uje AI da generira sadrÅ¾aj za nepostojeÄ‡u temu (kako bi se osiguralo da nije pronaÄ‘ena u skupu podataka za obuku). Na primjer - isprobao sam ovaj upit:

> **Upit:** generiraj plan lekcije o Marsovskom ratu 2076.

Web pretraga mi je pokazala da postoje izmiÅ¡ljeni prikazi (npr. televizijske serije ili knjige) o Marsovskim ratovima - ali nijedan 2076. Zdrav razum nam takoÄ‘er govori da je 2076. _u buduÄ‡nosti_ i stoga se ne moÅ¾e povezati s stvarnim dogaÄ‘ajem.

Pa Å¡to se dogaÄ‘a kada pokrenemo ovaj upit s razliÄitim pruÅ¾ateljima LLM-a?

Kao Å¡to se oÄekivalo, svaki model (ili verzija modela) proizvodi malo drugaÄije odgovore zahvaljujuÄ‡i stohastiÄkom ponaÅ¡anju i varijacijama u sposobnostima modela. Na primjer, jedan model cilja publiku osmog razreda, dok drugi pretpostavlja srednjoÅ¡kolskog uÄenika. Ali svi su modeli generirali odgovore koji bi mogli uvjeriti neinformiranog korisnika da je dogaÄ‘aj stvaran.

Tehnike projektiranja upita poput _metapromptiranja_ i _konfiguracije temperature_ mogu smanjiti izmiÅ¡ljotine modela do odreÄ‘ene mjere. Nove _arhitekture_ projektiranja upita takoÄ‘er besprijekorno integriraju nove alate i tehnike u tijek upita kako bi ublaÅ¾ile ili smanjile neke od ovih efekata.

## Studija sluÄaja: GitHub Copilot

ZavrÅ¡imo ovaj odjeljak dobivanjem osjeÄ‡aja za to kako se projektiranje upita koristi u stvarnim rjeÅ¡enjima, pogledom na jednu Studiju sluÄaja: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot je vaÅ¡ "AI parni programer" - pretvara tekstualne upite u dovrÅ¡etke koda i integriran je u vaÅ¡e razvojno okruÅ¾enje (npr. Visual Studio Code) za besprijekorno korisniÄko iskustvo. Kao Å¡to je dokumentirano u seriji blogova u nastavku, najranija verzija temeljila se na OpenAI Codex modelu - s inÅ¾enjerima
KonaÄna vrijednost predloÅ¾aka leÅ¾i u sposobnosti stvaranja i objavljivanja _biblioteka promptova_ za vertikalne domene primjene - gdje je predloÅ¾ak prompta sada _optimiziran_ kako bi odraÅ¾avao kontekst specifiÄan za aplikaciju ili primjere koji Äine odgovore relevantnijima i toÄnijima za ciljanu publiku korisnika. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) repozitorij je izvrstan primjer ovog pristupa, kreirajuÄ‡i biblioteku promptova za obrazovni domen s naglaskom na kljuÄne ciljeve kao Å¡to su planiranje lekcija, dizajn kurikuluma, poduÄavanje studenata itd.

## PomoÄ‡ni SadrÅ¾aj

Ako razmiÅ¡ljamo o konstrukciji promptova kao o zadatku (instrukciji) i cilju (primarni sadrÅ¾aj), tada je _sekundarni sadrÅ¾aj_ poput dodatnog konteksta koji pruÅ¾amo kako bismo **na neki naÄin utjecali na ishod**. To mogu biti parametri podeÅ¡avanja, upute za formatiranje, taksonomije tema itd. koji mogu pomoÄ‡i modelu da _prilagodi_ svoj odgovor kako bi odgovarao Å¾eljenim ciljevima ili oÄekivanjima korisnika.

Na primjer: DajuÄ‡i katalog teÄajeva s opseÅ¾nim metapodacima (naziv, opis, razina, oznake metapodataka, instruktor itd.) o svim dostupnim teÄajevima u kurikulumu:

- moÅ¾emo definirati instrukciju za "saÅ¾imanje kataloga teÄajeva za jesen 2023."
- moÅ¾emo koristiti primarni sadrÅ¾aj da pruÅ¾imo nekoliko primjera Å¾eljenog ishoda
- moÅ¾emo koristiti sekundarni sadrÅ¾aj da identificiramo top 5 "oznaka" od interesa.

Sada, model moÅ¾e pruÅ¾iti saÅ¾etak u formatu prikazanom kroz nekoliko primjera - ali ako rezultat ima viÅ¡e oznaka, moÅ¾e dati prioritet 5 oznaka identificiranih u sekundarnom sadrÅ¾aju.

---

<!--
PREDLOÅ½AK LEKCIJE:
Ova jedinica treba pokriti osnovni koncept #1.
OjaÄajte koncept s primjerima i referencama.

KONCEPT #3:
Tehnike InÅ¾enjeringa Promptova.
Koje su neke osnovne tehnike za inÅ¾enjering promptova?
Ilustrirajte to s nekim vjeÅ¾bama.
-->

## Najbolje Prakse za Promptiranje

Sada kada znamo kako se promptovi mogu _konstruirati_, moÅ¾emo poÄeti razmiÅ¡ljati o tome kako ih _dizajnirati_ da odraÅ¾avaju najbolje prakse. MoÅ¾emo o tome razmiÅ¡ljati u dva dijela - imati pravi _mentalni sklop_ i primijeniti prave _tehnike_.

### Mentalni Sklop za InÅ¾enjering Promptova

InÅ¾enjering promptova je proces pokuÅ¡aja i pogreÅ¡aka, pa imajte na umu tri Å¡iroka Äimbenika:

1. **Razumijevanje Domena je vaÅ¾no.** ToÄnost i relevantnost odgovora funkcija je _domena_ u kojem ta aplikacija ili korisnik djeluje. Primijenite svoju intuiciju i struÄnost u domeni kako biste dodatno **prilagodili tehnike**. Na primjer, definirajte _specifiÄne osobnosti za domenu_ u vaÅ¡im sistemskim promptovima ili koristite _specifiÄne predloÅ¡ke za domenu_ u vaÅ¡im korisniÄkim promptovima. PruÅ¾ite sekundarni sadrÅ¾aj koji odraÅ¾ava kontekste specifiÄne za domenu ili koristite _specifiÄne znakove i primjere za domenu_ kako biste vodili model prema poznatim obrascima koriÅ¡tenja.

2. **Razumijevanje Modela je vaÅ¾no.** Znamo da su modeli po prirodi stohastiÄki. Ali implementacije modela takoÄ‘er mogu varirati u pogledu skupa podataka za obuku koji koriste (prethodno nauÄeno znanje), moguÄ‡nosti koje pruÅ¾aju (npr. putem API-ja ili SDK-a) i vrste sadrÅ¾aja za koje su optimizirani (npr. kod vs. slike vs. tekst). Razumijte snage i ograniÄenja modela koji koristite i koristite to znanje za _prioritizaciju zadataka_ ili izgradnju _prilagoÄ‘enih predloÅ¾aka_ optimiziranih za sposobnosti modela.

3. **Iteracija i Validacija su vaÅ¾ne.** Modeli se brzo razvijaju, kao i tehnike za inÅ¾enjering promptova. Kao struÄnjak za domenu, moÅ¾da imate drugi kontekst ili kriterije za _vaÅ¡u_ specifiÄnu primjenu, koji moÅ¾da ne vrijede za Å¡iru zajednicu. Koristite alate i tehnike za inÅ¾enjering promptova da "zapoÄnete" konstrukciju promptova, a zatim iterirajte i validirajte rezultate koristeÄ‡i vlastitu intuiciju i struÄnost u domeni. ZabiljeÅ¾ite svoje uvide i stvorite **bazu znanja** (npr. biblioteke promptova) koja se moÅ¾e koristiti kao nova osnovica od strane drugih, za brÅ¾e iteracije u buduÄ‡nosti.

## Najbolje Prakse

Pogledajmo sada uobiÄajene najbolje prakse koje preporuÄuju [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) i [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) praktiÄari.

| Å to                                | ZaÅ¡to                                                                                                                                                                                                                                             |
| :--------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Procijenite najnovije modele.      | Nova generacija modela vjerojatno Ä‡e imati poboljÅ¡ane znaÄajke i kvalitetu - ali moÅ¾e takoÄ‘er donijeti veÄ‡e troÅ¡kove. Procijenite ih za utjecaj, a zatim donesite odluke o migraciji.                                                             |
| Odvojite upute i kontekst          | Provjerite definira li vaÅ¡ model/davatelj _graniÄnike_ kako bi jasnije razlikovao upute, primarni i sekundarni sadrÅ¾aj. To moÅ¾e pomoÄ‡i modelima da toÄnije dodijele teÅ¾ine tokenima.                                                              |
| Budite specifiÄni i jasni          | Dajte viÅ¡e detalja o Å¾eljenom kontekstu, ishodu, duljini, formatu, stilu itd. To Ä‡e poboljÅ¡ati i kvalitetu i dosljednost odgovora. Uhvatite recepte u ponovno upotrebljivim predloÅ¡cima.                                                          |
| Budite opisni, koristite primjere  | Modeli mogu bolje odgovarati na pristup "pokaÅ¾i i reci". PoÄnite s `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an â€œoutâ€           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` vrijednostima. Vratite se na [Odjeljak Sandbox za uÄenje](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) da nauÄite kako.

### Zatim, otvorite Jupyter Notebook

- Odaberite runtime kernel. Ako koristite opcije 1 ili 2, jednostavno odaberite zadani Python 3.10.x kernel koji pruÅ¾a razvojni kontejner.

Sve je spremno za izvoÄ‘enje vjeÅ¾bi. Imajte na umu da ovdje nema _toÄnih i netoÄnih_ odgovora - samo istraÅ¾ujemo opcije metodom pokuÅ¡aja i pogreÅ¡aka i gradimo intuiciju za ono Å¡to funkcionira za odreÄ‘eni model i domenu primjene.

_Iz tog razloga u ovoj lekciji nema segmenata s rjeÅ¡enjem koda. Umjesto toga, Notebook Ä‡e imati Markdown Ä‡elije naslovljene "Moje rjeÅ¡enje:" koje prikazuju jedan primjer izlaza za referencu._

 <!--
PREDLOÅ½AK LEKCIJE:
ZavrÅ¡ite odjeljak sa saÅ¾etkom i resursima za samostalno uÄenje.
-->

## Provjera Znanja

Koji od sljedeÄ‡ih je dobar prompt koji slijedi neke razumne najbolje prakse?

1. PokaÅ¾i mi sliku crvenog automobila
2. PokaÅ¾i mi sliku crvenog automobila marke Volvo i modela XC90 parkiranog uz liticu sa zalaskom sunca
3. PokaÅ¾i mi sliku crvenog automobila marke Volvo i modela XC90

A: 2, to je najbolji prompt jer pruÅ¾a detalje o "Äemu" i ide u specifiÄnosti (ne samo bilo koji automobil, veÄ‡ odreÄ‘ena marka i model) i takoÄ‘er opisuje cjelokupni ambijent. 3 je sljedeÄ‡i najbolji jer takoÄ‘er sadrÅ¾i puno opisa.

## ğŸš€ Izazov

Provjerite moÅ¾ete li iskoristiti tehniku "znaka" s promptom: DovrÅ¡ite reÄenicu "PokaÅ¾i mi sliku crvenog automobila marke Volvo i ". S Äime odgovara i kako biste to poboljÅ¡ali?

## OdliÄan Rad! Nastavite UÄiti

Å½elite li saznati viÅ¡e o razliÄitim konceptima InÅ¾enjeringa Promptova? Idite na [stranicu za kontinuirano uÄenje](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste pronaÅ¡li druge izvrsne resurse o ovoj temi.

Idite na Lekciju 5 gdje Ä‡emo pogledati [napredne tehnike promptiranja](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Odricanje odgovornosti**:
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako teÅ¾imo toÄnosti, imajte na umu da automatizirani prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni ljudski prijevod. Ne odgovaramo za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.