# Osnove prompt inÅ¾enjeringa

[![Osnove prompt inÅ¾enjeringa](../../../translated_images/hr/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Uvod
Ovaj modul pokriva osnovne pojmove i tehnike za izradu uÄinkovitih promptova u generativnim AI modelima. NaÄin na koji piÅ¡ete svoj prompt za LLM takoÄ‘er je vaÅ¾an. PaÅ¾ljivo izraÄ‘eni prompt moÅ¾e postiÄ‡i bolju kvalitetu odgovora. Ali Å¡to toÄno znaÄe pojmovi poput _prompt_ i _prompt inÅ¾enjering_? I kako poboljÅ¡ati prompt _ulaz_ koji Å¡aljem LLM-u? To su pitanja na koja Ä‡emo pokuÅ¡ati odgovoriti u ovom i sljedeÄ‡em poglavlju.

_Generativna AI_ je sposobna stvarati novi sadrÅ¾aj (npr. tekst, slike, audio, kod itd.) kao odgovor na korisniÄke zahtjeve. To postiÅ¾e koriÅ¡tenjem _velikih jeziÄnih modela_ poput OpenAI-jeve GPT ("Generative Pre-trained Transformer") serije koji su trenirani za rad s prirodnim jezikom i kodom.

Korisnici sada mogu komunicirati s tim modelima koristeÄ‡i poznate paradigme poput chata, bez potrebe za tehniÄkim znanjem ili obukom. Modeli su _prompt-bazirani_ - korisnici Å¡alju tekstualni unos (prompt) i dobivaju AI odgovor (dovrÅ¡etak). Zatim mogu "razgovarati s AI-em" iterativno, u viÅ¡ekruÅ¾nim konverzacijama, usavrÅ¡avajuÄ‡i svoj prompt dok odgovor ne zadovolji njihova oÄekivanja.

"Prompti" sada postaju glavno _programsko suÄelje_ za generativne AI aplikacije, govoreÄ‡i modelima Å¡to da rade i utjeÄuÄ‡i na kvalitetu vraÄ‡enih odgovora. "Prompt inÅ¾enjering" je brzo rastuÄ‡e podruÄje istraÅ¾ivanja koje se fokusira na _dizajn i optimizaciju_ promptova kako bi se isporuÄili dosljedni i kvalitetni odgovori u velikom opsegu.

## Ciljevi uÄenja

U ovom satu uÄimo Å¡to je prompt inÅ¾enjering, zaÅ¡to je vaÅ¾an i kako moÅ¾emo izraditi uÄinkovitije prompte za odreÄ‘eni model i cilj aplikacije. Razumjet Ä‡emo osnovne pojmove i najbolje prakse za prompt inÅ¾enjering â€“ te upoznati interaktivno Jupyter Notebook "sandbox" okruÅ¾enje gdje moÅ¾emo vidjeti primjenu tih koncepata na stvarnim primjerima.

Na kraju ovog sata moÄ‡i Ä‡emo:

1. Objasniti Å¡to je prompt inÅ¾enjering i zaÅ¡to je vaÅ¾an.
2. Opisati komponente prompta i kako se koriste.
3. NauÄiti najbolje prakse i tehnike za prompt inÅ¾enjering.
4. Primijeniti nauÄene tehnike na stvarne primjere, koristeÄ‡i OpenAI endpoint.

## KljuÄni pojmovi

Prompt inÅ¾enjering: Praksa dizajniranja i usavrÅ¡avanja unosa kako bi se AI modeli usmjerili na proizvodnju Å¾eljenih rezultata.  
Tokenizacija: Proces pretvaranja teksta u manje jedinice, zvane tokeni, koje model moÅ¾e razumjeti i obraditi.  
Instruction-Tuned LLMs: Veliki jeziÄni modeli (LLM) koji su dodatno trenirani s specifiÄnim uputama za poboljÅ¡anje toÄnosti i relevantnosti odgovora.

## Sandbox za uÄenje

Prompt inÅ¾enjering je trenutaÄno viÅ¡e umjetnost nego znanost. Najbolji naÄin da poboljÅ¡amo intuiciju jest _viÅ¡e vjeÅ¾bati_ i usvojiti pristup pokuÅ¡aja i pogreÅ¡aka koji kombinira struÄnost u podruÄju primjene s preporuÄenim tehnikama i optimizacijama specifiÄnim za model.

Jupyter Notebook koji prati ovaj sat pruÅ¾a _sandbox_ okruÅ¾enje gdje moÅ¾ete isprobati Å¡to ste nauÄili â€“ tijekom rada ili kao dio izazova koda na kraju. Za izvrÅ¡avanje vjeÅ¾bi potreban vam je:

1. **Azure OpenAI API kljuÄ** â€“ servisni endpoint za implementirani LLM.  
2. **Python runtime** â€“ u kojem se moÅ¾e izvrÅ¡iti Notebook.  
3. **Lokalne varijable okoline** â€“ _sada dovrÅ¡ite [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) korake da se pripremite_.

Notebook dolazi s _poÄetnim_ vjeÅ¾bama â€“ ali potiÄemo vas da dodate vlastite sekcije s _Markdown_ (opis) i _Code_ (zahtjevi prompta) kako biste isprobali viÅ¡e primjera ili ideja â€“ te gradili svoju intuiciju za dizajn promptova.

## Ilustrirani vodiÄ

Å½elite li dobiti cjelovitu sliku onoga Å¡to ovaj sat pokriva prije nego Å¡to krenete? Pogledajte ovaj ilustrirani vodiÄ koji Vam pruÅ¾a pregled glavnih tema i kljuÄnih poruka za razmiÅ¡ljanje. VodiÄ kroz sat vodi vas od razumijevanja osnovnih pojmova i izazova do njihovog rjeÅ¡avanja relevantnim tehnikama i najboljim praksama prompt inÅ¾enjeringa. Imajte na umu da se odjeljak "Napredne tehnike" u ovom vodiÄu odnosi na sadrÅ¾aj pokriven u _sljedeÄ‡em_ poglavlju ovog kurikuluma.

![Ilustrirani vodiÄ za prompt inÅ¾enjering](../../../translated_images/hr/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## NaÅ¡ startup

Sad, razgovarajmo o tome kako se _ova tema_ povezuje s naÅ¡om misijom startupa da [donesemo AI inovacije u obrazovanje](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Å½elimo izraditi AI-pokretane aplikacije za _personalizirano uÄenje_ â€“ pa razmislimo kako razliÄiti korisnici naÅ¡e aplikacije mogu "dizajnirati" prompte:

- **Administratori** mogu traÅ¾iti AI od _analize kurikuluma kako bi identificirali praznine u pokrivenosti_. AI moÅ¾e saÅ¾eti rezultate ili ih vizualizirati kodom.  
- **Nastavnici** mogu traÅ¾iti AI od _generiranja plana nastave za ciljno publiku i temu_. AI moÅ¾e izraditi personalizirani plan u zadanom formatu.  
- **UÄenici** mogu traÅ¾iti AI da ih _poduÄava u teÅ¡koj temi_. AI Ä‡e voditi uÄenike lekcijama, savjetima i primjerima prilagoÄ‘enim njihovoj razini.

To je samo vrh ledenog brijega. Pogledajte [Prompte za obrazovanje](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) â€“ open-source biblioteku promptova koju su kurirali obrazovni struÄnjaci â€“ da biste dobili Å¡iri dojam o moguÄ‡nostima! _Isprobajte neke od tih promptova u sandboxu ili koristeÄ‡i OpenAI Playground i vidite Å¡to Ä‡e se dogoditi!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Å to je Prompt InÅ¾enjering?

ZapoÄeli smo ovaj sat definiranjem **prompt inÅ¾enjeringa** kao procesa _dizajniranja i optimizacije_ tekstualnih unosa (promptova) za postizanje dosljednih i kvalitetnih odgovora (dovrÅ¡etaka) za odreÄ‘eni cilj aplikacije i model. To moÅ¾emo zamisliti kao proces u dva koraka:

- _dizajniranje_ poÄetnog prompta za odreÄ‘eni model i cilj  
- _usavrÅ¡avanje_ prompta iterativno za poboljÅ¡anje kvalitete odgovora

To je nuÅ¾no proces pokuÅ¡aja i pogreÅ¡aka koji zahtijeva korisniÄku intuiciju i trud da bi se postigli optimalni rezultati. ZaÅ¡to je to vaÅ¾no? Za odgovor prvo trebamo razumjeti tri pojma:

- _Tokenizacija_ = kako model "vidi" prompt  
- _Osnovni LLM_ = kako temeljni model "obraÄ‘uje" prompt  
- _Instruction-Tuned LLM_ = kako model sada moÅ¾e "vidjeti zadatke"

### Tokenizacija

LLM vidi prompte kao _niz tokena_ gdje razliÄiti modeli (ili verzije modela) mogu tokenizirati isti prompt na razliÄite naÄine. BuduÄ‡i da su LLM-ovi trenirani na tokenima (a ne na sirovom tekstu), naÄin na koji se prompt tokenizira direktno utjeÄe na kvalitetu generiranog odgovora.

Za intuiciju o tome kako funkcionira tokenizacija, isprobajte alate poput [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) prikazanog dolje. Kopirajte svoj prompt â€“ i pogledajte kako se pretvara u tokene, obraÄ‡ajuÄ‡i pozornost na to kako se tretiraju znakovi razmaka i interpunkcija. Imajte na umu da ovaj primjer prikazuje stariji LLM (GPT-3) â€“ pa isprobavanje s novijim modelom moÅ¾e dati drugaÄiji rezultat.

![Tokenizacija](../../../translated_images/hr/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Pojam: Temeljni modeli

Kad se prompt tokenizira, osnovna funkcija ["Osnovnog LLM-a"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ili temeljnog modela) je predvidjeti token u tom nizu. BuduÄ‡i da su LLM-ovi trenirani na ogromnim skupovima tekstualnih podataka, dobro poznaju statistiÄke odnose izmeÄ‘u tokena i mogu tu predikciju izvesti s odreÄ‘enom sigurnoÅ¡Ä‡u. Imajte na umu da oni ne razumiju _znaÄenje_ rijeÄi u promptu ili tokenu; oni samo vide obrazac koji mogu "dovrÅ¡iti" sljedeÄ‡om predikcijom. Mogu nastaviti predviÄ‘ati niz dok ih korisnik ne zaustavi ili se ne ispuni neki unaprijed postavljeni uvjet.

Å½elite li vidjeti kako radi dovrÅ¡avanje temeljeno na promptu? Unesite gornji prompt u Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) s zadanim postavkama. Sustav je konfiguriran da tretira prompte kao zahtjeve za informacijama â€“ tako da biste trebali vidjeti dovrÅ¡etak koji zadovoljava taj kontekst.

No Å¡to ako korisnik Å¾eli vidjeti neÅ¡to specifiÄno Å¡to zadovoljava neki kriterij ili cilj zadatka? Tu na scenu dolaze _instruction-tuned_ LLM-ovi.

![Osnovni LLM Chat dovrÅ¡etak](../../../translated_images/hr/04-playground-chat-base.65b76fcfde0caa67.webp)

### Pojam: Instruction-Tuned LLM

[Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zapoÄinje s temeljnim modelom i dodatno ga trenira s primjerima ili parovima ulaz/izlaz (npr. viÅ¡ekruÅ¾nim "porukama") koje mogu sadrÅ¾avati jasne upute â€“ a odgovor AI-a pokuÅ¡ava slijediti te upute.

Koriste se tehnike poput uÄenja potkrepljenog povratnom informacijom od ljudi (RLHF) koje model treniraju da _slijedi upute_ i _uÄi iz povratnih informacija_, tako da generira odgovore koji su prikladniji za praktiÄne primjene i relevantniji prema ciljevima korisnika.

Isprobajmo to â€“ vratite se na gore navedeni prompt, ali sada promijenite _sistemsku poruku_ da pruÅ¾i sljedeÄ‡u uputu kao kontekst:

> _SaÅ¾mi sadrÅ¾aj koji ti je dan za uÄenika drugog razreda. OgraniÄi rezultat na jedan odlomak s 3-5 toÄaka._

Vidite li kako je rezultat sada namjeÅ¡ten da odraÅ¾ava Å¾eljeni cilj i format? Nastavnik sada moÅ¾e direktno koristiti taj odgovor u svojim prezentacijama za tu nastavu.

![Instruction Tuned LLM Chat dovrÅ¡etak](../../../translated_images/hr/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## ZaÅ¡to trebamo prompt inÅ¾enjering?

Sad kad znamo kako modeli obraÄ‘uju prompte, razgovarajmo o _zaÅ¡to_ nam treba prompt inÅ¾enjering. Odgovor leÅ¾i u Äinjenici da trenutni LLM-ovi predstavljaju nekoliko izazova zbog kojih je teÅ¾e postiÄ‡i _pouzdane i dosljedne dovrÅ¡etke_ bez uloÅ¾enog truda u izgradnju i optimizaciju promptova. Na primjer:

1. **Odgovori modela su stohastiÄki.** _Isti prompt_ vjerojatno Ä‡e proizvesti razliÄite odgovore na razliÄitim modelima ili verzijama modela. ÄŒak moÅ¾e dati razliÄite rezultate s _istim modelom_ u razliÄito vrijeme. _Tehnike prompt inÅ¾enjeringa mogu nam pomoÄ‡i minimizirati ova odstupanja dajuÄ‡i bolje zaÅ¡titne ograde_.

1. **Modeli mogu izmiÅ¡ljati odgovore.** Modeli su predtrenirani na _velikim ali konaÄnim_ skupovima podataka, Å¡to znaÄi da nemaju znanje o konceptima izvan tog skupa podataka. Kao rezultat, mogu generirati dovrÅ¡etke koji su netoÄni, izmiÅ¡ljeni ili izravno suprotstavljeni poznatim Äinjenicama. _Tehnike prompt inÅ¾enjeringa pomaÅ¾u korisnicima identificirati i ublaÅ¾iti takve izmiÅ¡ljotine, npr. traÅ¾enjem citata ili obrazloÅ¾enja od AI-a_.

1. **Sposobnosti modela Ä‡e varirati.** Noviji modeli ili generacije modela imaju bogatije sposobnosti, ali donose i posebne neobiÄnosti i kompromise u troÅ¡kovima i sloÅ¾enosti. _Prompt inÅ¾enjering moÅ¾e pomoÄ‡i u razvoju najboljih praksi i tijekova rada koji apstrahiraju razlike i prilagoÄ‘avaju se zahtjevima specifiÄnim za model na skalabilan i neprimjetan naÄin_.

Pogledajmo to u akciji u OpenAI ili Azure OpenAI Playgroundu:

- Koristite isti prompt s razliÄitim LLM implementacijama (npr. OpenAI, Azure OpenAI, Hugging Face) â€“ jeste li vidjeli varijacije?  
- Koristite isti prompt viÅ¡e puta s _istom_ LLM implementacijom (npr. Azure OpenAI playground) â€“ kako su te varijacije bile razliÄite?

### Primjer izmiÅ¡ljotina

U ovom teÄaju koristimo pojam **"izmiÅ¡ljotina"** za fenomen kad LLM-ovi ponekad generiraju faktualno netoÄne informacije zbog ograniÄenja u treningu ili drugih uvjeta. MoÅ¾da ste ovaj fenomen Äuli i kao _"halucinacije"_ u popularnim Älancima ili istraÅ¾ivaÄkim radovima. MeÄ‘utim, snaÅ¾no preporuÄujemo koriÅ¡tenje termina _"izmiÅ¡ljotina"_ kako bismo izbjegli antropomorfiziranje ponaÅ¡anja dodjeljivanjem osobine sliÄne Äovjeku stroju. Ovo takoÄ‘er podrÅ¾ava [Smernice za odgovornu AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) s aspekta terminologije, uklanjajuÄ‡i pojmove koji mogu biti uvredljivi ili neinkluzivni u nekim kontekstima.

Å½elite li dobiti dojam kako izmiÅ¡ljotine funkcioniraju? Zamislite prompt koji AI-u daje uputu da generira sadrÅ¾aj za nepostojeÄ‡u temu (da ne bi bila prisutna u trening skupu podataka). Na primjer â€“ isprobao sam ovaj prompt:

> **Prompt:** generiraj plan lekcije o Marsovskoj ratu 2076. godine.
PretraÅ¾ivanje na webu pokazalo mi je da postoje fiktivni prikazi (npr. televizijske serije ili knjige) o ratovima na Marsu - ali nijedan iz 2076. Zdrav razum nam takoÄ‘er govori da je 2076. _u buduÄ‡nosti_ i stoga ne moÅ¾e biti povezan s pravim dogaÄ‘ajem.

Pa Å¡to se dogaÄ‘a kada ovaj upit pokrenemo kod razliÄitih LLM pruÅ¾atelja usluga?

> **Odgovor 1**: OpenAI Playground (GPT-35)

![Response 1](../../../translated_images/hr/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Odgovor 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../../translated_images/hr/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Odgovor 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../../translated_images/hr/04-fabrication-huggingchat.faf82a0a51278956.webp)

Kao Å¡to se i oÄekivalo, svaki model (ili verzija modela) proizvodi pomalo razliÄite odgovore zahvaljujuÄ‡i stohastiÄkom ponaÅ¡anju i varijacijama u sposobnostima modela. Na primjer, jedan model cilja na publiku osmoga razreda, dok drugi pretpostavlja uÄenika srednje Å¡kole. Ali sva tri modela generirala su odgovore koji bi mogli uvjeriti neupuÄ‡enog korisnika da je dogaÄ‘aj stvaran.

Tehnike dizajna upita poput _metaupita_ i _konfiguracije temperature_ mogu donekle smanjiti izmiÅ¡ljotine modela. Nove arhitekture dizajna upita takoÄ‘er beÅ¡avno uklapaju nove alate i tehnike u tijek upita, kako bi ublaÅ¾ile ili smanjile neke od tih efekata.

## Studija sluÄaja: GitHub Copilot

ZavrÅ¡imo ovaj odjeljak tako da steknemo dojam kako se dizajn upita koristi u rjeÅ¡enjima u stvarnom svijetu, pogledom na jednu Studiju sluÄaja: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot je vaÅ¡ "AI par-programer" â€“ pretvara tekstualne upite u dovrÅ¡etke koda i integriran je u vaÅ¡e razvojno okruÅ¾enje (npr. Visual Studio Code) za besprijekorno korisniÄko iskustvo. Kao Å¡to je dokumentirano u nizu blogova u nastavku, najranija verzija temeljila se na OpenAI Codex modelu â€“ uz brzo shvaÄ‡anje od strane inÅ¾enjera da je potrebno fino podeÅ¡avanje modela i razvoj boljih tehnika dizajna upita za poboljÅ¡anje kvalitete koda. U srpnju su [predstavili poboljÅ¡ani AI model koji ide dalje od Codexa](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) za joÅ¡ brÅ¾e prijedloge.

ProÄitajte postove redom kako biste pratili njihov put uÄenja.

- **Svibanj 2023** | [GitHub Copilot postaje bolji u razumijevanju vaÅ¡eg koda](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Svibanj 2023** | [Iznutra u GitHubu: Rad s LLM-ovima iza GitHub Copilota](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Lipanj 2023** | [Kako pisati bolje upite za GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Srpanj 2023** | [.. GitHub Copilot ide dalje od Codexa s poboljÅ¡anim AI modelom](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Srpanj 2023** | [VodiÄ za programere kroz dizajn upita i LLM-e](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Rujan 2023** | [Kako napraviti enterprise LLM aplikaciju: Lekcije iz GitHub Copilota](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

TakoÄ‘er moÅ¾ete pregledavati njihov [InÅ¾enjerski blog](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) za viÅ¡e postova poput [ovog](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) koji prikazuje kako se ovi modeli i tehnike _primjenjuju_ za pokretanje stvarnih aplikacija.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Izgradnja upita

VeÄ‡ smo vidjeli zaÅ¡to je dizajn upita vaÅ¾an â€“ sada razumijmo kako se upiti _izgraÄ‘uju_ da bismo mogli procijeniti razliÄite tehnike za uÄinkovitiji dizajn upita.

### Osnovni upit

PoÄnimo s osnovnim upitom: tekstualnim unosom poslanim modelu bez dodatnog konteksta. Evo primjera â€“ kada poÅ¡aljemo prve rijeÄi ameriÄke himne OpenAI [Completion API-ju](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), on odmah _dovrÅ¡i_ odgovor sljedeÄ‡im nekoliko redaka, ilustrirajuÄ‡i osnovno ponaÅ¡anje predviÄ‘anja.

| Upit (unos)       | DovrÅ¡etak (izlaz)                                                                                                                           |
| :---------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Izgleda da zapoÄinjete tekst "The Star-Spangled Banner," drÅ¾avne himne Sjedinjenih DrÅ¾ava. Cijeli tekst glasi ...                         |

### SloÅ¾eni upit

Sada dodajmo kontekst i upute tom osnovnom upitu. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) omoguÄ‡uje nam da sloÅ¾eni upit konstruiramo kao skup _poruka_ s:

- Parovima unos/izlaz koji odraÅ¾avaju korisniÄki upit i odgovor asistenta.
- Porukom sustava koja postavlja kontekst ponaÅ¡anja ili osobnosti asistenta.

Zahtjev je sada u obliku ispod, gdje _tokenizacija_ uÄinkovito hvata relevantne informacije iz konteksta i razgovora. Promjena sistemskog konteksta moÅ¾e biti jednako utjecajna na kvalitetu dovrÅ¡etaka kao i dani korisniÄki unosi.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Uputni upit

U gornjim primjerima, korisniÄki upit bio je jednostavan tekstualni upit koji se moÅ¾e interpretirati kao zahtjev za informacijom. Uz _upute_, moÅ¾emo koristiti taj tekst za detaljnije specificiranje zadatka, pruÅ¾ajuÄ‡i AI bolju smjernicu. Evo primjera:

| Upit (unos)                                                                                                                                                                                                                           | DovrÅ¡etak (izlaz)                                                                                                   | Tip upute          |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------ | :----------------- |
| NapiÅ¡i opis GraÄ‘anskog rata                                                                                                                                                                                                            | _vraÄ‡ena je jednostavna reÄenica_                                                                                  | Jednostavno        |
| NapiÅ¡i opis GraÄ‘anskog rata. Navedi kljuÄne datume i dogaÄ‘aje te opiÅ¡i njihov znaÄaj                                                                                                                                                  | _vratila se reÄenica praÄ‡ena popisom kljuÄnih datuma dogaÄ‘aja s opisima_                                            | SloÅ¾eno            |
| NapiÅ¡i opis GraÄ‘anskog rata u 1 odlomku. Navedi 3 stavke s kljuÄnim datumima i njihovim znaÄajem. Navedi joÅ¡ 3 stavke s vaÅ¾nim povijesnim osobama i njihovim doprinosima. Vrati izlaz kao JSON datoteku | _vraÄ‡a opseÅ¾niji tekst formatiran u JSON koji moÅ¾ete kopirati u datoteku i po potrebi validirati_                     | SloÅ¾eno. Formatirano. |

## Primarni sadrÅ¾aj

U gore navedenim primjerima, upit je joÅ¡ uvijek bio priliÄno otvoren, dopuÅ¡tajuÄ‡i LLM-u da odluÄi koji dio svog prethodno nauÄenog skupa podataka je relevantan. Uz dizajnerski uzorak _primarnog sadrÅ¾aja_, ulazni tekst dijeli se na dva dijela:

- uputa (akcija)
- relevantni sadrÅ¾aj (koji utjeÄe na akciju)

Evo primjera gdje je uputa "saÅ¾mi to u 2 reÄenice".

| Upit (unos)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | DovrÅ¡etak (izlaz)                                                                                                                                                                                                                                                       |
| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Jupiter je peti planet od Sunca i najveÄ‡i u SunÄevom sustavu. To je plinski div mase tisuÄ‡inu puta manje od Sunca, ali dvije i pol puta veÄ‡e od svih ostalih planeta u SunÄevom sustavu zajedno. Jupiter je jedan od najsjajnijih objekata vidljivih golim okom na noÄ‡nom nebu, poznat drevnim civilizacijama joÅ¡ prije zabiljeÅ¾ene povijesti. Ime je dobio po rimskom bogu Jupiteru.[19] Kada se promatra s Zemlje, Jupiter moÅ¾e biti dovoljno sjajan da odbaci vidljive sjene[20], i u prosjeku je treÄ‡i najsjajniji prirodni objekt na noÄ‡nom nebu nakon Mjeseca i Venere. <br/> **SaÅ¾mi ovo u 2 kratke reÄenice** | Jupiter, peti planet od Sunca, najveÄ‡i je u SunÄevom sustavu i poznat je kao jedan od najsjajnijih objekata na noÄ‡nom nebu. Ime je dobio po rimskom bogu Jupiteru i plinski je div Äija je masa dvije i pol puta veÄ‡a od mase svih ostalih planeta u SunÄevom sustavu zajedno. |

Segment primarnog sadrÅ¾aja moÅ¾e se koristiti na razliÄite naÄine za uÄinkovitije upute:

- **Primjeri** â€“ umjesto da modelu kaÅ¾emo Å¡to treba raditi eksplicitnom uputom, dajemo mu primjere onoga Å¡to treba napraviti i dopuÅ¡tamo mu da zakljuÄi uzorak.
- **Naznake** â€“ slijede uputu "naznakom" koja inicira dovrÅ¡etak, usmjeravajuÄ‡i model prema relevantnijim odgovorima.
- **PredloÅ¡ci** â€“ to su ponovljive 'recepte' za upite s rezerviranim mjestima (varijablama) koje se mogu prilagoditi podacima za specifiÄne sluÄajeve.

Pogledajmo kako to izgleda u praksi.

### KoriÅ¡tenje primjera

Ovo je pristup u kojem koristite primarni sadrÅ¾aj da "hranite model" nekim primjerima Å¾eljenog izlaza za odreÄ‘enu uputu i dopustite mu da zakljuÄi uzorak Å¾eljenog izlaza. Na temelju broja danih primjera, moÅ¾emo imati nula-shot, jedan-shot, few-shot i sl.

Upit sada sadrÅ¾i tri komponente:

- Opis zadatka
- Nekoliko primjera Å¾eljenog izlaza
- PoÄetak novog primjera (koji postaje implicitni opis zadatka)

| Tip uÄenja  | Upit (unos)                                                                                                                     | DovrÅ¡etak (izlaz)          |
| :---------- | :----------------------------------------------------------------------------------------------------------------------------- | :------------------------- |
| Nula-shot   | "The Sun is Shining". Prevedi na Å¡panjolski                                                                                   | "El Sol estÃ¡ brillando".   |
| Jedan-shot  | "The Sun is Shining" => ""El Sol estÃ¡ brillando". <br> "It's a Cold and Windy Day" =>                                          | "Es un dÃ­a frÃ­o y ventoso".|
| Few-shot    | IgraÄ je trÄao oko baza => Baseball <br/> IgraÄ je pogodio as => Tenis <br/> IgraÄ je pogodio Å¡esticu => Kriket <br/> IgraÄ je zabio zakucavanje => | KoÅ¡arka                    |
|             |                                                                                                                                |                            |

Primijetite kako smo morali dati eksplicitnu uputu ("Prevedi na Å¡panjolski") u nula-shot pristupu, ali (ona) se prepoznaje u primjeru jedan-shot. Few-shot primjer pokazuje kako dodavanje viÅ¡e primjera omoguÄ‡uje modelima da preciznije zakljuÄuju bez dodatnih uputa.

### Naznake upita

Druga tehnika za koriÅ¡tenje primarnog sadrÅ¾aja jest davanje _naznaka_ umjesto primjera. U tom sluÄaju dajemo modelu lagani poticaj u pravom smjeru tako Å¡to ga _poÄinje_ s isjeÄkom koji odraÅ¾ava Å¾eljeni format odgovora. Model potom "uzima naznaku" da nastavi u tom stilu.

| Broj naznaka | Upit (unos)                                                                                                                                                                                                                                                                                                                                                                                                                                               | DovrÅ¡etak (izlaz)                                                                                                                                                                                                                                                                                       |
| :----------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 0            | Jupiter je peti planet od Sunca i najveÄ‡i u SunÄevom sustavu. To je plinski div mase tisuÄ‡inu puta manje od Sunca, ali dvije i pol puta veÄ‡e od svih ostalih planeta u SunÄevom sustavu zajedno. Jupiter je jedan od najsjajnijih objekata vidljivih golim okom na noÄ‡nom nebu, poznat drevnim civilizacijama joÅ¡ prije zabiljeÅ¾ene povijesti. <br/>**SaÅ¾mi ovo**                                               | Jupiter je najveÄ‡i planet u naÅ¡em SunÄevom sustavu i peti je po redu od Sunca. To je plinski div mase 1/1000 masa Sunca, ali teÅ¾i viÅ¡e od svih ostalih planeta zajedno. Drevne su civilizacije jako dugo znale za Jupitera i lako je vidljiv na noÄ‡nom nebu.                                                           |
| 1              | Jupiter je peta planeta od Sunca i najveÄ‡a u SunÄevom sustavu. To je plinski div s masom tisuÄ‡inku SunÄeve, ali dvije i pol puta veÄ‡om od svih ostalih planeta u SunÄevom sustavu zajedno. Jupiter je jedan od najsvjetlijih objekata vidljivih golim okom na noÄ‡nom nebu i poznat je starim civilizacijama joÅ¡ iz predzabiljeÅ¾ene povijesti. <br/>**SaÅ¾etak** <br/> Ono Å¡to smo nauÄili jest da je Jupiter | peta planeta od Sunca i najveÄ‡a u SunÄevom sustavu. To je plinski div s masom tisuÄ‡inku SunÄeve, ali dvije i pol puta veÄ‡om od svih ostalih planeta zajedno. Lako je vidljiv golim okom i poznat je od davnina.                        |
| 2              | Jupiter je peta planeta od Sunca i najveÄ‡a u SunÄevom sustavu. To je plinski div s masom tisuÄ‡inku SunÄeve, ali dvije i pol puta veÄ‡om od svih ostalih planeta u SunÄevom sustavu zajedno. Jupiter je jedan od najsvjetlijih objekata vidljivih golim okom na noÄ‡nom nebu i poznat je starim civilizacijama joÅ¡ iz predzabiljeÅ¾ene povijesti. <br/>**SaÅ¾etak** <br/> 3 najvaÅ¾nije Äinjenice koje smo nauÄili:         | 1. Jupiter je peta planeta od Sunca i najveÄ‡a u SunÄevom sustavu. <br/> 2. To je plinski div s masom tisuÄ‡inku SunÄeve...<br/> 3. Jupiter je golim okom vidljiv od davnina ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### PredloÅ¡ci upita

PredloÅ¾ak upita je _unaprijed definirani recept za upit_ koji se moÅ¾e pohraniti i ponovno upotrijebiti prema potrebi kako bi se postiglo dosljednije korisniÄko iskustvo u velikom opsegu. U svom najjednostavnijem obliku to je jednostavno zbirka primjera upita poput [ovog iz OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) koji pruÅ¾a i interaktivne komponente upita (poruke korisnika i sustava) i API format zahtjeva - za podrÅ¡ku ponovnoj upotrebi.

U sloÅ¾enijem obliku kao [ovaj primjer iz LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) sadrÅ¾i _zamjenske oznake_ koje se mogu zamijeniti podacima iz razliÄitih izvora (korisniÄki unos, kontekst sustava, vanjski izvori podataka itd.) za dinamiÄko generiranje upita. To nam omoguÄ‡uje stvaranje biblioteke ponovljivo upotrebljivih upita kojima se moÅ¾e programatski upravljati radi postizanja dosljednog korisniÄkog iskustva u velikom opsegu.

Na kraju, stvarna vrijednost predloÅ¾aka leÅ¾i u moguÄ‡nosti stvaranja i objavljivanja _biblioteka upita_ za vertikalne aplikacijske domene - gdje je predloÅ¾ak upita sada _optimiziran_ kako bi odraÅ¾avao kontekst specifiÄan za aplikaciju ili primjere koji Äine odgovore relevantnijima i preciznijima za ciljanu korisniÄku publiku. SpremiÅ¡te [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) izvrstan je primjer takvog pristupa, sakupljajuÄ‡i biblioteku upita za obrazovni domen s naglaskom na kljuÄne ciljeve poput planiranja lekcija, dizajna kurikuluma, poduÄavanja uÄenika i sliÄno.

## PomoÄ‡ni sadrÅ¾aj

Ako promatramo konstrukciju upita kao kombinaciju upute (zadatka) i cilja (primarni sadrÅ¾aj), tada je _sekundarni sadrÅ¾aj_ poput dodatnog konteksta koji pruÅ¾amo kako bismo **na neki naÄin utjecali na izlaz**. To mogu biti parametri podeÅ¡avanja, upute za oblikovanje, taksonomije tema i sliÄno, Å¡to modelu pomaÅ¾e da _prilagodi_ svoj odgovor da udovolji Å¾eljenim korisniÄkim ciljevima ili oÄekivanjima.

Na primjer: Imamo katalog kolegija s opÅ¡irnim metapodacima (naziv, opis, razina, oznake metapodataka, predavaÄ itd.) o svim dostupnim kolegijima u programu:

- moÅ¾emo definirati uputu "saÅ¾mi katalog kolegija za jesen 2023."
- moÅ¾emo koristiti primarni sadrÅ¾aj za pruÅ¾anje nekoliko primjera Å¾eljenog rezultata
- moÅ¾emo koristiti sekundarni sadrÅ¾aj za identifikaciju pet najvaÅ¾nijih "oznatki"

Sada model moÅ¾e dati saÅ¾etak u formatu prikazanom primjerima - ali ako rezultat sadrÅ¾i viÅ¡e oznaka, moÅ¾e prioritetizirati pet oznaka identificiranih u sekundarnom sadrÅ¾aju.

---

<!--
LESSON TEMPLATE:
Ovaj odjeljak treba pokriti osnovni koncept #1.
OjaÄajte koncept primjerima i referencama.

KONCEPT #3:
Tehnike za izradu upita.
Koje su osnovne tehnike za izradu upita?
PrikaÅ¾ite to na vjeÅ¾bama.
-->

## Najbolje prakse za izradu upita

Sad kad znamo kako se upiti _konstruraju_, moÅ¾emo poÄeti razmiÅ¡ljati o tome kako ih _dizajnirati_ da odraÅ¾avaju najbolje prakse. To moÅ¾emo promatrati u dva dijela â€“ imati pravi _stav_ i primijeniti prave _tehnike_.

### Stav za inÅ¾enjerstvo upita

InÅ¾enjerstvo upita je proces pokuÅ¡aja i pogreÅ¡ke, pa imajte na umu tri Å¡iroka smjernice:

1. **Razumijevanje domene je vaÅ¾no.** ToÄnost i relevantnost odgovora ovisi o _domeni_ u kojoj korisnik ili aplikacija djeluju. Primijenite intuiciju i struÄnost za daljnju **personalizaciju tehnika**. Na primjer, definirajte _domenom specifiÄne osobnosti_ u sustavnim upitima ili koristite _domenom specifiÄne predloÅ¡ke_ u korisniÄkim upitima. PruÅ¾ite sekundarni sadrÅ¾aj koji odraÅ¾ava kontekst domene ili koristite _domenom specifiÄne naznake i primjere_ za voÄ‘enje modela prema poznatim uzorcima koriÅ¡tenja.

2. **Razumijevanje modela je vaÅ¾no.** Znamo da su modeli po prirodi stohastiÄki. No implementacije modela mogu se razlikovati po skupu podataka za treniranje (predtrenirano znanje), sposobnostima koje pruÅ¾aju (npr. putem API-ja ili SDK-a) i tipu sadrÅ¾aja za koji su optimizirani (npr. kod vs slike vs tekst). Razumite prednosti i ograniÄenja modela koji koristite i upotrijebite to znanje da _prioritizirate zadatke_ ili gradite _prilagoÄ‘ene predloÅ¡ke_ optimizirane za moguÄ‡nosti modela.

3. **Iteracija i provjera su vaÅ¾ne.** Modeli brzo napreduju, kao i tehnike za inÅ¾enjerstvo upita. Kao ekspert u domeni moÅ¾da imate dodatni kontekst ili kriterije za _vaÅ¡u_ specifiÄnu primjenu koji moÅ¾da nisu primjenjivi Å¡iroj zajednici. Koristite alate i tehnike za izradu upita za "brzi poÄetak", zatim iterirajte i provjeravajte rezultate koristeÄ‡i vlastitu intuiciju i znanja iz domene. ZapiÅ¡ite svoja saznanja i kreirajte **bazÄ™ znanja** (npr. biblioteke upita) koju drugi mogu koristiti kao novi osnovni presjek za brÅ¾e iteracije u buduÄ‡nosti.

## Najbolje prakse

Pogledajmo sada uobiÄajene najbolje prakse koje preporuÄuju [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) i [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) struÄnjaci.

| Å to                               | ZaÅ¡to                                                                                                                                                                                                                                          |
| :-------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Procijenite najnovije modele.     | Nove generacije modela vjerojatno imaju poboljÅ¡ane znaÄajke i kvalitetu â€“ ali mogu i imati veÄ‡e troÅ¡kove. Procijenite njihov utjecaj, pa donesite odluku o migraciji.                                                                           |
| Razdvojite upute i kontekst       | Provjerite koristi li vaÅ¡ model/ponuditelj _graniÄnike_ za jasnije razlikovanje uputa, primarnog i sekundarnog sadrÅ¾aja. To pomaÅ¾e modelima da toÄnije dodijele teÅ¾inu tokenima.                                                            |
| Budite precizni i jasni            | Dajte viÅ¡e detalja o Å¾eljenom kontekstu, rezultatu, duljini, formatu, stilu itd. To poboljÅ¡ava i kvalitetu i dosljednost odgovora. Primjere spremite u upotrebljive predloÅ¡ke.                                                               |
| Budite opisni, koristite primjere  | Modeli bolje reagiraju na pristup "pokaÅ¾i i reci". PoÄnite s pristupom bez primjera, zatim isprobajte s nekoliko primjera za rafiniranje. Koristite analogije.                                                                                |
| Koristite naznake za pokretanje dovrÅ¡etaka | Usmjerite model prema Å¾eljenom rezultatu tako da ponudite neke uvodne rijeÄi ili fraze koje moÅ¾e upotrijebiti kao poÄetak odgovora.                                                                                                            |
| Ponavljajte                        | Ponekad je potrebno modelu ponoviti uputu. Dajte upute prije i poslije primarnog sadrÅ¾aja, upotrijebite uputu i naznaku itd. Iterirajte i provjeravajte Å¡to najbolje funkcionira.                                                               |
| Redoslijed je vaÅ¾an               | Redoslijed kojim pruÅ¾ate informacije modelu moÅ¾e utjecati na rezultat, Äak i u primjerima uÄenja, zbog pristranosti prema nedavnom sadrÅ¾aju. Isprobajte razliÄite opcije da vidite Å¡to najbolje radi.                                         |
| Dajte modelu â€œizlazâ€              | OmoguÄ‡ite modelu rezultat za _povratni_ odgovor koji moÅ¾e dati ako iz bilo kojeg razloga ne moÅ¾e dovrÅ¡iti zadatak. Time se smanjuju Å¡anse za laÅ¾ne ili izmiÅ¡ljene odgovore.                                                                      |
|                                  |                                                                                                                                                                                                                                                |

Kao i kod svake najbolje prakse, imajte na umu da _vaÅ¡i rezultati mogu varirati_ ovisno o modelu, zadatku i domeni. Iskoristite ove smjernice kao polaznu toÄku, te iterirajte da pronaÄ‘ete Å¡to najbolje za vas funkcionira. Kontinuirano ponovno procjenjujte svoj proces inÅ¾enjerstva upita kako bi pratili nove modele i alate u cilju skalabilnosti procesa i kvalitete odgovora.

<!--
LESSON TEMPLATE:
Ovaj odjeljak treba pruÅ¾iti zadatak s kodom ako je primjenjivo

IZAZOV:
Veza na Jupyter Notebook s samo komentarima u uputama (kodni dijelovi su prazni).

RIJEÅ ENJE:
Veza na kopiju tog Notebooka s popunjenim upitima i pokrenutim, gdje se vidi jedan primjer rjeÅ¡enja.
-->

## Zadatak

ÄŒestitamo! Stigli ste do kraja lekcije! Vrijeme je da neke od ovih koncepata i tehnika stavite na probu s pravim primjerima!

Za naÅ¡ zadatak koristit Ä‡emo Jupyter Notebook s vjeÅ¾bama koje moÅ¾ete rijeÅ¡iti interaktivno. TakoÄ‘er moÅ¾ete proÅ¡iriti Notebook vlastitim Markdown i Kod Ä‡elijama za istraÅ¾ivanje ideja i tehnika.

### Za poÄetak, izradite fork repozitorija, zatim

- (PreporuÄeno) Pokrenite GitHub Codespaces
- (Alternativno) Klonirajte repozitorij na lokalno raÄunalo i koristite s Docker Desktopom
- (Alternativno) Otvorite Notebook u Å¾eljenom okruÅ¾enju za izvrÅ¡avanje notebooka.

### Zatim konfigurirajte svoje varijable okruÅ¾enja

- Kopirajte datoteku `.env.copy` iz korijena repozitorija u `.env` i ispunite vrijednosti `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` i `AZURE_OPENAI_DEPLOYMENT`. Vratite se na [dio Learning Sandbox](../../../04-prompt-engineering-fundamentals) kako biste saznali kako.

### Otvorite Jupyter Notebook

- Odaberite runtime kernel. Ako koristite 1. ili 2. opciju, jednostavno odaberite zadani Python 3.10.x kernel koji pruÅ¾a razvojno okruÅ¾enje.

Spremni ste za izvoÄ‘enje vjeÅ¾bi. Imajte na umu da nema _ispravnih ili pogreÅ¡nih_ odgovora â€“ samo istraÅ¾ujete moguÄ‡nosti pokuÅ¡ajem i pogreÅ¡kom te razvijate intuiciju za ono Å¡to funkcionira za dani model i domenu.

_Za ovaj razlog nema segmenata s rjeÅ¡enjima koda u ovoj lekciji. Umjesto toga, Notebook Ä‡e imati Markdown Ä‡elije naslova "Moje rjeÅ¡enje:" koje prikazuju jedan primjer izlaza za referencu._

 <!--
LESSON TEMPLATE:
ZaokruÅ¾ite odjeljak saÅ¾etkom i resursima za samostalno uÄenje.
-->

## Provjera znanja

Koji od sljedeÄ‡ih upita slijedi razumne najbolje prakse?

1. PrikaÅ¾i mi sliku crvenog auta
2. PrikaÅ¾i mi sliku crvenog auta marke Volvo i modela XC90 parkiranog kraj litice s zalaskom sunca
3. PrikaÅ¾i mi sliku crvenog auta marke Volvo i modela XC90

Odgovor: 2 je najbolji upit jer pruÅ¾a detalje o "Äemu" i ide u specifiÄnosti (ne samo bilo koji auto, nego odreÄ‘ena marka i model) te opisuje cjelokupni ambijent. 3 je sljedeÄ‡i najbolji jer takoÄ‘er sadrÅ¾i mnogo opisa.

## ğŸš€ Izazov

PokuÅ¡ajte iskoristiti tehniku "naznake" s upitom: DovrÅ¡i reÄenicu "PrikaÅ¾i mi sliku crvenog auta marke Volvo i ". Å to odgovara i kako biste ga poboljÅ¡ali?

## OdliÄno! Nastavite s uÄenjem

Å½elite li nauÄiti viÅ¡e o razliÄitim konceptima InÅ¾enjerstva upita? Posjetite [stranicu za daljnje uÄenje](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) za druge odliÄne izvore o ovoj temi.

Krenite na Lekciju 5 gdje Ä‡emo pogledati [napredne tehnike promptanja](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Odricanje od odgovornosti**:
Ovaj dokument preveden je koriÅ¡tenjem AI usluge za prijevod [Co-op Translator](https://github.com/Azure/co-op-translator). Iako teÅ¾imo toÄnosti, molimo imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni ljudski prijevod. Nismo odgovorni za bilo kakve nesporazume ili pogreÅ¡ne interpretacije koje proizlaze iz koriÅ¡tenja ovog prijevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->