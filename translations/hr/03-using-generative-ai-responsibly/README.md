<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "4d57fad773cbeb69c5dd62e65c34200d",
  "translation_date": "2025-10-18T01:31:11+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "hr"
}
-->
# Odgovorno koriÅ¡tenje generativne umjetne inteligencije

[![Odgovorno koriÅ¡tenje generativne umjetne inteligencije](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.hr.png)](https://youtu.be/YOp-e1GjZdA?si=7Wv4wu3x44L1DCVj)

> _Kliknite na sliku iznad za pregled videa ove lekcije_

Lako je biti fasciniran umjetnom inteligencijom, posebno generativnom umjetnom inteligencijom, ali vaÅ¾no je razmisliti o tome kako je odgovorno koristiti. Treba razmotriti stvari poput osiguravanja da je izlaz pravedan, neÅ¡kodljiv i joÅ¡ mnogo toga. Ovaj Ä‡e vam poglavlje pruÅ¾iti kontekst, na Å¡to obratiti paÅ¾nju i kako poduzeti aktivne korake za poboljÅ¡anje koriÅ¡tenja umjetne inteligencije.

## Uvod

Ova lekcija obuhvaÄ‡a:

- ZaÅ¡to biste trebali dati prednost odgovornoj umjetnoj inteligenciji prilikom izrade aplikacija temeljenih na generativnoj umjetnoj inteligenciji.
- Temeljna naÄela odgovorne umjetne inteligencije i njihovu povezanost s generativnom umjetnom inteligencijom.
- Kako primijeniti ova naÄela odgovorne umjetne inteligencije kroz strategiju i alate.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije znat Ä‡ete:

- VaÅ¾nost odgovorne umjetne inteligencije prilikom izrade aplikacija temeljenih na generativnoj umjetnoj inteligenciji.
- Kada razmiÅ¡ljati i primijeniti temeljna naÄela odgovorne umjetne inteligencije prilikom izrade aplikacija temeljenih na generativnoj umjetnoj inteligenciji.
- Koji su alati i strategije dostupni za primjenu koncepta odgovorne umjetne inteligencije.

## NaÄela odgovorne umjetne inteligencije

UzbuÄ‘enje oko generativne umjetne inteligencije nikada nije bilo veÄ‡e. Ovo uzbuÄ‘enje privuklo je mnoge nove programere, paÅ¾nju i financiranje u ovom podruÄju. Iako je to vrlo pozitivno za svakoga tko Å¾eli graditi proizvode i tvrtke koristeÄ‡i generativnu umjetnu inteligenciju, takoÄ‘er je vaÅ¾no postupati odgovorno.

Kroz ovaj teÄaj fokusiramo se na izgradnju naÅ¡eg startupa i naÅ¡eg edukacijskog AI proizvoda. Koristit Ä‡emo naÄela odgovorne umjetne inteligencije: pravednost, inkluzivnost, pouzdanost/sigurnost, sigurnost i privatnost, transparentnost i odgovornost. PomoÄ‡u ovih naÄela istraÅ¾it Ä‡emo kako se ona odnose na naÅ¡u upotrebu generativne umjetne inteligencije u naÅ¡im proizvodima.

## ZaÅ¡to biste trebali dati prednost odgovornoj umjetnoj inteligenciji

Prilikom izrade proizvoda, pristup usmjeren na ljude, koji uzima u obzir najbolje interese korisnika, dovodi do najboljih rezultata.

Jedinstvenost generativne umjetne inteligencije leÅ¾i u njezinoj sposobnosti stvaranja korisnih odgovora, informacija, smjernica i sadrÅ¾aja za korisnike. To se moÅ¾e uÄiniti bez mnogo ruÄnih koraka, Å¡to moÅ¾e dovesti do vrlo impresivnih rezultata. Bez odgovarajuÄ‡eg planiranja i strategija, to takoÄ‘er moÅ¾e, naÅ¾alost, dovesti do Å¡tetnih rezultata za vaÅ¡e korisnike, vaÅ¡ proizvod i druÅ¡tvo u cjelini.

Pogledajmo neke (ali ne sve) od potencijalno Å¡tetnih rezultata:

### Halucinacije

Halucinacije su pojam koji se koristi za opisivanje situacija kada LLM generira sadrÅ¾aj koji je ili potpuno besmislen ili neÅ¡to za Å¡to znamo da je ÄinjeniÄno netoÄno na temelju drugih izvora informacija.

Primjerice, zamislimo da gradimo funkciju za naÅ¡ startup koja omoguÄ‡uje studentima da postavljaju povijesna pitanja modelu. Student postavi pitanje `Tko je bio jedini preÅ¾ivjeli s Titanica?`

Model generira odgovor poput sljedeÄ‡eg:

![Upit "Tko je bio jedini preÅ¾ivjeli s Titanica"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Izvor: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Ovo je vrlo samouvjeren i detaljan odgovor. NaÅ¾alost, netoÄan je. ÄŒak i uz minimalno istraÅ¾ivanje, otkrilo bi se da je viÅ¡e od jedne osobe preÅ¾ivjelo katastrofu Titanica. Za studenta koji tek poÄinje istraÅ¾ivati ovu temu, ovaj odgovor moÅ¾e biti dovoljno uvjerljiv da ga ne dovede u pitanje i da ga prihvati kao Äinjenicu. Posljedice toga mogu dovesti do nepouzdanosti AI sustava i negativno utjecati na reputaciju naÅ¡eg startupa.

Svakom iteracijom bilo kojeg LLM-a vidimo poboljÅ¡anja u smanjenju halucinacija. ÄŒak i uz ovo poboljÅ¡anje, mi kao graditelji aplikacija i korisnici i dalje moramo biti svjesni ovih ograniÄenja.

### Å tetni sadrÅ¾aj

Ranije smo pokrili situacije kada LLM generira netoÄne ili besmislene odgovore. Drugi rizik kojeg moramo biti svjesni je kada model odgovara Å¡tetnim sadrÅ¾ajem.

Å tetni sadrÅ¾aj moÅ¾e se definirati kao:

- Davanje uputa ili poticanje na samoozljeÄ‘ivanje ili ozljeÄ‘ivanje odreÄ‘enih skupina.
- MrzilaÄki ili poniÅ¾avajuÄ‡i sadrÅ¾aj.
- PomoÄ‡ u planiranju bilo koje vrste napada ili nasilnih radnji.
- Davanje uputa o tome kako pronaÄ‡i ilegalni sadrÅ¾aj ili poÄiniti ilegalne radnje.
- Prikazivanje seksualno eksplicitnog sadrÅ¾aja.

Za naÅ¡ startup, Å¾elimo osigurati da imamo prave alate i strategije kako bismo sprijeÄili da ovakav sadrÅ¾aj bude dostupan studentima.

### Nedostatak pravednosti

Pravednost se definira kao "osiguranje da je AI sustav slobodan od pristranosti i diskriminacije te da sve tretira pravedno i jednako." U svijetu generativne umjetne inteligencije, Å¾elimo osigurati da iskljuÄujuÄ‡i svjetonazori marginaliziranih skupina nisu pojaÄani izlazom modela.

Ove vrste izlaza ne samo da su destruktivne za izgradnju pozitivnog iskustva proizvoda za naÅ¡e korisnike, veÄ‡ takoÄ‘er uzrokuju daljnju druÅ¡tvenu Å¡tetu. Kao graditelji aplikacija, uvijek bismo trebali imati na umu Å¡iroku i raznoliku bazu korisnika prilikom izrade rjeÅ¡enja s generativnom umjetnom inteligencijom.

## Kako odgovorno koristiti generativnu umjetnu inteligenciju

Sada kada smo identificirali vaÅ¾nost odgovorne generativne umjetne inteligencije, pogledajmo 4 koraka koje moÅ¾emo poduzeti kako bismo odgovorno izgradili naÅ¡e AI rjeÅ¡enja:

![Ciklus ublaÅ¾avanja](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.hr.png)

### Mjerenje potencijalnih Å¡teta

U testiranju softvera testiramo oÄekivane radnje korisnika na aplikaciji. SliÄno tome, testiranje raznolikog skupa upita koje Ä‡e korisnici najvjerojatnije koristiti dobar je naÄin za mjerenje potencijalne Å¡tete.

BuduÄ‡i da naÅ¡ startup gradi edukacijski proizvod, bilo bi dobro pripremiti popis upita vezanih uz obrazovanje. To bi moglo ukljuÄivati odreÄ‘ene predmete, povijesne Äinjenice i upite o studentskom Å¾ivotu.

### UblaÅ¾avanje potencijalnih Å¡teta

Sada je vrijeme da pronaÄ‘emo naÄine kako moÅ¾emo sprijeÄiti ili ograniÄiti potencijalnu Å¡tetu uzrokovanu modelom i njegovim odgovorima. Na to moÅ¾emo gledati kroz 4 razliÄita sloja:

![Slojevi ublaÅ¾avanja](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.hr.png)

- **Model**. Odabir pravog modela za pravi sluÄaj upotrebe. VeÄ‡i i sloÅ¾eniji modeli poput GPT-4 mogu predstavljati veÄ‡i rizik od Å¡tetnog sadrÅ¾aja kada se primjenjuju na manje i specifiÄne sluÄajeve upotrebe. KoriÅ¡tenje vaÅ¡ih podataka za treniranje modela takoÄ‘er smanjuje rizik od Å¡tetnog sadrÅ¾aja.

- **Sigurnosni sustav**. Sigurnosni sustav je skup alata i konfiguracija na platformi koja posluÅ¾uje model i pomaÅ¾e u ublaÅ¾avanju Å¡tete. Primjer toga je sustav za filtriranje sadrÅ¾aja na Azure OpenAI usluzi. Sustavi takoÄ‘er trebaju otkriti napade na sustav i neÅ¾eljene aktivnosti poput zahtjeva od strane botova.

- **Metaprompt**. Metapromptovi i uzemljenje su naÄini na koje moÅ¾emo usmjeriti ili ograniÄiti model na temelju odreÄ‘enih ponaÅ¡anja i informacija. To moÅ¾e ukljuÄivati koriÅ¡tenje ulaza sustava za definiranje odreÄ‘enih ograniÄenja modela. Osim toga, pruÅ¾anje izlaza koji su relevantniji za opseg ili podruÄje sustava.

TakoÄ‘er se mogu koristiti tehnike poput Retrieval Augmented Generation (RAG) kako bi model povlaÄio informacije samo iz odabranih pouzdanih izvora. Postoji lekcija kasnije u ovom teÄaju o [izradi aplikacija za pretraÅ¾ivanje](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **KorisniÄko iskustvo**. ZavrÅ¡ni sloj je mjesto gdje korisnik izravno komunicira s modelom putem suÄelja naÅ¡e aplikacije na neki naÄin. Na taj naÄin moÅ¾emo dizajnirati UI/UX kako bismo ograniÄili korisnika u vrstama unosa koje moÅ¾e poslati modelu, kao i tekst ili slike prikazane korisniku. Prilikom implementacije AI aplikacije, takoÄ‘er moramo biti transparentni o tome Å¡to naÅ¡a generativna AI aplikacija moÅ¾e, a Å¡to ne moÅ¾e uÄiniti.

Imamo cijelu lekciju posveÄ‡enu [Dizajniranju UX-a za AI aplikacije](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Procjena modela**. Rad s LLM-ovima moÅ¾e biti izazovan jer nemamo uvijek kontrolu nad podacima na kojima je model treniran. Bez obzira na to, uvijek bismo trebali procijeniti performanse i izlaze modela. I dalje je vaÅ¾no mjeriti toÄnost modela, sliÄnost, uzemljenost i relevantnost izlaza. To pomaÅ¾e pruÅ¾iti transparentnost i povjerenje dionicima i korisnicima.

### Upravljanje odgovornim generativnim AI rjeÅ¡enjem

Izgradnja operativne prakse oko vaÅ¡ih AI aplikacija je zavrÅ¡na faza. To ukljuÄuje suradnju s drugim dijelovima naÅ¡eg startupa, poput pravnog i sigurnosnog odjela, kako bismo osigurali usklaÄ‘enost sa svim regulatornim politikama. Prije lansiranja takoÄ‘er Å¾elimo izraditi planove oko isporuke, rjeÅ¡avanja incidenata i povlaÄenja kako bismo sprijeÄili bilo kakvu Å¡tetu za naÅ¡e korisnike.

## Alati

Iako se rad na razvoju rjeÅ¡enja odgovorne umjetne inteligencije moÅ¾e Äiniti zahtjevnim, to je trud koji se itekako isplati. Kako podruÄje generativne umjetne inteligencije raste, sve viÅ¡e alata koji pomaÅ¾u programerima da uÄinkovito integriraju odgovornost u svoje radne procese Ä‡e se razvijati. Na primjer, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) moÅ¾e pomoÄ‡i u otkrivanju Å¡tetnog sadrÅ¾aja i slika putem API zahtjeva.

## Provjera znanja

Na Å¡to trebate obratiti paÅ¾nju kako biste osigurali odgovorno koriÅ¡tenje umjetne inteligencije?

1. Da je odgovor toÄan.
1. Å tetna upotreba, da se AI ne koristi za kriminalne svrhe.
1. Osiguranje da AI nije pristrana i diskriminirajuÄ‡a.

A: 2 i 3 su toÄni. Odgovorna umjetna inteligencija pomaÅ¾e vam razmotriti kako ublaÅ¾iti Å¡tetne uÄinke i pristranosti i joÅ¡ mnogo toga.

## ğŸš€ Izazov

ProÄitajte o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) i istraÅ¾ite Å¡to moÅ¾ete primijeniti za svoju upotrebu.

## OdliÄno obavljeno, nastavite uÄiti

Nakon zavrÅ¡etka ove lekcije, pogledajte naÅ¡u [Generative AI Learning kolekciju](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili unapreÄ‘ivati svoje znanje o generativnoj umjetnoj inteligenciji!

PrijeÄ‘ite na lekciju 4 gdje Ä‡emo prouÄiti [Osnove inÅ¾enjeringa upita](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Izjava o odricanju odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.