<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T09:04:33+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "hr"
}
-->
# Odgovorno koriÅ¡tenje generativne AI

[![Using Generative AI Responsibly](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.hr.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite na gornju sliku za pregled videa ove lekcije_

Lako je biti fasciniran AI-jem, a posebno generativnom AI-jem, no vaÅ¾no je razmisliti o tome kako ga koristiti na odgovoran naÄin. Trebate uzeti u obzir kako osigurati da rezultati budu pravedni, neÅ¡kodljivi i sliÄno. Ova poglavlja imaju za cilj pruÅ¾iti vam kontekst, na Å¡to obratiti paÅ¾nju i kako poduzeti konkretne korake za poboljÅ¡anje koriÅ¡tenja AI-ja.

## Uvod

Ova lekcija Ä‡e obuhvatiti:

- ZaÅ¡to trebate dati prioritet Odgovornoj AI prilikom izrade aplikacija s generativnom AI.
- Osnovna naÄela Odgovorne AI i kako se ona odnose na generativnu AI.
- Kako primijeniti ta naÄela kroz strategiju i alate.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije znat Ä‡ete:

- Koliko je vaÅ¾na Odgovorna AI pri izradi aplikacija s generativnom AI.
- Kada razmiÅ¡ljati o osnovnim naÄelima Odgovorne AI i primjenjivati ih u razvoju generativnih AI aplikacija.
- Koji su vam alati i strategije dostupni za praktiÄnu primjenu koncepta Odgovorne AI.

## NaÄela Odgovorne AI

Zanimanje za generativnu AI nikada nije bilo veÄ‡e. Ovo uzbuÄ‘enje privuklo je mnoge nove developere, paÅ¾nju i financijska sredstva u ovo podruÄje. Iako je to vrlo pozitivno za sve koji Å¾ele graditi proizvode i tvrtke koristeÄ‡i generativnu AI, vaÅ¾no je da nastavimo odgovorno.

Kroz ovaj teÄaj fokusiramo se na izgradnju naÅ¡eg startupa i naÅ¡eg AI edukacijskog proizvoda. Koristit Ä‡emo naÄela Odgovorne AI: Pravednost, UkljuÄivost, Pouzdanost/Sigurnost, Sigurnost i Privatnost, Transparentnost i Odgovornost. Kroz ta naÄela istraÅ¾it Ä‡emo kako se ona odnose na naÅ¡u upotrebu generativne AI u proizvodima.

## ZaÅ¡to dati prioritet Odgovornoj AI

Prilikom izrade proizvoda, pristup usmjeren na Äovjeka, s fokusom na najbolje interese korisnika, vodi do najboljih rezultata.

Jedinstvenost generativne AI leÅ¾i u njenoj sposobnosti da stvara korisne odgovore, informacije, smjernice i sadrÅ¾aj za korisnike. To se moÅ¾e postiÄ‡i bez mnogo ruÄnih koraka, Å¡to moÅ¾e dovesti do impresivnih rezultata. No, bez odgovarajuÄ‡eg planiranja i strategija, naÅ¾alost, moÅ¾e dovesti i do Å¡tetnih posljedica za vaÅ¡e korisnike, proizvod i druÅ¡tvo u cjelini.

Pogledajmo neke (ali ne sve) od tih potencijalno Å¡tetnih posljedica:

### Halucinacije

Halucinacije su pojam koji se koristi za opis situacije kada LLM generira sadrÅ¾aj koji je potpuno besmislen ili je poznato da je ÄinjeniÄno netoÄan na temelju drugih izvora informacija.

Na primjer, zamislimo da razvijamo funkciju za naÅ¡ startup koja studentima omoguÄ‡uje postavljanje povijesnih pitanja modelu. Student postavi pitanje `Tko je bio jedini preÅ¾ivjeli Titanica?`

Model daje odgovor poput ovog:

![Prompt saying "Who was the sole survivor of the Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Izvor: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Ovo je vrlo samouvjeren i detaljan odgovor. NaÅ¾alost, netoÄan je. ÄŒak i uz minimalno istraÅ¾ivanje, otkrilo bi se da je bilo viÅ¡e preÅ¾ivjelih Titanica. Za studenta koji tek poÄinje istraÅ¾ivati ovu temu, ovaj odgovor moÅ¾e biti dovoljno uvjerljiv da se ne dovodi u pitanje i prihvati kao Äinjenica. Posljedice mogu biti da AI sustav postane nepouzdan i negativno utjeÄe na reputaciju naÅ¡eg startupa.

S svakom novom verzijom bilo kojeg LLM-a vidjeli smo poboljÅ¡anja u smanjenju halucinacija. Ipak, kao developeri i korisnici aplikacija, moramo biti svjesni ovih ograniÄenja.

### Å tetni sadrÅ¾aj

U prethodnom dijelu smo spomenuli kada LLM daje netoÄne ili besmislene odgovore. Drugi rizik na koji trebamo paziti je kada model generira Å¡tetni sadrÅ¾aj.

Å tetni sadrÅ¾aj moÅ¾e se definirati kao:

- Davanje uputa ili poticanje na samoozljeÄ‘ivanje ili nasilje prema odreÄ‘enim skupinama.
- MrzilaÄki ili poniÅ¾avajuÄ‡i sadrÅ¾aj.
- Upute za planiranje bilo kakvih napada ili nasilnih djela.
- Upute kako pronaÄ‡i ilegalni sadrÅ¾aj ili poÄiniti nezakonite radnje.
- Prikazivanje seksualno eksplicitnog sadrÅ¾aja.

Za naÅ¡ startup Å¾elimo osigurati da imamo prave alate i strategije kako bismo sprijeÄili da studenti vide ovakvu vrstu sadrÅ¾aja.

### Nedostatak pravednosti

Pravednost se definira kao â€osiguravanje da AI sustav nije pristran niti diskriminira te da sve tretira poÅ¡teno i jednako.â€œ U svijetu generativne AI Å¾elimo osigurati da modeli ne jaÄaju iskljuÄive poglede na svijet koji marginaliziraju odreÄ‘ene skupine.

Ovakvi rezultati ne samo da naruÅ¡avaju pozitivno korisniÄko iskustvo, veÄ‡ i dodatno Å¡tete druÅ¡tvu. Kao developeri aplikacija uvijek bismo trebali imati na umu Å¡iroku i raznoliku bazu korisnika prilikom izrade rjeÅ¡enja s generativnom AI.

## Kako odgovorno koristiti generativnu AI

Sada kada smo prepoznali vaÅ¾nost Odgovorne generativne AI, pogledajmo 4 koraka koje moÅ¾emo poduzeti da bismo svoje AI rjeÅ¡enja gradili odgovorno:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.hr.png)

### Mjerenje potencijalnih Å¡teta

U testiranju softvera testiramo oÄekivane radnje korisnika na aplikaciji. SliÄno tome, testiranje raznovrsnih upita koje korisnici najvjerojatnije koriste dobar je naÄin za mjerenje potencijalne Å¡tete.

BuduÄ‡i da naÅ¡ startup razvija edukacijski proizvod, bilo bi korisno pripremiti popis edukacijskih upita. To moÅ¾e ukljuÄivati odreÄ‘ene predmete, povijesne Äinjenice i upite vezane uz studentski Å¾ivot.

### UblaÅ¾avanje potencijalnih Å¡teta

Vrijeme je da pronaÄ‘emo naÄine kako sprijeÄiti ili ograniÄiti potencijalnu Å¡tetu koju model i njegovi odgovori mogu uzrokovati. To moÅ¾emo promatrati kroz 4 razliÄita sloja:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.hr.png)

- **Model**. Odabir pravog modela za odgovarajuÄ‡i sluÄaj upotrebe. VeÄ‡i i sloÅ¾eniji modeli poput GPT-4 mogu predstavljati veÄ‡i rizik od Å¡tetnog sadrÅ¾aja kada se primjenjuju na manje i specifiÄnije sluÄajeve. Fino podeÅ¡avanje modela na vlastitim podacima takoÄ‘er smanjuje rizik od Å¡tetnog sadrÅ¾aja.

- **Sigurnosni sustav**. Sigurnosni sustav je skup alata i konfiguracija na platformi koja posluÅ¾uje model, a pomaÅ¾e u ublaÅ¾avanju Å¡tete. Primjer je sustav filtriranja sadrÅ¾aja na Azure OpenAI servisu. Sustavi bi takoÄ‘er trebali otkrivati pokuÅ¡aje zaobilaÅ¾enja ograniÄenja (jailbreak) i neÅ¾eljene aktivnosti poput zahtjeva od botova.

- **Metaprompt**. Metapromptovi i "grounding" su naÄini na koje moÅ¾emo usmjeriti ili ograniÄiti model na temelju odreÄ‘enih ponaÅ¡anja i informacija. To moÅ¾e biti koriÅ¡tenje sistemskih ulaza za definiranje odreÄ‘enih granica modela. TakoÄ‘er, pruÅ¾anje odgovora koji su relevantniji za opseg ili domenu sustava.

TakoÄ‘er se mogu koristiti tehnike poput Retrieval Augmented Generation (RAG) kako bi model izvlaÄio informacije samo iz odabranih pouzdanih izvora. U kasnijoj lekciji ovog teÄaja obraÄ‘ujemo [izradu pretraÅ¾ivaÄkih aplikacija](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **KorisniÄko iskustvo**. Posljednji sloj je gdje korisnik izravno komunicira s modelom putem suÄelja naÅ¡e aplikacije. Na ovaj naÄin moÅ¾emo dizajnirati UI/UX tako da ograniÄimo vrste unosa koje korisnik moÅ¾e poslati modelu, kao i tekst ili slike koje se prikazuju korisniku. Prilikom implementacije AI aplikacije, takoÄ‘er moramo biti transparentni o tome Å¡to naÅ¡a generativna AI aplikacija moÅ¾e, a Å¡to ne moÅ¾e.

Imamo cijelu lekciju posveÄ‡enu [dizajnu UX-a za AI aplikacije](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Evaluacija modela**. Rad s LLM-ovima moÅ¾e biti izazovan jer nemamo uvijek kontrolu nad podacima na kojima je model treniran. Ipak, uvijek bismo trebali procjenjivati performanse i rezultate modela. VaÅ¾no je mjeriti toÄnost, sliÄnost, utemeljenost i relevantnost izlaza modela. To pomaÅ¾e u pruÅ¾anju transparentnosti i povjerenja dionicima i korisnicima.

### Upravljanje odgovornim generativnim AI rjeÅ¡enjem

Izgradnja operativne prakse oko vaÅ¡ih AI aplikacija je zavrÅ¡na faza. To ukljuÄuje suradnju s drugim dijelovima naÅ¡eg startupa poput pravnog i sigurnosnog odjela kako bismo osigurali usklaÄ‘enost sa svim regulatornim politikama. Prije lansiranja Å¾elimo izraditi planove za isporuku, upravljanje incidentima i povratak na prethodnu verziju kako bismo sprijeÄili Å¡tetu korisnicima.

## Alati

Iako se razvoj rjeÅ¡enja Odgovorne AI moÅ¾e Äiniti zahtjevnim, to je posao koji se isplati. Kako podruÄje generativne AI raste, razvijat Ä‡e se i alati koji pomaÅ¾u developerima da uÄinkovito integriraju odgovornost u svoje radne procese. Na primjer, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) moÅ¾e pomoÄ‡i u otkrivanju Å¡tetnog sadrÅ¾aja i slika putem API poziva.

## Provjera znanja

Koje stvari trebate uzeti u obzir kako biste osigurali odgovorno koriÅ¡tenje AI-ja?

1. Da je odgovor toÄan.  
1. Å tetna upotreba, da AI nije koriÅ¡ten za kriminalne svrhe.  
1. Osiguravanje da AI nije pristran niti diskriminira.

O: ToÄno su 2 i 3. Odgovorna AI pomaÅ¾e vam razmotriti kako ublaÅ¾iti Å¡tetne uÄinke, pristranosti i joÅ¡ mnogo toga.

## ğŸš€ Izazov

ProÄitajte o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) i istraÅ¾ite Å¡to moÅ¾ete primijeniti u svojoj upotrebi.

## OdliÄan posao, nastavite s uÄenjem

Nakon zavrÅ¡etka ove lekcije, pogledajte naÅ¡u [kolekciju za uÄenje generativne AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) i nastavite podizati svoje znanje o generativnoj AI!

Krenite na Lekciju 4 gdje Ä‡emo prouÄiti [osnove prompt inÅ¾enjeringa](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koriÅ¡tenjem AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo postiÄ‡i toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati sluÅ¾benim i autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakve nesporazume ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.