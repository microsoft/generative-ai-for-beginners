<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:52:35+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "hr"
}
-->
# Odgovorno koriÅ¡tenje generativne AI

> _Kliknite na sliku iznad za pregled videa ove lekcije_

Lako je biti fasciniran AI-jem, a posebno generativnom AI, ali morate razmisliti o tome kako ga koristiti odgovorno. Trebate razmotriti stvari poput osiguravanja da je izlaz pravedan, neÅ¡kodljiv i viÅ¡e. Ovaj poglavlje ima za cilj pruÅ¾iti vam navedeni kontekst, Å¡to uzeti u obzir i kako poduzeti aktivne korake za poboljÅ¡anje vaÅ¡eg koriÅ¡tenja AI.

## Uvod

Ova lekcija Ä‡e pokriti:

- ZaÅ¡to biste trebali prioritizirati Odgovornu AI kada gradite aplikacije s Generativnom AI.
- Osnovne principe Odgovorne AI i kako se odnose na Generativnu AI.
- Kako primijeniti ove principe Odgovorne AI kroz strategiju i alate.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije znat Ä‡ete:

- VaÅ¾nost Odgovorne AI pri izgradnji aplikacija s Generativnom AI.
- Kada razmiÅ¡ljati i primijeniti osnovne principe Odgovorne AI pri izgradnji aplikacija s Generativnom AI.
- Koji alati i strategije su vam dostupni za primjenu koncepta Odgovorne AI.

## Principi Odgovorne AI

UzbuÄ‘enje oko Generativne AI nikada nije bilo veÄ‡e. Ovo uzbuÄ‘enje donijelo je mnogo novih programera, paÅ¾nje i financiranja u ovaj prostor. Iako je ovo vrlo pozitivno za svakoga tko Å¾eli graditi proizvode i tvrtke koristeÄ‡i Generativnu AI, takoÄ‘er je vaÅ¾no da postupamo odgovorno.

Kroz ovaj teÄaj, fokusiramo se na izgradnju naÅ¡eg startupa i naÅ¡eg AI obrazovnog proizvoda. Koristit Ä‡emo principe Odgovorne AI: Pravednost, Inkluzivnost, Pouzdanost/Sigurnost, Sigurnost i Privatnost, Transparentnost i Odgovornost. S ovim principima istraÅ¾it Ä‡emo kako se odnose na naÅ¡u upotrebu Generativne AI u naÅ¡im proizvodima.

## ZaÅ¡to biste trebali prioritizirati Odgovornu AI

Kada gradite proizvod, uzimanje pristupa usmjerenog na ljude drÅ¾eÄ‡i najbolje interese vaÅ¡eg korisnika u umu vodi do najboljih rezultata.

Jedinstvenost Generativne AI je njezina moÄ‡ stvaranja korisnih odgovora, informacija, smjernica i sadrÅ¾aja za korisnike. To se moÅ¾e uÄiniti bez mnogo ruÄnih koraka, Å¡to moÅ¾e dovesti do vrlo impresivnih rezultata. Bez odgovarajuÄ‡eg planiranja i strategija, to takoÄ‘er naÅ¾alost moÅ¾e dovesti do nekih Å¡tetnih rezultata za vaÅ¡e korisnike, vaÅ¡ proizvod i druÅ¡tvo u cjelini.

Pogledajmo neke (ali ne sve) od ovih potencijalno Å¡tetnih rezultata:

### Halucinacije

Halucinacije su pojam koji se koristi za opisivanje kada LLM generira sadrÅ¾aj koji je ili potpuno besmislen ili neÅ¡to Å¡to znamo da je faktualno netoÄno na temelju drugih izvora informacija.

Uzmimo za primjer da gradimo znaÄajku za naÅ¡ startup koja omoguÄ‡uje studentima da postavljaju povijesna pitanja modelu. Student postavlja pitanje `Who was the sole survivor of Titanic?`

Model generira odgovor kao Å¡to je dolje:

Ovo je vrlo samopouzdan i detaljan odgovor. NaÅ¾alost, netoÄan je. ÄŒak i uz minimalno istraÅ¾ivanje, otkrilo bi se da je bilo viÅ¡e od jednog preÅ¾ivjelog iz katastrofe Titanica. Za studenta koji tek poÄinje istraÅ¾ivati ovu temu, ovaj odgovor moÅ¾e biti dovoljno uvjerljiv da se ne dovodi u pitanje i tretira kao Äinjenica. Posljedice ovoga mogu dovesti do toga da AI sustav bude nepouzdan i negativno utjeÄe na reputaciju naÅ¡eg startupa.

Svakom iteracijom bilo kojeg danog LLM-a, vidjeli smo poboljÅ¡anja performansi oko minimiziranja halucinacija. ÄŒak i s ovim poboljÅ¡anjem, mi kao graditelji aplikacija i korisnici joÅ¡ uvijek moramo biti svjesni ovih ograniÄenja.

### Å tetni sadrÅ¾aj

Pokrijali smo u ranijem dijelu kada LLM generira netoÄne ili besmislene odgovore. JoÅ¡ jedan rizik koji moramo biti svjesni je kada model odgovara Å¡tetnim sadrÅ¾ajem.

Å tetni sadrÅ¾aj moÅ¾e se definirati kao:

- PruÅ¾anje uputa ili poticanje na samoozljeÄ‘ivanje ili ozljeÄ‘ivanje odreÄ‘enih grupa.
- Mrziteljski ili poniÅ¾avajuÄ‡i sadrÅ¾aj.
- VoÄ‘enje planiranja bilo kakvog napada ili nasilnih djela.
- PruÅ¾anje uputa kako pronaÄ‡i ilegalni sadrÅ¾aj ili poÄiniti ilegalna djela.
- Prikazivanje seksualno eksplicitnog sadrÅ¾aja.

Za naÅ¡ startup, Å¾elimo biti sigurni da imamo prave alate i strategije na mjestu kako bismo sprijeÄili da ovaj tip sadrÅ¾aja bude viÄ‘en od strane studenata.

### Nedostatak pravednosti

Pravednost se definira kao â€œosiguravanje da AI sustav nije pristran i diskriminirajuÄ‡i i da tretira svakoga pravedno i jednako.â€ U svijetu Generativne AI, Å¾elimo osigurati da iskljuÄujuÄ‡i pogledi marginaliziranih grupa nisu pojaÄani izlazom modela.

Ove vrste izlaza nisu samo destruktivne za izgradnju pozitivnih iskustava proizvoda za naÅ¡e korisnike, veÄ‡ takoÄ‘er uzrokuju daljnju druÅ¡tvenu Å¡tetu. Kao graditelji aplikacija, uvijek bismo trebali imati Å¡iroku i raznoliku korisniÄku bazu na umu kada gradimo rjeÅ¡enja s Generativnom AI.

## Kako koristiti Generativnu AI odgovorno

Sada kada smo identificirali vaÅ¾nost Odgovorne Generativne AI, pogledajmo 4 koraka koje moÅ¾emo poduzeti da odgovorno izgradimo naÅ¡a AI rjeÅ¡enja:

### Mjerenje potencijalnih Å¡teta

U testiranju softvera, testiramo oÄekivane radnje korisnika na aplikaciji. SliÄno tome, testiranje raznolikog skupa upita koje korisnici najvjerojatnije Ä‡e koristiti je dobar naÄin za mjerenje potencijalne Å¡tete.

BuduÄ‡i da naÅ¡ startup gradi obrazovni proizvod, bilo bi dobro pripremiti popis obrazovnih upita. Ovo bi moglo pokriti odreÄ‘eni predmet, povijesne Äinjenice i upite o studentskom Å¾ivotu.

### UblaÅ¾avanje potencijalnih Å¡teta

Vrijeme je da pronaÄ‘emo naÄine kako moÅ¾emo sprijeÄiti ili ograniÄiti potencijalnu Å¡tetu uzrokovanu modelom i njegovim odgovorima. MoÅ¾emo pogledati ovo u 4 razliÄita sloja:

- **Model**. Odabir pravog modela za pravi sluÄaj upotrebe. VeÄ‡i i sloÅ¾eniji modeli kao GPT-4 mogu uzrokovati veÄ‡i rizik od Å¡tetnog sadrÅ¾aja kada se primjenjuju na manje i specifiÄnije sluÄajeve upotrebe. KoriÅ¡tenje vaÅ¡ih podataka za obuku za fino podeÅ¡avanje takoÄ‘er smanjuje rizik od Å¡tetnog sadrÅ¾aja.

- **Sigurnosni sustav**. Sigurnosni sustav je skup alata i konfiguracija na platformi koja posluÅ¾uje model koji pomaÅ¾e ublaÅ¾iti Å¡tetu. Primjer toga je sustav filtriranja sadrÅ¾aja na Azure OpenAI usluzi. Sustavi bi takoÄ‘er trebali otkriti napade na sustav i neÅ¾eljene aktivnosti kao Å¡to su zahtjevi od botova.

- **Metaprompt**. Metaprompts i uzemljenje su naÄini na koje moÅ¾emo usmjeriti ili ograniÄiti model na temelju odreÄ‘enih ponaÅ¡anja i informacija. Ovo bi moglo biti koriÅ¡tenje sistemskih unosa za definiranje odreÄ‘enih granica modela. Osim toga, pruÅ¾anje izlaza koji su relevantniji za opseg ili domenu sustava.

TakoÄ‘er moÅ¾e biti koriÅ¡tenje tehnika kao Å¡to je Retrieval Augmented Generation (RAG) da model samo povlaÄi informacije iz odabira pouzdanih izvora. Postoji lekcija kasnije u ovom teÄaju za [izgradnju aplikacija za pretraÅ¾ivanje](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **KorisniÄko iskustvo**. ZavrÅ¡ni sloj je gdje korisnik izravno komunicira s modelom putem suÄelja naÅ¡e aplikacije na neki naÄin. Na taj naÄin moÅ¾emo dizajnirati UI/UX da ograniÄimo korisnika na vrste unosa koje mogu poslati modelu kao i tekst ili slike prikazane korisniku. Kada implementiramo AI aplikaciju, takoÄ‘er moramo biti transparentni o tome Å¡to naÅ¡a Generativna AI aplikacija moÅ¾e i ne moÅ¾e uÄiniti.

Imamo cijelu lekciju posveÄ‡enu [Dizajnu UX za AI aplikacije](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Evaluacija modela**. Rad s LLM-ima moÅ¾e biti izazovan jer nemamo uvijek kontrolu nad podacima na kojima je model treniran. Bez obzira na to, uvijek bismo trebali evaluirati performanse i izlaze modela. JoÅ¡ uvijek je vaÅ¾no mjeriti toÄnost, sliÄnost, uzemljenost i relevantnost izlaza modela. Ovo pomaÅ¾e pruÅ¾iti transparentnost i povjerenje dionicima i korisnicima.

### Operativno odgovorno rjeÅ¡enje Generativne AI

Izgradnja operativne prakse oko vaÅ¡ih AI aplikacija je zavrÅ¡na faza. Ovo ukljuÄuje partnerstvo s drugim dijelovima naÅ¡eg startupa kao Å¡to su Pravni i Sigurnosni odjel kako bismo osigurali da smo u skladu sa svim regulatornim politikama. Prije lansiranja, takoÄ‘er Å¾elimo izgraditi planove oko isporuke, rukovanja incidentima i povratka kako bismo sprijeÄili bilo kakvu Å¡tetu naÅ¡im korisnicima od rasta.

## Alati

Iako se rad na razvoju rjeÅ¡enja Odgovorne AI moÅ¾e Äiniti puno, to je rad koji se isplati. Kako podruÄje Generativne AI raste, viÅ¡e alata za pomoÄ‡ programerima da uÄinkovito integriraju odgovornost u svoje radne tokove Ä‡e sazrijeti. Na primjer, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) moÅ¾e pomoÄ‡i u otkrivanju Å¡tetnog sadrÅ¾aja i slika putem API zahtjeva.

## Provjera znanja

Koje su neke stvari na koje trebate paziti kako biste osigurali odgovorno koriÅ¡tenje AI?

1. Da je odgovor toÄan.
1. Å tetna upotreba, da se AI ne koristi za kriminalne svrhe.
1. Osiguravanje da AI nije pristran i diskriminirajuÄ‡i.

A: 2 i 3 su toÄni. Odgovorna AI pomaÅ¾e vam razmotriti kako ublaÅ¾iti Å¡tetne uÄinke i pristranosti i viÅ¡e.

## ğŸš€ Izazov

ProÄitajte o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) i pogledajte Å¡to moÅ¾ete usvojiti za svoju upotrebu.

## OdliÄan rad, nastavite sa uÄenjem

Nakon zavrÅ¡etka ove lekcije, pogledajte naÅ¡u [Generativnu AI zbirku za uÄenje](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili podizati svoje znanje o Generativnoj AI!

PreÄ‘ite na Lekciju 4 gdje Ä‡emo pogledati [Osnove inÅ¾enjeringa upita](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Odricanje odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo postiÄ‡i toÄnost, molimo vas da budete svjesni da automatski prijevodi mogu sadrÅ¾avati greÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne odgovaramo za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.