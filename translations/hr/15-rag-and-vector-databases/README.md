# Retrieval Augmented Generation (RAG) i Vektorske Baze Podataka

[![Retrieval Augmented Generation (RAG) i Vektorske Baze Podataka](../../../translated_images/hr/15-lesson-banner.ac49e59506175d4f.webp)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

U lekciji o aplikacijama za pretraÅ¾ivanje, ukratko smo nauÄili kako integrirati vlastite podatke u velike jeziÄne modele (LLM). U ovoj lekciji Ä‡emo dublje istraÅ¾iti koncepte utemeljivanja vaÅ¡ih podataka u vaÅ¡oj LLM aplikaciji, mehaniku procesa i metode pohrane podataka, ukljuÄujuÄ‡i i ugraÄ‘ene podatke i tekst.

> **Video uskoro**

## Uvod

U ovoj lekciji Ä‡emo obraditi sljedeÄ‡e:

- Uvod u RAG, Å¡to je i zaÅ¡to se koristi u AI (umjetna inteligencija).

- Razumijevanje Å¡to su vektorske baze podataka i kreiranje jedne za naÅ¡u aplikaciju.

- PraktiÄni primjer kako integrirati RAG u aplikaciju.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije, moÄ‡i Ä‡ete:

- Objasniti znaÄaj RAG-a u dohvaÄ‡anju i obradi podataka.

- Postaviti RAG aplikaciju i utemeljiti svoje podatke u LLM.

- UÄinkovito integrirati RAG i Vektorske Baze Podataka u LLM aplikacije.

## NaÅ¡ scenarij: unaprjeÄ‘enje naÅ¡ih LLM-ova vlastitim podacima

Za ovu lekciju Å¾elimo dodati vlastite biljeÅ¡ke u edukativni startup, Å¡to omoguÄ‡uje chatbotu da dobije viÅ¡e informacija o razliÄitim predmetima. KoristeÄ‡i biljeÅ¡ke koje imamo, uÄenici Ä‡e moÄ‡i bolje uÄiti i razumjeti razliÄite teme, olakÅ¡avajuÄ‡i pritom pripremu za ispite. Za izradu naÅ¡eg scenarija koristit Ä‡emo:

- `Azure OpenAI:` LLM koji Ä‡emo koristiti za stvaranje naÅ¡eg chatbota

- `Lekcija AI za poÄetnike o neuronskim mreÅ¾ama:` to Ä‡e biti podaci na kojima utemeljujemo naÅ¡ LLM

- `Azure AI Search` i `Azure Cosmos DB:` vektorska baza podataka za pohranu naÅ¡ih podataka i kreiranje indeksa pretraÅ¾ivanja

Korisnici Ä‡e moÄ‡i kreirati vjeÅ¾bovne kvizove iz svojih biljeÅ¡ki, kartice za ponavljanje i saÅ¾etke u kratkim pregledima. Za poÄetak, pogledajmo Å¡to je RAG i kako funkcionira:

## Retrieval Augmented Generation (RAG)

Chatbot pokretan LLM-om obraÄ‘uje korisniÄke upite za generiranje odgovora. Dizajniran je da bude interaktivan i ukljuÄuje se u razgovore s korisnicima o Å¡irokom rasponu tema. MeÄ‘utim, njegovi su odgovori ograniÄeni na kontekst koji mu je dostavljen i temeljne podatke za uÄenje. Na primjer, GPT-4 ima datum rezanja znanja u rujnu 2021., Å¡to znaÄi da ne zna za dogaÄ‘aje koji su se dogodili nakon tog datuma. Osim toga, podaci koriÅ¡teni za treniranje LLM-ova ne ukljuÄuju povjerljive informacije poput osobnih biljeÅ¡ki ili uredskih priruÄnika.

### Kako RAG (Retrieval Augmented Generation) funkcionira

![crtanje koje prikazuje kako RAG funkcionira](../../../translated_images/hr/how-rag-works.f5d0ff63942bd3a6.webp)

Pretpostavimo da Å¾elite pokrenuti chatbota koji kreira kvizove iz vaÅ¡ih biljeÅ¡ki, trebat Ä‡e vam veza s bazom znanja. Tu na scenu stupa RAG. RAG-ovi funkcioniraju na sljedeÄ‡i naÄin:

- **Baza znanja:** Prije dohvaÄ‡anja ti dokumenti trebaju biti uneseni i prethodno obraÄ‘eni, obiÄno razbijeni na manje cjeline, pretvoreni u tekstualne ugradnje i pohranjeni u bazu podataka.

- **KorisniÄki upit:** korisnik postavlja pitanje

- **DohvaÄ‡anje:** Kada korisnik postavi pitanje, model ugradnje dohvaÄ‡a relevantne informacije iz naÅ¡e baze znanja kako bi pruÅ¾io viÅ¡e konteksta koji Ä‡e se ukljuÄiti u upit.

- **ProÅ¡irena Generacija:** LLM poboljÅ¡ava svoj odgovor na temelju dohvaÄ‡enih podataka. OmoguÄ‡uje da generirani odgovor ne bude samo na temelju prethodno treniranih podataka nego i relevantnih informacija iz dodanog konteksta. DohvaÄ‡eni podaci koriste se za obogaÄ‡ivanje odgovora LLM-a. LLM zatim vraÄ‡a odgovor na korisniÄko pitanje.

![crtanje koje prikazuje arhitekturu RAG](../../../translated_images/hr/encoder-decode.f2658c25d0eadee2.webp)

Arhitektura RAG implementirana je koriÅ¡tenjem transformera koji se sastoje od dva dijela: kodera i dekodera. Na primjer, kada korisnik postavi pitanje, ulazni tekst se 'kodira' u vektore koji hvataju znaÄenje rijeÄi, a vektori se 'dekodiraju' u naÅ¡ indeks dokumenata i generiraju novi tekst na temelju korisniÄkog upita. LLM koristi model kodera i dekodera za generiranje izlaza.

Dvije pristupa implementaciji RAG prema predloÅ¾enom radu: [Retrieval-Augmented Generation for Knowledge intensive NLP (natural language processing software) Tasks](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) su:

- **_RAG-Sequence_** koristi dohvaÄ‡ene dokumente za predviÄ‘anje najboljeg moguÄ‡eg odgovora na korisniÄki upit

- **RAG-Token** koristi dokumente za generiranje sljedeÄ‡eg tokena, zatim ih dohvaÄ‡a da odgovori na korisniÄki upit

### ZaÅ¡to koristiti RAG?

- **Bogatstvo informacija:** osigurava da su tekstualni odgovori aÅ¾urni i aktualni. Time poboljÅ¡ava izvedbu na zadacima specifiÄnim za domenu pristupanjem internom znanju baze.

- Smanjuje izmiÅ¡ljanje koriÅ¡tenjem **provjerljivih podataka** u bazi znanja za pruÅ¾anje konteksta korisniÄkim upitima.

- **Isplativ je** jer je ekonomiÄniji u usporedbi s finim podeÅ¡avanjem LLM-a

## Kreiranje baze znanja

NaÅ¡a je aplikacija temeljena na naÅ¡im osobnim podacima, tj. lekciji o neuronskim mreÅ¾ama na kurikulumu AI za poÄetnike.

### Vektorske baze podataka

Vektorska baza podataka, za razliku od tradicionalnih baza podataka, je specijalizirana baza dizajnirana za pohranu, upravljanje i pretraÅ¾ivanje ugraÄ‘enih vektora. Pohranjuje numeriÄke prikaze dokumenata. Razbijanje podataka u numeriÄke ugradnje olakÅ¡ava naÅ¡em AI sustavu razumijevanje i obradu podataka.

UgraÄ‘ene podatke pohranjujemo u vektorske baze podataka jer LLM-ovi imaju ograniÄenje broja tokena koje primaju kao ulaz. Kako ne moÅ¾ete poslati cijele ugradbe u LLM, morat Ä‡emo ih razbiti u cjeline, a kada korisnik postavi pitanje, vraÄ‡aju se najviÅ¡e povezane ugradbe zajedno s upitom. Razbijanje takoÄ‘er smanjuje troÅ¡kove broja tokena poslanih kroz LLM.

Neki od popularnih vektorskih baza podataka su Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant i DeepLake. MoÅ¾ete kreirati model Azure Cosmos DB koristeÄ‡i Azure CLI s ovom naredbom:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```


### Od teksta do ugradnji

Prije nego Å¡to pohranimo naÅ¡e podatke, moramo ih pretvoriti u vektorske ugradnje prije pohrane u bazu podataka. Ako radite s velikim dokumentima ili dugaÄkim tekstovima, moÅ¾ete ih razbiti na dijelove prema oÄekivanim upitima. Razbijanje se moÅ¾e napraviti na razini reÄenica ili paragrafa. BuduÄ‡i da razbijanje izvlaÄi znaÄenja iz rijeÄi oko njih, moÅ¾ete dodati dodatni kontekst u dio, na primjer, dodavanjem naslova dokumenta ili ukljuÄivanjem nekog teksta prije ili poslije dijela. Podatke moÅ¾ete razbiti na sljedeÄ‡i naÄin:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # Ako zadnji dio nije dosegnuo minimalnu duljinu, dodajte ga ipak
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```


Nakon razbijanja moÅ¾emo ugraÄ‘ivati tekst koristeÄ‡i razliÄite modele ugradnje. Neki od modela koje moÅ¾ete koristiti su: word2vec, ada-002 od OpenAI-ja, Azure Computer Vision i mnogi drugi. Izbor modela ovisi o jezicima koje koristite, tipu sadrÅ¾aja koji se kodira (tekst/slike/zvuk), veliÄini ulaza koju moÅ¾e kodirati i duljini izlazne ugradnje.

Primjer ugraÄ‘enog teksta pomoÄ‡u OpenAI modela `text-embedding-ada-002` je:
![ugradnja rijeÄi maÄka](../../../translated_images/hr/cat.74cbd7946bc9ca38.webp)

## DohvaÄ‡anje i Vektorsko PretraÅ¾ivanje

Kad korisnik postavi pitanje, retriver ga pretvara u vektor pomoÄ‡u enkodera upita, zatim pretraÅ¾uje naÅ¡ indeks dokumenata za relevantne vektore u dokumentu vezane uz ulazni upit. Nakon toga, konvertira i ulazni i dokumentarne vektore u tekst i prosljeÄ‘uje ih LLM-u.

### DohvaÄ‡anje

DohvaÄ‡anje se dogaÄ‘a kada sustav pokuÅ¡ava brzo pronaÄ‡i dokumente iz indeksa koji zadovoljavaju kriterije pretraÅ¾ivanja. Cilj retrivera je dobiti dokumente koji Ä‡e se koristiti za pruÅ¾anje konteksta i utemeljivanje LLM-a na vaÅ¡im podacima.

Postoji nekoliko naÄina za izvrÅ¡enje pretraÅ¾ivanja unutar naÅ¡e baze podataka kao Å¡to su:

- **PretraÅ¾ivanje kljuÄnih rijeÄi** - koristi se za tekstualna pretraÅ¾ivanja

- **Vektorsko pretraÅ¾ivanje** - pretvara dokumente iz teksta u vektorske prikaze koristeÄ‡i modele ugradnje, dopuÅ¡tajuÄ‡i **semantiÄko pretraÅ¾ivanje** koristeÄ‡i znaÄenje rijeÄi. DohvaÄ‡anje se vrÅ¡i upitivanjem dokumenata Äiji su vektorski prikazi najbliÅ¾i korisniÄkom pitanju.

- **Hibridno** - kombinacija pretraÅ¾ivanja kljuÄnih rijeÄi i vektorskog pretraÅ¾ivanja.

Izazov u dohvatu nastaje kada u bazi podataka nema sliÄnog odgovora na upit, tada sustav vraÄ‡a najbolje moguÄ‡e informacije. MeÄ‘utim, moÅ¾ete koristiti taktike kao Å¡to su postavljanje maksimalne udaljenosti za relevantnost ili koristiti hibridno pretraÅ¾ivanje koje kombinira i kljuÄne rijeÄi i vektorsko pretraÅ¾ivanje. U ovoj lekciji koristit Ä‡emo hibridno pretraÅ¾ivanje, kombinaciju oba naÄina pretraÅ¾ivanja. Pohranit Ä‡emo naÅ¡e podatke u tablicu s stupcima koji sadrÅ¾e dijelove i ugradnje.

### SliÄnost vektora

Retriver Ä‡e pretraÅ¾ivati u bazi znanja za ugradnjama koje su blizu jedna drugoj, najbliÅ¾im susjedom, jer su tekstovi sliÄni. U scenariju korisniÄkog upita, upit se prvo ugraÄ‘uje zatim usporeÄ‘uje sliÄnim ugradnjama. UobiÄajena mjera koja se koristi za odreÄ‘ivanje koliko su razliÄiti vektori sliÄni je kosinusna sliÄnost, koja je zasnovana na kutu izmeÄ‘u dva vektora.

SliÄnost moÅ¾emo mjeriti i drugim alternativama kao Å¡to su Euklidska udaljenost, Å¡to je pravocrtna udaljenost izmeÄ‘u krajeva vektora, i skalarni produkt koji mjeri zbroj proizvoda odgovarajuÄ‡ih elemenata dva vektora.

### Indeks pretraÅ¾ivanja

Prilikom dohvaÄ‡anja podataka, potrebno je najprije izgraditi indeks pretraÅ¾ivanja za bazu znanja. Indeks Ä‡e pohraniti naÅ¡e ugradnje i moÅ¾e brzo dohvatiti najsliÄnije dijelove Äak i u velikoj bazi. Indeks moÅ¾emo napraviti lokalno koristeÄ‡i:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Kreirajte indeks pretraÅ¾ivanja
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# Za upit indeksa moÅ¾ete koristiti metodu kneighbors
distances, indices = nbrs.kneighbors(embeddings)
```


### Ponovno rangiranje

Nakon Å¡to upitamo bazu podataka, moÅ¾da Ä‡e biti potrebno sortirati rezultate od najrelevantnijih. LLM za ponovno rangiranje koristi strojno uÄenje za poboljÅ¡anje relevantnosti rezultata pretraÅ¾ivanja tako da ih sortira po stupnju relevantnosti. KoristeÄ‡i Azure AI Search, ponovno rangiranje se automatski izvrÅ¡ava pomoÄ‡u semantiÄkog rerankera. Primjer kako ponovno rangiranje funkcionira pomoÄ‡u najbliÅ¾ih susjeda:

```python
# PronaÄ‘i najsliÄnije dokumente
distances, indices = nbrs.kneighbors([query_vector])

index = []
# IspiÅ¡i najsliÄnije dokumente
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```


## Spojimo sve zajedno

Zadnji korak je dodati naÅ¡ LLM u proces kako bismo mogli dobivati odgovore utemeljene na naÅ¡im podacima. MoÅ¾emo ga implementirati na sljedeÄ‡i naÄin:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Pretvori pitanje u vektor upita
    query_vector = create_embeddings(user_input)

    # PronaÄ‘i najsliÄnije dokumente
    distances, indices = nbrs.kneighbors([query_vector])

    # dodaj dokumente u upit radi pruÅ¾anja konteksta
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # spoji povijest i korisniÄki unos
    history.append(user_input)

    # kreiraj objekt poruke
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": "\n\n".join(history) }
    ]

    # koristi chat dovrÅ¡etak za generiranje odgovora
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```


## Evaluacija naÅ¡e aplikacije

### Mjerne vrijednosti evaluacije

- Kvaliteta danih odgovora, osiguravajuÄ‡i da zvuÄe prirodno, teÄno i nalik Äovjeku

- Utemeljenost podataka: procjena dolazi li odgovor iz dostavljenih dokumenata

- Relevancija: procjena da odgovor odgovara i povezan je sa postavljenim pitanjem

- TeÄnost - promatranje da li odgovor gramatiÄki ima smisla

## Primjene koriÅ¡tenja RAG (Retrieval Augmented Generation) i vektorskih baza podataka

Postoji mnogo razliÄitih primjena gdje pozivi funkcijama mogu unaprijediti vaÅ¡u aplikaciju poput:

- Pitanja i odgovori: utemeljivanje podataka vaÅ¡e tvrtke u chat koji zaposlenici mogu koristiti za postavljanje pitanja.

- Sustavi preporuke: gdje moÅ¾ete kreirati sustav koji pronalazi najviÅ¡e sliÄne vrijednosti, npr. filmove, restorane i mnogo viÅ¡e.

- Usluge chatbota: moÅ¾ete pohraniti povijest razgovora i personalizirati konverzaciju na temelju korisniÄkih podataka.

- PretraÅ¾ivanje slika na temelju vektorskih ugradnji, korisno kod prepoznavanja slika i otkrivanja anomalija.

## SaÅ¾etak

Obradili smo temeljna podruÄja RAG-a od dodavanja naÅ¡ih podataka u aplikaciju, korisniÄki upit i izlaz. Za pojednostavljenje izrade RAG-a, moÅ¾ete koristiti okvire poput SemantiÄkog Kernel-a, Langchain-a ili Autogen-a.

## Zadatak

Za nastavak uÄenja o Retrieval Augmented Generation (RAG), moÅ¾ete izgraditi:

- Front-end za aplikaciju koristeÄ‡i okvir po vaÅ¡em izboru

- Iskoristiti okvir, bilo LangChain ili Semantic Kernel, i ponovno izgraditi svoju aplikaciju.

ÄŒestitamo na zavrÅ¡etku lekcije ğŸ‘.

## UÄenje ne prestaje ovdje, nastavite putovanje

Nakon zavrÅ¡etka lekcije, pogledajte naÅ¡u [kolekciju za uÄenje Generative AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) i nastavite unapreÄ‘ivati svoje znanje o Generative AI!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Izjava o odricanju od odgovornosti**:
Ovaj dokument preveden je pomoÄ‡u AI prevodilaÄke usluge [Co-op Translator](https://github.com/Azure/co-op-translator). Iako teÅ¾imo toÄnosti, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati sluÅ¾benim i autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakva nesporazuma ili kriva tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->