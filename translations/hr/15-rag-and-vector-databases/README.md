<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b4b0266fbadbba7ded891b6485adc66d",
  "translation_date": "2025-10-18T01:31:59+00:00",
  "source_file": "15-rag-and-vector-databases/README.md",
  "language_code": "hr"
}
-->
# Generiranje uz pomoÄ‡ pretraÅ¾ivanja (RAG) i vektorske baze podataka

[![Generiranje uz pomoÄ‡ pretraÅ¾ivanja (RAG) i vektorske baze podataka](../../../translated_images/15-lesson-banner.ac49e59506175d4fc6ce521561dab2f9ccc6187410236376cfaed13cde371b90.hr.png)](https://youtu.be/4l8zhHUBeyI?si=BmvDmL1fnHtgQYkL)

U lekciji o aplikacijama za pretraÅ¾ivanje, ukratko smo nauÄili kako integrirati vlastite podatke u modele velikih jezika (LLM). U ovoj lekciji Ä‡emo detaljnije istraÅ¾iti koncepte povezivanja vaÅ¡ih podataka s aplikacijom LLM, mehanizme tog procesa i metode za pohranu podataka, ukljuÄujuÄ‡i i ugraÄ‘ene podatke i tekst.

> **Video uskoro dolazi**

## Uvod

U ovoj lekciji obradit Ä‡emo sljedeÄ‡e:

- Uvod u RAG, Å¡to je to i zaÅ¡to se koristi u umjetnoj inteligenciji (AI).

- Razumijevanje Å¡to su vektorske baze podataka i kako ih kreirati za naÅ¡u aplikaciju.

- PraktiÄan primjer kako integrirati RAG u aplikaciju.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije, moÄ‡i Ä‡ete:

- Objasniti znaÄaj RAG-a u pretraÅ¾ivanju i obradi podataka.

- Postaviti RAG aplikaciju i povezati svoje podatke s LLM-om.

- UÄinkovito integrirati RAG i vektorske baze podataka u LLM aplikacije.

## NaÅ¡ scenarij: poboljÅ¡anje LLM-a vlastitim podacima

Za ovu lekciju Å¾elimo dodati vlastite biljeÅ¡ke u obrazovni startup, Å¡to Ä‡e omoguÄ‡iti chatbotu da dobije viÅ¡e informacija o razliÄitim temama. KoristeÄ‡i biljeÅ¡ke koje imamo, uÄenici Ä‡e moÄ‡i bolje uÄiti i razumjeti razliÄite teme, Å¡to Ä‡e im olakÅ¡ati pripremu za ispite. Za stvaranje naÅ¡eg scenarija koristit Ä‡emo:

- `Azure OpenAI:` LLM koji Ä‡emo koristiti za izradu naÅ¡eg chatbota

- `Lekcija za poÄetnike o neuronskim mreÅ¾ama:` ovo Ä‡e biti podaci na kojima Ä‡emo temeljiti naÅ¡ LLM

- `Azure AI Search` i `Azure Cosmos DB:` vektorska baza podataka za pohranu naÅ¡ih podataka i stvaranje indeksa pretraÅ¾ivanja

Korisnici Ä‡e moÄ‡i kreirati vjeÅ¾bovne kvizove iz svojih biljeÅ¡ki, kartice za ponavljanje i saÅ¾etke. Za poÄetak, pogledajmo Å¡to je RAG i kako funkcionira:

## Generiranje uz pomoÄ‡ pretraÅ¾ivanja (RAG)

Chatbot pokretan LLM-om obraÄ‘uje korisniÄke upite kako bi generirao odgovore. Dizajniran je da bude interaktivan i da komunicira s korisnicima o Å¡irokom spektru tema. MeÄ‘utim, njegovi odgovori su ograniÄeni na kontekst koji mu je dostupan i na osnovne podatke na kojima je treniran. Na primjer, GPT-4 ima ograniÄenje znanja do rujna 2021., Å¡to znaÄi da mu nedostaju informacije o dogaÄ‘ajima koji su se dogodili nakon tog razdoblja. Osim toga, podaci koriÅ¡teni za treniranje LLM-a iskljuÄuju povjerljive informacije poput osobnih biljeÅ¡ki ili priruÄnika za proizvode tvrtke.

### Kako funkcionira RAG (Generiranje uz pomoÄ‡ pretraÅ¾ivanja)

![crteÅ¾ koji prikazuje kako funkcionira RAG](../../../translated_images/how-rag-works.f5d0ff63942bd3a638e7efee7a6fce7f0787f6d7a1fca4e43f2a7a4d03cde3e0.hr.png)

Pretpostavimo da Å¾elite implementirati chatbot koji kreira kvizove iz vaÅ¡ih biljeÅ¡ki, trebat Ä‡e vam veza s bazom znanja. Tu dolazi RAG u pomoÄ‡. RAG funkcionira na sljedeÄ‡i naÄin:

- **Baza znanja:** Prije pretraÅ¾ivanja, dokumenti se moraju unijeti i obraditi, obiÄno razbijanjem velikih dokumenata na manje dijelove, pretvaranjem u ugraÄ‘ene tekstove i pohranjivanjem u bazu podataka.

- **Upit korisnika:** korisnik postavlja pitanje.

- **PretraÅ¾ivanje:** Kada korisnik postavi pitanje, model za ugraÄ‘ivanje pronalazi relevantne informacije iz naÅ¡e baze znanja kako bi pruÅ¾io viÅ¡e konteksta koji Ä‡e biti ukljuÄen u upit.

- **Generiranje uz pomoÄ‡ pretraÅ¾ivanja:** LLM poboljÅ¡ava svoj odgovor na temelju pronaÄ‘enih podataka. To omoguÄ‡uje da generirani odgovor ne bude samo temeljen na prethodno treniranim podacima, veÄ‡ i na relevantnim informacijama iz dodanog konteksta. PronaÄ‘eni podaci koriste se za poboljÅ¡anje odgovora LLM-a. LLM zatim vraÄ‡a odgovor na korisniÄko pitanje.

![crteÅ¾ koji prikazuje arhitekturu RAG-a](../../../translated_images/encoder-decode.f2658c25d0eadee2377bb28cf3aee8b67aa9249bf64d3d57bb9be077c4bc4e1a.hr.png)

Arhitektura RAG-a implementira se pomoÄ‡u transformatora koji se sastoje od dva dijela: kodera i dekodera. Na primjer, kada korisnik postavi pitanje, ulazni tekst se 'kodira' u vektore koji sadrÅ¾e znaÄenje rijeÄi, a vektori se 'dekodiraju' u naÅ¡ indeks dokumenata i generiraju novi tekst na temelju korisniÄkog upita. LLM koristi model kodera-dekodera za generiranje izlaza.

Dva pristupa pri implementaciji RAG-a prema predloÅ¾enom radu: [Generiranje uz pomoÄ‡ pretraÅ¾ivanja za zadatke obrade prirodnog jezika (NLP)](https://arxiv.org/pdf/2005.11401.pdf?WT.mc_id=academic-105485-koreyst) su:

- **_RAG-Sequence_** koristi pronaÄ‘ene dokumente za predviÄ‘anje najboljeg moguÄ‡eg odgovora na korisniÄki upit.

- **RAG-Token** koristi dokumente za generiranje sljedeÄ‡eg tokena, zatim ih pronalazi kako bi odgovorio na korisniÄki upit.

### ZaÅ¡to koristiti RAG?Â 

- **Bogatstvo informacija:** osigurava da su tekstualni odgovori aÅ¾urirani i aktualni. Stoga poboljÅ¡ava performanse na zadacima specifiÄnim za odreÄ‘eno podruÄje pristupajuÄ‡i unutarnjoj bazi znanja.

- Smanjuje izmiÅ¡ljanje koristeÄ‡i **provjerljive podatke** iz baze znanja za pruÅ¾anje konteksta korisniÄkim upitima.

- **EkonomiÄan je** jer je isplativiji u usporedbi s finim podeÅ¡avanjem LLM-a.

## Kreiranje baze znanja

NaÅ¡a aplikacija temelji se na naÅ¡im osobnim podacima, tj. lekciji o neuronskim mreÅ¾ama iz kurikuluma AI za poÄetnike.

### Vektorske baze podataka

Vektorska baza podataka, za razliku od tradicionalnih baza podataka, specijalizirana je baza podataka dizajnirana za pohranu, upravljanje i pretraÅ¾ivanje ugraÄ‘enih vektora. Pohranjuje numeriÄke reprezentacije dokumenata. Razbijanje podataka na numeriÄke ugraÄ‘ene podatke olakÅ¡ava naÅ¡em AI sustavu razumijevanje i obradu podataka.

UgraÄ‘ene podatke pohranjujemo u vektorske baze podataka jer LLM-ovi imaju ograniÄenje broja tokena koje prihvaÄ‡aju kao ulaz. BuduÄ‡i da ne moÅ¾ete proslijediti cijele ugraÄ‘ene podatke LLM-u, morat Ä‡emo ih razbiti na dijelove, a kada korisnik postavi pitanje, ugraÄ‘eni podaci koji su najbliÅ¾i pitanju bit Ä‡e vraÄ‡eni zajedno s upitom. Razbijanje takoÄ‘er smanjuje troÅ¡kove broja tokena koji prolaze kroz LLM.

Neke popularne vektorske baze podataka ukljuÄuju Azure Cosmos DB, Clarifyai, Pinecone, Chromadb, ScaNN, Qdrant i DeepLake. MoÅ¾ete kreirati model Azure Cosmos DB koristeÄ‡i Azure CLI s sljedeÄ‡om naredbom:

```bash
az login
az group create -n <resource-group-name> -l <location>
az cosmosdb create -n <cosmos-db-name> -r <resource-group-name>
az cosmosdb list-keys -n <cosmos-db-name> -g <resource-group-name>
```

### Od teksta do ugraÄ‘enih podataka

Prije nego Å¡to pohranimo naÅ¡e podatke, morat Ä‡emo ih pretvoriti u vektorske ugraÄ‘ene podatke prije nego Å¡to ih pohranimo u bazu podataka. Ako radite s velikim dokumentima ili dugim tekstovima, moÅ¾ete ih razbiti na temelju upita koje oÄekujete. Razbijanje se moÅ¾e obaviti na razini reÄenice ili na razini paragrafa. BuduÄ‡i da razbijanje izvlaÄi znaÄenja iz rijeÄi koje ih okruÅ¾uju, moÅ¾ete dodati neki drugi kontekst dijelu, na primjer, dodavanjem naslova dokumenta ili ukljuÄivanjem nekog teksta prije ili nakon dijela. Podatke moÅ¾ete razbiti na sljedeÄ‡i naÄin:

```python
def split_text(text, max_length, min_length):
    words = text.split()
    chunks = []
    current_chunk = []

    for word in words:
        current_chunk.append(word)
        if len(' '.join(current_chunk)) < max_length and len(' '.join(current_chunk)) > min_length:
            chunks.append(' '.join(current_chunk))
            current_chunk = []

    # If the last chunk didn't reach the minimum length, add it anyway
    if current_chunk:
        chunks.append(' '.join(current_chunk))

    return chunks
```

Jednom razbijeni, moÅ¾emo zatim ugraditi naÅ¡ tekst koristeÄ‡i razliÄite modele za ugraÄ‘ivanje. Neki modeli koje moÅ¾ete koristiti ukljuÄuju: word2vec, ada-002 od OpenAI, Azure Computer Vision i mnoge druge. Odabir modela ovisit Ä‡e o jezicima koje koristite, vrsti sadrÅ¾aja koji se kodira (tekst/slike/audio), veliÄini ulaza koji moÅ¾e kodirati i duljini izlaza ugraÄ‘enih podataka.

Primjer ugraÄ‘enog teksta koristeÄ‡i OpenAI-ov model `text-embedding-ada-002` je:
![ugraÄ‘ivanje rijeÄi maÄka](../../../translated_images/cat.74cbd7946bc9ca380a8894c4de0c706a4f85b16296ffabbf52d6175df6bf841e.hr.png)

## PretraÅ¾ivanje i vektorsko pretraÅ¾ivanje

Kada korisnik postavi pitanje, pretraÅ¾ivaÄ ga pretvara u vektor koristeÄ‡i kodera upita, zatim pretraÅ¾uje naÅ¡ indeks dokumenata za relevantne vektore u dokumentu koji su povezani s ulazom. Nakon toga, pretvara ulazni vektor i vektore dokumenata u tekst i prosljeÄ‘uje ih kroz LLM.

### PretraÅ¾ivanje

PretraÅ¾ivanje se dogaÄ‘a kada sustav pokuÅ¡ava brzo pronaÄ‡i dokumente iz indeksa koji zadovoljavaju kriterije pretraÅ¾ivanja. Cilj pretraÅ¾ivaÄa je dobiti dokumente koji Ä‡e se koristiti za pruÅ¾anje konteksta i povezivanje LLM-a s vaÅ¡im podacima.

Postoji nekoliko naÄina za pretraÅ¾ivanje unutar naÅ¡e baze podataka, kao Å¡to su:

- **PretraÅ¾ivanje kljuÄnih rijeÄi** - koristi se za pretraÅ¾ivanje teksta.

- **SemantiÄko pretraÅ¾ivanje** - koristi semantiÄko znaÄenje rijeÄi.

- **Vektorsko pretraÅ¾ivanje** - pretvara dokumente iz teksta u vektorske reprezentacije koristeÄ‡i modele za ugraÄ‘ivanje. PretraÅ¾ivanje se obavlja upitom dokumenata Äije su vektorske reprezentacije najbliÅ¾e korisniÄkom pitanju.

- **Hibridno** - kombinacija pretraÅ¾ivanja kljuÄnih rijeÄi i vektorskog pretraÅ¾ivanja.

Izazov s pretraÅ¾ivanjem nastaje kada u bazi podataka ne postoji sliÄan odgovor na upit, sustav Ä‡e tada vratiti najbolje informacije koje moÅ¾e pronaÄ‡i, meÄ‘utim, moÅ¾ete koristiti taktike poput postavljanja maksimalne udaljenosti za relevantnost ili koristiti hibridno pretraÅ¾ivanje koje kombinira kljuÄne rijeÄi i vektorsko pretraÅ¾ivanje. U ovoj lekciji koristit Ä‡emo hibridno pretraÅ¾ivanje, kombinaciju vektorskog i pretraÅ¾ivanja kljuÄnih rijeÄi. Pohranit Ä‡emo naÅ¡e podatke u dataframe sa stupcima koji sadrÅ¾e dijelove teksta kao i ugraÄ‘ene podatke.

### Vektorska sliÄnost

PretraÅ¾ivaÄ Ä‡e pretraÅ¾ivati bazu znanja za ugraÄ‘ene podatke koji su blizu jedni drugima, najbliÅ¾i susjedi, jer su to tekstovi koji su sliÄni. U sluÄaju da korisnik postavi upit, prvo se ugraÄ‘uje, a zatim se podudara sa sliÄnim ugraÄ‘enim podacima. UobiÄajena mjera koja se koristi za odreÄ‘ivanje koliko su razliÄiti vektori sliÄni je kosinusna sliÄnost koja se temelji na kutu izmeÄ‘u dva vektora.

MoÅ¾emo mjeriti sliÄnost koristeÄ‡i i druge alternative poput Euklidske udaljenosti, koja je ravna linija izmeÄ‘u krajnjih toÄaka vektora, i skalarni produkt koji mjeri zbroj proizvoda odgovarajuÄ‡ih elemenata dvaju vektora.

### Indeks pretraÅ¾ivanja

Prilikom pretraÅ¾ivanja, trebat Ä‡emo izgraditi indeks pretraÅ¾ivanja za naÅ¡u bazu znanja prije nego Å¡to obavimo pretraÅ¾ivanje. Indeks Ä‡e pohraniti naÅ¡e ugraÄ‘ene podatke i moÄ‡i Ä‡e brzo pronaÄ‡i najsliÄnije dijelove Äak i u velikoj bazi podataka. Indeks moÅ¾emo kreirati lokalno koristeÄ‡i:

```python
from sklearn.neighbors import NearestNeighbors

embeddings = flattened_df['embeddings'].to_list()

# Create the search index
nbrs = NearestNeighbors(n_neighbors=5, algorithm='ball_tree').fit(embeddings)

# To query the index, you can use the kneighbors method
distances, indices = nbrs.kneighbors(embeddings)
```

### Ponovno rangiranje

Nakon Å¡to ste pretraÅ¾ili bazu podataka, moÅ¾da Ä‡ete trebati sortirati rezultate od najrelevantnijih. LLM za ponovno rangiranje koristi strojno uÄenje za poboljÅ¡anje relevantnosti rezultata pretraÅ¾ivanja tako Å¡to ih sortira od najrelevantnijih. KoristeÄ‡i Azure AI Search, ponovno rangiranje se automatski obavlja za vas koristeÄ‡i semantiÄki ponovni rangiratelj. Primjer kako ponovno rangiranje funkcionira koristeÄ‡i najbliÅ¾e susjede:

```python
# Find the most similar documents
distances, indices = nbrs.kneighbors([query_vector])

index = []
# Print the most similar documents
for i in range(3):
    index = indices[0][i]
    for index in indices[0]:
        print(flattened_df['chunks'].iloc[index])
        print(flattened_df['path'].iloc[index])
        print(flattened_df['distances'].iloc[index])
    else:
        print(f"Index {index} not found in DataFrame")
```

## Spajanje svega zajedno

Posljednji korak je dodavanje naÅ¡eg LLM-a u proces kako bismo mogli dobiti odgovore koji se temelje na naÅ¡im podacima. MoÅ¾emo ga implementirati na sljedeÄ‡i naÄin:

```python
user_input = "what is a perceptron?"

def chatbot(user_input):
    # Convert the question to a query vector
    query_vector = create_embeddings(user_input)

    # Find the most similar documents
    distances, indices = nbrs.kneighbors([query_vector])

    # add documents to query  to provide context
    history = []
    for index in indices[0]:
        history.append(flattened_df['chunks'].iloc[index])

    # combine the history and the user input
    history.append(user_input)

    # create a message object
    messages=[
        {"role": "system", "content": "You are an AI assistant that helps with AI questions."},
        {"role": "user", "content": history[-1]}
    ]

    # use chat completion to generate a response
    response = openai.chat.completions.create(
        model="gpt-4",
        temperature=0.7,
        max_tokens=800,
        messages=messages
    )

    return response.choices[0].message

chatbot(user_input)
```

## Evaluacija naÅ¡e aplikacije

### Metrike evaluacije

- Kvaliteta odgovora: osiguravanje da zvuÄe prirodno, teÄno i ljudski.

- Povezanost podataka: procjena je li odgovor doÅ¡ao iz dostavljenih dokumenata.

- Relevantnost: procjena odgovara li odgovor i je li povezan s postavljenim pitanjem.

- TeÄnost: procjena je li odgovor gramatiÄki smislen.

## Primjene RAG-a (Generiranje uz pomoÄ‡ pretraÅ¾ivanja) i vektorskih baza podataka

Postoji mnogo razliÄitih primjena gdje pozivi funkcija mogu poboljÅ¡ati vaÅ¡u aplikaciju, poput:

- Postavljanje pitanja i odgovaranje: povezivanje podataka vaÅ¡e tvrtke s chatom koji zaposlenici mogu koristiti za postavljanje pitanja.

- Sustavi preporuka: gdje moÅ¾ete kreirati sustav koji pronalazi najsliÄnije vrijednosti, npr. filmove, restorane i mnoge druge.

- Usluge chatbota: moÅ¾ete pohraniti povijest razgovora i personalizirati komunikaciju na temelju korisniÄkih podataka.

- PretraÅ¾ivanje slika na temelju vektorskih ugraÄ‘enih podataka, korisno pri prepoznavanju slika i otkrivanju anomalija.

## SaÅ¾etak

Obradili smo osnovne aspekte RAG-a, od dodavanja naÅ¡ih podataka u aplikaciju, korisniÄkog upita do izlaza. Kako bismo pojednostavili kreiranje RAG-a, moÅ¾ete koristiti okvire poput Semantic Kernel, Langchain ili Autogen.

## Zadatak

Za nastavak uÄenja o Generiranju uz pomoÄ‡ pretraÅ¾ivanja (RAG) moÅ¾ete:

- Izraditi korisniÄko suÄelje za aplikaciju koristeÄ‡i okvir po vaÅ¡em izboru.

- Koristiti okvir, bilo LangChain ili Semantic Kernel, i ponovno kreirati svoju aplikaciju.

ÄŒestitamo na zavrÅ¡etku lekcije ğŸ‘.

## UÄenje ne prestaje ovdje, nastavite svoje putovanje

Nakon zavrÅ¡etka ove lekcije, pogledajte naÅ¡u [Generativnu AI kolekciju za uÄenje](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili unapreÄ‘ivati svoje znanje o generativnoj umjetnoj inteligenciji!

---

**Izjava o odricanju odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.