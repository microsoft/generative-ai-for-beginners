{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Poglavlje 7: Izrada chat aplikacija\n",
    "## Brzi početak s Github Models API-jem\n",
    "\n",
    "Ova bilježnica je prilagođena iz [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) koji sadrži bilježnice za pristup [Azure OpenAI](notebook-azure-openai.ipynb) uslugama.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Pregled  \n",
    "\"Veliki jezični modeli su funkcije koje preslikavaju tekst u tekst. Kada dobiju ulazni niz teksta, veliki jezični model pokušava predvidjeti koji će tekst slijediti\"(1). Ova \"brza početna\" bilježnica upoznat će korisnike s osnovnim pojmovima vezanim uz LLM-ove, ključnim paketima potrebnim za početak rada s AML-om, laganim uvodom u dizajn upita te nekoliko kratkih primjera različitih slučajeva upotrebe.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sadržaj\n",
    "\n",
    "[Pregled](../../../../07-building-chat-applications/python)  \n",
    "[Kako koristiti OpenAI uslugu](../../../../07-building-chat-applications/python)  \n",
    "[1. Kreiranje vaše OpenAI usluge](../../../../07-building-chat-applications/python)  \n",
    "[2. Instalacija](../../../../07-building-chat-applications/python)  \n",
    "[3. Podaci za prijavu](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Primjeri upotrebe](../../../../07-building-chat-applications/python)  \n",
    "[1. Sažimanje teksta](../../../../07-building-chat-applications/python)  \n",
    "[2. Klasifikacija teksta](../../../../07-building-chat-applications/python)  \n",
    "[3. Generiranje novih imena proizvoda](../../../../07-building-chat-applications/python)  \n",
    "[4. Fino podešavanje klasifikatora](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Reference](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Napravite svoj prvi prompt  \n",
    "Ova kratka vježba pružit će vam osnovni uvod u slanje promptova modelu u Github Models za jednostavan zadatak \"sažimanja\".\n",
    "\n",
    "\n",
    "**Koraci**:  \n",
    "1. Instalirajte biblioteku `azure-ai-inference` u svoje Python okruženje, ako to već niste učinili.  \n",
    "2. Učitajte standardne pomoćne biblioteke i postavite vjerodajnice za Github Models.  \n",
    "3. Odaberite model za svoj zadatak  \n",
    "4. Napravite jednostavan prompt za model  \n",
    "5. Pošaljite svoj zahtjev na model API!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 1. Instalirajte `azure-ai-inference`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install azure-ai-inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 2. Uvezite pomoćne biblioteke i inicijalizirajte vjerodajnice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Pronalaženje pravog modela  \n",
    "GPT-3.5-turbo ili GPT-4 modeli mogu razumjeti i generirati prirodni jezik.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model_name = \"gpt-4o\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Dizajn upita  \n",
    "\n",
    "\"Čarolija velikih jezičnih modela je u tome što, trenirajući se da minimiziraju pogreške u predviđanju na ogromnim količinama teksta, modeli na kraju nauče pojmove korisne za ta predviđanja. Na primjer, nauče pojmove kao što su\"(1):\n",
    "\n",
    "* kako se pišu riječi\n",
    "* kako funkcionira gramatika\n",
    "* kako preformulirati rečenicu\n",
    "* kako odgovarati na pitanja\n",
    "* kako voditi razgovor\n",
    "* kako pisati na mnogim jezicima\n",
    "* kako programirati\n",
    "* itd.\n",
    "\n",
    "#### Kako upravljati velikim jezičnim modelom  \n",
    "\"Od svih ulaza u veliki jezični model, daleko najutjecajniji je tekstualni upit(1).\n",
    "\n",
    "Veliki jezični modeli mogu se potaknuti na generiranje izlaza na nekoliko načina:\n",
    "\n",
    "Instrukcija: Recite modelu što želite\n",
    "Dovršavanje: Potaknite model da dovrši početak onoga što želite\n",
    "Demonstracija: Pokažite modelu što želite, i to:\n",
    "S nekoliko primjera u upitu\n",
    "S mnogo stotina ili tisuća primjera u skupu podataka za fino podešavanje\"\n",
    "\n",
    "\n",
    "\n",
    "#### Tri su osnovne smjernice za izradu upita:\n",
    "\n",
    "**Pokažite i recite**. Jasno dajte do znanja što želite, bilo kroz upute, primjere ili kombinaciju oboje. Ako želite da model posloži popis stavki abecednim redom ili da klasificira odlomak prema sentimentu, pokažite mu da je to ono što želite.\n",
    "\n",
    "**Osigurajte kvalitetne podatke**. Ako pokušavate izraditi klasifikator ili želite da model slijedi određeni obrazac, pobrinite se da ima dovoljno primjera. Svakako provjerite primjere — model je obično dovoljno pametan da prepozna osnovne pravopisne pogreške i da vam odgovori, ali isto tako može pretpostaviti da su one namjerne, što može utjecati na odgovor.\n",
    "\n",
    "**Provjerite postavke.** Postavke temperature i top_p određuju koliko će model biti deterministički u generiranju odgovora. Ako tražite odgovor na koji postoji samo jedan točan odgovor, postavite ih niže. Ako želite raznovrsnije odgovore, možda ćete ih htjeti postaviti više. Najčešća pogreška kod ovih postavki je pretpostavka da su to kontrole \"pametnosti\" ili \"kreativnosti\".\n",
    "\n",
    "\n",
    "Izvor: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Sažmi tekst  \n",
    "#### Izazov  \n",
    "Sažmi tekst dodavanjem 'tl;dr:' na kraj odlomka. Primijetite kako model zna obaviti razne zadatke bez dodatnih uputa. Možete eksperimentirati s opisnijim promptima od tl;dr kako biste promijenili ponašanje modela i prilagodili sažetak koji dobijete(3).\n",
    "\n",
    "Nedavna istraživanja pokazala su značajan napredak u mnogim NLP zadacima i testovima zahvaljujući predtreningu na velikom korpusu teksta, nakon čega slijedi fino podešavanje za određeni zadatak. Iako je ova metoda obično neovisna o zadatku po svojoj arhitekturi, i dalje zahtijeva posebne skupove podataka za fino podešavanje s tisućama ili desecima tisuća primjera. S druge strane, ljudi obično mogu obaviti novi jezični zadatak već nakon nekoliko primjera ili jednostavnih uputa – što je nešto s čime se današnji NLP sustavi još uvijek uglavnom muče. Ovdje pokazujemo da povećanje jezičnih modela znatno poboljšava neovisnu izvedbu na zadacima s malo primjera, ponekad čak dosežući konkurentnost s dosadašnjim najboljim pristupima finog podešavanja.\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Vježbe za nekoliko slučajeva upotrebe  \n",
    "1. Sažmi tekst  \n",
    "2. Klasificiraj tekst  \n",
    "3. Generiraj nova imena proizvoda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klasificiraj tekst  \n",
    "#### Izazov  \n",
    "Klasificiraj stavke u kategorije koje se navode prilikom izvođenja. U sljedećem primjeru, u upitu navodimo i kategorije i tekst koji treba klasificirati (*playground_reference).\n",
    "\n",
    "Upit korisnika: Pozdrav, jedna tipka na mojoj tipkovnici za laptop se nedavno pokvarila i trebat će mi zamjena:\n",
    "\n",
    "Klasificirana kategorija:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Generiraj nova imena proizvoda\n",
    "#### Izazov\n",
    "Stvori imena proizvoda na temelju primjera riječi. U ovom zadatku uključujemo informacije o proizvodu za koji ćemo generirati imena. Također dajemo sličan primjer kako bismo pokazali obrazac koji želimo dobiti. Postavili smo i visoku vrijednost temperature kako bismo povećali nasumičnost i dobili inovativnije odgovore.\n",
    "\n",
    "Opis proizvoda: Aparat za pripremu milkshakea kod kuće\n",
    "Ključne riječi: brzo, zdravo, kompaktno.\n",
    "Imena proizvoda: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Opis proizvoda: Par cipela koje pristaju svakom broju stopala.\n",
    "Ključne riječi: prilagodljivo, pristaje, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.complete(\n",
    "  model=model_name,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Reference  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Primjeri](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Najbolje prakse za fino podešavanje GPT-3 za klasifikaciju teksta](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Za dodatnu pomoć  \n",
    "[OpenAI Komercijalni tim](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Suradnici\n",
    "* [Chew-Yean Yam](https://www.linkedin.com/in/cyyam/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Odricanje od odgovornosti**:  \nOvaj dokument je preveden pomoću AI usluge prevođenja [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati točnost, imajte na umu da automatski prijevodi mogu sadržavati pogreške ili netočnosti. Izvorni dokument na izvornom jeziku treba smatrati mjerodavnim izvorom. Za ključne informacije preporučuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakva nesporazume ili pogrešna tumačenja koja proizlaze iz korištenja ovog prijevoda.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "3eeb8e5cad61b52a8366f6259a53ed49",
   "translation_date": "2025-08-25T17:52:02+00:00",
   "source_file": "07-building-chat-applications/python/githubmodels-assignment.ipynb",
   "language_code": "hr"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}