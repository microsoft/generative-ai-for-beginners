<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:42:07+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "hr"
}
-->
# IstraÅ¾ivanje i usporedba razliÄitih LLM-ova

[![IstraÅ¾ivanje i usporedba razliÄitih LLM-ova](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.hr.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite na gornju sliku za pregled videa ove lekcije_

U prethodnoj lekciji vidjeli smo kako Generativna AI mijenja tehnoloÅ¡ki krajolik, kako rade Veliki jeziÄni modeli (LLM-ovi) i kako ih tvrtka â€“ poput naÅ¡eg startupa â€“ moÅ¾e primijeniti na svoje sluÄajeve upotrebe i rasti! U ovom poglavlju usporedit Ä‡emo i razlikovati razliÄite vrste velikih jeziÄnih modela (LLM-ova) kako bismo razumjeli njihove prednosti i nedostatke.

SljedeÄ‡i korak u putovanju naÅ¡eg startupa je istraÅ¾iti trenutni krajolik LLM-ova i razumjeti koji su prikladni za naÅ¡ sluÄaj upotrebe.

## Uvod

Ova lekcija Ä‡e obuhvatiti:

- RazliÄite vrste LLM-ova u trenutnom krajoliku.
- Testiranje, iteriranje i usporedbu razliÄitih modela za vaÅ¡ sluÄaj upotrebe u Azureu.
- Kako implementirati LLM.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije moÄ‡i Ä‡ete:

- Odabrati pravi model za svoj sluÄaj upotrebe.
- Razumjeti kako testirati, iterirati i poboljÅ¡ati performanse svog modela.
- Znati kako tvrtke implementiraju modele.

## Razumijevanje razliÄitih vrsta LLM-ova

LLM-ovi se mogu kategorizirati na viÅ¡e naÄina, ovisno o njihovoj arhitekturi, podacima za treniranje i svrsi upotrebe. Razumijevanje ovih razlika pomoÄ‡i Ä‡e naÅ¡em startupu da odabere pravi model za odreÄ‘eni scenarij te da zna kako testirati, iterirati i poboljÅ¡ati performanse.

Postoji mnogo razliÄitih vrsta LLM modela, a vaÅ¡ izbor ovisi o tome za Å¡to ih Å¾elite koristiti, o vaÅ¡im podacima, koliko ste spremni platiti i joÅ¡ mnogo toga.

Ovisno o tome Å¾elite li koristiti modele za tekst, audio, video, generiranje slika i sliÄno, moÅ¾da Ä‡ete odabrati drugaÄiji tip modela.

- **Prepoznavanje zvuka i govora**. Za ovu svrhu, Whisper modeli su izvrstan izbor jer su opÄ‡e namjene i usmjereni na prepoznavanje govora. Trenirani su na raznolikim audio zapisima i mogu obavljati prepoznavanje govora na viÅ¡e jezika. ViÅ¡e o [Whisper modelima proÄitajte ovdje](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generiranje slika**. Za generiranje slika, DALL-E i Midjourney su dva vrlo poznata izbora. DALL-E je dostupan putem Azure OpenAI. [ViÅ¡e o DALL-E proÄitajte ovdje](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) i takoÄ‘er u 9. poglavlju ovog kurikuluma.

- **Generiranje teksta**. VeÄ‡ina modela trenirana je za generiranje teksta i imate Å¡irok izbor od GPT-3.5 do GPT-4. Cijene variraju, pri Äemu je GPT-4 najskuplji. Vrijedi pogledati [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) kako biste procijenili koji modeli najbolje odgovaraju vaÅ¡im potrebama u pogledu moguÄ‡nosti i cijene.

- **ViÅ¡emodalnost**. Ako Å¾elite obraÄ‘ivati viÅ¡e vrsta podataka u ulazu i izlazu, moÅ¾da Ä‡ete htjeti pogledati modele poput [gpt-4 turbo s vidom ili gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) â€“ najnovija izdanja OpenAI modela â€“ koji mogu kombinirati obradu prirodnog jezika s vizualnim razumijevanjem, omoguÄ‡ujuÄ‡i interakcije putem viÅ¡emodalnih suÄelja.

Odabir modela znaÄi da dobivate osnovne moguÄ‡nosti, no to Äesto nije dovoljno. ÄŒesto imate podatke specifiÄne za tvrtku koje na neki naÄin trebate prenijeti LLM-u. Postoji nekoliko razliÄitih pristupa tome, o Äemu Ä‡e biti viÅ¡e rijeÄi u sljedeÄ‡im odjeljcima.

### Foundation modeli naspram LLM-ova

Pojam Foundation Model (temeljni model) [su skovali istraÅ¾ivaÄi sa Stanforda](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) i definiran je kao AI model koji zadovoljava odreÄ‘ene kriterije, poput:

- **Trenirani su koriÅ¡tenjem nenadzirane ili samonadzirane metode uÄenja**, Å¡to znaÄi da su trenirani na nemarkiranim viÅ¡emodalnim podacima i ne zahtijevaju ljudsku anotaciju ili oznaÄavanje podataka za proces treniranja.
- **Vrlo su veliki modeli**, temeljeni na dubokim neuronskim mreÅ¾ama treniranim na milijardama parametara.
- **ObiÄno su namijenjeni kao â€˜temeljâ€™ za druge modele**, Å¡to znaÄi da se mogu koristiti kao polazna toÄka za izgradnju drugih modela, Å¡to se moÅ¾e postiÄ‡i dodatnim podeÅ¡avanjem (fine-tuningom).

![Foundation modeli naspram LLM-ova](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.hr.png)

Izvor slike: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Da dodatno pojasnimo ovu razliku, uzmimo za primjer ChatGPT. Za izgradnju prve verzije ChatGPT-a, model nazvan GPT-3.5 sluÅ¾io je kao temeljni model. To znaÄi da je OpenAI koristio podatke specifiÄne za chat kako bi stvorio podeÅ¡enu verziju GPT-3.5 koja je specijalizirana za dobre performanse u konverzacijskim scenarijima, poput chatbota.

![Foundation model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.hr.png)

Izvor slike: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open source naspram vlasniÄkih modela

JoÅ¡ jedan naÄin kategorizacije LLM-ova je prema tome jesu li open source ili vlasniÄki.

Open source modeli su modeli dostupni javnosti i mogu ih koristiti svi. ÄŒesto ih objavljuje tvrtka koja ih je razvila ili istraÅ¾ivaÄka zajednica. Ovi modeli se mogu pregledavati, mijenjati i prilagoÄ‘avati za razliÄite sluÄajeve upotrebe LLM-ova. MeÄ‘utim, nisu uvijek optimizirani za produkcijsku upotrebu i moÅ¾da nisu toliko uÄinkoviti kao vlasniÄki modeli. TakoÄ‘er, financiranje open source modela moÅ¾e biti ograniÄeno, a moÅ¾da se ne odrÅ¾avaju dugoroÄno ili ne aÅ¾uriraju s najnovijim istraÅ¾ivanjima. Primjeri popularnih open source modela su [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) i [LLaMA](https://llama.meta.com).

VlasniÄki modeli su modeli u vlasniÅ¡tvu tvrtke i nisu dostupni javnosti. ÄŒesto su optimizirani za produkcijsku upotrebu. MeÄ‘utim, nije dopuÅ¡teno pregledavati, mijenjati ili prilagoÄ‘avati ih za razliÄite sluÄajeve upotrebe. TakoÄ‘er, nisu uvijek besplatni i mogu zahtijevati pretplatu ili plaÄ‡anje za koriÅ¡tenje. Korisnici nemaju kontrolu nad podacima koji se koriste za treniranje modela, Å¡to znaÄi da se trebaju osloniti na vlasnika modela da osigura poÅ¡tivanje privatnosti podataka i odgovornu upotrebu AI. Primjeri popularnih vlasniÄkih modela su [OpenAI modeli](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ili [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding naspram generiranja slika naspram generiranja teksta i koda

LLM-ovi se takoÄ‘er mogu kategorizirati prema tipu izlaza koji generiraju.

Embedding modeli su skup modela koji mogu pretvoriti tekst u numeriÄki oblik, tzv. embedding, Å¡to je numeriÄka reprezentacija ulaznog teksta. Embedding modeli olakÅ¡avaju strojevima razumijevanje odnosa izmeÄ‘u rijeÄi ili reÄenica i mogu se koristiti kao ulazi drugim modelima, poput klasifikacijskih modela ili modela za grupiranje koji bolje rade s numeriÄkim podacima. Embedding modeli se Äesto koriste za transferno uÄenje, gdje se model gradi za zamjenski zadatak za koji postoji obilje podataka, a zatim se teÅ¾ine modela (embeddingi) ponovno koriste za druge zadatke. Primjer ove kategorije su [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.hr.png)

Modeli za generiranje slika su modeli koji generiraju slike. ÄŒesto se koriste za ureÄ‘ivanje slika, sintezu slika i prevoÄ‘enje slika. Ovi modeli trenirani su na velikim skupovima podataka slika, poput [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generiranje novih slika ili ureÄ‘ivanje postojeÄ‡ih slika tehnikama poput inpaintinga, super-rezolucije i kolorizacije. Primjeri su [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) i [Stable Diffusion modeli](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generiranje slika](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.hr.png)

Modeli za generiranje teksta i koda su modeli koji generiraju tekst ili kod. ÄŒesto se koriste za saÅ¾imanje teksta, prevoÄ‘enje i odgovaranje na pitanja. Modeli za generiranje teksta trenirani su na velikim skupovima tekstualnih podataka, poput [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generiranje novog teksta ili odgovaranje na pitanja. Modeli za generiranje koda, poput [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), trenirani su na velikim skupovima koda, poput GitHub-a, i mogu se koristiti za generiranje novog koda ili ispravljanje greÅ¡aka u postojeÄ‡em kodu.

![Generiranje teksta i koda](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.hr.png)

### Encoder-Decoder naspram samo Decoder

Da bismo objasnili razliÄite vrste arhitektura LLM-ova, upotrijebimo analogiju.

Zamislite da vam je menadÅ¾er dao zadatak da napiÅ¡ete kviz za uÄenike. Imate dva kolege; jedan je zaduÅ¾en za kreiranje sadrÅ¾aja, a drugi za njegovu provjeru.

Kreator sadrÅ¾aja je poput modela samo s Decoderom, moÅ¾e pogledati temu i vidjeti Å¡to ste veÄ‡ napisali, a zatim napisati teÄaj na temelju toga. Vrlo su dobri u pisanju zanimljivog i informativnog sadrÅ¾aja, ali nisu baÅ¡ dobri u razumijevanju teme i ciljeva uÄenja. Neki primjeri Decoder modela su GPT obitelj modela, poput GPT-3.

Provjeravatelj je poput modela samo s Encoderom, gleda napisani teÄaj i odgovore, primjeÄ‡uje odnose izmeÄ‘u njih i razumije kontekst, ali nije dobar u generiranju sadrÅ¾aja. Primjer modela samo s Encoderom je BERT.

Zamislite da moÅ¾emo imati nekoga tko moÅ¾e i kreirati i provjeravati kviz, to je Encoder-Decoder model. Neki primjeri su BART i T5.

### Servis naspram modela

Sada, razgovarajmo o razlici izmeÄ‘u servisa i modela. Servis je proizvod koji nudi pruÅ¾atelj usluga u oblaku i Äesto je kombinacija modela, podataka i drugih komponenti. Model je osnovna komponenta servisa i Äesto je temeljni model, poput LLM-a.

Servisi su Äesto optimizirani za produkcijsku upotrebu i Äesto su lakÅ¡i za koriÅ¡tenje od modela, putem grafiÄkog korisniÄkog suÄelja. MeÄ‘utim, servisi nisu uvijek besplatni i mogu zahtijevati pretplatu ili plaÄ‡anje za koriÅ¡tenje, u zamjenu za koriÅ¡tenje opreme i resursa vlasnika servisa, optimizaciju troÅ¡kova i jednostavno skaliranje. Primjer servisa je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), koji nudi model plaÄ‡anja po koriÅ¡tenju, Å¡to znaÄi da se korisnici naplaÄ‡uju proporcionalno koliko koriste servis. TakoÄ‘er, Azure OpenAI Service nudi sigurnost na razini poduzeÄ‡a i okvir za odgovornu upotrebu AI uz moguÄ‡nosti modela.

Modeli su samo neuronske mreÅ¾e s parametrima, teÅ¾inama i ostalim. OmoguÄ‡uju tvrtkama da ih pokreÄ‡u lokalno, no za to je potrebno kupiti opremu, izgraditi infrastrukturu za skaliranje i kupiti licencu ili koristiti open source model. Model poput LLaMA dostupan je za koriÅ¡tenje, ali zahtijeva raÄunalnu snagu za njegovo pokretanje.

## Kako testirati i iterirati s razliÄitim modelima kako biste razumjeli performanse u Azureu

Nakon Å¡to je naÅ¡ tim istraÅ¾io trenutni krajolik LLM-ova i identificirao nekoliko dobrih kandidata za svoje scenarije, sljedeÄ‡i korak je testirati ih na svojim podacima i radnom optereÄ‡enju. To je iterativni proces, proveden kroz eksperimente i mjerenja.
VeÄ‡ina modela koje smo spomenuli u prethodnim odlomcima (OpenAI modeli, open source modeli poput Llama2 i Hugging Face transformeri) dostupni su u [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) u [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je Cloud platforma dizajnirana za developere za izgradnju generativnih AI aplikacija i upravljanje cijelim razvojnim ciklusom â€“ od eksperimentiranja do evaluacije â€“ kombinirajuÄ‡i sve Azure AI usluge u jedinstveni centar s praktiÄnim GUI-jem. Model Catalog u Azure AI Studio omoguÄ‡uje korisniku da:

- PronaÄ‘e Foundation Model od interesa u katalogu â€“ bilo vlasniÄki ili open source, filtrirajuÄ‡i po zadatku, licenci ili imenu. Kako bi se poboljÅ¡ala pretraÅ¾ivost, modeli su organizirani u kolekcije, poput Azure OpenAI kolekcije, Hugging Face kolekcije i drugih.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.hr.png)

- Pregleda model card, ukljuÄujuÄ‡i detaljan opis namjene i podataka za treniranje, primjere koda i rezultate evaluacije u internom evaluacijskom spremiÅ¡tu.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.hr.png)

- Usporedi benchmarke izmeÄ‘u modela i skupova podataka dostupnih u industriji kako bi procijenio koji najbolje odgovara poslovnom scenariju, kroz [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panel.

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.hr.png)

- Fino podeÅ¡ava model na prilagoÄ‘enim podacima za treniranje kako bi poboljÅ¡ao performanse modela u specifiÄnom zadatku, koristeÄ‡i moguÄ‡nosti eksperimentiranja i praÄ‡enja u Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.hr.png)

- Implementira originalni prethodno trenirani model ili fino podeÅ¡enu verziju na udaljeni real-time inference â€“ upravljani compute â€“ ili serverless API endpoint â€“ [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) â€“ kako bi aplikacije mogle koristiti model.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.hr.png)


> [!NOTE]
> Nisu svi modeli u katalogu trenutno dostupni za fino podeÅ¡avanje i/ili pay-as-you-go implementaciju. Provjerite model card za detalje o moguÄ‡nostima i ograniÄenjima modela.

## PoboljÅ¡anje rezultata LLM-a

NaÅ¡ startup tim je istraÅ¾ivao razliÄite vrste LLM-ova i Cloud platformu (Azure Machine Learning) koja nam omoguÄ‡uje usporedbu razliÄitih modela, njihovu evaluaciju na testnim podacima, poboljÅ¡anje performansi i implementaciju na inference endpointima.

Ali kada bi trebali razmotriti fino podeÅ¡avanje modela umjesto koriÅ¡tenja prethodno treniranog? Postoje li drugi pristupi za poboljÅ¡anje performansi modela na specifiÄnim zadacima?

Poslovanje moÅ¾e koristiti nekoliko pristupa kako bi dobilo Å¾eljene rezultate od LLM-a. MoÅ¾ete odabrati razliÄite vrste modela s razliÄitim stupnjevima treniranja prilikom implementacije LLM-a u produkciju, s razliÄitim razinama sloÅ¾enosti, troÅ¡kova i kvalitete. Evo nekoliko pristupa:

- **Prompt engineering s kontekstom**. Ideja je pruÅ¾iti dovoljno konteksta u promptu kako biste osigurali da dobijete potrebne odgovore.

- **Retrieval Augmented Generation, RAG**. VaÅ¡i podaci mogu postojati u bazi podataka ili web endpointu, na primjer, kako biste osigurali da ti podaci ili njihov podskup budu ukljuÄeni u trenutku promptanja, moÅ¾ete dohvatiti relevantne podatke i ukljuÄiti ih u prompt korisnika.

- **Fino podeÅ¡eni model**. Ovdje ste dodatno trenirali model na vlastitim podacima Å¡to je rezultiralo time da je model precizniji i bolje odgovara vaÅ¡im potrebama, ali moÅ¾e biti skuplje.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.hr.png)

Izvor slike: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering s kontekstom

Prethodno trenirani LLM-ovi vrlo dobro rade na opÄ‡enitim zadacima prirodnog jezika, Äak i kada ih se pozove s kratkim promptom, poput reÄenice za dovrÅ¡etak ili pitanja â€“ tzv. â€œzero-shotâ€ uÄenje.

MeÄ‘utim, Å¡to korisnik detaljnije oblikuje svoj upit, s detaljnim zahtjevom i primjerima â€“ Kontekstom â€“ to Ä‡e odgovor biti precizniji i bliÅ¾i oÄekivanjima korisnika. U tom sluÄaju govorimo o â€œone-shotâ€ uÄenju ako prompt ukljuÄuje samo jedan primjer i â€œfew-shotâ€ uÄenju ako ukljuÄuje viÅ¡e primjera. Prompt engineering s kontekstom je najisplativiji pristup za poÄetak.

### Retrieval Augmented Generation (RAG)

LLM-ovi imaju ograniÄenje da mogu koristiti samo podatke koji su koriÅ¡teni tijekom njihovog treniranja za generiranje odgovora. To znaÄi da ne znaju niÅ¡ta o dogaÄ‘ajima koji su se dogodili nakon procesa treniranja i ne mogu pristupiti ne-javnim informacijama (poput podataka tvrtke).
To se moÅ¾e prevladati tehnikom RAG, koja proÅ¡iruje prompt vanjskim podacima u obliku dijelova dokumenata, uzimajuÄ‡i u obzir ograniÄenja duljine prompta. To podrÅ¾avaju alati za vektorske baze podataka (poput [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) koji dohvaÄ‡aju korisne dijelove iz razliÄitih unaprijed definiranih izvora podataka i dodaju ih u kontekst prompta.

Ova tehnika je vrlo korisna kada poslovanje nema dovoljno podataka, vremena ili resursa za fino podeÅ¡avanje LLM-a, ali Å¾eli poboljÅ¡ati performanse na specifiÄnom zadatku i smanjiti rizik od izmiÅ¡ljotina, tj. iskrivljavanja stvarnosti ili Å¡tetnog sadrÅ¾aja.

### Fino podeÅ¡eni model

Fino podeÅ¡avanje je proces koji koristi transfer learning za â€˜prilagodbuâ€™ modela na zadatak niÅ¾e razine ili za rjeÅ¡avanje specifiÄnog problema. Za razliku od few-shot uÄenja i RAG-a, rezultira generiranjem novog modela s aÅ¾uriranim teÅ¾inama i pristranostima. Potreban je skup primjera za treniranje koji se sastoje od jednog ulaza (prompt) i pripadajuÄ‡eg izlaza (dovrÅ¡etak).
Ovo bi bio preferirani pristup ako:

- **Koristite fino podeÅ¡ene modele**. Poslovanje Å¾eli koristiti fino podeÅ¡ene manje sposobne modele (poput embedding modela) umjesto visokoperformantnih modela, Å¡to rezultira isplativijim i brÅ¾im rjeÅ¡enjem.

- **Razmatrate latenciju**. Latencija je vaÅ¾na za specifiÄan sluÄaj upotrebe, pa nije moguÄ‡e koristiti vrlo duge promte ili broj primjera koje model treba nauÄiti ne odgovara ograniÄenju duljine prompta.

- **Ostajete aÅ¾urni**. Poslovanje ima mnogo kvalitetnih podataka i toÄnih oznaka te resurse potrebne za odrÅ¾avanje tih podataka aÅ¾urnima tijekom vremena.

### Trenirani model

Treniranje LLM-a od nule je bez sumnje najzahtjevniji i najsloÅ¾eniji pristup, koji zahtijeva ogromne koliÄine podataka, struÄne resurse i odgovarajuÄ‡u raÄunalnu snagu. Ova opcija treba biti razmotrena samo u scenariju gdje poslovanje ima domenom specifiÄan sluÄaj upotrebe i veliku koliÄinu domenom centriranih podataka.

## Provjera znanja

Koji bi bio dobar pristup za poboljÅ¡anje rezultata dovrÅ¡etka LLM-a?

1. Prompt engineering s kontekstom  
1. RAG  
1. Fino podeÅ¡eni model

Odgovor: 3, ako imate vremena, resursa i kvalitetne podatke, fino podeÅ¡avanje je bolja opcija za ostati aÅ¾uran. MeÄ‘utim, ako Å¾elite brzo poboljÅ¡anje i nemate puno vremena, vrijedi prvo razmotriti RAG.

## ğŸš€ Izazov

ProÄitajte viÅ¡e o tome kako moÅ¾ete [koristiti RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) za svoje poslovanje.

## OdliÄan posao, nastavite s uÄenjem

Nakon Å¡to zavrÅ¡ite ovu lekciju, pogledajte naÅ¡u [Generative AI Learning kolekciju](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili podizati svoje znanje o Generativnoj AI!

Krenite na Lekciju 3 gdje Ä‡emo pogledati kako [odgovorno graditi s Generativnom AI](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koriÅ¡tenjem AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako teÅ¾imo toÄnosti, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni ljudski prijevod. Ne snosimo odgovornost za bilo kakva nesporazuma ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.