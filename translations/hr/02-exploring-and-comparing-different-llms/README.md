<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-18T01:32:23+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "hr"
}
-->
# IstraÅ¾ivanje i usporedba razliÄitih LLM-ova

[![IstraÅ¾ivanje i usporedba razliÄitih LLM-ova](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.hr.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _Kliknite na sliku iznad za pregled videozapisa ove lekcije_

U prethodnoj lekciji vidjeli smo kako generativna umjetna inteligencija mijenja tehnoloÅ¡ki krajolik, kako funkcioniraju veliki jeziÄni modeli (LLM-ovi) i kako ih tvrtke - poput naÅ¡eg startupa - mogu primijeniti na svoje sluÄajeve upotrebe i rasti! U ovom poglavlju usporeÄ‘ujemo i kontrastiramo razliÄite vrste velikih jeziÄnih modela (LLM-ova) kako bismo razumjeli njihove prednosti i nedostatke.

SljedeÄ‡i korak u putovanju naÅ¡eg startupa je istraÅ¾ivanje trenutnog krajolika LLM-ova i razumijevanje koji su prikladni za naÅ¡ sluÄaj upotrebe.

## Uvod

Ova lekcija obuhvaÄ‡a:

- RazliÄite vrste LLM-ova u trenutnom krajoliku.
- Testiranje, iteraciju i usporedbu razliÄitih modela za vaÅ¡ sluÄaj upotrebe u Azureu.
- Kako implementirati LLM.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije, moÄ‡i Ä‡ete:

- Odabrati pravi model za vaÅ¡ sluÄaj upotrebe.
- Razumjeti kako testirati, iterirati i poboljÅ¡ati performanse vaÅ¡eg modela.
- Znati kako tvrtke implementiraju modele.

## Razumijevanje razliÄitih vrsta LLM-ova

LLM-ovi se mogu kategorizirati na temelju njihove arhitekture, podataka za treniranje i sluÄaja upotrebe. Razumijevanje ovih razlika pomoÄ‡i Ä‡e naÅ¡em startupu da odabere pravi model za scenarij i razumije kako testirati, iterirati i poboljÅ¡ati performanse.

Postoji mnogo razliÄitih vrsta LLM modela, a vaÅ¡ izbor modela ovisi o tome za Å¡to ih namjeravate koristiti, vaÅ¡im podacima, koliko ste spremni platiti i joÅ¡ mnogo toga.

Ovisno o tome namjeravate li koristiti modele za generiranje teksta, zvuka, videa, slika i sliÄno, moÅ¾da Ä‡ete se odluÄiti za razliÄitu vrstu modela.

- **Prepoznavanje zvuka i govora**. Za ovu svrhu, modeli tipa Whisper su odliÄan izbor jer su univerzalni i namijenjeni prepoznavanju govora. Trenirani su na raznovrsnim audio podacima i mogu obavljati viÅ¡ejeziÄno prepoznavanje govora. Saznajte viÅ¡e o [modelima tipa Whisper ovdje](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generiranje slika**. Za generiranje slika, DALL-E i Midjourney su dva vrlo poznata izbora. DALL-E nudi Azure OpenAI. [ProÄitajte viÅ¡e o DALL-E ovdje](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) i takoÄ‘er u 9. poglavlju ovog kurikuluma.

- **Generiranje teksta**. VeÄ‡ina modela trenirana je za generiranje teksta i imate veliki izbor od GPT-3.5 do GPT-4. Dolaze s razliÄitim troÅ¡kovima, pri Äemu je GPT-4 najskuplji. Vrijedi istraÅ¾iti [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) kako biste procijenili koji modeli najbolje odgovaraju vaÅ¡im potrebama u smislu sposobnosti i troÅ¡kova.

- **Multimodalnost**. Ako Å¾elite raditi s viÅ¡e vrsta podataka u ulazu i izlazu, moÅ¾da biste trebali razmotriti modele poput [gpt-4 turbo s vizijom ili gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - najnovija izdanja OpenAI modela - koji su sposobni kombinirati obradu prirodnog jezika s vizualnim razumijevanjem, omoguÄ‡ujuÄ‡i interakcije putem multimodalnih suÄelja.

Odabir modela znaÄi da dobivate osnovne sposobnosti, koje moÅ¾da neÄ‡e biti dovoljne. ÄŒesto imate podatke specifiÄne za tvrtku koje nekako trebate prenijeti LLM-u. Postoji nekoliko razliÄitih pristupa kako to uÄiniti, viÅ¡e o tome u nadolazeÄ‡im odjeljcima.

### Osnovni modeli naspram LLM-ova

Pojam Osnovni model [skovali su istraÅ¾ivaÄi sa Stanforda](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) i definiran je kao AI model koji slijedi odreÄ‘ene kriterije, kao Å¡to su:

- **Trenirani su pomoÄ‡u nenadgledanog uÄenja ili samonadgledanog uÄenja**, Å¡to znaÄi da su trenirani na nelabeliranim multimodalnim podacima i ne zahtijevaju ljudsku anotaciju ili oznaÄavanje podataka za svoj proces treniranja.
- **To su vrlo veliki modeli**, temeljeni na vrlo dubokim neuronskim mreÅ¾ama treniranim na milijardama parametara.
- **ObiÄno su namijenjeni kao 'osnova' za druge modele**, Å¡to znaÄi da se mogu koristiti kao poÄetna toÄka za izgradnju drugih modela, Å¡to se moÅ¾e postiÄ‡i finim podeÅ¡avanjem.

![Osnovni modeli naspram LLM-ova](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.hr.png)

Izvor slike: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Kako bismo dodatno pojasnili ovu razliku, uzmimo ChatGPT kao primjer. Za izradu prve verzije ChatGPT-a, model nazvan GPT-3.5 sluÅ¾io je kao osnovni model. To znaÄi da je OpenAI koristio neke podatke specifiÄne za chat kako bi stvorio prilagoÄ‘enu verziju GPT-3.5 koja je bila specijalizirana za dobro funkcioniranje u konverzacijskim scenarijima, poput chatbotova.

![Osnovni model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.hr.png)

Izvor slike: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source naspram vlasniÄkih modela

JoÅ¡ jedan naÄin kategorizacije LLM-ova je prema tome jesu li otvorenog koda ili vlasniÄki.

Modeli otvorenog koda su modeli koji su dostupni javnosti i mogu ih koristiti svi. ÄŒesto ih objavljuje tvrtka koja ih je stvorila ili istraÅ¾ivaÄka zajednica. Ovi modeli mogu se pregledavati, mijenjati i prilagoÄ‘avati za razliÄite sluÄajeve upotrebe LLM-ova. MeÄ‘utim, nisu uvijek optimizirani za proizvodnu upotrebu i moÅ¾da nisu toliko uÄinkoviti kao vlasniÄki modeli. Osim toga, financiranje za modele otvorenog koda moÅ¾e biti ograniÄeno, moÅ¾da neÄ‡e biti dugoroÄno odrÅ¾avani ili aÅ¾urirani najnovijim istraÅ¾ivanjima. Primjeri popularnih modela otvorenog koda ukljuÄuju [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) i [LLaMA](https://llama.meta.com).

VlasniÄki modeli su modeli koji su u vlasniÅ¡tvu tvrtke i nisu dostupni javnosti. Ovi modeli Äesto su optimizirani za proizvodnu upotrebu. MeÄ‘utim, nije ih moguÄ‡e pregledavati, mijenjati ili prilagoÄ‘avati za razliÄite sluÄajeve upotrebe. Osim toga, nisu uvijek besplatni i njihovo koriÅ¡tenje moÅ¾e zahtijevati pretplatu ili plaÄ‡anje. Korisnici takoÄ‘er nemaju kontrolu nad podacima koji se koriste za treniranje modela, Å¡to znaÄi da moraju vjerovati vlasniku modela da Ä‡e osigurati privatnost podataka i odgovornu upotrebu AI-a. Primjeri popularnih vlasniÄkih modela ukljuÄuju [OpenAI modele](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ili [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### UgraÄ‘ivanje naspram generiranja slika naspram generiranja teksta i koda

LLM-ovi se takoÄ‘er mogu kategorizirati prema izlazu koji generiraju.

UgraÄ‘ivanja su skup modela koji mogu pretvoriti tekst u numeriÄki oblik, nazvan ugraÄ‘ivanje, Å¡to je numeriÄka reprezentacija ulaznog teksta. UgraÄ‘ivanja olakÅ¡avaju strojevima razumijevanje odnosa izmeÄ‘u rijeÄi ili reÄenica i mogu se koristiti kao ulazi za druge modele, poput modela za klasifikaciju ili modela za grupiranje koji imaju bolje performanse na numeriÄkim podacima. Modeli ugraÄ‘ivanja Äesto se koriste za prijenosno uÄenje, gdje se model gradi za zamjenski zadatak za koji postoji obilje podataka, a zatim se teÅ¾ine modela (ugraÄ‘ivanja) ponovno koriste za druge zadatke. Primjer ove kategorije je [OpenAI ugraÄ‘ivanja](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![UgraÄ‘ivanje](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.hr.png)

Modeli za generiranje slika su modeli koji generiraju slike. Ovi modeli Äesto se koriste za ureÄ‘ivanje slika, sintezu slika i prevoÄ‘enje slika. Modeli za generiranje slika Äesto se treniraju na velikim skupovima podataka o slikama, poput [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generiranje novih slika ili za ureÄ‘ivanje postojeÄ‡ih slika tehnikama poput nadopunjavanja, super-rezolucije i koloriranja. Primjeri ukljuÄuju [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) i [Stable Diffusion modele](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generiranje slika](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.hr.png)

Modeli za generiranje teksta i koda su modeli koji generiraju tekst ili kod. Ovi modeli Äesto se koriste za saÅ¾imanje teksta, prevoÄ‘enje i odgovaranje na pitanja. Modeli za generiranje teksta Äesto se treniraju na velikim skupovima podataka o tekstu, poput [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generiranje novog teksta ili za odgovaranje na pitanja. Modeli za generiranje koda, poput [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), Äesto se treniraju na velikim skupovima podataka o kodu, poput GitHuba, i mogu se koristiti za generiranje novog koda ili za ispravljanje greÅ¡aka u postojeÄ‡em kodu.

![Generiranje teksta i koda](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.hr.png)

### Encoder-Decoder naspram samo Decoder

Kako bismo razgovarali o razliÄitim vrstama arhitektura LLM-ova, koristit Ä‡emo analogiju.

Zamislite da vam je vaÅ¡ menadÅ¾er dao zadatak da napiÅ¡ete kviz za studente. Imate dva kolege; jedan se bavi stvaranjem sadrÅ¾aja, a drugi pregledavanjem.

Stvaratelj sadrÅ¾aja je poput modela samo Decoder, moÅ¾e pogledati temu i vidjeti Å¡to ste veÄ‡ napisali, a zatim moÅ¾e napisati teÄaj na temelju toga. Vrlo su dobri u pisanju zanimljivog i informativnog sadrÅ¾aja, ali nisu baÅ¡ dobri u razumijevanju teme i ciljeva uÄenja. Neki primjeri modela Decoder su modeli iz GPT obitelji, poput GPT-3.

Recenzent je poput modela samo Encoder, gleda napisani teÄaj i odgovore, primjeÄ‡ujuÄ‡i odnos izmeÄ‘u njih i razumijevajuÄ‡i kontekst, ali nije dobar u generiranju sadrÅ¾aja. Primjer modela samo Encoder bio bi BERT.

Zamislite da takoÄ‘er moÅ¾emo imati nekoga tko bi mogao i kreirati i pregledavati kviz, to je model Encoder-Decoder. Neki primjeri bili bi BART i T5.

### Usluga naspram modela

Sada, razgovarajmo o razlici izmeÄ‘u usluge i modela. Usluga je proizvod koji nudi pruÅ¾atelj usluga u oblaku i Äesto je kombinacija modela, podataka i drugih komponenti. Model je osnovna komponenta usluge i Äesto je osnovni model, poput LLM-a.

Usluge su Äesto optimizirane za proizvodnu upotrebu i Äesto ih je lakÅ¡e koristiti nego modele, putem grafiÄkog korisniÄkog suÄelja. MeÄ‘utim, usluge nisu uvijek besplatne i njihovo koriÅ¡tenje moÅ¾e zahtijevati pretplatu ili plaÄ‡anje, u zamjenu za koriÅ¡tenje opreme i resursa vlasnika usluge, optimizaciju troÅ¡kova i jednostavno skaliranje. Primjer usluge je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), koja nudi plan plaÄ‡anja prema koriÅ¡tenju, Å¡to znaÄi da se korisnici naplaÄ‡uju proporcionalno koliko koriste uslugu. TakoÄ‘er, Azure OpenAI Service nudi sigurnost na razini poduzeÄ‡a i okvir za odgovornu upotrebu AI-a uz moguÄ‡nosti modela.

Modeli su samo neuronske mreÅ¾e, s parametrima, teÅ¾inama i ostalim. OmoguÄ‡uju tvrtkama lokalno pokretanje, meÄ‘utim, potrebno je kupiti opremu, izgraditi strukturu za skaliranje i kupiti licencu ili koristiti model otvorenog koda. Model poput LLaMA dostupan je za koriÅ¡tenje, ali zahtijeva raÄunalnu snagu za pokretanje modela.

## Kako testirati i iterirati s razliÄitim modelima kako biste razumjeli performanse na Azureu

Nakon Å¡to naÅ¡ tim istraÅ¾i trenutni krajolik LLM-ova i identificira neke dobre kandidate za svoje scenarije, sljedeÄ‡i korak je testiranje na njihovim podacima i radnom optereÄ‡enju. Ovo je iterativni proces, koji se provodi putem eksperimenata i mjerenja.
VeÄ‡ina modela koje smo spomenuli u prethodnim odlomcima (OpenAI modeli, open source modeli poput Llama2 i Hugging Face transformera) dostupni su u [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) u [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je cloud platforma dizajnirana za razvojne inÅ¾enjere kako bi mogli izraditi aplikacije temeljene na generativnoj umjetnoj inteligenciji i upravljati cijelim razvojnim ciklusom - od eksperimentiranja do evaluacije - kombinirajuÄ‡i sve Azure AI usluge u jedinstveni centar s praktiÄnim grafiÄkim suÄeljem. Model Catalog u Azure AI Studio omoguÄ‡uje korisnicima:

- PronaÄ‡i temeljni model od interesa u katalogu - bilo vlasniÄki ili open source, filtrirajuÄ‡i prema zadatku, licenci ili nazivu. Kako bi se poboljÅ¡ala pretraÅ¾ivost, modeli su organizirani u kolekcije, poput Azure OpenAI kolekcije, Hugging Face kolekcije i drugih.

![Model katalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.hr.png)

- Pregledati karticu modela, ukljuÄujuÄ‡i detaljan opis namjene i podataka za treniranje, primjere koda i rezultate evaluacije iz interne biblioteke evaluacija.

![Kartica modela](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.hr.png)

- Usporediti mjerila izmeÄ‘u modela i dostupnih skupova podataka u industriji kako bi se procijenilo koji najbolje odgovara poslovnom scenariju, putem [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) panela.

![Mjerila modela](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.hr.png)

- Fino podesiti model na prilagoÄ‘enim podacima za treniranje kako bi se poboljÅ¡ala izvedba modela u odreÄ‘enom radnom optereÄ‡enju, koristeÄ‡i moguÄ‡nosti eksperimentiranja i praÄ‡enja u Azure AI Studio.

![Fino podeÅ¡avanje modela](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.hr.png)

- Implementirati originalni unaprijed trenirani model ili fino podeÅ¡enu verziju za udaljenu inferenciju u stvarnom vremenu - upravljano raÄunanje - ili serverless API endpoint - [plaÄ‡anje po koriÅ¡tenju](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - kako bi aplikacije mogle koristiti model.

![Implementacija modela](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.hr.png)

> [!NOTE]
> Nisu svi modeli u katalogu trenutno dostupni za fino podeÅ¡avanje i/ili implementaciju putem plaÄ‡anja po koriÅ¡tenju. Provjerite karticu modela za detalje o moguÄ‡nostima i ograniÄenjima modela.

## PoboljÅ¡anje rezultata LLM-a

IstraÅ¾ili smo s naÅ¡im startup timom razliÄite vrste LLM-ova i cloud platformu (Azure Machine Learning) koja nam omoguÄ‡uje usporedbu razliÄitih modela, njihovu evaluaciju na testnim podacima, poboljÅ¡anje performansi i implementaciju na inferencijskim endpointima.

Ali kada bi trebali razmotriti fino podeÅ¡avanje modela umjesto koriÅ¡tenja unaprijed treniranog? Postoje li drugi pristupi za poboljÅ¡anje performansi modela na specifiÄnim radnim optereÄ‡enjima?

Postoji nekoliko pristupa koje tvrtka moÅ¾e koristiti kako bi postigla Å¾eljene rezultate od LLM-a. MoÅ¾ete odabrati razliÄite vrste modela s razliÄitim stupnjevima treniranja prilikom implementacije LLM-a u produkciju, s razliÄitim razinama sloÅ¾enosti, troÅ¡kova i kvalitete. Evo nekoliko razliÄitih pristupa:

- **Prompt engineering s kontekstom**. Ideja je pruÅ¾iti dovoljno konteksta prilikom postavljanja upita kako biste osigurali da dobijete odgovore koji su vam potrebni.

- **Retrieval Augmented Generation, RAG**. VaÅ¡i podaci mogu postojati u bazi podataka ili na web endpointu, na primjer, kako biste osigurali da ti podaci ili njihov podskup budu ukljuÄeni u trenutku postavljanja upita, moÅ¾ete dohvatiti relevantne podatke i uÄiniti ih dijelom korisniÄkog upita.

- **Fino podeÅ¡en model**. Ovdje dodatno trenirate model na vlastitim podacima, Å¡to dovodi do toga da model postane precizniji i odgovara vaÅ¡im potrebama, ali to moÅ¾e biti skupo.

![Implementacija LLM-a](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.hr.png)

Izvor slike: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering s Kontekstom

Unaprijed trenirani LLM-ovi vrlo dobro funkcioniraju na opÄ‡im zadacima obrade prirodnog jezika, Äak i kada ih pozovete s kratkim upitom, poput reÄenice za dovrÅ¡avanje ili pitanja â€“ takozvano uÄenje bez primjera ("zero-shot" learning).

MeÄ‘utim, Å¡to korisnik bolje moÅ¾e oblikovati svoj upit, s detaljnim zahtjevom i primjerima â€“ Kontekstom â€“ to Ä‡e odgovor biti toÄniji i bliÅ¾i oÄekivanjima korisnika. U ovom sluÄaju govorimo o uÄenju s jednim primjerom ("one-shot" learning) ako upit ukljuÄuje samo jedan primjer i o uÄenju s nekoliko primjera ("few-shot learning") ako ukljuÄuje viÅ¡e primjera. Prompt engineering s kontekstom je najisplativiji pristup za poÄetak.

### Retrieval Augmented Generation (RAG)

LLM-ovi imaju ograniÄenje da mogu koristiti samo podatke koji su koriÅ¡teni tijekom njihovog treniranja za generiranje odgovora. To znaÄi da ne znaju niÅ¡ta o Äinjenicama koje su se dogodile nakon procesa treniranja i ne mogu pristupiti ne-javnim informacijama (poput podataka tvrtke). 
Ovo se moÅ¾e prevladati putem RAG-a, tehnike koja proÅ¡iruje upit vanjskim podacima u obliku dijelova dokumenata, uzimajuÄ‡i u obzir ograniÄenja duljine upita. Ovo podrÅ¾avaju alati za pretraÅ¾ivanje vektora (poput [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) koji dohvaÄ‡aju korisne dijelove iz razliÄitih unaprijed definiranih izvora podataka i dodaju ih u kontekst upita.

Ova tehnika je vrlo korisna kada tvrtka nema dovoljno podataka, vremena ili resursa za fino podeÅ¡avanje LLM-a, ali ipak Å¾eli poboljÅ¡ati performanse na specifiÄnom radnom optereÄ‡enju i smanjiti rizik od izmiÅ¡ljanja, tj. iskrivljavanja stvarnosti ili Å¡tetnog sadrÅ¾aja.

### Fino podeÅ¡en model

Fino podeÅ¡avanje je proces koji koristi transferno uÄenje za 'prilagodbu' modela na zadatak ili za rjeÅ¡avanje specifiÄnog problema. Za razliku od uÄenja s nekoliko primjera i RAG-a, rezultira stvaranjem novog modela s aÅ¾uriranim teÅ¾inama i pristranostima. Zahtijeva skup primjera za treniranje koji se sastoje od jednog ulaza (upita) i njegovog povezanog izlaza (rezultata). 
Ovo bi bio preferirani pristup ako:

- **KoriÅ¡tenje fino podeÅ¡enih modela**. Tvrtka Å¾eli koristiti fino podeÅ¡ene manje sposobne modele (poput modela za ugraÄ‘ivanje) umjesto modela visokih performansi, Å¡to rezultira isplativijim i brÅ¾im rjeÅ¡enjem.

- **Razmatranje latencije**. Latencija je vaÅ¾na za odreÄ‘eni sluÄaj upotrebe, pa nije moguÄ‡e koristiti vrlo duge upite ili broj primjera koji bi model trebao nauÄiti ne odgovara ograniÄenju duljine upita.

- **OdrÅ¾avanje aÅ¾urnosti**. Tvrtka ima puno visokokvalitetnih podataka i oznaka istine te resurse potrebne za odrÅ¾avanje tih podataka aÅ¾urnima tijekom vremena.

### Trenirani model

Treniranje LLM-a od nule bez sumnje je najteÅ¾i i najsloÅ¾eniji pristup koji se moÅ¾e usvojiti, zahtijevajuÄ‡i ogromne koliÄine podataka, struÄne resurse i odgovarajuÄ‡u raÄunalnu snagu. Ova opcija trebala bi se razmotriti samo u scenariju gdje tvrtka ima sluÄaj upotrebe specifiÄan za odreÄ‘enu domenu i veliku koliÄinu podataka vezanih za tu domenu.

## Provjera znanja

Koji bi mogao biti dobar pristup za poboljÅ¡anje rezultata LLM-a?

1. Prompt engineering s kontekstom  
1. RAG  
1. Fino podeÅ¡en model  

A:3, ako imate vremena, resursa i visokokvalitetne podatke, fino podeÅ¡avanje je bolja opcija za ostati aÅ¾uran. MeÄ‘utim, ako Å¾elite poboljÅ¡ati stvari, a nemate dovoljno vremena, vrijedi prvo razmotriti RAG.

## ğŸš€ Izazov

ProÄitajte viÅ¡e o tome kako moÅ¾ete [koristiti RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) za svoje poslovanje.

## OdliÄno obavljeno, nastavite uÄiti

Nakon Å¡to zavrÅ¡ite ovu lekciju, pogledajte naÅ¡u [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili unapreÄ‘ivati svoje znanje o generativnoj umjetnoj inteligenciji!

PrijeÄ‘ite na Lekciju 3 gdje Ä‡emo pogledati kako [odgovorno koristiti generativnu umjetnu inteligenciju](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Izjava o odricanju odgovornosti**:  
Ovaj dokument je preveden pomoÄ‡u AI usluge za prevoÄ‘enje [Co-op Translator](https://github.com/Azure/co-op-translator). Iako nastojimo osigurati toÄnost, imajte na umu da automatski prijevodi mogu sadrÅ¾avati pogreÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati autoritativnim izvorom. Za kljuÄne informacije preporuÄuje se profesionalni prijevod od strane Äovjeka. Ne preuzimamo odgovornost za nesporazume ili pogreÅ¡ne interpretacije nastale koriÅ¡tenjem ovog prijevoda.