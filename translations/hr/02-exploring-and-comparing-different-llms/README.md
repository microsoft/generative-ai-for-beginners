<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:26:45+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "hr"
}
-->
# IstraÅ¾ivanje i usporedba razliÄitih LLM-ova

[![IstraÅ¾ivanje i usporedba razliÄitih LLM-ova](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.hr.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknite na sliku iznad za pregled videa ove lekcije_

U prethodnoj lekciji vidjeli smo kako Generativna AI mijenja tehnoloÅ¡ki krajolik, kako Veliki JeziÄni Modeli (LLM-ovi) rade i kako ih tvrtka - poput naÅ¡eg startupa - moÅ¾e primijeniti na svoje sluÄajeve koriÅ¡tenja i rasti! U ovom poglavlju Å¾elimo usporediti i kontrastirati razliÄite vrste velikih jeziÄnih modela (LLM-ova) kako bismo razumjeli njihove prednosti i nedostatke.

SljedeÄ‡i korak na putovanju naÅ¡eg startupa je istraÅ¾ivanje trenutnog krajolika LLM-ova i razumijevanje koji su prikladni za naÅ¡ sluÄaj koriÅ¡tenja.

## Uvod

Ova lekcija Ä‡e pokriti:

- RazliÄite vrste LLM-ova u trenutnom krajoliku.
- Testiranje, iteriranje i usporedbu razliÄitih modela za vaÅ¡ sluÄaj koriÅ¡tenja u Azureu.
- Kako implementirati LLM.

## Ciljevi uÄenja

Nakon zavrÅ¡etka ove lekcije, moÄ‡i Ä‡ete:

- Odabrati pravi model za vaÅ¡ sluÄaj koriÅ¡tenja.
- Razumjeti kako testirati, iterirati i poboljÅ¡ati performanse vaÅ¡eg modela.
- Znati kako tvrtke implementiraju modele.

## Razumjeti razliÄite vrste LLM-ova

LLM-ovi mogu imati viÅ¡e kategorizacija na temelju njihove arhitekture, podataka za obuku i sluÄaja koriÅ¡tenja. Razumijevanje ovih razlika pomoÄ‡i Ä‡e naÅ¡em startupu da odabere pravi model za scenarij i razumije kako testirati, iterirati i poboljÅ¡ati performanse.

Postoji mnogo razliÄitih vrsta LLM modela, vaÅ¡ izbor modela ovisi o tome Å¡to namjeravate koristiti, vaÅ¡im podacima, koliko ste spremni platiti i viÅ¡e.

Ovisno o tome namjeravate li koristiti modele za generiranje teksta, zvuka, videa, slike i sliÄno, moÅ¾ete se odluÄiti za razliÄitu vrstu modela.

- **Prepoznavanje zvuka i govora**. Za ovu svrhu, modeli tipa Whisper su odliÄan izbor jer su univerzalni i usmjereni na prepoznavanje govora. ObuÄeni su na raznolikim audio podacima i mogu obavljati viÅ¡ejeziÄno prepoznavanje govora. Saznajte viÅ¡e o [Whisper tip modelima ovdje](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Generiranje slika**. Za generiranje slika, DALL-E i Midjourney su dva vrlo poznata izbora. DALL-E nudi Azure OpenAI. [ProÄitajte viÅ¡e o DALL-E ovdje](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) i takoÄ‘er u Poglavlju 9 ovog kurikuluma.

- **Generiranje teksta**. VeÄ‡ina modela je obuÄena za generiranje teksta i imate veliki izbor od GPT-3.5 do GPT-4. Dolaze s razliÄitim troÅ¡kovima, pri Äemu je GPT-4 najskuplji. Vrijedi istraÅ¾iti [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) kako biste procijenili koji modeli najbolje odgovaraju vaÅ¡im potrebama u smislu sposobnosti i troÅ¡kova.

- **ViÅ¡estruka modalnost**. Ako Å¾elite obraditi viÅ¡e vrsta podataka u ulazu i izlazu, moÅ¾da biste htjeli istraÅ¾iti modele poput [gpt-4 turbo s vizijom ili gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - najnovija izdanja OpenAI modela - koji su sposobni kombinirati obradu prirodnog jezika s vizualnim razumijevanjem, omoguÄ‡ujuÄ‡i interakcije putem multimodalnih suÄelja.

Odabir modela znaÄi da dobivate neke osnovne sposobnosti, koje moÅ¾da neÄ‡e biti dovoljne. ÄŒesto imate specifiÄne podatke tvrtke koje nekako trebate prenijeti LLM-u. Postoji nekoliko razliÄitih izbora kako to pristupiti, viÅ¡e o tome u nadolazeÄ‡im sekcijama.

### Temeljni modeli naspram LLM-ova

Izraz Temeljni Model [skovali su istraÅ¾ivaÄi sa Stanforda](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) i definirali kao AI model koji slijedi neke kriterije, kao Å¡to su:

- **ObuÄeni su koriÅ¡tenjem nesuperviziranog uÄenja ili samonadziranog uÄenja**, Å¡to znaÄi da su obuÄeni na nenadziranim multimodalnim podacima i ne zahtijevaju ljudsku anotaciju ili oznaÄavanje podataka za svoj proces obuke.
- **Vrlo su veliki modeli**, bazirani na vrlo dubokim neuronskim mreÅ¾ama obuÄeni na milijardama parametara.
- **Normalno su namijenjeni da sluÅ¾e kao 'temelj' za druge modele**, Å¡to znaÄi da se mogu koristiti kao poÄetna toÄka za druge modele koji se mogu izgraditi na vrhu, Å¡to se moÅ¾e postiÄ‡i finim podeÅ¡avanjem.

![Temeljni modeli naspram LLM-ova](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.hr.png)

Izvor slike: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Kako bismo dodatno razjasnili ovu razliku, uzmimo ChatGPT kao primjer. Za izgradnju prve verzije ChatGPT-a, model nazvan GPT-3.5 sluÅ¾io je kao temeljni model. To znaÄi da je OpenAI koristio neke specifiÄne podatke o razgovoru za stvaranje podeÅ¡ene verzije GPT-3.5 koja je bila specijalizirana za dobro obavljanje u konverzacijskim scenarijima, kao Å¡to su chatboti.

![Temeljni Model](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.hr.png)

Izvor slike: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source naspram VlasniÄki modeli

JoÅ¡ jedan naÄin kategoriziranja LLM-ova je jesu li open source ili vlasniÄki.

Open-source modeli su modeli koji su dostupni javnosti i mogu ih koristiti bilo tko. ÄŒesto ih Äini dostupnim tvrtka koja ih je stvorila ili istraÅ¾ivaÄka zajednica. Ovi modeli mogu se pregledati, modificirati i prilagoditi za razliÄite sluÄajeve koriÅ¡tenja u LLM-ovima. MeÄ‘utim, nisu uvijek optimizirani za proizvodnu upotrebu i moÅ¾da nisu tako performansni kao vlasniÄki modeli. Osim toga, financiranje open-source modela moÅ¾e biti ograniÄeno i moÅ¾da neÄ‡e biti dugoroÄno odrÅ¾avani ili aÅ¾urirani s najnovijim istraÅ¾ivanjima. Primjeri popularnih open-source modela ukljuÄuju [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) i [LLaMA](https://llama.meta.com).

VlasniÄki modeli su modeli koji su u vlasniÅ¡tvu tvrtke i nisu dostupni javnosti. Ovi modeli su Äesto optimizirani za proizvodnu upotrebu. MeÄ‘utim, nije dopuÅ¡teno da se pregledaju, modificiraju ili prilagode za razliÄite sluÄajeve koriÅ¡tenja. Osim toga, nisu uvijek dostupni besplatno i moÅ¾da zahtijevaju pretplatu ili plaÄ‡anje za koriÅ¡tenje. TakoÄ‘er, korisnici nemaju kontrolu nad podacima koji se koriste za obuku modela, Å¡to znaÄi da trebaju vjerovati vlasniku modela da Ä‡e osigurati obvezu prema privatnosti podataka i odgovornoj upotrebi AI-a. Primjeri popularnih vlasniÄkih modela ukljuÄuju [OpenAI modele](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) ili [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### UgraÄ‘ivanje naspram Generiranje slika naspram Generiranje teksta i koda

LLM-ovi se takoÄ‘er mogu kategorizirati prema izlazu koji generiraju.

UgraÄ‘ivanja su skup modela koji mogu pretvoriti tekst u numeriÄki oblik, nazvan ugraÄ‘ivanje, Å¡to je numeriÄki prikaz ulaznog teksta. UgraÄ‘ivanja olakÅ¡avaju strojevima razumijevanje odnosa izmeÄ‘u rijeÄi ili reÄenica i mogu se koristiti kao ulazi za druge modele, kao Å¡to su modeli klasifikacije ili modeli grupiranja koji imaju bolje performanse na numeriÄkim podacima. UgraÄ‘ivanje modela Äesto se koriste za prijenosno uÄenje, gdje se model gradi za zamjenski zadatak za koji postoji obilje podataka, a zatim se teÅ¾ine modela (ugraÄ‘ivanja) ponovno koriste za druge zadatke nizvodno. Primjer ove kategorije je [OpenAI ugraÄ‘ivanja](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![UgraÄ‘ivanje](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.hr.png)

Modeli generiranja slika su modeli koji generiraju slike. Ovi modeli Äesto se koriste za ureÄ‘ivanje slika, sintezu slika i prevoÄ‘enje slika. Modeli generiranja slika Äesto se obuÄavaju na velikim skupovima podataka o slikama, kao Å¡to je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generiranje novih slika ili za ureÄ‘ivanje postojeÄ‡ih slika tehnikama poput inpaintinga, super-rezolucije i kolorizacije. Primjeri ukljuÄuju [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) i [Stable Diffusion modeli](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![Generiranje slika](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.hr.png)

Modeli generiranja teksta i koda su modeli koji generiraju tekst ili kod. Ovi modeli Äesto se koriste za saÅ¾imanje teksta, prevoÄ‘enje i odgovaranje na pitanja. Modeli generiranja teksta Äesto se obuÄavaju na velikim skupovima podataka o tekstu, kao Å¡to je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), i mogu se koristiti za generiranje novog teksta ili za odgovaranje na pitanja. Modeli generiranja koda, poput [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), Äesto se obuÄavaju na velikim skupovima podataka o kodu, kao Å¡to je GitHub, i mogu se koristiti za generiranje novog koda ili za ispravljanje greÅ¡aka u postojeÄ‡em kodu.

![Generiranje teksta i koda](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.hr.png)

### Encoder-Decoder naspram Samo Decoder

Da bismo razgovarali o razliÄitim vrstama arhitektura LLM-ova, koristimo analogiju.

Zamislite da vam je menadÅ¾er dao zadatak pisanja kviza za studente. Imate dva kolege; jedan nadzire stvaranje sadrÅ¾aja, a drugi nadzire pregledavanje.

Stvaratelj sadrÅ¾aja je poput modela samo Decoder, moÅ¾e pogledati temu i vidjeti Å¡to ste veÄ‡ napisali, a zatim moÅ¾e napisati kurs na temelju toga. Vrlo su dobri u pisanju zanimljivog i informativnog sadrÅ¾aja, ali nisu vrlo dobri u razumijevanju teme i ciljeva uÄenja. Neki primjeri modela Decoder su GPT obitelj modela, kao Å¡to je GPT-3.

Recenzent je poput modela samo Encoder, gleda na napisani kurs i odgovore, primjeÄ‡ujuÄ‡i odnos izmeÄ‘u njih i razumijevanje konteksta, ali nije dobar u generiranju sadrÅ¾aja. Primjer modela samo Encoder bio bi BERT.

Zamislite da moÅ¾emo imati nekoga tko bi mogao stvoriti i pregledati kviz, ovo je Encoder-Decoder model. Neki primjeri bili bi BART i T5.

### Usluga naspram Model

Sada, razgovarajmo o razlici izmeÄ‘u usluge i modela. Usluga je proizvod koji nudi pruÅ¾atelj usluga u oblaku i Äesto je kombinacija modela, podataka i drugih komponenti. Model je osnovna komponenta usluge i Äesto je temeljni model, kao Å¡to je LLM.

Usluge su Äesto optimizirane za proizvodnu upotrebu i Äesto ih je lakÅ¡e koristiti od modela, putem grafiÄkog korisniÄkog suÄelja. MeÄ‘utim, usluge nisu uvijek dostupne besplatno i moÅ¾da zahtijevaju pretplatu ili plaÄ‡anje za koriÅ¡tenje, u zamjenu za koriÅ¡tenje opreme i resursa vlasnika usluge, optimizaciju troÅ¡kova i lako skaliranje. Primjer usluge je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), koji nudi plan plaÄ‡anja prema koriÅ¡tenju, Å¡to znaÄi da se korisnicima naplaÄ‡uje proporcionalno koliko koriste uslugu. TakoÄ‘er, Azure OpenAI Service nudi sigurnost na razini poduzeÄ‡a i okvir odgovorne AI na vrhu sposobnosti modela.

Modeli su samo Neuronska MreÅ¾a, s parametrima, teÅ¾inama i ostalim. OmoguÄ‡uju tvrtkama da se pokreÄ‡u lokalno, meÄ‘utim, trebale bi kupiti opremu, izgraditi strukturu za skaliranje i kupiti licencu ili koristiti open-source model. Model poput LLaMA je dostupan za koriÅ¡tenje, zahtijevajuÄ‡i raÄunalnu snagu za pokretanje modela.

## Kako testirati i iterirati s razliÄitim modelima za razumijevanje performansi na Azureu

Nakon Å¡to je naÅ¡ tim istraÅ¾io trenutni krajolik LLM-ova i identificirao neke dobre kandidate za njihove scenarije, sljedeÄ‡i korak je testiranje na njihovim podacima i radnom optereÄ‡enju. Ovo je iterativni proces, provodi se putem eksperimenata i mjerenja.
VeÄ‡ina modela koje smo spomenuli u prethodnim paragrafima (OpenAI modeli, open source modeli poput Llama2 i Hugging Face transformatori) dostupni su u [Katalogu modela](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) u [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je Cloud Platforma dizajnirana za developere za izgradnju generativnih AI aplikacija i upravljanje cijelim razvojnim Å¾ivotnim ciklusom - od eksperimentiranja do evaluacije - kombiniranjem svih Azure AI usluga u jedinstvenom centru s praktiÄnim GUI-jem. Katalog modela u Azure AI Studio omoguÄ‡uje korisniku da:

- PronaÄ‘e Temeljni Model od interesa u katalogu - bilo vlasniÄki ili open source, filtriranjem prema zadatku, licenci ili nazivu. Kako bi se poboljÅ¡ala pretraÅ¾ivost, modeli su organizirani u kolekcije, poput Azure OpenAI kolekcije, Hugging Face kolekcije i viÅ¡e.

![Katalog modela](../../../translated_images/AzureAIStudioModelCatalog.e34ac207ac348d31e74246c4f91d10086444783b72bbee3658e0453918aa5d22.hr.png)

- Pregleda karticu modela, ukljuÄujuÄ‡i detaljan opis namijenjene upotrebe i podataka za obuku, primjere koda i rezultate evaluacije u internom evaluacijskom biblioteci.

![Kartica modela](../../../translated_images/ModelCard.8b25784bb406028655a12ea87d1ef3d52302e5d692ae4ec559c2dce7682027c7.hr.png)
- Usporedite mjerila meÄ‘u modelima i skupovima podataka dostupnim u industriji kako biste procijenili koji najbolje odgovara poslovnom scenariju, putem [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst) ploÄe.

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.hr.png)

- Precizno prilagodite model na prilagoÄ‘enim podacima za obuku kako biste poboljÅ¡ali izvedbu modela u odreÄ‘enom radnom optereÄ‡enju, koristeÄ‡i moguÄ‡nosti eksperimentiranja i praÄ‡enja Azure AI Studija.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.hr.png)

- Implementirajte originalni unaprijed obuÄeni model ili precizno prilagoÄ‘enu verziju na udaljeni kraj za inferenciju u stvarnom vremenu - upravljano raÄunanje - ili bez posluÅ¾itelja api krajnju toÄku - [plaÄ‡anje prema koriÅ¡tenju](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - kako bi ga aplikacije mogle koristiti.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.hr.png)

> [!NOTE]
> Trenutno nisu svi modeli u katalogu dostupni za precizno prilagoÄ‘avanje i/ili implementaciju plaÄ‡anja prema koriÅ¡tenju. Provjerite karticu modela za pojedinosti o moguÄ‡nostima i ograniÄenjima modela.

## PoboljÅ¡anje rezultata LLM-a

IstraÅ¾ili smo s naÅ¡im startup timom razliÄite vrste LLM-a i Cloud Platformu (Azure Machine Learning) koja nam omoguÄ‡uje usporedbu razliÄitih modela, njihovu procjenu na testnim podacima, poboljÅ¡anje performansi i implementaciju na inferencijskim krajnjim toÄkama.

Ali kada bi trebali razmotriti precizno prilagoÄ‘avanje modela umjesto koriÅ¡tenja unaprijed obuÄenog? Postoje li drugi pristupi za poboljÅ¡anje performansi modela u specifiÄnim radnim optereÄ‡enjima?

Postoji nekoliko pristupa koje poslovanje moÅ¾e koristiti kako bi postiglo Å¾eljene rezultate od LLM-a. MoÅ¾ete odabrati razliÄite vrste modela s razliÄitim stupnjevima obuke prilikom implementacije LLM-a u proizvodnju, s razliÄitim razinama sloÅ¾enosti, troÅ¡kova i kvalitete. Evo nekoliko razliÄitih pristupa:

- **InÅ¾enjering upita s kontekstom**. Ideja je pruÅ¾iti dovoljno konteksta prilikom upita kako biste osigurali da dobijete potrebne odgovore.

- **Generiranje obogaÄ‡eno preuzimanjem, RAG**. VaÅ¡i podaci mogu postojati u bazi podataka ili web krajnjoj toÄki, na primjer, kako biste osigurali da su ti podaci, ili njihov podskup, ukljuÄeni u vrijeme upita, moÅ¾ete dohvatiti relevantne podatke i uÄiniti ih dijelom korisniÄkog upita.

- **Precizno prilagoÄ‘eni model**. Ovdje ste dodatno obuÄili model na vlastitim podacima Å¡to je dovelo do toga da model bude precizniji i odgovara vaÅ¡im potrebama, ali to moÅ¾e biti skupo.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.hr.png)

Izvor slike: [ÄŒetiri naÄina na koje poduzeÄ‡a implementiraju LLM-e | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### InÅ¾enjering upita s kontekstom

Unaprijed obuÄeni LLM-ovi vrlo dobro funkcioniraju na generaliziranim zadacima prirodnog jezika, Äak i kada ih se poziva kratkim upitom, poput reÄenice za dovrÅ¡avanje ili pitanja â€“ takozvano "zero-shot" uÄenje.

MeÄ‘utim, Å¡to viÅ¡e korisnik moÅ¾e oblikovati svoj upit, s detaljnim zahtjevom i primjerima â€“ Kontekstom â€“ to Ä‡e odgovor biti precizniji i bliÅ¾i korisnikovim oÄekivanjima. U ovom sluÄaju, govorimo o "one-shot" uÄenju ako upit ukljuÄuje samo jedan primjer i "few-shot uÄenju" ako ukljuÄuje viÅ¡e primjera. InÅ¾enjering upita s kontekstom je najisplativiji pristup za poÄetak.

### Generiranje obogaÄ‡eno preuzimanjem (RAG)

LLM-ovi imaju ograniÄenje da mogu koristiti samo podatke koji su koriÅ¡teni tijekom njihove obuke za generiranje odgovora. To znaÄi da ne znaju niÅ¡ta o Äinjenicama koje su se dogodile nakon njihovog procesa obuke i ne mogu pristupiti ne-javnim informacijama (poput podataka tvrtke). Ovo se moÅ¾e prevladati kroz RAG, tehniku koja obogaÄ‡uje upit vanjskim podacima u obliku dijelova dokumenata, uzimajuÄ‡i u obzir ograniÄenja duljine upita. To je podrÅ¾ano alatima za vektorske baze podataka (poput [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) koji dohvaÄ‡aju korisne dijelove iz raznih unaprijed definiranih izvora podataka i dodaju ih u kontekst upita.

Ova tehnika je vrlo korisna kada poduzeÄ‡e nema dovoljno podataka, dovoljno vremena ili resursa za precizno prilagoÄ‘avanje LLM-a, ali i dalje Å¾eli poboljÅ¡ati performanse u specifiÄnom radnom optereÄ‡enju i smanjiti rizike od izmiÅ¡ljotina, tj. mistifikacije stvarnosti ili Å¡tetnog sadrÅ¾aja.

### Precizno prilagoÄ‘eni model

Precizno prilagoÄ‘avanje je proces koji koristi prijenosno uÄenje kako bi 'prilagodio' model za zadatak nizvodno ili rijeÅ¡io specifiÄan problem. Za razliku od uÄenja na nekoliko primjera i RAG-a, rezultira generiranjem novog modela s aÅ¾uriranim teÅ¾inama i pristranostima. Zahtijeva skup primjera za obuku koji se sastoje od jednog ulaza (upita) i njegovog povezanog izlaza (dovrÅ¡etka). Ovo bi bio preferirani pristup ako:

- **KoriÅ¡tenje precizno prilagoÄ‘enih modela**. PoduzeÄ‡e bi Å¾eljelo koristiti precizno prilagoÄ‘ene manje sposobne modele (poput modela za ugraÄ‘ivanje) umjesto modela visokih performansi, Å¡to rezultira isplativijim i brÅ¾im rjeÅ¡enjem.

- **Razmatranje latencije**. Latencija je vaÅ¾na za specifiÄan sluÄaj uporabe, tako da nije moguÄ‡e koristiti vrlo duge upite ili broj primjera koji bi se trebali nauÄiti iz modela ne odgovara ograniÄenju duljine upita.

- **OdrÅ¾avanje aÅ¾urnosti**. PoduzeÄ‡e ima puno visokokvalitetnih podataka i oznaka istine i resurse potrebne za odrÅ¾avanje tih podataka aÅ¾urnima tijekom vremena.

### ObuÄeni model

ObuÄavanje LLM-a od nule je bez sumnje najteÅ¾i i najsloÅ¾eniji pristup koji treba usvojiti, zahtijevajuÄ‡i ogromne koliÄine podataka, vjeÅ¡te resurse i odgovarajuÄ‡u raÄunalnu snagu. Ova opcija bi se trebala razmotriti samo u scenariju gdje poduzeÄ‡e ima sluÄaj uporabe specifiÄan za domenu i veliku koliÄinu podataka usmjerenih na domenu.

## Provjera znanja

Koji bi mogao biti dobar pristup za poboljÅ¡anje rezultata dovrÅ¡etka LLM-a?

1. InÅ¾enjering upita s kontekstom
1. RAG
1. Precizno prilagoÄ‘eni model

A:3, ako imate vremena i resursa te visokokvalitetne podatke, precizno prilagoÄ‘avanje je bolja opcija za odrÅ¾avanje aÅ¾urnosti. MeÄ‘utim, ako traÅ¾ite poboljÅ¡anja i nedostaje vam vremena, vrijedi prvo razmotriti RAG.

## ğŸš€ Izazov

ProÄitajte viÅ¡e o tome kako moÅ¾ete [koristiti RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) za svoje poslovanje.

## OdliÄan posao, nastavite s uÄenjem

Nakon Å¡to zavrÅ¡ite ovu lekciju, pogledajte naÅ¡u [Kolekciju za uÄenje generativne AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) kako biste nastavili usavrÅ¡avati svoje znanje o generativnoj AI!

PrijeÄ‘ite na Lekciju 3 gdje Ä‡emo pogledati kako [odgovorno graditi s generativnom AI](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Odricanje od odgovornosti**:  
Ovaj dokument je preveden koriÅ¡tenjem AI usluge prevoÄ‘enja [Co-op Translator](https://github.com/Azure/co-op-translator). Iako teÅ¾imo preciznosti, molimo vas da budete svjesni da automatizirani prijevodi mogu sadrÅ¾avati greÅ¡ke ili netoÄnosti. Izvorni dokument na izvornom jeziku treba smatrati mjerodavnim izvorom. Za kritiÄne informacije preporuÄuje se profesionalni ljudski prijevod. Ne odgovaramo za nesporazume ili pogreÅ¡na tumaÄenja koja proizlaze iz koriÅ¡tenja ovog prijevoda.