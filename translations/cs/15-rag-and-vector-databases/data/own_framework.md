<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-05-20T02:25:58+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "cs"
}
-->
# Ãšvod do neuronovÃ½ch sÃ­tÃ­. VÃ­cevrstvÃ½ perceptron

V pÅ™edchozÃ­ ÄÃ¡sti jste se seznÃ¡mili s nejjednoduÅ¡Å¡Ã­m modelem neuronovÃ© sÃ­tÄ› - jednovrstvÃ½m perceptronem, coÅ¾ je lineÃ¡rnÃ­ model pro dvoutÅ™Ã­dnÃ­ klasifikaci.

V tÃ©to ÄÃ¡sti rozÅ¡Ã­Å™Ã­me tento model na flexibilnÄ›jÅ¡Ã­ rÃ¡mec, kterÃ½ nÃ¡m umoÅ¾nÃ­:

* provÃ¡dÄ›t **vÃ­cetÅ™Ã­dnÃ­ klasifikaci** kromÄ› dvoutÅ™Ã­dnÃ­
* Å™eÅ¡it **regresnÃ­ problÃ©my** kromÄ› klasifikace
* oddÄ›lit tÅ™Ã­dy, kterÃ© nejsou lineÃ¡rnÄ› separovatelnÃ©

Vyvineme takÃ© vlastnÃ­ modulÃ¡rnÃ­ rÃ¡mec v Pythonu, kterÃ½ nÃ¡m umoÅ¾nÃ­ konstruovat rÅ¯znÃ© architektury neuronovÃ½ch sÃ­tÃ­.

## Formalizace strojovÃ©ho uÄenÃ­

ZaÄnÄ›me formalizacÃ­ problÃ©mu strojovÃ©ho uÄenÃ­. PÅ™edpoklÃ¡dejme, Å¾e mÃ¡me trÃ©novacÃ­ datovou sadu **X** s oznaÄenÃ­mi **Y** a potÅ™ebujeme vytvoÅ™it model *f*, kterÃ½ bude dÄ›lat co nejpÅ™esnÄ›jÅ¡Ã­ pÅ™edpovÄ›di. Kvalita pÅ™edpovÄ›dÃ­ je mÄ›Å™ena pomocÃ­ **ztrÃ¡tovÃ© funkce** â„’. NÃ¡sledujÃ­cÃ­ ztrÃ¡tovÃ© funkce se Äasto pouÅ¾Ã­vajÃ­:

* Pro regresnÃ­ problÃ©m, kdy potÅ™ebujeme pÅ™edpovÄ›dÄ›t ÄÃ­slo, mÅ¯Å¾eme pouÅ¾Ã­t **absolutnÃ­ chybu** âˆ‘<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>| nebo **kvadratickou chybu** âˆ‘<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Pro klasifikaci pouÅ¾Ã­vÃ¡me **0-1 ztrÃ¡tu** (coÅ¾ je v podstatÄ› totÃ©Å¾ jako **pÅ™esnost** modelu) nebo **logistickou ztrÃ¡tu**.

Pro jednovrstvÃ½ perceptron byla funkce *f* definovÃ¡na jako lineÃ¡rnÃ­ funkce *f(x)=wx+b* (zde *w* je matice vah, *x* je vektor vstupnÃ­ch znakÅ¯ a *b* je vektor biasu). Pro rÅ¯znÃ© architektury neuronovÃ½ch sÃ­tÃ­ mÅ¯Å¾e tato funkce nabÃ½t sloÅ¾itÄ›jÅ¡Ã­ formy.

> V pÅ™Ã­padÄ› klasifikace je Äasto Å¾Ã¡doucÃ­ zÃ­skat pravdÄ›podobnosti odpovÃ­dajÃ­cÃ­ch tÅ™Ã­d jako vÃ½stup sÃ­tÄ›. K pÅ™evodu libovolnÃ½ch ÄÃ­sel na pravdÄ›podobnosti (napÅ™. k normalizaci vÃ½stupu) Äasto pouÅ¾Ã­vÃ¡me funkci **softmax** Ïƒ, a funkce *f* se stÃ¡vÃ¡ *f(x)=Ïƒ(wx+b)*

Ve vÃ½Å¡e uvedenÃ© definici *f* se *w* a *b* nazÃ½vajÃ­ **parametry** Î¸=âŸ¨*w,b*âŸ©. Vzhledem k datovÃ© sadÄ› âŸ¨**X**,**Y**âŸ© mÅ¯Å¾eme vypoÄÃ­tat celkovou chybu na celÃ© datovÃ© sadÄ› jako funkci parametrÅ¯ Î¸.

> âœ… **CÃ­lem trÃ©novÃ¡nÃ­ neuronovÃ© sÃ­tÄ› je minimalizovat chybu zmÄ›nou parametrÅ¯ Î¸**

## Optimalizace gradientnÃ­ho sestupu

Existuje znÃ¡mÃ¡ metoda optimalizace funkcÃ­ nazvanÃ¡ **gradientnÃ­ sestup**. MyÅ¡lenka je, Å¾e mÅ¯Å¾eme vypoÄÃ­tat derivaci (v multidimenzionÃ¡lnÃ­m pÅ™Ã­padÄ› nazÃ½vanou **gradient**) ztrÃ¡tovÃ© funkce vzhledem k parametrÅ¯m a mÄ›nit parametry takovÃ½m zpÅ¯sobem, aby se chyba zmenÅ¡ovala. To lze formalizovat nÃ¡sledovnÄ›:

* Inicializujte parametry nÄ›jakÃ½mi nÃ¡hodnÃ½mi hodnotami w<sup>(0)</sup>, b<sup>(0)</sup>
* Opakujte nÃ¡sledujÃ­cÃ­ krok mnohokrÃ¡t:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚b

BÄ›hem trÃ©novÃ¡nÃ­ se oÄekÃ¡vÃ¡, Å¾e optimalizaÄnÃ­ kroky budou vypoÄÃ­tÃ¡ny s ohledem na celou datovou sadu (pamatujte, Å¾e ztrÃ¡ta se poÄÃ­tÃ¡ jako souÄet pÅ™es vÅ¡echny trÃ©novacÃ­ vzorky). V reÃ¡lnÃ©m Å¾ivotÄ› vÅ¡ak bereme malÃ© ÄÃ¡sti datovÃ© sady nazÃ½vanÃ© **minibatch**, a poÄÃ­tÃ¡me gradienty na zÃ¡kladÄ› podmnoÅ¾iny dat. ProtoÅ¾e podmnoÅ¾ina je pokaÅ¾dÃ© vybÃ­rÃ¡na nÃ¡hodnÄ›, takovÃ¡ metoda se nazÃ½vÃ¡ **stochastickÃ½ gradientnÃ­ sestup** (SGD).

## VÃ­cevrstvÃ© perceptrony a zpÄ›tnÃ¡ propagace

JednovrstvÃ¡ sÃ­Å¥, jak jsme vidÄ›li vÃ½Å¡e, je schopnÃ¡ klasifikovat lineÃ¡rnÄ› separovatelnÃ© tÅ™Ã­dy. Abychom vytvoÅ™ili bohatÅ¡Ã­ model, mÅ¯Å¾eme kombinovat nÄ›kolik vrstev sÃ­tÄ›. Matematicky by to znamenalo, Å¾e funkce *f* by mÄ›la sloÅ¾itÄ›jÅ¡Ã­ formu a bude vypoÄÃ­tÃ¡na v nÄ›kolika krocÃ­ch:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Î±(z<sub>1</sub>)+b<sub>2</sub>
* f = Ïƒ(z<sub>2</sub>)

Zde je Î± **nelineÃ¡rnÃ­ aktivaÄnÃ­ funkce**, Ïƒ je softmax funkce a parametry Î¸=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>

Algoritmus gradientnÃ­ho sestupu by zÅ¯stal stejnÃ½, ale bylo by obtÃ­Å¾nÄ›jÅ¡Ã­ vypoÄÃ­tat gradienty. Vzhledem k pravidlu Å™etÄ›zovÃ© diferenciace mÅ¯Å¾eme vypoÄÃ­tat derivace jako:

* âˆ‚â„’/âˆ‚w<sub>2</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚w<sub>2</sub>)
* âˆ‚â„’/âˆ‚w<sub>1</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚Î±)(âˆ‚Î±/âˆ‚z<sub>1</sub>)(âˆ‚z<sub>1</sub>/âˆ‚w<sub>1</sub>)

> âœ… Pravidlo Å™etÄ›zovÃ© diferenciace se pouÅ¾Ã­vÃ¡ k vÃ½poÄtu derivacÃ­ ztrÃ¡tovÃ© funkce vzhledem k parametrÅ¯m.

VÅ¡imnÄ›te si, Å¾e levÃ¡ ÄÃ¡st vÅ¡ech tÄ›chto vÃ½razÅ¯ je stejnÃ¡, a tak mÅ¯Å¾eme efektivnÄ› vypoÄÃ­tat derivace zaÄÃ­najÃ­cÃ­ od ztrÃ¡tovÃ© funkce a jÃ­t "zpÄ›t" skrze vÃ½poÄetnÃ­ graf. TakÅ¾e metoda trÃ©novÃ¡nÃ­ vÃ­cevrstvÃ©ho perceptronu se nazÃ½vÃ¡ **zpÄ›tnÃ¡ propagace**, nebo 'backprop'.

> TODO: citace obrÃ¡zku

> âœ… ZpÄ›tnou propagaci probereme mnohem podrobnÄ›ji v naÅ¡em pÅ™Ã­kladu v notebooku.

## ZÃ¡vÄ›r

V tÃ©to lekci jsme vytvoÅ™ili vlastnÃ­ knihovnu neuronovÃ½ch sÃ­tÃ­ a pouÅ¾ili jsme ji pro jednoduchÃ½ dvourozmÄ›rnÃ½ klasifikaÄnÃ­ Ãºkol.

## ğŸš€ VÃ½zva

V pÅ™iloÅ¾enÃ©m notebooku implementujete vlastnÃ­ rÃ¡mec pro vytvÃ¡Å™enÃ­ a trÃ©novÃ¡nÃ­ vÃ­cevrstvÃ½ch perceptronÅ¯. Budete mÃ­t moÅ¾nost vidÄ›t podrobnÄ›, jak modernÃ­ neuronovÃ© sÃ­tÄ› fungujÃ­.

PokraÄujte do notebooku OwnFramework a projdÄ›te si ho.

## PÅ™ehled & Samostudium

ZpÄ›tnÃ¡ propagace je bÄ›Å¾nÃ½ algoritmus pouÅ¾Ã­vanÃ½ v AI a ML, stojÃ­ za to ji podrobnÄ›ji prostudovat.

## Ãškol

V tÃ©to laboratoÅ™i jste poÅ¾Ã¡dÃ¡ni, abyste pouÅ¾ili rÃ¡mec, kterÃ½ jste vytvoÅ™ili v tÃ©to lekci, k vyÅ™eÅ¡enÃ­ klasifikace ruÄnÄ› psanÃ½ch ÄÃ­slic MNIST.

* Pokyny
* Notebook

**UpozornÄ›nÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte na pamÄ›ti, Å¾e automatizovanÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro kritickÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme zodpovÄ›dnÃ­ za jakÃ©koli nedorozumÄ›nÃ­ nebo chybnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.