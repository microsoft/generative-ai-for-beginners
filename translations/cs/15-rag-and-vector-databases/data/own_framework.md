<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-07-09T16:50:34+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "cs"
}
-->
# Ãšvod do neuronovÃ½ch sÃ­tÃ­. VÃ­cevrstvÃ½ perceptron

V pÅ™edchozÃ­ ÄÃ¡sti jste se seznÃ¡mili s nejjednoduÅ¡Å¡Ã­m modelem neuronovÃ© sÃ­tÄ› â€“ jednovrstvÃ½m perceptronem, coÅ¾ je lineÃ¡rnÃ­ model pro dvoutÅ™Ã­dnÃ­ klasifikaci.

V tÃ©to ÄÃ¡sti tento model rozÅ¡Ã­Å™Ã­me do flexibilnÄ›jÅ¡Ã­ho rÃ¡mce, kterÃ½ nÃ¡m umoÅ¾nÃ­:

* provÃ¡dÄ›t **vÃ­cetÅ™Ã­dnÃ­ klasifikaci** kromÄ› dvoutÅ™Ã­dnÃ­
* Å™eÅ¡it **regresnÃ­ Ãºlohy** kromÄ› klasifikace
* oddÄ›lit tÅ™Ã­dy, kterÃ© nejsou lineÃ¡rnÄ› separabilnÃ­

TakÃ© si vytvoÅ™Ã­me vlastnÃ­ modulÃ¡rnÃ­ rÃ¡mec v Pythonu, kterÃ½ nÃ¡m umoÅ¾nÃ­ sestavovat rÅ¯znÃ© architektury neuronovÃ½ch sÃ­tÃ­.

## Formalizace strojovÃ©ho uÄenÃ­

ZaÄnÄ›me formalizacÃ­ problÃ©mu strojovÃ©ho uÄenÃ­. PÅ™edpoklÃ¡dejme, Å¾e mÃ¡me trÃ©novacÃ­ datovou sadu **X** s popisky **Y** a potÅ™ebujeme vytvoÅ™it model *f*, kterÃ½ bude dÄ›lat co nejpÅ™esnÄ›jÅ¡Ã­ predikce. Kvalita predikcÃ­ se mÄ›Å™Ã­ pomocÃ­ **ztrÃ¡tovÃ© funkce** â„’. ÄŒasto pouÅ¾Ã­vanÃ© ztrÃ¡tovÃ© funkce jsou:

* Pro regresnÃ­ Ãºlohu, kdy potÅ™ebujeme pÅ™edpovÄ›dÄ›t ÄÃ­slo, mÅ¯Å¾eme pouÅ¾Ã­t **absolutnÃ­ chybu** âˆ‘<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, nebo **Ätvercovou chybu** âˆ‘<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* Pro klasifikaci pouÅ¾Ã­vÃ¡me **0-1 ztrÃ¡tu** (coÅ¾ je v podstatÄ› totÃ©Å¾ jako **pÅ™esnost** modelu), nebo **logistickou ztrÃ¡tu**.

U jednovrstvÃ©ho perceptronu byla funkce *f* definovÃ¡na jako lineÃ¡rnÃ­ funkce *f(x)=wx+b* (kde *w* je matice vah, *x* je vektor vstupnÃ­ch rysÅ¯ a *b* je vektor biasÅ¯). U rÅ¯znÃ½ch architektur neuronovÃ½ch sÃ­tÃ­ mÅ¯Å¾e mÃ­t tato funkce sloÅ¾itÄ›jÅ¡Ã­ podobu.

> V pÅ™Ã­padÄ› klasifikace je Äasto Å¾Ã¡doucÃ­ zÃ­skat jako vÃ½stup sÃ­tÄ› pravdÄ›podobnosti pÅ™Ã­sluÅ¡nÃ½ch tÅ™Ã­d. Pro pÅ™evedenÃ­ libovolnÃ½ch ÄÃ­sel na pravdÄ›podobnosti (napÅ™. normalizaci vÃ½stupu) Äasto pouÅ¾Ã­vÃ¡me **softmax** funkci Ïƒ, a funkce *f* se pak stÃ¡vÃ¡ *f(x)=Ïƒ(wx+b)*

Ve vÃ½Å¡e uvedenÃ© definici *f* jsou *w* a *b* nazÃ½vÃ¡ny **parametry** Î¸=âŸ¨*w,b*âŸ©. Pro danou datovou sadu âŸ¨**X**,**Y**âŸ© mÅ¯Å¾eme spoÄÃ­tat celkovou chybu na celÃ© sadÄ› jako funkci parametrÅ¯ Î¸.

> âœ… **CÃ­lem trÃ©ninku neuronovÃ© sÃ­tÄ› je minimalizovat chybu zmÄ›nou parametrÅ¯ Î¸**

## Optimalizace pomocÃ­ gradientnÃ­ho sestupu

Existuje znÃ¡mÃ¡ metoda optimalizace funkcÃ­ nazÃ½vanÃ¡ **gradientnÃ­ sestup**. MyÅ¡lenka je takovÃ¡, Å¾e mÅ¯Å¾eme spoÄÃ­tat derivaci (v pÅ™Ã­padÄ› vÃ­ce rozmÄ›rÅ¯ nazÃ½vanou **gradient**) ztrÃ¡tovÃ© funkce vzhledem k parametrÅ¯m a mÄ›nit parametry tak, aby se chyba sniÅ¾ovala. FormÃ¡lnÄ› to lze vyjÃ¡dÅ™it takto:

* Inicializujeme parametry nÃ¡hodnÃ½mi hodnotami w<sup>(0)</sup>, b<sup>(0)</sup>
* Opakujeme nÃ¡sledujÃ­cÃ­ krok mnohokrÃ¡t:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚b

BÄ›hem trÃ©ninku by se optimalizaÄnÃ­ kroky mÄ›ly poÄÃ­tat s ohledem na celou datovou sadu (pamatujte, Å¾e ztrÃ¡ta se poÄÃ­tÃ¡ jako souÄet pÅ™es vÅ¡echny trÃ©novacÃ­ vzorky). V praxi vÅ¡ak bereme malÃ© ÄÃ¡sti dat nazÃ½vanÃ© **minibatches** a poÄÃ­tÃ¡me gradienty na zÃ¡kladÄ› podmnoÅ¾iny dat. ProtoÅ¾e podmnoÅ¾ina je pokaÅ¾dÃ© nÃ¡hodnÃ¡, tato metoda se nazÃ½vÃ¡ **stochastickÃ½ gradientnÃ­ sestup** (SGD).

## VÃ­cevrstvÃ½ perceptron a zpÄ›tnÃ¡ propagace

JednovrstvÃ¡ sÃ­Å¥, jak jsme vidÄ›li vÃ½Å¡e, dokÃ¡Å¾e klasifikovat lineÃ¡rnÄ› separabilnÃ­ tÅ™Ã­dy. Pro vytvoÅ™enÃ­ bohatÅ¡Ã­ho modelu mÅ¯Å¾eme zkombinovat nÄ›kolik vrstev sÃ­tÄ›. Matematicky to znamenÃ¡, Å¾e funkce *f* bude mÃ­t sloÅ¾itÄ›jÅ¡Ã­ podobu a bude se poÄÃ­tat ve vÃ­ce krocÃ­ch:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Î±(z<sub>1</sub>)+b<sub>2</sub>
* f = Ïƒ(z<sub>2</sub>)

Zde je Î± **nelineÃ¡rnÃ­ aktivaÄnÃ­ funkce**, Ïƒ je softmax funkce a parametry Î¸=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Algoritmus gradientnÃ­ho sestupu zÅ¯stÃ¡vÃ¡ stejnÃ½, ale vÃ½poÄet gradientÅ¯ je sloÅ¾itÄ›jÅ¡Ã­. DÃ­ky pravidlu Å™etÄ›zce pro derivace mÅ¯Å¾eme spoÄÃ­tat derivace takto:

* âˆ‚â„’/âˆ‚w<sub>2</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚w<sub>2</sub>)
* âˆ‚â„’/âˆ‚w<sub>1</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚Î±)(âˆ‚Î±/âˆ‚z<sub>1</sub>)(âˆ‚z<sub>1</sub>/âˆ‚w<sub>1</sub>)

> âœ… Pravidlo Å™etÄ›zce se pouÅ¾Ã­vÃ¡ k vÃ½poÄtu derivacÃ­ ztrÃ¡tovÃ© funkce vzhledem k parametrÅ¯m.

VÅ¡imnÄ›te si, Å¾e levÃ¡ ÄÃ¡st vÅ¡ech tÄ›chto vÃ½razÅ¯ je stejnÃ¡, a proto mÅ¯Å¾eme efektivnÄ› poÄÃ­tat derivace zaÄÃ­najÃ­cÃ­ od ztrÃ¡tovÃ© funkce a postupovat â€zpÄ›tnÄ›â€œ pÅ™es vÃ½poÄetnÃ­ graf. Tato metoda trÃ©ninku vÃ­cevrstvÃ©ho perceptronu se nazÃ½vÃ¡ **zpÄ›tnÃ¡ propagace** (backpropagation), nebo zkrÃ¡cenÄ› 'backprop'.



> TODO: citace obrÃ¡zku

> âœ… ZpÄ›tnou propagaci podrobnÄ›ji probereme v naÅ¡em pÅ™Ã­kladu v notebooku.  

## ZÃ¡vÄ›r

V tÃ©to lekci jsme si vytvoÅ™ili vlastnÃ­ knihovnu pro neuronovÃ© sÃ­tÄ› a pouÅ¾ili ji pro jednoduchÃ½ dvourozmÄ›rnÃ½ klasifikaÄnÃ­ Ãºkol.

## ğŸš€ VÃ½zva

V pÅ™iloÅ¾enÃ©m notebooku si implementujete vlastnÃ­ rÃ¡mec pro tvorbu a trÃ©nink vÃ­cevrstvÃ½ch perceptronÅ¯. PodrobnÄ› uvidÃ­te, jak modernÃ­ neuronovÃ© sÃ­tÄ› fungujÃ­.

PÅ™ejdÄ›te do notebooku OwnFramework a projdÄ›te si ho.

## PÅ™ehled a samostudium

ZpÄ›tnÃ¡ propagace je bÄ›Å¾nÃ½ algoritmus pouÅ¾Ã­vanÃ½ v AI a ML, stojÃ­ za to se mu vÄ›novat podrobnÄ›ji.

## ZadÃ¡nÃ­

V tomto cviÄenÃ­ mÃ¡te za Ãºkol pouÅ¾Ã­t rÃ¡mec, kterÃ½ jste si vytvoÅ™ili v tÃ©to lekci, k Å™eÅ¡enÃ­ klasifikace ruÄnÄ› psanÃ½ch ÄÃ­slic MNIST.

* Instrukce
* Notebook

**ProhlÃ¡Å¡enÃ­ o vylouÄenÃ­ odpovÄ›dnosti**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ usilujeme o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatizovanÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho mateÅ™skÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme odpovÄ›dnÃ­ za jakÃ©koliv nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© vÃ½klady vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.