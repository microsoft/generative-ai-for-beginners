<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T18:56:15+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "cs"
}
-->
[![Open Source Models](../../../../../translated_images/cs/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# DoladÄ›nÃ­ vaÅ¡eho LLM

PouÅ¾Ã­vÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ pro tvorbu generativnÃ­ch AI aplikacÃ­ pÅ™inÃ¡Å¡Ã­ novÃ© vÃ½zvy. KlÃ­ÄovÃ½m problÃ©mem je zajistit kvalitu odpovÄ›dÃ­ (pÅ™esnost a relevanci) v obsahu generovanÃ©m modelem pro danÃ½ uÅ¾ivatelskÃ½ poÅ¾adavek. V pÅ™edchozÃ­ch lekcÃ­ch jsme diskutovali techniky jako prompt engineering a generovÃ¡nÃ­ s podporou vyhledÃ¡vÃ¡nÃ­, kterÃ© se snaÅ¾Ã­ problÃ©m vyÅ™eÅ¡it _Ãºpravou vstupu promptu_ do existujÃ­cÃ­ho modelu.

V dneÅ¡nÃ­ lekci se budeme vÄ›novat tÅ™etÃ­ technice, **doladÄ›nÃ­ (fine-tuning)**, kterÃ¡ se snaÅ¾Ã­ vÃ½zvu Å™eÅ¡it _pÅ™eÅ¡kolenÃ­m samotnÃ©ho modelu_ s pouÅ¾itÃ­m dalÅ¡Ã­ch dat. PojÄme se ponoÅ™it do detailÅ¯.

## VÃ½ukovÃ© cÃ­le

Tato lekce pÅ™edstavuje koncept doladÄ›nÃ­ pÅ™edtrÃ©novanÃ½ch jazykovÃ½ch modelÅ¯, prozkoumÃ¡ vÃ½hody a vÃ½zvy tohoto pÅ™Ã­stupu a poskytuje doporuÄenÃ­, kdy a jak doladÄ›nÃ­ pouÅ¾Ã­t ke zlepÅ¡enÃ­ vÃ½konu vaÅ¡ich generativnÃ­ch AI modelÅ¯.

Na konci lekce byste mÄ›li umÄ›t odpovÄ›dÄ›t na nÃ¡sledujÃ­cÃ­ otÃ¡zky:

- Co je doladÄ›nÃ­ jazykovÃ½ch modelÅ¯?
- Kdy a proÄ je doladÄ›nÃ­ uÅ¾iteÄnÃ©?
- Jak mohu doladit pÅ™edtrÃ©novanÃ½ model?
- JakÃ¡ jsou omezenÃ­ doladÄ›nÃ­?

Jste pÅ™ipraveni? PojÄme zaÄÃ­t.

## IlustrovanÃ½ prÅ¯vodce

Chcete zÃ­skat pÅ™ehled o tom, co budeme probÃ­rat, jeÅ¡tÄ› pÅ™edtÃ­m, neÅ¾ se pustÃ­me do podrobnostÃ­? PodÃ­vejte se na tento ilustrovanÃ½ prÅ¯vodce, kterÃ½ popisuje vzdÄ›lÃ¡vacÃ­ cestu tÃ©to lekce â€“ od seznÃ¡menÃ­ s klÃ­ÄovÃ½mi koncepty a motivacÃ­ pro doladÄ›nÃ­ aÅ¾ po pochopenÃ­ procesu a nejlepÅ¡Ã­ch postupÅ¯ pro provedenÃ­ doladÄ›nÃ­. Je to fascinujÃ­cÃ­ tÃ©ma k prozkoumÃ¡nÃ­, tak nezapomeÅˆte navÅ¡tÃ­vit strÃ¡nku [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pro dalÅ¡Ã­ odkazy na podporu vaÅ¡eho samostatnÃ©ho vzdÄ›lÃ¡vÃ¡nÃ­!

![IlustrovanÃ½ prÅ¯vodce doladÄ›nÃ­m jazykovÃ½ch modelÅ¯](../../../../../translated_images/cs/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Co je doladÄ›nÃ­ jazykovÃ½ch modelÅ¯?

Podle definice jsou velkÃ© jazykovÃ© modely _pÅ™edtrÃ©novanÃ©_ na rozsÃ¡hlÃ½ch mnoÅ¾stvÃ­ch textu zÃ­skanÃ½ch z rÅ¯znÃ½ch zdrojÅ¯ vÄetnÄ› internetu. Jak jsme se nauÄili v pÅ™edchozÃ­ch lekcÃ­ch, potÅ™ebujeme techniky jako _prompt engineering_ a _generovÃ¡nÃ­ s podporou vyhledÃ¡vÃ¡nÃ­_, abychom zlepÅ¡ili kvalitu odpovÄ›dÃ­ modelu na uÅ¾ivatelskÃ© dotazy (â€promptyâ€œ).

OblÃ­benÃ¡ technika prompt engineeringu zahrnuje poskytnutÃ­ modelu vÃ­ce pokynÅ¯, co se oÄekÃ¡vÃ¡ v odpovÄ›di, buÄ poskytnutÃ­m _instrukcÃ­_ (explicitnÃ­ vedenÃ­), nebo _nÄ›kolika pÅ™Ã­klady_ (implicitnÃ­ vedenÃ­). To se nazÃ½vÃ¡ _few-shot learning_, ale mÃ¡ dvÄ› omezenÃ­:

- Limity tokenÅ¯ modelu mohou omezit poÄet pÅ™Ã­kladÅ¯, kterÃ© mÅ¯Å¾ete uvÃ©st, a omezit efektivitu.
- NÃ¡klady na tokeny modelu mohou bÃ½t vysokÃ©, pokud pÅ™idÃ¡vÃ¡te pÅ™Ã­klady do kaÅ¾dÃ©ho promptu, coÅ¾ omezuje flexibilitu.

DoladÄ›nÃ­ je bÄ›Å¾nÃ¡ praxe v systÃ©mech strojovÃ©ho uÄenÃ­, kde vezmeme pÅ™edtrÃ©novanÃ½ model a pÅ™eÅ¡kolÃ­me ho s novÃ½mi daty, abychom zlepÅ¡ili jeho vÃ½kon na urÄitÃ©m Ãºkolu. V kontextu jazykovÃ½ch modelÅ¯ mÅ¯Å¾eme doladit pÅ™edtrÃ©novanÃ½ model _na peÄlivÄ› vybranÃ© sadÄ› pÅ™Ã­kladÅ¯ pro danÃ½ Ãºkol nebo aplikaÄnÃ­ domÃ©nu_, abychom vytvoÅ™ili **vlastnÃ­ model**, kterÃ½ mÅ¯Å¾e bÃ½t pÅ™esnÄ›jÅ¡Ã­ a relevantnÄ›jÅ¡Ã­ pro tento konkrÃ©tnÃ­ Ãºkol nebo domÃ©nu. VedlejÅ¡Ã­m pÅ™Ã­nosem doladÄ›nÃ­ je, Å¾e mÅ¯Å¾e takÃ© snÃ­Å¾it poÄet pÅ™Ã­kladÅ¯ potÅ™ebnÃ½ch pro few-shot learning â€“ tÃ­m se snÃ­Å¾Ã­ vyuÅ¾itÃ­ tokenÅ¯ a souvisejÃ­cÃ­ nÃ¡klady.

## Kdy a proÄ bychom mÄ›li doladit modely?

V _tomto_ kontextu, kdyÅ¾ mluvÃ­me o doladÄ›nÃ­, odkazujeme na **Å™Ã­zenÃ© (supervised)** doladÄ›nÃ­, kde se pÅ™eÅ¡kolenÃ­ provÃ¡dÃ­ **pÅ™idÃ¡nÃ­m novÃ½ch dat**, kterÃ¡ nebyla souÄÃ¡stÃ­ pÅ¯vodnÃ­ trÃ©novacÃ­ sady. To je odliÅ¡nÃ© od neÅ™Ã­zenÃ©ho doladÄ›nÃ­, kde je model pÅ™eÅ¡kolen na pÅ¯vodnÃ­ch datech, ale s jinÃ½mi hyperparametry.

KlÃ­ÄovÃ© je si uvÄ›domit, Å¾e doladÄ›nÃ­ je pokroÄilÃ¡ technika, kterÃ¡ vyÅ¾aduje urÄitou ÃºroveÅˆ odbornosti k dosaÅ¾enÃ­ oÄekÃ¡vanÃ½ch vÃ½sledkÅ¯. Pokud je provedena nesprÃ¡vnÄ›, nemusÃ­ pÅ™inÃ©st oÄekÃ¡vanÃ¡ zlepÅ¡enÃ­ a mÅ¯Å¾e dokonce zhorÅ¡it vÃ½kon modelu pro vaÅ¡e cÃ­lovÃ© domÃ©nÄ›.

Proto neÅ¾ se nauÄÃ­te "jak" doladit jazykovÃ© modely, musÃ­te vÄ›dÄ›t "proÄ" byste mÄ›li touto cestou jÃ­t a "kdy" zaÄÃ­t s procesem doladÄ›nÃ­. ZaÄnÄ›te tÃ­m, Å¾e si poloÅ¾Ã­te tyto otÃ¡zky:

- **PÅ™Ã­pad pouÅ¾itÃ­**: JakÃ½ je vÃ¡Å¡ _pÅ™Ã­pad pouÅ¾itÃ­_ pro doladÄ›nÃ­? JakÃ½ aspekt souÄasnÃ©ho pÅ™edtrÃ©novanÃ©ho modelu chcete zlepÅ¡it?
- **Alternativy**: ZkouÅ¡eli jste _jinÃ© techniky_ k dosaÅ¾enÃ­ poÅ¾adovanÃ½ch vÃ½sledkÅ¯? PouÅ¾ijte je k vytvoÅ™enÃ­ zÃ¡kladny pro porovnÃ¡nÃ­.
  - Prompt engineering: VyzkouÅ¡ejte techniky jako few-shot prompting s pÅ™Ã­klady relevantnÃ­ch odpovÄ›dÃ­. ZhodnoÅ¥te kvalitu odpovÄ›dÃ­.
  - GenerovÃ¡nÃ­ s podporou vyhledÃ¡vÃ¡nÃ­: VyzkouÅ¡ejte rozÅ¡Ã­Å™enÃ­ promptÅ¯ o vÃ½sledky vyhledÃ¡vanÃ© ve vaÅ¡ich datech. ZhodnoÅ¥te kvalitu odpovÄ›dÃ­.
- **NÃ¡klady**: Identifikovali jste nÃ¡klady doladÄ›nÃ­?
  - Schopnost ladÄ›nÃ­ - je pÅ™edtrÃ©novanÃ½ model dostupnÃ½ pro doladÄ›nÃ­?
  - ÃšsilÃ­ - pÅ™Ã­prava trÃ©novacÃ­ch dat, vyhodnocovÃ¡nÃ­ a zdokonalovÃ¡nÃ­ modelu.
  - VÃ½poÄetnÃ­ nÃ¡roÄnost - pro bÄ›h doladÄ›nÃ­ a nasazenÃ­ doladÄ›nÃ©ho modelu.
  - Data - pÅ™Ã­stup k dostateÄnÃ© kvalitÄ› pÅ™Ã­kladÅ¯, kterÃ© ovlivnÃ­ doladÄ›nÃ­.
- **PÅ™Ã­nosy**: Potvrdili jste pÅ™Ã­nosy doladÄ›nÃ­?
  - Kvalita - pÅ™ekonal doladÄ›nÃ½ model zÃ¡kladnÃ­ ÃºroveÅˆ?
  - NÃ¡klady - sniÅ¾uje pouÅ¾itÃ­ tokenÅ¯ zjednoduÅ¡enÃ­m promptÅ¯?
  - RozÅ¡iÅ™itelnost - lze zÃ¡kladnÃ­ model pouÅ¾Ã­t i pro novÃ© domÃ©ny?

OdpovÄ›Ämi na tyto otÃ¡zky byste mÄ›li bÃ½t schopni rozhodnout, jestli je doladÄ›nÃ­ sprÃ¡vnÃ½ pÅ™Ã­stup pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­. IdeÃ¡lnÄ› je tento pÅ™Ã­stup platnÃ½ pouze tehdy, pokud pÅ™Ã­nosy pÅ™evÃ¡Å¾Ã­ nÃ¡klady. Jakmile se rozhodnete pokraÄovat, je Äas pÅ™emÃ½Å¡let o tom, _jak_ doladit pÅ™edtrÃ©novanÃ½ model.

Chcete zÃ­skat vÃ­ce informacÃ­ o rozhodovacÃ­m procesu? PodÃ­vejte se na [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Jak mÅ¯Å¾eme doladit pÅ™edtrÃ©novanÃ½ model?

K doladÄ›nÃ­ pÅ™edtrÃ©novanÃ©ho modelu potÅ™ebujete:

- pÅ™edtrÃ©novanÃ½ model k doladÄ›nÃ­
- datovou sadu k pouÅ¾itÃ­ pro doladÄ›nÃ­
- trÃ©novacÃ­ prostÅ™edÃ­ pro spuÅ¡tÄ›nÃ­ doladÄ›nÃ­
- hostingovÃ© prostÅ™edÃ­ pro nasazenÃ­ doladÄ›nÃ©ho modelu

## DoladÄ›nÃ­ v praxi

NÃ¡sledujÃ­cÃ­ zdroje poskytujÃ­ podrobnÃ© nÃ¡vody krok za krokem, kterÃ© vÃ¡s provedou skuteÄnÃ½m pÅ™Ã­kladem pouÅ¾itÃ­ vybranÃ©ho modelu s peÄlivÄ› vybranou datovou sadou. Pro prÃ¡ci s tÄ›mito nÃ¡vody potÅ™ebujete ÃºÄet u konkrÃ©tnÃ­ho poskytovatele, spolu s pÅ™Ã­stupem k relevantnÃ­mu modelu a datovÃ½m sadÃ¡m.

| Poskytovatel | NÃ¡vod                                                                                                                                                                       | Popis                                                                                                                                                                                                                                                                                                                                                                                                                             |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Jak doladit chatovacÃ­ modely](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | NauÄte se doladit `gpt-35-turbo` pro konkrÃ©tnÃ­ domÃ©nu (â€asistent receptÅ¯â€œ) pÅ™Ã­pravou trÃ©ninkovÃ½ch dat, spuÅ¡tÄ›nÃ­m doladÄ›nÃ­ a pouÅ¾itÃ­m doladÄ›nÃ©ho modelu pro inference.                                                                                                                                                                                                                                                           |
| Azure OpenAI | [NÃ¡vod na doladÄ›nÃ­ GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst)      | NauÄte se doladit model `gpt-35-turbo-0613` **na Azure** tÃ­m, Å¾e vytvoÅ™Ã­te a nahrajete trÃ©ninkovÃ¡ data, spustÃ­te doladÄ›nÃ­, nasadÃ­te a pouÅ¾ijete novÃ½ model.                                                                                                                                                                                                                                                                        |
| Hugging Face | [DoladÄ›nÃ­ LLM s Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                                     | Tento blogovÃ½ pÅ™Ã­spÄ›vek vÃ¡s provede doladÄ›nÃ­m _otevÅ™enÃ©ho LLM_ (napÅ™. `CodeLlama 7B`) pomocÃ­ knihovny [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) & [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) s otevÅ™enÃ½mi [datasetÅ¯](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ğŸ¤— AutoTrain | [DoladÄ›nÃ­ LLM s AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                                 | AutoTrain (nebo AutoTrain Advanced) je pythonovÃ¡ knihovna vyvinutÃ¡ Hugging Face, kterÃ¡ umoÅ¾Åˆuje doladÄ›nÃ­ pro rÅ¯znÃ© Ãºkoly vÄetnÄ› doladÄ›nÃ­ LLM. AutoTrain je Å™eÅ¡enÃ­ bez kÃ³du a doladÄ›nÃ­ lze provÃ¡dÄ›t ve vaÅ¡em vlastnÃ­m cloudu, na Hugging Face Spaces nebo lokÃ¡lnÄ›. Podporuje webovÃ© GUI, CLI a trÃ©novÃ¡nÃ­ pÅ™es yaml konfiguraÄnÃ­ soubory.                                                                                                            |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
| ğŸ¦¥ Unsloth   | [DoladÄ›nÃ­ LLM s Unsloth](https://github.com/unslothai/unsloth)                                                                                                                | Unsloth je open-source framework, kterÃ½ podporuje doladÄ›nÃ­ LLM a posilovacÃ­ uÄenÃ­ (RL). Unsloth usnadÅˆuje lokÃ¡lnÃ­ trÃ©novÃ¡nÃ­, hodnocenÃ­ a nasazenÃ­ s ready-to-use [notebooky](https://github.com/unslothai/notebooks). Podporuje takÃ© text-to-speech (TTS), BERT a multimodÃ¡lnÃ­ modely. Chcete-li zaÄÃ­t, pÅ™eÄtÄ›te si jejich krok za krokem [PrÅ¯vodce doladÄ›nÃ­m LLM](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                                                            |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                 |
## ZadÃ¡nÃ­

Vyberte si jeden z vÃ½Å¡e uvedenÃ½ch nÃ¡vodÅ¯ a projdÄ›te si jej. _MÅ¯Å¾eme v tomto repozitÃ¡Å™i pÅ™Ã­padnÄ› replikovat verzi tÄ›chto nÃ¡vodÅ¯ jako Jupyter Notebooky pouze pro referenci. Pro aktuÃ¡lnÃ­ verze prosÃ­m pouÅ¾Ã­vejte pÅ™Ã­mo originÃ¡lnÃ­ zdroje_.

## SkvÄ›lÃ¡ prÃ¡ce! PokraÄujte ve svÃ©m vzdÄ›lÃ¡vÃ¡nÃ­.

Po dokonÄenÃ­ tÃ©to lekce navÅ¡tivte naÅ¡i [kolekci Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), abyste pokraÄovali v rozvÃ­jenÃ­ svÃ½ch znalostÃ­ generativnÃ­ AI!

Gratulujeme!! DokonÄili jste zÃ¡vÄ›reÄnou lekci z Å™ady v2 tohoto kurzu! NepÅ™estÃ¡vejte se uÄit a tvoÅ™it. \*\*PodÃ­vejte se na strÃ¡nku [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pro seznam dalÅ¡Ã­ch doporuÄenÃ­ pÅ™Ã­mo k tomuto tÃ©matu.

NaÅ¡e Å™ada lekcÃ­ v1 byla takÃ© aktualizovÃ¡na o dalÅ¡Ã­ zadÃ¡nÃ­ a koncepty. Tak si na chvÃ­li osvÄ›Å¾te svÃ© znalosti â€“ a prosÃ­m [sdÃ­lejte svÃ© otÃ¡zky a zpÄ›tnou vazbu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), abychom mohli tyto lekce pro komunitu vylepÅ¡it.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ProhlÃ¡Å¡enÃ­ o vylouÄenÃ­ odpovÄ›dnosti**:
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). PÅ™estoÅ¾e usilujeme o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho mateÅ™skÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za zÃ¡vaznÃ½ zdroj. Pro kritickÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme odpovÄ›dni za jakÃ©koliv nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© vÃ½klady vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->