<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-07-09T17:48:44+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "cs"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.cs.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# DoladÄ›nÃ­ vaÅ¡eho LLM

PouÅ¾Ã­vÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ pro tvorbu generativnÃ­ch AI aplikacÃ­ pÅ™inÃ¡Å¡Ã­ novÃ© vÃ½zvy. KlÃ­ÄovÃ½m problÃ©mem je zajistit kvalitu odpovÄ›dÃ­ (pÅ™esnost a relevanci) v obsahu generovanÃ©m modelem na zÃ¡kladÄ› uÅ¾ivatelskÃ©ho poÅ¾adavku. V pÅ™edchozÃ­ch lekcÃ­ch jsme probÃ­rali techniky jako prompt engineering a retrieval-augmented generation, kterÃ© se snaÅ¾Ã­ problÃ©m vyÅ™eÅ¡it _Ãºpravou vstupnÃ­ho promptu_ pro existujÃ­cÃ­ model.

V dneÅ¡nÃ­ lekci se zamÄ›Å™Ã­me na tÅ™etÃ­ techniku, **doladÄ›nÃ­ (fine-tuning)**, kterÃ¡ se snaÅ¾Ã­ vÃ½zvu Å™eÅ¡it _pÅ™eÅ¡kolenÃ­m samotnÃ©ho modelu_ s vyuÅ¾itÃ­m dodateÄnÃ½ch dat. PojÄme se podÃ­vat na podrobnosti.

## CÃ­le uÄenÃ­

Tato lekce pÅ™edstavuje koncept doladÄ›nÃ­ pÅ™edtrÃ©novanÃ½ch jazykovÃ½ch modelÅ¯, zkoumÃ¡ vÃ½hody a vÃ½zvy tohoto pÅ™Ã­stupu a poskytuje rady, kdy a jak doladÄ›nÃ­ pouÅ¾Ã­t ke zlepÅ¡enÃ­ vÃ½konu vaÅ¡ich generativnÃ­ch AI modelÅ¯.

Na konci lekce byste mÄ›li bÃ½t schopni odpovÄ›dÄ›t na nÃ¡sledujÃ­cÃ­ otÃ¡zky:

- Co je doladÄ›nÃ­ jazykovÃ½ch modelÅ¯?
- Kdy a proÄ je doladÄ›nÃ­ uÅ¾iteÄnÃ©?
- Jak mohu doladit pÅ™edtrÃ©novanÃ½ model?
- JakÃ¡ jsou omezenÃ­ doladÄ›nÃ­?

Jste pÅ™ipraveni? PojÄme na to.

## IlustrovanÃ½ prÅ¯vodce

Chcete zÃ­skat pÅ™ehled o tom, co budeme probÃ­rat, neÅ¾ se do toho pustÃ­me? PodÃ­vejte se na tento ilustrovanÃ½ prÅ¯vodce, kterÃ½ popisuje vzdÄ›lÃ¡vacÃ­ cestu tÃ©to lekce â€“ od pochopenÃ­ zÃ¡kladnÃ­ch konceptÅ¯ a motivace pro doladÄ›nÃ­ aÅ¾ po porozumÄ›nÃ­ procesu a osvÄ›dÄenÃ½m postupÅ¯m pÅ™i provÃ¡dÄ›nÃ­ doladÄ›nÃ­. Je to fascinujÃ­cÃ­ tÃ©ma k prozkoumÃ¡nÃ­, tak nezapomeÅˆte navÅ¡tÃ­vit strÃ¡nku [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pro dalÅ¡Ã­ odkazy, kterÃ© podpoÅ™Ã­ vaÅ¡e samostatnÃ© uÄenÃ­!

![IlustrovanÃ½ prÅ¯vodce doladÄ›nÃ­m jazykovÃ½ch modelÅ¯](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.cs.png)

## Co je doladÄ›nÃ­ jazykovÃ½ch modelÅ¯?

VelkÃ© jazykovÃ© modely jsou podle definice _pÅ™edtrÃ©novanÃ©_ na velkÃ©m mnoÅ¾stvÃ­ textÅ¯ pochÃ¡zejÃ­cÃ­ch z rÅ¯znÃ½ch zdrojÅ¯ vÄetnÄ› internetu. Jak jsme se nauÄili v pÅ™edchozÃ­ch lekcÃ­ch, potÅ™ebujeme techniky jako _prompt engineering_ a _retrieval-augmented generation_, abychom zlepÅ¡ili kvalitu odpovÄ›dÃ­ modelu na uÅ¾ivatelskÃ© dotazy (â€promptyâ€œ).

OblÃ­benou technikou prompt engineeringu je poskytnout modelu vÃ­ce vodÃ­tek, co se od odpovÄ›di oÄekÃ¡vÃ¡, buÄ formou _instrukcÃ­_ (explicitnÃ­ vedenÃ­), nebo _pÅ™edloÅ¾enÃ­m nÄ›kolika pÅ™Ã­kladÅ¯_ (implicitnÃ­ vedenÃ­). Tomu se Å™Ã­kÃ¡ _few-shot learning_, ale mÃ¡ to dvÄ› omezenÃ­:

- Limity poÄtu tokenÅ¯ modelu omezujÃ­ poÄet pÅ™Ã­kladÅ¯, kterÃ© mÅ¯Å¾ete zadat, a tÃ­m i efektivitu.
- NÃ¡klady na tokeny modelu mohou bÃ½t vysokÃ©, pokud pÅ™idÃ¡vÃ¡te pÅ™Ã­klady ke kaÅ¾dÃ©mu promptu, coÅ¾ omezuje flexibilitu.

DoladÄ›nÃ­ je bÄ›Å¾nÃ¡ praxe v systÃ©mech strojovÃ©ho uÄenÃ­, kdy vezmeme pÅ™edtrÃ©novanÃ½ model a pÅ™eÅ¡kolÃ­me ho na novÃ½ch datech, abychom zlepÅ¡ili jeho vÃ½kon pro konkrÃ©tnÃ­ Ãºkol. V kontextu jazykovÃ½ch modelÅ¯ mÅ¯Å¾eme doladit pÅ™edtrÃ©novanÃ½ model _pomocÃ­ peÄlivÄ› vybranÃ½ch pÅ™Ã­kladÅ¯ pro danÃ½ Ãºkol nebo oblast pouÅ¾itÃ­_, ÄÃ­mÅ¾ vytvoÅ™Ã­me **vlastnÃ­ model**, kterÃ½ mÅ¯Å¾e bÃ½t pÅ™esnÄ›jÅ¡Ã­ a relevantnÄ›jÅ¡Ã­ pro danÃ½ Ãºkol nebo domÃ©nu. VedlejÅ¡Ã­m pÅ™Ã­nosem doladÄ›nÃ­ je, Å¾e mÅ¯Å¾e takÃ© snÃ­Å¾it poÄet pÅ™Ã­kladÅ¯ potÅ™ebnÃ½ch pro few-shot learning â€“ coÅ¾ sniÅ¾uje spotÅ™ebu tokenÅ¯ a souvisejÃ­cÃ­ nÃ¡klady.

## Kdy a proÄ bychom mÄ›li modely doladit?

V _tomto_ kontextu, kdyÅ¾ mluvÃ­me o doladÄ›nÃ­, mÃ¡me na mysli **supervidovanÃ©** doladÄ›nÃ­, kdy se pÅ™eÅ¡kolenÃ­ provÃ¡dÃ­ **pÅ™idÃ¡nÃ­m novÃ½ch dat**, kterÃ¡ nebyla souÄÃ¡stÃ­ pÅ¯vodnÃ­ho trÃ©ninkovÃ©ho datasetu. To se liÅ¡Ã­ od nesupervidovanÃ©ho doladÄ›nÃ­, kdy je model pÅ™eÅ¡kolen na pÅ¯vodnÃ­ch datech, ale s jinÃ½mi hyperparametry.

KlÃ­ÄovÃ© je si uvÄ›domit, Å¾e doladÄ›nÃ­ je pokroÄilÃ¡ technika, kterÃ¡ vyÅ¾aduje urÄitou ÃºroveÅˆ odbornosti, aby pÅ™inesla poÅ¾adovanÃ© vÃ½sledky. Pokud je provedena nesprÃ¡vnÄ›, nemusÃ­ pÅ™inÃ©st oÄekÃ¡vanÃ© zlepÅ¡enÃ­ a mÅ¯Å¾e dokonce zhorÅ¡it vÃ½kon modelu pro vaÅ¡i cÃ­lovou domÃ©nu.

NeÅ¾ se tedy nauÄÃ­te â€jakâ€œ doladit jazykovÃ© modely, musÃ­te vÄ›dÄ›t â€proÄâ€œ byste mÄ›li touto cestou jÃ­t a â€kdyâ€œ zaÄÃ­t proces doladÄ›nÃ­. ZaÄnÄ›te tÃ­m, Å¾e si poloÅ¾Ã­te tyto otÃ¡zky:

- **PÅ™Ã­pad pouÅ¾itÃ­**: JakÃ½ je vÃ¡Å¡ _pÅ™Ã­pad pouÅ¾itÃ­_ pro doladÄ›nÃ­? KterÃ½ aspekt souÄasnÃ©ho pÅ™edtrÃ©novanÃ©ho modelu chcete zlepÅ¡it?
- **Alternativy**: ZkouÅ¡eli jste _jinÃ© techniky_ k dosaÅ¾enÃ­ poÅ¾adovanÃ½ch vÃ½sledkÅ¯? PouÅ¾ijte je jako zÃ¡klad pro srovnÃ¡nÃ­.
  - Prompt engineering: VyzkouÅ¡ejte techniky jako few-shot prompting s pÅ™Ã­klady relevantnÃ­ch odpovÄ›dÃ­. ZhodnoÅ¥te kvalitu odpovÄ›dÃ­.
  - Retrieval Augmented Generation: Zkuste doplnit prompty o vÃ½sledky dotazÅ¯ zÃ­skanÃ© vyhledÃ¡vÃ¡nÃ­m ve vaÅ¡ich datech. ZhodnoÅ¥te kvalitu odpovÄ›dÃ­.
- **NÃ¡klady**: Identifikovali jste nÃ¡klady spojenÃ© s doladÄ›nÃ­m?
  - MoÅ¾nost ladÄ›nÃ­ â€“ je pÅ™edtrÃ©novanÃ½ model dostupnÃ½ pro doladÄ›nÃ­?
  - ÃšsilÃ­ â€“ pÅ™Ã­prava trÃ©ninkovÃ½ch dat, vyhodnocenÃ­ a ladÄ›nÃ­ modelu.
  - VÃ½poÄetnÃ­ zdroje â€“ pro spuÅ¡tÄ›nÃ­ doladÄ›nÃ­ a nasazenÃ­ doladÄ›nÃ©ho modelu.
  - Data â€“ pÅ™Ã­stup k dostateÄnÄ› kvalitnÃ­m pÅ™Ã­kladÅ¯m pro efektivnÃ­ doladÄ›nÃ­.
- **PÅ™Ã­nosy**: Potvrdili jste pÅ™Ã­nosy doladÄ›nÃ­?
  - Kvalita â€“ pÅ™ekonal doladÄ›nÃ½ model zÃ¡kladnÃ­ verzi?
  - NÃ¡klady â€“ sniÅ¾uje spotÅ™ebu tokenÅ¯ dÃ­ky zjednoduÅ¡enÃ­ promptÅ¯?
  - RozÅ¡iÅ™itelnost â€“ lze zÃ¡kladnÃ­ model znovu pouÅ¾Ã­t pro novÃ© domÃ©ny?

OdpovÄ›dÃ­ na tyto otÃ¡zky byste mÄ›li bÃ½t schopni rozhodnout, zda je doladÄ›nÃ­ sprÃ¡vnÃ½ pÅ™Ã­stup pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­. IdeÃ¡lnÄ› je tento pÅ™Ã­stup vhodnÃ½ pouze tehdy, pokud pÅ™Ã­nosy pÅ™evÃ¡Å¾Ã­ nÃ¡klady. Jakmile se rozhodnete pokraÄovat, je Äas pÅ™emÃ½Å¡let o tom, _jak_ mÅ¯Å¾ete doladit pÅ™edtrÃ©novanÃ½ model.

Chcete zÃ­skat vÃ­ce informacÃ­ o rozhodovacÃ­m procesu? PodÃ­vejte se na [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Jak mÅ¯Å¾eme doladit pÅ™edtrÃ©novanÃ½ model?

Pro doladÄ›nÃ­ pÅ™edtrÃ©novanÃ©ho modelu potÅ™ebujete:

- pÅ™edtrÃ©novanÃ½ model k doladÄ›nÃ­
- dataset pro doladÄ›nÃ­
- trÃ©ninkovÃ© prostÅ™edÃ­ pro spuÅ¡tÄ›nÃ­ doladÄ›nÃ­
- hostingovÃ© prostÅ™edÃ­ pro nasazenÃ­ doladÄ›nÃ©ho modelu

## DoladÄ›nÃ­ v praxi

NÃ¡sledujÃ­cÃ­ zdroje poskytujÃ­ krok za krokem nÃ¡vody, kterÃ© vÃ¡s provedou reÃ¡lnÃ½m pÅ™Ã­kladem pouÅ¾itÃ­ vybranÃ©ho modelu s peÄlivÄ› vybranÃ½m datasetem. Pro prÃ¡ci s tÄ›mito nÃ¡vody potÅ™ebujete ÃºÄet u konkrÃ©tnÃ­ho poskytovatele a pÅ™Ã­stup k relevantnÃ­m modelÅ¯m a datasetÅ¯m.

| Poskytovatel | NÃ¡vod                                                                                                                                                                         | Popis                                                                                                                                                                                                                                                                                                                                                                                                                            |
| ------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Jak doladit chatovacÃ­ modely](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)              | NauÄte se doladit `gpt-35-turbo` pro konkrÃ©tnÃ­ domÃ©nu (â€asistent pro receptyâ€œ) pÅ™Ã­pravou trÃ©ninkovÃ½ch dat, spuÅ¡tÄ›nÃ­m doladÄ›nÃ­ a pouÅ¾itÃ­m doladÄ›nÃ©ho modelu pro inferenci.                                                                                                                                                                                                                                                      |
| Azure OpenAI | [NÃ¡vod na doladÄ›nÃ­ GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst)     | NauÄte se doladit model `gpt-35-turbo-0613` **na Azure** krok za krokem â€“ vytvoÅ™enÃ­ a nahrÃ¡nÃ­ trÃ©ninkovÃ½ch dat, spuÅ¡tÄ›nÃ­ doladÄ›nÃ­, nasazenÃ­ a pouÅ¾itÃ­ novÃ©ho modelu.                                                                                                                                                                                                                                                             |
| Hugging Face | [DoladÄ›nÃ­ LLM s Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                                     | Tento blogovÃ½ pÅ™Ã­spÄ›vek vÃ¡s provede doladÄ›nÃ­m _otevÅ™enÃ©ho LLM_ (napÅ™. `CodeLlama 7B`) pomocÃ­ knihovny [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) s otevÅ™enÃ½mi [dataset](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ğŸ¤— AutoTrain | [DoladÄ›nÃ­ LLM s AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                               | AutoTrain (nebo AutoTrain Advanced) je python knihovna vyvinutÃ¡ Hugging Face, kterÃ¡ umoÅ¾Åˆuje doladÄ›nÃ­ pro rÅ¯znÃ© Ãºkoly vÄetnÄ› doladÄ›nÃ­ LLM. AutoTrain je Å™eÅ¡enÃ­ bez nutnosti kÃ³dovÃ¡nÃ­ a doladÄ›nÃ­ lze provÃ¡dÄ›t ve vaÅ¡em vlastnÃ­m cloudu, na Hugging Face Spaces nebo lokÃ¡lnÄ›. Podporuje webovÃ© GUI, CLI i trÃ©nink pÅ™es yaml konfiguraÄnÃ­ soubory.                                                                                     |
|              |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                  |

## ZadÃ¡nÃ­

Vyberte si jeden z vÃ½Å¡e uvedenÃ½ch nÃ¡vodÅ¯ a projdÄ›te si ho krok za krokem. _MÅ¯Å¾eme vytvoÅ™it verzi tÄ›chto nÃ¡vodÅ¯ v Jupyter NoteboocÃ­ch v tomto repozitÃ¡Å™i pouze pro referenci. Pro nejnovÄ›jÅ¡Ã­ verze prosÃ­m pouÅ¾Ã­vejte pÅ™Ã­mo originÃ¡lnÃ­ zdroje_.

## SkvÄ›lÃ¡ prÃ¡ce! PokraÄujte ve svÃ©m vzdÄ›lÃ¡vÃ¡nÃ­.

Po dokonÄenÃ­ tÃ©to lekce se podÃ­vejte na naÅ¡i [kolekci Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), kde mÅ¯Å¾ete dÃ¡le rozÅ¡iÅ™ovat svÃ© znalosti o generativnÃ­ AI!

Gratulujeme!! DokonÄili jste zÃ¡vÄ›reÄnou lekci z verze 2 tohoto kurzu! NepÅ™estÃ¡vejte se uÄit a tvoÅ™it. \*\*NavÅ¡tivte strÃ¡nku [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pro seznam dalÅ¡Ã­ch doporuÄenÃ­ prÃ¡vÄ› k tomuto tÃ©matu.

NaÅ¡e sÃ©rie lekcÃ­ verze 1 byla takÃ© aktualizovÃ¡na o dalÅ¡Ã­ Ãºkoly a koncepty. VÄ›nujte chvÃ­li osvÄ›Å¾enÃ­ svÃ½ch znalostÃ­ â€“ a prosÃ­m [sdÃ­lejte svÃ© otÃ¡zky a zpÄ›tnou vazbu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), abychom mohli tyto lekce pro komunitu dÃ¡le zlepÅ¡ovat.

**ProhlÃ¡Å¡enÃ­ o vylouÄenÃ­ odpovÄ›dnosti**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ usilujeme o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho mateÅ™skÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za zÃ¡vaznÃ½ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme odpovÄ›dnÃ­ za jakÃ©koliv nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© vÃ½klady vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.