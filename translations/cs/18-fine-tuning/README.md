<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "807f0d9fc1747e796433534e1be6a98a",
  "translation_date": "2025-10-17T21:41:42+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "cs"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.f30176815b1a5074fce9cceba317720586caa99e24001231a92fd04eeb54a121.cs.png)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# DoladÄ›nÃ­ vaÅ¡eho LLM

PouÅ¾Ã­vÃ¡nÃ­ velkÃ½ch jazykovÃ½ch modelÅ¯ k vytvÃ¡Å™enÃ­ aplikacÃ­ generativnÃ­ AI pÅ™inÃ¡Å¡Ã­ novÃ© vÃ½zvy. KlÃ­ÄovÃ½m problÃ©mem je zajiÅ¡tÄ›nÃ­ kvality odpovÄ›dÃ­ (pÅ™esnosti a relevance) v obsahu generovanÃ©m modelem na zÃ¡kladÄ› konkrÃ©tnÃ­ho poÅ¾adavku uÅ¾ivatele. V pÅ™edchozÃ­ch lekcÃ­ch jsme diskutovali o technikÃ¡ch, jako je nÃ¡vrh promptÅ¯ a generovÃ¡nÃ­ obohacenÃ© o vyhledÃ¡vÃ¡nÃ­, kterÃ© se snaÅ¾Ã­ tento problÃ©m Å™eÅ¡it _Ãºpravou vstupnÃ­ho promptu_ existujÃ­cÃ­ho modelu.

V dneÅ¡nÃ­ lekci se zamÄ›Å™Ã­me na tÅ™etÃ­ techniku, **doladÄ›nÃ­**, kterÃ¡ se snaÅ¾Ã­ tento problÃ©m Å™eÅ¡it _pÅ™eÅ¡kolenÃ­m samotnÃ©ho modelu_ pomocÃ­ dodateÄnÃ½ch dat. PojÄme se ponoÅ™it do podrobnostÃ­.

## CÃ­le uÄenÃ­

Tato lekce pÅ™edstavuje koncept doladÄ›nÃ­ pÅ™edtrÃ©novanÃ½ch jazykovÃ½ch modelÅ¯, zkoumÃ¡ vÃ½hody a vÃ½zvy tohoto pÅ™Ã­stupu a poskytuje nÃ¡vod, kdy a jak pouÅ¾Ã­t doladÄ›nÃ­ ke zlepÅ¡enÃ­ vÃ½konu vaÅ¡ich generativnÃ­ch AI modelÅ¯.

Na konci tÃ©to lekce byste mÄ›li bÃ½t schopni odpovÄ›dÄ›t na nÃ¡sledujÃ­cÃ­ otÃ¡zky:

- Co je doladÄ›nÃ­ jazykovÃ½ch modelÅ¯?
- Kdy a proÄ je doladÄ›nÃ­ uÅ¾iteÄnÃ©?
- Jak mohu doladit pÅ™edtrÃ©novanÃ½ model?
- JakÃ© jsou omezenÃ­ doladÄ›nÃ­?

PÅ™ipraveni? PojÄme zaÄÃ­t.

## IlustrovanÃ½ prÅ¯vodce

Chcete zÃ­skat celkovÃ½ pÅ™ehled o tom, co budeme probÃ­rat, neÅ¾ se ponoÅ™Ã­me do detailÅ¯? PodÃ­vejte se na tento ilustrovanÃ½ prÅ¯vodce, kterÃ½ popisuje vzdÄ›lÃ¡vacÃ­ cestu tÃ©to lekce - od pochopenÃ­ zÃ¡kladnÃ­ch konceptÅ¯ a motivace pro doladÄ›nÃ­ aÅ¾ po porozumÄ›nÃ­ procesu a osvÄ›dÄenÃ½m postupÅ¯m pro provedenÃ­ Ãºkolu doladÄ›nÃ­. Toto je fascinujÃ­cÃ­ tÃ©ma k prozkoumÃ¡nÃ­, takÅ¾e nezapomeÅˆte navÅ¡tÃ­vit strÃ¡nku [Resources](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) pro dalÅ¡Ã­ odkazy, kterÃ© podpoÅ™Ã­ vaÅ¡i samostatnou vzdÄ›lÃ¡vacÃ­ cestu!

![IlustrovanÃ½ prÅ¯vodce doladÄ›nÃ­m jazykovÃ½ch modelÅ¯](../../../translated_images/18-fine-tuning-sketchnote.11b21f9ec8a703467a120cb79a28b5ac1effc8d8d9d5b31bbbac6b8640432e14.cs.png)

## Co je doladÄ›nÃ­ jazykovÃ½ch modelÅ¯?

VelkÃ© jazykovÃ© modely jsou podle definice _pÅ™edtrÃ©novanÃ©_ na velkÃ©m mnoÅ¾stvÃ­ textÅ¯ pochÃ¡zejÃ­cÃ­ch z rÅ¯znÃ½ch zdrojÅ¯, vÄetnÄ› internetu. Jak jsme se nauÄili v pÅ™edchozÃ­ch lekcÃ­ch, potÅ™ebujeme techniky jako _nÃ¡vrh promptÅ¯_ a _generovÃ¡nÃ­ obohacenÃ© o vyhledÃ¡vÃ¡nÃ­_, abychom zlepÅ¡ili kvalitu odpovÄ›dÃ­ modelu na otÃ¡zky uÅ¾ivatele ("prompty").

OblÃ­benou technikou nÃ¡vrhu promptÅ¯ je poskytnutÃ­ modelu vÃ­ce pokynÅ¯, co se od nÄ›j oÄekÃ¡vÃ¡ v odpovÄ›di, buÄ _instrukcemi_ (explicitnÃ­ pokyny), nebo _nÄ›kolika pÅ™Ã­klady_ (implicitnÃ­ pokyny). Tomu se Å™Ã­kÃ¡ _few-shot learning_, ale mÃ¡ dvÄ› omezenÃ­:

- OmezenÃ­ poÄtu tokenÅ¯ modelu mÅ¯Å¾e omezit poÄet pÅ™Ã­kladÅ¯, kterÃ© mÅ¯Å¾ete poskytnout, a tÃ­m i ÃºÄinnost.
- NÃ¡klady na tokeny modelu mohou bÃ½t vysokÃ©, pokud pÅ™idÃ¡vÃ¡te pÅ™Ã­klady ke kaÅ¾dÃ©mu promptu, coÅ¾ omezuje flexibilitu.

DoladÄ›nÃ­ je bÄ›Å¾nÃ¡ praxe v systÃ©mech strojovÃ©ho uÄenÃ­, kdy vezmeme pÅ™edtrÃ©novanÃ½ model a pÅ™eÅ¡kolÃ­me ho s novÃ½mi daty, abychom zlepÅ¡ili jeho vÃ½kon na konkrÃ©tnÃ­m Ãºkolu. V kontextu jazykovÃ½ch modelÅ¯ mÅ¯Å¾eme doladit pÅ™edtrÃ©novanÃ½ model _s peÄlivÄ› vybranou sadou pÅ™Ã­kladÅ¯ pro danÃ½ Ãºkol nebo aplikaÄnÃ­ domÃ©nu_, abychom vytvoÅ™ili **vlastnÃ­ model**, kterÃ½ mÅ¯Å¾e bÃ½t pÅ™esnÄ›jÅ¡Ã­ a relevantnÄ›jÅ¡Ã­ pro danÃ½ Ãºkol nebo domÃ©nu. VedlejÅ¡Ã­m pÅ™Ã­nosem doladÄ›nÃ­ je, Å¾e mÅ¯Å¾e takÃ© snÃ­Å¾it poÄet pÅ™Ã­kladÅ¯ potÅ™ebnÃ½ch pro few-shot learning - ÄÃ­mÅ¾ se sniÅ¾uje vyuÅ¾itÃ­ tokenÅ¯ a souvisejÃ­cÃ­ nÃ¡klady.

## Kdy a proÄ bychom mÄ›li doladit modely?

V _tomto_ kontextu, kdyÅ¾ mluvÃ­me o doladÄ›nÃ­, mÃ¡me na mysli **supervizovanÃ©** doladÄ›nÃ­, kdy se pÅ™eÅ¡kolenÃ­ provÃ¡dÃ­ **pÅ™idÃ¡nÃ­m novÃ½ch dat**, kterÃ¡ nebyla souÄÃ¡stÃ­ pÅ¯vodnÃ­ho trÃ©ninkovÃ©ho datasetu. To se liÅ¡Ã­ od nesupervizovanÃ©ho doladÄ›nÃ­, kdy je model pÅ™eÅ¡kolen na pÅ¯vodnÃ­ch datech, ale s rÅ¯znÃ½mi hyperparametry.

KlÃ­ÄovÃ© je si uvÄ›domit, Å¾e doladÄ›nÃ­ je pokroÄilÃ¡ technika, kterÃ¡ vyÅ¾aduje urÄitou ÃºroveÅˆ odbornosti, aby bylo dosaÅ¾eno poÅ¾adovanÃ½ch vÃ½sledkÅ¯. Pokud je provedeno nesprÃ¡vnÄ›, nemusÃ­ pÅ™inÃ©st oÄekÃ¡vanÃ¡ zlepÅ¡enÃ­ a mÅ¯Å¾e dokonce zhorÅ¡it vÃ½kon modelu pro vaÅ¡i cÃ­lovou domÃ©nu.

NeÅ¾ se tedy nauÄÃ­te "jak" doladit jazykovÃ© modely, musÃ­te vÄ›dÄ›t "proÄ" byste mÄ›li tuto cestu zvolit a "kdy" zaÄÃ­t proces doladÄ›nÃ­. ZaÄnÄ›te tÃ­m, Å¾e si poloÅ¾Ã­te tyto otÃ¡zky:

- **PouÅ¾itÃ­**: JakÃ½ je vÃ¡Å¡ _pÅ™Ã­pad pouÅ¾itÃ­_ pro doladÄ›nÃ­? JakÃ½ aspekt aktuÃ¡lnÃ­ho pÅ™edtrÃ©novanÃ©ho modelu chcete zlepÅ¡it?
- **Alternativy**: VyzkouÅ¡eli jste _jinÃ© techniky_, abyste dosÃ¡hli poÅ¾adovanÃ½ch vÃ½sledkÅ¯? PouÅ¾ijte je k vytvoÅ™enÃ­ zÃ¡kladnÃ­ho srovnÃ¡nÃ­.
  - NÃ¡vrh promptÅ¯: VyzkouÅ¡ejte techniky jako few-shot prompting s pÅ™Ã­klady relevantnÃ­ch odpovÄ›dÃ­ na prompty. ZhodnoÅ¥te kvalitu odpovÄ›dÃ­.
  - GenerovÃ¡nÃ­ obohacenÃ© o vyhledÃ¡vÃ¡nÃ­: Zkuste obohatit prompty o vÃ½sledky vyhledÃ¡vÃ¡nÃ­ ve vaÅ¡ich datech. ZhodnoÅ¥te kvalitu odpovÄ›dÃ­.
- **NÃ¡klady**: Identifikovali jste nÃ¡klady na doladÄ›nÃ­?
  - MoÅ¾nost doladÄ›nÃ­ - je pÅ™edtrÃ©novanÃ½ model dostupnÃ½ pro doladÄ›nÃ­?
  - ÃšsilÃ­ - pÅ™Ã­prava trÃ©ninkovÃ½ch dat, hodnocenÃ­ a zdokonalovÃ¡nÃ­ modelu.
  - VÃ½poÄetnÃ­ vÃ½kon - spuÅ¡tÄ›nÃ­ Ãºloh doladÄ›nÃ­ a nasazenÃ­ doladÄ›nÃ©ho modelu.
  - Data - pÅ™Ã­stup k dostateÄnÃ©mu mnoÅ¾stvÃ­ kvalitnÃ­ch pÅ™Ã­kladÅ¯ pro dopad doladÄ›nÃ­.
- **PÅ™Ã­nosy**: Potvrdili jste pÅ™Ã­nosy doladÄ›nÃ­?
  - Kvalita - pÅ™ekonal doladÄ›nÃ½ model zÃ¡kladnÃ­ srovnÃ¡nÃ­?
  - NÃ¡klady - sniÅ¾uje vyuÅ¾itÃ­ tokenÅ¯ zjednoduÅ¡enÃ­m promptÅ¯?
  - RozÅ¡iÅ™itelnost - lze zÃ¡kladnÃ­ model pÅ™izpÅ¯sobit novÃ½m domÃ©nÃ¡m?

OdpovÄ›dÃ­ na tyto otÃ¡zky byste mÄ›li bÃ½t schopni rozhodnout, zda je doladÄ›nÃ­ sprÃ¡vnÃ½m pÅ™Ã­stupem pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­. IdeÃ¡lnÄ› je tento pÅ™Ã­stup platnÃ½ pouze tehdy, pokud pÅ™Ã­nosy pÅ™evyÅ¡ujÃ­ nÃ¡klady. Jakmile se rozhodnete pokraÄovat, je Äas pÅ™emÃ½Å¡let o _tom, jak_ mÅ¯Å¾ete doladit pÅ™edtrÃ©novanÃ½ model.

Chcete zÃ­skat vÃ­ce informacÃ­ o rozhodovacÃ­m procesu? PodÃ­vejte se na [Doladit nebo nedoladit](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Jak mÅ¯Å¾eme doladit pÅ™edtrÃ©novanÃ½ model?

K doladÄ›nÃ­ pÅ™edtrÃ©novanÃ©ho modelu potÅ™ebujete:

- pÅ™edtrÃ©novanÃ½ model k doladÄ›nÃ­
- dataset pro doladÄ›nÃ­
- trÃ©ninkovÃ© prostÅ™edÃ­ pro spuÅ¡tÄ›nÃ­ Ãºlohy doladÄ›nÃ­
- hostingovÃ© prostÅ™edÃ­ pro nasazenÃ­ doladÄ›nÃ©ho modelu

## DoladÄ›nÃ­ v praxi

NÃ¡sledujÃ­cÃ­ zdroje poskytujÃ­ podrobnÃ© nÃ¡vody, kterÃ© vÃ¡s provedou skuteÄnÃ½m pÅ™Ã­kladem pouÅ¾itÃ­ vybranÃ©ho modelu s peÄlivÄ› vybranÃ½m datasetem. Pro prÃ¡ci s tÄ›mito nÃ¡vody potÅ™ebujete ÃºÄet u konkrÃ©tnÃ­ho poskytovatele spolu s pÅ™Ã­stupem k relevantnÃ­mu modelu a datasetÅ¯m.

| Poskytovatel | NÃ¡vod                                                                                                                                                                       | Popis                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Jak doladit chatovacÃ­ modely](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)             | NauÄte se doladit `gpt-35-turbo` pro konkrÃ©tnÃ­ domÃ©nu ("asistent pro recepty") pÅ™Ã­pravou trÃ©ninkovÃ½ch dat, spuÅ¡tÄ›nÃ­m Ãºlohy doladÄ›nÃ­ a pouÅ¾itÃ­m doladÄ›nÃ©ho modelu pro inferenci.                                                                                                                                                                                                                                              |
| Azure OpenAI | [NÃ¡vod na doladÄ›nÃ­ GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | NauÄte se doladit model `gpt-35-turbo-0613` **na Azure** provedenÃ­m krokÅ¯ k vytvoÅ™enÃ­ a nahrÃ¡nÃ­ trÃ©ninkovÃ½ch dat, spuÅ¡tÄ›nÃ­ Ãºlohy doladÄ›nÃ­. NasazenÃ­ a pouÅ¾itÃ­ novÃ©ho modelu.                                                                                                                                                                                                                                                                 |
| Hugging Face | [DoladÄ›nÃ­ LLM pomocÃ­ Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Tento blogovÃ½ pÅ™Ã­spÄ›vek vÃ¡s provede doladÄ›nÃ­m _otevÅ™enÃ©ho LLM_ (napÅ™. `CodeLlama 7B`) pomocÃ­ knihovny [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) a [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) s otevÅ™enÃ½mi [datovÃ½mi sadami](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ğŸ¤— AutoTrain | [DoladÄ›nÃ­ LLM pomocÃ­ AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (nebo AutoTrain Advanced) je pythonovÃ¡ knihovna vyvinutÃ¡ spoleÄnostÃ­ Hugging Face, kterÃ¡ umoÅ¾Åˆuje doladÄ›nÃ­ pro mnoho rÅ¯znÃ½ch ÃºkolÅ¯ vÄetnÄ› doladÄ›nÃ­ LLM. AutoTrain je Å™eÅ¡enÃ­ bez nutnosti kÃ³dovÃ¡nÃ­ a doladÄ›nÃ­ lze provÃ©st ve vaÅ¡em vlastnÃ­m cloudu, na Hugging Face Spaces nebo lokÃ¡lnÄ›. Podporuje jak webovÃ© GUI, tak CLI a trÃ©nink prostÅ™ednictvÃ­m yaml konfiguraÄnÃ­ch souborÅ¯.                                                                               |
|              |                                                                                                                                                                             |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Ãškol

Vyberte si jeden z vÃ½Å¡e uvedenÃ½ch nÃ¡vodÅ¯ a projdÄ›te si ho. _MÅ¯Å¾eme vytvoÅ™it verzi tÄ›chto nÃ¡vodÅ¯ v Jupyter Notebooks v tomto repozitÃ¡Å™i pouze pro referenci. PouÅ¾ijte prosÃ­m pÅ™Ã­mo pÅ¯vodnÃ­ zdroje, abyste zÃ­skali nejnovÄ›jÅ¡Ã­ verze_.

## SkvÄ›lÃ¡ prÃ¡ce! PokraÄujte ve svÃ©m vzdÄ›lÃ¡vÃ¡nÃ­.

Po dokonÄenÃ­ tÃ©to lekce se podÃ­vejte na naÅ¡i [kolekci uÄenÃ­ o generativnÃ­ AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), abyste pokraÄovali ve zvyÅ¡ovÃ¡nÃ­ svÃ½ch znalostÃ­ o generativnÃ­ AI!

Gratulujeme!! DokonÄili jste poslednÃ­ lekci ze sÃ©rie v2 tohoto kurzu! NepÅ™estÃ¡vejte se uÄit a tvoÅ™it. \*\*PodÃ­vejte se na strÃ¡nku [RESOURCES](RESOURCES.md?WT.mc_id=academic-105485-koreyst) pro seznam dalÅ¡Ã­ch nÃ¡vrhÅ¯ prÃ¡vÄ› k tomuto tÃ©matu.

NaÅ¡e sÃ©rie lekcÃ­ v1 byla takÃ© aktualizovÃ¡na o dalÅ¡Ã­ Ãºkoly a koncepty. TakÅ¾e si udÄ›lejte chvÃ­li na osvÄ›Å¾enÃ­ svÃ½ch znalostÃ­ - a prosÃ­m [sdÃ­lejte svÃ© otÃ¡zky a zpÄ›tnou vazbu](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), abyste nÃ¡m pomohli tyto lekce pro komunitu zlepÅ¡it.

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by AI pro pÅ™eklady [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho rodnÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.