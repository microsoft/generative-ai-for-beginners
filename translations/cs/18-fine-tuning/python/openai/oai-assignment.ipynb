{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jemné ladění modelů Open AI\n",
    "\n",
    "Tento notebook vychází z aktuálních doporučení uvedených v dokumentaci [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) od Open AI.\n",
    "\n",
    "Jemné ladění zlepšuje výkon základních modelů pro vaši aplikaci tím, že je znovu trénuje s dalšími daty a kontextem, které jsou relevantní pro konkrétní použití nebo scénář. Mějte na paměti, že techniky jako _few shot learning_ a _retrieval augmented generation_ umožňují vylepšit výchozí prompt o relevantní data a tím zvýšit kvalitu. Tyto přístupy jsou však omezeny maximální velikostí tokenového okna daného základního modelu.\n",
    "\n",
    "Při jemném ladění vlastně znovu trénujeme samotný model s potřebnými daty (což nám umožňuje použít mnohem více příkladů, než kolik se vejde do maximálního tokenového okna) – a nasazujeme _vlastní_ verzi modelu, která už při vyhodnocování nepotřebuje příklady. To nejen zvyšuje efektivitu návrhu promptu (máme větší volnost v tom, jak tokenové okno využít), ale může také snížit náklady (protože při vyhodnocování posíláme modelu méně tokenů).\n",
    "\n",
    "Jemné ladění má 4 kroky:\n",
    "1. Připravte trénovací data a nahrajte je.\n",
    "1. Spusťte trénovací úlohu a získejte jemně doladěný model.\n",
    "1. Ověřte kvalitu jemně doladěného modelu a případně upravte.\n",
    "1. Nasazujte jemně doladěný model pro vyhodnocování, když jste spokojeni.\n",
    "\n",
    "Ne všechny základní modely podporují jemné ladění – [zkontrolujte dokumentaci OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) pro nejnovější informace. Jemně doladit můžete i model, který už byl jemně doladěn dříve. V tomto tutoriálu použijeme jako cílový základní model pro jemné ladění `gpt-35-turbo`.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 1.1: Připravte si svůj dataset\n",
    "\n",
    "Pojďme vytvořit chatbot, který vám pomůže pochopit periodickou tabulku prvků tím, že bude odpovídat na otázky o prvku pomocí limeriku. V _tomto_ jednoduchém návodu jen vytvoříme dataset pro trénování modelu s několika ukázkovými příklady odpovědí, které ukazují očekávaný formát dat. V reálném použití byste potřebovali vytvořit dataset s mnohem více příklady. Můžete také využít otevřený dataset (pro vaši oblast použití), pokud existuje, a upravit ho pro použití při doladění.\n",
    "\n",
    "Protože se zaměřujeme na `gpt-35-turbo` a chceme jednorázovou odpověď (chat completion), můžeme vytvořit příklady podle [tohoto doporučeného formátu](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), který odpovídá požadavkům OpenAI na chat completion. Pokud očekáváte konverzaci na více tahů, použijete [formát pro více tahů](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), který obsahuje parametr `weight` pro určení, které zprávy mají být použity (nebo ne) při doladění.\n",
    "\n",
    "Pro náš návod použijeme jednodušší formát pro jeden tah. Data jsou ve [formátu jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) s jedním záznamem na řádek, každý je reprezentován jako objekt ve formátu JSON. Ukázka níže ukazuje 2 záznamy jako příklad – kompletní vzorovou sadu (10 příkladů), kterou použijeme pro náš tutoriál doladění, najdete v [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl). **Poznámka:** Každý záznam _musí_ být definován na jednom řádku (nesmí být rozdělený na více řádků jako je běžné u formátovaného JSON souboru)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "V reálném použití budete potřebovat mnohem větší sadu příkladů pro dobré výsledky – je to kompromis mezi kvalitou odpovědí a časem/náklady na doladění. My používáme malou sadu, abychom mohli doladění rychle dokončit a ukázat postup. Podívejte se na [tento příklad v OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) pro složitější návod na doladění.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 1.2 Nahrajte svůj dataset\n",
    "\n",
    "Nahrajte data pomocí Files API [jak je popsáno zde](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Upozorňujeme, že abyste mohli tento kód spustit, musíte nejprve provést následující kroky:\n",
    " - Nainstalovat Python balíček `openai` (ujistěte se, že používáte verzi >=0.28.0 kvůli nejnovějším funkcím)\n",
    " - Nastavit proměnnou prostředí `OPENAI_API_KEY` na váš OpenAI API klíč\n",
    "Více informací najdete v [průvodci nastavením](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), který je součástí kurzu.\n",
    "\n",
    "Nyní spusťte kód, který vytvoří soubor pro nahrání z vašeho lokálního JSONL souboru.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 2.1: Vytvoření úlohy pro doladění pomocí SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 2.2: Zkontrolujte stav úlohy\n",
    "\n",
    "Zde je několik věcí, které můžete dělat pomocí API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` – Vypíše posledních n úloh pro doladění\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` – Získá podrobnosti o konkrétní úloze pro doladění\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` – Zruší úlohu pro doladění\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` – Vypíše až n událostí z dané úlohy\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Prvním krokem tohoto procesu je _ověření trénovacího souboru_, abyste se ujistili, že data mají správný formát.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 2.3: Sledujte události pro monitorování postupu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 2.4: Zobrazit stav v OpenAI Dashboard\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stav můžete také zobrazit na webových stránkách OpenAI v sekci _Fine-tuning_ na platformě. Zde uvidíte stav aktuální úlohy a také můžete sledovat historii předchozích spuštění. Na tomto snímku obrazovky je vidět, že předchozí spuštění selhalo a druhý pokus byl úspěšný. Pro vysvětlení – k tomu došlo, když první spuštění použilo JSON soubor se špatně naformátovanými záznamy. Po opravě druhý pokus proběhl úspěšně a model byl zpřístupněn k použití.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.cs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Můžete si také prohlédnout stavové zprávy a metriky posunutím dolů ve vizuálním panelu, jak je znázorněno:\n",
    "\n",
    "| Zprávy | Metriky |\n",
    "|:---|:---|\n",
    "| ![Zprávy](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.cs.png) |  ![Metriky](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.cs.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 3.1: Získání ID a otestování jemně doladěného modelu v kódu\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Krok 3.2: Načtení a testování doladěného modelu v Playgroundu\n",
    "\n",
    "Nyní můžete otestovat doladěný model dvěma způsoby. Nejprve můžete navštívit Playground a v rozbalovacím menu Models vybrat svůj nově doladěný model z nabízených možností. Druhou možností je použít volbu \"Playground\" zobrazenou v panelu Fine-tuning (viz screenshot výše), která spustí _porovnávací_ zobrazení, kde vedle sebe vidíte základní a doladěnou verzi modelu pro rychlé vyhodnocení.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.cs.png)\n",
    "\n",
    "Stačí vyplnit systémový kontext použitý ve vašich trénovacích datech a zadat testovací otázku. Všimnete si, že na obou stranách se aktualizuje stejný kontext i otázka. Spusťte porovnání a uvidíte rozdíl ve výstupech mezi oběma modely. _Všimněte si, jak doladěný model odpovídá ve formátu, který jste zadali ve svých příkladech, zatímco základní model pouze následuje systémový prompt_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.cs.png)\n",
    "\n",
    "Všimnete si také, že porovnání zobrazuje počet tokenů pro každý model a čas potřebný na inferenci. **Tento konkrétní příklad je zjednodušený a slouží pouze k ukázce postupu, nereprezentuje reálný dataset nebo scénář**. Můžete si všimnout, že oba vzorky mají stejný počet tokenů (systémový kontext a uživatelský prompt jsou totožné), přičemž doladěný model potřebuje na inferenci více času (vlastní model).\n",
    "\n",
    "V reálných scénářích nebudete používat takto jednoduchý příklad, ale budete doladit model na reálných datech (například produktový katalog pro zákaznickou podporu), kde bude kvalita odpovědí mnohem zřetelnější. V _takovém_ případě bude dosažení srovnatelné kvality odpovědí se základním modelem vyžadovat více úprav promptu, což zvýší spotřebu tokenů a pravděpodobně i dobu zpracování inference. _Pokud si to chcete vyzkoušet, podívejte se na příklady doladění v OpenAI Cookbook._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Prohlášení**:  \nTento dokument byl přeložen pomocí AI překladatelské služby [Co-op Translator](https://github.com/Azure/co-op-translator). Přestože se snažíme o přesnost, mějte prosím na paměti, že automatizované překlady mohou obsahovat chyby nebo nepřesnosti. Za autoritativní zdroj by měl být považován původní dokument v jeho rodném jazyce. Pro kritické informace doporučujeme profesionální lidský překlad. Neodpovídáme za žádná nedorozumění nebo nesprávné výklady vzniklé v důsledku použití tohoto překladu.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:53:46+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "cs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}