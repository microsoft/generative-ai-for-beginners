<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b2651fb16bcfbc62b8e518751ed90fdb",
  "translation_date": "2025-10-17T21:35:05+00:00",
  "source_file": "05-advanced-prompts/README.md",
  "language_code": "cs"
}
-->
# Vytv√°≈ôen√≠ pokroƒçil√Ωch prompt≈Ø

[![Vytv√°≈ôen√≠ pokroƒçil√Ωch prompt≈Ø](../../../translated_images/05-lesson-banner.522610fd4a2cd82dbed66bb7e6fe104ed6da172e085dbb4d9100b28dc73ed435.cs.png)](https://youtu.be/BAjzkaCdRok?si=NmUIyRf7-cDgbjtt)

Pojƒème si zopakovat nƒõkter√© poznatky z p≈ôedchoz√≠ kapitoly:

> Prompt _engineering_ je proces, kter√Ωm **smƒõ≈ôujeme model k relevantnƒõj≈°√≠m odpovƒõd√≠m** t√≠m, ≈æe poskytujeme u≈æiteƒçnƒõj≈°√≠ instrukce nebo kontext.

Existuj√≠ tak√© dva kroky p≈ôi psan√≠ prompt≈Ø: konstrukce promptu, tedy poskytov√°n√≠ relevantn√≠ho kontextu, a _optimalizace_, tedy postupn√© zlep≈°ov√°n√≠ promptu.

V tuto chv√≠li m√°me z√°kladn√≠ p≈ôedstavu o tom, jak ps√°t prompty, ale pot≈ôebujeme j√≠t hloubƒõji. V t√©to kapitole p≈ôejdete od zkou≈°en√≠ r≈Øzn√Ωch prompt≈Ø k pochopen√≠, proƒç je jeden prompt lep≈°√≠ ne≈æ druh√Ω. Nauƒç√≠te se, jak konstruovat prompty podle z√°kladn√≠ch technik, kter√© lze aplikovat na jak√Ωkoli LLM.

## √övod

V t√©to kapitole se budeme zab√Ωvat n√°sleduj√≠c√≠mi t√©maty:

- Roz≈°√≠≈ôen√≠ znalost√≠ o prompt engineeringu aplikac√≠ r≈Øzn√Ωch technik na va≈°e prompty.
- Konfigurace prompt≈Ø pro r≈Øzn√© v√Ωstupy.

## C√≠le uƒçen√≠

Po dokonƒçen√≠ t√©to lekce budete schopni:

- Pou≈æ√≠t techniky prompt engineeringu, kter√© zlep≈°uj√≠ v√Ωsledky va≈°ich prompt≈Ø.
- Prov√°dƒõt prompting, kter√Ω je buƒè variabiln√≠, nebo deterministick√Ω.

## Prompt engineering

Prompt engineering je proces vytv√°≈ôen√≠ prompt≈Ø, kter√© p≈ôinesou po≈æadovan√Ω v√Ωsledek. Prompt engineering nen√≠ jen o psan√≠ textov√Ωch prompt≈Ø. Nejedn√° se o in≈æen√Ωrskou discipl√≠nu, ale sp√≠≈°e o soubor technik, kter√© m≈Ø≈æete pou≈æ√≠t k dosa≈æen√≠ po≈æadovan√©ho v√Ωsledku.

### P≈ô√≠klad promptu

Pod√≠vejme se na z√°kladn√≠ prompt, jako je tento:

> Vytvo≈ôte 10 ot√°zek na t√©ma geografie.

V tomto promptu vlastnƒõ aplikujete sadu r≈Øzn√Ωch technik prompt≈Ø.

Rozlo≈æme si to.

- **Kontext**, specifikujete, ≈æe by se mƒõlo jednat o "geografii".
- **Omezen√≠ v√Ωstupu**, chcete maxim√°lnƒõ 10 ot√°zek.

### Omezen√≠ jednoduch√©ho promptingu

Mo≈æn√° dostanete po≈æadovan√Ω v√Ωsledek, mo≈æn√° ne. Ot√°zky budou vygenerov√°ny, ale geografie je ≈°irok√© t√©ma a mo≈æn√° nedostanete to, co chcete, z n√°sleduj√≠c√≠ch d≈Øvod≈Ø:

- **≈†irok√© t√©ma**, nev√≠te, zda se bude jednat o zemƒõ, hlavn√≠ mƒõsta, ≈ôeky a podobnƒõ.
- **Form√°t**, co kdy≈æ chcete, aby ot√°zky byly form√°tov√°ny urƒçit√Ωm zp≈Øsobem?

Jak vid√≠te, p≈ôi vytv√°≈ôen√≠ prompt≈Ø je t≈ôeba zv√°≈æit mnoho vƒõc√≠.

Doposud jsme vidƒõli jednoduch√Ω p≈ô√≠klad promptu, ale generativn√≠ AI je schopna mnohem v√≠ce, aby pomohla lidem v r≈Øzn√Ωch rol√≠ch a odvƒõtv√≠ch. Pojƒème si nyn√≠ prozkoumat nƒõkter√© z√°kladn√≠ techniky.

### Techniky pro prompting

Nejprve mus√≠me pochopit, ≈æe prompting je _emergentn√≠_ vlastnost LLM, co≈æ znamen√°, ≈æe to nen√≠ funkce zabudovan√° do modelu, ale sp√≠≈°e nƒõco, co objevujeme p≈ôi jeho pou≈æ√≠v√°n√≠.

Existuje nƒõkolik z√°kladn√≠ch technik, kter√© m≈Ø≈æeme pou≈æ√≠t k promptov√°n√≠ LLM. Pojƒème si je prozkoumat.

- **Zero-shot prompting**, to je nejz√°kladnƒõj≈°√≠ forma promptingu. Jedn√° se o jedin√Ω prompt, kter√Ω ≈æ√°d√° odpovƒõƒè od LLM pouze na z√°kladƒõ jeho tr√©ninkov√Ωch dat.
- **Few-shot prompting**, tento typ promptingu vede LLM t√≠m, ≈æe poskytuje 1 nebo v√≠ce p≈ô√≠klad≈Ø, na kter√© se m≈Ø≈æe spolehnout p≈ôi generov√°n√≠ odpovƒõdi.
- **Chain-of-thought**, tento typ promptingu ≈ô√≠k√° LLM, jak rozdƒõlit probl√©m na jednotliv√© kroky.
- **Generated knowledge**, pro zlep≈°en√≠ odpovƒõdi promptu m≈Ø≈æete k promptu p≈ôidat generovan√° fakta nebo znalosti.
- **Least to most**, podobnƒõ jako chain-of-thought, tato technika spoƒç√≠v√° v rozdƒõlen√≠ probl√©mu na s√©rii krok≈Ø a n√°sledn√©m po≈æ√°d√°n√≠ o jejich proveden√≠ v po≈ôad√≠.
- **Self-refine**, tato technika spoƒç√≠v√° v kritice v√Ωstupu LLM a n√°sledn√©m po≈æ√°d√°n√≠ o jeho zlep≈°en√≠.
- **Maieutic prompting**, zde chcete zajistit, ≈æe odpovƒõƒè LLM je spr√°vn√°, a po≈æ√°d√°te ho, aby vysvƒõtlilo r≈Øzn√© ƒç√°sti odpovƒõdi. Jedn√° se o formu self-refine.

### Zero-shot prompting

Tento styl promptingu je velmi jednoduch√Ω, skl√°d√° se z jedin√©ho promptu. Tuto techniku pravdƒõpodobnƒõ pou≈æ√≠v√°te, kdy≈æ se zaƒç√≠n√°te uƒçit o LLM. Zde je p≈ô√≠klad:

- Prompt: "Co je algebra?"
- Odpovƒõƒè: "Algebra je odvƒõtv√≠ matematiky, kter√© studuje matematick√© symboly a pravidla pro manipulaci s tƒõmito symboly."

### Few-shot prompting

Tento styl promptingu pom√°h√° modelu t√≠m, ≈æe poskytuje nƒõkolik p≈ô√≠klad≈Ø spolu s po≈æadavkem. Skl√°d√° se z jedin√©ho promptu s dal≈°√≠mi daty specifick√Ωmi pro √∫kol. Zde je p≈ô√≠klad:

- Prompt: "Napi≈°te b√°se≈à ve stylu Shakespeara. Zde je nƒõkolik p≈ô√≠klad≈Ø Shakespearov√Ωch sonet≈Ø:
  Sonet 18: 'M√°m tƒõ p≈ôirovnat k letn√≠mu dni? Jsi kr√°snƒõj≈°√≠ a m√≠rnƒõj≈°√≠...'
  Sonet 116: 'Nedovol√≠m p≈ôek√°≈æky v man≈æelstv√≠ prav√Ωch mysl√≠. L√°ska nen√≠ l√°skou, kter√° se mƒõn√≠, kdy≈æ se mƒõn√≠ okolnosti...'
  Sonet 132: 'Tv√© oƒçi miluji, a ony, jakoby mƒõ litovaly, Znaj√≠ tv√© srdce, kter√© mƒõ tr√°p√≠ pohrd√°n√≠m,...'
  Nyn√≠ napi≈°te sonet o kr√°se mƒõs√≠ce."
- Odpovƒõƒè: "Na nebi mƒõs√≠c ti≈°e z√°≈ô√≠, V st≈ô√≠brn√©m svƒõtle, kter√© vrh√° svou jemnou kr√°su,..."

P≈ô√≠klady poskytuj√≠ LLM kontext, form√°t nebo styl po≈æadovan√©ho v√Ωstupu. Pom√°haj√≠ modelu pochopit konkr√©tn√≠ √∫kol a generovat p≈ôesnƒõj≈°√≠ a relevantnƒõj≈°√≠ odpovƒõdi.

### Chain-of-thought

Chain-of-thought je velmi zaj√≠mav√° technika, proto≈æe jde o to, jak prov√©st LLM s√©ri√≠ krok≈Ø. My≈°lenka je instruovat LLM takov√Ωm zp≈Øsobem, aby pochopilo, jak nƒõco udƒõlat. Zva≈æte n√°sleduj√≠c√≠ p≈ô√≠klad, s a bez chain-of-thought:

    - Prompt: "Alice m√° 5 jablek, vyhod√≠ 3 jablka, d√° 2 Bobovi a Bob j√≠ jedno vr√°t√≠, kolik jablek m√° Alice?"
    - Odpovƒõƒè: 5

LLM odpov√≠ 5, co≈æ je nespr√°vn√©. Spr√°vn√° odpovƒõƒè je 1 jablko, podle v√Ωpoƒçtu (5 -3 -2 + 1 = 1).

Jak m≈Ø≈æeme nauƒçit LLM, aby to udƒõlalo spr√°vnƒõ?

Zkusme chain-of-thought. Pou≈æit√≠ chain-of-thought znamen√°:

1. Poskytnout LLM podobn√Ω p≈ô√≠klad.
1. Uk√°zat v√Ωpoƒçet a jak ho spr√°vnƒõ vypoƒç√≠tat.
1. Poskytnout p≈Øvodn√≠ prompt.

Zde je postup:

- Prompt: "Lisa m√° 7 jablek, vyhod√≠ 1 jablko, d√° 4 jablka Bartovi a Bart j√≠ jedno vr√°t√≠:
  7 -1 = 6
  6 -4 = 2
  2 +1 = 3  
  Alice m√° 5 jablek, vyhod√≠ 3 jablka, d√° 2 Bobovi a Bob j√≠ jedno vr√°t√≠, kolik jablek m√° Alice?"
  Odpovƒõƒè: 1

V≈°imnƒõte si, jak p√≠≈°eme podstatnƒõ del≈°√≠ prompt s dal≈°√≠m p≈ô√≠kladem, v√Ωpoƒçtem a pot√© p≈Øvodn√≠m promptem, a dospƒõjeme ke spr√°vn√© odpovƒõdi 1.

Jak vid√≠te, chain-of-thought je velmi siln√° technika.

### Generated knowledge

ƒåasto, kdy≈æ chcete vytvo≈ôit prompt, chcete to udƒõlat pomoc√≠ dat va≈°√≠ vlastn√≠ spoleƒçnosti. Chcete, aby ƒç√°st promptu poch√°zela od spoleƒçnosti a druh√° ƒç√°st by mƒõla b√Ωt skuteƒçn√Ω prompt, kter√Ω v√°s zaj√≠m√°.

Nap≈ô√≠klad, pokud pracujete v poji≈°≈•ovnictv√≠, v√°≈° prompt m≈Ø≈æe vypadat takto:

```text
{{company}}: {{company_name}}
{{products}}:
{{products_list}}
Please suggest an insurance given the following budget and requirements:
Budget: {{budget}}
Requirements: {{requirements}}
```

V√Ω≈°e vid√≠te, jak je prompt vytvo≈ôen pomoc√≠ ≈°ablony. V ≈°ablonƒõ je nƒõkolik promƒõnn√Ωch, oznaƒçen√Ωch `{{variable}}`, kter√© budou nahrazeny skuteƒçn√Ωmi hodnotami z firemn√≠ho API.

Zde je p≈ô√≠klad, jak by mohl prompt vypadat, jakmile budou promƒõnn√© nahrazeny obsahem z va≈°√≠ spoleƒçnosti:

```text
Insurance company: ACME Insurance
Insurance products (cost per month):
- Car, cheap, 500 USD
- Car, expensive, 1100 USD
- Home, cheap, 600 USD
- Home, expensive, 1200 USD
- Life, cheap, 100 USD

Please suggest an insurance given the following budget and requirements:
Budget: $1000
Requirements: Car, Home, and Life insurance
```

Pokud tento prompt spust√≠te p≈ôes LLM, z√≠sk√°te odpovƒõƒè jako:

```output
Given the budget and requirements, we suggest the following insurance package from ACME Insurance:
- Car, cheap, 500 USD
- Home, cheap, 600 USD
- Life, cheap, 100 USD
Total cost: $1,200 USD
```

Jak vid√≠te, tak√© navrhuje ≈æivotn√≠ poji≈°tƒõn√≠, co≈æ by nemƒõlo. Tento v√Ωsledek naznaƒçuje, ≈æe mus√≠me optimalizovat prompt t√≠m, ≈æe ho uprav√≠me, aby byl jasnƒõj≈°√≠ ohlednƒõ toho, co je povoleno. Po nƒõkolika _pokus√≠ch a omylech_ dospƒõjeme k n√°sleduj√≠c√≠mu promptu:

```text
Insurance company: ACME Insurance
Insurance products (cost per month):
- type: Car, cheap, cost: 500 USD
- type: Car, expensive, cost: 1100 USD
- type: Home, cheap, cost: 600 USD
- type: Home, expensive, cost: 1200 USD
- type: Life, cheap, cost: 100 USD

Please suggest an insurance given the following budget and requirements:
Budget: $1000 restrict choice to types: Car, Home
```

V≈°imnƒõte si, jak p≈ôid√°n√≠ _type_ a _cost_ a tak√© pou≈æit√≠ kl√≠ƒçov√©ho slova _restrict_ pom√°h√° LLM pochopit, co chceme.

Nyn√≠ dostaneme n√°sleduj√≠c√≠ odpovƒõƒè:

```output
Given the budget and requirements, we suggest the Car, Cheap insurance product which costs 500 USD per month.
```

C√≠lem tohoto p≈ô√≠kladu bylo uk√°zat, ≈æe i kdy≈æ pou≈æ√≠v√°me z√°kladn√≠ techniku jako _generated knowledge_, st√°le mus√≠me ve vƒõt≈°inƒõ p≈ô√≠pad≈Ø optimalizovat prompt, abychom dos√°hli po≈æadovan√©ho v√Ωsledku.

### Least-to-most

My≈°lenka techniky Least-to-most je rozdƒõlit vƒõt≈°√≠ probl√©m na d√≠lƒç√≠ probl√©my. T√≠m pom√°h√°te LLM "dob√Ωt" vƒõt≈°√≠ probl√©m. Dobr√Ωm p≈ô√≠kladem m≈Ø≈æe b√Ωt datov√° anal√Ωza, kde m≈Ø≈æete po≈æ√°dat LLM, aby rozdƒõlilo probl√©m takto:

> Prompt: Jak prov√©st datovou anal√Ωzu v 5 kroc√≠ch?

Va≈°e AI asistent odpov√≠:

1. Sb√≠rejte data
1. Vyƒçistƒõte data
1. Analyzujte data
1. Vytvo≈ôte grafy
1. Prezentujte data

### Self-refine, kritika v√Ωsledk≈Ø

U generativn√≠ch AI a LLM nem≈Ø≈æete d≈Øvƒõ≈ôovat v√Ωstupu. Mus√≠te ho ovƒõ≈ôit. Koneckonc≈Ø, LLM v√°m pouze prezentuje, co je nejpravdƒõpodobnƒõj≈°√≠ ≈ô√≠ci d√°l, ne co je spr√°vn√©. Proto je dobr√Ω n√°pad po≈æ√°dat LLM, aby se samo zkritizovalo, co≈æ n√°s p≈ôiv√°d√≠ k technice self-refine.

Jak to funguje:

1. Poƒç√°teƒçn√≠ prompt, kter√Ω ≈æ√°d√° LLM o vy≈ôe≈°en√≠ probl√©mu.
1. LLM odpov√≠.
1. Kritizujete odpovƒõƒè a po≈æ√°d√°te AI o zlep≈°en√≠.
1. LLM odpov√≠ znovu, tentokr√°t zohledn√≠ kritiku a navrhne ≈ôe≈°en√≠, kter√° vymyslelo.

Tento proces m≈Ø≈æete opakovat tolikr√°t, kolikr√°t chcete.

Zde je p≈ô√≠klad pou≈æit√≠ t√©to techniky:

> Prompt: "Vytvo≈ôte Python Web API s routami products a customers"

Odpovƒõƒè AI:

```python
import flask
app = Flask(__name__)

@app.route('/products')
def products():
    return 'Products'

@app.route('/customers')
def customers():
    return 'Customers'
```

> Prompt: Navrhnƒõte 3 vylep≈°en√≠ v√Ω≈°e uveden√©ho k√≥du

Odpovƒõƒè AI:

```text
Sure, here are three suggestions to improve the code:

Import the correct module: The first line should import Flask instead of flask. The correct import statement should be from flask import Flask.

Add a main function: Add a if __name__ == '__main__': block to the end of the file to run the application when the file is executed.

Use f-strings: Use f-strings to format the return statements in the route functions. For example, return 'Products' can be changed to return f'This is the {request.path} page'.
```

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/products')
def products():
    return f'This is the {request.path} page'

@app.route('/customers')
def customers():
    return f'This is the {request.path} page'

if __name__ == '__main__':
    app.run()
```

Jak vid√≠te, v√Ω≈°e uveden√° odpovƒõƒè AI zlep≈°uje prvn√≠ navr≈æen√Ω k√≥d d√≠ky kritice prvn√≠ odpovƒõdi.

### Maieutic prompting

Maieutic prompting je technika, kter√° je podobn√° self-refine, ale v√≠ce se zamƒõ≈ôuje na to, aby LLM vysvƒõtlilo samo sebe. C√≠lem je sn√≠≈æit nekonzistence ve v√Ωstupu LLM, aby bylo zaji≈°tƒõno, ≈æe dospƒõje ke spr√°vn√© odpovƒõdi. Postup je n√°sleduj√≠c√≠:

1. Po≈æ√°dejte LLM, aby odpovƒõdƒõlo na ot√°zku.
1. U ka≈æd√© ƒç√°sti odpovƒõdi po≈æ√°dejte LLM, aby ji podrobnƒõji vysvƒõtlilo.
1. Pokud jsou nekonzistence, odstra≈àte ƒç√°sti, kter√© jsou nekonzistentn√≠.

Opakujte kroky 2 a 3, dokud neprojdete v≈°echny ƒç√°sti a nebudete spokojeni s odpovƒõd√≠.

Zde je p≈ô√≠klad promptu:

> prompt: Jak mohu vytvo≈ôit krizov√Ω pl√°n pro zm√≠rnƒõn√≠ pandemie v 5 kroc√≠ch?
> Odpovƒõƒè LLM:

```text
1. Identify the risks
1. Identify the stakeholders
1. Identify the resources
1. Identify the actions
1. Identify the communication channels
```

Identifikovalo 5 krok≈Ø, ale m≈Ø≈æeme urƒçit, zda je to spr√°vn√©? Po≈æ√°dejme LLM, aby vysvƒõtlilo ka≈æd√Ω krok:

> prompt: Vysvƒõtlete prvn√≠ krok podrobnƒõji, jak√© jsou podrobn√© rizika pandemie?

```text
The risks are the following:

- Loss of life
- Loss of business
- Loss of reputation
- Loss of customers
- Loss of employees
```

V tuto chv√≠li chceme zajistit, ≈æe LLM je spr√°vn√©, tak≈æe ho po≈æ√°d√°me, aby vysvƒõtlilo prvn√≠ riziko podrobnƒõji a douf√°me, ≈æe je konzistentn√≠ s v√Ω≈°e uvedenou odpovƒõd√≠:

> prompt: V pandemii, jak√© je nejvƒõt≈°√≠ riziko a proƒç?

```text
The biggest risk is loss of life because it's the most important thing to protect.
```

> Jak√° jsou dvƒõ nejvƒõt≈°√≠ rizika v pandemii?

```text
The two biggest risks are loss of life and loss of business.
```

V tuto chv√≠li je LLM konzistentn√≠ a zmi≈àuje "≈æivot" a "byznys" jako dvƒõ nejvƒõt≈°√≠ rizika. Nyn√≠ m≈Ø≈æeme pokraƒçovat k dal≈°√≠mu kroku a c√≠tit se pomƒõrnƒõ jistƒõ. Nicm√©nƒõ bychom nemƒõli LLM slepƒõ d≈Øvƒõ≈ôovat, v≈ædy bychom mƒõli ovƒõ≈ôit v√Ωstup.

## Variabilita v√Ωstupu

LLM jsou svou povahou nedeterministick√©, co≈æ znamen√°, ≈æe poka≈æd√©, kdy≈æ spust√≠te stejn√Ω prompt, dostanete r≈Øzn√© v√Ωsledky. Zkuste nap≈ô√≠klad n√°sleduj√≠c√≠ prompt:

> "Vygenerujte k√≥d pro Python Web API"

```python
# Import necessary modules
import flask
from flask import request, jsonify

# Create a Flask app
app = flask.Flask(__name__)

# Create a route for the API
@app.route('/api', methods=['GET'])
def api():
    # Get the data from the request
    data = request.args

    # Process the data
    result = process_data(data)

    # Return the result as JSON
    return jsonify(result)

# Function to process the data
def process_data(data):
    # Do something with the data
    result = data + 1

    # Return the result
    return result

# Run the app
if __name__ == '__main__':
    app.run()

```

Pokud spust√≠te stejn√Ω prompt znovu, z√≠sk√°te m√≠rnƒõ odli≈°nou odpovƒõƒè:

```python
#import necessary packages
import flask
from flask import request, jsonify

#create the Flask application
app = flask.Flask(__name__)
app.config["DEBUG"] = True

#create a list of books
books = [
    {'id': 0,
     'title': 'A Fire Upon the Deep',
     'author': 'Vernor Vinge',
     'first_sentence': 'The coldsleep itself was dreamless.',
     'year_published': '1992'},
    {'id': 1,
     'title': 'The Ones Who Walk Away From Omelas',
     'author': 'Ursula K. Le Guin',
     'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.',
     'published': '1973'},
    {'id': 2,
     'title': 'Dhalgren',
     'author': 'Samuel R. Delany',
     'first_sentence': 'to wound the autumnal city.',
     'published': '1975'}
]

#create an endpoint for the API
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Books API</h1>
<p>A prototype API for retrieving books.</p>'''

#create an endpoint to return all books
@app.route('/api/v1/resources/books/all', methods=['GET'])
def api_all():
    return jsonify(books)

#create an endpoint to return a single book
@app.route('/api/v1/resources/books', methods=['GET'])
def api_id():
    #check if an ID was provided as part of the URL
    #if ID is provided, assign it to a variable
    #if no ID is provided, display an error
    if 'id' in request.args:
        id = int(request.args['id'])
    else:
        return "Error: No id field provided. Please specify an id."

    #create an empty list for our results
    results = []

    #loop through the data and match results that fit the requested ID
    #IDs are unique, but other fields might return many results
    for book in books:
        if book['id'] == id:
            results.append(book)

    #use the jsonify function from Flask to convert our list of
    #Python dictionaries to the JSON format
    return jsonify(results)

app.run()
```

> Je variabiln√≠ v√Ωstup probl√©m?

Z√°le≈æ√≠ na tom, co se sna≈æ√≠te udƒõlat. Pokud chcete konkr√©tn√≠ odpovƒõƒè, pak je to probl√©m. Pokud v√°m nevad√≠ variabiln√≠ v√Ωstup, jako nap≈ô√≠klad "Vygenerujte libovoln√© 3 ot√°zky na t√©ma geografie", pak to probl√©m nen√≠.

### Pou≈æit√≠ teploty pro variabilitu v√Ωstupu

Dob≈ôe, rozhodli jsme se, ≈æe chceme omezit v√Ωstup, aby byl p≈ôedv√≠datelnƒõj≈°√≠, tedy v√≠ce deterministick√Ω. Jak to udƒõlat?

Teplota je hodnota mezi 0 a 1, kde 0 je nejv√≠ce deterministick√° a 1 je nejv√≠ce variabiln√≠. V√Ωchoz√≠ hodnota je 0.7. Pod√≠vejme se, co se stane p≈ôi dvou spu≈°tƒõn√≠ch stejn√©ho promptu s teplotou nastavenou na 0.1:

> "Vygenerujte k√≥d pro Python Web API"

```python
#import necessary libraries
import flask
from flask import request, jsonify

#create an instance of the Flask class
app = flask.Flask(__name__)

#create an endpoint for the API
@app.route('/api/v1/endpoint', methods=['GET'])
def api_endpoint():
    #get the request data
    data = request.get_json()

    #process the data
    result = process_data(data)

    #return the result
    return jsonify(result)

#function to process the data
def process_data(data):
    #process the data
    result = {'result': 'success'}

    #return the result
    return result

#run the Flask app
if __name__ == '__main__':
    app.run()

```

Pokud prompt spust√≠me znovu, z√≠sk√°me tento v√Ωsledek:

```python
#import necessary libraries
import flask
from flask import request, jsonify

#create a Flask app
app = flask.Flask(__name__)

#create a route for the API
@app.route('/api', methods=['GET'])
def api_call():
    #get the data from the request
    data = request.get_json()

    #process the data
    result = process_data(data)

    #return the result
    return jsonify(result)

#define the process_data function
def process_data(data):
    #do something with the data
    result = data + 1

    #return the result
    return result

#run the app
if __name__ == '__main__':
    app.run()

```

Mezi tƒõmito dvƒõma v√Ωstupy je jen mal√Ω rozd√≠l. Tentokr√°t udƒõlejme opak, nastavme teplotu na 0.9:

```python
# Import necessary libraries
import flask
from flask import request, jsonify

# Create a Flask app
app = flask.Flask(__name__)

# Create a route for the API
@app.route('/api', methods=['GET'])
def api_call():
    # Get the data from the request
    data = request.args

    # Process the data
    result = process_data(data)

    # Return the result
    return jsonify(result)

# Function to process the data
def process_data(data):
    # Do something with the data
    result = data + 1

    # Return the result
    return result

# Run the app
if __name__ == '__main__':
    app.run()

```

a druh√Ω pokus s hodnotou teploty 0.9:

```python
import flask
from flask import request, jsonify

# create the Flask app
app = flask.Flask(__name__)
app.config['DEBUG'] = True

# create some test data
books = [
    {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},
    {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},
    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}
]

# create an endpoint
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Welcome to our book API!</h1>'''

@app.route('/api/v1/resources/books

```

Jak vid√≠te, v√Ωsledky nemohly b√Ωt rozmanitƒõj≈°√≠.

> V≈°imnƒõte si, ≈æe existuje v√≠ce parametr≈Ø, kter√© m≈Ø≈æete zmƒõnit, aby se v√Ωstup li≈°il, jako nap≈ô√≠klad top-k, top-p, penalizace opakov√°n√≠, penalizace d√©lky a penalizace rozmanitosti, ale tyto parametry jsou mimo rozsah tohoto kurzu.

## Dobr√© praktiky

Existuje mnoho postup≈Ø, kter√© m≈Ø≈æete pou≈æ√≠t, abyste dos√°hli po≈æadovan√©ho v√Ωsledku. Jak budete v√≠ce a v√≠ce pou≈æ√≠vat promptov√°n√≠, najdete sv≈Øj vlastn√≠ styl.

Kromƒõ technik, kter√© jsme probrali, je t≈ôeba zv√°≈æit nƒõkter√© dobr√© praktiky p≈ôi promptov√°n√≠ LLM.

Zde jsou nƒõkter√© dobr√© praktiky, kter√© je t≈ôeba zv√°≈æit:

- **Specifikujte kontext**. Kontext je d≈Øle≈æit√Ω, ƒç√≠m v√≠ce m≈Ø≈æete specifikovat, nap≈ô√≠klad dom√©nu, t√©ma atd., t√≠m l√©pe.
- Omezte v√Ωstup. Pokud chcete konkr√©tn√≠ poƒçet polo≈æek nebo konkr√©tn√≠ d√©lku, specifikujte to.
- **Specifikujte co a jak**. Nezapome≈àte zm√≠nit nejen co chcete, ale i jak to chcete, nap≈ô√≠klad "Vytvo≈ô Python Web API s routami products a customers, rozdƒõl ho do 3 soubor≈Ø".
- **Pou≈æ√≠vejte ≈°ablony**. ƒåasto budete cht√≠t obohatit sv√© prompty daty z va≈°√≠ spoleƒçnosti. Pou≈æ√≠vejte ≈°ablony k tomu. ≈†ablony mohou obsahovat promƒõnn√©, kter√© nahrad√≠te skuteƒçn√Ωmi daty.
- **Pi≈°te spr√°vnƒõ**. LLM v√°m m≈Ø≈æe poskytnout spr√°vnou odpovƒõƒè, ale pokud budete ps√°t spr√°vnƒõ, dostanete lep≈°√≠ odpovƒõƒè.

## √ökol

Zde je k√≥d v Pythonu, kter√Ω ukazuje, jak vytvo≈ôit jednoduch√© API pomoc√≠ Flask:

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/')
def hello():
    name = request.args.get('name', 'World')
    return f'Hello, {name}!'

if __name__ == '__main__':
    app.run()
```

Pou≈æijte AI asistenta, jako je GitHub Copilot nebo ChatGPT, a aplikujte techniku "self-refine" k vylep≈°en√≠ k√≥du.

## ≈òe≈°en√≠

Pokuste se vy≈ôe≈°it √∫kol p≈ôid√°n√≠m vhodn√Ωch prompt≈Ø do k√≥du.

> [!TIP]
> Formulujte prompt tak, aby po≈æ√°dal o vylep≈°en√≠, je dobr√© omezit poƒçet vylep≈°en√≠. M≈Ø≈æete tak√© po≈æ√°dat o vylep≈°en√≠ urƒçit√Ωm zp≈Øsobem, nap≈ô√≠klad architektura, v√Ωkon, bezpeƒçnost atd.

[≈òe≈°en√≠](../../../05-advanced-prompts/python/aoai-solution.py)

## Kontrola znalost√≠

Proƒç bych mƒõl pou≈æ√≠t chain-of-thought promptov√°n√≠? Uka≈æte mi 1 spr√°vnou odpovƒõƒè a 2 nespr√°vn√© odpovƒõdi.

1. Nauƒçit LLM, jak vy≈ôe≈°it probl√©m.
1. B, Nauƒçit LLM hledat chyby v k√≥du.
1. C, Instruovat LLM, aby p≈ôi≈°lo s r≈Øzn√Ωmi ≈ôe≈°en√≠mi.

A: 1, proto≈æe chain-of-thought je o tom, jak uk√°zat LLM, jak vy≈ôe≈°it probl√©m poskytnut√≠m s√©rie krok≈Ø, podobn√Ωch probl√©m≈Ø a zp≈Øsob≈Ø, jak byly vy≈ôe≈°eny.

## üöÄ V√Ωzva

Pr√°vƒõ jste pou≈æili techniku self-refine v √∫kolu. Vezmƒõte jak√Ωkoli program, kter√Ω jste vytvo≈ôili, a zva≈æte, jak√° vylep≈°en√≠ byste na nƒõj chtƒõli aplikovat. Nyn√≠ pou≈æijte techniku self-refine k aplikaci navr≈æen√Ωch zmƒõn. Co si mysl√≠te o v√Ωsledku, je lep≈°√≠ nebo hor≈°√≠?

## Skvƒõl√° pr√°ce! Pokraƒçujte v uƒçen√≠

Po dokonƒçen√≠ t√©to lekce se pod√≠vejte na na≈°i [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), abyste pokraƒçovali ve zvy≈°ov√°n√≠ sv√Ωch znalost√≠ o generativn√≠ AI!

P≈ôejdƒõte na Lekci 6, kde vyu≈æijeme na≈°e znalosti o Prompt Engineering k [vytvo≈ôen√≠ aplikac√≠ pro generov√°n√≠ textu](../06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst)

---

**Prohl√°≈°en√≠**:  
Tento dokument byl p≈ôelo≈æen pomoc√≠ slu≈æby AI pro p≈ôeklady [Co-op Translator](https://github.com/Azure/co-op-translator). Aƒçkoli se sna≈æ√≠me o p≈ôesnost, mƒõjte pros√≠m na pamƒõti, ≈æe automatizovan√© p≈ôeklady mohou obsahovat chyby nebo nep≈ôesnosti. P≈Øvodn√≠ dokument v jeho p≈Øvodn√≠m jazyce by mƒõl b√Ωt pova≈æov√°n za autoritativn√≠ zdroj. Pro d≈Øle≈æit√© informace se doporuƒçuje profesion√°ln√≠ lidsk√Ω p≈ôeklad. Neodpov√≠d√°me za ≈æ√°dn√° nedorozumƒõn√≠ nebo nespr√°vn√© interpretace vypl√Ωvaj√≠c√≠ z pou≈æit√≠ tohoto p≈ôekladu.