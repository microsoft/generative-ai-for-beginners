<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "13084c6321a2092841b9a081b29497ba",
  "translation_date": "2025-05-19T14:48:54+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "cs"
}
-->
# PouÅ¾itÃ­ generativnÃ­ AI zodpovÄ›dnÄ›

[![PouÅ¾itÃ­ generativnÃ­ AI zodpovÄ›dnÄ›](../../../translated_images/03-lesson-banner.63a265562d8a9f9230f5c636ab303a0137d11420177528f475b0a05c5f6a9ff9.cs.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _KliknÄ›te na obrÃ¡zek vÃ½Å¡e a zhlÃ©dnÄ›te video tÃ©to lekce_

Je snadnÃ© bÃ½t fascinovÃ¡n AI, a zejmÃ©na generativnÃ­ AI, ale je dÅ¯leÅ¾itÃ© zvÃ¡Å¾it, jak ji pouÅ¾Ã­vat zodpovÄ›dnÄ›. MusÃ­te uvaÅ¾ovat o vÄ›cech jako zajiÅ¡tÄ›nÃ­, Å¾e vÃ½stup je spravedlivÃ½, neÅ¡kodnÃ½ a dalÅ¡Ã­. Tato kapitola vÃ¡m poskytne uvedenÃ½ kontext, co zvÃ¡Å¾it a jak podniknout aktivnÃ­ kroky ke zlepÅ¡enÃ­ pouÅ¾Ã­vÃ¡nÃ­ AI.

## Ãšvod

Tato lekce se zamÄ›Å™Ã­ na:

- ProÄ byste mÄ›li upÅ™ednostÅˆovat zodpovÄ›dnou AI pÅ™i vytvÃ¡Å™enÃ­ aplikacÃ­ generativnÃ­ AI.
- ZÃ¡kladnÃ­ principy zodpovÄ›dnÃ© AI a jak se vztahujÃ­ k generativnÃ­ AI.
- Jak tyto principy zodpovÄ›dnÃ© AI uvÃ©st do praxe prostÅ™ednictvÃ­m strategie a nÃ¡strojÅ¯.

## CÃ­le uÄenÃ­

Po dokonÄenÃ­ tÃ©to lekce budete vÄ›dÄ›t:

- DÅ¯leÅ¾itost zodpovÄ›dnÃ© AI pÅ™i vytvÃ¡Å™enÃ­ aplikacÃ­ generativnÃ­ AI.
- Kdy uvaÅ¾ovat a aplikovat zÃ¡kladnÃ­ principy zodpovÄ›dnÃ© AI pÅ™i vytvÃ¡Å™enÃ­ aplikacÃ­ generativnÃ­ AI.
- JakÃ© nÃ¡stroje a strategie mÃ¡te k dispozici, abyste koncept zodpovÄ›dnÃ© AI uvedli do praxe.

## Principy zodpovÄ›dnÃ© AI

NadÅ¡enÃ­ z generativnÃ­ AI nikdy nebylo vyÅ¡Å¡Ã­. Toto nadÅ¡enÃ­ pÅ™ineslo mnoho novÃ½ch vÃ½vojÃ¡Å™Å¯, pozornost a financovÃ¡nÃ­ do tÃ©to oblasti. AÄkoli je to velmi pozitivnÃ­ pro kaÅ¾dÃ©ho, kdo chce vytvÃ¡Å™et produkty a spoleÄnosti vyuÅ¾Ã­vajÃ­cÃ­ generativnÃ­ AI, je takÃ© dÅ¯leÅ¾itÃ© postupovat zodpovÄ›dnÄ›.

BÄ›hem tohoto kurzu se zamÄ›Å™ujeme na budovÃ¡nÃ­ naÅ¡eho startupu a naÅ¡eho AI vzdÄ›lÃ¡vacÃ­ho produktu. PouÅ¾ijeme principy zodpovÄ›dnÃ© AI: spravedlnost, inkluzivnost, spolehlivost/bezpeÄnost, zabezpeÄenÃ­ a soukromÃ­, transparentnost a odpovÄ›dnost. S tÄ›mito principy prozkoumÃ¡me, jak se vztahujÃ­ k naÅ¡emu pouÅ¾itÃ­ generativnÃ­ AI v naÅ¡ich produktech.

## ProÄ byste mÄ›li upÅ™ednostÅˆovat zodpovÄ›dnou AI

PÅ™i vytvÃ¡Å™enÃ­ produktu vede pÅ™Ã­stup zamÄ›Å™enÃ½ na ÄlovÄ›ka, kterÃ½ mÃ¡ na pamÄ›ti nejlepÅ¡Ã­ zÃ¡jem uÅ¾ivatele, k nejlepÅ¡Ã­m vÃ½sledkÅ¯m.

JedineÄnost generativnÃ­ AI spoÄÃ­vÃ¡ v jejÃ­ schopnosti vytvÃ¡Å™et uÅ¾iteÄnÃ© odpovÄ›di, informace, vedenÃ­ a obsah pro uÅ¾ivatele. To lze provÃ©st bez mnoha manuÃ¡lnÃ­ch krokÅ¯, coÅ¾ mÅ¯Å¾e vÃ©st k velmi pÅ¯sobivÃ½m vÃ½sledkÅ¯m. Bez Å™Ã¡dnÃ©ho plÃ¡novÃ¡nÃ­ a strategiÃ­ to vÅ¡ak mÅ¯Å¾e bohuÅ¾el vÃ©st k nÄ›kterÃ½m Å¡kodlivÃ½m vÃ½sledkÅ¯m pro vaÅ¡e uÅ¾ivatele, vÃ¡Å¡ produkt a spoleÄnost jako celek.

PodÃ­vejme se na nÄ›kterÃ© (ale ne vÅ¡echny) z tÄ›chto potenciÃ¡lnÄ› Å¡kodlivÃ½ch vÃ½sledkÅ¯:

### Halucinace

Halucinace je termÃ­n pouÅ¾Ã­vanÃ½ k popisu, kdyÅ¾ LLM produkuje obsah, kterÃ½ je buÄ zcela nesmyslnÃ½, nebo nÄ›co, co vÃ­me, Å¾e je fakticky Å¡patnÃ© na zÃ¡kladÄ› jinÃ½ch zdrojÅ¯ informacÃ­.

VezmÄ›me si napÅ™Ã­klad, Å¾e vytvÃ¡Å™Ã­me funkci pro nÃ¡Å¡ startup, kterÃ¡ umoÅ¾Åˆuje studentÅ¯m klÃ¡st historickÃ© otÃ¡zky modelu. Student poloÅ¾Ã­ otÃ¡zku `Who was the sole survivor of Titanic?`

Model produkuje odpovÄ›Ä, jako je ta nÃ­Å¾e:

![Dotaz "Kdo byl jedinÃ½m pÅ™eÅ¾ivÅ¡Ã­m Titaniku"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Zdroj: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Toto je velmi sebevÄ›domÃ¡ a dÅ¯kladnÃ¡ odpovÄ›Ä. BohuÅ¾el je nesprÃ¡vnÃ¡. I s minimÃ¡lnÃ­m mnoÅ¾stvÃ­m vÃ½zkumu by ÄlovÄ›k zjistil, Å¾e bylo vÃ­ce neÅ¾ jeden pÅ™eÅ¾ivÅ¡Ã­ katastrofy Titaniku. Pro studenta, kterÃ½ prÃ¡vÄ› zaÄÃ­nÃ¡ zkoumat toto tÃ©ma, mÅ¯Å¾e bÃ½t tato odpovÄ›Ä dostateÄnÄ› pÅ™esvÄ›dÄivÃ¡, aby nebyla zpochybnÄ›na a povaÅ¾ovÃ¡na za fakt. DÅ¯sledky toho mohou vÃ©st k tomu, Å¾e AI systÃ©m je nespolehlivÃ½ a negativnÄ› ovlivÅˆuje reputaci naÅ¡eho startupu.

S kaÅ¾dou iteracÃ­ danÃ©ho LLM jsme vidÄ›li zlepÅ¡enÃ­ vÃ½konu v minimalizaci halucinacÃ­. I s tÃ­mto zlepÅ¡enÃ­m musÃ­me jako tvÅ¯rci aplikacÃ­ a uÅ¾ivatelÃ© zÅ¯stat si vÄ›domi tÄ›chto omezenÃ­.

### Å kodlivÃ½ obsah

V pÅ™edchozÃ­ ÄÃ¡sti jsme se zabÃ½vali, kdyÅ¾ LLM produkuje nesprÃ¡vnÃ© nebo nesmyslnÃ© odpovÄ›di. DalÅ¡Ã­m rizikem, kterÃ© musÃ­me mÃ­t na pamÄ›ti, je, kdyÅ¾ model reaguje Å¡kodlivÃ½m obsahem.

Å kodlivÃ½ obsah lze definovat jako:

- PoskytovÃ¡nÃ­ pokynÅ¯ nebo podporovÃ¡nÃ­ sebepoÅ¡kozovÃ¡nÃ­ nebo poÅ¡kozovÃ¡nÃ­ urÄitÃ½ch skupin.
- NenÃ¡vistnÃ½ nebo poniÅ¾ujÃ­cÃ­ obsah.
- VedenÃ­ plÃ¡novÃ¡nÃ­ jakÃ©hokoli typu Ãºtoku nebo nÃ¡silnÃ½ch ÄinÅ¯.
- PoskytovÃ¡nÃ­ pokynÅ¯, jak najÃ­t nelegÃ¡lnÃ­ obsah nebo spÃ¡chat nelegÃ¡lnÃ­ Äiny.
- ZobrazenÃ­ sexuÃ¡lnÄ› explicitnÃ­ho obsahu.

Pro nÃ¡Å¡ startup chceme zajistit, Å¾e mÃ¡me sprÃ¡vnÃ© nÃ¡stroje a strategie, abychom zabrÃ¡nili tomu, aby tento typ obsahu byl vidÄ›n studenty.

### Nedostatek spravedlnosti

Spravedlnost je definovÃ¡na jako â€zajiÅ¡tÄ›nÃ­, Å¾e AI systÃ©m je bez pÅ™edsudkÅ¯ a diskriminace a Å¾e s kaÅ¾dÃ½m zachÃ¡zÃ­ spravedlivÄ› a rovnÄ›â€œ. Ve svÄ›tÄ› generativnÃ­ AI chceme zajistit, aby vyluÄujÃ­cÃ­ svÄ›tovÃ© nÃ¡zory marginalizovanÃ½ch skupin nebyly posilovÃ¡ny vÃ½stupem modelu.

Tyto typy vÃ½stupÅ¯ nejsou pouze destruktivnÃ­ pro budovÃ¡nÃ­ pozitivnÃ­ch produktovÃ½ch zkuÅ¡enostÃ­ pro naÅ¡e uÅ¾ivatele, ale takÃ© zpÅ¯sobujÃ­ dalÅ¡Ã­ spoleÄenskÃ© Å¡kody. Jako tvÅ¯rci aplikacÃ­ bychom mÄ›li vÅ¾dy mÃ­t na pamÄ›ti Å¡irokou a rozmanitou uÅ¾ivatelskou zÃ¡kladnu pÅ™i vytvÃ¡Å™enÃ­ Å™eÅ¡enÃ­ s generativnÃ­ AI.

## Jak pouÅ¾Ã­vat generativnÃ­ AI zodpovÄ›dnÄ›

NynÃ­, kdyÅ¾ jsme identifikovali dÅ¯leÅ¾itost zodpovÄ›dnÃ© generativnÃ­ AI, podÃ­vejme se na 4 kroky, kterÃ© mÅ¯Å¾eme podniknout k budovÃ¡nÃ­ naÅ¡ich AI Å™eÅ¡enÃ­ zodpovÄ›dnÄ›:

![Cyklus zmÃ­rnÄ›nÃ­](../../../translated_images/mitigate-cycle.f82610b2048bda5a84aaa3a3cb2cda8b35fe614a7269743fdc63cbc2cbb8f20f.cs.png)

### MÄ›Å™enÃ­ potenciÃ¡lnÃ­ch Å¡kod

V testovÃ¡nÃ­ softwaru testujeme oÄekÃ¡vanÃ© akce uÅ¾ivatele na aplikaci. PodobnÄ› testovÃ¡nÃ­ rozmanitÃ© sady dotazÅ¯, kterÃ© uÅ¾ivatelÃ© s nejvÄ›tÅ¡Ã­ pravdÄ›podobnostÃ­ pouÅ¾ijÃ­, je dobrÃ½ zpÅ¯sob, jak mÄ›Å™it potenciÃ¡lnÃ­ Å¡kodu.

ProtoÅ¾e nÃ¡Å¡ startup vytvÃ¡Å™Ã­ vzdÄ›lÃ¡vacÃ­ produkt, bylo by dobrÃ© pÅ™ipravit seznam dotazÅ¯ souvisejÃ­cÃ­ch s vzdÄ›lÃ¡nÃ­m. To by mohlo pokrÃ½vat urÄitÃ½ pÅ™edmÄ›t, historickÃ© fakty a dotazy tÃ½kajÃ­cÃ­ se studentskÃ©ho Å¾ivota.

### ZmÃ­rnÄ›nÃ­ potenciÃ¡lnÃ­ch Å¡kod

NynÃ­ je Äas najÃ­t zpÅ¯soby, jak mÅ¯Å¾eme zabrÃ¡nit nebo omezit potenciÃ¡lnÃ­ Å¡kodu zpÅ¯sobenou modelem a jeho odpovÄ›Ämi. MÅ¯Å¾eme se na to podÃ­vat ve 4 rÅ¯znÃ½ch vrstvÃ¡ch:

![Vrstvy zmÃ­rnÄ›nÃ­](../../../translated_images/mitigation-layers.db2d802e3affb2f49681cf8ae39e8f1a67ff1ce29c3f1099c96948a841d62037.cs.png)

- **Model**. VÃ½bÄ›r sprÃ¡vnÃ©ho modelu pro sprÃ¡vnÃ½ pÅ™Ã­pad pouÅ¾itÃ­. VÄ›tÅ¡Ã­ a sloÅ¾itÄ›jÅ¡Ã­ modely jako GPT-4 mohou zpÅ¯sobit vÄ›tÅ¡Ã­ riziko Å¡kodlivÃ©ho obsahu, kdyÅ¾ jsou aplikovÃ¡ny na menÅ¡Ã­ a specifickÃ© pÅ™Ã­pady pouÅ¾itÃ­. PouÅ¾itÃ­ vaÅ¡ich trÃ©ninkovÃ½ch dat k doladÄ›nÃ­ takÃ© sniÅ¾uje riziko Å¡kodlivÃ©ho obsahu.

- **BezpeÄnostnÃ­ systÃ©m**. BezpeÄnostnÃ­ systÃ©m je sada nÃ¡strojÅ¯ a konfiguracÃ­ na platformÄ›, kterÃ¡ slouÅ¾Ã­ modelu a pomÃ¡hÃ¡ zmÃ­rnit Å¡kody. PÅ™Ã­kladem je systÃ©m filtrovÃ¡nÃ­ obsahu na sluÅ¾bÄ› Azure OpenAI. SystÃ©my by mÄ›ly takÃ© detekovat Ãºtoky typu jailbreak a neÅ¾Ã¡doucÃ­ aktivitu jako poÅ¾adavky od botÅ¯.

- **Metaprompt**. Metaprompty a ukotvenÃ­ jsou zpÅ¯soby, jak mÅ¯Å¾eme Å™Ã­dit nebo omezit model na zÃ¡kladÄ› urÄitÃ½ch chovÃ¡nÃ­ a informacÃ­. To by mohlo bÃ½t pouÅ¾itÃ­ systÃ©movÃ½ch vstupÅ¯ k definovÃ¡nÃ­ urÄitÃ½ch limitÅ¯ modelu. NavÃ­c poskytovÃ¡nÃ­ vÃ½stupÅ¯, kterÃ© jsou relevantnÄ›jÅ¡Ã­ pro rozsah nebo domÃ©nu systÃ©mu.

MÅ¯Å¾e to bÃ½t takÃ© pouÅ¾itÃ­ technik jako Retrieval Augmented Generation (RAG), aby model Äerpal informace pouze z vÃ½bÄ›ru dÅ¯vÄ›ryhodnÃ½ch zdrojÅ¯. V tÃ©to lekci je pozdÄ›ji lekce pro [budovÃ¡nÃ­ vyhledÃ¡vacÃ­ch aplikacÃ­](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **UÅ¾ivatelskÃ¡ zkuÅ¡enost**. PoslednÃ­ vrstva je, kde uÅ¾ivatel interaguje pÅ™Ã­mo s modelem prostÅ™ednictvÃ­m rozhranÃ­ naÅ¡Ã­ aplikace nÄ›jakÃ½m zpÅ¯sobem. TÃ­mto zpÅ¯sobem mÅ¯Å¾eme navrhnout UI/UX tak, aby omezilo uÅ¾ivatele na typy vstupÅ¯, kterÃ© mohou poslat modelu, stejnÄ› jako text nebo obrÃ¡zky zobrazenÃ© uÅ¾ivateli. PÅ™i nasazovÃ¡nÃ­ AI aplikace musÃ­me bÃ½t takÃ© transparentnÃ­ ohlednÄ› toho, co naÅ¡e generativnÃ­ AI aplikace mÅ¯Å¾e a nemÅ¯Å¾e dÄ›lat.

MÃ¡me celou lekci vÄ›novanou [navrhovÃ¡nÃ­ UX pro AI aplikace](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **VyhodnocenÃ­ modelu**. PrÃ¡ce s LLM mÅ¯Å¾e bÃ½t nÃ¡roÄnÃ¡, protoÅ¾e nemÃ¡me vÅ¾dy kontrolu nad daty, na kterÃ½ch byl model trÃ©novÃ¡n. Bez ohledu na to bychom mÄ›li vÅ¾dy vyhodnocovat vÃ½kon a vÃ½stupy modelu. Je stÃ¡le dÅ¯leÅ¾itÃ© mÄ›Å™it pÅ™esnost, podobnost, ukotvenost a relevanci vÃ½stupu modelu. To pomÃ¡hÃ¡ poskytovat transparentnost a dÅ¯vÄ›ru zainteresovanÃ½m stranÃ¡m a uÅ¾ivatelÅ¯m.

### ProvozovÃ¡nÃ­ zodpovÄ›dnÃ©ho generativnÃ­ho AI Å™eÅ¡enÃ­

BudovÃ¡nÃ­ provoznÃ­ praxe kolem vaÅ¡ich AI aplikacÃ­ je poslednÃ­ etapa. To zahrnuje spoluprÃ¡ci s jinÃ½mi ÄÃ¡stmi naÅ¡eho startupu jako prÃ¡vnÃ­ a bezpeÄnostnÃ­, aby bylo zajiÅ¡tÄ›no, Å¾e jsme v souladu se vÅ¡emi regulaÄnÃ­mi politikami. PÅ™ed spuÅ¡tÄ›nÃ­m takÃ© chceme vytvoÅ™it plÃ¡ny kolem dodÃ¡vky, Å™eÅ¡enÃ­ incidentÅ¯ a rollbacku, abychom zabrÃ¡nili jakÃ©koli Å¡kodÄ› naÅ¡im uÅ¾ivatelÅ¯m z rÅ¯stu.

## NÃ¡stroje

AÄkoli se prÃ¡ce na vÃ½voji zodpovÄ›dnÃ½ch AI Å™eÅ¡enÃ­ mÅ¯Å¾e zdÃ¡t jako hodnÄ›, je to prÃ¡ce, kterÃ¡ stojÃ­ za ÃºsilÃ­. Jak oblast generativnÃ­ AI roste, vÃ­ce nÃ¡strojÅ¯, kterÃ© pomÃ¡hajÃ­ vÃ½vojÃ¡Å™Å¯m efektivnÄ› integrovat zodpovÄ›dnost do jejich pracovnÃ­ch postupÅ¯, se bude vyvÃ­jet. NapÅ™Ã­klad [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) mÅ¯Å¾e pomoci detekovat Å¡kodlivÃ½ obsah a obrÃ¡zky prostÅ™ednictvÃ­m API poÅ¾adavku.

## Kontrola znalostÃ­

Na kterÃ© vÄ›ci musÃ­te dbÃ¡t, abyste zajistili zodpovÄ›dnÃ© pouÅ¾Ã­vÃ¡nÃ­ AI?

1. Å½e odpovÄ›Ä je sprÃ¡vnÃ¡.
2. Å kodlivÃ© pouÅ¾itÃ­, Å¾e AI nenÃ­ pouÅ¾ita pro trestnÃ© ÃºÄely.
3. ZajiÅ¡tÄ›nÃ­, Å¾e AI je bez pÅ™edsudkÅ¯ a diskriminace.

A: 2 a 3 jsou sprÃ¡vnÃ©. ZodpovÄ›dnÃ¡ AI vÃ¡m pomÃ¡hÃ¡ uvaÅ¾ovat o tom, jak zmÃ­rnit Å¡kodlivÃ© ÃºÄinky a pÅ™edsudky a dalÅ¡Ã­.

## ğŸš€ VÃ½zva

PÅ™eÄtÄ›te si o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) a podÃ­vejte se, co mÅ¯Å¾ete pÅ™ijmout pro svÃ© pouÅ¾itÃ­.

## SkvÄ›lÃ¡ prÃ¡ce, pokraÄujte ve svÃ©m uÄenÃ­

Po dokonÄenÃ­ tÃ©to lekce se podÃ­vejte na naÅ¡i [kolekci uÄenÃ­ o generativnÃ­ AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), abyste pokraÄovali v zvyÅ¡ovÃ¡nÃ­ svÃ© znalosti o generativnÃ­ AI!

PÅ™ejdÄ›te k lekci 4, kde se podÃ­vÃ¡me na [ZÃ¡klady inÅ¾enÃ½rstvÃ­ promptÅ¯](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatizovanÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument ve svÃ©m rodnÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro kritickÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme zodpovÄ›dnÃ­ za jakÃ©koli nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© vÃ½klady vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.