{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úvod\n",
    "\n",
    "Tato lekce pokryje:\n",
    "- Co je volání funkce a její použití\n",
    "- Jak vytvořit volání funkce pomocí OpenAI\n",
    "- Jak integrovat volání funkce do aplikace\n",
    "\n",
    "## Cíle učení\n",
    "\n",
    "Po dokončení této lekce budete vědět, jak a rozumět:\n",
    "\n",
    "- Účelu používání volání funkcí\n",
    "- Nastavení volání funkce pomocí služby OpenAI\n",
    "- Navrhovat efektivní volání funkcí pro použití ve vaší aplikaci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pochopení volání funkcí\n",
    "\n",
    "Pro tuto lekci chceme vytvořit funkci pro náš vzdělávací startup, která uživatelům umožní použít chatbot k nalezení technických kurzů. Doporučíme kurzy, které odpovídají jejich úrovni dovedností, aktuální roli a zájmu o technologii.\n",
    "\n",
    "K dokončení použijeme kombinaci:\n",
    " - `OpenAI` pro vytvoření chatovacího zážitku pro uživatele\n",
    " - `Microsoft Learn Catalog API` k pomoci uživatelům najít kurzy na základě požadavku uživatele\n",
    " - `Volání funkcí` k převzetí dotazu uživatele a jeho odeslání do funkce pro provedení požadavku na API.\n",
    "\n",
    "Pro začátek se podívejme, proč bychom chtěli volání funkcí vůbec použít:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # získejte novou odpověď od GPT, kde může vidět odpověď funkce\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proč volání funkcí\n",
    "\n",
    "Pokud jste dokončili jakoukoli jinou lekci v tomto kurzu, pravděpodobně chápete sílu používání velkých jazykových modelů (LLM). Doufejme, že také vidíte některá jejich omezení.\n",
    "\n",
    "Volání funkcí je funkce služby OpenAI navržená k řešení následujících výzev:\n",
    "\n",
    "Nekonzistentní formátování odpovědí:\n",
    "- Před voláním funkcí byly odpovědi z velkého jazykového modelu nestrukturované a nekonzistentní. Vývojáři museli psát složitý validační kód, aby zvládli každou variantu výstupu.\n",
    "\n",
    "Omezená integrace s externími daty:\n",
    "- Před touto funkcí bylo obtížné začlenit data z jiných částí aplikace do kontextu chatu.\n",
    "\n",
    "Standardizací formátů odpovědí a umožněním bezproblémové integrace s externími daty volání funkcí zjednodušuje vývoj a snižuje potřebu další validační logiky.\n",
    "\n",
    "Uživatelé nemohli získat odpovědi jako „Jaké je aktuální počasí ve Stockholmu?“. Je to proto, že modely byly omezeny na dobu, kdy byla data trénována.\n",
    "\n",
    "Podívejme se na níže uvedený příklad, který ilustruje tento problém:\n",
    "\n",
    "Řekněme, že chceme vytvořit databázi studentských dat, abychom jim mohli navrhnout správný kurz. Níže máme dva popisy studentů, které jsou velmi podobné v datech, která obsahují.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chceme to poslat do LLM, aby analyzoval data. To může být později použito v naší aplikaci k odeslání na API nebo uložení do databáze.\n",
    "\n",
    "Vytvořme dva identické prompt, ve kterých LLM instruujeme, jaké informace nás zajímají:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chceme to poslat LLM, aby analyzoval části, které jsou důležité pro náš produkt. Takže můžeme vytvořit dva identické podněty k instrukci LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po vytvoření těchto dvou promptů je odešleme do LLM pomocí `openai.ChatCompletion`. Prompt uložíme do proměnné `messages` a přiřadíme roli `user`. Tím simulujeme zprávu od uživatele, která je psána chatbotovi.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní můžeme odeslat oba požadavky do LLM a prozkoumat odpověď, kterou obdržíme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I když jsou výzvy stejné a popisy podobné, můžeme získat různé formáty vlastnosti `Grades`.\n",
    "\n",
    "Pokud spustíte výše uvedenou buňku několikrát, formát může být `3.7` nebo `3.7 GPA`.\n",
    "\n",
    "Je to proto, že LLM přijímá nestrukturovaná data ve formě psané výzvy a také vrací nestrukturovaná data. Potřebujeme mít strukturovaný formát, abychom věděli, co očekávat při ukládání nebo používání těchto dat.\n",
    "\n",
    "Použitím volání funkcí můžeme zajistit, že obdržíme zpět strukturovaná data. Při použití volání funkcí LLM ve skutečnosti žádné funkce nevolá ani nespouští. Místo toho vytvoříme strukturu, kterou má LLM dodržovat ve svých odpovědích. Tyto strukturované odpovědi pak používáme k tomu, abychom věděli, kterou funkci spustit v našich aplikacích.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram toku volání funkce](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.cs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Poté můžeme vzít to, co funkce vrátí, a poslat to zpět do LLM. LLM pak odpoví pomocí přirozeného jazyka, aby odpověděl na dotaz uživatele.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Případy použití volání funkcí\n",
    "\n",
    "**Volání externích nástrojů**  \n",
    "Chatboti jsou skvělí v poskytování odpovědí na otázky uživatelů. Pomocí volání funkcí mohou chatboti využívat zprávy od uživatelů k dokončení určitých úkolů. Například student může požádat chatbota: „Pošli e-mail mému vyučujícímu, že potřebuji více pomoci s tímto předmětem“. To může vyvolat volání funkce `send_email(to: string, body: string)`.\n",
    "\n",
    "**Vytváření API nebo databázových dotazů**  \n",
    "Uživatelé mohou najít informace pomocí přirozeného jazyka, který se převede na formátovaný dotaz nebo API požadavek. Příkladem může být učitel, který požádá: „Kteří studenti dokončili poslední úkol“, což může vyvolat volání funkce `get_completed(student_name: string, assignment: int, current_status: string)`.\n",
    "\n",
    "**Vytváření strukturovaných dat**  \n",
    "Uživatelé mohou vzít blok textu nebo CSV a použít LLM k extrakci důležitých informací. Například student může převést článek z Wikipedie o mírových dohodách a vytvořit AI flash karty. To lze provést pomocí funkce `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vytvoření vašeho prvního volání funkce\n",
    "\n",
    "Proces vytvoření volání funkce zahrnuje 3 hlavní kroky:\n",
    "1. Zavolání API Chat Completions s seznamem vašich funkcí a uživatelskou zprávou\n",
    "2. Přečtení odpovědi modelu pro provedení akce, tj. spuštění funkce nebo API volání\n",
    "3. Provedení dalšího volání API Chat Completions s odpovědí z vaší funkce, aby bylo možné použít tyto informace k vytvoření odpovědi uživateli.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tok volání funkce](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.cs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prvky volání funkce\n",
    "\n",
    "#### Uživatelský vstup\n",
    "\n",
    "Prvním krokem je vytvořit uživatelskou zprávu. Ta může být dynamicky přiřazena získáním hodnoty z textového vstupu, nebo můžete hodnotu přiřadit zde. Pokud pracujete s API Chat Completions poprvé, musíme definovat `role` a `content` zprávy.\n",
    "\n",
    "`role` může být buď `system` (vytváření pravidel), `assistant` (model) nebo `user` (konečný uživatel). Pro volání funkce přiřadíme tuto hodnotu jako `user` a uvedeme příklad otázky.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vytváření funkcí. \n",
    "\n",
    "Dále definujeme funkci a parametry této funkce. Použijeme zde pouze jednu funkci nazvanou `search_courses`, ale můžete vytvořit více funkcí.\n",
    "\n",
    "**Důležité** : Funkce jsou zahrnuty v systémové zprávě pro LLM a budou započítány do množství dostupných tokenů, které máte k dispozici. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definice** \n",
    "\n",
    "Struktura definice funkce má několik úrovní, z nichž každá má své vlastní vlastnosti. Zde je rozpis vnořené struktury:\n",
    "\n",
    "**Vlastnosti funkce na nejvyšší úrovni:**\n",
    "\n",
    "`name` - Název funkce, kterou chceme zavolat. \n",
    "\n",
    "`description` - Popis toho, jak funkce funguje. Zde je důležité být konkrétní a jasný. \n",
    "\n",
    "`parameters` - Seznam hodnot a formát, který chcete, aby model ve své odpovědi vytvořil. \n",
    "\n",
    "**Vlastnosti objektu parametrů:**\n",
    "\n",
    "`type` - Datový typ objektu parametrů (obvykle \"object\")\n",
    "\n",
    "`properties` - Seznam konkrétních hodnot, které model použije ve své odpovědi. \n",
    "\n",
    "**Vlastnosti jednotlivých parametrů:**\n",
    "\n",
    "`name` - Implicitně definováno klíčem vlastnosti (např. \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Datový typ tohoto konkrétního parametru (např. \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - Popis konkrétního parametru \n",
    "\n",
    "**Volitelné vlastnosti:**\n",
    "\n",
    "`required` - Pole uvádějící, které parametry jsou vyžadovány pro dokončení volání funkce.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volání funkce  \n",
    "Po definování funkce ji nyní musíme zahrnout do volání API Chat Completion. To provedeme přidáním `functions` do požadavku. V tomto případě `functions=functions`.  \n",
    "\n",
    "Existuje také možnost nastavit `function_call` na `auto`. To znamená, že necháme LLM rozhodnout, která funkce by měla být volána na základě uživatelské zprávy, místo abychom ji přiřazovali sami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní se podívejme na odpověď a jak je formátována:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Vidíte, že je volána funkce podle jména a z uživatelské zprávy byl LLM schopen najít data, která odpovídají argumentům funkce.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.Integrace volání funkcí do aplikace. \n",
    "\n",
    "\n",
    "Poté, co jsme otestovali formátovanou odpověď z LLM, nyní ji můžeme integrovat do aplikace. \n",
    "\n",
    "### Řízení toku \n",
    "\n",
    "Pro integraci do naší aplikace proveďme následující kroky: \n",
    "\n",
    "Nejprve proveďme volání služeb OpenAI a uložme zprávu do proměnné nazvané `response_message`. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní definujeme funkci, která zavolá Microsoft Learn API pro získání seznamu kurzů:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako nejlepší praxi si pak ukážeme, zda model chce zavolat funkci. Poté vytvoříme jednu z dostupných funkcí a přiřadíme ji k volané funkci.  \n",
    "Následně vezmeme argumenty funkce a namapujeme je na argumenty z LLM.\n",
    "\n",
    "Nakonec připojíme zprávu o volání funkce a hodnoty, které byly vráceny zprávou `search_courses`. To dává LLM všechny informace, které potřebuje k odpovědi uživateli pomocí přirozeného jazyka.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní pošleme aktualizovanou zprávu do LLM, abychom mohli obdržet odpověď v přirozeném jazyce místo odpovědi ve formátu JSON API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Výzva kódování\n",
    "\n",
    "Skvělá práce! Pro pokračování ve vašem učení o volání funkcí OpenAI můžete vytvořit: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Více parametrů funkce, které mohou pomoci studentům najít více kurzů. Dostupné parametry API najdete zde:  \n",
    " - Vytvořte další volání funkce, které získá více informací od studenta, například jeho rodný jazyk  \n",
    " - Vytvořte zpracování chyb, když volání funkce a/nebo volání API nevrátí žádné vhodné kurzy  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Prohlášení o vyloučení odpovědnosti**:  \nTento dokument byl přeložen pomocí AI překladatelské služby [Co-op Translator](https://github.com/Azure/co-op-translator). Přestože usilujeme o přesnost, mějte prosím na paměti, že automatické překlady mohou obsahovat chyby nebo nepřesnosti. Původní dokument v jeho mateřském jazyce by měl být považován za autoritativní zdroj. Pro důležité informace se doporučuje profesionální lidský překlad. Nejsme odpovědní za jakékoliv nedorozumění nebo nesprávné výklady vyplývající z použití tohoto překladu.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T11:22:30+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "cs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}