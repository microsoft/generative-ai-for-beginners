{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Úvod\n",
    "\n",
    "Tato lekce se zaměří na:\n",
    "- Co je volání funkcí a k čemu se používá\n",
    "- Jak vytvořit volání funkce pomocí Azure OpenAI\n",
    "- Jak integrovat volání funkce do aplikace\n",
    "\n",
    "## Výukové cíle\n",
    "\n",
    "Po dokončení této lekce budete vědět a rozumět:\n",
    "\n",
    "- Účelu používání volání funkcí\n",
    "- Nastavení volání funkce pomocí služby Azure Open AI\n",
    "- Navrhování efektivních volání funkcí pro konkrétní použití ve vaší aplikaci\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pochopení volání funkcí\n",
    "\n",
    "V této lekci chceme vytvořit funkci pro náš vzdělávací startup, která umožní uživatelům pomocí chatbota najít technické kurzy. Budeme doporučovat kurzy, které odpovídají jejich úrovni znalostí, aktuální pracovní pozici a technologii, o kterou mají zájem.\n",
    "\n",
    "K dokončení tohoto úkolu použijeme kombinaci:\n",
    " - `Azure Open AI` pro vytvoření chatovacího prostředí pro uživatele\n",
    " - `Microsoft Learn Catalog API` pro pomoc uživatelům najít kurzy na základě jejich požadavků\n",
    " - `Function Calling` pro zpracování dotazu uživatele a jeho odeslání do funkce, která provede API požadavek\n",
    "\n",
    "Než začneme, podívejme se, proč bychom vlastně chtěli použít volání funkcí:\n",
    "\n",
    "print(\"Zprávy v dalším požadavku:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # získání nové odpovědi od GPT, která už vidí odpověď funkce\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Proč používat Function Calling\n",
    "\n",
    "Pokud jste absolvovali jakoukoli jinou lekci v tomto kurzu, pravděpodobně už chápete sílu využití velkých jazykových modelů (LLM). Doufáme, že si také uvědomujete některá jejich omezení.\n",
    "\n",
    "Function Calling je funkce služby Azure Open AI, která pomáhá překonat následující omezení:\n",
    "1) Konzistentní formát odpovědí\n",
    "2) Možnost využívat data z jiných zdrojů aplikace v rámci konverzace\n",
    "\n",
    "Před zavedením function calling byly odpovědi z LLM nestrukturované a nekonzistentní. Vývojáři museli psát složitý validační kód, aby dokázali zpracovat každou variantu odpovědi.\n",
    "\n",
    "Uživatelé nemohli získat odpovědi typu „Jaké je aktuální počasí ve Stockholmu?“. Důvodem bylo, že modely měly omezené znalosti pouze na období, kdy byla data trénována.\n",
    "\n",
    "Podívejme se na následující příklad, který tento problém ilustruje:\n",
    "\n",
    "Představme si, že chceme vytvořit databázi studentských údajů, abychom jim mohli doporučit vhodný kurz. Níže máme dva popisy studentů, které obsahují velmi podobná data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Toto chceme poslat LLM, aby zpracoval data. Později to můžeme použít v naší aplikaci k odeslání na API nebo uložení do databáze.\n",
    "\n",
    "Vytvořme dva totožné promptové dotazy, kterými LLM sdělíme, o jaké informace máme zájem:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chceme to poslat LLM, aby analyzoval části, které jsou důležité pro náš produkt. Takže můžeme vytvořit dva identické promptu, abychom LLM instruovali:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Po vytvoření těchto dvou promptů je odešleme do LLM pomocí `openai.ChatCompletion`. Prompt uložíme do proměnné `messages` a přiřadíme roli `user`. To slouží k napodobení zprávy od uživatele, která je zaslána chatbotu.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import AzureOpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  api_key=os.environ['AZURE_OPENAI_API_KEY'],  # this is also the default, it can be omitted\n",
    "  api_version = \"2023-07-01-preview\"\n",
    "  )\n",
    "\n",
    "deployment=os.environ['AZURE_OPENAI_DEPLOYMENT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I když jsou zadání stejná a popisy podobné, můžeme dostat různé formáty vlastnosti `Grades`.\n",
    "\n",
    "Pokud spustíte výše uvedenou buňku několikrát, formát může být `3.7` nebo `3.7 GPA`.\n",
    "\n",
    "Je to proto, že LLM pracuje s nestrukturovanými daty ve formě napsaného zadání a vrací také nestrukturovaná data. Potřebujeme mít strukturovaný formát, abychom věděli, co očekávat při ukládání nebo používání těchto dat.\n",
    "\n",
    "Použitím funkčního volání si můžeme zajistit, že dostaneme zpět strukturovaná data. Při použití funkčního volání LLM ve skutečnosti žádné funkce nevolá ani nespouští. Místo toho vytvoříme strukturu, kterou má LLM dodržovat ve svých odpovědích. Tyto strukturované odpovědi pak využíváme k tomu, abychom věděli, jakou funkci v našich aplikacích spustit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Diagram toku volání funkcí](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.cs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Příklady použití volání funkcí\n",
    "\n",
    "**Volání externích nástrojů**  \n",
    "Chatboti jsou skvělí v poskytování odpovědí na dotazy uživatelů. Díky volání funkcí mohou chatboti využít zprávy od uživatelů k provedení určitých úkolů. Například student může požádat chatbota: „Pošli e-mail mému vyučujícímu, že potřebuji s tímto předmětem více pomoci.“ To může vyvolat volání funkce `send_email(to: string, body: string)`\n",
    "\n",
    "**Vytváření API nebo databázových dotazů**  \n",
    "Uživatelé mohou najít informace pomocí přirozeného jazyka, který se převede na formátovaný dotaz nebo API požadavek. Příkladem může být učitel, který se zeptá: „Kteří studenti dokončili poslední úkol?“, což může vyvolat funkci s názvem `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Vytváření strukturovaných dat**  \n",
    "Uživatelé mohou vzít blok textu nebo CSV a použít LLM k extrakci důležitých informací. Například student může převést článek z Wikipedie o mírových dohodách a vytvořit z něj AI kartičky. To lze provést pomocí funkce `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Vytvoření vašeho prvního volání funkce\n",
    "\n",
    "Proces vytvoření volání funkce zahrnuje 3 hlavní kroky:\n",
    "1. Zavolání Chat Completions API se seznamem vašich funkcí a uživatelskou zprávou\n",
    "2. Přečtení odpovědi modelu za účelem provedení akce, například spuštění funkce nebo API volání\n",
    "3. Opětovné zavolání Chat Completions API s odpovědí z vaší funkce, abyste tuto informaci použili k vytvoření odpovědi pro uživatele.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Tok volání funkce](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.cs.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prvky volání funkce\n",
    "\n",
    "#### Vstup uživatele\n",
    "\n",
    "Prvním krokem je vytvořit zprávu od uživatele. To lze dynamicky nastavit podle hodnoty textového vstupu, nebo můžete hodnotu přiřadit přímo zde. Pokud s Chat Completions API pracujete poprvé, je potřeba definovat `role` a `content` zprávy.\n",
    "\n",
    "`role` může být buď `system` (nastavení pravidel), `assistant` (model) nebo `user` (koncový uživatel). Pro volání funkce nastavíme tuto hodnotu na `user` a přidáme ukázkovou otázku.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vytváření funkcí.\n",
    "\n",
    "Nyní si definujeme funkci a její parametry. V tomto příkladu použijeme pouze jednu funkci s názvem `search_courses`, ale můžete si vytvořit i více funkcí.\n",
    "\n",
    "**Důležité** : Funkce jsou zahrnuty ve zprávě systému pro LLM a budou započítány do počtu dostupných tokenů, které máte k dispozici.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Definice**\n",
    "\n",
    "`name` - Název funkce, kterou chceme zavolat.\n",
    "\n",
    "`description` - Popis toho, jak funkce funguje. Je důležité být konkrétní a jasný.\n",
    "\n",
    "`parameters` - Seznam hodnot a formát, který chcete, aby model použil ve své odpovědi.\n",
    "\n",
    "`type` - Datový typ, ve kterém budou vlastnosti uloženy.\n",
    "\n",
    "`properties` - Seznam konkrétních hodnot, které model použije ve své odpovědi.\n",
    "\n",
    "`name` - Název vlastnosti, kterou model použije ve své formátované odpovědi.\n",
    "\n",
    "`type` - Datový typ této vlastnosti.\n",
    "\n",
    "`description` - Popis konkrétní vlastnosti.\n",
    "\n",
    "**Volitelné**\n",
    "\n",
    "`required` - Povinná vlastnost, aby bylo možné volání funkce dokončit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Volání funkce\n",
    "Po definování funkce ji nyní musíme zahrnout do volání Chat Completion API. Uděláme to tak, že do požadavku přidáme `functions`. V tomto případě `functions=functions`.\n",
    "\n",
    "Je zde také možnost nastavit `function_call` na `auto`. To znamená, že necháme LLM rozhodnout, kterou funkci má zavolat na základě zprávy od uživatele, místo abychom ji určovali sami.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní se podívejme na odpověď a zjistíme, jak je naformátovaná:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Můžete vidět, že je volána funkce s názvem a z uživatelské zprávy LLM dokázal najít data, která odpovídají argumentům funkce.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Integrace volání funkcí do aplikace.\n",
    "\n",
    "Poté, co jsme otestovali naformátovanou odpověď z LLM, můžeme ji nyní integrovat do aplikace.\n",
    "\n",
    "### Řízení toku\n",
    "\n",
    "Abychom to integrovali do naší aplikace, postupujme následovně:\n",
    "\n",
    "Nejprve zavoláme služby Open AI a uložíme zprávu do proměnné s názvem `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nyní definujeme funkci, která zavolá Microsoft Learn API a získá seznam kurzů:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jako osvědčený postup nejprve zjistíme, zda model chce zavolat nějakou funkci. Poté vytvoříme jednu z dostupných funkcí a přiřadíme ji k funkci, kterou model požaduje.\n",
    "\n",
    "Následně vezmeme argumenty funkce a namapujeme je na argumenty z LLM.\n",
    "\n",
    "Nakonec připojíme zprávu o volání funkce a hodnoty, které byly vráceny zprávou `search_courses`. Tím získá LLM všechny potřebné informace k tomu, aby mohl uživateli odpovědět přirozeným jazykem.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kódová výzva\n",
    "\n",
    "Skvělá práce! Pokud chcete dále rozvíjet své znalosti o Azure Open AI Function Calling, můžete si vyzkoušet: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - Přidejte více parametrů do funkce, které mohou studentům pomoci najít více kurzů. Dostupné parametry API najdete zde: \n",
    " - Vytvořte další volání funkce, které bude brát v úvahu více informací od studenta, například jeho rodný jazyk \n",
    " - Přidejte zpracování chyb pro případ, že volání funkce a/nebo API nevrátí žádné vhodné kurzy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Prohlášení**:  \nTento dokument byl přeložen pomocí AI překladatelské služby [Co-op Translator](https://github.com/Azure/co-op-translator). Přestože se snažíme o přesnost, mějte prosím na paměti, že automatizované překlady mohou obsahovat chyby nebo nepřesnosti. Za autoritativní zdroj by měl být považován původní dokument v jeho rodném jazyce. Pro kritické informace doporučujeme profesionální lidský překlad. Neodpovídáme za žádná nedorozumění nebo nesprávné výklady vzniklé v důsledku použití tohoto překladu.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "2277587ff6cb5c40437e18d61fc2e239",
   "translation_date": "2025-08-25T20:28:58+00:00",
   "source_file": "11-integrating-with-function-calling/python/aoai-assignment.ipynb",
   "language_code": "cs"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}