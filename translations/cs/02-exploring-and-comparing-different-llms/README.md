<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-07-09T08:38:04+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "cs"
}
-->
# ProzkoumÃ¡nÃ­ a porovnÃ¡nÃ­ rÅ¯znÃ½ch LLM

[![ProzkoumÃ¡nÃ­ a porovnÃ¡nÃ­ rÅ¯znÃ½ch LLM](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.cs.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _KliknÄ›te na obrÃ¡zek vÃ½Å¡e pro zhlÃ©dnutÃ­ videa tÃ©to lekce_

V pÅ™edchozÃ­ lekci jsme vidÄ›li, jak GenerativnÃ­ AI mÄ›nÃ­ technologickÃ© prostÅ™edÃ­, jak fungujÃ­ velkÃ© jazykovÃ© modely (LLM) a jak je mÅ¯Å¾e firma â€“ jako nÃ¡Å¡ startup â€“ vyuÅ¾Ã­t pro svÃ© pÅ™Ã­pady pouÅ¾itÃ­ a rÅ¯st! V tÃ©to kapitole se zamÄ›Å™Ã­me na porovnÃ¡nÃ­ rÅ¯znÃ½ch typÅ¯ velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), abychom pochopili jejich vÃ½hody a nevÃ½hody.

DalÅ¡Ã­m krokem na cestÄ› naÅ¡eho startupu je prozkoumat souÄasnÃ© prostÅ™edÃ­ LLM a zjistit, kterÃ© modely jsou vhodnÃ© pro nÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­.

## Ãšvod

Tato lekce pokryje:

- RÅ¯znÃ© typy LLM v souÄasnÃ©m prostÅ™edÃ­.
- TestovÃ¡nÃ­, iteraci a porovnÃ¡vÃ¡nÃ­ rÅ¯znÃ½ch modelÅ¯ pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­ v Azure.
- Jak nasadit LLM.

## CÃ­le uÄenÃ­

Po dokonÄenÃ­ tÃ©to lekce budete schopni:

- Vybrat sprÃ¡vnÃ½ model pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­.
- Pochopit, jak testovat, iterovat a zlepÅ¡ovat vÃ½kon modelu.
- VÄ›dÄ›t, jak firmy nasazujÃ­ modely.

## PochopenÃ­ rÅ¯znÃ½ch typÅ¯ LLM

LLM lze rozdÄ›lit do nÄ›kolika kategoriÃ­ podle jejich architektury, trÃ©ninkovÃ½ch dat a pÅ™Ã­padu pouÅ¾itÃ­. PorozumÄ›nÃ­ tÄ›mto rozdÃ­lÅ¯m pomÅ¯Å¾e naÅ¡emu startupu vybrat sprÃ¡vnÃ½ model pro danÃ½ scÃ©nÃ¡Å™ a pochopit, jak testovat, iterovat a zlepÅ¡ovat vÃ½kon.

Existuje mnoho rÅ¯znÃ½ch typÅ¯ LLM modelÅ¯, vÃ½bÄ›r zÃ¡visÃ­ na tom, k Äemu je chcete pouÅ¾Ã­t, jakÃ¡ mÃ¡te data, kolik jste ochotni zaplatit a dalÅ¡Ã­ faktory.

Podle toho, zda chcete modely vyuÅ¾Ã­t pro text, audio, video, generovÃ¡nÃ­ obrÃ¡zkÅ¯ a podobnÄ›, mÅ¯Å¾ete zvolit odliÅ¡nÃ½ typ modelu.

- **Audio a rozpoznÃ¡vÃ¡nÃ­ Å™eÄi**. Pro tento ÃºÄel jsou skvÄ›lou volbou modely typu Whisper, protoÅ¾e jsou univerzÃ¡lnÃ­ a zamÄ›Å™enÃ© na rozpoznÃ¡vÃ¡nÃ­ Å™eÄi. Jsou trÃ©novÃ¡ny na rÅ¯znorodÃ½ch audio datech a zvlÃ¡dajÃ­ vÃ­cejazyÄnÃ© rozpoznÃ¡vÃ¡nÃ­ Å™eÄi. VÃ­ce o [modelech typu Whisper zde](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **GenerovÃ¡nÃ­ obrÃ¡zkÅ¯**. Pro generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou velmi znÃ¡mÃ© modely DALL-E a Midjourney. DALL-E je dostupnÃ½ pÅ™es Azure OpenAI. [VÃ­ce o DALL-E zde](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) a takÃ© v kapitole 9 tohoto kurzu.

- **GenerovÃ¡nÃ­ textu**. VÄ›tÅ¡ina modelÅ¯ je trÃ©novÃ¡na na generovÃ¡nÃ­ textu a mÃ¡te Å¡irokÃ½ vÃ½bÄ›r od GPT-3.5 po GPT-4. Tyto modely majÃ­ rÅ¯znÃ© ceny, pÅ™iÄemÅ¾ GPT-4 je nejdraÅ¾Å¡Ã­. StojÃ­ za to vyzkouÅ¡et [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), kde mÅ¯Å¾ete vyhodnotit, kterÃ© modely nejlÃ©pe vyhovujÃ­ vaÅ¡im potÅ™ebÃ¡m z hlediska schopnostÃ­ a ceny.

- **Multimodalita**. Pokud chcete pracovat s vÃ­ce typy dat na vstupu i vÃ½stupu, mÅ¯Å¾ete se podÃ­vat na modely jako [gpt-4 turbo s vizÃ­ nebo gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) â€“ nejnovÄ›jÅ¡Ã­ verze OpenAI modelÅ¯ â€“ kterÃ© kombinujÃ­ zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka s vizuÃ¡lnÃ­m porozumÄ›nÃ­m a umoÅ¾ÅˆujÃ­ interakce pÅ™es multimodÃ¡lnÃ­ rozhranÃ­.

VÃ½bÄ›r modelu znamenÃ¡ zÃ­skat zÃ¡kladnÃ­ schopnosti, kterÃ© ale nemusÃ­ vÅ¾dy staÄit. ÄŒasto mÃ¡te specifickÃ¡ data firmy, o kterÃ½ch je potÅ™eba LLM nÄ›jak informovat. Existuje nÄ›kolik moÅ¾nostÃ­, jak to Å™eÅ¡it, o tom vÃ­ce v nÃ¡sledujÃ­cÃ­ch ÄÃ¡stech.

### Foundation Models versus LLM

TermÃ­n Foundation Model byl [zaveden vÃ½zkumnÃ­ky ze Stanfordu](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) a definuje se jako AI model, kterÃ½ splÅˆuje nÄ›kterÃ¡ kritÃ©ria, napÅ™Ã­klad:

- **Jsou trÃ©novÃ¡ny pomocÃ­ uÄenÃ­ bez uÄitele nebo samo-uÄenÃ­**, coÅ¾ znamenÃ¡, Å¾e jsou trÃ©novÃ¡ny na neoznaÄenÃ½ch multimodÃ¡lnÃ­ch datech a nevyÅ¾adujÃ­ lidskÃ© anotace nebo oznaÄovÃ¡nÃ­ dat bÄ›hem trÃ©ninku.
- **Jsou to velmi velkÃ© modely**, zaloÅ¾enÃ© na hlubokÃ½ch neuronovÃ½ch sÃ­tÃ­ch trÃ©novanÃ½ch na miliardÃ¡ch parametrÅ¯.
- **Obvykle slouÅ¾Ã­ jako â€zÃ¡kladâ€œ pro dalÅ¡Ã­ modely**, coÅ¾ znamenÃ¡, Å¾e mohou bÃ½t pouÅ¾ity jako vÃ½chozÃ­ bod pro dalÅ¡Ã­ modely, kterÃ© lze doladit (fine-tuningem).

![Foundation Models versus LLMs](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.cs.png)

Zdroj obrÃ¡zku: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pro lepÅ¡Ã­ pochopenÃ­ rozdÃ­lu si vezmÄ›me pÅ™Ã­klad ChatGPT. Pro vytvoÅ™enÃ­ prvnÃ­ verze ChatGPT poslouÅ¾il model GPT-3.5 jako zÃ¡kladnÃ­ model. To znamenÃ¡, Å¾e OpenAI pouÅ¾ilo data specifickÃ¡ pro chat, aby vytvoÅ™ilo doladÄ›nou verzi GPT-3.5, kterÃ¡ byla specializovanÃ¡ na dobrÃ½ vÃ½kon v konverzaÄnÃ­ch scÃ©nÃ¡Å™Ã­ch, jako jsou chatboti.

![Foundation Model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.cs.png)

Zdroj obrÃ¡zku: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source versus ProprietÃ¡rnÃ­ modely

DalÅ¡Ã­ zpÅ¯sob, jak kategorizovat LLM, je podle toho, zda jsou open source nebo proprietÃ¡rnÃ­.

Open source modely jsou modely zpÅ™Ã­stupnÄ›nÃ© veÅ™ejnosti a mÅ¯Å¾e je pouÅ¾Ã­vat kdokoliv. ÄŒasto je poskytuje firma, kterÃ¡ je vytvoÅ™ila, nebo vÃ½zkumnÃ¡ komunita. Tyto modely lze prohlÃ­Å¾et, upravovat a pÅ™izpÅ¯sobovat rÅ¯znÃ½m pÅ™Ã­padÅ¯m pouÅ¾itÃ­. NicmÃ©nÄ› nejsou vÅ¾dy optimalizovanÃ© pro produkÄnÃ­ nasazenÃ­ a nemusÃ­ bÃ½t tak vÃ½konnÃ© jako proprietÃ¡rnÃ­ modely. FinancovÃ¡nÃ­ open source modelÅ¯ mÅ¯Å¾e bÃ½t omezenÃ©, nemusÃ­ bÃ½t dlouhodobÄ› udrÅ¾ovÃ¡ny nebo aktualizovÃ¡ny s nejnovÄ›jÅ¡Ã­m vÃ½zkumem. PÅ™Ã­klady populÃ¡rnÃ­ch open source modelÅ¯ jsou [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) a [LLaMA](https://llama.meta.com).

ProprietÃ¡rnÃ­ modely jsou modely vlastnÄ›nÃ© firmou a nejsou veÅ™ejnÄ› dostupnÃ©. Tyto modely jsou Äasto optimalizovanÃ© pro produkÄnÃ­ pouÅ¾itÃ­. NenÃ­ dovoleno je prohlÃ­Å¾et, upravovat ani pÅ™izpÅ¯sobovat pro rÅ¯znÃ© pÅ™Ã­pady pouÅ¾itÃ­. NavÃ­c nejsou vÅ¾dy zdarma a mohou vyÅ¾adovat pÅ™edplatnÃ© nebo platbu za pouÅ¾Ã­vÃ¡nÃ­. UÅ¾ivatelÃ© takÃ© nemajÃ­ kontrolu nad daty pouÅ¾itÃ½mi k trÃ©ninku modelu, coÅ¾ znamenÃ¡, Å¾e musÃ­ dÅ¯vÄ›Å™ovat vlastnÃ­kovi modelu, Å¾e zajistÃ­ ochranu dat a odpovÄ›dnÃ© vyuÅ¾itÃ­ AI. PÅ™Ã­klady populÃ¡rnÃ­ch proprietÃ¡rnÃ­ch modelÅ¯ jsou [OpenAI modely](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) nebo [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus generovÃ¡nÃ­ obrÃ¡zkÅ¯ versus generovÃ¡nÃ­ textu a kÃ³du

LLM lze takÃ© rozdÄ›lit podle typu vÃ½stupu, kterÃ½ generujÃ­.

Embeddingy jsou sada modelÅ¯, kterÃ© dokÃ¡Å¾ou pÅ™evÃ©st text do ÄÃ­selnÃ© podoby, nazÃ½vanÃ© embedding, coÅ¾ je ÄÃ­selnÃ¡ reprezentace vstupnÃ­ho textu. Embeddingy usnadÅˆujÃ­ strojÅ¯m pochopit vztahy mezi slovy nebo vÄ›tami a mohou bÃ½t pouÅ¾ity jako vstupy pro jinÃ© modely, napÅ™Ã­klad klasifikaÄnÃ­ nebo shlukovacÃ­ modely, kterÃ© lÃ©pe pracujÃ­ s ÄÃ­selnÃ½mi daty. Embedding modely se Äasto pouÅ¾Ã­vajÃ­ pro transfer learning, kdy je model vytvoÅ™en pro nÃ¡hradnÃ­ Ãºlohu, pro kterou je dostatek dat, a pak se vÃ¡hy modelu (embeddingy) znovu vyuÅ¾Ã­vajÃ­ pro dalÅ¡Ã­ Ãºlohy. PÅ™Ã­kladem tÃ©to kategorie jsou [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.cs.png)

Modely generujÃ­cÃ­ obrÃ¡zky jsou modely, kterÃ© vytvÃ¡Å™ejÃ­ obrÃ¡zky. ÄŒasto se pouÅ¾Ã­vajÃ­ pro Ãºpravu obrÃ¡zkÅ¯, syntÃ©zu nebo pÅ™eklad obrÃ¡zkÅ¯. Jsou trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch obrÃ¡zkÅ¯, jako je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), a mohou generovat novÃ© obrÃ¡zky nebo upravovat existujÃ­cÃ­ pomocÃ­ technik jako inpainting, super-resolution a kolorovÃ¡nÃ­. PÅ™Ã­klady zahrnujÃ­ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) a [Stable Diffusion modely](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![GenerovÃ¡nÃ­ obrÃ¡zkÅ¯](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.cs.png)

Modely generujÃ­cÃ­ text a kÃ³d jsou modely, kterÃ© vytvÃ¡Å™ejÃ­ text nebo kÃ³d. ÄŒasto se pouÅ¾Ã­vajÃ­ pro shrnutÃ­ textu, pÅ™eklad nebo odpovÃ­dÃ¡nÃ­ na otÃ¡zky. TextovÃ© modely jsou trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch textu, jako je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), a mohou generovat novÃ½ text nebo odpovÃ­dat na otÃ¡zky. Modely generujÃ­cÃ­ kÃ³d, jako je [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), jsou trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch kÃ³du, napÅ™Ã­klad z GitHubu, a mohou generovat novÃ½ kÃ³d nebo opravovat chyby v existujÃ­cÃ­m kÃ³du.

![GenerovÃ¡nÃ­ textu a kÃ³du](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.cs.png)

### Encoder-Decoder versus pouze Decoder

Pro vysvÄ›tlenÃ­ rÅ¯znÃ½ch architektur LLM pouÅ¾ijme analogii.

PÅ™edstavte si, Å¾e vÃ¡m vÃ¡Å¡ manaÅ¾er zadal Ãºkol napsat kvÃ­z pro studenty. MÃ¡te dva kolegy; jeden se starÃ¡ o tvorbu obsahu a druhÃ½ o jeho kontrolu.

TvÅ¯rce obsahu je jako model pouze s Decoderem, mÅ¯Å¾e se podÃ­vat na tÃ©ma a vidÄ›t, co uÅ¾ jste napsali, a pak na zÃ¡kladÄ› toho napsat kurz. Jsou velmi dobÅ™Ã­ v psanÃ­ poutavÃ©ho a informativnÃ­ho obsahu, ale nejsou pÅ™Ã­liÅ¡ dobÅ™Ã­ v porozumÄ›nÃ­ tÃ©matu a vzdÄ›lÃ¡vacÃ­m cÃ­lÅ¯m. NÄ›kterÃ© pÅ™Ã­klady Decoder modelÅ¯ jsou modely rodiny GPT, napÅ™Ã­klad GPT-3.

Kontrolor je jako model pouze s Encoderem, podÃ­vÃ¡ se na napsanÃ½ kurz a odpovÄ›di, vÅ¡Ã­mÃ¡ si vztahÅ¯ mezi nimi a chÃ¡pe kontext, ale nenÃ­ dobrÃ½ v generovÃ¡nÃ­ obsahu. PÅ™Ã­kladem Encoder modelu je BERT.

PÅ™edstavte si, Å¾e bychom mohli mÃ­t nÄ›koho, kdo by mohl kvÃ­z jak vytvoÅ™it, tak zkontrolovat â€“ to je model Encoder-Decoder. NÄ›kterÃ© pÅ™Ã­klady jsou BART a T5.

### SluÅ¾ba versus Model

NynÃ­ si povÄ›zme rozdÃ­l mezi sluÅ¾bou a modelem. SluÅ¾ba je produkt nabÃ­zenÃ½ poskytovatelem cloudovÃ½ch sluÅ¾eb a Äasto kombinuje modely, data a dalÅ¡Ã­ komponenty. Model je jÃ¡drem sluÅ¾by a Äasto je to zÃ¡kladnÃ­ model, jako LLM.

SluÅ¾by jsou Äasto optimalizovanÃ© pro produkÄnÃ­ pouÅ¾itÃ­ a jsou obvykle snadnÄ›jÅ¡Ã­ na pouÅ¾Ã­vÃ¡nÃ­ neÅ¾ samotnÃ© modely, napÅ™Ã­klad pÅ™es grafickÃ© uÅ¾ivatelskÃ© rozhranÃ­. NicmÃ©nÄ› sluÅ¾by nejsou vÅ¾dy zdarma a mohou vyÅ¾adovat pÅ™edplatnÃ© nebo platbu za pouÅ¾Ã­vÃ¡nÃ­, vÃ½mÄ›nou za vyuÅ¾itÃ­ vybavenÃ­ a zdrojÅ¯ poskytovatele sluÅ¾by, optimalizaci nÃ¡kladÅ¯ a snadnÃ© Å¡kÃ¡lovÃ¡nÃ­. PÅ™Ã­kladem sluÅ¾by je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), kterÃ¡ nabÃ­zÃ­ tarif pay-as-you-go, tedy uÅ¾ivatelÃ© platÃ­ podle toho, kolik sluÅ¾bu vyuÅ¾ijÃ­. Azure OpenAI Service takÃ© nabÃ­zÃ­ bezpeÄnost na Ãºrovni podniku a rÃ¡mec odpovÄ›dnÃ©ho vyuÅ¾itÃ­ AI nad schopnostmi modelÅ¯.

Modely jsou pouze neuronovÃ© sÃ­tÄ› s parametry, vÃ¡hami a dalÅ¡Ã­mi prvky. Firmy si je mohou provozovat lokÃ¡lnÄ›, ale musÃ­ si poÅ™Ã­dit vybavenÃ­, vybudovat infrastrukturu pro Å¡kÃ¡lovÃ¡nÃ­ a koupit licenci nebo pouÅ¾Ã­t open source model. Model jako LLaMA je dostupnÃ½ k pouÅ¾itÃ­, ale vyÅ¾aduje vÃ½poÄetnÃ­ vÃ½kon pro bÄ›h modelu.

## Jak testovat a iterovat s rÅ¯znÃ½mi modely pro pochopenÃ­ vÃ½konu v Azure

Jakmile nÃ¡Å¡ tÃ½m prozkoumÃ¡ souÄasnÃ© prostÅ™edÃ­ LLM a vybere nÄ›kolik vhodnÃ½ch kandidÃ¡tÅ¯ pro svÃ© scÃ©nÃ¡Å™e, dalÅ¡Ã­m krokem je testovÃ¡nÃ­ tÄ›chto modelÅ¯ na svÃ½ch datech a zÃ¡tÄ›Å¾i. JednÃ¡ se o iterativnÃ­ proces, kterÃ½ probÃ­hÃ¡ pomocÃ­ experimentÅ¯ a mÄ›Å™enÃ­.
VÄ›tÅ¡ina modelÅ¯, kterÃ© jsme zmÃ­nili v pÅ™edchozÃ­ch odstavcÃ­ch (modely OpenAI, open source modely jako Llama2 a Hugging Face transformery) je dostupnÃ¡ v [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) v [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je cloudovÃ¡ platforma navrÅ¾enÃ¡ pro vÃ½vojÃ¡Å™e, kterÃ¡ umoÅ¾Åˆuje vytvÃ¡Å™et generativnÃ­ AI aplikace a spravovat celÃ½ vÃ½vojovÃ½ cyklus â€“ od experimentovÃ¡nÃ­ aÅ¾ po vyhodnocenÃ­ â€“ tÃ­m, Å¾e kombinuje vÅ¡echny Azure AI sluÅ¾by do jednoho centra s pÅ™ehlednÃ½m grafickÃ½m rozhranÃ­m. Model Catalog v Azure AI Studio umoÅ¾Åˆuje uÅ¾ivateli:

- NajÃ­t v katalogu zÃ¡kladnÃ­ model, kterÃ½ ho zajÃ­mÃ¡ â€“ aÅ¥ uÅ¾ proprietÃ¡rnÃ­ nebo open source, s moÅ¾nostÃ­ filtrovÃ¡nÃ­ podle Ãºkolu, licence nebo nÃ¡zvu. Pro lepÅ¡Ã­ vyhledÃ¡vÃ¡nÃ­ jsou modely uspoÅ™Ã¡dÃ¡ny do kolekcÃ­, jako je Azure OpenAI kolekce, Hugging Face kolekce a dalÅ¡Ã­.

![Model catalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.cs.png)

- ProhlÃ©dnout si model card, kterÃ¡ obsahuje podrobnÃ½ popis zamÃ½Å¡lenÃ©ho pouÅ¾itÃ­ a trÃ©ninkovÃ½ch dat, ukÃ¡zky kÃ³du a vÃ½sledky hodnocenÃ­ v internÃ­ knihovnÄ› evaluacÃ­.

![Model card](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.cs.png)

- Porovnat benchmarky napÅ™Ã­Ä modely a datovÃ½mi sadami dostupnÃ½mi v oboru, aby bylo moÅ¾nÃ© vyhodnotit, kterÃ½ model nejlÃ©pe vyhovuje konkrÃ©tnÃ­mu obchodnÃ­mu scÃ©nÃ¡Å™i, prostÅ™ednictvÃ­m panelu [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.cs.png)

- Doladit model na vlastnÃ­ch trÃ©ninkovÃ½ch datech, aby se zlepÅ¡il vÃ½kon modelu pro konkrÃ©tnÃ­ Ãºlohu, a vyuÅ¾Ã­t pÅ™itom moÅ¾nosti experimentovÃ¡nÃ­ a sledovÃ¡nÃ­ v Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.cs.png)

- Nasadit pÅ¯vodnÃ­ pÅ™edtrÃ©novanÃ½ model nebo jeho doladÄ›nou verzi na vzdÃ¡lenÃ½ real-time inference â€“ spravovanÃ½ vÃ½poÄetnÃ­ vÃ½kon â€“ nebo serverless API endpoint â€“ [pay-as-you-go](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) â€“ aby aplikace mohly model vyuÅ¾Ã­vat.

![Model deployment](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.cs.png)


> [!NOTE]
> Ne vÅ¡echny modely v katalogu jsou momentÃ¡lnÄ› dostupnÃ© pro doladÄ›nÃ­ a/nebo nasazenÃ­ na pay-as-you-go bÃ¡zi. Podrobnosti o moÅ¾nostech a omezenÃ­ch modelu najdete v model card.

## ZlepÅ¡ovÃ¡nÃ­ vÃ½sledkÅ¯ LLM

S naÅ¡Ã­m startupovÃ½m tÃ½mem jsme zkoumali rÅ¯znÃ© typy LLM a cloudovou platformu (Azure Machine Learning), kterÃ¡ nÃ¡m umoÅ¾Åˆuje porovnÃ¡vat rÅ¯znÃ© modely, hodnotit je na testovacÃ­ch datech, zlepÅ¡ovat jejich vÃ½kon a nasazovat je na inference endpointy.

Kdy by ale mÄ›li zvÃ¡Å¾it doladÄ›nÃ­ modelu mÃ­sto pouÅ¾itÃ­ pÅ™edtrÃ©novanÃ©ho? ExistujÃ­ i jinÃ© zpÅ¯soby, jak zlepÅ¡it vÃ½kon modelu pro konkrÃ©tnÃ­ Ãºlohy?

Podniky mohou vyuÅ¾Ã­t nÄ›kolik pÅ™Ã­stupÅ¯, jak zÃ­skat poÅ¾adovanÃ© vÃ½sledky z LLM. PÅ™i nasazenÃ­ LLM do produkce lze vybrat rÅ¯znÃ© typy modelÅ¯ s rÅ¯znou mÃ­rou trÃ©ninku, rÅ¯znou sloÅ¾itostÃ­, nÃ¡klady a kvalitou. Zde jsou nÄ›kterÃ© z moÅ¾nostÃ­:

- **Prompt engineering s kontextem**. Jde o to poskytnout dostatek kontextu v promptu, aby odpovÄ›di odpovÃ­daly poÅ¾adavkÅ¯m.

- **Retrieval Augmented Generation, RAG**. VaÅ¡e data mohou bÃ½t napÅ™Ã­klad v databÃ¡zi nebo na webovÃ©m endpointu. Aby se tato data nebo jejich ÄÃ¡st zahrnula do promptu, mÅ¯Å¾ete vyhledat relevantnÃ­ informace a pÅ™idat je do promptu uÅ¾ivatele.

- **DoladÄ›nÃ½ model**. Model je dÃ¡le trÃ©novÃ¡n na vlastnÃ­ch datech, coÅ¾ vede k pÅ™esnÄ›jÅ¡Ã­m a citlivÄ›jÅ¡Ã­m odpovÄ›dÃ­m na vaÅ¡e potÅ™eby, ale mÅ¯Å¾e to bÃ½t nÃ¡kladnÄ›jÅ¡Ã­.

![LLMs deployment](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.cs.png)

Zdroj obrÃ¡zku: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering s kontextem

PÅ™edtrÃ©novanÃ© LLM fungujÃ­ velmi dobÅ™e u obecnÃ½ch Ãºloh zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka, i kdyÅ¾ je zavolÃ¡te s krÃ¡tkÃ½m promptem, napÅ™Ã­klad vÄ›tou k doplnÄ›nÃ­ nebo otÃ¡zkou â€“ tzv. â€zero-shotâ€œ uÄenÃ­.

ÄŒÃ­m vÃ­ce uÅ¾ivatel dokÃ¡Å¾e svÅ¯j dotaz rÃ¡movat podrobnou Å¾Ã¡dostÃ­ a pÅ™Ã­klady â€“ tedy kontextem â€“ tÃ­m pÅ™esnÄ›jÅ¡Ã­ a blÃ­Å¾e oÄekÃ¡vÃ¡nÃ­m uÅ¾ivatele bude odpovÄ›Ä. V tomto pÅ™Ã­padÄ› mluvÃ­me o â€one-shotâ€œ uÄenÃ­, pokud prompt obsahuje pouze jeden pÅ™Ã­klad, a o â€few-shotâ€œ uÄenÃ­, pokud obsahuje vÃ­ce pÅ™Ã­kladÅ¯.
Prompt engineering s kontextem je nejefektivnÄ›jÅ¡Ã­ a nejlevnÄ›jÅ¡Ã­ zpÅ¯sob, jak zaÄÃ­t.

### Retrieval Augmented Generation (RAG)

LLM majÃ­ omezenÃ­, Å¾e mohou pouÅ¾Ã­t pouze data, kterÃ¡ byla pouÅ¾ita bÄ›hem jejich trÃ©ninku k vytvoÅ™enÃ­ odpovÄ›di. To znamenÃ¡, Å¾e neznajÃ­ fakta, kterÃ¡ nastala po jejich trÃ©ninku, a nemajÃ­ pÅ™Ã­stup k neveÅ™ejnÃ½m informacÃ­m (napÅ™Ã­klad firemnÃ­m datÅ¯m).
Toto omezenÃ­ lze pÅ™ekonat pomocÃ­ RAG, techniky, kterÃ¡ rozÅ¡iÅ™uje prompt o externÃ­ data ve formÄ› ÃºryvkÅ¯ dokumentÅ¯, pÅ™iÄemÅ¾ bere v Ãºvahu limit dÃ©lky promptu. PodporujÃ­ to nÃ¡stroje pro vektorovÃ© databÃ¡ze (napÅ™Ã­klad [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), kterÃ© vyhledÃ¡vajÃ­ uÅ¾iteÄnÃ© Ãºryvky z rÅ¯znÃ½ch pÅ™eddefinovanÃ½ch zdrojÅ¯ dat a pÅ™idÃ¡vajÃ­ je do kontextu promptu.

Tato technika je velmi uÅ¾iteÄnÃ¡, kdyÅ¾ podnik nemÃ¡ dostatek dat, Äasu nebo zdrojÅ¯ na doladÄ›nÃ­ LLM, ale pÅ™esto chce zlepÅ¡it vÃ½kon pro konkrÃ©tnÃ­ Ãºlohu a snÃ­Å¾it riziko vymyÅ¡lenÃ½ch informacÃ­, tedy zkreslenÃ­ reality nebo Å¡kodlivÃ©ho obsahu.

### DoladÄ›nÃ½ model

DoladÄ›nÃ­ je proces, kterÃ½ vyuÅ¾Ã­vÃ¡ transfer learning k â€pÅ™izpÅ¯sobenÃ­â€œ modelu konkrÃ©tnÃ­mu Ãºkolu nebo Å™eÅ¡enÃ­ specifickÃ©ho problÃ©mu. Na rozdÃ­l od few-shot uÄenÃ­ a RAG vede k vytvoÅ™enÃ­ novÃ©ho modelu s aktualizovanÃ½mi vÃ¡hami a biasy. VyÅ¾aduje sadu trÃ©ninkovÃ½ch pÅ™Ã­kladÅ¯, kterÃ© obsahujÃ­ vstup (prompt) a odpovÃ­dajÃ­cÃ­ vÃ½stup (dokonÄenÃ­).
Tento pÅ™Ã­stup je vhodnÃ½, pokud:

- **PouÅ¾Ã­vÃ¡te doladÄ›nÃ© modely**. Podnik chce pouÅ¾Ã­vat doladÄ›nÃ© mÃ©nÄ› vÃ½konnÃ© modely (napÅ™Ã­klad embedding modely) mÃ­sto vysoce vÃ½konnÃ½ch, coÅ¾ vede k ÃºspornÄ›jÅ¡Ã­mu a rychlejÅ¡Ã­mu Å™eÅ¡enÃ­.

- **ZohledÅˆujete latenci**. Latence je dÅ¯leÅ¾itÃ¡ pro konkrÃ©tnÃ­ pÅ™Ã­pad pouÅ¾itÃ­, takÅ¾e nenÃ­ moÅ¾nÃ© pouÅ¾Ã­t pÅ™Ã­liÅ¡ dlouhÃ© prompty nebo poÄet pÅ™Ã­kladÅ¯, kterÃ© by model mÄ›l nauÄit, nevyhovuje limitu dÃ©lky promptu.

- **Chcete bÃ½t aktuÃ¡lnÃ­**. Podnik mÃ¡ velkÃ© mnoÅ¾stvÃ­ kvalitnÃ­ch dat a sprÃ¡vnÃ½ch oznaÄenÃ­ a zdroje potÅ™ebnÃ© k udrÅ¾ovÃ¡nÃ­ tÄ›chto dat aktuÃ¡lnÃ­ch v Äase.

### TrÃ©novanÃ½ model

TrÃ©novÃ¡nÃ­ LLM od zaÄÃ¡tku je bezpochyby nejnÃ¡roÄnÄ›jÅ¡Ã­ a nejsloÅ¾itÄ›jÅ¡Ã­ pÅ™Ã­stup, vyÅ¾adujÃ­cÃ­ obrovskÃ© mnoÅ¾stvÃ­ dat, zkuÅ¡enÃ© odbornÃ­ky a odpovÃ­dajÃ­cÃ­ vÃ½poÄetnÃ­ kapacitu. Tuto moÅ¾nost by mÄ›l podnik zvÃ¡Å¾it pouze v pÅ™Ã­padÄ›, Å¾e mÃ¡ domÃ©novÄ› specifickÃ½ pÅ™Ã­pad pouÅ¾itÃ­ a velkÃ© mnoÅ¾stvÃ­ dat zamÄ›Å™enÃ½ch na danou oblast.

## Kontrola znalostÃ­

Co by mohl bÃ½t dobrÃ½ pÅ™Ã­stup ke zlepÅ¡enÃ­ vÃ½sledkÅ¯ dokonÄovÃ¡nÃ­ LLM?

1. Prompt engineering s kontextem  
1. RAG  
1. DoladÄ›nÃ½ model

OdpovÄ›Ä: 3, pokud mÃ¡te Äas, zdroje a kvalitnÃ­ data, doladÄ›nÃ­ je lepÅ¡Ã­ volba pro udrÅ¾enÃ­ aktuÃ¡lnosti. Pokud ale chcete vÄ›ci zlepÅ¡it a nemÃ¡te dost Äasu, stojÃ­ za to nejdÅ™Ã­ve zvÃ¡Å¾it RAG.

## ğŸš€ VÃ½zva

PÅ™eÄtÄ›te si vÃ­ce o tom, jak mÅ¯Å¾ete [vyuÅ¾Ã­t RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pro vaÅ¡e podnikÃ¡nÃ­.

## SkvÄ›lÃ¡ prÃ¡ce, pokraÄujte ve vzdÄ›lÃ¡vÃ¡nÃ­

Po dokonÄenÃ­ tÃ©to lekce si prohlÃ©dnÄ›te naÅ¡i [kolekci Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) a pokraÄujte ve zvyÅ¡ovÃ¡nÃ­ svÃ½ch znalostÃ­ o generativnÃ­ AI!

PÅ™ejdÄ›te do Lekce 3, kde se podÃ­vÃ¡me na to, jak [budovat s generativnÃ­ AI zodpovÄ›dnÄ›](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**ProhlÃ¡Å¡enÃ­ o vylouÄenÃ­ odpovÄ›dnosti**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ AI pÅ™ekladatelskÃ© sluÅ¾by [Co-op Translator](https://github.com/Azure/co-op-translator). I kdyÅ¾ usilujeme o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatizovanÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho mateÅ™skÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme odpovÄ›dnÃ­ za jakÃ©koliv nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© vÃ½klady vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.