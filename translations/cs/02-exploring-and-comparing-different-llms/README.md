<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "6b7629b8ee4d7d874a27213e903d86a7",
  "translation_date": "2025-10-17T21:39:30+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "cs"
}
-->
# ZkoumÃ¡nÃ­ a porovnÃ¡vÃ¡nÃ­ rÅ¯znÃ½ch LLM

[![ZkoumÃ¡nÃ­ a porovnÃ¡vÃ¡nÃ­ rÅ¯znÃ½ch LLM](../../../translated_images/02-lesson-banner.ef94c84979f97f60f07e27d905e708cbcbdf78707120553ccab27d91c947805b.cs.png)](https://youtu.be/KIRUeDKscfI?si=8BHX1zvwzQBn-PlK)

> _KliknÄ›te na obrÃ¡zek vÃ½Å¡e pro zhlÃ©dnutÃ­ videa tÃ©to lekce_

V pÅ™edchozÃ­ lekci jsme vidÄ›li, jak GenerativnÃ­ AI mÄ›nÃ­ technologickÃ© prostÅ™edÃ­, jak fungujÃ­ velkÃ© jazykovÃ© modely (LLM) a jak je mÅ¯Å¾e firma - jako nÃ¡Å¡ startup - aplikovat na svÃ© pÅ™Ã­pady pouÅ¾itÃ­ a rÅ¯st! V tÃ©to kapitole se zamÄ›Å™Ã­me na porovnÃ¡nÃ­ rÅ¯znÃ½ch typÅ¯ velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), abychom pochopili jejich vÃ½hody a nevÃ½hody.

DalÅ¡Ã­m krokem na cestÄ› naÅ¡eho startupu je prozkoumÃ¡nÃ­ souÄasnÃ©ho prostÅ™edÃ­ LLM a pochopenÃ­, kterÃ© z nich jsou vhodnÃ© pro nÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­.

## Ãšvod

Tato lekce pokryje:

- RÅ¯znÃ© typy LLM v souÄasnÃ©m prostÅ™edÃ­.
- TestovÃ¡nÃ­, iteraci a porovnÃ¡vÃ¡nÃ­ rÅ¯znÃ½ch modelÅ¯ pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­ v Azure.
- Jak nasadit LLM.

## CÃ­le uÄenÃ­

Po dokonÄenÃ­ tÃ©to lekce budete schopni:

- Vybrat sprÃ¡vnÃ½ model pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­.
- Pochopit, jak testovat, iterovat a zlepÅ¡ovat vÃ½kon vaÅ¡eho modelu.
- VÄ›dÄ›t, jak firmy nasazujÃ­ modely.

## PochopenÃ­ rÅ¯znÃ½ch typÅ¯ LLM

LLM mohou bÃ½t kategorizovÃ¡ny podle jejich architektury, trÃ©ninkovÃ½ch dat a pÅ™Ã­padu pouÅ¾itÃ­. PochopenÃ­ tÄ›chto rozdÃ­lÅ¯ pomÅ¯Å¾e naÅ¡emu startupu vybrat sprÃ¡vnÃ½ model pro danÃ½ scÃ©nÃ¡Å™ a pochopit, jak testovat, iterovat a zlepÅ¡ovat vÃ½kon.

Existuje mnoho rÅ¯znÃ½ch typÅ¯ LLM modelÅ¯, vÃ½bÄ›r modelu zÃ¡visÃ­ na tom, k Äemu je chcete pouÅ¾Ã­t, na vaÅ¡ich datech, na tom, kolik jste ochotni zaplatit a dalÅ¡Ã­ch faktorech.

V zÃ¡vislosti na tom, zda chcete modely pouÅ¾Ã­t pro generovÃ¡nÃ­ textu, audia, videa, obrÃ¡zkÅ¯ a podobnÄ›, mÅ¯Å¾ete zvolit jinÃ½ typ modelu.

- **RozpoznÃ¡vÃ¡nÃ­ zvuku a Å™eÄi**. Pro tento ÃºÄel jsou modely typu Whisper skvÄ›lou volbou, protoÅ¾e jsou univerzÃ¡lnÃ­ a zamÄ›Å™enÃ© na rozpoznÃ¡vÃ¡nÃ­ Å™eÄi. Jsou trÃ©novÃ¡ny na rÅ¯znorodÃ©m zvuku a dokÃ¡Å¾ou provÃ¡dÄ›t vÃ­cejazyÄnÃ© rozpoznÃ¡vÃ¡nÃ­ Å™eÄi. VÃ­ce o [modelech typu Whisper zde](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **GenerovÃ¡nÃ­ obrÃ¡zkÅ¯**. Pro generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou dvÄ› velmi znÃ¡mÃ© volby DALL-E a Midjourney. DALL-E je nabÃ­zeno sluÅ¾bou Azure OpenAI. [PÅ™eÄtÄ›te si vÃ­ce o DALL-E zde](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) a takÃ© v kapitole 9 tohoto kurzu.

- **GenerovÃ¡nÃ­ textu**. VÄ›tÅ¡ina modelÅ¯ je trÃ©novÃ¡na na generovÃ¡nÃ­ textu a mÃ¡te Å¡irokou Å¡kÃ¡lu moÅ¾nostÃ­ od GPT-3.5 po GPT-4. PÅ™ichÃ¡zejÃ­ s rÅ¯znÃ½mi nÃ¡klady, pÅ™iÄemÅ¾ GPT-4 je nejdraÅ¾Å¡Ã­. StojÃ­ za to podÃ­vat se na [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), abyste vyhodnotili, kterÃ© modely nejlÃ©pe vyhovujÃ­ vaÅ¡im potÅ™ebÃ¡m z hlediska schopnostÃ­ a nÃ¡kladÅ¯.

- **Multimodalita**. Pokud chcete pracovat s vÃ­ce typy dat na vstupu a vÃ½stupu, mÅ¯Å¾ete se podÃ­vat na modely jako [gpt-4 turbo s vizÃ­ nebo gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - nejnovÄ›jÅ¡Ã­ verze modelÅ¯ OpenAI - kterÃ© dokÃ¡Å¾ou kombinovat zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka s vizuÃ¡lnÃ­m porozumÄ›nÃ­m, coÅ¾ umoÅ¾Åˆuje interakce prostÅ™ednictvÃ­m multimodÃ¡lnÃ­ch rozhranÃ­.

VÃ½bÄ›r modelu znamenÃ¡ zÃ­skÃ¡nÃ­ zÃ¡kladnÃ­ch schopnostÃ­, kterÃ© vÅ¡ak nemusÃ­ bÃ½t dostateÄnÃ©. ÄŒasto mÃ¡te firemnÃ­ specifickÃ¡ data, kterÃ¡ nÄ›jakÃ½m zpÅ¯sobem potÅ™ebujete sdÄ›lit LLM. Existuje nÄ›kolik rÅ¯znÃ½ch pÅ™Ã­stupÅ¯, jak to udÄ›lat, vÃ­ce o tom v nadchÃ¡zejÃ­cÃ­ch sekcÃ­ch.

### ZÃ¡kladnÃ­ modely versus LLM

TermÃ­n ZÃ¡kladnÃ­ model byl [zaveden vÃ½zkumnÃ­ky ze Stanfordu](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) a je definovÃ¡n jako AI model, kterÃ½ splÅˆuje nÄ›kterÃ¡ kritÃ©ria, napÅ™Ã­klad:

- **Jsou trÃ©novÃ¡ny pomocÃ­ neÅ™Ã­zenÃ©ho uÄenÃ­ nebo samostatnÄ› Å™Ã­zenÃ©ho uÄenÃ­**, coÅ¾ znamenÃ¡, Å¾e jsou trÃ©novÃ¡ny na neoznaÄenÃ½ch multimodÃ¡lnÃ­ch datech a nevyÅ¾adujÃ­ lidskÃ© anotace nebo oznaÄovÃ¡nÃ­ dat pro svÅ¯j trÃ©ninkovÃ½ proces.
- **Jsou velmi velkÃ© modely**, zaloÅ¾enÃ© na velmi hlubokÃ½ch neuronovÃ½ch sÃ­tÃ­ch trÃ©novanÃ½ch na miliardÃ¡ch parametrÅ¯.
- **Obvykle slouÅ¾Ã­ jako â€zÃ¡kladâ€œ pro jinÃ© modely**, coÅ¾ znamenÃ¡, Å¾e mohou bÃ½t pouÅ¾ity jako vÃ½chozÃ­ bod pro vytvoÅ™enÃ­ dalÅ¡Ã­ch modelÅ¯, coÅ¾ lze provÃ©st jemnÃ½m doladÄ›nÃ­m.

![ZÃ¡kladnÃ­ modely versus LLM](../../../translated_images/FoundationModel.e4859dbb7a825c94b284f17eae1c186aabc21d4d8644331f5b007d809cf8d0f2.cs.png)

Zdroj obrÃ¡zku: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium
](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pro dalÅ¡Ã­ objasnÄ›nÃ­ tohoto rozliÅ¡enÃ­ si vezmÄ›me jako pÅ™Ã­klad ChatGPT. Pro vytvoÅ™enÃ­ prvnÃ­ verze ChatGPT slouÅ¾il model GPT-3.5 jako zÃ¡kladnÃ­ model. To znamenÃ¡, Å¾e OpenAI pouÅ¾ilo nÄ›kterÃ¡ data specifickÃ¡ pro chat k vytvoÅ™enÃ­ upravenÃ© verze GPT-3.5, kterÃ¡ byla specializovÃ¡na na dobrÃ½ vÃ½kon v konverzaÄnÃ­ch scÃ©nÃ¡Å™Ã­ch, jako jsou chatboty.

![ZÃ¡kladnÃ­ model](../../../translated_images/Multimodal.2c389c6439e0fc51b0b7b226d95d7d900d372ae66902d71b8ce5ec4951b8efbe.cs.png)

Zdroj obrÃ¡zku: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### Open Source versus ProprietÃ¡rnÃ­ modely

DalÅ¡Ã­m zpÅ¯sobem kategorizace LLM je, zda jsou open source nebo proprietÃ¡rnÃ­.

Open-source modely jsou modely, kterÃ© jsou zpÅ™Ã­stupnÄ›ny veÅ™ejnosti a mohou bÃ½t pouÅ¾ity kÃ½mkoli. ÄŒasto jsou zpÅ™Ã­stupnÄ›ny spoleÄnostÃ­, kterÃ¡ je vytvoÅ™ila, nebo vÃ½zkumnou komunitou. Tyto modely mohou bÃ½t prohlÃ­Å¾eny, upravovÃ¡ny a pÅ™izpÅ¯sobovÃ¡ny pro rÅ¯znÃ© pÅ™Ã­pady pouÅ¾itÃ­ v LLM. NicmÃ©nÄ› nejsou vÅ¾dy optimalizovÃ¡ny pro produkÄnÃ­ pouÅ¾itÃ­ a nemusÃ­ bÃ½t tak vÃ½konnÃ© jako proprietÃ¡rnÃ­ modely. NavÃ­c financovÃ¡nÃ­ open-source modelÅ¯ mÅ¯Å¾e bÃ½t omezenÃ©, nemusÃ­ bÃ½t dlouhodobÄ› udrÅ¾ovÃ¡ny nebo aktualizovÃ¡ny s nejnovÄ›jÅ¡Ã­m vÃ½zkumem. PÅ™Ã­klady populÃ¡rnÃ­ch open-source modelÅ¯ zahrnujÃ­ [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) a [LLaMA](https://llama.meta.com).

ProprietÃ¡rnÃ­ modely jsou modely, kterÃ© vlastnÃ­ spoleÄnost a nejsou zpÅ™Ã­stupnÄ›ny veÅ™ejnosti. Tyto modely jsou Äasto optimalizovÃ¡ny pro produkÄnÃ­ pouÅ¾itÃ­. NicmÃ©nÄ› nenÃ­ dovoleno je prohlÃ­Å¾et, upravovat nebo pÅ™izpÅ¯sobovat pro rÅ¯znÃ© pÅ™Ã­pady pouÅ¾itÃ­. NavÃ­c nejsou vÅ¾dy dostupnÃ© zdarma a mohou vyÅ¾adovat pÅ™edplatnÃ© nebo platbu za pouÅ¾itÃ­. UÅ¾ivatelÃ© takÃ© nemajÃ­ kontrolu nad daty, kterÃ¡ jsou pouÅ¾ita k trÃ©novÃ¡nÃ­ modelu, coÅ¾ znamenÃ¡, Å¾e by mÄ›li dÅ¯vÄ›Å™ovat vlastnÃ­kovi modelu, Å¾e zajistÃ­ zÃ¡vazek k ochranÄ› dat a odpovÄ›dnÃ©mu pouÅ¾Ã­vÃ¡nÃ­ AI. PÅ™Ã­klady populÃ¡rnÃ­ch proprietÃ¡rnÃ­ch modelÅ¯ zahrnujÃ­ [OpenAI modely](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) nebo [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus GenerovÃ¡nÃ­ obrÃ¡zkÅ¯ versus GenerovÃ¡nÃ­ textu a kÃ³du

LLM mohou bÃ½t takÃ© kategorizovÃ¡ny podle vÃ½stupu, kterÃ½ generujÃ­.

Embeddings jsou sada modelÅ¯, kterÃ© dokÃ¡Å¾ou pÅ™evÃ©st text do numerickÃ© podoby, nazÃ½vanÃ© embedding, coÅ¾ je numerickÃ¡ reprezentace vstupnÃ­ho textu. Embeddings usnadÅˆujÃ­ strojÅ¯m pochopenÃ­ vztahÅ¯ mezi slovy nebo vÄ›tami a mohou bÃ½t pouÅ¾ity jako vstupy pro jinÃ© modely, jako jsou klasifikaÄnÃ­ modely nebo modely shlukovÃ¡nÃ­, kterÃ© majÃ­ lepÅ¡Ã­ vÃ½kon na numerickÃ½ch datech. Embedding modely se Äasto pouÅ¾Ã­vajÃ­ pro transfer learning, kde je model vytvoÅ™en pro nÃ¡hradnÃ­ Ãºkol, pro kterÃ½ je dostatek dat, a potÃ© jsou vÃ¡hy modelu (embeddings) znovu pouÅ¾ity pro jinÃ© nÃ¡slednÃ© Ãºkoly. PÅ™Ã­kladem tÃ©to kategorie je [OpenAI embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![Embedding](../../../translated_images/Embedding.c3708fe988ccf76073d348483dbb7569f622211104f073e22e43106075c04800.cs.png)

Modely generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou modely, kterÃ© generujÃ­ obrÃ¡zky. Tyto modely se Äasto pouÅ¾Ã­vajÃ­ pro Ãºpravy obrÃ¡zkÅ¯, syntÃ©zu obrÃ¡zkÅ¯ a pÅ™eklad obrÃ¡zkÅ¯. Modely generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou Äasto trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch obrÃ¡zkÅ¯, jako je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), a mohou bÃ½t pouÅ¾ity k vytvÃ¡Å™enÃ­ novÃ½ch obrÃ¡zkÅ¯ nebo k ÃºpravÄ› existujÃ­cÃ­ch obrÃ¡zkÅ¯ pomocÃ­ technik jako inpainting, super-rozliÅ¡enÃ­ a kolorovÃ¡nÃ­. PÅ™Ã­klady zahrnujÃ­ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) a [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![GenerovÃ¡nÃ­ obrÃ¡zkÅ¯](../../../translated_images/Image.349c080266a763fd255b840a921cd8fc526ed78dc58708fa569ff1873d302345.cs.png)

Modely generovÃ¡nÃ­ textu a kÃ³du jsou modely, kterÃ© generujÃ­ text nebo kÃ³d. Tyto modely se Äasto pouÅ¾Ã­vajÃ­ pro sumarizaci textu, pÅ™eklad a odpovÃ­dÃ¡nÃ­ na otÃ¡zky. Modely generovÃ¡nÃ­ textu jsou Äasto trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch textu, jako je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), a mohou bÃ½t pouÅ¾ity k vytvÃ¡Å™enÃ­ novÃ©ho textu nebo k odpovÃ­dÃ¡nÃ­ na otÃ¡zky. Modely generovÃ¡nÃ­ kÃ³du, jako [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), jsou Äasto trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch kÃ³du, jako je GitHub, a mohou bÃ½t pouÅ¾ity k vytvÃ¡Å™enÃ­ novÃ©ho kÃ³du nebo k opravÄ› chyb v existujÃ­cÃ­m kÃ³du.

![GenerovÃ¡nÃ­ textu a kÃ³du](../../../translated_images/Text.a8c0cf139e5cc2a0cd3edaba8d675103774e6ddcb3c9fc5a98bb17c9a450e31d.cs.png)

### Encoder-Decoder versus Pouze Decoder

Abychom mohli hovoÅ™it o rÅ¯znÃ½ch typech architektur LLM, pouÅ¾ijme analogii.

PÅ™edstavte si, Å¾e vÃ¡m vÃ¡Å¡ nadÅ™Ã­zenÃ½ zadal Ãºkol napsat kvÃ­z pro studenty. MÃ¡te dva kolegy; jeden se starÃ¡ o tvorbu obsahu a druhÃ½ o jeho kontrolu.

TvÅ¯rce obsahu je jako model pouze Decoder, mÅ¯Å¾e se podÃ­vat na tÃ©ma a na to, co jste jiÅ¾ napsali, a na zÃ¡kladÄ› toho vytvoÅ™it kurz. Jsou velmi dobÅ™Ã­ v psanÃ­ poutavÃ©ho a informativnÃ­ho obsahu, ale nejsou pÅ™Ã­liÅ¡ dobÅ™Ã­ v pochopenÃ­ tÃ©matu a vzdÄ›lÃ¡vacÃ­ch cÃ­lÅ¯. NÄ›kterÃ© pÅ™Ã­klady modelÅ¯ pouze Decoder jsou modely rodiny GPT, jako je GPT-3.

Recenzent je jako model pouze Encoder, podÃ­vÃ¡ se na napsanÃ½ kurz a odpovÄ›di, vÅ¡imne si vztahu mezi nimi a pochopÃ­ kontext, ale nenÃ­ dobrÃ½ v generovÃ¡nÃ­ obsahu. PÅ™Ã­kladem modelu pouze Encoder by byl BERT.

PÅ™edstavte si, Å¾e bychom mohli mÃ­t nÄ›koho, kdo by mohl kvÃ­z vytvoÅ™it i zkontrolovat, to je model Encoder-Decoder. NÄ›kterÃ© pÅ™Ã­klady by byly BART a T5.

### SluÅ¾ba versus Model

NynÃ­ si povÃ­me o rozdÃ­lu mezi sluÅ¾bou a modelem. SluÅ¾ba je produkt, kterÃ½ je nabÃ­zen poskytovatelem cloudovÃ½ch sluÅ¾eb a Äasto je kombinacÃ­ modelÅ¯, dat a dalÅ¡Ã­ch komponent. Model je zÃ¡kladnÃ­ souÄÃ¡stÃ­ sluÅ¾by a Äasto je zÃ¡kladnÃ­m modelem, jako je LLM.

SluÅ¾by jsou Äasto optimalizovÃ¡ny pro produkÄnÃ­ pouÅ¾itÃ­ a Äasto se snadnÄ›ji pouÅ¾Ã­vajÃ­ neÅ¾ modely, prostÅ™ednictvÃ­m grafickÃ©ho uÅ¾ivatelskÃ©ho rozhranÃ­. NicmÃ©nÄ› sluÅ¾by nejsou vÅ¾dy dostupnÃ© zdarma a mohou vyÅ¾adovat pÅ™edplatnÃ© nebo platbu za pouÅ¾itÃ­, vÃ½mÄ›nou za vyuÅ¾itÃ­ vybavenÃ­ a zdrojÅ¯ vlastnÃ­ka sluÅ¾by, optimalizaci nÃ¡kladÅ¯ a snadnÃ© Å¡kÃ¡lovÃ¡nÃ­. PÅ™Ã­kladem sluÅ¾by je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), kterÃ¡ nabÃ­zÃ­ plÃ¡n plateb podle vyuÅ¾itÃ­, coÅ¾ znamenÃ¡, Å¾e uÅ¾ivatelÃ© jsou ÃºÄtovÃ¡ni ÃºmÄ›rnÄ› tomu, kolik sluÅ¾bu vyuÅ¾Ã­vajÃ­. NavÃ­c Azure OpenAI Service nabÃ­zÃ­ bezpeÄnost na Ãºrovni podniku a rÃ¡mec odpovÄ›dnÃ© AI nad schopnostmi modelÅ¯.

Modely jsou pouze neuronovÃ¡ sÃ­Å¥, s parametry, vÃ¡hami a dalÅ¡Ã­mi. UmoÅ¾ÅˆujÃ­ firmÃ¡m provozovat lokÃ¡lnÄ›, avÅ¡ak vyÅ¾adujÃ­ nÃ¡kup vybavenÃ­, vytvoÅ™enÃ­ struktury pro Å¡kÃ¡lovÃ¡nÃ­ a zakoupenÃ­ licence nebo pouÅ¾itÃ­ open-source modelu. Model jako LLaMA je dostupnÃ½ k pouÅ¾itÃ­, vyÅ¾aduje vÅ¡ak vÃ½poÄetnÃ­ vÃ½kon pro provoz modelu.

## Jak testovat a iterovat s rÅ¯znÃ½mi modely pro pochopenÃ­ vÃ½konu v Azure

Jakmile nÃ¡Å¡ tÃ½m prozkoumÃ¡ souÄasnÃ© prostÅ™edÃ­ LLM a identifikuje nÄ›kterÃ© dobrÃ© kandidÃ¡ty pro svÃ© scÃ©nÃ¡Å™e, dalÅ¡Ã­m krokem je jejich testovÃ¡nÃ­ na vlastnÃ­ch datech a pracovnÃ­ch zÃ¡tÄ›Å¾Ã­ch. JednÃ¡ se o iterativnÃ­ proces, kterÃ½ se provÃ¡dÃ­ prostÅ™ednictvÃ­m experimentÅ¯ a mÄ›Å™enÃ­.
VÄ›tÅ¡ina modelÅ¯, kterÃ© jsme zmÃ­nili v pÅ™edchozÃ­ch odstavcÃ­ch (modely OpenAI, open source modely jako Llama2 a Hugging Face transformers), je dostupnÃ¡ v [ModelovÃ©m katalogu](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) v [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je cloudovÃ¡ platforma navrÅ¾enÃ¡ pro vÃ½vojÃ¡Å™e, kteÅ™Ã­ chtÄ›jÃ­ vytvÃ¡Å™et aplikace generativnÃ­ AI a spravovat celÃ½ vÃ½vojovÃ½ cyklus â€“ od experimentovÃ¡nÃ­ po hodnocenÃ­ â€“ kombinacÃ­ vÅ¡ech sluÅ¾eb Azure AI do jednoho centra s praktickÃ½m grafickÃ½m rozhranÃ­m. ModelovÃ½ katalog v Azure AI Studio umoÅ¾Åˆuje uÅ¾ivatelÅ¯m:

- NajÃ­t zÃ¡kladnÃ­ model, kterÃ½ je zajÃ­mÃ¡, v katalogu â€“ aÅ¥ uÅ¾ proprietÃ¡rnÃ­ nebo open source, s moÅ¾nostÃ­ filtrovÃ¡nÃ­ podle Ãºkolu, licence nebo nÃ¡zvu. Pro zlepÅ¡enÃ­ vyhledÃ¡vÃ¡nÃ­ jsou modely organizovÃ¡ny do kolekcÃ­, jako je kolekce Azure OpenAI, kolekce Hugging Face a dalÅ¡Ã­.

![ModelovÃ½ katalog](../../../translated_images/AzureAIStudioModelCatalog.3cf8a499aa8ba0314f2c73d4048b3225d324165f547525f5b7cfa5f6c9c68941.cs.png)

- ProhlÃ©dnout si kartu modelu, kterÃ¡ obsahuje podrobnÃ½ popis zamÃ½Å¡lenÃ©ho pouÅ¾itÃ­ a trÃ©ninkovÃ½ch dat, ukÃ¡zky kÃ³du a vÃ½sledky hodnocenÃ­ z internÃ­ knihovny hodnocenÃ­.

![Karta modelu](../../../translated_images/ModelCard.598051692c6e400d681a713ba7717e8b6e5e65f08d12131556fcec0f1789459b.cs.png)

- Porovnat benchmarky napÅ™Ã­Ä modely a datovÃ½mi sadami dostupnÃ½mi v prÅ¯myslu, aby bylo moÅ¾nÃ© posoudit, kterÃ½ model nejlÃ©pe odpovÃ­dÃ¡ obchodnÃ­mu scÃ©nÃ¡Å™i, prostÅ™ednictvÃ­m panelu [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Benchmarky modelÅ¯](../../../translated_images/ModelBenchmarks.254cb20fbd06c03a4ca53994585c5ea4300a88bcec8eff0450f2866ee2ac5ff3.cs.png)

- Doladit model na vlastnÃ­ch trÃ©ninkovÃ½ch datech, aby se zlepÅ¡il vÃ½kon modelu v konkrÃ©tnÃ­ pracovnÃ­ zÃ¡tÄ›Å¾i, s vyuÅ¾itÃ­m experimentÃ¡lnÃ­ch a sledovacÃ­ch schopnostÃ­ Azure AI Studio.

![DoladÄ›nÃ­ modelu](../../../translated_images/FineTuning.aac48f07142e36fddc6571b1f43ea2e003325c9c6d8e3fc9d8834b771e308dbf.cs.png)

- Nasadit pÅ¯vodnÃ­ pÅ™edtrÃ©novanÃ½ model nebo doladÄ›nou verzi na vzdÃ¡lenÃ© rozhranÃ­ pro inferenci v reÃ¡lnÃ©m Äase â€“ spravovanÃ½ vÃ½poÄetnÃ­ vÃ½kon â€“ nebo serverless API endpoint â€“ [platba za pouÅ¾itÃ­](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) â€“ aby aplikace mohly model vyuÅ¾Ã­vat.

![NasazenÃ­ modelu](../../../translated_images/ModelDeploy.890da48cbd0bccdb4abfc9257f3d884831e5d41b723e7d1ceeac9d60c3c4f984.cs.png)

> [!NOTE]
> Ne vÅ¡echny modely v katalogu jsou aktuÃ¡lnÄ› dostupnÃ© pro doladÄ›nÃ­ a/nebo nasazenÃ­ s platbou za pouÅ¾itÃ­. Podrobnosti o schopnostech a omezenÃ­ch modelu najdete na jeho kartÄ›.

## ZlepÅ¡enÃ­ vÃ½sledkÅ¯ LLM

S naÅ¡Ã­m startupovÃ½m tÃ½mem jsme prozkoumali rÅ¯znÃ© typy LLM a cloudovou platformu (Azure Machine Learning), kterÃ¡ nÃ¡m umoÅ¾Åˆuje porovnÃ¡vat rÅ¯znÃ© modely, hodnotit je na testovacÃ­ch datech, zlepÅ¡ovat jejich vÃ½kon a nasazovat je na inferenÄnÃ­ endpointy.

Kdy by mÄ›li zvÃ¡Å¾it doladÄ›nÃ­ modelu mÃ­sto pouÅ¾itÃ­ pÅ™edtrÃ©novanÃ©ho? ExistujÃ­ jinÃ© pÅ™Ã­stupy ke zlepÅ¡enÃ­ vÃ½konu modelu na specifickÃ½ch pracovnÃ­ch zÃ¡tÄ›Å¾Ã­ch?

Existuje nÄ›kolik pÅ™Ã­stupÅ¯, kterÃ© mÅ¯Å¾e firma pouÅ¾Ã­t k dosaÅ¾enÃ­ poÅ¾adovanÃ½ch vÃ½sledkÅ¯ z LLM. PÅ™i nasazovÃ¡nÃ­ LLM do produkce mÅ¯Å¾ete vybÃ­rat rÅ¯znÃ© typy modelÅ¯ s rÅ¯znÃ½mi stupni trÃ©ninku, s rÅ¯znou ÃºrovnÃ­ sloÅ¾itosti, nÃ¡kladÅ¯ a kvality. Zde jsou nÄ›kterÃ© pÅ™Ã­stupy:

- **Prompt engineering s kontextem**. CÃ­lem je poskytnout dostatek kontextu pÅ™i zadÃ¡vÃ¡nÃ­ promptu, aby bylo zajiÅ¡tÄ›no, Å¾e dostanete poÅ¾adovanÃ© odpovÄ›di.

- **Retrieval Augmented Generation, RAG**. VaÅ¡e data mohou bÃ½t napÅ™Ã­klad v databÃ¡zi nebo na webovÃ©m endpointu. Aby byla tato data nebo jejich podmnoÅ¾ina zahrnuta pÅ™i zadÃ¡vÃ¡nÃ­ promptu, mÅ¯Å¾ete relevantnÃ­ data naÄÃ­st a pÅ™idat je do promptu uÅ¾ivatele.

- **DoladÄ›nÃ½ model**. Zde model dÃ¡le trÃ©nujete na vlastnÃ­ch datech, coÅ¾ vede k tomu, Å¾e model je pÅ™esnÄ›jÅ¡Ã­ a lÃ©pe reaguje na vaÅ¡e potÅ™eby, ale mÅ¯Å¾e bÃ½t nÃ¡kladnÃ½.

![NasazenÃ­ LLM](../../../translated_images/Deploy.18b2d27412ec8c02871386cbe91097c7f2190a8c6e2be88f66392b411609a48c.cs.png)

Zdroj obrÃ¡zku: [ÄŒtyÅ™i zpÅ¯soby, jak firmy nasazujÃ­ LLM | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt engineering s kontextem

PÅ™edtrÃ©novanÃ© LLM fungujÃ­ velmi dobÅ™e na obecnÃ© Ãºkoly v oblasti pÅ™irozenÃ©ho jazyka, i kdyÅ¾ je volÃ¡te s krÃ¡tkÃ½m promptem, napÅ™Ã­klad vÄ›tou k dokonÄenÃ­ nebo otÃ¡zkou â€“ tzv. â€zero-shotâ€œ uÄenÃ­.

NicmÃ©nÄ› ÄÃ­m vÃ­ce uÅ¾ivatel dokÃ¡Å¾e formulovat svÅ¯j dotaz, s podrobnÃ½m poÅ¾adavkem a pÅ™Ã­klady â€“ tedy Kontextem â€“ tÃ­m pÅ™esnÄ›jÅ¡Ã­ a bliÅ¾Å¡Ã­ oÄekÃ¡vÃ¡nÃ­m uÅ¾ivatele bude odpovÄ›Ä. V tomto pÅ™Ã­padÄ› mluvÃ­me o â€one-shotâ€œ uÄenÃ­, pokud prompt obsahuje pouze jeden pÅ™Ã­klad, a o â€few-shotâ€œ uÄenÃ­, pokud obsahuje vÃ­ce pÅ™Ã­kladÅ¯. Prompt engineering s kontextem je nejefektivnÄ›jÅ¡Ã­ pÅ™Ã­stup pro zaÄÃ¡tek.

### Retrieval Augmented Generation (RAG)

LLM majÃ­ omezenÃ­ v tom, Å¾e mohou pouÅ¾Ã­vat pouze data, kterÃ¡ byla pouÅ¾ita bÄ›hem jejich trÃ©ninku k vytvoÅ™enÃ­ odpovÄ›di. To znamenÃ¡, Å¾e neznajÃ­ nic o faktech, kterÃ¡ se stala po jejich trÃ©ninkovÃ©m procesu, a nemohou pÅ™istupovat k neveÅ™ejnÃ½m informacÃ­m (napÅ™Ã­klad firemnÃ­m datÅ¯m).
Toto lze pÅ™ekonat pomocÃ­ RAG, techniky, kterÃ¡ rozÅ¡iÅ™uje prompt o externÃ­ data ve formÄ› ÄÃ¡stÃ­ dokumentÅ¯, s ohledem na limity dÃ©lky promptu. To je podporovÃ¡no nÃ¡stroji pro vektorovÃ© databÃ¡ze (jako [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), kterÃ© zÃ­skÃ¡vajÃ­ uÅ¾iteÄnÃ© ÄÃ¡sti z rÅ¯znÃ½ch pÅ™edem definovanÃ½ch datovÃ½ch zdrojÅ¯ a pÅ™idÃ¡vajÃ­ je do kontextu promptu.

Tato technika je velmi uÅ¾iteÄnÃ¡, kdyÅ¾ firma nemÃ¡ dostatek dat, Äasu nebo zdrojÅ¯ na doladÄ›nÃ­ LLM, ale pÅ™esto si pÅ™eje zlepÅ¡it vÃ½kon na specifickÃ© pracovnÃ­ zÃ¡tÄ›Å¾i a snÃ­Å¾it riziko mystifikacÃ­, tj. zkreslenÃ­ reality nebo Å¡kodlivÃ©ho obsahu.

### DoladÄ›nÃ½ model

DoladÄ›nÃ­ je proces, kterÃ½ vyuÅ¾Ã­vÃ¡ transferovÃ© uÄenÃ­ k â€pÅ™izpÅ¯sobenÃ­â€œ modelu na konkrÃ©tnÃ­ Ãºkol nebo k Å™eÅ¡enÃ­ specifickÃ©ho problÃ©mu. Na rozdÃ­l od few-shot uÄenÃ­ a RAG vede k vytvoÅ™enÃ­ novÃ©ho modelu s aktualizovanÃ½mi vÃ¡hami a biasy. VyÅ¾aduje sadu trÃ©ninkovÃ½ch pÅ™Ã­kladÅ¯, kterÃ© se sklÃ¡dajÃ­ z jednoho vstupu (promptu) a jeho odpovÃ­dajÃ­cÃ­ho vÃ½stupu (dokonÄenÃ­).
Tento pÅ™Ã­stup by byl preferovÃ¡n, pokud:

- **PouÅ¾itÃ­ doladÄ›nÃ½ch modelÅ¯**. Firma by chtÄ›la pouÅ¾Ã­t doladÄ›nÃ© mÃ©nÄ› schopnÃ© modely (jako embedding modely) mÃ­sto vysoce vÃ½konnÃ½ch modelÅ¯, coÅ¾ by vedlo k nÃ¡kladovÄ› efektivnÄ›jÅ¡Ã­mu a rychlejÅ¡Ã­mu Å™eÅ¡enÃ­.

- **ZohlednÄ›nÃ­ latence**. Latence je dÅ¯leÅ¾itÃ¡ pro konkrÃ©tnÃ­ pÅ™Ã­pad pouÅ¾itÃ­, takÅ¾e nenÃ­ moÅ¾nÃ© pouÅ¾Ã­t velmi dlouhÃ© prompty nebo poÄet pÅ™Ã­kladÅ¯, kterÃ© by se mÄ›ly modelu nauÄit, neodpovÃ­dÃ¡ limitu dÃ©lky promptu.

- **Aktualizace dat**. Firma mÃ¡ velkÃ© mnoÅ¾stvÃ­ kvalitnÃ­ch dat a referenÄnÃ­ch Å¡tÃ­tkÅ¯ a zdroje potÅ™ebnÃ© k tomu, aby tato data byla prÅ¯bÄ›Å¾nÄ› aktualizovÃ¡na.

### TrÃ©novanÃ½ model

TrÃ©novÃ¡nÃ­ LLM od zaÄÃ¡tku je bezpochyby nejnÃ¡roÄnÄ›jÅ¡Ã­ a nejsloÅ¾itÄ›jÅ¡Ã­ pÅ™Ã­stup, kterÃ½ vyÅ¾aduje obrovskÃ© mnoÅ¾stvÃ­ dat, kvalifikovanÃ© zdroje a odpovÃ­dajÃ­cÃ­ vÃ½poÄetnÃ­ vÃ½kon. Tuto moÅ¾nost by bylo vhodnÃ© zvÃ¡Å¾it pouze v situaci, kdy mÃ¡ firma pÅ™Ã­pad pouÅ¾itÃ­ specifickÃ½ pro danou oblast a velkÃ© mnoÅ¾stvÃ­ dat zamÄ›Å™enÃ½ch na danou oblast.

## Kontrola znalostÃ­

JakÃ½ by mohl bÃ½t dobrÃ½ pÅ™Ã­stup ke zlepÅ¡enÃ­ vÃ½sledkÅ¯ dokonÄenÃ­ LLM?

1. Prompt engineering s kontextem  
1. RAG  
1. DoladÄ›nÃ½ model  

A:3, pokud mÃ¡te Äas, zdroje a kvalitnÃ­ data, doladÄ›nÃ­ je lepÅ¡Ã­ moÅ¾nost, jak zÅ¯stat aktuÃ¡lnÃ­. NicmÃ©nÄ› pokud chcete zlepÅ¡it vÃ½sledky a nemÃ¡te dostatek Äasu, stojÃ­ za to nejprve zvÃ¡Å¾it RAG.

## ğŸš€ VÃ½zva

ZjistÄ›te vÃ­ce o tom, jak mÅ¯Å¾ete [pouÅ¾Ã­t RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pro vaÅ¡e podnikÃ¡nÃ­.

## SkvÄ›lÃ¡ prÃ¡ce, pokraÄujte ve svÃ©m vzdÄ›lÃ¡vÃ¡nÃ­

Po dokonÄenÃ­ tÃ©to lekce se podÃ­vejte na naÅ¡i [kolekci Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), abyste si dÃ¡le rozÅ¡Ã­Å™ili svÃ© znalosti o generativnÃ­ AI!

PÅ™ejdÄ›te na lekci 3, kde se podÃ­vÃ¡me na to, jak [budovat s generativnÃ­ AI odpovÄ›dnÄ›](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

---

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by AI pro pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatizovanÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho pÅ¯vodnÃ­m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro dÅ¯leÅ¾itÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. NeodpovÃ­dÃ¡me za Å¾Ã¡dnÃ¡ nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.