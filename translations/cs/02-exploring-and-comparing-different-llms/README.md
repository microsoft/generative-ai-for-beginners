<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:19:50+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "cs"
}
-->
# ZkoumÃ¡nÃ­ a porovnÃ¡vÃ¡nÃ­ rÅ¯znÃ½ch LLM

[![ZkoumÃ¡nÃ­ a porovnÃ¡vÃ¡nÃ­ rÅ¯znÃ½ch LLM](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.cs.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _KliknÄ›te na obrÃ¡zek vÃ½Å¡e a zhlÃ©dnÄ›te video tÃ©to lekce_

V pÅ™edchozÃ­ lekci jsme vidÄ›li, jak GenerativnÃ­ AI mÄ›nÃ­ technologickÃ© prostÅ™edÃ­, jak fungujÃ­ VelkÃ© jazykovÃ© modely (LLM) a jak je mÅ¯Å¾e podnik - jako naÅ¡e startupovÃ¡ firma - aplikovat na svÃ© pÅ™Ã­pady pouÅ¾itÃ­ a rÅ¯st! V tÃ©to kapitole se chystÃ¡me porovnat a kontrastovat rÅ¯znÃ© typy velkÃ½ch jazykovÃ½ch modelÅ¯ (LLM), abychom pochopili jejich vÃ½hody a nevÃ½hody.

DalÅ¡Ã­m krokem na cestÄ› naÅ¡eho startupu je prozkoumÃ¡nÃ­ aktuÃ¡lnÃ­ho prostÅ™edÃ­ LLM a pochopenÃ­, kterÃ© jsou vhodnÃ© pro nÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­.

## Ãšvod

Tato lekce se bude zabÃ½vat:

- RÅ¯znÃ½mi typy LLM v souÄasnÃ©m prostÅ™edÃ­.
- TestovÃ¡nÃ­m, iteracÃ­ a porovnÃ¡vÃ¡nÃ­m rÅ¯znÃ½ch modelÅ¯ pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­ v Azure.
- Jak nasadit LLM.

## CÃ­le uÄenÃ­

Po dokonÄenÃ­ tÃ©to lekce budete schopni:

- Vybrat sprÃ¡vnÃ½ model pro vÃ¡Å¡ pÅ™Ã­pad pouÅ¾itÃ­.
- Pochopit, jak testovat, iterovat a zlepÅ¡ovat vÃ½kon vaÅ¡eho modelu.
- VÄ›dÄ›t, jak podniky nasazujÃ­ modely.

## PorozumÄ›nÃ­ rÅ¯znÃ½m typÅ¯m LLM

LLM mohou mÃ­t nÄ›kolik kategorizacÃ­ na zÃ¡kladÄ› svÃ© architektury, trÃ©ninkovÃ½ch dat a pÅ™Ã­padu pouÅ¾itÃ­. PochopenÃ­ tÄ›chto rozdÃ­lÅ¯ pomÅ¯Å¾e naÅ¡emu startupu vybrat sprÃ¡vnÃ½ model pro danÃ½ scÃ©nÃ¡Å™ a pochopit, jak testovat, iterovat a zlepÅ¡ovat vÃ½kon.

Existuje mnoho rÅ¯znÃ½ch typÅ¯ LLM modelÅ¯, vaÅ¡e volba modelu zÃ¡visÃ­ na tom, co mÃ¡te v Ãºmyslu s nimi dÄ›lat, na vaÅ¡ich datech, na tom, kolik jste ochotni zaplatit a na dalÅ¡Ã­ch faktorech.

V zÃ¡vislosti na tom, zda mÃ¡te v Ãºmyslu pouÅ¾Ã­t modely pro generovÃ¡nÃ­ textu, zvuku, videa, obrÃ¡zkÅ¯ a podobnÄ›, mÅ¯Å¾ete zvolit jinÃ½ typ modelu.

- **RozpoznÃ¡vÃ¡nÃ­ zvuku a Å™eÄi**. Pro tento ÃºÄel jsou modely typu Whisper skvÄ›lou volbou, protoÅ¾e jsou univerzÃ¡lnÃ­ a zamÄ›Å™enÃ© na rozpoznÃ¡vÃ¡nÃ­ Å™eÄi. Jsou trÃ©novÃ¡ny na rÅ¯znorodÃ©m zvuku a mohou provÃ¡dÄ›t vÃ­cejazyÄnÃ© rozpoznÃ¡vÃ¡nÃ­ Å™eÄi. VÃ­ce se dozvÃ­te o [modelech typu Whisper zde](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **GenerovÃ¡nÃ­ obrÃ¡zkÅ¯**. Pro generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou DALL-E a Midjourney dvÄ› velmi znÃ¡mÃ© volby. DALL-E je nabÃ­zen Azure OpenAI. [PÅ™eÄtÄ›te si vÃ­ce o DALL-E zde](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) a takÃ© v kapitole 9 tohoto kurzu.

- **GenerovÃ¡nÃ­ textu**. VÄ›tÅ¡ina modelÅ¯ je trÃ©novÃ¡na na generovÃ¡nÃ­ textu a mÃ¡te velkou Å¡kÃ¡lu moÅ¾nostÃ­ od GPT-3.5 po GPT-4. PÅ™ichÃ¡zejÃ­ s rÅ¯znÃ½mi nÃ¡klady, pÅ™iÄemÅ¾ GPT-4 je nejdraÅ¾Å¡Ã­. StojÃ­ za to podÃ­vat se na [Azure OpenAI playground](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst), abyste zhodnotili, kterÃ© modely nejlÃ©pe vyhovujÃ­ vaÅ¡im potÅ™ebÃ¡m z hlediska schopnostÃ­ a nÃ¡kladÅ¯.

- **Multimodalita**. Pokud hledÃ¡te modely schopnÃ© zpracovÃ¡vat rÅ¯znÃ© typy dat v vstupu a vÃ½stupu, mÅ¯Å¾ete se podÃ­vat na modely jako [gpt-4 turbo s vidÄ›nÃ­m nebo gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - nejnovÄ›jÅ¡Ã­ vydÃ¡nÃ­ modelÅ¯ OpenAI - kterÃ© jsou schopnÃ© kombinovat zpracovÃ¡nÃ­ pÅ™irozenÃ©ho jazyka s vizuÃ¡lnÃ­m porozumÄ›nÃ­m, coÅ¾ umoÅ¾Åˆuje interakce prostÅ™ednictvÃ­m multimodÃ¡lnÃ­ch rozhranÃ­.

VÃ½bÄ›r modelu znamenÃ¡, Å¾e zÃ­skÃ¡te nÄ›jakÃ© zÃ¡kladnÃ­ schopnosti, kterÃ© vÅ¡ak nemusÃ­ bÃ½t dostateÄnÃ©. ÄŒasto mÃ¡te firemnÃ­ specifickÃ¡ data, o kterÃ½ch potÅ™ebujete nÄ›jakÃ½m zpÅ¯sobem informovat LLM. Existuje nÄ›kolik rÅ¯znÃ½ch moÅ¾nostÃ­, jak k tomu pÅ™istoupit, vÃ­ce o tom v nadchÃ¡zejÃ­cÃ­ch sekcÃ­ch.

### ZÃ¡kladnÃ­ modely versus LLM

TermÃ­n ZÃ¡kladnÃ­ model byl [vytvoÅ™en vÃ½zkumnÃ­ky ze Stanfordu](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) a definovÃ¡n jako AI model, kterÃ½ splÅˆuje nÄ›kterÃ¡ kritÃ©ria, jako napÅ™Ã­klad:

- **Jsou trÃ©novÃ¡ny pomocÃ­ uÄenÃ­ bez dohledu nebo samostatnÃ©ho uÄenÃ­**, coÅ¾ znamenÃ¡, Å¾e jsou trÃ©novÃ¡ny na neoznaÄenÃ½ch multimodÃ¡lnÃ­ch datech a nevyÅ¾adujÃ­ lidskÃ© anotace nebo oznaÄenÃ­ dat pro svÅ¯j trÃ©ninkovÃ½ proces.
- **Jsou velmi velkÃ© modely**, zaloÅ¾enÃ© na velmi hlubokÃ½ch neuronovÃ½ch sÃ­tÃ­ch trÃ©novanÃ½ch na miliardÃ¡ch parametrÅ¯.
- **Jsou obvykle urÄeny jako 'zÃ¡klad' pro jinÃ© modely**, coÅ¾ znamenÃ¡, Å¾e mohou bÃ½t pouÅ¾ity jako vÃ½chozÃ­ bod pro dalÅ¡Ã­ modely, kterÃ© lze postavit na jejich zÃ¡kladÄ›, coÅ¾ lze provÃ©st jemnÃ½m doladÄ›nÃ­m.

![ZÃ¡kladnÃ­ modely versus LLM](../../../translated_images/FoundationModel.1b89e9d94c6a60a9af557b1c0a10faa3a55c0cbc6bb357eb144512ab833d162c.cs.png)

Zdroj obrÃ¡zku: [Essential Guide to Foundation Models and Large Language Models | by Babar M Bhatti | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

Pro dalÅ¡Ã­ objasnÄ›nÃ­ tohoto rozliÅ¡enÃ­ si vezmÄ›me ChatGPT jako pÅ™Ã­klad. K vytvoÅ™enÃ­ prvnÃ­ verze ChatGPT slouÅ¾il model GPT-3.5 jako zÃ¡kladnÃ­ model. To znamenÃ¡, Å¾e OpenAI pouÅ¾ila nÄ›jakÃ¡ data specifickÃ¡ pro chat k vytvoÅ™enÃ­ ladÄ›nÃ© verze GPT-3.5, kterÃ¡ byla specializovanÃ¡ na dobrÃ½ vÃ½kon v konverzaÄnÃ­ch scÃ©nÃ¡Å™Ã­ch, jako jsou chatboti.

![ZÃ¡kladnÃ­ model](../../../translated_images/Multimodal.41df52bb0de979b80e9643ba34f8f1b53d7791cebd88bceedda6497241495f27.cs.png)

Zdroj obrÃ¡zku: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-koreyst)

### OtevÅ™enÃ© versus proprietÃ¡rnÃ­ modely

DalÅ¡Ã­m zpÅ¯sobem, jak kategorizovat LLM, je, zda jsou otevÅ™enÃ© nebo proprietÃ¡rnÃ­.

OtevÅ™enÃ© modely jsou modely, kterÃ© jsou zpÅ™Ã­stupnÄ›ny veÅ™ejnosti a mohou bÃ½t pouÅ¾ity kÃ½mkoli. ÄŒasto jsou zpÅ™Ã­stupnÄ›ny spoleÄnostÃ­, kterÃ¡ je vytvoÅ™ila, nebo vÃ½zkumnou komunitou. Tyto modely mohou bÃ½t prozkoumÃ¡ny, upraveny a pÅ™izpÅ¯sobeny pro rÅ¯znÃ© pÅ™Ã­pady pouÅ¾itÃ­ v LLM. NicmÃ©nÄ› nejsou vÅ¾dy optimalizovÃ¡ny pro produkÄnÃ­ pouÅ¾itÃ­ a nemusÃ­ bÃ½t tak vÃ½konnÃ© jako proprietÃ¡rnÃ­ modely. NavÃ­c financovÃ¡nÃ­ otevÅ™enÃ½ch modelÅ¯ mÅ¯Å¾e bÃ½t omezenÃ© a nemusÃ­ bÃ½t dlouhodobÄ› udrÅ¾ovÃ¡ny nebo aktualizovÃ¡ny s nejnovÄ›jÅ¡Ã­m vÃ½zkumem. PÅ™Ã­klady populÃ¡rnÃ­ch otevÅ™enÃ½ch modelÅ¯ zahrnujÃ­ [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) a [LLaMA](https://llama.meta.com).

ProprietÃ¡rnÃ­ modely jsou modely, kterÃ© jsou vlastnÄ›ny spoleÄnostÃ­ a nejsou zpÅ™Ã­stupnÄ›ny veÅ™ejnosti. Tyto modely jsou Äasto optimalizovÃ¡ny pro produkÄnÃ­ pouÅ¾itÃ­. NicmÃ©nÄ› nejsou povoleny k prozkoumÃ¡nÃ­, ÃºpravÃ¡m nebo pÅ™izpÅ¯sobenÃ­ pro rÅ¯znÃ© pÅ™Ã­pady pouÅ¾itÃ­. NavÃ­c nejsou vÅ¾dy dostupnÃ© zdarma a mohou vyÅ¾adovat pÅ™edplatnÃ© nebo platbu za pouÅ¾itÃ­. UÅ¾ivatelÃ© takÃ© nemajÃ­ kontrolu nad daty, kterÃ¡ jsou pouÅ¾ita k trÃ©novÃ¡nÃ­ modelu, coÅ¾ znamenÃ¡, Å¾e by mÄ›li dÅ¯vÄ›Å™ovat vlastnÃ­kovi modelu, Å¾e zajistÃ­ zÃ¡vazek k ochranÄ› dat a odpovÄ›dnÃ©mu pouÅ¾itÃ­ AI. PÅ™Ã­klady populÃ¡rnÃ­ch proprietÃ¡rnÃ­ch modelÅ¯ zahrnujÃ­ [OpenAI modely](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) nebo [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Embedding versus GenerovÃ¡nÃ­ obrÃ¡zkÅ¯ versus GenerovÃ¡nÃ­ textu a kÃ³du

LLM mohou bÃ½t takÃ© kategorizovÃ¡ny podle vÃ½stupu, kterÃ½ generujÃ­.

EmbedovÃ¡nÃ­ jsou sada modelÅ¯, kterÃ© mohou pÅ™evÃ©st text na numerickou formu, nazÃ½vanou embedovÃ¡nÃ­, coÅ¾ je numerickÃ¡ reprezentace vstupnÃ­ho textu. EmbedovÃ¡nÃ­ usnadÅˆujÃ­ strojÅ¯m porozumÄ›nÃ­ vztahÅ¯m mezi slovy nebo vÄ›tami a mohou bÃ½t pouÅ¾ity jako vstupy pro jinÃ© modely, jako jsou klasifikaÄnÃ­ modely nebo modely pro shlukovÃ¡nÃ­, kterÃ© majÃ­ lepÅ¡Ã­ vÃ½kon na numerickÃ½ch datech. EmbedovacÃ­ modely se Äasto pouÅ¾Ã­vajÃ­ pro transferovÃ© uÄenÃ­, kde je model postaven pro nÃ¡hradnÃ­ Ãºkol, pro kterÃ½ je dostatek dat, a pak jsou vÃ¡hy modelu (embedovÃ¡nÃ­) znovu pouÅ¾ity pro jinÃ© Ãºkoly. PÅ™Ã­kladem tÃ©to kategorie je [OpenAI embedovÃ¡nÃ­](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

![EmbedovÃ¡nÃ­](../../../translated_images/Embedding.fbf261f314681a51994056854fd928b69b253616bb313e68a9ce19a2b15c8768.cs.png)

Modely generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou modely, kterÃ© generujÃ­ obrÃ¡zky. Tyto modely se Äasto pouÅ¾Ã­vajÃ­ pro Ãºpravu obrÃ¡zkÅ¯, syntÃ©zu obrÃ¡zkÅ¯ a pÅ™eklad obrÃ¡zkÅ¯. Modely generovÃ¡nÃ­ obrÃ¡zkÅ¯ jsou Äasto trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch obrÃ¡zkÅ¯, jako je [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), a mohou bÃ½t pouÅ¾ity k generovÃ¡nÃ­ novÃ½ch obrÃ¡zkÅ¯ nebo k ÃºpravÄ› existujÃ­cÃ­ch obrÃ¡zkÅ¯ pomocÃ­ technik doplÅˆovÃ¡nÃ­, super-rozliÅ¡enÃ­ a kolorovÃ¡nÃ­. PÅ™Ã­klady zahrnujÃ­ [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) a [Stable Diffusion modely](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

![GenerovÃ¡nÃ­ obrÃ¡zkÅ¯](../../../translated_images/Image.fffee8e361cc35ed409975f6fc85502ae3d20b8eb01273cd327294e26318a049.cs.png)

Modely generovÃ¡nÃ­ textu a kÃ³du jsou modely, kterÃ© generujÃ­ text nebo kÃ³d. Tyto modely se Äasto pouÅ¾Ã­vajÃ­ pro sumarizaci textu, pÅ™eklad a odpovÃ­dÃ¡nÃ­ na otÃ¡zky. Modely generovÃ¡nÃ­ textu jsou Äasto trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch textu, jako je [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), a mohou bÃ½t pouÅ¾ity k generovÃ¡nÃ­ novÃ©ho textu nebo k odpovÃ­dÃ¡nÃ­ na otÃ¡zky. Modely generovÃ¡nÃ­ kÃ³du, jako [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), jsou Äasto trÃ©novÃ¡ny na velkÃ½ch datovÃ½ch sadÃ¡ch kÃ³du, jako je GitHub, a mohou bÃ½t pouÅ¾ity k generovÃ¡nÃ­ novÃ©ho kÃ³du nebo k opravÄ› chyb v existujÃ­cÃ­m kÃ³du.

![GenerovÃ¡nÃ­ textu a kÃ³du](../../../translated_images/Text.35cfbe12e08d5b5615cf7db5174fe477bf96f45c5b82d53c29523bd8b94bdc17.cs.png)

### Encoder-Decoder versus pouze Decoder

Pro popis rÅ¯znÃ½ch typÅ¯ architektur LLM pouÅ¾ijme analogii.

PÅ™edstavte si, Å¾e vÃ¡Å¡ manaÅ¾er vÃ¡m dal Ãºkol napsat kvÃ­z pro studenty. MÃ¡te dva kolegy; jeden je zodpovÄ›dnÃ½ za tvorbu obsahu a druhÃ½ za jeho revizi.

TvÅ¯rce obsahu je jako model pouze Decoder, mÅ¯Å¾e se podÃ­vat na tÃ©ma a vidÄ›t, co jste jiÅ¾ napsali, a pak mÅ¯Å¾e napsat kurz na zÃ¡kladÄ› toho. Jsou velmi dobÅ™Ã­ v psanÃ­ poutavÃ©ho a informativnÃ­ho obsahu, ale nejsou pÅ™Ã­liÅ¡ dobÅ™Ã­ v porozumÄ›nÃ­ tÃ©matu a uÄebnÃ­m cÃ­lÅ¯m. NÄ›kterÃ© pÅ™Ã­klady modelÅ¯ Decoder jsou modely rodiny GPT, jako GPT-3.

Revizor je jako model pouze Encoder, podÃ­vÃ¡ se na napsanÃ½ kurz a odpovÄ›di, vÅ¡imne si vztahu mezi nimi a pochopÃ­ kontext, ale nenÃ­ dobrÃ½ v generovÃ¡nÃ­ obsahu. PÅ™Ã­kladem modelu pouze Encoder by byl BERT.

PÅ™edstavte si, Å¾e bychom mohli mÃ­t nÄ›koho, kdo by mohl vytvÃ¡Å™et i revidovat kvÃ­z, to je model Encoder-Decoder. NÄ›kterÃ© pÅ™Ã­klady by byly BART a T5.

### SluÅ¾ba versus model

NynÃ­ si povÃ­me o rozdÃ­lu mezi sluÅ¾bou a modelem. SluÅ¾ba je produkt nabÃ­zenÃ½ poskytovatelem cloudovÃ½ch sluÅ¾eb a Äasto je kombinacÃ­ modelÅ¯, dat a dalÅ¡Ã­ch komponent. Model je jÃ¡drem sluÅ¾by a Äasto je to zÃ¡kladnÃ­ model, jako LLM.

SluÅ¾by jsou Äasto optimalizovÃ¡ny pro produkÄnÃ­ pouÅ¾itÃ­ a Äasto se snadnÄ›ji pouÅ¾Ã­vajÃ­ neÅ¾ modely, prostÅ™ednictvÃ­m grafickÃ©ho uÅ¾ivatelskÃ©ho rozhranÃ­. NicmÃ©nÄ› sluÅ¾by nejsou vÅ¾dy dostupnÃ© zdarma a mohou vyÅ¾adovat pÅ™edplatnÃ© nebo platbu za pouÅ¾itÃ­, vÃ½mÄ›nou za vyuÅ¾itÃ­ vybavenÃ­ a zdrojÅ¯ vlastnÃ­ka sluÅ¾by, optimalizaci nÃ¡kladÅ¯ a snadnÃ© Å¡kÃ¡lovÃ¡nÃ­. PÅ™Ã­kladem sluÅ¾by je [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), kterÃ¡ nabÃ­zÃ­ tarifnÃ­ plÃ¡n pay-as-you-go, coÅ¾ znamenÃ¡, Å¾e uÅ¾ivatelÃ© jsou ÃºÄtovÃ¡ni ÃºmÄ›rnÄ› tomu, jak moc pouÅ¾Ã­vajÃ­ sluÅ¾bu. TakÃ© Azure OpenAI Service nabÃ­zÃ­ podnikovÃ© zabezpeÄenÃ­ a rÃ¡mec pro odpovÄ›dnou AI nad schopnostmi modelÅ¯.

Modely jsou jen NeuronovÃ¡ sÃ­Å¥ s parametry, vÃ¡hami a dalÅ¡Ã­mi. UmoÅ¾ÅˆujÃ­ spoleÄnostem provozovat lokÃ¡lnÄ›, avÅ¡ak by bylo potÅ™eba zakoupit vybavenÃ­, vytvoÅ™it strukturu pro Å¡kÃ¡lovÃ¡nÃ­ a zakoupit licenci nebo pouÅ¾Ã­t otevÅ™enÃ½ model. Model jako LLaMA je k dispozici k pouÅ¾itÃ­, vyÅ¾aduje vÃ½poÄetnÃ­ vÃ½kon pro provoz modelu.

## Jak testovat a iterovat s rÅ¯znÃ½mi modely pro porozumÄ›nÃ­ vÃ½konu na Azure

Jakmile nÃ¡Å¡ tÃ½m prozkoumal aktuÃ¡lnÃ­ prostÅ™edÃ­ LLM a identifikoval nÄ›kterÃ© dobrÃ© kandidÃ¡ty pro svÃ© scÃ©nÃ¡Å™e, dalÅ¡Ã­m krokem je testovÃ¡nÃ­ na jejich datech a na jejich pracovnÃ­m zatÃ­Å¾enÃ­. Toto je iterativnÃ­ proces, provÃ¡dÄ›nÃ½ experimenty a mÄ›Å™enÃ­mi. VÄ›tÅ¡ina modelÅ¯, kterÃ© jsme zmÃ­nili v pÅ™edchozÃ­ch odstavcÃ­ch (OpenAI modely, otevÅ™enÃ© modely jako Llama2 a Hugging Face transformÃ¡tory) jsou dostupnÃ© v [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) v [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) je Cloud Platforma navrÅ¾enÃ¡ pro vÃ½vojÃ¡Å™e k vytvÃ¡Å™enÃ­ aplikacÃ­ generativnÃ­ AI a sprÃ¡vu celÃ©ho Å¾ivotnÃ­ho cyklu vÃ½voje - od experimentovÃ¡nÃ­ po hodnocenÃ­ - kombinovÃ¡nÃ­m vÅ¡ech Azure AI sluÅ¾eb do jednoho centra s praktickÃ½m GUI. Model Catalog v Azure AI Studio umoÅ¾Åˆuje uÅ¾ivateli:

- NajÃ­t ZÃ¡kladnÃ­ Model zÃ¡jmu v katalogu - buÄ proprietÃ¡rnÃ­ nebo otevÅ™enÃ½, filtrovÃ¡nÃ­m podle Ãºkolu, licence nebo jmÃ©na. Pro zlepÅ¡enÃ­ vyhledatelnosti jsou modely organizovÃ¡ny do kolekcÃ­, jako Azure OpenAI kolekce, Hugging Face kolekce a dalÅ¡Ã­.

![ModelovÃ½ katalog](../../../translated_images/AzureAIStudioModelCatalog.e34ac207ac348d31e74246c4f91d10086444783b72bbee3658e0453918aa5d22.cs.png)

- Prozkoumat kartu modelu, vÄetnÄ› podrobnÃ©ho popisu zamÃ½Å¡lenÃ©ho pouÅ¾itÃ­ a trÃ©ninkovÃ½ch dat, vzorkÅ¯ kÃ³du a vÃ½sledkÅ¯ hodnocenÃ­ na internÃ­ knihovnÄ› hodnocenÃ­.

![Karta modelu](../../../translated_images/ModelCard.8b25784bb406028655a12ea87d1ef3d52302e5d692ae4ec559c2dce7682027c7.cs.png)
- Porovnejte benchmarky mezi modely a datovÃ½mi sadami dostupnÃ½mi v prÅ¯myslu, abyste zjistili, kterÃ½ z nich nejlÃ©pe vyhovuje obchodnÃ­mu scÃ©nÃ¡Å™i, pomocÃ­ panelu [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst).

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.cs.png)

- DoladÄ›te model na vlastnÃ­ch trÃ©ninkovÃ½ch datech, abyste zlepÅ¡ili jeho vÃ½kon v konkrÃ©tnÃ­m pracovnÃ­m zatÃ­Å¾enÃ­, s vyuÅ¾itÃ­m experimentÃ¡lnÃ­ch a sledovacÃ­ch schopnostÃ­ Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.cs.png)

- Nasazujte pÅ¯vodnÃ­ pÅ™edtrÃ©novanÃ½ model nebo jeho doladÄ›nou verzi na vzdÃ¡lenou inference v reÃ¡lnÃ©m Äase - Å™Ã­zenÃ© vÃ½poÄetnÃ­ prostÅ™edky - nebo serverless API endpoint - [platba za pouÅ¾itÃ­](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - aby aplikace mohly model vyuÅ¾Ã­vat.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.cs.png)

> [!NOTE]
> Ne vÅ¡echny modely v katalogu jsou momentÃ¡lnÄ› dostupnÃ© pro doladÄ›nÃ­ a/nebo nasazenÃ­ s platbou za pouÅ¾itÃ­. Zkontrolujte kartu modelu pro podrobnosti o schopnostech a omezenÃ­ch modelu.

## ZlepÅ¡ovÃ¡nÃ­ vÃ½sledkÅ¯ LLM

Prozkoumali jsme s naÅ¡Ã­m startupovÃ½m tÃ½mem rÅ¯znÃ© druhy LLM a cloudovou platformu (Azure Machine Learning), kterÃ¡ nÃ¡m umoÅ¾Åˆuje porovnÃ¡vat rÅ¯znÃ© modely, hodnotit je na testovacÃ­ch datech, zlepÅ¡ovat vÃ½kon a nasazovat je na inference endpointy.

Kdy by mÄ›li zvÃ¡Å¾it doladÄ›nÃ­ modelu mÃ­sto pouÅ¾itÃ­ pÅ™edtrÃ©novanÃ©ho? ExistujÃ­ jinÃ© pÅ™Ã­stupy ke zlepÅ¡enÃ­ vÃ½konu modelu v konkrÃ©tnÃ­ch pracovnÃ­ch zatÃ­Å¾enÃ­ch?

Existuje nÄ›kolik pÅ™Ã­stupÅ¯, kterÃ© mÅ¯Å¾e podnik pouÅ¾Ã­t k dosaÅ¾enÃ­ potÅ™ebnÃ½ch vÃ½sledkÅ¯ z LLM. PÅ™i nasazenÃ­ LLM do produkce mÅ¯Å¾ete vybrat rÅ¯znÃ© typy modelÅ¯ s rÅ¯znou mÃ­rou trÃ©ninku, s rÅ¯znou ÃºrovnÃ­ sloÅ¾itosti, nÃ¡kladÅ¯ a kvality. Zde jsou nÄ›kterÃ© rÅ¯znÃ© pÅ™Ã­stupy:

- **Prompt engineering s kontextem**. MyÅ¡lenka je poskytnout dostateÄnÃ½ kontext pÅ™i zadÃ¡vÃ¡nÃ­, aby se zajistilo, Å¾e dostanete potÅ™ebnÃ© odpovÄ›di.

- **Retrieval Augmented Generation, RAG**. VaÅ¡e data mohou existovat napÅ™Ã­klad v databÃ¡zi nebo webovÃ©m endpointu, aby bylo zajiÅ¡tÄ›no, Å¾e tato data nebo jejich podmnoÅ¾ina jsou zahrnuta pÅ™i zadÃ¡vÃ¡nÃ­, mÅ¯Å¾ete zÃ­skat relevantnÃ­ data a uÄinit je souÄÃ¡stÃ­ uÅ¾ivatelskÃ©ho zadÃ¡nÃ­.

- **DoladÄ›nÃ½ model**. Zde jste model dÃ¡le trÃ©novali na vlastnÃ­ch datech, coÅ¾ vedlo k tomu, Å¾e model je pÅ™esnÄ›jÅ¡Ã­ a reaguje na vaÅ¡e potÅ™eby, ale mÅ¯Å¾e bÃ½t nÃ¡kladnÃ½.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.cs.png)

Zdroj obrÃ¡zku: [ÄŒtyÅ™i zpÅ¯soby, jak podniky nasazujÃ­ LLM | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering s kontextem

PÅ™edtrÃ©novanÃ© LLM fungujÃ­ velmi dobÅ™e na obecnÃ© Ãºkoly s pÅ™irozenÃ½m jazykem, dokonce i pÅ™i jejich volÃ¡nÃ­ krÃ¡tkÃ½m zadÃ¡nÃ­m, jako je vÄ›ta k dokonÄenÃ­ nebo otÃ¡zka â€“ takzvanÃ© â€zero-shotâ€œ uÄenÃ­.

ÄŒÃ­m vÃ­ce mÅ¯Å¾e uÅ¾ivatel formulovat svÅ¯j dotaz, s podrobnÃ½m poÅ¾adavkem a pÅ™Ã­klady â€“ Kontext â€“ tÃ­m pÅ™esnÄ›jÅ¡Ã­ a bliÅ¾Å¡Ã­ oÄekÃ¡vÃ¡nÃ­m uÅ¾ivatele bude odpovÄ›Ä. V tomto pÅ™Ã­padÄ› mluvÃ­me o â€one-shotâ€œ uÄenÃ­, pokud zadÃ¡nÃ­ obsahuje pouze jeden pÅ™Ã­klad, a â€few-shot learningâ€œ, pokud obsahuje vÃ­ce pÅ™Ã­kladÅ¯. Prompt engineering s kontextem je nejefektivnÄ›jÅ¡Ã­ pÅ™Ã­stup k zahÃ¡jenÃ­.

### Retrieval Augmented Generation (RAG)

LLM majÃ­ omezenÃ­, Å¾e mohou pouÅ¾Ã­t pouze data, kterÃ¡ byla pouÅ¾ita bÄ›hem jejich trÃ©ninku k vygenerovÃ¡nÃ­ odpovÄ›di. To znamenÃ¡, Å¾e nevÄ›dÃ­ nic o faktech, kterÃ¡ se stala po jejich trÃ©ninkovÃ©m procesu, a nemohou pÅ™istupovat k neveÅ™ejnÃ½m informacÃ­m (jako jsou data spoleÄnosti).
To lze pÅ™ekonat pomocÃ­ RAG, techniky, kterÃ¡ rozÅ¡iÅ™uje zadÃ¡nÃ­ o externÃ­ data ve formÄ› ÃºtrÅ¾kÅ¯ dokumentÅ¯, s ohledem na omezenÃ­ dÃ©lky zadÃ¡nÃ­. To je podporovÃ¡no nÃ¡stroji pro vektorovÃ© databÃ¡ze (jako [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)), kterÃ© zÃ­skÃ¡vajÃ­ uÅ¾iteÄnÃ© ÃºtrÅ¾ky z rÅ¯znÃ½ch pÅ™eddefinovanÃ½ch datovÃ½ch zdrojÅ¯ a pÅ™idÃ¡vajÃ­ je do kontextu zadÃ¡nÃ­.

Tato technika je velmi uÅ¾iteÄnÃ¡, kdyÅ¾ podnik nemÃ¡ dostatek dat, Äasu nebo zdrojÅ¯ na doladÄ›nÃ­ LLM, ale stÃ¡le si pÅ™eje zlepÅ¡it vÃ½kon na konkrÃ©tnÃ­m pracovnÃ­m zatÃ­Å¾enÃ­ a snÃ­Å¾it rizika fabricacÃ­, tj. mystifikace reality nebo Å¡kodlivÃ©ho obsahu.

### DoladÄ›nÃ½ model

DoladÄ›nÃ­ je proces, kterÃ½ vyuÅ¾Ã­vÃ¡ pÅ™enosovÃ© uÄenÃ­ k â€pÅ™izpÅ¯sobenÃ­â€œ modelu na nÃ¡slednÃ½ Ãºkol nebo k Å™eÅ¡enÃ­ konkrÃ©tnÃ­ho problÃ©mu. Na rozdÃ­l od few-shot learning a RAG vede k vytvoÅ™enÃ­ novÃ©ho modelu s aktualizovanÃ½mi vahami a zkreslenÃ­mi. VyÅ¾aduje sadu trÃ©ninkovÃ½ch pÅ™Ã­kladÅ¯ sestÃ¡vajÃ­cÃ­ z jedinÃ©ho vstupu (zadÃ¡nÃ­) a jeho pÅ™idruÅ¾enÃ©ho vÃ½stupu (dokonÄenÃ­).
Toto by byl preferovanÃ½ pÅ™Ã­stup, pokud:

- **PouÅ¾Ã­vÃ¡nÃ­ doladÄ›nÃ½ch modelÅ¯**. Podnik by rÃ¡d pouÅ¾Ã­val doladÄ›nÃ© mÃ©nÄ› schopnÃ© modely (jako modely pro embedding) mÃ­sto vysoce vÃ½konnÃ½ch modelÅ¯, coÅ¾ vede k nÃ¡kladovÄ› efektivnÄ›jÅ¡Ã­mu a rychlejÅ¡Ã­mu Å™eÅ¡enÃ­.

- **ZvaÅ¾ovÃ¡nÃ­ latence**. Latence je dÅ¯leÅ¾itÃ¡ pro konkrÃ©tnÃ­ pouÅ¾itÃ­, takÅ¾e nenÃ­ moÅ¾nÃ© pouÅ¾Ã­vat velmi dlouhÃ¡ zadÃ¡nÃ­ nebo poÄet pÅ™Ã­kladÅ¯, kterÃ© by se mÄ›l model nauÄit, neodpovÃ­dÃ¡ limitu dÃ©lky zadÃ¡nÃ­.

- **UdrÅ¾ovÃ¡nÃ­ aktuÃ¡lnosti**. Podnik mÃ¡ mnoho vysoce kvalitnÃ­ch dat a pravdivÃ½ch Å¡tÃ­tkÅ¯ a zdroje potÅ™ebnÃ© k udrÅ¾ovÃ¡nÃ­ tÄ›chto dat aktuÃ¡lnÃ­ch v prÅ¯bÄ›hu Äasu.

### TrÃ©novanÃ½ model

TrÃ©novÃ¡nÃ­ LLM od nuly je bezpochyby nejtÄ›Å¾Å¡Ã­ a nejsloÅ¾itÄ›jÅ¡Ã­ pÅ™Ã­stup, kterÃ½ je tÅ™eba pÅ™ijmout, vyÅ¾adujÃ­cÃ­ obrovskÃ© mnoÅ¾stvÃ­ dat, kvalifikovanÃ© zdroje a odpovÃ­dajÃ­cÃ­ vÃ½poÄetnÃ­ vÃ½kon. Tuto moÅ¾nost by bylo tÅ™eba zvÃ¡Å¾it pouze v situaci, kdy mÃ¡ podnik specifickÃ½ pÅ™Ã­pad pouÅ¾itÃ­ a velkÃ© mnoÅ¾stvÃ­ dat zamÄ›Å™enÃ½ch na danou oblast.

## Kontrola znalostÃ­

JakÃ½ by mohl bÃ½t dobrÃ½ pÅ™Ã­stup ke zlepÅ¡enÃ­ vÃ½sledkÅ¯ dokonÄenÃ­ LLM?

1. Prompt engineering s kontextem
1. RAG
1. DoladÄ›nÃ½ model

A:3, pokud mÃ¡te Äas a zdroje a vysoce kvalitnÃ­ data, doladÄ›nÃ­ je lepÅ¡Ã­ moÅ¾nost, jak zÅ¯stat aktuÃ¡lnÃ­. NicmÃ©nÄ›, pokud se snaÅ¾Ã­te vÄ›ci zlepÅ¡it a nemÃ¡te Äas, stojÃ­ za zvÃ¡Å¾enÃ­ RAG jako prvnÃ­.

## ğŸš€ VÃ½zva

ZjistÄ›te vÃ­ce o tom, jak mÅ¯Å¾ete [pouÅ¾Ã­t RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) pro vÃ¡Å¡ podnik.

## SkvÄ›lÃ¡ prÃ¡ce, pokraÄujte ve svÃ©m uÄenÃ­

Po dokonÄenÃ­ tÃ©to lekce se podÃ­vejte na naÅ¡i [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), abyste dÃ¡le rozvÃ­jeli svÃ© znalosti o Generative AI!

PÅ™ejdÄ›te na lekci 3, kde se podÃ­vÃ¡me na to, jak [budovat s Generative AI zodpovÄ›dnÄ›](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**ProhlÃ¡Å¡enÃ­**:  
Tento dokument byl pÅ™eloÅ¾en pomocÃ­ sluÅ¾by AI pro pÅ™eklad [Co-op Translator](https://github.com/Azure/co-op-translator). AÄkoli se snaÅ¾Ã­me o pÅ™esnost, mÄ›jte prosÃ­m na pamÄ›ti, Å¾e automatickÃ© pÅ™eklady mohou obsahovat chyby nebo nepÅ™esnosti. PÅ¯vodnÃ­ dokument v jeho rodnÃ©m jazyce by mÄ›l bÃ½t povaÅ¾ovÃ¡n za autoritativnÃ­ zdroj. Pro kritickÃ© informace se doporuÄuje profesionÃ¡lnÃ­ lidskÃ½ pÅ™eklad. Nejsme zodpovÄ›dnÃ­ za jakÃ©koli nedorozumÄ›nÃ­ nebo nesprÃ¡vnÃ© interpretace vyplÃ½vajÃ­cÃ­ z pouÅ¾itÃ­ tohoto pÅ™ekladu.