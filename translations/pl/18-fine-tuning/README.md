<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "3772dcd23a98e2010f53ce8b9c583631",
  "translation_date": "2026-01-18T18:11:31+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "pl"
}
-->
[![Otwarte Modele Å¹rÃ³dÅ‚owe](../../../../../translated_images/pl/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Dostosowywanie Twojego LLM

UÅ¼ywanie duÅ¼ych modeli jÄ™zykowych do budowy generatywnych aplikacji AI wiÄ…Å¼e siÄ™ z nowymi wyzwaniami. KluczowÄ… kwestiÄ… jest zapewnienie jakoÅ›ci odpowiedzi (dokÅ‚adnoÅ›ci i trafnoÅ›ci) w treÅ›ci generowanej przez model na okreÅ›lone zapytanie uÅ¼ytkownika. W poprzednich lekcjach omawialiÅ›my techniki takie jak inÅ¼ynieria promptÃ³w oraz generowanie wspomagane wyszukiwaniem, ktÃ³re prÃ³bujÄ… rozwiÄ…zaÄ‡ problem przez _modyfikacjÄ™ wejÅ›cia promptu_ do istniejÄ…cego modelu.

W dzisiejszej lekcji omÃ³wimy trzeciÄ… technikÄ™, **dostosowywanie (fine-tuning)**, ktÃ³ra stara siÄ™ rozwiÄ…zaÄ‡ wyzwanie przez _ponowne trenowanie samego modelu_ na dodatkowych danych. Przyjrzyjmy siÄ™ szczegÃ³Å‚om.

## Cele Nauki

Ta lekcja wprowadza koncepcjÄ™ dostosowywania dla wczeÅ›niej wytrenowanych modeli jÄ™zykowych, bada zalety i wyzwania takiego podejÅ›cia oraz daje wskazÃ³wki, kiedy i jak uÅ¼ywaÄ‡ dostosowywania, aby poprawiÄ‡ wydajnoÅ›Ä‡ twoich generatywnych modeli AI.

Na koniec tej lekcji powinieneÅ› byÄ‡ w stanie odpowiedzieÄ‡ na nastÄ™pujÄ…ce pytania:

- Czym jest dostosowywanie modeli jÄ™zykowych?
- Kiedy i dlaczego dostosowywanie jest przydatne?
- Jak mogÄ™ dostosowaÄ‡ wczeÅ›niej wytrenowany model?
- Jakie sÄ… ograniczenia dostosowywania?

Gotowy? Zaczynajmy.

## Przewodnik Ilustrowany

Chcesz zobaczyÄ‡ ogÃ³lny obraz tego, co omÃ³wimy, zanim zaczniemy? SprawdÅº ten ilustrowany przewodnik, ktÃ³ry opisuje Å›cieÅ¼kÄ™ nauki dla tej lekcji â€“ od poznania podstawowych pojÄ™Ä‡ i motywacji do dostosowywania, po zrozumienie procesu i najlepszych praktyk realizacji zadania dostosowywania. To fascynujÄ…cy temat do eksploracji, wiÄ™c nie zapomnij odwiedziÄ‡ strony [Zasoby](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) po dodatkowe linki wspierajÄ…ce twojÄ… samodzielnÄ… naukÄ™!

![Przewodnik Ilustrowany po Dostosowywaniu Modeli JÄ™zykowych](../../../../../translated_images/pl/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Czym jest dostosowywanie modeli jÄ™zykowych?

Z definicji, duÅ¼e modele jÄ™zykowe sÄ… _wczeÅ›niej wytrenowane_ na duÅ¼ych iloÅ›ciach tekstu pochodzÄ…cego z rÃ³Å¼nych ÅºrÃ³deÅ‚, w tym internetu. Jak dowiedzieliÅ›my siÄ™ w poprzednich lekcjach, potrzebujemy technik takich jak _inÅ¼ynieria promptÃ³w_ i _generowanie wspomagane wyszukiwaniem_, aby poprawiÄ‡ jakoÅ›Ä‡ odpowiedzi modelu na pytania uÅ¼ytkownika (â€promptyâ€).

PopularnÄ… technikÄ… inÅ¼ynierii promptÃ³w jest udzielanie modelowi wiÄ™kszej iloÅ›ci wskazÃ³wek, co ma znaleÅºÄ‡ siÄ™ w odpowiedzi, poprzez dostarczanie _instrukcji_ (wyraÅºnych wskazÃ³wek) lub _pokazywanie kilku przykÅ‚adÃ³w_ (wskazÃ³wki niejawne). Nazywa siÄ™ to _uczeniem na maÅ‚ej liczbie przykÅ‚adÃ³w_ (few-shot learning), ale ma dwa ograniczenia:

- Limity tokenÃ³w modelu mogÄ… ograniczaÄ‡ liczbÄ™ przykÅ‚adÃ³w, ktÃ³re moÅ¼na podaÄ‡, i zmniejszaÄ‡ efektywnoÅ›Ä‡.
- Koszty tokenÃ³w modelu mogÄ… sprawiÄ‡, Å¼e dodawanie przykÅ‚adÃ³w do kaÅ¼dego promptu bÄ™dzie drogie, ograniczajÄ…c elastycznoÅ›Ä‡.

Dostosowywanie to powszechna praktyka w systemach uczenia maszynowego, gdzie bierzemy wczeÅ›niej wytrenowany model i ponownie go trenujemy na nowych danych, aby poprawiÄ‡ jego wydajnoÅ›Ä‡ w okreÅ›lonym zadaniu. W kontekÅ›cie modeli jÄ™zykowych moÅ¼emy dostosowaÄ‡ wczeÅ›niej wytrenowany model _za pomocÄ… wyselekcjonowanego zestawu przykÅ‚adÃ³w dla konkretnego zadania lub domeny zastosowania_, tworzÄ…c **model dostosowany**, ktÃ³ry moÅ¼e byÄ‡ dokÅ‚adniejszy i bardziej trafny dla tego konkretnie zadania lub domeny. Dodatkowym efektem dostosowywania jest to, Å¼e moÅ¼e ono rÃ³wnieÅ¼ zmniejszyÄ‡ liczbÄ™ przykÅ‚adÃ³w potrzebnych przy uczeniu na maÅ‚ej liczbie przykÅ‚adÃ³w â€“ zmniejszajÄ…c uÅ¼ycie tokenÃ³w i powiÄ…zane koszty.

## Kiedy i dlaczego powinniÅ›my dostosowywaÄ‡ modele?

W _tym_ kontekÅ›cie, gdy mÃ³wimy o dostosowywaniu, odnosimy siÄ™ do **nadzorowanego** dostosowywania, gdzie ponowne trenowanie odbywa siÄ™ przez **dodanie nowych danych**, ktÃ³re nie byÅ‚y czÄ™Å›ciÄ… oryginalnego zestawu treningowego. To rÃ³Å¼ni siÄ™ od nienadzorowanego dostosowywania, gdzie model jest ponownie trenowany na oryginalnych danych, ale z rÃ³Å¼nymi hiperparametrami.

KluczowÄ… rzeczÄ… do zapamiÄ™tania jest to, Å¼e dostosowywanie to zaawansowana technika, ktÃ³ra wymaga pewnego poziomu wiedzy, aby uzyskaÄ‡ oczekiwane rezultaty. JeÅ›li zostanie wykonane niepoprawnie, moÅ¼e nie przynieÅ›Ä‡ spodziewanych ulepszeÅ„, a nawet pogorszyÄ‡ wydajnoÅ›Ä‡ modelu w twojej docelowej domenie.

Zatem zanim nauczysz siÄ™ â€jakâ€ dostosowywaÄ‡ modele jÄ™zykowe, musisz wiedzieÄ‡ â€dlaczegoâ€ powinieneÅ› obraÄ‡ tÄ™ Å›cieÅ¼kÄ™ i â€kiedyâ€ rozpoczÄ…Ä‡ proces dostosowywania. Zacznij od zadania sobie tych pytaÅ„:

- **Przypadek uÅ¼ycia**: Jaki jest twÃ³j _przypadek uÅ¼ycia_ dla dostosowywania? Co chcesz poprawiÄ‡ w obecnym wczeÅ›niej wytrenowanym modelu?
- **Alternatywy**: Czy prÃ³bowaÅ‚eÅ› _innych technik_, aby osiÄ…gnÄ…Ä‡ poÅ¼Ä…dane wyniki? UÅ¼yj ich do stworzenia bazy do porÃ³wnania.
  - InÅ¼ynieria promptÃ³w: SprÃ³buj technik takich jak few-shot prompting z przykÅ‚adami odpowiedzi. OceÅ„ jakoÅ›Ä‡ odpowiedzi.
  - Generowanie wspomagane wyszukiwaniem: SprÃ³buj wzbogaciÄ‡ prompt o wyniki zapytaÅ„ uzyskanych przez wyszukiwanie w twoich danych. OceÅ„ jakoÅ›Ä‡ odpowiedzi.
- **Koszty**: Czy zidentyfikowaÅ‚eÅ› koszty zwiÄ…zane z dostosowywaniem?
  - MoÅ¼liwoÅ›Ä‡ dostosowania â€“ czy model wczeÅ›niej wytrenowany jest dostÄ™pny do dostosowania?
  - NakÅ‚ad pracy â€“ przygotowanie danych treningowych, ocena i dopracowanie modelu.
  - Obliczenia â€“ przeprowadzanie zadaÅ„ dostosowywania i wdraÅ¼anie modelu dostosowanego.
  - Dane â€“ dostÄ™p do dostatecznej jakoÅ›ci przykÅ‚adÃ³w, aby dostosowanie miaÅ‚o efekt.
- **KorzyÅ›ci**: Czy potwierdziÅ‚eÅ› korzyÅ›ci pÅ‚ynÄ…ce z dostosowywania?
  - JakoÅ›Ä‡ â€“ czy model dostosowany przewyÅ¼szaÅ‚ bazÄ™?
  - Koszty â€“ czy zmniejsza zuÅ¼ycie tokenÃ³w przez uproszczenie promptÃ³w?
  - RozszerzalnoÅ›Ä‡ â€“ czy moÅ¼esz wykorzystaÄ‡ model bazowy dla nowych domen?

OdpowiadajÄ…c na te pytania, powinieneÅ› mÃ³c zdecydowaÄ‡, czy dostosowywanie jest wÅ‚aÅ›ciwym podejÅ›ciem dla twojego przypadku uÅ¼ycia. Idealnie, podejÅ›cie ma sens tylko wtedy, gdy korzyÅ›ci przewyÅ¼szajÄ… koszty. Gdy juÅ¼ zdecydujesz siÄ™ kontynuowaÄ‡, czas pomyÅ›leÄ‡ o tym, _jak_ moÅ¼esz dostosowaÄ‡ wczeÅ›niej wytrenowany model.

Chcesz uzyskaÄ‡ wiÄ™cej informacji na temat procesu podejmowania decyzji? Obejrzyj [DostosowaÄ‡ czy nie dostosowaÄ‡](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Jak moÅ¼emy dostosowaÄ‡ wczeÅ›niej wytrenowany model?

Aby dostosowaÄ‡ wczeÅ›niej wytrenowany model, potrzebujesz:

- wczeÅ›niej wytrenowanego modelu do dostosowania
- zbioru danych do wykorzystania w dostosowywaniu
- Å›rodowiska treningowego do uruchomienia zadania dostosowywania
- Å›rodowiska hostingowego do wdroÅ¼enia modelu dostosowanego

## Dostosowywanie w Praktyce

PoniÅ¼sze zasoby dostarczajÄ… samouczkÃ³w krok po kroku, ktÃ³re przeprowadzÄ… ciÄ™ przez rzeczywisty przykÅ‚ad z wybranym modelem i wyselekcjonowanym zbiorem danych. Aby skorzystaÄ‡ z tych samouczkÃ³w, potrzebujesz konta u konkretnego dostawcy, wraz z dostÄ™pem do odpowiednich modeli i zbiorÃ³w danych.

| Dostawca    | Samouczek                                                                                                                                                                     | Opis                                                                                                                                                                                                                                                                                                                                                                                                                               |
| ----------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI      | [Jak dostosowaÄ‡ modele czatu](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Naucz siÄ™ dostosowywaÄ‡ `gpt-35-turbo` do konkretnej domeny (â€asystent przepisÃ³wâ€) poprzez przygotowanie danych treningowych, uruchomienie zadania dostosowywania oraz wykorzystanie modelu dostosowanego do wnioskowania.                                                                                                                                                                                                        |
| Azure OpenAI| [Samouczek dostosowywania GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Naucz siÄ™ jak dostosowaÄ‡ model `gpt-35-turbo-0613` **na platformie Azure** przechodzÄ…c przez etapy tworzenia i przesyÅ‚ania danych treningowych, uruchamiania zadania dostosowywania, wdroÅ¼enia i uÅ¼ycia nowego modelu.                                                                                                                                                                                                              |
| Hugging Face| [Dostosowywanie LLM z Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                              | Ten wpis na blogu przeprowadza ciÄ™ przez dostosowywanie _otwartego LLM_ (np. `CodeLlama 7B`) z uÅ¼yciem biblioteki [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) oraz [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) z otwartymi [zbiorami danych](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|             |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ğŸ¤— AutoTrain| [Dostosowywanie LLM z AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (lub AutoTrain Advanced) to biblioteka Pythona opracowana przez Hugging Face, ktÃ³ra umoÅ¼liwia dostosowywanie dla wielu rÃ³Å¼nych zadaÅ„, w tym dostosowywanie LLM. AutoTrain to rozwiÄ…zanie bez kodu, a dostosowywanie moÅ¼na przeprowadziÄ‡ w swojej wÅ‚asnej chmurze, na Hugging Face Spaces lub lokalnie. ObsÅ‚uguje zarÃ³wno interfejs webowy, CLI, jak i trening przez pliki konfiguracyjne yaml.                                               |
|             |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
| ğŸ¦¥ Unsloth  | [Dostosowywanie LLM z Unsloth](https://github.com/unslothai/unsloth)                                                                                                         | Unsloth to otwartoÅºrÃ³dÅ‚owy framework wspierajÄ…cy dostosowywanie LLM i uczenie ze wzmocnieniem (RL). Unsloth usprawnia lokalne trenowanie, ocenÄ™ i wdraÅ¼anie z gotowymi do uÅ¼ycia [notatnikami](https://github.com/unslothai/notebooks). ObsÅ‚uguje rÃ³wnieÅ¼ syntezÄ™ mowy (TTS), BERT oraz modele multimodalne. Aby zaczÄ…Ä‡, przeczytaj ich krok po kroku [Przewodnik po dostosowywaniu LLM](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).             |
|             |                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
## Zadanie

Wybierz jeden z powyÅ¼szych samouczkÃ³w i przejdÅº go krok po kroku. _MoÅ¼emy przygotowaÄ‡ wersjÄ™ tych samouczkÃ³w w notatnikach Jupyter w tym repozytorium wyÅ‚Ä…cznie dla odniesienia. Prosimy korzystaj bezpoÅ›rednio z oryginalnych ÅºrÃ³deÅ‚, aby uzyskaÄ‡ najnowsze wersje_.

## Åšwietna praca! Kontynuuj naukÄ™.

Po ukoÅ„czeniu tej lekcji, sprawdÅº naszÄ… kolekcjÄ™ [Generatywnej Sztucznej Inteligencji](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby dalej rozwijaÄ‡ swojÄ… wiedzÄ™ o Generatywnej AI!

Gratulacje!! UkoÅ„czyÅ‚eÅ› ostatniÄ… lekcjÄ™ z serii v2 tego kursu! Nie przestawaj siÄ™ uczyÄ‡ i tworzyÄ‡. **SprawdÅº stronÄ™ [ZASOBY](RESOURCES.md?WT.mc_id=academic-105485-koreyst) z listÄ… dodatkowych sugestii wÅ‚aÅ›nie na ten temat.

Nasza seria lekcji v1 rÃ³wnieÅ¼ zostaÅ‚a zaktualizowana o wiÄ™cej zadaÅ„ i koncepcji. PoÅ›wiÄ™Ä‡ chwilÄ™, aby odÅ›wieÅ¼yÄ‡ swojÄ… wiedzÄ™ â€“ i prosimy, [dziel siÄ™ swoimi pytaniami i opiniami](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), aby pomÃ³c nam ulepszaÄ‡ te lekcje dla spoÅ‚ecznoÅ›ci.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Zrzeczenie siÄ™ odpowiedzialnoÅ›ci**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony przy uÅ¼yciu usÅ‚ugi tÅ‚umaczeÅ„ AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do jak najwiÄ™kszej dokÅ‚adnoÅ›ci, prosimy pamiÄ™taÄ‡, Å¼e tÅ‚umaczenia automatyczne mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za autorytatywne ÅºrÃ³dÅ‚o. W przypadku istotnych informacji zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z uÅ¼ycia tego tÅ‚umaczenia.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->