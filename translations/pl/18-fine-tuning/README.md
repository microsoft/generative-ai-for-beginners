<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "68664f7e754a892ae1d8d5e2b7bd2081",
  "translation_date": "2025-05-20T07:46:55+00:00",
  "source_file": "18-fine-tuning/README.md",
  "language_code": "pl"
}
-->
[![Open Source Models](../../../translated_images/18-lesson-banner.8487555c3e3225eefc1dc84e72c8e00bce1ee76db867a080628fb0fbb04aa0d2.pl.png)](https://aka.ms/gen-ai-lesson18-gh?WT.mc_id=academic-105485-koreyst)

# Dostrajanie Twojego LLM

Wykorzystanie du偶ych modeli jzykowych do budowy aplikacji generatywnej AI wi偶e si z nowymi wyzwaniami. Kluczowym problemem jest zapewnienie jakoci odpowiedzi (dokadnoci i trafnoci) w treciach generowanych przez model dla danego zapytania u偶ytkownika. W poprzednich lekcjach omawialimy techniki takie jak in偶ynieria prompt贸w i generacja wspomagana wyszukiwaniem, kt贸re pr贸buj rozwiza problem poprzez _modyfikacj wejcia promptu_ dla istniejcego modelu.

W dzisiejszej lekcji omawiamy trzeci technik, **dostrajanie**, kt贸ra pr贸buje rozwiza wyzwanie poprzez _ponowne trenowanie samego modelu_ z dodatkowymi danymi. Zanurzmy si w szczeg贸y.

## Cele nauki

Ta lekcja wprowadza pojcie dostrajania dla wstpnie wytrenowanych modeli jzykowych, bada korzyci i wyzwania zwizane z tym podejciem oraz daje wskaz贸wki, kiedy i jak u偶ywa dostrajania, aby poprawi wydajno swoich modeli generatywnej AI.

Na koniec tej lekcji powiniene by w stanie odpowiedzie na nastpujce pytania:

- Czym jest dostrajanie dla modeli jzykowych?
- Kiedy i dlaczego dostrajanie jest przydatne?
- Jak mog dostroi wstpnie wytrenowany model?
- Jakie s ograniczenia dostrajania?

Gotowy? Zaczynajmy.

## Ilustrowany przewodnik

Chcesz zobaczy og贸lny obraz tego, co bdziemy omawia, zanim zagbimy si w szczeg贸y? Sprawd藕 ten ilustrowany przewodnik, kt贸ry opisuje cie偶k nauki dla tej lekcji - od poznania podstawowych koncepcji i motywacji do dostrajania, po zrozumienie procesu i najlepszych praktyk dotyczcych wykonywania zadania dostrajania. To fascynujcy temat do eksploracji, wic nie zapomnij sprawdzi strony [Zasoby](./RESOURCES.md?WT.mc_id=academic-105485-koreyst) z dodatkowymi linkami wspierajcymi Twoj samodzieln cie偶k nauki!

![Ilustrowany przewodnik po dostrajaniu modeli jzykowych](../../../translated_images/18-fine-tuning-sketchnote.92733966235199dd260184b1aae3a84b877c7496bc872d8e63ad6fa2dd96bafc.pl.png)

## Czym jest dostrajanie dla modeli jzykowych?

Z definicji, du偶e modele jzykowe s _wstpnie wytrenowane_ na du偶ych ilociach tekstu pochodzcego z r贸偶nych 藕r贸de, w tym z internetu. Jak nauczylimy si w poprzednich lekcjach, potrzebujemy technik takich jak _in偶ynieria prompt贸w_ i _generacja wspomagana wyszukiwaniem_, aby poprawi jako odpowiedzi modelu na pytania u偶ytkownika ("prompty").

Popularna technika in偶ynierii prompt贸w polega na dostarczeniu modelowi wikszej iloci wskaz贸wek dotyczcych oczekiwanego wyniku odpowiedzi, poprzez dostarczenie _instrukcji_ (wyra藕ne wskaz贸wki) lub _podanie kilku przykad贸w_ (niejawne wskaz贸wki). To jest okrelane jako _uczenie si na kilku przykadach_, ale ma dwie ograniczenia:

- Limity token贸w modelu mog ogranicza liczb przykad贸w, kt贸re mo偶esz poda, i ogranicza skuteczno.
- Koszty token贸w modelu mog sprawi, 偶e dodanie przykad贸w do ka偶dego promptu bdzie kosztowne i ogranicza elastyczno.

Dostrajanie jest powszechn praktyk w systemach uczenia maszynowego, gdzie bierzemy wstpnie wytrenowany model i ponownie go trenujemy z nowymi danymi, aby poprawi jego wydajno w konkretnym zadaniu. W kontekcie modeli jzykowych mo偶emy dostroi wstpnie wytrenowany model _z wyselekcjonowanym zestawem przykad贸w dla danego zadania lub domeny aplikacji_, aby stworzy **model niestandardowy**, kt贸ry mo偶e by bardziej dokadny i trafny dla tego konkretnego zadania lub domeny. Dodatkow korzyci dostrajania jest to, 偶e mo偶e r贸wnie偶 zmniejszy liczb przykad贸w potrzebnych do uczenia si na kilku przykadach - zmniejszajc zu偶ycie token贸w i zwizane z tym koszty.

## Kiedy i dlaczego powinnimy dostraja modele?

W _tym_ kontekcie, gdy m贸wimy o dostrajaniu, odnosimy si do **nadzorowanego** dostrajania, gdzie ponowne trenowanie odbywa si poprzez **dodanie nowych danych**, kt贸re nie byy czci pierwotnego zestawu danych treningowych. Jest to inne ni偶 podejcie dostrajania nienadzorowanego, gdzie model jest ponownie trenowany na pierwotnych danych, ale z innymi hiperparametrami.

Kluczow rzecz do zapamitania jest to, 偶e dostrajanie jest zaawansowan technik, kt贸ra wymaga pewnego poziomu wiedzy, aby osign po偶dane rezultaty. Jeli zostanie wykonane nieprawidowo, mo偶e nie zapewni oczekiwanych ulepsze, a nawet pogorszy wydajno modelu dla Twojej docelowej domeny.

Wic zanim nauczysz si "jak" dostraja modele jzykowe, musisz wiedzie "dlaczego" powiniene obra t drog i "kiedy" rozpocz proces dostrajania. Zacznij od zadania sobie tych pyta:

- **Zastosowanie**: Jaki jest Tw贸j _przypadek u偶ycia_ dla dostrajania? Jaki aspekt obecnego wstpnie wytrenowanego modelu chcesz poprawi?
- **Alternatywy**: Czy pr贸bowae _innych technik_, aby osign po偶dane rezultaty? U偶yj ich do stworzenia punktu odniesienia do por贸wnania.
  - In偶ynieria prompt贸w: Wypr贸buj techniki takie jak promptowanie na kilku przykadach z odpowiedziami na odpowiednie prompty. Oce jako odpowiedzi.
  - Generacja wspomagana wyszukiwaniem: Wypr贸buj augmentacj prompt贸w z wynikami zapyta uzyskanymi poprzez wyszukiwanie w swoich danych. Oce jako odpowiedzi.
- **Koszty**: Czy zidentyfikowae koszty dostrajania?
  - Dostpno do dostrajania - czy wstpnie wytrenowany model jest dostpny do dostrajania?
  - Wysiek - na przygotowanie danych treningowych, ocen i udoskonalanie modelu.
  - Obliczenia - na uruchamianie zada dostrajania i wdra偶anie dostrojonego modelu
  - Dane - dostp do wystarczajcej iloci jakociowych przykad贸w dla wpywu dostrajania
- **Korzyci**: Czy potwierdzie korzyci dostrajania?
  - Jako - czy dostrojony model przewy偶szy punkt odniesienia?
  - Koszt - czy zmniejsza zu偶ycie token贸w przez uproszczenie prompt贸w?
  - Rozszerzalno - czy mo偶esz ponownie wykorzysta bazowy model dla nowych domen?

Odpowiadajc na te pytania, powiniene by w stanie zdecydowa, czy dostrajanie jest waciwym podejciem dla Twojego przypadku u偶ycia. Idealnie, podejcie jest wa偶ne tylko wtedy, gdy korzyci przewy偶szaj koszty. Gdy zdecydujesz si kontynuowa, czas pomyle o _jak_ mo偶esz dostroi wstpnie wytrenowany model.

Chcesz uzyska wicej informacji na temat procesu podejmowania decyzji? Obejrzyj [Dostroi czy nie dostroi](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Jak mo偶emy dostroi wstpnie wytrenowany model?

Aby dostroi wstpnie wytrenowany model, potrzebujesz:

- wstpnie wytrenowanego modelu do dostrojenia
- zestawu danych do u偶ycia do dostrajania
- rodowiska treningowego do uruchomienia zadania dostrajania
- rodowiska hostingowego do wdro偶enia dostrojonego modelu

## Dostrajanie w dziaaniu

Poni偶sze zasoby oferuj szczeg贸owe samouczki, kt贸re przeprowadz Ci przez prawdziwy przykad u偶ycia wybranego modelu z wyselekcjonowanym zestawem danych. Aby przej przez te samouczki, potrzebujesz konta u konkretnego dostawcy, wraz z dostpem do odpowiedniego modelu i zestaw贸w danych.

| Dostawca     | Samouczek                                                                                                                                                                       | Opis                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Jak dostroi modele czatu](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)                | Naucz si dostraja `gpt-35-turbo` dla konkretnej domeny ("asystent kulinarny") poprzez przygotowanie danych treningowych, uruchomienie zadania dostrajania i u偶ycie dostrojonego modelu do wnioskowania.                                                                                                                                                                                                                                              |
| Azure OpenAI | [Samouczek dostrajania GPT 3.5 Turbo](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | Naucz si dostraja model `gpt-35-turbo-0613` **na Azure** poprzez podjcie krok贸w w celu stworzenia i przesania danych treningowych, uruchomienia zadania dostrajania. Wdra偶aj i u偶ywaj nowego modelu.                                                                                                                                                                                                                                                                 |
| Hugging Face | [Dostrajanie LLM z Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                               | Ten wpis na blogu przeprowadzi Ci przez dostrajanie _otwartego LLM_ (np. `CodeLlama 7B`) przy u偶yciu biblioteki [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) i [Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst]) z otwartymi [zestawami danych](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) na Hugging Face. |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |
|  AutoTrain | [Dostrajanie LLM z AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                         | AutoTrain (lub AutoTrain Advanced) to biblioteka Python rozwinita przez Hugging Face, kt贸ra umo偶liwia dostrajanie dla wielu r贸偶nych zada, w tym dostrajanie LLM. AutoTrain to rozwizanie bez kodu, a dostrajanie mo偶na przeprowadzi we wasnej chmurze, na Hugging Face Spaces lub lokalnie. Obsuguje zar贸wno GUI oparte na webie, CLI, jak i trening za pomoc plik贸w konfiguracyjnych yaml.                                                                               |
|              |                                                                                                                                                                                |                                                                                                                                                                                                                                                                                                                                                                                                                                    |

## Zadanie

Wybierz jeden z powy偶szych samouczk贸w i przejd藕 przez niego. _Mo偶emy zreplikowa wersj tych samouczk贸w w Jupyter Notebooks w tym repozytorium tylko do cel贸w referencyjnych. Prosz u偶ywa bezporednio oryginalnych 藕r贸de, aby uzyska najnowsze wersje_.

## wietna robota! Kontynuuj nauk.

Po ukoczeniu tej lekcji, sprawd藕 nasz [kolekcj nauki Generative AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby kontynuowa rozwijanie swojej wiedzy na temat Generative AI!

Gratulacje!! Ukoczye ostatni lekcj z serii v2 dla tego kursu! Nie przestawaj si uczy i budowa. **Sprawd藕 stron [ZASOBY](RESOURCES.md?WT.mc_id=academic-105485-koreyst) dla listy dodatkowych sugestii dotyczcych tego tematu.

Nasza seria lekcji v1 r贸wnie偶 zostaa zaktualizowana o wicej zada i koncepcji. Wic powi chwil, aby odwie偶y swoj wiedz - i prosz [podziel si swoimi pytaniami i opini](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst), aby pom贸c nam poprawi te lekcje dla spoecznoci.

**Zastrze偶enie**:  
Ten dokument zosta przetumaczony przy u偶yciu usugi tumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chocia偶 d偶ymy do dokadnoci, prosimy pamita, 偶e automatyczne tumaczenia mog zawiera bdy lub niecisoci. Oryginalny dokument w jego rodzimym jzyku powinien by uznawany za wiarygodne 藕r贸do. W przypadku informacji krytycznych zaleca si profesjonalne tumaczenie przez czowieka. Nie ponosimy odpowiedzialnoci za wszelkie nieporozumienia lub bdne interpretacje wynikajce z u偶ycia tego tumaczenia.