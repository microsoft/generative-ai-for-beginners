{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Buduj aplikacje generujące tekst\n",
    "\n",
    "W trakcie tego kursu poznałeś już podstawowe pojęcia, takie jak prompt, a nawet całą dziedzinę zwaną \"inżynierią promptów\". Wiele narzędzi, z których możesz korzystać, takich jak ChatGPT, Office 365, Microsoft Power Platform i inne, pozwala używać promptów do realizacji różnych zadań.\n",
    "\n",
    "Aby dodać takie możliwości do swojej aplikacji, musisz zrozumieć pojęcia takie jak prompt, completion oraz wybrać bibliotekę, z którą będziesz pracować. Właśnie tego nauczysz się w tym rozdziale.\n",
    "\n",
    "## Wprowadzenie\n",
    "\n",
    "W tym rozdziale:\n",
    "\n",
    "- Poznasz bibliotekę openai i jej kluczowe pojęcia.\n",
    "- Zbudujesz aplikację generującą tekst z użyciem openai.\n",
    "- Dowiesz się, jak wykorzystać takie pojęcia jak prompt, temperatura i tokeny do stworzenia aplikacji generującej tekst.\n",
    "\n",
    "## Cele nauki\n",
    "\n",
    "Po zakończeniu tej lekcji będziesz potrafić:\n",
    "\n",
    "- Wyjaśnić, czym jest aplikacja generująca tekst.\n",
    "- Zbudować aplikację generującą tekst z użyciem openai.\n",
    "- Skonfigurować aplikację tak, by używała więcej lub mniej tokenów oraz zmieniać temperaturę, aby uzyskać różnorodne wyniki.\n",
    "\n",
    "## Czym jest aplikacja generująca tekst?\n",
    "\n",
    "Zazwyczaj, gdy tworzysz aplikację, ma ona jakiś interfejs, na przykład:\n",
    "\n",
    "- Oparta na komendach. Typowe aplikacje konsolowe, w których wpisujesz komendę, a ona wykonuje zadanie. Przykładem jest `git`.\n",
    "- Interfejs użytkownika (UI). Niektóre aplikacje mają graficzny interfejs, gdzie klikasz przyciski, wpisujesz tekst, wybierasz opcje i więcej.\n",
    "\n",
    "### Aplikacje konsolowe i UI mają ograniczenia\n",
    "\n",
    "Porównaj to z aplikacją opartą na komendach, gdzie wpisujesz polecenie:\n",
    "\n",
    "- **Są ograniczone**. Nie możesz wpisać dowolnej komendy, tylko te, które aplikacja obsługuje.\n",
    "- **Specyficzne dla języka**. Niektóre aplikacje obsługują wiele języków, ale domyślnie są stworzone dla konkretnego języka, nawet jeśli można dodać wsparcie dla innych.\n",
    "\n",
    "### Zalety aplikacji generujących tekst\n",
    "\n",
    "Czym więc różni się aplikacja generująca tekst?\n",
    "\n",
    "W takiej aplikacji masz większą swobodę, nie jesteś ograniczony do zestawu komend czy konkretnego języka wejściowego. Zamiast tego możesz używać języka naturalnego do komunikacji z aplikacją. Kolejną zaletą jest to, że korzystasz z bazy danych, która została wytrenowana na ogromnej ilości informacji, podczas gdy tradycyjna aplikacja może być ograniczona do tego, co znajduje się w bazie danych.\n",
    "\n",
    "### Co mogę zbudować z aplikacją generującą tekst?\n",
    "\n",
    "Możliwości jest wiele. Na przykład:\n",
    "\n",
    "- **Chatbot**. Chatbot odpowiadający na pytania dotyczące różnych tematów, np. Twojej firmy i jej produktów, to świetne zastosowanie.\n",
    "- **Asystent**. LLM-y świetnie sprawdzają się w podsumowywaniu tekstu, wyciąganiu wniosków, tworzeniu tekstów takich jak CV i wielu innych zadaniach.\n",
    "- **Asystent programisty**. W zależności od używanego modelu językowego możesz stworzyć asystenta, który pomoże Ci pisać kod. Przykładem są produkty takie jak GitHub Copilot czy ChatGPT.\n",
    "\n",
    "## Jak zacząć?\n",
    "\n",
    "Musisz znaleźć sposób na integrację z LLM, co zazwyczaj sprowadza się do dwóch podejść:\n",
    "\n",
    "- Użycie API. Tworzysz zapytania webowe z promptem i otrzymujesz wygenerowany tekst.\n",
    "- Użycie biblioteki. Biblioteki ułatwiają wywoływanie API i upraszczają korzystanie z nich.\n",
    "\n",
    "## Biblioteki/SDK\n",
    "\n",
    "Jest kilka znanych bibliotek do pracy z LLM, takich jak:\n",
    "\n",
    "- **openai** – ta biblioteka pozwala łatwo połączyć się z modelem i wysyłać prompt.\n",
    "\n",
    "Są też biblioteki działające na wyższym poziomie, na przykład:\n",
    "\n",
    "- **Langchain**. Langchain jest dobrze znany i wspiera Pythona.\n",
    "- **Semantic Kernel**. Semantic Kernel to biblioteka Microsoftu wspierająca C#, Pythona i Javę.\n",
    "\n",
    "## Pierwsza aplikacja z GitHub Models Playground i Azure AI Inference SDK\n",
    "\n",
    "Zobaczmy, jak zbudować pierwszą aplikację, jakich bibliotek potrzebujemy, ile pracy to wymaga i tak dalej.\n",
    "\n",
    "### Czym są GitHub Models?\n",
    "\n",
    "Witaj w [GitHub Models](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)! Wszystko jest już gotowe, byś mógł eksplorować różne modele AI hostowane na Azure AI, dostępne przez playground na GitHubie lub bezpośrednio w ulubionym IDE, całkowicie za darmo.\n",
    "\n",
    "### Czego potrzebuję?\n",
    "\n",
    "* Konto GitHub: [github.com/signup](https://github.com/signup?WT.mc_id=academic-105485-koreyst)\n",
    "* Zapisz się do GitHub Models: [github.com/marketplace/models/waitlist](https://GitHub.com/marketplace/models/waitlist?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Zaczynajmy!\n",
    "\n",
    "### Znajdź model i przetestuj go\n",
    "\n",
    "Przejdź do [GitHub Models w Marketplace](https://github.com/marketplace/models?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "![Główna strona GitHub Models pokazująca listę kart modeli, takich jak Cohere, Meta llama, Mistral i GPT](../../../../translated_images/GithubModelsMainScreen.62aed2c56e2bee6499716d6b2743a7a1b54ee8e25059137ee907b1d45e40d66e.pl.png)\n",
    "\n",
    "Wybierz model – na przykład [Open AI GPT-4o](https://github.com/marketplace/models/azure-openai/gpt-4o?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "Zobaczysz kartę modelu. Możesz:\n",
    "* Interaktywnie korzystać z modelu, wpisując wiadomość w polu tekstowym\n",
    "* Przeczytać szczegóły o modelu w zakładkach readme, Evaluation, Transparency i License\n",
    "* Przejrzeć sekcję 'About' po prawej, by dowiedzieć się więcej o dostępie do modelu\n",
    "\n",
    "![Karta modelu GitHub Models GPT-4o](../../../../translated_images/GithubModels-modelcard.c65ce4538e7bee923f0c5dd8d2250e8e1873a95db88bdc6648d1ae78af5f4db6.pl.png)\n",
    "\n",
    "Ale przejdziemy od razu do playground, klikając [przycisk 'Playground' w prawym górnym rogu](https://github.com/marketplace/models/azure-openai/gpt-4o/playground?WT.mc_id=academic-105485-koreyst). Tutaj możesz korzystać z modelu, dodawać systemowe prompt i zmieniać parametry – a także pobrać cały kod potrzebny do uruchomienia tego gdziekolwiek. Dostępne od września 2024: Python, Javascript, C# i REST.\n",
    "\n",
    "![Doświadczenie GitHub Models Playground z kodem i pokazanymi językami](../../../../translated_images/GithubModels-plagroundcode.da2dea486f1ad5e0f567fd67ff46b61c023683e4af953390583ff7d7b744491b.pl.png)  \n",
    "\n",
    "\n",
    "### Użyj modelu w swoim IDE\n",
    "\n",
    "Masz dwie opcje:\n",
    "1. **GitHub Codespaces** – płynna integracja z Codespaces, nie potrzebujesz tokena na start\n",
    "2. **VS Code (lub dowolne ulubione IDE)** – musisz uzyskać [Personal Access Token z GitHub](https://github.com/settings/tokens?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "\n",
    "W obu przypadkach instrukcje znajdziesz po kliknięciu zielonego przycisku 'Get started' w prawym górnym rogu.\n",
    "\n",
    "![Ekran Get Started pokazujący, jak uzyskać dostęp do Codespaces lub użyć personal access token do konfiguracji w swoim IDE](../../../../translated_images/GithubModels-getstarted.4821f6f3182fc66620ed25fc5eaecb957298e7d17fad97e51b2e28d1e9d6693c.pl.png)\n",
    "\n",
    "### 1. Codespaces \n",
    "\n",
    "* W oknie 'Get started' wybierz \"Run codespace\"\n",
    "* Utwórz nowy codespace (lub użyj istniejącego)\n",
    "* VS Code otworzy się w przeglądarce z zestawem przykładowych notebooków w różnych językach, które możesz wypróbować\n",
    "* Uruchom przykład ```./githubmodels-app.py```. \n",
    "\n",
    "> Note: W codespaces nie trzeba ustawiać zmiennej Github Token, pomiń ten krok\n",
    "\n",
    "**Przejdź teraz do sekcji 'Generowanie tekstu', aby kontynuować zadanie**\n",
    "\n",
    "### 2. VS Code (lub dowolne ulubione IDE)\n",
    "\n",
    "Po kliknięciu zielonego przycisku 'Get started' znajdziesz wszystkie informacje potrzebne do uruchomienia w swoim IDE. Ten przykład pokazuje VS Code\n",
    "\n",
    "* Wybierz język i SDK – w tym przykładzie wybieramy Python i Azure AI Inference SDK\n",
    "* Utwórz personal access token na GitHub. Znajdziesz to w sekcji Developer Settings. Token nie wymaga żadnych uprawnień. Pamiętaj, że token zostanie wysłany do usługi Microsoft.\n",
    "* Utwórz zmienną środowiskową do przechowywania tokena – przykłady dostępne dla bash, powershell i windows command prompt\n",
    "* Zainstaluj zależności: ```pip install azure-ai-inference```\n",
    "* Skopiuj podstawowy kod do pliku .py\n",
    "* Przejdź do folderu z kodem i uruchom plik: ```python filename.py```\n",
    "\n",
    "Pamiętaj, że korzystając z Azure AI Inference SDK, możesz łatwo eksperymentować z różnymi modelami, zmieniając wartość `model_name` w kodzie. \n",
    "\n",
    "W GitHub Models dostępne są następujące modele (stan na wrzesień 2024):\n",
    "\n",
    "* AI21 Labs: AI21-Jamba-1.5-Large, AI21-Jamba-1.5-Mini, AI21-Jamba-Instruct\n",
    "* Cohere: Cohere-Command-R, Cohere-Command-R-Plus, Cohere-Embed-v3-Multilingual, Cohere-Embed-v3-English\n",
    "* Meta: Meta-Llama-3-70B-Instruct, Meta-Llama-3-8B-Instruct, Meta-Llama-3.1-405B-Instruct, Meta-Llama-3.1-70B-Instruct, Meta-Llama-3.1-8B-Instruct\n",
    "* Mistral AI: Mistral-Large, Mistral-Large-2407, Mistral-Nemo, Mistral-Small\n",
    "* Microsoft: Phi-3-mini-4k-instruct, Phi-3.5-mini-128k-instruct, Phi-3-small-4k-instruct, Phi-3-small-128k-instruct, Phi-3-medium-4k-instruct, Phi-3-medium-128k-instruct, Phi-3.5-vision-128k-instruct\n",
    "* OpenAI: OpenAI-GPT-4o, Open-AI-GPT-4o-mini, OpenAI-Textembedding-3-large, OpenAI-Textembedding-3-small\n",
    "\n",
    "\n",
    "\n",
    "**Przejdź teraz do sekcji 'Generowanie tekstu', aby kontynuować zadanie**\n",
    "\n",
    "## Generowanie tekstu z ChatCompletions\n",
    "\n",
    "Aby wygenerować tekst, użyj klasy `ChatCompletionsClient`. \n",
    "W pliku `samples/python/azure_ai_inference/basic.py`, w sekcji odpowiedzi, zaktualizuj kod roli użytkownika, zmieniając parametr content na poniższy:\n",
    "\n",
    "```python\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Complete the following: Once upon a time there was a\",\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "```\n",
    "\n",
    "Uruchom zaktualizowany plik, aby zobaczyć wynik\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Różne rodzaje promptów do różnych zastosowań\n",
    "\n",
    "Widziałeś już, jak generować tekst za pomocą promptu. Masz nawet działający program, który możesz modyfikować i zmieniać, aby generować różne rodzaje tekstów.\n",
    "\n",
    "Prompty można wykorzystywać do wielu różnych zadań. Na przykład:\n",
    "\n",
    "- **Generowanie określonego typu tekstu**. Możesz na przykład wygenerować wiersz, pytania do quizu itp.\n",
    "- **Wyszukiwanie informacji**. Prompty mogą służyć do szukania informacji, np. w takim stylu: „Co oznacza CORS w programowaniu webowym?”.\n",
    "- **Generowanie kodu**. Prompty mogą posłużyć do generowania kodu, np. stworzenia wyrażenia regularnego do walidacji adresów e-mail albo nawet całego programu, np. aplikacji webowej.\n",
    "\n",
    "## Ćwiczenie: generator przepisów\n",
    "\n",
    "Wyobraź sobie, że masz w domu pewne składniki i chcesz coś ugotować. Do tego potrzebujesz przepisu. Jednym ze sposobów na znalezienie przepisu jest użycie wyszukiwarki, ale możesz też skorzystać z LLM.\n",
    "\n",
    "Możesz napisać taki prompt:\n",
    "\n",
    "> „Pokaż mi 5 przepisów na danie z następującymi składnikami: kurczak, ziemniaki i marchewka. Dla każdego przepisu wypisz wszystkie użyte składniki.”\n",
    "\n",
    "Na taki prompt możesz otrzymać odpowiedź podobną do tej:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 2 cloves garlic, minced\n",
    "- 1 teaspoon dried oregano\n",
    "```\n",
    "\n",
    "To świetny rezultat, wiem już, co mogę ugotować. W tym momencie przydatne mogą być następujące ulepszenia:\n",
    "\n",
    "- Odfiltrowanie składników, których nie lubię lub na które mam alergię.\n",
    "- Stworzenie listy zakupów, jeśli nie mam wszystkich składników w domu.\n",
    "\n",
    "W powyższych przypadkach możemy dodać kolejny prompt:\n",
    "\n",
    "> „Proszę usuń przepisy z czosnkiem, ponieważ mam na niego alergię, i zastąp go czymś innym. Przygotuj też listę zakupów do tych przepisów, biorąc pod uwagę, że mam już w domu kurczaka, ziemniaki i marchewkę.”\n",
    "\n",
    "Teraz otrzymujesz nowy rezultat, czyli:\n",
    "\n",
    "```output\n",
    "1. Roasted Chicken and Vegetables: \n",
    "Ingredients: \n",
    "- 4 chicken thighs\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 2 tablespoons olive oil\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 teaspoon dried oregano\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "2. Chicken and Potato Stew: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "3. Chicken and Potato Bake: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 1 cup chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "4. Chicken and Potato Soup: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 1 onion, diced\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 teaspoon dried oregano\n",
    "- 1 teaspoon dried thyme\n",
    "- 4 cups chicken broth\n",
    "- Salt and pepper, to taste\n",
    "\n",
    "5. Chicken and Potato Hash: \n",
    "Ingredients: \n",
    "- 2 tablespoons olive oil\n",
    "- 2 chicken breasts, cut into cubes\n",
    "- 2 potatoes, cut into cubes\n",
    "- 2 carrots, cut into cubes\n",
    "- 1 onion, diced\n",
    "- 1 teaspoon dried oregano\n",
    "\n",
    "Shopping List: \n",
    "- Olive oil\n",
    "- Onion\n",
    "- Thyme\n",
    "- Oregano\n",
    "- Salt\n",
    "- Pepper\n",
    "```\n",
    "\n",
    "Oto twoje pięć przepisów, bez czosnku, oraz lista zakupów uwzględniająca to, co już masz w domu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ćwiczenie - zbuduj generator przepisów\n",
    "\n",
    "Skoro już przećwiczyliśmy scenariusz, napiszmy kod odpowiadający temu, co zostało pokazane. Aby to zrobić, wykonaj następujące kroki:\n",
    "\n",
    "1. Użyj istniejącego pliku jako punktu wyjścia\n",
    "1. Utwórz zmienną `prompt` i zmodyfikuj przykładowy kod zgodnie z poniższym opisem:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "prompt = \"Show me 5 recipes for a dish with the following ingredients: chicken, potatoes, and carrots. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Jeśli teraz uruchomisz ten kod, powinieneś zobaczyć wynik podobny do:\n",
    "\n",
    "```output\n",
    "### Recipe 1: Classic Chicken Stew\n",
    "#### Ingredients:\n",
    "- 2 lbs chicken thighs or drumsticks, skinless\n",
    "- 4 cups chicken broth\n",
    "- 4 medium potatoes, peeled and diced\n",
    "- 4 large carrots, peeled and sliced\n",
    "- 1 large onion, chopped\n",
    "- 2 cloves garlic, minced\n",
    "- 2 celery stalks, sliced\n",
    "- 1 tsp dried thyme\n",
    "- 1 tsp dried rosemary\n",
    "- Salt and pepper to taste\n",
    "- 2 tbsp olive oil\n",
    "- 2 tbsp flour (optional, for thickening)\n",
    "\n",
    "### Recipe 2: Chicken and Vegetable Roast\n",
    "#### Ingredients:\n",
    "- 4 chicken breasts or thighs\n",
    "- 4 medium potatoes, cut into wedges\n",
    "- 4 large carrots, cut into sticks\n",
    "- 1 large onion, cut into wedges\n",
    "- 3 cloves garlic, minced\n",
    "- 1/4 cup olive oil \n",
    "- 1 tsp paprika\n",
    "- 1 tsp dried oregano\n",
    "- Salt and pepper to taste\n",
    "- Juice of 1 lemon\n",
    "- Fresh parsley, chopped (for garnish)\n",
    "(continued ...)\n",
    "```\n",
    "\n",
    "> NOTE, Twój LLM jest niedeterministyczny, więc za każdym razem, gdy uruchomisz program, możesz otrzymać inne wyniki.\n",
    "\n",
    "Świetnie, zobaczmy, jak możemy to ulepszyć. Aby poprawić działanie, chcemy upewnić się, że kod jest elastyczny, dzięki czemu składniki i liczba przepisów mogą być łatwo zmieniane i ulepszane.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "no_recipes = input(\"No of recipes (for example, 5): \")\n",
    "\n",
    "ingredients = input(\"List of ingredients (for example, chicken, potatoes, and carrots): \")\n",
    "\n",
    "# interpolate the number of recipes into the prompt an ingredients\n",
    "prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used\"\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are a helpful assistant.\",\n",
    "        },\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": prompt,\n",
    "        },\n",
    "    ],\n",
    "    model=model_name,\n",
    "    # Optional parameters\n",
    "    temperature=1.,\n",
    "    max_tokens=1000,\n",
    "    top_p=1.    \n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testowanie kodu może wyglądać tak:\n",
    "\n",
    "```output\n",
    "No of recipes (for example, 5): 2\n",
    "List of ingredients (for example, chicken, potatoes, and carrots): milk, strawberries\n",
    "\n",
    "Sure! Here are two recipes featuring milk and strawberries:\n",
    "\n",
    "### Recipe 1: Strawberry Milkshake\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and sliced\n",
    "- 2 tablespoons sugar (optional, to taste)\n",
    "- 1/2 teaspoon vanilla extract\n",
    "- 5-6 ice cubes\n",
    "\n",
    "#### Instructions:\n",
    "1. Combine the milk, strawberries, sugar (if using), and vanilla extract in a blender.\n",
    "2. Blend on high until smooth and creamy.\n",
    "3. Add the ice cubes and blend again until the ice is fully crushed and the milkshake is frothy.\n",
    "4. Pour into a glass and serve immediately.\n",
    "\n",
    "### Recipe 2: Strawberry Panna Cotta\n",
    "\n",
    "#### Ingredients:\n",
    "- 1 cup milk\n",
    "- 1 cup strawberries, hulled and pureed\n",
    "- 1/4 cup sugar\n",
    "- 1 teaspoon vanilla extract\n",
    "- 1 envelope unflavored gelatin (about 2 1/2 teaspoons)\n",
    "- 2 tablespoons cold water\n",
    "- 1 cup heavy cream\n",
    "\n",
    "#### Instructions:\n",
    "1. Sprinkle the gelatin over the cold water in a small bowl and let it stand for about 5-10 minutes to soften.\n",
    "2. In a saucepan, combine the milk, heavy cream, and sugar. Cook over medium heat, stirring frequently until the sugar is dissolved and the mixture begins to simmer. Do not let it boil.\n",
    "3. Remove the saucepan from the heat and stir in the softened gelatin until completely dissolved.\n",
    "4. Stir in the vanilla extract and allow the mixture to cool slightly.\n",
    "5. Divide the mixture evenly into serving cups or molds and refrigerate for at least 4 hours or until set.\n",
    "6. To prepare the strawberry puree, blend the strawberries until smooth.\n",
    "7. Once the panna cotta is set, spoon the strawberry puree over the top of each panna cotta.\n",
    "8. Serve chilled.\n",
    "\n",
    "Enjoy these delightful recipes!\n",
    "```\n",
    "\n",
    "### Ulepszanie przez dodanie filtra i listy zakupów\n",
    "\n",
    "Mamy już działającą aplikację, która potrafi generować przepisy i jest elastyczna, bo opiera się na danych od użytkownika – zarówno co do liczby przepisów, jak i użytych składników.\n",
    "\n",
    "Aby ją jeszcze ulepszyć, chcemy dodać następujące funkcje:\n",
    "\n",
    "- **Filtrowanie składników**. Chcemy mieć możliwość odfiltrowania składników, których nie lubimy lub na które jesteśmy uczuleni. Aby to osiągnąć, możemy edytować nasz istniejący prompt i dodać warunek filtra na końcu, na przykład tak:\n",
    "\n",
    "    ```python\n",
    "    filter = input(\"Filter (for example, vegetarian, vegan, or gluten-free: \")\n",
    "\n",
    "    prompt = f\"Show me {no_recipes} recipes for a dish with the following ingredients: {ingredients}. Per recipe, list all the ingredients used, no {filter}\"\n",
    "    ```\n",
    "\n",
    "    Powyżej dodajemy `{filter}` na końcu promptu i pobieramy wartość filtra od użytkownika.\n",
    "\n",
    "    Przykładowe uruchomienie programu może teraz wyglądać tak:\n",
    "    \n",
    "    ```output    \n",
    "    No of recipes (for example, 5): 2\n",
    "    List of ingredients (for example, chicken, potatoes, and carrots): onion, milk\n",
    "    Filter (for example, vegetarian, vegan, or gluten-free: no milk\n",
    "    Certainly! Here are two recipes using onion but omitting milk:\n",
    "    \n",
    "    ### Recipe 1: Caramelized Onions\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 2 tablespoons olive oil\n",
    "    - 1 tablespoon butter\n",
    "    - 1 teaspoon salt\n",
    "    - 1 teaspoon sugar (optional)\n",
    "    - 1 tablespoon balsamic vinegar (optional)\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Heat the olive oil and butter in a large skillet over medium heat until the butter is melted.\n",
    "    2. Add the onions and stir to coat them with the oil and butter mixture.\n",
    "    3. Add salt (and sugar if using) to the onions.\n",
    "    4. Cook the onions, stirring occasionally, for about 45 minutes to an hour until they are golden brown and caramelized.\n",
    "    5. If using, add balsamic vinegar during the last 5 minutes of cooking.\n",
    "    6. Remove from heat and serve as a topping for burgers, steak, or as a side dish.\n",
    "    \n",
    "    ### Recipe 2: French Onion Soup\n",
    "    \n",
    "    #### Ingredients:\n",
    "    - 4 large onions, thinly sliced\n",
    "    - 3 tablespoons unsalted butter\n",
    "    - 2 cloves garlic, minced\n",
    "    - 1 teaspoon sugar\n",
    "    - 1 teaspoon salt\n",
    "    - 1/4 cup dry white wine (optional)\n",
    "    - 4 cups beef broth\n",
    "    - 4 cups chicken broth\n",
    "    - 1 bay leaf\n",
    "    - 1 teaspoon fresh thyme, chopped (or 1/2 teaspoon dried thyme)\n",
    "    - 1 baguette, sliced\n",
    "    - 2 cups Gruyère cheese, grated\n",
    "    \n",
    "    #### Instructions:\n",
    "    1. Melt the butter in a large pot over medium heat.\n",
    "    2. Add the onions, garlic, sugar, and salt, and cook, stirring frequently, until the onions are deeply caramelized (about 30-35 minutes).\n",
    "    3. If using, add the white wine and cook until it evaporates, about 3-5 minutes.\n",
    "    4. Add the beef and chicken broths, bay leaf, and thyme. Bring to a simmer and cook for another 30 minutes. Remove the bay leaf.\n",
    "    5. Preheat the oven to 400°F (200°C).\n",
    "    6. Place the baguette slices on a baking sheet and toast them in the preheated oven until golden brown, about 5 minutes.\n",
    "    7. Ladle the soup into oven-safe bowls and place a slice of toasted baguette on top of each bowl.\n",
    "    8. Sprinkle the grated Gruyère cheese generously over the baguette slices.\n",
    "    9. Place the bowls under the broiler until the cheese is melted and bubbly, about 3-5 minutes.\n",
    "    10. Serve hot.\n",
    "    \n",
    "    Enjoy your delicious onion dishes!\n",
    "    ```\n",
    "    \n",
    "- **Tworzenie listy zakupów**. Chcemy wygenerować listę zakupów, biorąc pod uwagę to, co już mamy w domu.\n",
    "\n",
    "    W tym celu możemy spróbować rozwiązać wszystko w jednym promptcie albo podzielić to na dwa. Spróbujmy tego drugiego podejścia. Proponujemy tutaj dodanie dodatkowego promptu, ale żeby to zadziałało, musimy dodać wynik pierwszego promptu jako kontekst do drugiego.\n",
    "\n",
    "    Znajdź w kodzie miejsce, w którym wyświetlany jest wynik pierwszego promptu i dodaj poniższy kod:\n",
    "\n",
    "    ```python\n",
    "    old_prompt_result = response.choices[0].message.content\n",
    "    prompt = \"Produce a shopping list for the generated recipes and please don't include ingredients that I already have.\"\n",
    "        \n",
    "    new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "    \n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=1.,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "        \n",
    "    # print response\n",
    "    print(\"Shopping list:\")\n",
    "    print(response.choices[0].message.content)\n",
    "    ```\n",
    "\n",
    "    Zwróć uwagę na następujące rzeczy:\n",
    "\n",
    "    - Tworzymy nowy prompt, dodając wynik z pierwszego promptu do nowego promptu:\n",
    "\n",
    "        ```python\n",
    "        new_prompt = f\"{old_prompt_result} {prompt}\"\n",
    "        messages = [{\"role\": \"user\", \"content\": new_prompt}]\n",
    "        ```\n",
    "\n",
    "    - Wysyłamy nowe zapytanie, ale bierzemy też pod uwagę liczbę tokenów, o które prosiliśmy w pierwszym promptcie, więc tym razem ustawiamy `max_tokens` na 1200. **Kilka słów o długości tokenów**. Powinniśmy przemyśleć, ile tokenów potrzebujemy, by wygenerować pożądany tekst. Tokeny kosztują, więc tam, gdzie to możliwe, warto oszczędzać na ich liczbie. Na przykład, czy możemy sformułować prompt tak, by użyć mniej tokenów?\n",
    "\n",
    "        ```python\n",
    "        response = client.complete(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are a helpful assistant.\",\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": new_prompt,\n",
    "                },\n",
    "            ],\n",
    "            model=model_name,\n",
    "            # Optional parameters\n",
    "            temperature=1.,\n",
    "            max_tokens=1200,\n",
    "            top_p=1.    \n",
    "        )    \n",
    "        ```  \n",
    "\n",
    "        Po uruchomieniu tego kodu otrzymujemy taki wynik:\n",
    "\n",
    "        ```output\n",
    "        No of recipes (for example, 5): 1\n",
    "        List of ingredients (for example, chicken, potatoes, and carrots): strawberry, milk\n",
    "        Filter (for example, vegetarian, vegan, or gluten-free): nuts\n",
    "        \n",
    "        Certainly! Here's a simple and delicious recipe for a strawberry milkshake using strawberry and milk as primary ingredients:\n",
    "        \n",
    "        ### Strawberry Milkshake\n",
    "        \n",
    "        #### Ingredients:\n",
    "        - 1 cup fresh strawberries, hulled\n",
    "        - 1 cup cold milk\n",
    "        - 1 tablespoon honey or sugar (optional, to taste)\n",
    "        - 1/2 teaspoon vanilla extract (optional)\n",
    "        - 3-4 ice cubes\n",
    "        \n",
    "        #### Instructions:\n",
    "        1. Wash and hull the strawberries, then slice them in half.\n",
    "        2. In a blender, combine the strawberries, cold milk, honey or sugar (if using), vanilla extract (if using), and ice cubes.\n",
    "        3. Blend until smooth and frothy.\n",
    "        4. Pour the milkshake into a glass.\n",
    "        5. Serve immediately and enjoy your refreshing strawberry milkshake!\n",
    "        \n",
    "        This recipe is nut-free and makes for a delightful and quick treat!\n",
    "        Shopping list:\n",
    "        Sure! Here’s the shopping list for the Strawberry Milkshake recipe based on the ingredients provided. Please adjust based on what you already have at home:\n",
    "        \n",
    "        ### Shopping List:\n",
    "        - Fresh strawberries (1 cup)\n",
    "        - Milk (1 cup)\n",
    "        \n",
    "        Optional:\n",
    "        - Honey or sugar (1 tablespoon)\n",
    "        - Vanilla extract (1/2 teaspoon)\n",
    "        - Ice cubes (3-4)\n",
    "        \n",
    "        Feel free to omit the optional ingredients if you prefer or if you already have them on hand. Enjoy your delicious strawberry milkshake!\n",
    "        ```\n",
    "        \n",
    "- **Eksperymentowanie z temperaturą**. Temperatura to coś, o czym jeszcze nie wspominaliśmy, ale ma duże znaczenie dla działania programu. Im wyższa wartość temperatury, tym bardziej losowy będzie wynik. Im niższa, tym bardziej przewidywalny będzie rezultat. Zastanów się, czy zależy Ci na różnorodności w odpowiedziach.\n",
    "\n",
    "   Aby zmienić temperaturę, możesz użyć parametru `temperature`. Na przykład, jeśli chcesz ustawić temperaturę na 0.5, zrobisz to tak:\n",
    "\n",
    "```python\n",
    "    response = client.complete(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You are a helpful assistant.\",\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": new_prompt,\n",
    "            },\n",
    "        ],\n",
    "        model=model_name,\n",
    "        # Optional parameters\n",
    "        temperature=0.5,\n",
    "        max_tokens=1200,\n",
    "        top_p=1.    \n",
    "    )\n",
    "```\n",
    "\n",
    "   > Pamiętaj, im bliżej 1.0, tym bardziej zróżnicowane będą odpowiedzi.\n",
    "\n",
    "\n",
    "## Zadanie\n",
    "\n",
    "W tym zadaniu możesz wybrać, co chcesz zbudować.\n",
    "\n",
    "Oto kilka propozycji:\n",
    "\n",
    "- Dopracuj generator przepisów, by był jeszcze lepszy. Pobaw się wartościami temperatury i promptami, by zobaczyć, co uda Ci się osiągnąć.\n",
    "- Zbuduj \"kolegę do nauki\". Ta aplikacja powinna odpowiadać na pytania dotyczące wybranego tematu, na przykład Pythona. Możesz mieć prompty typu \"Czym jest dany temat w Pythonie?\" albo prompt, który pokazuje kod dla danego zagadnienia itp.\n",
    "- Bot historyczny – spraw, by historia ożyła. Poproś bota, by wcielił się w wybraną postać historyczną i zadawaj mu pytania o jego życie i czasy.\n",
    "\n",
    "## Rozwiązanie\n",
    "\n",
    "### Kolega do nauki\n",
    "\n",
    "- \"Jesteś ekspertem od języka Python\n",
    "\n",
    "    Zaproponuj lekcję dla początkujących z Pythona w następującym formacie:\n",
    "    \n",
    "    Format:\n",
    "    - pojęcia:\n",
    "    - krótkie wyjaśnienie lekcji:\n",
    "    - ćwiczenie w kodzie z rozwiązaniami\"\n",
    "\n",
    "Powyżej znajduje się przykładowy prompt – zobacz, jak możesz go wykorzystać i dostosować do swoich potrzeb.\n",
    "\n",
    "### Bot historyczny\n",
    "\n",
    "Oto przykładowe prompty, których możesz użyć:\n",
    "\n",
    "- \"Jesteś Abe Lincolnem, opowiedz o sobie w 3 zdaniach i odpowiadaj używając gramatyki i słownictwa, jakiego używałby Abe\"\n",
    "- \"Jesteś Abe Lincolnem, odpowiadaj używając gramatyki i słownictwa, jakiego używałby Abe:\n",
    "\n",
    "   Opowiedz o swoich największych osiągnięciach w 300 słowach:\"\n",
    "\n",
    "## Sprawdzenie wiedzy\n",
    "\n",
    "Do czego służy parametr temperature?\n",
    "\n",
    "1. Kontroluje, jak bardzo losowy jest wynik.\n",
    "1. Kontroluje, jak duża jest odpowiedź.\n",
    "1. Kontroluje, ile tokenów zostanie użytych.\n",
    "\n",
    "Odp: 1\n",
    "\n",
    "Jaki jest dobry sposób na przechowywanie sekretów, takich jak klucze API?\n",
    "\n",
    "1. W kodzie.\n",
    "1. W pliku.\n",
    "1. W zmiennych środowiskowych.\n",
    "\n",
    "Odp: 3, ponieważ zmienne środowiskowe nie są przechowywane w kodzie i można je załadować z poziomu kodu.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Zastrzeżenie**:  \nTen dokument został przetłumaczony przy użyciu usługi tłumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chociaż dokładamy wszelkich starań, aby zapewnić poprawność tłumaczenia, prosimy pamiętać, że automatyczne tłumaczenia mogą zawierać błędy lub nieścisłości. Oryginalny dokument w jego rodzimym języku powinien być uznawany za źródło nadrzędne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnego tłumaczenia wykonanego przez człowieka. Nie ponosimy odpowiedzialności za jakiekolwiek nieporozumienia lub błędne interpretacje wynikające z korzystania z tego tłumaczenia.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "e098ceda5593d3f1a23fbcb99d7164ef",
   "translation_date": "2025-08-25T15:08:58+00:00",
   "source_file": "06-text-generation-apps/python/githubmodels-assignment.ipynb",
   "language_code": "pl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}