<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "b5466bcedc3c75aa35476270362f626a",
  "translation_date": "2025-07-09T16:31:16+00:00",
  "source_file": "15-rag-and-vector-databases/data/frameworks.md",
  "language_code": "pl"
}
-->
# Frameworki sieci neuronowych

Jak juÅ¼ wiemy, aby efektywnie trenowaÄ‡ sieci neuronowe, musimy zrobiÄ‡ dwie rzeczy:

* OperowaÄ‡ na tensorach, np. mnoÅ¼yÄ‡, dodawaÄ‡ oraz obliczaÄ‡ funkcje takie jak sigmoid czy softmax
* ObliczaÄ‡ gradienty wszystkich wyraÅ¼eÅ„, aby mÃ³c przeprowadziÄ‡ optymalizacjÄ™ metodÄ… spadku gradientu

ChociaÅ¼ biblioteka `numpy` radzi sobie z pierwszÄ… czÄ™Å›ciÄ…, potrzebujemy mechanizmu do obliczania gradientÃ³w. W naszym frameworku, ktÃ³ry stworzyliÅ›my w poprzedniej sekcji, musieliÅ›my rÄ™cznie programowaÄ‡ wszystkie funkcje pochodnych w metodzie `backward`, ktÃ³ra realizuje propagacjÄ™ wstecznÄ…. Idealnie, framework powinien dawaÄ‡ moÅ¼liwoÅ›Ä‡ obliczania gradientÃ³w *dowolnego wyraÅ¼enia*, ktÃ³re zdefiniujemy.

KolejnÄ… waÅ¼nÄ… rzeczÄ… jest moÅ¼liwoÅ›Ä‡ wykonywania obliczeÅ„ na GPU lub innych wyspecjalizowanych jednostkach obliczeniowych, takich jak TPU. Trening gÅ‚Ä™bokich sieci neuronowych wymaga *bardzo duÅ¼ej* liczby obliczeÅ„, a moÅ¼liwoÅ›Ä‡ ich rÃ³wnolegÅ‚ego wykonywania na GPU jest niezwykle istotna.

> âœ… Termin 'parallelize' oznacza rozdzielenie obliczeÅ„ na wiele urzÄ…dzeÅ„.

Obecnie dwa najpopularniejsze frameworki do sieci neuronowych to: TensorFlow i PyTorch. Oba oferujÄ… niskopoziomowe API do operacji na tensorach zarÃ³wno na CPU, jak i GPU. Na bazie niskopoziomowego API dostÄ™pne sÄ… takÅ¼e wyÅ¼sze poziomy API, odpowiednio Keras i PyTorch Lightning.

Low-Level API | TensorFlow | PyTorch
--------------|-------------------------------------|--------------------------------
High-level API| Keras | PyTorch

**Niskopoziomowe API** w obu frameworkach pozwalajÄ… budowaÄ‡ tzw. **grafy obliczeniowe**. Graf ten definiuje, jak obliczyÄ‡ wynik (zwykle funkcjÄ™ straty) dla podanych parametrÃ³w wejÅ›ciowych i moÅ¼e byÄ‡ wykonany na GPU, jeÅ›li jest dostÄ™pne. IstniejÄ… funkcje do rÃ³Å¼niczkowania tego grafu i obliczania gradientÃ³w, ktÃ³re nastÄ™pnie moÅ¼na wykorzystaÄ‡ do optymalizacji parametrÃ³w modelu.

**Wysokopoziomowe API** traktujÄ… sieci neuronowe jako **sekwencjÄ™ warstw** i znacznie uÅ‚atwiajÄ… budowÄ™ wiÄ™kszoÅ›ci sieci neuronowych. Trening modelu zwykle wymaga przygotowania danych, a nastÄ™pnie wywoÅ‚ania funkcji `fit`, ktÃ³ra wykonuje caÅ‚y proces.

Wysokopoziomowe API pozwala szybko tworzyÄ‡ typowe sieci neuronowe bez martwienia siÄ™ o wiele szczegÃ³Å‚Ã³w. JednoczeÅ›nie niskopoziomowe API dajÄ… duÅ¼o wiÄ™kszÄ… kontrolÄ™ nad procesem treningu, dlatego sÄ… czÄ™sto wykorzystywane w badaniach, gdy pracujemy z nowymi architekturami sieci neuronowych.

WaÅ¼ne jest teÅ¼ zrozumienie, Å¼e moÅ¼na uÅ¼ywaÄ‡ obu API razem, np. moÅ¼na stworzyÄ‡ wÅ‚asnÄ… architekturÄ™ warstwy sieci korzystajÄ…c z niskopoziomowego API, a nastÄ™pnie uÅ¼yÄ‡ jej w wiÄ™kszej sieci zbudowanej i trenowanej za pomocÄ… wysokopoziomowego API. MoÅ¼na teÅ¼ zdefiniowaÄ‡ sieÄ‡ jako sekwencjÄ™ warstw w wysokopoziomowym API, a nastÄ™pnie uÅ¼yÄ‡ wÅ‚asnej pÄ™tli treningowej na niskim poziomie do optymalizacji. Oba API opierajÄ… siÄ™ na tych samych podstawowych koncepcjach i zostaÅ‚y zaprojektowane tak, aby dobrze ze sobÄ… wspÃ³Å‚pracowaÄ‡.

## Nauka

W tym kursie oferujemy wiÄ™kszoÅ›Ä‡ materiaÅ‚Ã³w zarÃ³wno dla PyTorch, jak i TensorFlow. MoÅ¼esz wybraÄ‡ preferowany framework i przejÅ›Ä‡ tylko przez odpowiadajÄ…ce mu notatniki. JeÅ›li nie jesteÅ› pewien, ktÃ³ry framework wybraÄ‡, przeczytaj dyskusje w internecie na temat **PyTorch vs. TensorFlow**. MoÅ¼esz teÅ¼ zapoznaÄ‡ siÄ™ z oboma frameworkami, aby lepiej je zrozumieÄ‡.

Tam, gdzie to moÅ¼liwe, bÄ™dziemy korzystaÄ‡ z wysokopoziomowych API dla uproszczenia. Jednak uwaÅ¼amy, Å¼e waÅ¼ne jest zrozumienie dziaÅ‚ania sieci neuronowych od podstaw, dlatego na poczÄ…tku zaczynamy od pracy z niskopoziomowym API i tensorami. JeÅ›li jednak chcesz szybko zaczÄ…Ä‡ i nie chcesz poÅ›wiÄ™caÄ‡ duÅ¼o czasu na naukÄ™ tych szczegÃ³Å‚Ã³w, moÅ¼esz pominÄ…Ä‡ ten etap i przejÅ›Ä‡ od razu do notatnikÃ³w z wysokopoziomowym API.

## âœï¸ Ä†wiczenia: Frameworki

Kontynuuj naukÄ™ w nastÄ™pujÄ…cych notatnikach:

Low-Level API | TensorFlow+Keras Notebook | PyTorch
--------------|-------------------------------------|--------------------------------
High-level API| Keras | *PyTorch Lightning*

Po opanowaniu frameworkÃ³w, podsumujmy pojÄ™cie overfittingu.

# Overfitting

Overfitting to niezwykle waÅ¼ne pojÄ™cie w uczeniu maszynowym i bardzo istotne jest, aby je dobrze zrozumieÄ‡!

RozwaÅ¼my problem aproksymacji 5 punktÃ³w (oznaczonych jako `x` na poniÅ¼szych wykresach):

!linear | overfit
-------------------------|--------------------------
**Model liniowy, 2 parametry** | **Model nieliniowy, 7 parametrÃ³w**
BÅ‚Ä…d treningowy = 5.3 | BÅ‚Ä…d treningowy = 0
BÅ‚Ä…d walidacyjny = 5.1 | BÅ‚Ä…d walidacyjny = 20

* Po lewej widzimy dobrÄ… liniowÄ… aproksymacjÄ™. PoniewaÅ¼ liczba parametrÃ³w jest odpowiednia, model dobrze uchwyciÅ‚ rozkÅ‚ad punktÃ³w.
* Po prawej model jest zbyt zÅ‚oÅ¼ony. PoniewaÅ¼ mamy tylko 5 punktÃ³w, a model ma 7 parametrÃ³w, moÅ¼e tak siÄ™ dopasowaÄ‡, Å¼e przejdzie przez wszystkie punkty, co daje bÅ‚Ä…d treningowy rÃ³wny 0. Jednak uniemoÅ¼liwia to modelowi zrozumienie prawidÅ‚owego wzoru danych, dlatego bÅ‚Ä…d walidacyjny jest bardzo wysoki.

Bardzo waÅ¼ne jest znalezienie wÅ‚aÅ›ciwej rÃ³wnowagi miÄ™dzy zÅ‚oÅ¼onoÅ›ciÄ… modelu (liczbÄ… parametrÃ³w) a liczbÄ… prÃ³bek treningowych.

## Dlaczego wystÄ™puje overfitting

  * Za maÅ‚o danych treningowych
  * Model zbyt zÅ‚oÅ¼ony
  * Zbyt duÅ¼o szumu w danych wejÅ›ciowych

## Jak wykryÄ‡ overfitting

Jak widaÄ‡ na powyÅ¼szym wykresie, overfitting moÅ¼na wykryÄ‡ po bardzo niskim bÅ‚Ä™dzie treningowym i wysokim bÅ‚Ä™dzie walidacyjnym. Zazwyczaj podczas treningu oba bÅ‚Ä™dy â€“ treningowy i walidacyjny â€“ zaczynajÄ… spadaÄ‡, a nastÄ™pnie w pewnym momencie bÅ‚Ä…d walidacyjny przestaje maleÄ‡ i zaczyna rosnÄ…Ä‡. To jest sygnaÅ‚ overfittingu i wskazÃ³wka, Å¼e powinniÅ›my prawdopodobnie zatrzymaÄ‡ trening w tym momencie (lub przynajmniej zrobiÄ‡ migawkÄ™ modelu).

overfitting

## Jak zapobiegaÄ‡ overfittingowi

JeÅ›li zauwaÅ¼ysz, Å¼e wystÄ™puje overfitting, moÅ¼esz zrobiÄ‡ jednÄ… z nastÄ™pujÄ…cych rzeczy:

 * ZwiÄ™kszyÄ‡ iloÅ›Ä‡ danych treningowych
 * ZmniejszyÄ‡ zÅ‚oÅ¼onoÅ›Ä‡ modelu
 * ZastosowaÄ‡ technikÄ™ regularizacji, takÄ… jak Dropout, ktÃ³rÄ… omÃ³wimy pÃ³Åºniej.

## Overfitting a kompromis Bias-Variance

Overfitting jest wÅ‚aÅ›ciwie przypadkiem bardziej ogÃ³lnego problemu w statystyce zwanego kompromisem Bias-Variance. JeÅ›li rozwaÅ¼ymy moÅ¼liwe ÅºrÃ³dÅ‚a bÅ‚Ä™dÃ³w w naszym modelu, moÅ¼emy wyrÃ³Å¼niÄ‡ dwa typy bÅ‚Ä™dÃ³w:

* **BÅ‚Ä™dy bias** sÄ… spowodowane tym, Å¼e nasz algorytm nie potrafi poprawnie uchwyciÄ‡ zaleÅ¼noÅ›ci w danych treningowych. MoÅ¼e to wynikaÄ‡ z faktu, Å¼e model nie jest wystarczajÄ…co zÅ‚oÅ¼ony (**underfitting**).
* **BÅ‚Ä™dy wariancji**, ktÃ³re wynikajÄ… z tego, Å¼e model aproksymuje szum w danych wejÅ›ciowych zamiast istotnych zaleÅ¼noÅ›ci (**overfitting**).

Podczas treningu bÅ‚Ä…d bias maleje (gdy model uczy siÄ™ aproksymowaÄ‡ dane), a bÅ‚Ä…d wariancji roÅ›nie. WaÅ¼ne jest, aby zatrzymaÄ‡ trening â€“ albo rÄ™cznie (gdy wykryjemy overfitting), albo automatycznie (poprzez wprowadzenie regularizacji) â€“ aby zapobiec overfittingowi.

## Podsumowanie

W tej lekcji dowiedziaÅ‚eÅ› siÄ™ o rÃ³Å¼nicach miÄ™dzy rÃ³Å¼nymi API w dwÃ³ch najpopularniejszych frameworkach AI, TensorFlow i PyTorch. Ponadto poznaÅ‚eÅ› bardzo waÅ¼ny temat, jakim jest overfitting.

## ğŸš€ Wyzwanie

W doÅ‚Ä…czonych notatnikach znajdziesz na dole â€zadaniaâ€; przejdÅº przez notatniki i wykonaj te zadania.

## PowtÃ³rka i samodzielna nauka

ZrÃ³b research na nastÄ™pujÄ…ce tematy:

- TensorFlow
- PyTorch
- Overfitting

Zadaj sobie nastÄ™pujÄ…ce pytania:

- Jaka jest rÃ³Å¼nica miÄ™dzy TensorFlow a PyTorch?
- Jaka jest rÃ³Å¼nica miÄ™dzy overfittingiem a underfittingiem?

## Zadanie

W tym laboratorium masz rozwiÄ…zaÄ‡ dwa problemy klasyfikacji, uÅ¼ywajÄ…c jedno- i wielowarstwowych w peÅ‚ni poÅ‚Ä…czonych sieci, korzystajÄ…c z PyTorch lub TensorFlow.

**ZastrzeÅ¼enie**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony za pomocÄ… usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do dokÅ‚adnoÅ›ci, prosimy mieÄ‡ na uwadze, Å¼e tÅ‚umaczenia automatyczne mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.