<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "2b4c36be7d66b32e4fac47761718b4a9",
  "translation_date": "2025-07-09T11:31:44+00:00",
  "source_file": "05-advanced-prompts/README.md",
  "language_code": "pl"
}
-->

> "Generuj kod dla Python Web API"
```python
#import necessary libraries
import flask
from flask import request, jsonify

#create an instance of the Flask class
app = flask.Flask(__name__)

#create an endpoint for the API
@app.route('/api/v1/endpoint', methods=['GET'])
def api_endpoint():
    #get the request data
    data = request.get_json()

    #process the data
    result = process_data(data)

    #return the result
    return jsonify(result)

#function to process the data
def process_data(data):
    #process the data
    result = {'result': 'success'}

    #return the result
    return result

#run the Flask app
if __name__ == '__main__':
    app.run()

```

Ponowne uruchomienie promptu daje nam taki wynik:

```python
#import necessary libraries
import flask
from flask import request, jsonify

#create a Flask app
app = flask.Flask(__name__)

#create a route for the API
@app.route('/api', methods=['GET'])
def api_call():
    #get the data from the request
    data = request.get_json()

    #process the data
    result = process_data(data)

    #return the result
    return jsonify(result)

#define the process_data function
def process_data(data):
    #do something with the data
    result = data + 1

    #return the result
    return result

#run the app
if __name__ == '__main__':
    app.run()

```

RÃ³Å¼nica miÄ™dzy tymi dwoma wynikami jest minimalna. Tym razem zrÃ³bmy odwrotnie i ustawmy temperaturÄ™ na 0.9:

```python
# Import necessary libraries
import flask
from flask import request, jsonify

# Create a Flask app
app = flask.Flask(__name__)

# Create a route for the API
@app.route('/api', methods=['GET'])
def api_call():
    # Get the data from the request
    data = request.args

    # Process the data
    result = process_data(data)

    # Return the result
    return jsonify(result)

# Function to process the data
def process_data(data):
    # Do something with the data
    result = data + 1

    # Return the result
    return result

# Run the app
if __name__ == '__main__':
    app.run()

```

a to druga prÃ³ba z temperaturÄ… ustawionÄ… na 0.9:

```python
import flask
from flask import request, jsonify

# create the Flask app
app = flask.Flask(__name__)
app.config['DEBUG'] = True

# create some test data
books = [
    {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},
    {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},
    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}
]

# create an endpoint
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Welcome to our book API!</h1>'''

@app.route('/api/v1/resources/books

```

Jak widaÄ‡, rezultaty sÄ… znacznie bardziej zrÃ³Å¼nicowane.

> PamiÄ™taj, Å¼e istnieje wiÄ™cej parametrÃ³w, ktÃ³re moÅ¼esz zmieniaÄ‡, aby uzyskaÄ‡ rÃ³Å¼norodne wyniki, takich jak top-k, top-p, repetition penalty, length penalty czy diversity penalty, ale te tematy wykraczajÄ… poza zakres tego kursu.

## Dobre praktyki

Istnieje wiele praktyk, ktÃ³re moÅ¼esz stosowaÄ‡, aby uzyskaÄ‡ oczekiwany efekt. Z czasem, korzystajÄ…c z promptÃ³w, wypracujesz swÃ³j wÅ‚asny styl.

OprÃ³cz technik, ktÃ³re omÃ³wiliÅ›my, warto pamiÄ™taÄ‡ o kilku dobrych praktykach podczas tworzenia promptÃ³w dla LLM.

Oto kilka z nich:

- **OkreÅ›l kontekst**. Kontekst ma znaczenie â€“ im wiÄ™cej szczegÃ³Å‚Ã³w podasz, takich jak dziedzina, temat itp., tym lepiej.
- Ogranicz wynik. JeÅ›li chcesz okreÅ›lonÄ… liczbÄ™ elementÃ³w lub konkretnÄ… dÅ‚ugoÅ›Ä‡, zaznacz to.
- **OkreÅ›l zarÃ³wno co, jak i jak**. PamiÄ™taj, aby wskazaÄ‡ zarÃ³wno co chcesz, jak i w jaki sposÃ³b, np. â€StwÃ³rz Python Web API z trasami products i customers, podziel je na 3 plikiâ€.
- **UÅ¼ywaj szablonÃ³w**. CzÄ™sto bÄ™dziesz chciaÅ‚ wzbogaciÄ‡ swoje prompta o dane z firmy. Wykorzystaj do tego szablony, ktÃ³re mogÄ… zawieraÄ‡ zmienne zastÄ™powane rzeczywistymi danymi.
- **Poprawna pisownia**. LLM moÅ¼e udzieliÄ‡ poprawnej odpowiedzi, ale jeÅ›li poprawnie napiszesz prompt, otrzymasz lepszy rezultat.

## Zadanie

Oto kod w Pythonie pokazujÄ…cy, jak zbudowaÄ‡ prostÄ… API za pomocÄ… Flask:

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/')
def hello():
    name = request.args.get('name', 'World')
    return f'Hello, {name}!'

if __name__ == '__main__':
    app.run()
```

Skorzystaj z asystenta AI, takiego jak GitHub Copilot lub ChatGPT, i zastosuj technikÄ™ â€self-refineâ€, aby ulepszyÄ‡ ten kod.

## RozwiÄ…zanie

SprÃ³buj rozwiÄ…zaÄ‡ zadanie, dodajÄ…c odpowiednie prompta do kodu.

> [!TIP]
> SformuÅ‚uj prompt z proÅ›bÄ… o ulepszenie, dobrze jest ograniczyÄ‡ liczbÄ™ proponowanych zmian. MoÅ¼esz teÅ¼ poprosiÄ‡ o poprawÄ™ w konkretnym obszarze, np. architektura, wydajnoÅ›Ä‡, bezpieczeÅ„stwo itp.

[Solution](../../../05-advanced-prompts/python/aoai-solution.py)

## Sprawdzenie wiedzy

Dlaczego warto stosowaÄ‡ chain-of-thought prompting? PokaÅ¼ 1 poprawnÄ… odpowiedÅº i 2 bÅ‚Ä™dne.

1. Aby nauczyÄ‡ LLM, jak rozwiÄ…zywaÄ‡ problem.
1. B, Aby nauczyÄ‡ LLM znajdowania bÅ‚Ä™dÃ³w w kodzie.
1. C, Aby nakazaÄ‡ LLM wymyÅ›lanie rÃ³Å¼nych rozwiÄ…zaÅ„.

OdpowiedÅº: 1, poniewaÅ¼ chain-of-thought polega na pokazaniu LLM, jak rozwiÄ…zaÄ‡ problem, dostarczajÄ…c mu serii krokÃ³w oraz podobnych problemÃ³w i sposobÃ³w ich rozwiÄ…zania.

## ğŸš€ Wyzwanie

WÅ‚aÅ›nie uÅ¼yÅ‚eÅ› techniki self-refine w zadaniu. WeÅº dowolny program, ktÃ³ry stworzyÅ‚eÅ›, i zastanÃ³w siÄ™, jakie ulepszenia chciaÅ‚byÅ› wprowadziÄ‡. NastÄ™pnie zastosuj technikÄ™ self-refine, aby wprowadziÄ‡ proponowane zmiany. Jak oceniasz efekt â€“ lepszy czy gorszy?

## Åšwietna robota! Kontynuuj naukÄ™

Po ukoÅ„czeniu tej lekcji sprawdÅº naszÄ… [kolekcjÄ™ Generative AI Learning](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby dalej rozwijaÄ‡ swojÄ… wiedzÄ™ o Generative AI!

PrzejdÅº do Lekcji 6, gdzie zastosujemy naszÄ… wiedzÄ™ o Prompt Engineering, [tworzÄ…c aplikacje do generowania tekstu](../06-text-generation-apps/README.md?WT.mc_id=academic-105485-koreyst)

**ZastrzeÅ¼enie**:  
Niniejszy dokument zostaÅ‚ przetÅ‚umaczony przy uÅ¼yciu usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Mimo Å¼e dÄ…Å¼ymy do dokÅ‚adnoÅ›ci, prosimy mieÄ‡ na uwadze, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jÄ™zyku ÅºrÃ³dÅ‚owym powinien byÄ‡ uznawany za ÅºrÃ³dÅ‚o autorytatywne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnego tÅ‚umaczenia wykonanego przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za jakiekolwiek nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.