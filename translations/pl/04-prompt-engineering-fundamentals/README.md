<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dcbaaae026cb50fee071e690685b5843",
  "translation_date": "2025-08-26T16:42:41+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "pl"
}
-->
# Podstawy InÅ¼ynierii PromptÃ³w

[![Podstawy InÅ¼ynierii PromptÃ³w](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.pl.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Wprowadzenie
Ten moduÅ‚ omawia kluczowe pojÄ™cia i techniki tworzenia skutecznych promptÃ³w dla generatywnych modeli AI. SposÃ³b, w jaki napiszesz prompt do LLM, ma znaczenie. Starannie przygotowany prompt moÅ¼e zapewniÄ‡ lepszÄ… jakoÅ›Ä‡ odpowiedzi. Ale co wÅ‚aÅ›ciwie oznaczajÄ… terminy _prompt_ i _inÅ¼ynieria promptÃ³w_? I jak mogÄ™ ulepszyÄ‡ _input promptu_, ktÃ³ry wysyÅ‚am do LLM? Na te pytania postaramy siÄ™ odpowiedzieÄ‡ w tym rozdziale i kolejnym.

_Generatywna AI_ potrafi tworzyÄ‡ nowe treÅ›ci (np. tekst, obrazy, dÅºwiÄ™k, kod itd.) w odpowiedzi na zapytania uÅ¼ytkownika. OsiÄ…ga to dziÄ™ki _DuÅ¼ym Modelom JÄ™zykowym_ takim jak seria GPT ("Generative Pre-trained Transformer") od OpenAI, ktÃ³re sÄ… trenowane do pracy z jÄ™zykiem naturalnym i kodem.

UÅ¼ytkownicy mogÄ… teraz korzystaÄ‡ z tych modeli w znanych formatach, takich jak czat, bez potrzeby posiadania wiedzy technicznej czy specjalistycznego szkolenia. Modele te sÄ… _oparte na promptach_ â€“ uÅ¼ytkownik wysyÅ‚a tekstowy input (prompt), a AI zwraca odpowiedÅº (completion). NastÄ™pnie moÅ¼na "rozmawiaÄ‡ z AI" w kilku turach, stopniowo dopracowujÄ…c prompt, aÅ¼ odpowiedÅº speÅ‚ni oczekiwania.

"Prompt" staje siÄ™ gÅ‚Ã³wnym _interfejsem programistycznym_ dla aplikacji generatywnej AI, okreÅ›lajÄ…c, co model ma zrobiÄ‡ i wpÅ‚ywajÄ…c na jakoÅ›Ä‡ zwracanych odpowiedzi. "InÅ¼ynieria promptÃ³w" to szybko rozwijajÄ…ca siÄ™ dziedzina, skupiajÄ…ca siÄ™ na _projektowaniu i optymalizacji_ promptÃ³w, by uzyskiwaÄ‡ spÃ³jne i wysokiej jakoÅ›ci odpowiedzi na duÅ¼Ä… skalÄ™.

## Cele nauki

W tej lekcji dowiemy siÄ™, czym jest inÅ¼ynieria promptÃ³w, dlaczego jest waÅ¼na i jak moÅ¼emy tworzyÄ‡ bardziej skuteczne prompt dla wybranego modelu i celu aplikacji. Poznamy podstawowe pojÄ™cia i dobre praktyki w inÅ¼ynierii promptÃ³w â€“ oraz Å›rodowisko "piaskownicy" w Jupyter Notebook, gdzie zobaczymy te koncepcje na prawdziwych przykÅ‚adach.

Po ukoÅ„czeniu tej lekcji bÄ™dziesz w stanie:

1. WyjaÅ›niÄ‡, czym jest inÅ¼ynieria promptÃ³w i dlaczego jest istotna.
2. OpisaÄ‡ elementy promptu i sposÃ³b ich wykorzystania.
3. PoznaÄ‡ dobre praktyki i techniki inÅ¼ynierii promptÃ³w.
4. ZastosowaÄ‡ poznane techniki na prawdziwych przykÅ‚adach, korzystajÄ…c z endpointu OpenAI.

## Kluczowe pojÄ™cia

InÅ¼ynieria promptÃ³w: Praktyka projektowania i udoskonalania inputÃ³w, by kierowaÄ‡ modele AI do generowania poÅ¼Ä…danych wynikÃ³w.
Tokenizacja: Proces przeksztaÅ‚cania tekstu w mniejsze jednostki, zwane tokenami, ktÃ³re model potrafi zrozumieÄ‡ i przetwarzaÄ‡.
LLM-y dostrojone instrukcjami: DuÅ¼e modele jÄ™zykowe (LLM), ktÃ³re zostaÅ‚y dodatkowo wytrenowane na konkretnych instrukcjach, by poprawiÄ‡ trafnoÅ›Ä‡ i precyzjÄ™ odpowiedzi.

## Piaskownica nauki

InÅ¼ynieria promptÃ³w to obecnie bardziej sztuka niÅ¼ nauka. Najlepszy sposÃ³b na rozwiniÄ™cie intuicji w tym zakresie to _praktyka_ i podejÅ›cie prÃ³b i bÅ‚Ä™dÃ³w, Å‚Ä…czÄ…ce wiedzÄ™ z danej dziedziny z zalecanymi technikami i optymalizacjami specyficznymi dla modelu.

Jupyter Notebook doÅ‚Ä…czony do tej lekcji zapewnia Å›rodowisko _piaskownicy_, w ktÃ³rym moÅ¼esz testowaÄ‡ to, czego siÄ™ uczysz â€“ na bieÅ¼Ä…co lub w ramach wyzwania kodowego na koÅ„cu. Do wykonania Ä‡wiczeÅ„ potrzebujesz:

1. **Klucz API Azure OpenAI** â€“ endpoint usÅ‚ugi dla wdroÅ¼onego LLM.
2. **Åšrodowisko Python** â€“ w ktÃ³rym moÅ¼na uruchomiÄ‡ Notebook.
3. **Lokalne zmienne Å›rodowiskowe** â€“ _zrealizuj teraz kroki z [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), by siÄ™ przygotowaÄ‡_.

Notebook zawiera _Ä‡wiczenia startowe_ â€“ ale zachÄ™camy, by dodawaÄ‡ wÅ‚asne sekcje _Markdown_ (opis) i _Code_ (zapytania prompt), by testowaÄ‡ wiÄ™cej przykÅ‚adÃ³w lub pomysÅ‚Ã³w â€“ i rozwijaÄ‡ swojÄ… intuicjÄ™ w projektowaniu promptÃ³w.

## Przewodnik ilustrowany

Chcesz najpierw zobaczyÄ‡ ogÃ³lny obraz tego, co obejmuje ta lekcja? SprawdÅº ten ilustrowany przewodnik, ktÃ³ry pokazuje gÅ‚Ã³wne tematy i kluczowe wnioski, nad ktÃ³rymi warto siÄ™ zastanowiÄ‡ w kaÅ¼dym z nich. Mapa lekcji prowadzi od zrozumienia podstawowych pojÄ™Ä‡ i wyzwaÅ„ do ich rozwiÄ…zania za pomocÄ… odpowiednich technik inÅ¼ynierii promptÃ³w i dobrych praktyk. ZwrÃ³Ä‡ uwagÄ™, Å¼e sekcja "Zaawansowane techniki" w tym przewodniku odnosi siÄ™ do treÅ›ci omawianych w _nastÄ™pnym_ rozdziale tego kursu.

![Ilustrowany przewodnik po inÅ¼ynierii promptÃ³w](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.pl.png)

## Nasz startup

Porozmawiajmy teraz, jak _ten temat_ Å‚Ä…czy siÄ™ z naszÄ… misjÄ… startupowÄ…, by [wprowadzaÄ‡ innowacje AI do edukacji](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Chcemy budowaÄ‡ aplikacje AI wspierajÄ…ce _spersonalizowanÄ… naukÄ™_ â€“ wiÄ™c zastanÃ³wmy siÄ™, jak rÃ³Å¼ni uÅ¼ytkownicy naszej aplikacji mogÄ… "projektowaÄ‡" prompt:

- **Administratorzy** mogÄ… poprosiÄ‡ AI o _analizÄ™ danych programowych w celu wykrycia luk w zakresie materiaÅ‚u_. AI moÅ¼e podsumowaÄ‡ wyniki lub zwizualizowaÄ‡ je za pomocÄ… kodu.
- **Nauczyciele** mogÄ… poprosiÄ‡ AI o _stworzenie planu lekcji dla okreÅ›lonej grupy odbiorcÃ³w i tematu_. AI moÅ¼e przygotowaÄ‡ spersonalizowany plan w wybranym formacie.
- **Uczniowie** mogÄ… poprosiÄ‡ AI o _pomoc w trudnym przedmiocie_. AI moÅ¼e prowadziÄ‡ ucznia przez lekcje, wskazÃ³wki i przykÅ‚ady dostosowane do jego poziomu.

To tylko wierzchoÅ‚ek gÃ³ry lodowej. Zajrzyj do [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) â€“ otwartej biblioteki promptÃ³w przygotowanej przez ekspertÃ³w edukacyjnych â€“ by zobaczyÄ‡, jak szerokie sÄ… moÅ¼liwoÅ›ci! _SprÃ³buj uruchomiÄ‡ niektÃ³re z tych promptÃ³w w piaskownicy lub w OpenAI Playground i zobacz, co siÄ™ stanie!_

<!--
SZABLON LEKCJI:
Ta jednostka powinna obejmowaÄ‡ podstawowÄ… koncepcjÄ™ #1.
Wzmocnij koncepcjÄ™ przykÅ‚adami i odniesieniami.

KONCEPCJA #1:
InÅ¼ynieria promptÃ³w.
Zdefiniuj jÄ… i wyjaÅ›nij, dlaczego jest potrzebna.
-->

## Czym jest inÅ¼ynieria promptÃ³w?

Na poczÄ…tku tej lekcji zdefiniowaliÅ›my **inÅ¼ynieriÄ™ promptÃ³w** jako proces _projektowania i optymalizacji_ tekstowych inputÃ³w (promptÃ³w), by uzyskiwaÄ‡ spÃ³jne i wysokiej jakoÅ›ci odpowiedzi (completions) dla okreÅ›lonego celu aplikacji i modelu. MoÅ¼na to potraktowaÄ‡ jako proces dwuetapowy:

- _projektowanie_ poczÄ…tkowego promptu dla wybranego modelu i celu
- _udoskonalanie_ promptu w kolejnych iteracjach, by poprawiÄ‡ jakoÅ›Ä‡ odpowiedzi

To proces oparty na prÃ³bach i bÅ‚Ä™dach, wymagajÄ…cy intuicji i zaangaÅ¼owania uÅ¼ytkownika, by osiÄ…gnÄ…Ä‡ optymalne rezultaty. Dlaczego jest to waÅ¼ne? By odpowiedzieÄ‡ na to pytanie, musimy najpierw zrozumieÄ‡ trzy pojÄ™cia:

- _Tokenizacja_ = jak model "widzi" prompt
- _Bazowe LLM-y_ = jak model bazowy "przetwarza" prompt
- _LLM-y dostrojone instrukcjami_ = jak model moÅ¼e "widzieÄ‡ zadania"

### Tokenizacja

LLM widzi prompt jako _ciÄ…g tokenÃ³w_, przy czym rÃ³Å¼ne modele (lub ich wersje) mogÄ… tokenizowaÄ‡ ten sam prompt w rÃ³Å¼ny sposÃ³b. PoniewaÅ¼ LLM-y sÄ… trenowane na tokenach (a nie na surowym tekÅ›cie), sposÃ³b tokenizacji promptu bezpoÅ›rednio wpÅ‚ywa na jakoÅ›Ä‡ generowanej odpowiedzi.

Aby lepiej zrozumieÄ‡, jak dziaÅ‚a tokenizacja, wyprÃ³buj narzÄ™dzia takie jak [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) pokazane poniÅ¼ej. Wklej swÃ³j prompt â€“ i zobacz, jak zostaje przeksztaÅ‚cony w tokeny, zwracajÄ…c uwagÄ™ na sposÃ³b traktowania spacji i znakÃ³w interpunkcyjnych. ZwrÃ³Ä‡ uwagÄ™, Å¼e ten przykÅ‚ad pokazuje starszy LLM (GPT-3) â€“ wiÄ™c uÅ¼ycie nowszego modelu moÅ¼e daÄ‡ inny rezultat.

![Tokenizacja](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.pl.png)

### Koncepcja: Modele bazowe

Gdy prompt zostanie ztokenizowany, gÅ‚Ã³wnÄ… funkcjÄ… ["bazowego LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (czyli modelu bazowego) jest przewidywanie kolejnego tokenu w tym ciÄ…gu. PoniewaÅ¼ LLM-y sÄ… trenowane na ogromnych zbiorach tekstÃ³w, dobrze rozpoznajÄ… statystyczne zaleÅ¼noÅ›ci miÄ™dzy tokenami i potrafiÄ… dokonaÄ‡ takiego przewidywania z pewnÄ… pewnoÅ›ciÄ…. Warto zauwaÅ¼yÄ‡, Å¼e nie rozumiejÄ… _znaczenia_ sÅ‚Ã³w czy tokenÃ³w w promptach; widzÄ… jedynie wzÃ³r, ktÃ³ry mogÄ… "dokoÅ„czyÄ‡" kolejnÄ… prognozÄ…. MogÄ… kontynuowaÄ‡ przewidywanie ciÄ…gu aÅ¼ do zakoÅ„czenia przez uÅ¼ytkownika lub speÅ‚nienia ustalonego warunku.

Chcesz zobaczyÄ‡, jak dziaÅ‚a generowanie odpowiedzi na podstawie promptu? WprowadÅº powyÅ¼szy prompt do [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) w Azure OpenAI Studio z domyÅ›lnymi ustawieniami. System traktuje prompt jako proÅ›bÄ™ o informacjÄ™ â€“ wiÄ™c powinieneÅ› zobaczyÄ‡ odpowiedÅº pasujÄ…cÄ… do tego kontekstu.

A co jeÅ›li uÅ¼ytkownik chce zobaczyÄ‡ coÅ› konkretnego, speÅ‚niajÄ…cego okreÅ›lone kryteria lub cel zadania? Tu pojawiajÄ… siÄ™ LLM-y dostrojone instrukcjami.

![Bazowy LLM â€“ generowanie odpowiedzi](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.pl.png)

### Koncepcja: LLM-y dostrojone instrukcjami

[LLM dostrojony instrukcjami](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zaczyna od modelu bazowego i jest dodatkowo trenowany na przykÅ‚adach lub parach input/output (np. wieloturowych "wiadomoÅ›ciach"), ktÃ³re mogÄ… zawieraÄ‡ jasne instrukcje â€“ a odpowiedÅº AI prÃ³buje je wykonaÄ‡.

Wykorzystuje to techniki takie jak uczenie ze wzmocnieniem z informacjÄ… zwrotnÄ… od czÅ‚owieka (RLHF), ktÃ³re pozwalajÄ… modelowi _podÄ…Å¼aÄ‡ za instrukcjami_ i _uczyÄ‡ siÄ™ na podstawie feedbacku_, by generowaÄ‡ odpowiedzi lepiej dopasowane do praktycznych zastosowaÅ„ i bardziej trafne wzglÄ™dem celÃ³w uÅ¼ytkownika.

SprÃ³bujmy â€“ wrÃ³Ä‡ do powyÅ¼szego promptu, ale teraz zmieÅ„ _wiadomoÅ›Ä‡ systemowÄ…_, by dodaÄ‡ nastÄ™pujÄ…cÄ… instrukcjÄ™ jako kontekst:

> _Streszczaj treÅ›ci, ktÃ³re otrzymujesz, dla ucznia drugiej klasy. Ogranicz wynik do jednego akapitu z 3-5 punktami wypunktowanymi._

Zobacz, jak wynik jest teraz dostosowany do oczekiwanego celu i formatu? Nauczyciel moÅ¼e bezpoÅ›rednio wykorzystaÄ‡ takÄ… odpowiedÅº w swoich materiaÅ‚ach dla tej klasy.

![LLM dostrojony instrukcjami â€“ generowanie odpowiedzi](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.pl.png)

## Dlaczego potrzebujemy inÅ¼ynierii promptÃ³w?

Skoro wiemy, jak LLM-y przetwarzajÄ… prompt, porozmawiajmy o _powodach_, dla ktÃ³rych inÅ¼ynieria promptÃ³w jest potrzebna. OdpowiedÅº tkwi w tym, Å¼e obecne LLM-y stawiajÄ… przed nami szereg wyzwaÅ„, przez ktÃ³re _uzyskanie wiarygodnych i spÃ³jnych odpowiedzi_ jest trudniejsze bez odpowiedniego wysiÅ‚ku w projektowanie i optymalizacjÄ™ promptÃ³w. Na przykÅ‚ad:

1. **Odpowiedzi modeli sÄ… stochastyczne.** _Ten sam prompt_ prawdopodobnie wygeneruje rÃ³Å¼ne odpowiedzi w rÃ³Å¼nych modelach lub wersjach modelu. MoÅ¼e teÅ¼ daÄ‡ rÃ³Å¼ne wyniki w _tym samym modelu_ w rÃ³Å¼nych momentach. _Techniki inÅ¼ynierii promptÃ³w pomagajÄ… ograniczyÄ‡ te rÃ³Å¼nice, zapewniajÄ…c lepsze "ramy" dla odpowiedzi_.

1. **Modele mogÄ… wymyÅ›laÄ‡ odpowiedzi.** Modele sÄ… trenowane na _duÅ¼ych, ale skoÅ„czonych_ zbiorach danych, wiÄ™c nie majÄ… wiedzy o zagadnieniach spoza tego zakresu. W efekcie mogÄ… generowaÄ‡ odpowiedzi nieprawdziwe, zmyÅ›lone lub sprzeczne z faktami. _Techniki inÅ¼ynierii promptÃ³w pomagajÄ… wykrywaÄ‡ i ograniczaÄ‡ takie wymysÅ‚y, np. proszÄ…c AI o cytowanie ÅºrÃ³deÅ‚ lub uzasadnienie odpowiedzi_.

1. **MoÅ¼liwoÅ›ci modeli bÄ™dÄ… siÄ™ rÃ³Å¼niÄ‡.** Nowsze modele lub generacje majÄ… wiÄ™ksze moÅ¼liwoÅ›ci, ale teÅ¼ wÅ‚asne specyficzne cechy i kompromisy kosztowe czy zÅ‚oÅ¼onoÅ›ci. _InÅ¼ynieria promptÃ³w pozwala wypracowaÄ‡ dobre praktyki i procesy, ktÃ³re niwelujÄ… rÃ³Å¼nice i dostosowujÄ… siÄ™ do wymagaÅ„ konkretnych modeli w skalowalny, pÅ‚ynny sposÃ³b_.

Zobacz to w praktyce w OpenAI lub Azure OpenAI Playground:

- UÅ¼yj tego samego promptu w rÃ³Å¼nych wdroÅ¼eniach LLM (np. OpenAI, Azure OpenAI, Hugging Face) â€“ czy zauwaÅ¼yÅ‚eÅ› rÃ³Å¼nice?
- UÅ¼yj tego samego promptu wielokrotnie w _tym samym_ wdroÅ¼eniu LLM (np. Azure OpenAI playground) â€“ jak rÃ³Å¼niÅ‚y siÄ™ odpowiedzi?

### PrzykÅ‚ad wymyÅ›lania odpowiedzi

W tym kursie uÅ¼ywamy terminu **"wymyÅ›lanie"** (ang. "fabrication") na okreÅ›lenie zjawiska, gdy LLM-y generujÄ… nieprawdziwe informacje z powodu ograniczeÅ„ treningowych lub innych czynnikÃ³w. MoÅ¼esz teÅ¼ spotkaÄ‡ siÄ™ z okreÅ›leniem _"halucynacje"_ w artykuÅ‚ach czy publikacjach naukowych. Zalecamy jednak uÅ¼ywanie terminu _"wymyÅ›lanie"_, by nie przypisywaÄ‡ maszynie cech ludzkich i nie antropomorfizowaÄ‡ jej dziaÅ‚ania. To takÅ¼e zgodne z [wytycznymi Responsible AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) pod wzglÄ™dem terminologii, eliminujÄ…c okreÅ›lenia, ktÃ³re mogÄ… byÄ‡ uznane za nieodpowiednie lub wykluczajÄ…ce w niektÃ³rych kontekstach.

Chcesz zobaczyÄ‡, jak dziaÅ‚a wymyÅ›lanie odpowiedzi? WymyÅ›l prompt, ktÃ³ry poleca AI wygenerowaÄ‡ treÅ›Ä‡ na temat nieistniejÄ…cy (by mieÄ‡ pewnoÅ›Ä‡, Å¼e nie wystÄ™puje w zbiorze treningowym). Na przykÅ‚ad â€“ uÅ¼yÅ‚em takiego promptu:
# Plan lekcji: Wojna MarsjaÅ„ska 2076

## Cel lekcji

- Poznanie przyczyn, przebiegu i skutkÃ³w Wojny MarsjaÅ„skiej 2076
- Analiza wpÅ‚ywu konfliktu na spoÅ‚eczeÅ„stwo marsjaÅ„skie i ziemskie
- Rozwijanie umiejÄ™tnoÅ›ci krytycznego myÅ›lenia poprzez dyskusjÄ™ na temat etyki i technologii wojennych

## Wprowadzenie (10 minut)

- KrÃ³tkie przypomnienie kolonizacji Marsa i napiÄ™Ä‡ miÄ™dzy ZiemiÄ… a Marsjanami
- Wprowadzenie do tematu: Dlaczego doszÅ‚o do wojny w 2076 roku?

## Prezentacja multimedialna (15 minut)

- Pokaz slajdÃ³w przedstawiajÄ…cy kluczowe wydarzenia wojny
- OmÃ³wienie gÅ‚Ã³wnych stron konfliktu: RzÄ…d MarsjaÅ„ski, Sojusz Ziemski, niezaleÅ¼ne frakcje
- PrzykÅ‚ady uÅ¼ycia nowoczesnych technologii wojennych (np. drony, sztuczna inteligencja, broÅ„ orbitalna)

## Praca w grupach (20 minut)

- PodziaÅ‚ uczniÃ³w na grupy, kaÅ¼da analizuje inny aspekt wojny:
    - Przyczyny konfliktu
    - Przebieg najwaÅ¼niejszych bitew
    - Skutki dla Marsa i Ziemi
    - Rola mediÃ³w i propagandy
- Grupy przygotowujÄ… krÃ³tkie prezentacje

## Prezentacje grupowe (15 minut)

- KaÅ¼da grupa przedstawia swoje wnioski
- Dyskusja na temat rÃ³Å¼nych perspektyw

## Debata klasowa (15 minut)

- Temat: Czy wojna byÅ‚a nieunikniona? Jak moÅ¼na byÅ‚o jej zapobiec?
- Uczniowie argumentujÄ… za i przeciw, nauczyciel moderuje dyskusjÄ™

## Podsumowanie i refleksja (10 minut)

- OmÃ³wienie najwaÅ¼niejszych wnioskÃ³w z lekcji
- KrÃ³tkie zadanie pisemne: Jakie lekcje moÅ¼emy wyciÄ…gnÄ…Ä‡ z Wojny MarsjaÅ„skiej 2076?

## Praca domowa

- Napisz esej na temat: "WpÅ‚yw Wojny MarsjaÅ„skiej 2076 na przyszÅ‚oÅ›Ä‡ relacji miÄ™dzyplanetarnych"
- Przeczytaj rozdziaÅ‚ z podrÄ™cznika dotyczÄ…cy technologii wojennych uÅ¼ytych podczas konfliktu

## MateriaÅ‚y dodatkowe

- Linki do artykuÅ‚Ã³w, filmÃ³w dokumentalnych i wywiadÃ³w z uczestnikami wojny
- Lista ksiÄ…Å¼ek i powieÅ›ci science fiction inspirowanych wydarzeniami z 2076 roku
Wyszukiwanie w internecie pokazaÅ‚o, Å¼e istniejÄ… fikcyjne opowieÅ›ci (np. seriale telewizyjne lub ksiÄ…Å¼ki) o wojnach marsjaÅ„skich â€“ ale Å¼adna z nich nie dotyczy roku 2076. Zdrowy rozsÄ…dek podpowiada teÅ¼, Å¼e rok 2076 jest _przyszÅ‚oÅ›ciÄ…_, wiÄ™c nie moÅ¼e byÄ‡ powiÄ…zany z prawdziwym wydarzeniem.

Co siÄ™ stanie, gdy uruchomimy ten prompt u rÃ³Å¼nych dostawcÃ³w LLM?

> **OdpowiedÅº 1**: OpenAI Playground (GPT-35)

![OdpowiedÅº 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.pl.png)

> **OdpowiedÅº 2**: Azure OpenAI Playground (GPT-35)

![OdpowiedÅº 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.pl.png)

> **OdpowiedÅº 3**: Hugging Face Chat Playground (LLama-2)

![OdpowiedÅº 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.pl.png)

Jak moÅ¼na siÄ™ spodziewaÄ‡, kaÅ¼dy model (lub jego wersja) generuje nieco inne odpowiedzi ze wzglÄ™du na stochastyczne dziaÅ‚anie i rÃ³Å¼nice w moÅ¼liwoÅ›ciach. Na przykÅ‚ad jeden model kieruje odpowiedÅº do ucznia Ã³smej klasy, a drugi do licealisty. Jednak wszystkie trzy odpowiedzi mogÅ‚yby przekonaÄ‡ nieÅ›wiadomego uÅ¼ytkownika, Å¼e wydarzenie byÅ‚o prawdziwe.

Techniki inÅ¼ynierii promptÃ³w, takie jak _metaprompting_ czy _konfiguracja temperatury_, mogÄ… w pewnym stopniu ograniczyÄ‡ zmyÅ›lone odpowiedzi modeli. Nowe _architektury_ inÅ¼ynierii promptÃ³w pÅ‚ynnie wÅ‚Ä…czajÄ… nowe narzÄ™dzia i techniki do procesu tworzenia promptÃ³w, by Å‚agodziÄ‡ lub ograniczaÄ‡ te efekty.

## Studium przypadku: GitHub Copilot

Na zakoÅ„czenie tej sekcji zobaczmy, jak inÅ¼ynieria promptÃ³w jest wykorzystywana w praktycznych rozwiÄ…zaniach, na przykÅ‚adzie [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot to TwÃ³j â€AI Pair Programmerâ€ â€“ zamienia tekstowe polecenia na uzupeÅ‚nienia kodu i jest zintegrowany z Twoim Å›rodowiskiem programistycznym (np. Visual Studio Code), zapewniajÄ…c pÅ‚ynne doÅ›wiadczenie uÅ¼ytkownika. Jak opisano w serii poniÅ¼szych wpisÃ³w na blogu, najwczeÅ›niejsza wersja opieraÅ‚a siÄ™ na modelu OpenAI Codex â€“ inÅ¼ynierowie szybko zauwaÅ¼yli potrzebÄ™ dostrajania modelu i opracowania lepszych technik inÅ¼ynierii promptÃ³w, by poprawiÄ‡ jakoÅ›Ä‡ kodu. W lipcu [zaprezentowano ulepszony model AI, ktÃ³ry wykracza poza Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst), oferujÄ…c jeszcze szybsze sugestie.

Przeczytaj wpisy po kolei, by Å›ledziÄ‡ ich drogÄ™ rozwoju.

- **Maj 2023** | [GitHub Copilot coraz lepiej rozumie TwÃ³j kod](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [WewnÄ…trz GitHub: Praca z LLM stojÄ…cymi za GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Czerwiec 2023** | [Jak pisaÄ‡ lepsze promptâ€™y dla GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Lipiec 2023** | [.. GitHub Copilot wykracza poza Codex dziÄ™ki ulepszonemu modelowi AI](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Lipiec 2023** | [Przewodnik programisty po inÅ¼ynierii promptÃ³w i LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **WrzesieÅ„ 2023** | [Jak zbudowaÄ‡ aplikacjÄ™ LLM dla firmy: Lekcje z GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

MoÅ¼esz teÅ¼ przejrzeÄ‡ ich [blog inÅ¼ynierski](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) po wiÄ™cej wpisÃ³w, takich jak [ten](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), pokazujÄ…cy jak te modele i techniki sÄ… _stosowane_ w rzeczywistych aplikacjach.

---

## Konstrukcja promptÃ³w

WidzieliÅ›my juÅ¼, dlaczego inÅ¼ynieria promptÃ³w jest waÅ¼na â€“ teraz przyjrzyjmy siÄ™, jak promptâ€™y sÄ… _budowane_, by mÃ³c oceniÄ‡ rÃ³Å¼ne techniki skutecznego projektowania promptÃ³w.

### Podstawowy prompt

Zacznijmy od najprostszego promptu: tekstowego wejÅ›cia wysyÅ‚anego do modelu bez dodatkowego kontekstu. Oto przykÅ‚ad â€“ gdy wyÅ›lemy pierwsze sÅ‚owa amerykaÅ„skiego hymnu narodowego do OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), model natychmiast _uzupeÅ‚nia_ odpowiedÅº kolejnymi wersami, pokazujÄ…c podstawowe zachowanie predykcyjne.

| Prompt (WejÅ›cie)     | UzupeÅ‚nienie (WyjÅ›cie)                                                                                                                        |
| :------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see   | WyglÄ…da na to, Å¼e zaczynasz tekst â€The Star-Spangled Bannerâ€, hymnu narodowego StanÃ³w Zjednoczonych. PeÅ‚ny tekst to ...                      |

### ZÅ‚oÅ¼ony prompt

Teraz dodajmy kontekst i instrukcje do podstawowego promptu. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) pozwala zbudowaÄ‡ zÅ‚oÅ¼ony prompt jako zbiÃ³r _wiadomoÅ›ci_ z:

- Parami wejÅ›cie/wyjÅ›cie odzwierciedlajÄ…cymi _uÅ¼ytkownika_ i _asystenta_.
- WiadomoÅ›ciÄ… systemowÄ… ustawiajÄ…cÄ… kontekst zachowania lub osobowoÅ›ci asystenta.

Å»Ä…danie wyglÄ…da teraz jak poniÅ¼ej, gdzie _tokenizacja_ skutecznie wyÅ‚apuje istotne informacje z kontekstu i rozmowy. Zmiana kontekstu systemowego moÅ¼e mieÄ‡ rÃ³wnie duÅ¼y wpÅ‚yw na jakoÅ›Ä‡ odpowiedzi, jak podane przez uÅ¼ytkownika dane wejÅ›ciowe.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt instrukcyjny

W powyÅ¼szych przykÅ‚adach prompt uÅ¼ytkownika byÅ‚ prostym zapytaniem tekstowym, ktÃ³re moÅ¼na zinterpretowaÄ‡ jako proÅ›bÄ™ o informacjÄ™. W promptach _instrukcyjnych_ moÅ¼emy uÅ¼yÄ‡ tekstu, by dokÅ‚adniej okreÅ›liÄ‡ zadanie, dajÄ…c AI lepsze wskazÃ³wki. Oto przykÅ‚ad:

| Prompt (WejÅ›cie)                                                                                                                                                                                                                         | UzupeÅ‚nienie (WyjÅ›cie)                                                                                                        | Typ instrukcji      |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Napisz opis wojny secesyjnej                                                                                                                                                                      | _zwrÃ³cono prosty akapit_                                                                                                     | Prosta              |
| Napisz opis wojny secesyjnej. Podaj kluczowe daty i wydarzenia oraz opisz ich znaczenie                                                                                                           | _zwrÃ³cono akapit, a nastÄ™pnie listÄ™ kluczowych dat z opisami wydarzeÅ„_                                                       | ZÅ‚oÅ¼ona             |
| Napisz opis wojny secesyjnej w 1 akapicie. Podaj 3 punkty z kluczowymi datami i ich znaczeniem. Podaj 3 kolejne punkty z kluczowymi postaciami historycznymi i ich wkÅ‚adem. ZwrÃ³Ä‡ wynik jako plik JSON | _zwrÃ³cono bardziej szczegÃ³Å‚owe dane w polu tekstowym, sformatowane jako JSON, ktÃ³ry moÅ¼na skopiowaÄ‡ do pliku i zweryfikowaÄ‡_ | ZÅ‚oÅ¼ona. Sformatowana. |

## TreÅ›Ä‡ gÅ‚Ã³wna

W powyÅ¼szych przykÅ‚adach prompt byÅ‚ doÅ›Ä‡ otwarty, pozwalajÄ…c LLM zdecydowaÄ‡, ktÃ³ra czÄ™Å›Ä‡ jego wytrenowanego zbioru danych jest istotna. W wzorcu _treÅ›ci gÅ‚Ã³wnej_ wejÅ›cie dzielimy na dwie czÄ™Å›ci:

- instrukcjÄ™ (akcjÄ™)
- istotnÄ… treÅ›Ä‡ (wpÅ‚ywajÄ…cÄ… na akcjÄ™)

Oto przykÅ‚ad, gdzie instrukcja brzmi â€podsumuj to w 2 zdaniachâ€.

| Prompt (WejÅ›cie)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | UzupeÅ‚nienie (WyjÅ›cie)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jowisz to piÄ…ta planeta od SÅ‚oÅ„ca i najwiÄ™ksza w UkÅ‚adzie SÅ‚onecznym. Jest gazowym olbrzymem o masie tysiÄ™cznej masy SÅ‚oÅ„ca, ale dwa i pÃ³Å‚ razy wiÄ™kszej niÅ¼ masa wszystkich pozostaÅ‚ych planet razem wziÄ™tych. Jowisz jest jednym z najjaÅ›niejszych obiektÃ³w widocznych goÅ‚ym okiem na nocnym niebie i byÅ‚ znany staroÅ¼ytnym cywilizacjom jeszcze przed poczÄ…tkiem historii. Nazwa pochodzi od rzymskiego boga Jowisza.[19] OglÄ…dany z Ziemi, Jowisz moÅ¼e byÄ‡ na tyle jasny, Å¼e jego odbite Å›wiatÅ‚o rzuca widoczne cienie,[20] a Å›rednio jest trzecim najjaÅ›niejszym naturalnym obiektem na nocnym niebie po KsiÄ™Å¼ycu i Wenus. <br/> **Podsumuj to w 2 krÃ³tkich zdaniach** | Jowisz, piÄ…ta planeta od SÅ‚oÅ„ca, jest najwiÄ™kszÄ… w UkÅ‚adzie SÅ‚onecznym i jednym z najjaÅ›niejszych obiektÃ³w na nocnym niebie. Nazwany na czeÅ›Ä‡ rzymskiego boga, jest gazowym olbrzymem o masie dwa i pÃ³Å‚ razy wiÄ™kszej niÅ¼ masa wszystkich pozostaÅ‚ych planet razem wziÄ™tych. |

Segment treÅ›ci gÅ‚Ã³wnej moÅ¼na wykorzystaÄ‡ na rÃ³Å¼ne sposoby, by skuteczniej przekazywaÄ‡ instrukcje:

- **PrzykÅ‚ady** â€“ zamiast mÃ³wiÄ‡ modelowi, co ma zrobiÄ‡, podaj przykÅ‚ady oczekiwanego wyniku i pozwÃ³l mu wywnioskowaÄ‡ wzorzec.
- **WskazÃ³wki** â€“ po instrukcji dodaj â€wskazÃ³wkÄ™â€, ktÃ³ra naprowadza model na odpowiedni format odpowiedzi.
- **Szablony** â€“ powtarzalne â€przepisyâ€ na promptâ€™y z miejscami na zmienne, ktÃ³re moÅ¼na uzupeÅ‚niÄ‡ danymi dla konkretnych zastosowaÅ„.

Przyjrzyjmy siÄ™ tym technikom w praktyce.

### Wykorzystanie przykÅ‚adÃ³w

To podejÅ›cie polega na â€nakarmieniu modeluâ€ przykÅ‚adami oczekiwanego wyniku dla danej instrukcji i pozwoleniu mu wywnioskowaÄ‡ wzorzec. W zaleÅ¼noÅ›ci od liczby podanych przykÅ‚adÃ³w, moÅ¼emy mieÄ‡ prompt zero-shot, one-shot, few-shot itd.

Prompt skÅ‚ada siÄ™ teraz z trzech elementÃ³w:

- Opisu zadania
- Kilku przykÅ‚adÃ³w oczekiwanego wyniku
- PoczÄ…tku nowego przykÅ‚adu (ktÃ³ry staje siÄ™ domyÅ›lnÄ… instrukcjÄ…)

| Typ uczenia   | Prompt (WejÅ›cie)                                                                                                                                        | UzupeÅ‚nienie (WyjÅ›cie)         |
| :------------ | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :----------------------------- |
| Zero-shot     | "The Sun is Shining". PrzetÅ‚umacz na hiszpaÅ„ski                                                                                                        | "El Sol estÃ¡ brillando".       |
| One-shot      | "The Sun is Shining" => ""El Sol estÃ¡ brillando". <br> "It's a Cold and Windy Day" =>                                                                  | "Es un dÃ­a frÃ­o y ventoso".    |
| Few-shot      | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk => | Basketball                     |
|               |                                                                                                                                                         |                                |

ZwrÃ³Ä‡ uwagÄ™, Å¼e w prompt zero-shot musieliÅ›my podaÄ‡ wyraÅºnÄ… instrukcjÄ™ (â€PrzetÅ‚umacz na hiszpaÅ„skiâ€), ale w one-shot model juÅ¼ jÄ… wywnioskowaÅ‚. PrzykÅ‚ad few-shot pokazuje, jak dodanie wiÄ™kszej liczby przykÅ‚adÃ³w pozwala modelom trafniej wnioskowaÄ‡ bez dodatkowych instrukcji.

### WskazÃ³wki w promptach

InnÄ… technikÄ… wykorzystania treÅ›ci gÅ‚Ã³wnej jest podanie _wskazÃ³wek_ zamiast przykÅ‚adÃ³w. W tym przypadku dajemy modelowi â€zaczepkÄ™â€ â€“ fragment, ktÃ³ry odzwierciedla poÅ¼Ä…dany format odpowiedzi. Model â€Å‚apie wskazÃ³wkÄ™â€ i kontynuuje w tym stylu.

| Liczba wskazÃ³wek | Prompt (WejÅ›cie)                                                                                                                                                                                                                                                                                                                                                                                                                                               | UzupeÅ‚nienie (WyjÅ›cie)                                                                                                                                                                                                                                                                                       |
| :--------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 0                | Jowisz to piÄ…ta planeta od SÅ‚oÅ„ca i najwiÄ™ksza w UkÅ‚adzie SÅ‚onecznym. Jest gazowym olbrzymem o masie tysiÄ™cznej masy SÅ‚oÅ„ca, ale dwa i pÃ³Å‚ razy wiÄ™kszej niÅ¼ masa wszystkich pozostaÅ‚ych planet razem wziÄ™tych. Jowisz jest jednym z najjaÅ›niejszych obiektÃ³w widocznych goÅ‚ym okiem na nocnym niebie i byÅ‚ znany staroÅ¼ytnym cywilizacjom jeszcze przed poczÄ…tkiem historii.

**Podsumuj to**                                       | Jowisz jest najwiÄ™kszÄ… planetÄ… w naszym UkÅ‚adzie SÅ‚onecznym i piÄ…tÄ… od SÅ‚oÅ„ca. To gazowy olbrzym o masie stanowiÄ…cej 1/1000 masy SÅ‚oÅ„ca, ale ciÄ™Å¼szy niÅ¼ wszystkie pozostaÅ‚e planety razem wziÄ™te. StaroÅ¼ytne cywilizacje znaÅ‚y Jowisza od dawna, a na nocnym niebie jest Å‚atwo widoczny. |
| 1              | Jowisz to piÄ…ta planeta od SÅ‚oÅ„ca i najwiÄ™ksza w UkÅ‚adzie SÅ‚onecznym. Jest gazowym olbrzymem o masie stanowiÄ…cej jednÄ… tysiÄ™cznÄ… masy SÅ‚oÅ„ca, ale dwa i pÃ³Å‚ razy wiÄ™kszej niÅ¼ masa wszystkich pozostaÅ‚ych planet razem wziÄ™tych. Jowisz jest jednym z najjaÅ›niejszych obiektÃ³w widocznych goÅ‚ym okiem na nocnym niebie i byÅ‚ znany staroÅ¼ytnym cywilizacjom jeszcze przed powstaniem pisma. <br/>**Podsumuj to** <br/> DowiedzieliÅ›my siÄ™, Å¼e Jowisz | jest piÄ…tÄ… planetÄ… od SÅ‚oÅ„ca i najwiÄ™kszÄ… w UkÅ‚adzie SÅ‚onecznym. To gazowy olbrzym o masie stanowiÄ…cej jednÄ… tysiÄ™cznÄ… masy SÅ‚oÅ„ca, ale dwa i pÃ³Å‚ razy wiÄ™kszej niÅ¼ masa wszystkich pozostaÅ‚ych planet razem wziÄ™tych. Jest Å‚atwo widoczny goÅ‚ym okiem i znany od czasÃ³w staroÅ¼ytnych.                        |
| 2              | Jowisz to piÄ…ta planeta od SÅ‚oÅ„ca i najwiÄ™ksza w UkÅ‚adzie SÅ‚onecznym. Jest gazowym olbrzymem o masie stanowiÄ…cej jednÄ… tysiÄ™cznÄ… masy SÅ‚oÅ„ca, ale dwa i pÃ³Å‚ razy wiÄ™kszej niÅ¼ masa wszystkich pozostaÅ‚ych planet razem wziÄ™tych. Jowisz jest jednym z najjaÅ›niejszych obiektÃ³w widocznych goÅ‚ym okiem na nocnym niebie i byÅ‚ znany staroÅ¼ytnym cywilizacjom jeszcze przed powstaniem pisma. <br/>**Podsumuj to** <br/> Top 3 Fakty, ktÃ³rych siÄ™ dowiedzieliÅ›my:         | 1. Jowisz to piÄ…ta planeta od SÅ‚oÅ„ca i najwiÄ™ksza w UkÅ‚adzie SÅ‚onecznym. <br/> 2. Jest gazowym olbrzymem o masie stanowiÄ…cej jednÄ… tysiÄ™cznÄ… masy SÅ‚oÅ„ca...<br/> 3. Jowisz jest widoczny goÅ‚ym okiem od czasÃ³w staroÅ¼ytnych ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Szablony promptÃ³w

Szablon promptu to _z gÃ³ry zdefiniowany przepis na prompt_, ktÃ³ry moÅ¼na zapisaÄ‡ i ponownie wykorzystaÄ‡ w razie potrzeby, aby zapewniÄ‡ bardziej spÃ³jne doÅ›wiadczenia uÅ¼ytkownikÃ³w na duÅ¼Ä… skalÄ™. W najprostszej formie jest to po prostu zbiÃ³r przykÅ‚adÃ³w promptÃ³w jak [ten od OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), ktÃ³ry zawiera zarÃ³wno interaktywne komponenty promptu (wiadomoÅ›ci uÅ¼ytkownika i systemu), jak i format Å¼Ä…dania obsÅ‚ugiwany przez API â€“ co umoÅ¼liwia ponowne uÅ¼ycie.

W bardziej zÅ‚oÅ¼onej formie, jak [ten przykÅ‚ad z LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), zawiera _pola zastÄ™pcze_, ktÃ³re moÅ¼na zastÄ…piÄ‡ danymi z rÃ³Å¼nych ÅºrÃ³deÅ‚ (wejÅ›cie uÅ¼ytkownika, kontekst systemowy, zewnÄ™trzne ÅºrÃ³dÅ‚a danych itd.), aby dynamicznie generowaÄ‡ prompt. Pozwala to tworzyÄ‡ bibliotekÄ™ gotowych promptÃ³w, ktÃ³re moÅ¼na programistycznie wykorzystywaÄ‡ do zapewnienia spÃ³jnych doÅ›wiadczeÅ„ uÅ¼ytkownikÃ³w na duÅ¼Ä… skalÄ™.

Prawdziwa wartoÅ›Ä‡ szablonÃ³w polega na moÅ¼liwoÅ›ci tworzenia i publikowania _bibliotek promptÃ³w_ dla konkretnych dziedzin â€“ gdzie szablon promptu jest _optymalizowany_ pod kÄ…tem specyficznego kontekstu aplikacji lub przykÅ‚adÃ³w, ktÃ³re sprawiajÄ…, Å¼e odpowiedzi sÄ… bardziej trafne i precyzyjne dla docelowych uÅ¼ytkownikÃ³w. Repozytorium [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) jest Å›wietnym przykÅ‚adem takiego podejÅ›cia â€“ gromadzi bibliotekÄ™ promptÃ³w dla edukacji z naciskiem na kluczowe cele, takie jak planowanie lekcji, projektowanie programÃ³w nauczania, wsparcie uczniÃ³w itd.

## TreÅ›ci wspierajÄ…ce

JeÅ›li potraktujemy konstruowanie promptÃ³w jako majÄ…ce instrukcjÄ™ (zadanie) i cel (gÅ‚Ã³wna treÅ›Ä‡), to _treÅ›Ä‡ drugorzÄ™dna_ to dodatkowy kontekst, ktÃ³ry dostarczamy, aby **w jakiÅ› sposÃ³b wpÅ‚ynÄ…Ä‡ na wynik**. MogÄ… to byÄ‡ parametry dostrajajÄ…ce, instrukcje formatowania, taksonomie tematÃ³w itd., ktÃ³re pomagajÄ… modelowi _dostosowaÄ‡_ odpowiedÅº do oczekiwaÅ„ lub celÃ³w uÅ¼ytkownika.

Na przykÅ‚ad: MajÄ…c katalog kursÃ³w z rozbudowanymi metadanymi (nazwa, opis, poziom, tagi, prowadzÄ…cy itd.) wszystkich dostÄ™pnych kursÃ³w w programie nauczania:

- moÅ¼emy zdefiniowaÄ‡ instrukcjÄ™ â€podsumuj katalog kursÃ³w na semestr jesienny 2023â€
- moÅ¼emy uÅ¼yÄ‡ gÅ‚Ã³wnej treÅ›ci, by podaÄ‡ kilka przykÅ‚adÃ³w oczekiwanego wyniku
- moÅ¼emy uÅ¼yÄ‡ treÅ›ci drugorzÄ™dnej, by wskazaÄ‡ 5 najwaÅ¼niejszych â€tagÃ³wâ€ do uwzglÄ™dnienia.

Teraz model moÅ¼e wygenerowaÄ‡ podsumowanie w formacie pokazanym w przykÅ‚adach, ale jeÅ›li wynik zawiera wiele tagÃ³w, moÅ¼e nadaÄ‡ priorytet 5 wskazanym w treÅ›ci drugorzÄ™dnej.

---

<!--
SZABLON LEKCJI:
Ta jednostka powinna obejmowaÄ‡ kluczowÄ… koncepcjÄ™ #1.
Wzmocnij koncepcjÄ™ przykÅ‚adami i odniesieniami.

KONCEPCJA #3:
Techniki inÅ¼ynierii promptÃ³w.
Jakie sÄ… podstawowe techniki inÅ¼ynierii promptÃ³w?
Zilustruj to Ä‡wiczeniami.
-->

## Najlepsze praktyki tworzenia promptÃ³w

Teraz, gdy wiemy, jak moÅ¼na _konstruowaÄ‡_ prompt, moÅ¼emy zaczÄ…Ä‡ myÅ›leÄ‡ o tym, jak je _projektowaÄ‡_, by odzwierciedlaÅ‚y najlepsze praktyki. MoÅ¼emy podzieliÄ‡ to na dwie czÄ™Å›ci â€“ odpowiednie _nastawienie_ i stosowanie wÅ‚aÅ›ciwych _technik_.

### Nastawienie do inÅ¼ynierii promptÃ³w

InÅ¼ynieria promptÃ³w to proces prÃ³b i bÅ‚Ä™dÃ³w, wiÄ™c miej na uwadze trzy ogÃ³lne czynniki przewodnie:

1. **Zrozumienie domeny ma znaczenie.** TrafnoÅ›Ä‡ i dokÅ‚adnoÅ›Ä‡ odpowiedzi zaleÅ¼y od _domeny_, w ktÃ³rej dziaÅ‚a aplikacja lub uÅ¼ytkownik. Wykorzystaj swojÄ… intuicjÄ™ i wiedzÄ™ domenowÄ…, by **dostosowaÄ‡ techniki**. Na przykÅ‚ad, zdefiniuj _osobowoÅ›ci specyficzne dla domeny_ w promptach systemowych lub uÅ¼yj _szablonÃ³w specyficznych dla domeny_ w promptach uÅ¼ytkownika. Dodaj treÅ›ci drugorzÄ™dne odzwierciedlajÄ…ce kontekst domenowy lub uÅ¼yj _wskazÃ³wek i przykÅ‚adÃ³w z danej dziedziny_, by ukierunkowaÄ‡ model na znane wzorce uÅ¼ycia.

2. **Zrozumienie modelu ma znaczenie.** Wiemy, Å¼e modele sÄ… z natury stochastyczne. Jednak implementacje modeli mogÄ… siÄ™ rÃ³Å¼niÄ‡ pod wzglÄ™dem zbioru danych treningowych (wiedza wstÄ™pna), oferowanych moÅ¼liwoÅ›ci (np. przez API lub SDK) i rodzaju treÅ›ci, do ktÃ³rych sÄ… zoptymalizowane (np. kod, obrazy, tekst). Poznaj mocne i sÅ‚abe strony uÅ¼ywanego modelu i wykorzystaj tÄ™ wiedzÄ™, by _priorytetyzowaÄ‡ zadania_ lub budowaÄ‡ _dostosowane szablony_ zoptymalizowane pod moÅ¼liwoÅ›ci modelu.

3. **Iteracja i walidacja majÄ… znaczenie.** Modele rozwijajÄ… siÄ™ bardzo szybko, podobnie jak techniki inÅ¼ynierii promptÃ³w. Jako ekspert domenowy moÅ¼esz mieÄ‡ inne kryteria lub kontekst dla _swojej_ aplikacji, ktÃ³re nie muszÄ… dotyczyÄ‡ szerszej spoÅ‚ecznoÅ›ci. Wykorzystaj narzÄ™dzia i techniki inÅ¼ynierii promptÃ³w, by â€rozpoczÄ…Ä‡â€ budowÄ™ promptu, a nastÄ™pnie iteruj i weryfikuj wyniki, korzystajÄ…c z wÅ‚asnej intuicji i wiedzy. Zapisuj swoje spostrzeÅ¼enia i twÃ³rz **bazÄ™ wiedzy** (np. biblioteki promptÃ³w), ktÃ³ra moÅ¼e sÅ‚uÅ¼yÄ‡ innym jako nowy punkt wyjÅ›cia do szybszych iteracji w przyszÅ‚oÅ›ci.

## Najlepsze praktyki

Przyjrzyjmy siÄ™ teraz najczÄ™Å›ciej zalecanym najlepszym praktykom wedÅ‚ug [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) i specjalistÃ³w [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Co                              | Dlaczego                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Testuj najnowsze modele.       | Nowe generacje modeli prawdopodobnie majÄ… lepsze funkcje i jakoÅ›Ä‡ â€“ ale mogÄ… byÄ‡ teÅ¼ droÅ¼sze. OceÅ„ ich wpÅ‚yw, a potem podejmij decyzjÄ™ o migracji.                                                                                |
| Oddziel instrukcje i kontekst   | SprawdÅº, czy TwÃ³j model/dostawca definiuje _znaczniki_, ktÃ³re wyraÅºniej oddzielajÄ… instrukcje, treÅ›Ä‡ gÅ‚Ã³wnÄ… i drugorzÄ™dnÄ…. To moÅ¼e pomÃ³c modelom lepiej przypisywaÄ‡ wagi do tokenÃ³w.                                                         |
| BÄ…dÅº precyzyjny i jasny             | Podaj wiÄ™cej szczegÃ³Å‚Ã³w dotyczÄ…cych oczekiwanego kontekstu, wyniku, dÅ‚ugoÅ›ci, formatu, stylu itd. To poprawi jakoÅ›Ä‡ i spÃ³jnoÅ›Ä‡ odpowiedzi. Zapisuj przepisy w szablonach do ponownego uÅ¼ycia.                                                          |
| BÄ…dÅº opisowy, uÅ¼ywaj przykÅ‚adÃ³w      | Modele czÄ™sto lepiej reagujÄ… na podejÅ›cie â€pokaÅ¼ i opowiedzâ€. Zacznij od podejÅ›cia `zero-shot`, gdzie dajesz tylko instrukcjÄ™ (bez przykÅ‚adÃ³w), a potem sprÃ³buj `few-shot` jako doprecyzowanie, podajÄ…c kilka przykÅ‚adÃ³w oczekiwanego wyniku. UÅ¼ywaj analogii. |
| UÅ¼ywaj wskazÃ³wek do rozpoczÄ™cia odpowiedzi | Skieruj model w stronÄ™ oczekiwanego wyniku, podajÄ…c kilka wiodÄ…cych sÅ‚Ã³w lub fraz, ktÃ³re moÅ¼e wykorzystaÄ‡ jako punkt wyjÅ›cia do odpowiedzi.                                                                                                               |
| Powtarzaj                       | Czasem trzeba powtÃ³rzyÄ‡ instrukcjÄ™ modelowi. Podaj instrukcjÄ™ przed i po gÅ‚Ã³wnej treÅ›ci, uÅ¼yj instrukcji i wskazÃ³wki itd. Iteruj i sprawdzaj, co dziaÅ‚a najlepiej.                                                         |
| KolejnoÅ›Ä‡ ma znaczenie                     | KolejnoÅ›Ä‡ prezentowania informacji modelowi moÅ¼e wpÅ‚ywaÄ‡ na wynik, nawet w przykÅ‚adach uczÄ…cych, ze wzglÄ™du na efekt Å›wieÅ¼oÅ›ci. Przetestuj rÃ³Å¼ne opcje, by zobaczyÄ‡, co dziaÅ‚a najlepiej.                                                               |
| Daj modelowi â€wyjÅ›cieâ€           | Podaj modelowi _odpowiedÅº awaryjnÄ…_, ktÃ³rÄ… moÅ¼e zwrÃ³ciÄ‡, jeÅ›li z jakiegoÅ› powodu nie moÅ¼e wykonaÄ‡ zadania. To moÅ¼e zmniejszyÄ‡ ryzyko generowania faÅ‚szywych lub zmyÅ›lonych odpowiedzi.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Jak w przypadku kaÅ¼dej najlepszej praktyki, _Twoje rezultaty mogÄ… siÄ™ rÃ³Å¼niÄ‡_ w zaleÅ¼noÅ›ci od modelu, zadania i domeny. Potraktuj je jako punkt wyjÅ›cia i iteruj, by znaleÅºÄ‡ to, co dziaÅ‚a najlepiej dla Ciebie. Regularnie oceniaj swÃ³j proces inÅ¼ynierii promptÃ³w, gdy pojawiajÄ… siÄ™ nowe modele i narzÄ™dzia, skupiajÄ…c siÄ™ na skalowalnoÅ›ci procesu i jakoÅ›ci odpowiedzi.

<!--
SZABLON LEKCJI:
Ta jednostka powinna zawieraÄ‡ wyzwanie programistyczne, jeÅ›li to moÅ¼liwe

WYZWANIE:
Link do notatnika Jupyter z samymi komentarzami w instrukcjach (sekcje kodu sÄ… puste).

ROZWIÄ„ZANIE:
Link do kopii tego notatnika z uzupeÅ‚nionymi i uruchomionymi promptami, pokazujÄ…cej przykÅ‚adowe rozwiÄ…zanie.
-->

## Zadanie

Gratulacje! DotarÅ‚eÅ› do koÅ„ca lekcji! Czas sprawdziÄ‡ niektÃ³re z tych koncepcji i technik na prawdziwych przykÅ‚adach!

W naszym zadaniu bÄ™dziemy korzystaÄ‡ z notatnika Jupyter z Ä‡wiczeniami, ktÃ³re moÅ¼esz wykonaÄ‡ interaktywnie. MoÅ¼esz teÅ¼ rozbudowaÄ‡ notatnik o wÅ‚asne komÃ³rki Markdown i kodu, by samodzielnie eksplorowaÄ‡ pomysÅ‚y i techniki.

### Aby zaczÄ…Ä‡, zforkuj repozytorium, a nastÄ™pnie

- (Zalecane) Uruchom GitHub Codespaces
- (Alternatywnie) Sklonuj repozytorium na swoje urzÄ…dzenie i uÅ¼yj go z Docker Desktop
- (Alternatywnie) OtwÃ³rz notatnik w swoim ulubionym Å›rodowisku do pracy z notatnikami.

### NastÄ™pnie skonfiguruj zmienne Å›rodowiskowe

- Skopiuj plik `.env.copy` z gÅ‚Ã³wnego katalogu repozytorium do `.env` i uzupeÅ‚nij wartoÅ›ci `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` oraz `AZURE_OPENAI_DEPLOYMENT`. WrÃ³Ä‡ do sekcji [Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), aby dowiedzieÄ‡ siÄ™ jak to zrobiÄ‡.

### NastÄ™pnie otwÃ³rz notatnik Jupyter

- Wybierz kernel uruchomieniowy. JeÅ›li korzystasz z opcji 1 lub 2, po prostu wybierz domyÅ›lny kernel Python 3.10.x dostarczony przez kontener deweloperski.

JesteÅ› gotowy do wykonania Ä‡wiczeÅ„. PamiÄ™taj, Å¼e tutaj nie ma _dobrych i zÅ‚ych_ odpowiedzi â€“ chodzi o eksplorowanie opcji metodÄ… prÃ³b i bÅ‚Ä™dÃ³w oraz budowanie intuicji, co dziaÅ‚a dla danego modelu i domeny aplikacji.

_Z tego powodu w tej lekcji nie ma segmentÃ³w z rozwiÄ…zaniami kodu. Zamiast tego, w notatniku znajdziesz komÃ³rki Markdown zatytuÅ‚owane â€Moje rozwiÄ…zanie:â€, ktÃ³re pokazujÄ… przykÅ‚adowy wynik dla odniesienia._

 <!--
SZABLON LEKCJI:
ZakoÅ„cz sekcjÄ™ podsumowaniem i zasobami do samodzielnej nauki.
-->

## Sprawdzenie wiedzy

KtÃ³ry z poniÅ¼szych promptÃ³w jest dobry, zgodnie z rozsÄ…dnymi najlepszymi praktykami?

1. PokaÅ¼ mi obraz czerwonego samochodu
2. PokaÅ¼ mi obraz czerwonego samochodu marki Volvo, model XC90, zaparkowanego przy klifie o zachodzie sÅ‚oÅ„ca
3. PokaÅ¼ mi obraz czerwonego samochodu marki Volvo, model XC90

OdpowiedÅº: 2, to najlepszy prompt, bo podaje szczegÃ³Å‚y dotyczÄ…ce â€czegoâ€ i jest bardzo precyzyjny (nie po prostu dowolny samochÃ³d, ale konkretny model i marka), a takÅ¼e opisuje ogÃ³lne otoczenie. 3 jest kolejnym dobrym wyborem, bo rÃ³wnieÅ¼ zawiera duÅ¼o opisu.

## ğŸš€ Wyzwanie

SprÃ³buj wykorzystaÄ‡ technikÄ™ â€wskazÃ³wkiâ€ z promptem: DokoÅ„cz zdanie â€PokaÅ¼ mi obraz czerwonego samochodu marki Volvo i â€. Co odpowiada model i jak byÅ› to poprawiÅ‚?

## Åšwietna robota! Kontynuuj naukÄ™

Chcesz dowiedzieÄ‡ siÄ™ wiÄ™cej o rÃ³Å¼nych koncepcjach inÅ¼ynierii promptÃ³w? PrzejdÅº na [stronÄ™ z materiaÅ‚ami do dalszej nauki](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), gdzie znajdziesz inne Å›wietne zasoby na ten temat.

PrzejdÅº do lekcji 5, gdzie przyjrzymy siÄ™ [zaawansowanym technikom promptowania](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony przy uÅ¼yciu usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ dokÅ‚adamy wszelkich staraÅ„, aby tÅ‚umaczenie byÅ‚o dokÅ‚adne, prosimy pamiÄ™taÄ‡, Å¼e tÅ‚umaczenia automatyczne mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego ojczystym jÄ™zyku powinien byÄ‡ traktowany jako ÅºrÃ³dÅ‚o nadrzÄ™dne. W przypadku informacji krytycznych zalecane jest skorzystanie z profesjonalnych usÅ‚ug tÅ‚umaczeniowych. Nie ponosimy odpowiedzialnoÅ›ci za wszelkie nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.