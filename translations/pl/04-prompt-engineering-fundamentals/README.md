<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "0135e6c271f3ece8699050d4debbce88",
  "translation_date": "2025-10-18T00:57:29+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "pl"
}
-->
# Podstawy In偶ynierii Prompt贸w

[![Podstawy In偶ynierii Prompt贸w](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.pl.png)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Wprowadzenie
Ten modu obejmuje podstawowe pojcia i techniki tworzenia skutecznych prompt贸w dla modeli generatywnej sztucznej inteligencji. Spos贸b, w jaki piszesz sw贸j prompt do LLM, ma znaczenie. Starannie skonstruowany prompt mo偶e zapewni lepsz jako odpowiedzi. Ale co dokadnie oznaczaj takie terminy jak _prompt_ i _in偶ynieria prompt贸w_? I jak mog poprawi dane wejciowe _promptu_, kt贸re wysyam do LLM? Na te pytania spr贸bujemy odpowiedzie w tym rozdziale i nastpnym.

_Generatywna sztuczna inteligencja_ potrafi tworzy now tre (np. tekst, obrazy, d藕wik, kod itp.) w odpowiedzi na zapytania u偶ytkownik贸w. Osiga to za pomoc _Wielkich Modeli Jzykowych_ takich jak seria GPT ("Generative Pre-trained Transformer") od OpenAI, kt贸re s trenowane do pracy z jzykiem naturalnym i kodem.

U偶ytkownicy mog teraz wchodzi w interakcje z tymi modelami za pomoc znanych interfejs贸w, takich jak czat, bez potrzeby posiadania specjalistycznej wiedzy technicznej czy szkolenia. Modele s oparte na _promptach_ - u偶ytkownicy wysyaj tekst wejciowy (prompt) i otrzymuj odpowied藕 AI (wynik). Nastpnie mog "rozmawia z AI" w spos贸b iteracyjny, w wieloetapowych konwersacjach, dopracowujc sw贸j prompt, a偶 odpowied藕 speni ich oczekiwania.

"Prompty" staj si teraz g贸wnym _interfejsem programistycznym_ dla aplikacji generatywnej AI, wskazujc modelom, co maj robi i wpywajc na jako zwracanych odpowiedzi. "In偶ynieria prompt贸w" to szybko rozwijajca si dziedzina bada, kt贸ra koncentruje si na _projektowaniu i optymalizacji_ prompt贸w w celu uzyskania sp贸jnych i wysokiej jakoci odpowiedzi na du偶 skal.

## Cele nauki

W tej lekcji dowiemy si, czym jest in偶ynieria prompt贸w, dlaczego jest wa偶na i jak mo偶emy tworzy bardziej skuteczne prompty dla danego modelu i celu aplikacji. Zrozumiemy podstawowe pojcia i najlepsze praktyki w zakresie in偶ynierii prompt贸w - oraz poznamy interaktywne rodowisko "sandbox" w Jupyter Notebooks, w kt贸rym mo偶emy zastosowa te koncepcje na rzeczywistych przykadach.

Pod koniec tej lekcji bdziemy w stanie:

1. Wyjani, czym jest in偶ynieria prompt贸w i dlaczego jest wa偶na.
2. Opisa elementy promptu i spos贸b ich wykorzystania.
3. Pozna najlepsze praktyki i techniki in偶ynierii prompt贸w.
4. Zastosowa poznane techniki na rzeczywistych przykadach, korzystajc z punktu kocowego OpenAI.

## Kluczowe pojcia

In偶ynieria prompt贸w: Praktyka projektowania i udoskonalania danych wejciowych w celu nakierowania modeli AI na generowanie po偶danych wynik贸w.
Tokenizacja: Proces przeksztacania tekstu w mniejsze jednostki, zwane tokenami, kt贸re model mo偶e zrozumie i przetworzy.
LLM dostosowane do instrukcji: Wielkie modele jzykowe (LLM), kt贸re zostay dostrojone za pomoc konkretnych instrukcji w celu poprawy dokadnoci i trafnoci odpowiedzi.

## rodowisko nauki

In偶ynieria prompt贸w jest obecnie bardziej sztuk ni偶 nauk. Najlepszym sposobem na rozwinicie intuicji w tym zakresie jest _praktyka_ i podejcie oparte na pr贸bach i bdach, kt贸re czy wiedz eksperck z zalecanymi technikami i optymalizacjami specyficznymi dla modelu.

Notatnik Jupyter towarzyszcy tej lekcji zapewnia rodowisko _sandbox_, w kt贸rym mo偶esz wypr贸bowa to, czego si uczysz - na bie偶co lub w ramach wyzwania programistycznego na kocu. Aby wykona wiczenia, bdziesz potrzebowa:

1. **Klucza API Azure OpenAI** - punktu kocowego dla wdro偶onego LLM.
2. **rodowiska uruchomieniowego Python** - w kt贸rym mo偶na uruchomi notatnik.
3. **Lokalnych zmiennych rodowiskowych** - _ukocz [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) teraz, aby si przygotowa_.

Notatnik zawiera wiczenia _startowe_ - ale zachcamy do dodawania wasnych sekcji _Markdown_ (opis) i _Code_ (zapytania prompt贸w), aby wypr贸bowa wicej przykad贸w lub pomys贸w - i rozwija intuicj w projektowaniu prompt贸w.

## Przewodnik ilustrowany

Chcesz zrozumie og贸lny obraz tego, co obejmuje ta lekcja, zanim si zagbisz? Sprawd藕 ten przewodnik ilustrowany, kt贸ry daje poczucie g贸wnych temat贸w i kluczowych wniosk贸w, o kt贸rych warto pomyle w ka偶dym z nich. Plan lekcji prowadzi od zrozumienia podstawowych koncepcji i wyzwa do ich rozwizania za pomoc odpowiednich technik in偶ynierii prompt贸w i najlepszych praktyk. Zauwa偶, 偶e sekcja "Zaawansowane techniki" w tym przewodniku odnosi si do treci om贸wionych w _nastpnym_ rozdziale tego programu nauczania.

![Przewodnik ilustrowany po in偶ynierii prompt贸w](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.pl.png)

## Nasz startup

Porozmawiajmy teraz o tym, jak _ten temat_ odnosi si do naszej misji startupu, aby [wprowadza innowacje AI do edukacji](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Chcemy budowa aplikacje wspierane przez AI, kt贸re umo偶liwiaj _spersonalizowan nauk_ - wic zastan贸wmy si, jak r贸偶ni u偶ytkownicy naszej aplikacji mog "projektowa" prompty:

- **Administratorzy** mog poprosi AI o _analiz danych dotyczcych programu nauczania w celu zidentyfikowania luk w pokryciu tematycznym_. AI mo偶e podsumowa wyniki lub przedstawi je w formie wizualnej za pomoc kodu.
- **Nauczyciele** mog poprosi AI o _stworzenie planu lekcji dla okrelonej grupy docelowej i tematu_. AI mo偶e stworzy spersonalizowany plan w okrelonym formacie.
- **Uczniowie** mog poprosi AI o _pomoc w nauce trudnego przedmiotu_. AI mo偶e teraz prowadzi uczni贸w, oferujc lekcje, wskaz贸wki i przykady dostosowane do ich poziomu.

To tylko wierzchoek g贸ry lodowej. Sprawd藕 [Prompty dla edukacji](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - otwart bibliotek prompt贸w, opracowan przez ekspert贸w edukacyjnych - aby uzyska szersze spojrzenie na mo偶liwoci! _Spr贸buj uruchomi niekt贸re z tych prompt贸w w sandboxie lub w OpenAI Playground, aby zobaczy, co si stanie!_

## Czym jest in偶ynieria prompt贸w?

Rozpoczlimy t lekcj od zdefiniowania **in偶ynierii prompt贸w** jako procesu _projektowania i optymalizacji_ tekstowych danych wejciowych (prompt贸w) w celu uzyskania sp贸jnych i wysokiej jakoci odpowiedzi (wynik贸w) dla danego celu aplikacji i modelu. Mo偶emy myle o tym jako o procesie dwustopniowym:

- _projektowanie_ pocztkowego promptu dla danego modelu i celu
- _udoskonalanie_ promptu w spos贸b iteracyjny w celu poprawy jakoci odpowiedzi

Jest to proces oparty na pr贸bach i bdach, kt贸ry wymaga intuicji u偶ytkownika i wysiku, aby osign optymalne wyniki. Dlaczego wic jest to wa偶ne? Aby odpowiedzie na to pytanie, musimy najpierw zrozumie trzy pojcia:

- _Tokenizacja_ = jak model "widzi" prompt
- _Podstawowe LLM_ = jak model bazowy "przetwarza" prompt
- _LLM dostosowane do instrukcji_ = jak model mo偶e teraz widzie "zadania"

### Tokenizacja

LLM widzi prompty jako _cig token贸w_, przy czym r贸偶ne modele (lub wersje modelu) mog tokenizowa ten sam prompt w r贸偶ny spos贸b. Poniewa偶 LLM s trenowane na tokenach (a nie na surowym tekcie), spos贸b, w jaki prompty s tokenizowane, ma bezporedni wpyw na jako generowanej odpowiedzi.

Aby zrozumie, jak dziaa tokenizacja, wypr贸buj narzdzia takie jak [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) pokazane poni偶ej. Skopiuj sw贸j prompt - i zobacz, jak zostaje przeksztacony w tokeny, zwracajc uwag na spos贸b, w jaki obsugiwane s znaki odstpu i znaki interpunkcyjne. Zauwa偶, 偶e ten przykad pokazuje starszy LLM (GPT-3) - wic wypr贸bowanie tego z nowszym modelem mo偶e da inny wynik.

![Tokenizacja](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.pl.png)

### Koncepcja: Modele bazowe

Po tokenizacji promptu g贸wn funkcj ["Podstawowego LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (lub modelu bazowego) jest przewidywanie tokenu w tym cigu. Poniewa偶 LLM s trenowane na ogromnych zbiorach danych tekstowych, maj dobr znajomo statystycznych relacji midzy tokenami i mog dokonywa tego przewidywania z pewnym stopniem pewnoci. Nale偶y zauwa偶y, 偶e nie rozumiej _znaczenia_ s贸w w promptach czy tokenach; widz jedynie wz贸r, kt贸ry mog "uzupeni" kolejnym przewidywaniem. Mog kontynuowa przewidywanie cigu, a偶 zostanie ono przerwane przez interwencj u偶ytkownika lub jaki wczeniej ustalony warunek.

Chcesz zobaczy, jak dziaa uzupenianie oparte na promptach? Wprowad藕 powy偶szy prompt do [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) w Azure OpenAI Studio z domylnymi ustawieniami. System jest skonfigurowany tak, aby traktowa prompty jako zapytania o informacje - wic powiniene zobaczy wynik, kt贸ry spenia ten kontekst.

Ale co, jeli u偶ytkownik chciaby zobaczy co konkretnego, co spenia okrelone kryteria lub cel zadania? Wanie tutaj wchodz w gr _LLM dostosowane do instrukcji_.

![Uzupenianie czatu w modelu bazowym LLM](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.pl.png)

### Koncepcja: LLM dostosowane do instrukcji

[LLM dostosowane do instrukcji](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zaczynaj od modelu bazowego i dostrajaj go za pomoc przykad贸w lub par wejcie/wyjcie (np. wieloetapowych "wiadomoci"), kt贸re mog zawiera jasne instrukcje - a odpowied藕 AI pr贸buje pod偶a za t instrukcj.

Wykorzystuje to techniki takie jak uczenie przez wzmocnienie z informacj zwrotn od czowieka (RLHF), kt贸re mog trenowa model do _pod偶ania za instrukcjami_ i _uczenia si na podstawie informacji zwrotnej_, aby generowa odpowiedzi lepiej dostosowane do praktycznych zastosowa i bardziej trafne w kontekcie cel贸w u偶ytkownika.

Spr贸bujmy - wr贸 do powy偶szego promptu, ale teraz zmie _wiadomo systemow_, aby dostarczy nastpujc instrukcj jako kontekst:

> _Podsumuj tre, kt贸r otrzymasz, dla ucznia drugiej klasy. Ogranicz wynik do jednego akapitu z 3-5 punktami._

Zobacz, jak wynik jest teraz dostosowany do odzwierciedlenia po偶danego celu i formatu? Nauczyciel mo偶e teraz bezporednio wykorzysta t odpowied藕 w swoich slajdach na lekcji.

![Uzupenianie czatu w modelu dostosowanym do instrukcji LLM](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.pl.png)

## Dlaczego potrzebujemy in偶ynierii prompt贸w?

Teraz, gdy wiemy, jak prompty s przetwarzane przez LLM, porozmawiajmy o _dlaczego_ potrzebujemy in偶ynierii prompt贸w. Odpowied藕 le偶y w fakcie, 偶e obecne LLM stawiaj przed nami szereg wyzwa, kt贸re sprawiaj, 偶e _wiarygodne i sp贸jne wyniki_ s trudniejsze do osignicia bez wysiku wo偶onego w konstrukcj i optymalizacj prompt贸w. Na przykad:

1. **Odpowiedzi modeli s stochastyczne.** _Ten sam prompt_ prawdopodobnie wygeneruje r贸偶ne odpowiedzi w r贸偶nych modelach lub wersjach modeli. Mo偶e r贸wnie偶 generowa r贸偶ne wyniki w _tym samym modelu_ w r贸偶nych momentach. _Techniki in偶ynierii prompt贸w mog pom贸c nam zminimalizowa te r贸偶nice, zapewniajc lepsze zabezpieczenia_.

1. **Modele mog tworzy faszywe odpowiedzi.** Modele s wstpnie trenowane na _du偶ych, ale ograniczonych_ zbiorach danych, co oznacza, 偶e brakuje im wiedzy na temat poj spoza zakresu tego treningu. W rezultacie mog generowa wyniki, kt贸re s niecise, wymylone lub bezporednio sprzeczne z znanymi faktami. _Techniki in偶ynierii prompt贸w pomagaj u偶ytkownikom identyfikowa i minimalizowa takie faszerstwa, np. proszc AI o cytaty lub uzasadnienia_.

1. **Zdolnoci modeli bd si r贸偶ni.** Nowsze modele lub generacje modeli bd miay bogatsze mo偶liwoci, ale tak偶e wprowadz unikalne cechy i kompromisy w kosztach i zo偶onoci. _In偶ynieria prompt贸w mo偶e pom贸c nam opracowa najlepsze praktyki i przepywy pracy, kt贸re abstrahuj r贸偶nice i dostosowuj si do specyficznych wymaga modeli w skalowalny, pynny spos贸b_.

Zobaczmy to w dziaaniu w OpenAI lub Azure OpenAI Playground:

- U偶yj tego samego promptu z r贸偶nymi wdro偶eniami LLM (np. OpenAI, Azure OpenAI, Hugging Face) - czy zauwa偶ye r贸偶nice?
- U偶yj tego samego promptu wielokrotnie z _tym samym_ wdro偶eniem LLM (np. Azure OpenAI Playground) - jak r贸偶niy si te wariacje?

### Przykad faszerstw

W tym kursie u偶ywamy terminu **"faszerstwo"** w odniesieniu do zjawiska, w kt贸rym LLM czasami generuj nieprawdziwe informacje z powodu ogranicze w ich treningu lub innych uwarunkowa. Mo偶esz r贸wnie偶 spotka si z okreleniem _"halucynacje"_ w popularnych artykuach lub pracach naukowych. Jednak zdecydowanie zalecamy u偶ywanie terminu _"faszerstwo"_, aby przypadkowo nie przypisywa cech ludzkich do wyniku generowanego przez maszyn. W ten spos贸b wzmacniamy [wytyczne dotyczce odpowiedzialnej AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) z perspektywy terminologicznej, eliminujc terminy, kt贸re mog by uznane za obra藕liwe lub nieinkluzywne w niekt贸rych kontekstach.

Chcesz zrozumie, jak dziaaj faszerstwa? Pomyl o promptcie, kt贸ry instruuje AI, aby wygenerowaa tre na temat nieistniejcego zagadnienia (aby upewni si, 偶e nie znajduje si ono w zbiorze danych treningowych). Na przykad - spr贸bowaem tego promptu:

> **Prompt:** stw贸rz plan lekcji na
Wyszukiwanie w Internecie pokazao, 偶e istniej fikcyjne opowieci (np. seriale telewizyjne lub ksi偶ki) o wojnach na Marsie - ale 偶adna z nich nie dotyczy roku 2076. Zdrowy rozsdek podpowiada r贸wnie偶, 偶e rok 2076 jest _przyszoci_ i nie mo偶e by zwizany z rzeczywistym wydarzeniem.

Co si wic dzieje, gdy uruchamiamy ten prompt z r贸偶nymi dostawcami LLM?

> **Odpowied藕 1**: OpenAI Playground (GPT-35)

![Odpowied藕 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.pl.png)

> **Odpowied藕 2**: Azure OpenAI Playground (GPT-35)

![Odpowied藕 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.pl.png)

> **Odpowied藕 3**: Hugging Face Chat Playground (LLama-2)

![Odpowied藕 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.pl.png)

Zgodnie z oczekiwaniami, ka偶dy model (lub wersja modelu) generuje nieco inne odpowiedzi dziki stochastycznemu zachowaniu i r贸偶nicom w mo偶liwociach modelu. Na przykad jeden model kieruje si do odbiorc贸w na poziomie 贸smej klasy, podczas gdy inny zakada poziom ucznia szkoy redniej. Jednak wszystkie trzy modele wygeneroway odpowiedzi, kt贸re mogyby przekona niewiadomego u偶ytkownika, 偶e wydarzenie byo prawdziwe.

Techniki in偶ynierii prompt贸w, takie jak _metaprompting_ i _konfiguracja temperatury_, mog w pewnym stopniu zmniejszy fabrykacje modelu. Nowe _architektury_ in偶ynierii prompt贸w r贸wnie偶 pynnie integruj nowe narzdzia i techniki w przepywie prompt贸w, aby zagodzi lub zmniejszy niekt贸re z tych efekt贸w.

## Studium przypadku: GitHub Copilot

Zakoczmy t sekcj, zyskujc wgld w to, jak in偶ynieria prompt贸w jest wykorzystywana w rzeczywistych rozwizaniach, przygldajc si jednemu studium przypadku: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot to Tw贸j "AI Pair Programmer" - przeksztaca tekstowe prompty w uzupenienia kodu i jest zintegrowany z Twoim rodowiskiem programistycznym (np. Visual Studio Code), zapewniajc pynne dowiadczenie u偶ytkownika. Jak udokumentowano w serii poni偶szych wpis贸w na blogu, najwczeniejsza wersja bya oparta na modelu OpenAI Codex - in偶ynierowie szybko zdali sobie spraw z potrzeby dostosowania modelu i opracowania lepszych technik in偶ynierii prompt贸w, aby poprawi jako kodu. W lipcu [zadebiutowali ulepszonym modelem AI, kt贸ry wykracza poza Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst), oferujc jeszcze szybsze sugestie.

Przeczytaj wpisy w kolejnoci, aby ledzi ich drog nauki.

- **Maj 2023** | [GitHub Copilot staje si coraz lepszy w rozumieniu Twojego kodu](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Wewntrz GitHub: Praca z LLM za GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Czerwiec 2023** | [Jak pisa lepsze prompty dla GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Lipiec 2023** | [.. GitHub Copilot wykracza poza Codex dziki ulepszonemu modelowi AI](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Lipiec 2023** | [Przewodnik dla programist贸w po in偶ynierii prompt贸w i LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Wrzesie 2023** | [Jak zbudowa aplikacj LLM dla przedsibiorstw: Lekcje z GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Mo偶esz r贸wnie偶 przeglda ich [blog in偶ynieryjny](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) w poszukiwaniu wicej wpis贸w, takich jak [ten](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), kt贸ry pokazuje, jak te modele i techniki s _stosowane_ w celu napdzania rzeczywistych aplikacji.

---

## Konstrukcja prompt贸w

Widzielimy, dlaczego in偶ynieria prompt贸w jest wa偶na - teraz zrozummy, jak prompty s _konstruowane_, abymy mogli oceni r贸偶ne techniki projektowania bardziej efektywnych prompt贸w.

### Podstawowy prompt

Zacznijmy od podstawowego promptu: tekstowego wejcia wysyanego do modelu bez dodatkowego kontekstu. Oto przykad - gdy wysyamy pierwsze sowa hymnu narodowego USA do OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), natychmiast _uzupenia_ odpowied藕 o kolejne linijki, ilustrujc podstawowe zachowanie predykcyjne.

| Prompt (Wejcie) | Completion (Wyjcie)                                                                                                                        |
| :--------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Wyglda na to, 偶e zaczynasz tekst "The Star-Spangled Banner", hymnu narodowego Stan贸w Zjednoczonych. Peny tekst to ... |

### Zo偶ony prompt

Teraz dodajmy kontekst i instrukcje do tego podstawowego promptu. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) pozwala nam skonstruowa zo偶ony prompt jako kolekcj _wiadomoci_ z:

- Parami wejcie/wyjcie odzwierciedlajcymi _wejcie u偶ytkownika_ i _odpowied藕 asystenta_.
- Wiadomoci systemow ustawiajc kontekst dla zachowania lub osobowoci asystenta.

呕danie ma teraz poni偶sz form, gdzie _tokenizacja_ skutecznie przechwytuje istotne informacje z kontekstu i rozmowy. Zmiana kontekstu systemowego mo偶e by r贸wnie wpywowa na jako uzupenie, jak dostarczone wejcia u偶ytkownika.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt instrukcji

W powy偶szych przykadach prompt u偶ytkownika by prostym zapytaniem tekstowym, kt贸re mo偶na interpretowa jako prob o informacje. W przypadku prompt贸w _instrukcji_ mo偶emy u偶y tego tekstu, aby bardziej szczeg贸owo okreli zadanie, zapewniajc lepsze wskaz贸wki dla AI. Oto przykad:

| Prompt (Wejcie)                                                                                                                                                                                                                         | Completion (Wyjcie)                                                                                                        | Typ instrukcji      |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Napisz opis wojny secesyjnej                                                                                                                                                                      | _zwr贸cono prosty akapit_                                                                                                   | Prosty              |
| Napisz opis wojny secesyjnej. Podaj kluczowe daty i wydarzenia oraz opisz ich znaczenie                                                                                                          | _zwr贸cono akapit, a nastpnie list kluczowych dat wydarze z opisami_                                                     | Zo偶ony             |
| Napisz opis wojny secesyjnej w jednym akapicie. Podaj 3 punkty z kluczowymi datami i ich znaczeniem. Podaj 3 kolejne punkty z kluczowymi postaciami historycznymi i ich wkadem. Zwr贸 wynik jako plik JSON | _zwr贸cono bardziej szczeg贸owe informacje w polu tekstowym, sformatowane jako JSON, kt贸re mo偶na skopiowa i zweryfikowa_ | Zo偶ony. Sformatowany. |

## G贸wna tre

W powy偶szych przykadach prompt by nadal do otwarty, pozwalajc LLM zdecydowa, kt贸ra cz jego wstpnie wytrenowanego zestawu danych jest istotna. W przypadku wzorca projektowego _g贸wnej treci_ tekst wejciowy jest podzielony na dwie czci:

- instrukcj (dziaanie)
- istotn tre (kt贸ra wpywa na dziaanie)

Oto przykad, w kt贸rym instrukcja brzmi "podsumuj to w 2 zdaniach".

| Prompt (Wejcie)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Wyjcie)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest gazowym olbrzymem o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 masa wszystkich innych planet w Ukadzie Sonecznym razem wzitych. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom jeszcze przed zapisaniem historii. Zosta nazwany na cze rzymskiego boga Jowisza.[19] Gdy jest widoczny z Ziemi, Jowisz mo偶e by na tyle jasny, 偶e jego odbite wiato rzuca widoczne cienie,[20] i jest rednio trzecim najjaniejszym naturalnym obiektem na nocnym niebie po Ksi偶ycu i Wenus. <br/> **Podsumuj to w 2 kr贸tkich zdaniach** | Jowisz, pita planeta od Soca, jest najwiksz w Ukadzie Sonecznym i znany jest jako jeden z najjaniejszych obiekt贸w na nocnym niebie. Nazwany na cze rzymskiego boga Jowisza, jest gazowym olbrzymem o masie dwa i p贸 razy wikszej ni偶 masa wszystkich innych planet w Ukadzie Sonecznym razem wzitych. |

Segment g贸wnej treci mo偶e by u偶ywany na r贸偶ne sposoby, aby skuteczniej kierowa instrukcjami:

- **Przykady** - zamiast m贸wi modelowi, co ma zrobi za pomoc wyra藕nej instrukcji, podaj mu przykady tego, co ma zrobi, i pozw贸l mu wywnioskowa wzorzec.
- **Wskaz贸wki** - pod偶aj za instrukcj z "wskaz贸wk", kt贸ra przygotowuje uzupenienie, kierujc model w stron bardziej istotnych odpowiedzi.
- **Szablony** - s to powtarzalne 'przepisy' na prompty z miejscami na zmienne, kt贸re mo偶na dostosowa za pomoc danych do konkretnych przypadk贸w u偶ycia.

Przyjrzyjmy si, jak to dziaa w praktyce.

### U偶ycie przykad贸w

To podejcie polega na u偶yciu g贸wnej treci do "nakarmienia modelu" kilkoma przykadami po偶danego wyniku dla danego polecenia i pozwoleniu mu na wywnioskowanie wzorca dla po偶danego wyniku. W zale偶noci od liczby podanych przykad贸w mo偶emy mie prompty zero-shot, one-shot, few-shot itd.

Prompt skada si teraz z trzech element贸w:

- Opis zadania
- Kilka przykad贸w po偶danego wyniku
- Pocztek nowego przykadu (kt贸ry staje si domylnym opisem zadania)

| Typ uczenia | Prompt (Wejcie)                                                                                                                                        | Completion (Wyjcie)         |
| :---------- | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------- |
| Zero-shot   | "Soce wieci". Przetumacz na hiszpaski                                                                                                              | "El Sol est谩 brillando".    |
| One-shot    | "Soce wieci" => ""El Sol est谩 brillando". <br> "Jest zimny i wietrzny dzie" =>                                                                      | "Es un d铆a fr铆o y ventoso". |
| Few-shot    | Zawodnik przebieg bazy => Baseball <br/> Zawodnik zdoby asa => Tenis <br/> Zawodnik zdoby sz贸stk => Krykiet <br/> Zawodnik wykona wsad =>          | Koszyk贸wka                  |
|             |                                                                                                                                                         |                             |

Zauwa偶, 偶e musielimy poda wyra藕n instrukcj ("Przetumacz na hiszpaski") w przykadzie zero-shot, ale jest ona wywnioskowana w przykadzie one-shot. Przykad few-shot pokazuje, jak dodanie wikszej liczby przykad贸w pozwala modelom na bardziej precyzyjne wnioskowanie bez dodatkowych instrukcji.

### Wskaz贸wki w promptach

Inn technik wykorzystania g贸wnej treci jest podanie _wskaz贸wek_ zamiast przykad贸w. W tym przypadku dajemy modelowi wskaz贸wk w odpowiednim kierunku, _rozpoczynajc_ go fragmentem, kt贸ry odzwierciedla po偶dany format odpowiedzi. Model nastpnie "pod偶a za wskaz贸wk", kontynuujc w tym samym stylu.

| Liczba wskaz贸wek | Prompt (Wejcie)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Wyjcie)                                                                                                                                                                                                                                                                                       |
| :--------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                | Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest gazowym olbrzymem o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 masa wszystkich innych planet w Ukadzie Sonecznym razem wzitych. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom jeszcze przed zapisaniem historii. <br/>**Podsumuj to**                                       | Jowisz jest najwiksz planet w naszym Ukadzie Sonecznym i pit od Soca. Jest gazowym olbrzymem o masie 1/1000 masy Soca, ale jest ci偶szy ni偶 wszystkie inne planety razem wzite. Staro偶ytne cywilizacje znay Jowisza od dawna, a na nocnym niebie jest atwo widoczny. |
| 1              | Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest gazowym olbrzymem o masie stanowicej jedn tysiczn masy Soca, ale dwa i p贸 razy wikszej ni偶 masa wszystkich innych planet w Ukadzie Sonecznym razem wzitych. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom jeszcze przed zapisaniem historii. <br/>**Podsumuj to** <br/> Dowiedzielimy si, 偶e Jowisz | jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest gazowym olbrzymem o masie stanowicej jedn tysiczn masy Soca, ale dwa i p贸 razy wikszej ni偶 masa wszystkich innych planet razem wzitych. Jest atwo widoczny goym okiem i znany od czas贸w staro偶ytnych.                        |
| 2              | Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest gazowym olbrzymem o masie stanowicej jedn tysiczn masy Soca, ale dwa i p贸 razy wikszej ni偶 masa wszystkich innych planet w Ukadzie Sonecznym razem wzitych. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom jeszcze przed zapisaniem historii. <br/>**Podsumuj to** <br/> Top 3 Fakty, kt贸re poznalimy:         | 1. Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. <br/> 2. Jest gazowym olbrzymem o masie stanowicej jedn tysiczn masy Soca...<br/> 3. Jowisz by widoczny goym okiem od czas贸w staro偶ytnych ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Szablony prompt贸w

Szablon promptu to _z g贸ry zdefiniowany przepis na prompt_, kt贸ry mo偶na przechowywa i ponownie wykorzystywa w razie potrzeby, aby zapewni bardziej sp贸jne dowiadczenia u偶ytkownika na du偶 skal. W najprostszej formie jest to po prostu zbi贸r przykad贸w prompt贸w, takich jak [ten od OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), kt贸ry zawiera zar贸wno interaktywne komponenty promptu (wiadomoci u偶ytkownika i systemu), jak i format 偶dania API - wspierajc ponowne u偶ycie.

W bardziej zo偶onej formie, jak [ten przykad z LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), zawiera _zastpniki_, kt贸re mo偶na zastpi danymi z r贸偶nych 藕r贸de (wejcie u偶ytkownika, kontekst systemu, zewntrzne 藕r贸da danych itp.), aby dynamicznie generowa prompt. Pozwala to na stworzenie biblioteki wielokrotnego u偶ytku prompt贸w, kt贸re mog by u偶ywane do programowego zapewnienia sp贸jnych dowiadcze u偶ytkownika na du偶 skal.

Ostatecznie prawdziwa warto szablon贸w le偶y w mo偶liwoci tworzenia i publikowania _bibliotek prompt贸w_ dla pionowych domen aplikacji - gdzie szablon promptu jest teraz _optymalizowany_ w celu odzwierciedlenia kontekstu specyficznego dla aplikacji lub przykad贸w, kt贸re sprawiaj, 偶e odpowiedzi s bardziej trafne i dokadne dla docelowej grupy u偶ytkownik贸w. Repozytorium [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) jest wietnym przykadem tego podejcia, kurujc bibliotek prompt贸w dla domeny edukacyjnej z naciskiem na kluczowe cele, takie jak planowanie lekcji, projektowanie program贸w nauczania, korepetycje dla uczni贸w itp.

## Treci wspierajce

Jeli mylimy o konstrukcji promptu jako o posiadaniu instrukcji (zadania) i celu (g贸wnej treci), to _treci drugorzdne_ s jak dodatkowy kontekst, kt贸ry dostarczamy, aby **wpyn na wynik w jaki spos贸b**. Mog to by parametry dostrajania, instrukcje formatowania, taksonomie temat贸w itp., kt贸re mog pom贸c modelowi _dostosowa_ swoj odpowied藕 do oczekiwa lub cel贸w u偶ytkownika.

Na przykad: Majc katalog kurs贸w z obszernymi metadanymi (nazwa, opis, poziom, tagi metadanych, instruktor itp.) na temat wszystkich dostpnych kurs贸w w programie nauczania:

- mo偶emy zdefiniowa instrukcj "podsumuj katalog kurs贸w na jesie 2023"
- mo偶emy u偶y g贸wnej treci, aby dostarczy kilka przykad贸w po偶danego wyniku
- mo偶emy u偶y treci drugorzdnych, aby zidentyfikowa 5 najwa偶niejszych "tag贸w" zainteresowania.

Teraz model mo偶e dostarczy podsumowanie w formacie pokazanym przez kilka przykad贸w - ale jeli wynik ma wiele tag贸w, mo偶e priorytetyzowa 5 tag贸w zidentyfikowanych w treci drugorzdnej.

---

<!--
SZABLON LEKCJI:
Ta jednostka powinna obejmowa podstawowy koncept #1.
Wzmocnij koncept przykadami i odniesieniami.

KONCEPT #3:
Techniki in偶ynierii prompt贸w.
Jakie s podstawowe techniki in偶ynierii prompt贸w?
Zilustruj to wiczeniami.
-->

## Najlepsze praktyki tworzenia prompt贸w

Teraz, gdy wiemy, jak mo偶na _konstruowa_ prompty, mo偶emy zacz myle o tym, jak je _projektowa_, aby odzwierciedlay najlepsze praktyki. Mo偶emy to rozwa偶y w dw贸ch czciach - majc odpowiednie _nastawienie_ i stosujc odpowiednie _techniki_.

### Nastawienie w in偶ynierii prompt贸w

In偶ynieria prompt贸w to proces pr贸b i bd贸w, wic pamitaj o trzech szerokich czynnikach przewodnich:

1. **Zrozumienie domeny ma znaczenie.** Dokadno i trafno odpowiedzi zale偶y od _domeny_, w kt贸rej dziaa aplikacja lub u偶ytkownik. Wykorzystaj swoj intuicj i wiedz domenow, aby **dostosowa techniki**. Na przykad, zdefiniuj _osobowoci specyficzne dla domeny_ w promptach systemowych lub u偶yj _szablon贸w specyficznych dla domeny_ w promptach u偶ytkownika. Dostarcz treci drugorzdne, kt贸re odzwierciedlaj konteksty specyficzne dla domeny, lub u偶yj _wskaz贸wek i przykad贸w specyficznych dla domeny_, aby skierowa model na znane wzorce u偶ycia.

2. **Zrozumienie modelu ma znaczenie.** Wiemy, 偶e modele s z natury stochastyczne. Ale implementacje modeli mog r贸wnie偶 r贸偶ni si pod wzgldem u偶ywanego zestawu danych treningowych (wiedza wstpnie wytrenowana), dostarczanych mo偶liwoci (np. za porednictwem API lub SDK) i rodzaju treci, do kt贸rych s zoptymalizowane (np. kod, obrazy, tekst). Zrozum mocne i sabe strony modelu, kt贸rego u偶ywasz, i wykorzystaj t wiedz do _priorytetyzacji zada_ lub budowy _dostosowanych szablon贸w_ zoptymalizowanych pod ktem mo偶liwoci modelu.

3. **Iteracja i walidacja maj znaczenie.** Modele ewoluuj szybko, podobnie jak techniki in偶ynierii prompt贸w. Jako ekspert domenowy mo偶esz mie inne konteksty lub kryteria dla _swojej_ specyficznej aplikacji, kt贸re mog nie mie zastosowania do szerszej spoecznoci. U偶yj narzdzi i technik in偶ynierii prompt贸w, aby "rozpocz" konstrukcj promptu, a nastpnie iteruj i weryfikuj wyniki, korzystajc z wasnej intuicji i wiedzy domenowej. Zapisuj swoje spostrze偶enia i tw贸rz **baz wiedzy** (np. biblioteki prompt贸w), kt贸re mog by u偶ywane jako nowa baza przez innych, aby przyspieszy iteracje w przyszoci.

## Najlepsze praktyki

Przyjrzyjmy si teraz powszechnym najlepszym praktykom zalecanym przez [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) i praktyk贸w [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Co                               | Dlaczego                                                                                                                                                                                                                                               |
| :------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Oce najnowsze modele.           | Nowe generacje modeli prawdopodobnie maj ulepszone funkcje i jako - ale mog r贸wnie偶 wiza si z wy偶szymi kosztami. Oce ich wpyw, a nastpnie podejmij decyzje o migracji.                                                                        |
| Oddziel instrukcje i kontekst    | Sprawd藕, czy Tw贸j model/dostawca definiuje _delimitery_, aby wyra藕niej rozr贸偶ni instrukcje, treci g贸wne i drugorzdne. Mo偶e to pom贸c modelom dokadniej przypisywa wagi do token贸w.                                                                  |
| Bd藕 konkretny i jasny           | Podaj wicej szczeg贸贸w na temat po偶danego kontekstu, wyniku, dugoci, formatu, stylu itp. Poprawi to zar贸wno jako, jak i sp贸jno odpowiedzi. Zapisuj przepisy w szablonach wielokrotnego u偶ytku.                                                  |
| Bd藕 opisowy, u偶ywaj przykad贸w  | Modele mog lepiej reagowa na podejcie "poka偶 i opowiedz". Zacznij od podejcia `zero-shot`, w kt贸rym podajesz instrukcj (ale bez przykad贸w), a nastpnie spr贸buj `few-shot` jako udoskonalenie, dostarczajc kilka przykad贸w po偶danego wyniku. U偶ywaj analogii. |
| U偶ywaj wskaz贸wek do rozpoczcia  | Skieruj model w stron po偶danego wyniku, podajc mu kilka wiodcych s贸w lub fraz, kt贸re mo偶e wykorzysta jako punkt wyjcia do odpowiedzi.                                                                                                         |
| Powtarzaj                        | Czasami mo偶e by konieczne powt贸rzenie instrukcji modelowi. Podaj instrukcje przed i po g贸wnej treci, u偶yj instrukcji i wskaz贸wki itp. Iteruj i weryfikuj, aby zobaczy, co dziaa.                                                                  |
| Kolejno ma znaczenie           | Kolejno, w jakiej przedstawiasz informacje modelowi, mo偶e wpyn na wynik, nawet w przykadach uczcych, dziki efektowi wie偶oci. Wypr贸buj r贸偶ne opcje, aby zobaczy, co dziaa najlepiej.                                                          |
| Daj modelowi "wyjcie"           | Daj modelowi _odpowied藕 awaryjn_, kt贸r mo偶e poda, jeli z jakiego powodu nie mo偶e wykona zadania. Mo偶e to zmniejszy szanse na generowanie faszywych lub wymylonych odpowiedzi przez modele.                                                    |
|                                 |                                                                                                                                                                                                                                                       |

Jak w przypadku ka偶dej najlepszej praktyki, pamitaj, 偶e _Twoje dowiadczenia mog si r贸偶ni_ w zale偶noci od modelu, zadania i domeny. U偶ywaj tych wskaz贸wek jako punktu wyjcia i iteruj, aby znale藕 to, co dziaa najlepiej dla Ciebie. Stale oceniaj sw贸j proces in偶ynierii prompt贸w, gdy pojawiaj si nowe modele i narzdzia, koncentrujc si na skalowalnoci procesu i jakoci odpowiedzi.

<!--
SZABLON LEKCJI:
Ta jednostka powinna zawiera wyzwanie kodowe, jeli to mo偶liwe.

WYZWANIE:
Link do Jupyter Notebook z tylko komentarzami w instrukcjach (sekcje kodu s puste).

ROZWIZANIE:
Link do kopii tego Notebooka z wypenionymi i uruchomionymi promptami, pokazujcymi, jak mo偶e wyglda jeden przykad.
-->

## Zadanie

Gratulacje! Dotare do koca lekcji! Czas przetestowa niekt贸re z tych koncepcji i technik na prawdziwych przykadach!

Do naszego zadania u偶yjemy Jupyter Notebook z wiczeniami, kt贸re mo偶esz wykona interaktywnie. Mo偶esz tak偶e rozszerzy Notebook o wasne kom贸rki Markdown i kodu, aby samodzielnie eksplorowa pomysy i techniki.

### Aby rozpocz, zr贸b fork repozytorium, a nastpnie

- (Zalecane) Uruchom GitHub Codespaces
- (Alternatywnie) Sklonuj repozytorium na swoje lokalne urzdzenie i u偶yj go z Docker Desktop
- (Alternatywnie) Otw贸rz Notebook w preferowanym rodowisku uruchomieniowym Notebooka.

### Nastpnie skonfiguruj zmienne rodowiskowe

- Skopiuj plik `.env.copy` w katalogu g贸wnym repozytorium do `.env` i wypenij wartoci `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` i `AZURE_OPENAI_DEPLOYMENT`. Wr贸 do sekcji [Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), aby dowiedzie si jak.

### Nastpnie otw贸rz Jupyter Notebook

- Wybierz jdro uruchomieniowe. Jeli u偶ywasz opcji 1 lub 2, po prostu wybierz domylne jdro Python 3.10.x dostarczone przez kontener deweloperski.

Jeste gotowy do uruchomienia wicze. Zauwa偶, 偶e tutaj nie ma _dobrych i zych_ odpowiedzi - chodzi o eksplorowanie opcji metod pr贸b i bd贸w oraz budowanie intuicji, co dziaa w danym modelu i domenie aplikacji.

_Z tego powodu w tej lekcji nie ma segment贸w z rozwizaniami kodu. Zamiast tego Notebook bdzie zawiera kom贸rki Markdown zatytuowane "Moje rozwizanie:", kt贸re pokazuj jeden przykad wyniku dla odniesienia._

 <!--
SZABLON LEKCJI:
Zakocz sekcj podsumowaniem i zasobami do samodzielnej nauki.
-->

## Sprawdzenie wiedzy

Kt贸ry z poni偶szych prompt贸w jest dobry, zgodnie z rozsdnymi najlepszymi praktykami?

1. Poka偶 mi obraz czerwonego samochodu
2. Poka偶 mi obraz czerwonego samochodu marki Volvo i modelu XC90 zaparkowanego przy klifie z zachodzcym socem
3. Poka偶 mi obraz czerwonego samochodu marki Volvo i modelu XC90

Odpowied藕: 2, to najlepszy prompt, poniewa偶 dostarcza szczeg贸贸w na temat "czego" i wchodzi w szczeg贸y (nie tylko dowolny samoch贸d, ale konkretn mark i model) oraz opisuje og贸lne otoczenie. 3 jest nastpny w kolejnoci, poniewa偶 r贸wnie偶 zawiera du偶o opisu.

##  Wyzwanie

Spr贸buj wykorzysta technik "wskaz贸wki" z promptem: Uzupenij zdanie "Poka偶 mi obraz czerwonego samochodu marki Volvo i ". Co odpowiada model, i jak by to poprawi?

## wietna robota! Kontynuuj nauk

Chcesz dowiedzie si wicej o r贸偶nych koncepcjach in偶ynierii prompt贸w? Przejd藕 na [stron kontynuacji nauki](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby znale藕 inne wietne zasoby na ten temat.

Przejd藕 do Lekcji 5, gdzie przyjrzymy si [zaawansowanym technikom prompt贸w](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Zastrze偶enie**:  
Ten dokument zosta przetumaczony za pomoc usugi tumaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). Chocia偶 staramy si zapewni dokadno, prosimy pamita, 偶e automatyczne tumaczenia mog zawiera bdy lub niecisoci. Oryginalny dokument w jego jzyku ojczystym powinien by uznawany za autorytatywne 藕r贸do. W przypadku informacji krytycznych zaleca si skorzystanie z profesjonalnego tumaczenia przez czowieka. Nie ponosimy odpowiedzialnoci za jakiekolwiek nieporozumienia lub bdne interpretacje wynikajce z u偶ycia tego tumaczenia.