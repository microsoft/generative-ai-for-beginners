<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-05-19T09:37:05+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "pl"
}
-->
# Podstawy InÅ¼ynierii PromptÃ³w

## Wprowadzenie
Ten moduÅ‚ obejmuje kluczowe pojÄ™cia i techniki tworzenia skutecznych promptÃ³w w modelach generatywnej AI. SposÃ³b, w jaki piszesz prompt do LLM, ma znaczenie. Starannie opracowany prompt moÅ¼e przynieÅ›Ä‡ lepszÄ… jakoÅ›Ä‡ odpowiedzi. Ale co dokÅ‚adnie oznaczajÄ… terminy takie jak _prompt_ i _inÅ¼ynieria promptÃ³w_? I jak mogÄ™ poprawiÄ‡ _wejÅ›cie promptu_, ktÃ³re wysyÅ‚am do LLM? To sÄ… pytania, na ktÃ³re sprÃ³bujemy odpowiedzieÄ‡ w tym rozdziale i nastÄ™pnym.

_Generatywna AI_ potrafi tworzyÄ‡ nowÄ… zawartoÅ›Ä‡ (np. tekst, obrazy, dÅºwiÄ™ki, kod itp.) w odpowiedzi na zapytania uÅ¼ytkownikÃ³w. OsiÄ…ga to za pomocÄ… _Modeli JÄ™zykowych Wielkiej Skali_ takich jak seria GPT ("Generative Pre-trained Transformer") firmy OpenAI, ktÃ³re sÄ… trenowane do uÅ¼ywania jÄ™zyka naturalnego i kodu.

UÅ¼ytkownicy mogÄ… teraz wchodziÄ‡ w interakcje z tymi modelami za pomocÄ… znanych paradygmatÃ³w, takich jak czat, bez potrzeby posiadania wiedzy technicznej czy szkolenia. Modele sÄ… _oparte na promptach_ - uÅ¼ytkownicy wysyÅ‚ajÄ… wejÅ›cie tekstowe (prompt) i otrzymujÄ… odpowiedÅº AI (uzupeÅ‚nienie). MogÄ… nastÄ™pnie "rozmawiaÄ‡ z AI" w sposÃ³b iteracyjny, w wieloetapowych konwersacjach, udoskonalajÄ…c swÃ³j prompt, aÅ¼ odpowiedÅº speÅ‚ni ich oczekiwania.

"Prompty" stajÄ… siÄ™ teraz podstawowym _interfejsem programowania_ dla aplikacji generatywnej AI, wskazujÄ…c modelom, co majÄ… robiÄ‡ i wpÅ‚ywajÄ…c na jakoÅ›Ä‡ zwracanych odpowiedzi. "InÅ¼ynieria PromptÃ³w" to szybko rozwijajÄ…ca siÄ™ dziedzina badaÅ„, ktÃ³ra koncentruje siÄ™ na _projektowaniu i optymalizacji_ promptÃ³w w celu dostarczania spÃ³jnych i wysokiej jakoÅ›ci odpowiedzi na duÅ¼Ä… skalÄ™.

## Cele Nauki

W tej lekcji dowiemy siÄ™, czym jest InÅ¼ynieria PromptÃ³w, dlaczego ma znaczenie i jak moÅ¼emy tworzyÄ‡ bardziej efektywne prompty dla danego modelu i celu aplikacji. Zrozumiemy podstawowe pojÄ™cia i najlepsze praktyki w inÅ¼ynierii promptÃ³w - oraz poznamy interaktywne Å›rodowisko "piaskownicy" Jupyter Notebooks, w ktÃ³rym moÅ¼emy zobaczyÄ‡ zastosowanie tych pojÄ™Ä‡ w praktycznych przykÅ‚adach.

Pod koniec tej lekcji bÄ™dziemy w stanie:

1. WyjaÅ›niÄ‡, czym jest inÅ¼ynieria promptÃ³w i dlaczego jest waÅ¼na.
2. OpisaÄ‡ skÅ‚adniki promptu i sposÃ³b ich uÅ¼ycia.
3. PoznaÄ‡ najlepsze praktyki i techniki inÅ¼ynierii promptÃ³w.
4. ZastosowaÄ‡ poznane techniki do rzeczywistych przykÅ‚adÃ³w, uÅ¼ywajÄ…c punktu koÅ„cowego OpenAI.

## Kluczowe PojÄ™cia

InÅ¼ynieria PromptÃ³w: Praktyka projektowania i udoskonalania wejÅ›Ä‡, aby skierowaÄ‡ modele AI do generowania poÅ¼Ä…danych wynikÃ³w.
Tokenizacja: Proces przeksztaÅ‚cania tekstu w mniejsze jednostki, zwane tokenami, ktÃ³re model moÅ¼e zrozumieÄ‡ i przetworzyÄ‡.
LLM-y dostosowane do instrukcji: Modele JÄ™zykowe Wielkiej Skali (LLM), ktÃ³re zostaÅ‚y dostosowane do konkretnych instrukcji w celu poprawy dokÅ‚adnoÅ›ci i trafnoÅ›ci ich odpowiedzi.

## Piaskownica Nauki

InÅ¼ynieria promptÃ³w jest obecnie bardziej sztukÄ… niÅ¼ naukÄ…. Najlepszym sposobem na poprawÄ™ naszej intuicji w tym zakresie jest _praktyka_ i przyjÄ™cie podejÅ›cia prÃ³b i bÅ‚Ä™dÃ³w, ktÃ³re Å‚Ä…czy wiedzÄ™ dziedzinowÄ… z zalecanymi technikami i optymalizacjami specyficznymi dla modelu.

Jupyter Notebook towarzyszÄ…cy tej lekcji zapewnia Å›rodowisko _piaskownicy_, w ktÃ³rym moÅ¼esz wyprÃ³bowaÄ‡ to, czego siÄ™ nauczysz - na bieÅ¼Ä…co lub jako czÄ™Å›Ä‡ wyzwania kodowego na koÅ„cu. Aby wykonaÄ‡ Ä‡wiczenia, bÄ™dziesz potrzebowaÄ‡:

1. **Klucz API Azure OpenAI** - punkt koÅ„cowy usÅ‚ugi dla wdroÅ¼onego LLM.
2. **Åšrodowisko wykonawcze Pythona** - w ktÃ³rym moÅ¼na uruchomiÄ‡ Notebook.
3. **Lokalne zmienne Å›rodowiskowe** - _ukoÅ„cz kroki [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst), aby siÄ™ przygotowaÄ‡_.

Notebook zawiera Ä‡wiczenia _startowe_ - ale zachÄ™camy do dodania wÅ‚asnych sekcji _Markdown_ (opis) i _Code_ (Å¼Ä…dania promptÃ³w), aby wyprÃ³bowaÄ‡ wiÄ™cej przykÅ‚adÃ³w lub pomysÅ‚Ã³w - i budowaÄ‡ swojÄ… intuicjÄ™ dotyczÄ…cÄ… projektowania promptÃ³w.

## Przewodnik Ilustrowany

Chcesz zobaczyÄ‡ ogÃ³lny obraz tego, co obejmuje ta lekcja, zanim siÄ™ zagÅ‚Ä™bisz? SprawdÅº ten przewodnik ilustrowany, ktÃ³ry daje ci wyobraÅ¼enie o gÅ‚Ã³wnych tematach omÃ³wionych i kluczowych wnioskach, ktÃ³re powinieneÅ› przemyÅ›leÄ‡ w kaÅ¼dym z nich. Plan lekcji prowadzi ciÄ™ od zrozumienia podstawowych pojÄ™Ä‡ i wyzwaÅ„ do ich rozwiÄ…zania za pomocÄ… odpowiednich technik inÅ¼ynierii promptÃ³w i najlepszych praktyk. ZauwaÅ¼, Å¼e sekcja "Zaawansowane Techniki" w tym przewodniku odnosi siÄ™ do treÅ›ci omÃ³wionych w _nastÄ™pnym_ rozdziale tego programu nauczania.

## Nasz Startup

Teraz porozmawiajmy o tym, jak _ten temat_ odnosi siÄ™ do naszej misji startupowej, aby [przynieÅ›Ä‡ innowacje AI do edukacji](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Chcemy budowaÄ‡ aplikacje AI wspomagajÄ…ce _spersonalizowane uczenie siÄ™_ - wiÄ™c zastanÃ³wmy siÄ™, jak rÃ³Å¼ni uÅ¼ytkownicy naszej aplikacji mogÄ… "projektowaÄ‡" prompty:

- **Administratorzy** mogÄ… poprosiÄ‡ AI o _analizÄ™ danych programu nauczania w celu zidentyfikowania luk w pokryciu_. AI moÅ¼e podsumowaÄ‡ wyniki lub przedstawiÄ‡ je w formie wizualnej za pomocÄ… kodu.
- **Nauczyciele** mogÄ… poprosiÄ‡ AI o _wygenerowanie planu lekcji dla docelowej grupy odbiorcÃ³w i tematu_. AI moÅ¼e zbudowaÄ‡ spersonalizowany plan w okreÅ›lonym formacie.
- **Studenci** mogÄ… poprosiÄ‡ AI o _nauczanie ich trudnego przedmiotu_. AI moÅ¼e teraz prowadziÄ‡ uczniÃ³w za pomocÄ… lekcji, wskazÃ³wek i przykÅ‚adÃ³w dostosowanych do ich poziomu.

To tylko wierzchoÅ‚ek gÃ³ry lodowej. SprawdÅº [Prompty dla Edukacji](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - otwartÄ… bibliotekÄ™ promptÃ³w kuratorowanÄ… przez ekspertÃ³w edukacyjnych - aby uzyskaÄ‡ szersze pojÄ™cie o moÅ¼liwoÅ›ciach! _SprÃ³buj uruchomiÄ‡ niektÃ³re z tych promptÃ³w w piaskownicy lub uÅ¼ywajÄ…c OpenAI Playground, aby zobaczyÄ‡, co siÄ™ stanie!_

## Co to jest InÅ¼ynieria PromptÃ³w?

ZaczÄ™liÅ›my tÄ™ lekcjÄ™ od zdefiniowania **InÅ¼ynierii PromptÃ³w** jako procesu _projektowania i optymalizacji_ tekstowych wejÅ›Ä‡ (promptÃ³w) w celu dostarczania spÃ³jnych i wysokiej jakoÅ›ci odpowiedzi (uzupeÅ‚nieÅ„) dla danego celu aplikacji i modelu. MoÅ¼emy myÅ›leÄ‡ o tym jako o procesie dwustopniowym:

- _projektowanie_ poczÄ…tkowego promptu dla danego modelu i celu
- _udoskonalanie_ promptu iteracyjnie w celu poprawy jakoÅ›ci odpowiedzi

Jest to koniecznie proces prÃ³b i bÅ‚Ä™dÃ³w, ktÃ³ry wymaga intuicji uÅ¼ytkownika i wysiÅ‚ku, aby osiÄ…gnÄ…Ä‡ optymalne wyniki. Dlaczego jest to waÅ¼ne? Aby odpowiedzieÄ‡ na to pytanie, musimy najpierw zrozumieÄ‡ trzy pojÄ™cia:

- _Tokenizacja_ = jak model "widzi" prompt
- _Podstawowe LLM-y_ = jak model bazowy "przetwarza" prompt
- _LLM-y dostosowane do instrukcji_ = jak model moÅ¼e teraz widzieÄ‡ "zadania"

### Tokenizacja

LLM widzi prompty jako _sekwencjÄ™ tokenÃ³w_, gdzie rÃ³Å¼ne modele (lub wersje modelu) mogÄ… tokenizowaÄ‡ ten sam prompt na rÃ³Å¼ne sposoby. PoniewaÅ¼ LLM-y sÄ… trenowane na tokenach (a nie na surowym tekÅ›cie), sposÃ³b, w jaki prompty sÄ… tokenizowane, ma bezpoÅ›redni wpÅ‚yw na jakoÅ›Ä‡ generowanej odpowiedzi.

Aby uzyskaÄ‡ intuicjÄ™ na temat tego, jak dziaÅ‚a tokenizacja, wyprÃ³buj narzÄ™dzia takie jak [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) pokazane poniÅ¼ej. Skopiuj swÃ³j prompt - i zobacz, jak to zostaje przeksztaÅ‚cone w tokeny, zwracajÄ…c uwagÄ™ na to, jak traktowane sÄ… znaki biaÅ‚e i znaki interpunkcyjne. ZauwaÅ¼, Å¼e ten przykÅ‚ad pokazuje starszy LLM (GPT-3) - wiÄ™c wyprÃ³bowanie tego z nowszym modelem moÅ¼e daÄ‡ inny wynik.

### PojÄ™cie: Modele Bazowe

Gdy prompt zostanie tokenizowany, gÅ‚Ã³wnÄ… funkcjÄ… ["Podstawowego LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (lub modelu bazowego) jest przewidywanie tokenu w tej sekwencji. PoniewaÅ¼ LLM-y sÄ… trenowane na ogromnych zbiorach danych tekstowych, majÄ… dobrÄ… znajomoÅ›Ä‡ statystycznych relacji miÄ™dzy tokenami i mogÄ… dokonaÄ‡ tego przewidywania z pewnym stopniem pewnoÅ›ci. ZauwaÅ¼, Å¼e nie rozumiejÄ… _znaczenia_ sÅ‚Ã³w w promptach czy tokenach; widzÄ… tylko wzÃ³r, ktÃ³ry mogÄ… "uzupeÅ‚niÄ‡" swojÄ… nastÄ™pnÄ… przewidywanÄ… wartoÅ›ciÄ…. MogÄ… kontynuowaÄ‡ przewidywanie sekwencji aÅ¼ do przerwania przez interwencjÄ™ uÅ¼ytkownika lub jakÄ…Å› wczeÅ›niej ustalonÄ… warunek.

Chcesz zobaczyÄ‡, jak dziaÅ‚a uzupeÅ‚nianie oparte na promptach? WprowadÅº powyÅ¼szy prompt do [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) w Azure OpenAI Studio z domyÅ›lnymi ustawieniami. System jest skonfigurowany do traktowania promptÃ³w jako Å¼Ä…daÅ„ informacji - wiÄ™c powinieneÅ› zobaczyÄ‡ uzupeÅ‚nienie, ktÃ³re speÅ‚nia ten kontekst.

Ale co, jeÅ›li uÅ¼ytkownik chciaÅ‚by zobaczyÄ‡ coÅ› konkretnego, co speÅ‚nia pewne kryteria lub cel zadania? Tutaj wkraczajÄ… _LLM-y dostosowane do instrukcji_.

### PojÄ™cie: LLM-y Dostosowane do Instrukcji

[LLM Dostosowany do Instrukcji](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zaczyna siÄ™ od modelu bazowego i dostraja go za pomocÄ… przykÅ‚adÃ³w lub par wejÅ›cie/wyjÅ›cie (np. wieloetapowych "wiadomoÅ›ci"), ktÃ³re mogÄ… zawieraÄ‡ jasne instrukcje - a odpowiedÅº AI prÃ³buje podÄ…Å¼aÄ‡ za tÄ… instrukcjÄ….

UÅ¼ywa to technik takich jak Uczenie siÄ™ przez Wzmocnienie z InformacjÄ… ZwrotnÄ… od CzÅ‚owieka (RLHF), ktÃ³re mogÄ… trenowaÄ‡ model do _podÄ…Å¼ania za instrukcjami_ i _uczenia siÄ™ na podstawie informacji zwrotnej_, aby generowaÅ‚ odpowiedzi lepiej dostosowane do praktycznych zastosowaÅ„ i bardziej trafne dla celÃ³w uÅ¼ytkownika.

SprÃ³bujmy - odwiedÅº ponownie powyÅ¼szy prompt, ale teraz zmieÅ„ _wiadomoÅ›Ä‡ systemowÄ…_, aby dostarczyÄ‡ nastÄ™pujÄ…cÄ… instrukcjÄ™ jako kontekst:

> _Podsumuj treÅ›Ä‡, ktÃ³rÄ… Ci dostarczono, dla ucznia drugiej klasy. Zachowaj wynik w jednym akapicie z 3-5 punktami._

Zobacz, jak wynik jest teraz dostosowany, aby odzwierciedlaÄ‡ poÅ¼Ä…dany cel i format? Nauczyciel moÅ¼e teraz bezpoÅ›rednio uÅ¼yÄ‡ tej odpowiedzi w swoich slajdach dla tej klasy.

## Dlaczego potrzebujemy InÅ¼ynierii PromptÃ³w?

Teraz, gdy wiemy, jak prompty sÄ… przetwarzane przez LLM-y, porozmawiajmy o _dlaczego_ potrzebujemy inÅ¼ynierii promptÃ³w. OdpowiedÅº leÅ¼y w fakcie, Å¼e obecne LLM-y stawiajÄ… szereg wyzwaÅ„, ktÃ³re sprawiajÄ…, Å¼e _wiarygodne i spÃ³jne uzupeÅ‚nienia_ sÄ… trudniejsze do osiÄ…gniÄ™cia bez wÅ‚oÅ¼enia wysiÅ‚ku w konstrukcjÄ™ i optymalizacjÄ™ promptÃ³w. Na przykÅ‚ad:

1. **Odpowiedzi modeli sÄ… stochastyczne.** _Ten sam prompt_ prawdopodobnie wygeneruje rÃ³Å¼ne odpowiedzi w rÃ³Å¼nych modelach lub wersjach modeli. MoÅ¼e rÃ³wnieÅ¼ generowaÄ‡ rÃ³Å¼ne wyniki z _tym samym modelem_ w rÃ³Å¼nych momentach. _Techniki inÅ¼ynierii promptÃ³w mogÄ… pomÃ³c nam zminimalizowaÄ‡ te wariacje, zapewniajÄ…c lepsze ograniczenia_.

1. **Modele mogÄ… fabrykowaÄ‡ odpowiedzi.** Modele sÄ… wstÄ™pnie trenowane na _duÅ¼ych, ale skoÅ„czonych_ zbiorach danych, co oznacza, Å¼e brakuje im wiedzy na temat pojÄ™Ä‡ spoza tego zakresu treningowego. W rezultacie mogÄ… generowaÄ‡ uzupeÅ‚nienia, ktÃ³re sÄ… niedokÅ‚adne, fikcyjne lub bezpoÅ›rednio sprzeczne z znanymi faktami. _Techniki inÅ¼ynierii promptÃ³w pomagajÄ… uÅ¼ytkownikom zidentyfikowaÄ‡ i zminimalizowaÄ‡ takie fabrykacje, np. proszÄ…c AI o cytaty lub rozumowanie_.

1. **ZdolnoÅ›ci modeli bÄ™dÄ… siÄ™ rÃ³Å¼niÄ‡.** Nowsze modele lub generacje modeli bÄ™dÄ… miaÅ‚y bogatsze zdolnoÅ›ci, ale takÅ¼e wprowadzÄ… unikalne cechy i kompromisy w zakresie kosztÃ³w i zÅ‚oÅ¼onoÅ›ci. _InÅ¼ynieria promptÃ³w moÅ¼e pomÃ³c nam opracowaÄ‡ najlepsze praktyki i przepÅ‚ywy pracy, ktÃ³re abstrahujÄ… rÃ³Å¼nice i dostosowujÄ… siÄ™ do wymagaÅ„ specyficznych dla modelu w skalowalny, bezproblemowy sposÃ³b_.

Zobaczmy to w dziaÅ‚aniu w OpenAI lub Azure OpenAI Playground:

- UÅ¼yj tego samego promptu z rÃ³Å¼nymi wdroÅ¼eniami LLM (np. OpenAI, Azure OpenAI, Hugging Face) - czy zauwaÅ¼yÅ‚eÅ› rÃ³Å¼nice?
- UÅ¼yj tego samego promptu wielokrotnie z _tym samym_ wdroÅ¼eniem LLM (np. Azure OpenAI playground) - jak te rÃ³Å¼nice siÄ™ rÃ³Å¼niÅ‚y?

### PrzykÅ‚ad Fabrykacji

W tym kursie uÅ¼ywamy terminu **"fabrykacja"** do odniesienia siÄ™ do zjawiska, w ktÃ³rym LLM-y czasami generujÄ… faktycznie niepoprawne informacje z powodu ograniczeÅ„ w ich treningu lub innych ograniczeÅ„. MoÅ¼esz rÃ³wnieÅ¼ sÅ‚yszeÄ‡ o tym jako _"halucynacje"_ w popularnych artykuÅ‚ach lub pracach badawczych. Jednak zdecydowanie zalecamy uÅ¼ywanie terminu _"fabrykacja"_, aby nie przypisywaÄ‡ zachowaniu cechy ludzkiej, przypisujÄ…c wynikowi generowanemu przez maszynÄ™ cechÄ™ przypisywanÄ… czÅ‚owiekowi. To takÅ¼e wzmacnia [Zasady Odpowiedzialnej AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) z perspektywy terminologii, eliminujÄ…c terminy, ktÃ³re mogÄ… byÄ‡ uznane za obraÅºliwe lub nieinkluzywne w niektÃ³rych kontekstach.

Chcesz zobaczyÄ‡, jak dziaÅ‚ajÄ… fabrykacje? PomyÅ›l o promptcie, ktÃ³ry instruuje AI, aby wygenerowaÅ‚a treÅ›Ä‡ na temat nieistniejÄ…cego tematu (aby upewniÄ‡ siÄ™, Å¼e nie znajduje siÄ™ w zbiorze danych treningowych). Na przykÅ‚ad - sprÃ³bowaÅ‚em tego promptu:

> **Prompt:** wygeneruj plan lekcji na temat Wojny MarsjaÅ„skiej z 2076 roku.

Wyszukiwanie w sieci pokazaÅ‚o mi, Å¼e istniejÄ… fikcyjne opowieÅ›ci (np. seriale telewizyjne lub ksiÄ…Å¼ki) o wojnach marsjaÅ„skich - ale Å¼adna w 2076 roku. Zdrowy rozsÄ…dek rÃ³wnieÅ¼ mÃ³wi nam, Å¼e 2076 rok jest _w przyszÅ‚oÅ›ci_ i dlatego nie moÅ¼e byÄ‡ zwiÄ…zany z prawdziwym wydarzeniem.

WiÄ™c co siÄ™ dzieje, gdy uruchamiamy ten prompt z rÃ³Å¼nymi dostawcami LLM?

> **OdpowiedÅº 1**: OpenAI Playground (GPT-35)

> **OdpowiedÅº 2**: Azure OpenAI Playground (GPT-35)

> **OdpowiedÅº 3**: : Hugging Face Chat Playground (LLama-2)

Jak moÅ¼na siÄ™ spodziewaÄ‡, kaÅ¼dy model (lub wersja modelu) generuje nieco inne odpowiedzi dziÄ™ki zachowaniu st
Ostateczna wartoÅ›Ä‡ szablonÃ³w leÅ¼y w moÅ¼liwoÅ›ci tworzenia i publikowania _bibliotek promptÃ³w_ dla pionowych domen aplikacji - gdzie szablon promptu jest teraz _optymalizowany_, aby odzwierciedlaÄ‡ kontekst aplikacji lub przykÅ‚ady, ktÃ³re sprawiajÄ…, Å¼e odpowiedzi sÄ… bardziej trafne i dokÅ‚adne dla docelowej grupy uÅ¼ytkownikÃ³w. Repozytorium [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) jest doskonaÅ‚ym przykÅ‚adem tego podejÅ›cia, zbierajÄ…c bibliotekÄ™ promptÃ³w dla domeny edukacyjnej z naciskiem na kluczowe cele, takie jak planowanie lekcji, projektowanie programÃ³w nauczania, korepetycje dla studentÃ³w itd.

## WspierajÄ…ca treÅ›Ä‡

JeÅ›li myÅ›limy o konstruowaniu promptÃ³w jako o posiadaniu instrukcji (zadania) i celu (gÅ‚Ã³wnej treÅ›ci), to _treÅ›Ä‡ wtÃ³rna_ jest jak dodatkowy kontekst, ktÃ³ry dostarczamy, aby **wpÅ‚ynÄ…Ä‡ na wynik w jakiÅ› sposÃ³b**. MoÅ¼e to byÄ‡ dostrajanie parametrÃ³w, instrukcje formatowania, taksonomie tematÃ³w itd., ktÃ³re mogÄ… pomÃ³c modelowi _dostosowaÄ‡_ swojÄ… odpowiedÅº do oczekiwanych celÃ³w uÅ¼ytkownika.

Na przykÅ‚ad: MajÄ…c katalog kursÃ³w z rozbudowanymi metadanymi (nazwa, opis, poziom, tagi metadanych, instruktor itd.) dotyczÄ…cymi wszystkich dostÄ™pnych kursÃ³w w programie nauczania:

- moÅ¼emy zdefiniowaÄ‡ instrukcjÄ™ "podsumuj katalog kursÃ³w na jesieÅ„ 2023"
- moÅ¼emy uÅ¼yÄ‡ gÅ‚Ã³wnej treÅ›ci, aby dostarczyÄ‡ kilka przykÅ‚adÃ³w poÅ¼Ä…danego wyniku
- moÅ¼emy uÅ¼yÄ‡ treÅ›ci wtÃ³rnej, aby zidentyfikowaÄ‡ 5 najwaÅ¼niejszych "tagÃ³w" zainteresowania.

Teraz model moÅ¼e dostarczyÄ‡ podsumowanie w formacie pokazanym przez kilka przykÅ‚adÃ³w - ale jeÅ›li wynik ma wiele tagÃ³w, moÅ¼e priorytetyzowaÄ‡ 5 tagÃ³w zidentyfikowanych w treÅ›ci wtÃ³rnej.

---

<!--
SZABLON LEKCJI:
Ta jednostka powinna obejmowaÄ‡ podstawowÄ… koncepcjÄ™ #1.
Wzmocnij koncepcjÄ™ przykÅ‚adami i odniesieniami.

KONCEPCJA #3:
Techniki inÅ¼ynierii promptÃ³w.
Jakie sÄ… podstawowe techniki inÅ¼ynierii promptÃ³w?
Zilustruj to za pomocÄ… Ä‡wiczeÅ„.
-->

## Najlepsze praktyki w tworzeniu promptÃ³w

Teraz, gdy wiemy, jak moÅ¼na _konstruowaÄ‡_ prompty, moÅ¼emy zaczÄ…Ä‡ myÅ›leÄ‡ o tym, jak je _projektowaÄ‡_, aby odzwierciedlaÅ‚y najlepsze praktyki. MoÅ¼emy rozwaÅ¼yÄ‡ to w dwÃ³ch czÄ™Å›ciach - posiadanie odpowiedniego _nastawienia_ i zastosowanie odpowiednich _technik_.

### Nastawienie do inÅ¼ynierii promptÃ³w

InÅ¼ynieria promptÃ³w to proces prÃ³b i bÅ‚Ä™dÃ³w, wiÄ™c miej na uwadze trzy szerokie czynniki przewodnie:

1. **Zrozumienie domeny ma znaczenie.** DokÅ‚adnoÅ›Ä‡ i trafnoÅ›Ä‡ odpowiedzi jest funkcjÄ… _domeny_, w ktÃ³rej dziaÅ‚a aplikacja lub uÅ¼ytkownik. Zastosuj swojÄ… intuicjÄ™ i wiedzÄ™ domenowÄ…, aby **dostosowaÄ‡ techniki** dalej. Na przykÅ‚ad, zdefiniuj _osobowoÅ›ci specyficzne dla domeny_ w swoich promptach systemowych lub uÅ¼yj _szablonÃ³w specyficznych dla domeny_ w swoich promptach uÅ¼ytkownika. Dostarcz treÅ›Ä‡ wtÃ³rnÄ…, ktÃ³ra odzwierciedla konteksty specyficzne dla domeny lub uÅ¼yj _wskazÃ³wek i przykÅ‚adÃ³w specyficznych dla domeny_, aby poprowadziÄ‡ model w kierunku znanych wzorcÃ³w uÅ¼ytkowania.

2. **Zrozumienie modelu ma znaczenie.** Wiemy, Å¼e modele sÄ… z natury stochastyczne. Ale implementacje modeli mogÄ… rÃ³wnieÅ¼ rÃ³Å¼niÄ‡ siÄ™ pod wzglÄ™dem uÅ¼ywanego zestawu danych treningowych (wiedza wstÄ™pnie trenowana), moÅ¼liwoÅ›ci, ktÃ³re oferujÄ… (np. przez API lub SDK) i rodzaju treÅ›ci, do ktÃ³rych sÄ… optymalizowane (np. kod vs. obrazy vs. tekst). Zrozumienie mocnych stron i ograniczeÅ„ modelu, ktÃ³rego uÅ¼ywasz, i uÅ¼ycie tej wiedzy do _priorytetyzacji zadaÅ„_ lub budowania _dostosowanych szablonÃ³w_, ktÃ³re sÄ… optymalizowane pod kÄ…tem moÅ¼liwoÅ›ci modelu.

3. **Iteracja i walidacja ma znaczenie.** Modele szybko siÄ™ rozwijajÄ…, podobnie jak techniki inÅ¼ynierii promptÃ³w. Jako ekspert domeny, moÅ¼esz mieÄ‡ inne konteksty lub kryteria _swojej_ specyficznej aplikacji, ktÃ³re mogÄ… nie mieÄ‡ zastosowania do szerszej spoÅ‚ecznoÅ›ci. UÅ¼yj narzÄ™dzi i technik inÅ¼ynierii promptÃ³w, aby "rozpoczÄ…Ä‡" konstrukcjÄ™ promptÃ³w, a nastÄ™pnie iteruj i waliduj wyniki, uÅ¼ywajÄ…c swojej intuicji i wiedzy domenowej. Zapisuj swoje spostrzeÅ¼enia i twÃ³rz **bazÄ™ wiedzy** (np. biblioteki promptÃ³w), ktÃ³ra moÅ¼e byÄ‡ uÅ¼ywana jako nowa baza przez innych, dla szybszych iteracji w przyszÅ‚oÅ›ci.

## Najlepsze praktyki

Teraz przyjrzyjmy siÄ™ powszechnym najlepszym praktykom zalecanym przez praktykÃ³w [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) i [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Co                               | Dlaczego                                                                                                                                                                                                                                               |
| :------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| OceÅ„ najnowsze modele.           | Nowe generacje modeli prawdopodobnie majÄ… ulepszone funkcje i jakoÅ›Ä‡ - ale mogÄ… rÃ³wnieÅ¼ generowaÄ‡ wyÅ¼sze koszty. OceÅ„ je pod kÄ…tem wpÅ‚ywu, a nastÄ™pnie podejmij decyzje o migracji.                                                                     |
| Oddziel instrukcje i kontekst    | SprawdÅº, czy twÃ³j model/dostawca definiuje _oddzielacze_, aby wyraÅºniej rozrÃ³Å¼niaÄ‡ instrukcje, treÅ›Ä‡ gÅ‚Ã³wnÄ… i wtÃ³rnÄ…. To moÅ¼e pomÃ³c modelom przypisywaÄ‡ wagi bardziej dokÅ‚adnie do tokenÃ³w.                                                              |
| BÄ…dÅº konkretny i jasny           | Podaj wiÄ™cej szczegÃ³Å‚Ã³w dotyczÄ…cych poÅ¼Ä…danego kontekstu, wyniku, dÅ‚ugoÅ›ci, formatu, stylu itd. To poprawi zarÃ³wno jakoÅ›Ä‡, jak i spÃ³jnoÅ›Ä‡ odpowiedzi. Zapisz przepisy w szablonach do ponownego uÅ¼ycia.                                                  |
| BÄ…dÅº opisowy, uÅ¼ywaj przykÅ‚adÃ³w  | Modele mogÄ… lepiej reagowaÄ‡ na podejÅ›cie "pokaÅ¼ i powiedz". Zacznij od `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an â€œoutâ€           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or fabricated responses.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

As with any best practice, remember that _your mileage may vary_ based on the model, the task and the domain. Use these as a starting point, and iterate to find what works best for you. Constantly re-evaluate your prompt engineering process as new models and tools become available, with a focus on process scalability and response quality.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Congratulations! You made it to the end of the lesson! It's time to put some of those concepts and techniques to the test with real examples!

For our assignment, we'll be using a Jupyter Notebook with exercises you can complete interactively. You can also extend the Notebook with your own Markdown and Code cells to explore ideas and techniques on your own.

### To get started, fork the repo, then

- (Recommended) Launch GitHub Codespaces
- (Alternatively) Clone the repo to your local device and use it with Docker Desktop
- (Alternatively) Open the Notebook with your preferred Notebook runtime environment.

### Next, configure your environment variables

- Copy the `.env.copy` file in repo root to `.env` and fill in the `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` and `AZURE_OPENAI_DEPLOYMENT` wartoÅ›ci. WrÃ³Ä‡ do sekcji [Learning Sandbox](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals), aby dowiedzieÄ‡ siÄ™ wiÄ™cej.

### NastÄ™pnie otwÃ³rz Jupyter Notebook

- Wybierz jÄ…dro runtime. JeÅ›li uÅ¼ywasz opcji 1 lub 2, po prostu wybierz domyÅ›lne jÄ…dro Python 3.10.x dostarczone przez kontener deweloperski.

JesteÅ› gotowy do wykonania Ä‡wiczeÅ„. ZauwaÅ¼, Å¼e nie ma tutaj _dobrych i zÅ‚ych_ odpowiedzi - po prostu eksplorowanie opcji metodÄ… prÃ³b i bÅ‚Ä™dÃ³w i budowanie intuicji dotyczÄ…cej tego, co dziaÅ‚a dla danego modelu i domeny aplikacji.

_Z tego powodu w tej lekcji nie ma segmentÃ³w z rozwiÄ…zaniami kodu. Zamiast tego, Notebook bÄ™dzie miaÅ‚ komÃ³rki Markdown zatytuÅ‚owane "Moje rozwiÄ…zanie:", ktÃ³re pokazujÄ… jeden przykÅ‚adowy wynik jako odniesienie._

 <!--
SZABLON LEKCJI:
ZakoÅ„cz sekcjÄ™ podsumowaniem i zasobami do samodzielnego uczenia siÄ™.
-->

## Sprawdzenie wiedzy

KtÃ³ry z poniÅ¼szych jest dobrym promptem, zgodnym z rozsÄ…dnymi najlepszymi praktykami?

1. PokaÅ¼ mi obraz czerwonego samochodu
2. PokaÅ¼ mi obraz czerwonego samochodu marki Volvo i modelu XC90 zaparkowanego przy klifie z zachodzÄ…cym sÅ‚oÅ„cem
3. PokaÅ¼ mi obraz czerwonego samochodu marki Volvo i modelu XC90

A: 2, to najlepszy prompt, poniewaÅ¼ dostarcza szczegÃ³Å‚Ã³w na temat "czego" i wchodzi w szczegÃ³Å‚y (nie tylko jakikolwiek samochÃ³d, ale konkretnÄ… markÄ™ i model) oraz opisuje ogÃ³lnÄ… sceneriÄ™. 3 jest nastÄ™pny najlepszy, poniewaÅ¼ rÃ³wnieÅ¼ zawiera wiele opisÃ³w.

## ğŸš€ Wyzwanie

Zobacz, czy moÅ¼esz wykorzystaÄ‡ technikÄ™ "wskazÃ³wki" z promptem: UkoÅ„cz zdanie "PokaÅ¼ mi obraz czerwonego samochodu marki Volvo i ". Jak na to odpowiada, i jak byÅ› to poprawiÅ‚?

## Åšwietna praca! Kontynuuj naukÄ™

Chcesz dowiedzieÄ‡ siÄ™ wiÄ™cej o rÃ³Å¼nych koncepcjach inÅ¼ynierii promptÃ³w? PrzejdÅº do [strony kontynuowanej nauki](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby znaleÅºÄ‡ inne Å›wietne zasoby na ten temat.

PrzejdÅº do Lekcji 5, gdzie przyjrzymy siÄ™ [zaawansowanym technikom promptÃ³w](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**ZastrzeÅ¼enie**:  
Ten dokument zostaÅ‚ przetÅ‚umaczony przy uÅ¼yciu usÅ‚ugi tÅ‚umaczenia AI [Co-op Translator](https://github.com/Azure/co-op-translator). ChociaÅ¼ staramy siÄ™ o dokÅ‚adnoÅ›Ä‡, prosimy pamiÄ™taÄ‡, Å¼e automatyczne tÅ‚umaczenia mogÄ… zawieraÄ‡ bÅ‚Ä™dy lub nieÅ›cisÅ‚oÅ›ci. Oryginalny dokument w jego rodzimym jÄ™zyku powinien byÄ‡ uwaÅ¼any za autorytatywne ÅºrÃ³dÅ‚o. W przypadku krytycznych informacji zalecane jest profesjonalne tÅ‚umaczenie przez czÅ‚owieka. Nie ponosimy odpowiedzialnoÅ›ci za wszelkie nieporozumienia lub bÅ‚Ä™dne interpretacje wynikajÄ…ce z korzystania z tego tÅ‚umaczenia.