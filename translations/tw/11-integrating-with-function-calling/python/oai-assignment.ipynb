{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 介紹\n",
    "\n",
    "本課程將涵蓋：\n",
    "- 什麼是函式呼叫及其使用案例\n",
    "- 如何使用 OpenAI 建立函式呼叫\n",
    "- 如何將函式呼叫整合到應用程式中\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "完成本課程後，您將了解並知道如何：\n",
    "\n",
    "- 使用函式呼叫的目的\n",
    "- 使用 OpenAI 服務設定函式呼叫\n",
    "- 為您的應用程式使用案例設計有效的函式呼叫\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 理解函式呼叫\n",
    "\n",
    "在本課程中，我們想為我們的教育新創公司建立一個功能，讓使用者能使用聊天機器人來尋找技術課程。我們將推薦符合他們技能水平、目前職務和感興趣技術的課程。\n",
    "\n",
    "為了完成這個目標，我們將結合使用：\n",
    " - `OpenAI` 來為使用者創建聊天體驗\n",
    " - `Microsoft Learn Catalog API` 來根據使用者的請求幫助他們尋找課程\n",
    " - `Function Calling` 將使用者的查詢傳送到函式以進行 API 請求。\n",
    "\n",
    "首先，讓我們看看為什麼我們會想要使用函式呼叫：\n",
    "\n",
    "print(\"下一次請求中的訊息：\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # 從 GPT 獲取新的回應，讓它能看到函式回應\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 為什麼要使用函式呼叫\n",
    "\n",
    "如果你已經完成本課程中的其他課程，你大概了解使用大型語言模型（LLMs）的強大功能。希望你也能看到它們的一些限制。\n",
    "\n",
    "函式呼叫是 OpenAI 服務的一項功能，旨在解決以下挑戰：\n",
    "\n",
    "回應格式不一致：\n",
    "- 在函式呼叫之前，大型語言模型的回應是非結構化且不一致的。開發者必須撰寫複雜的驗證程式碼來處理輸出中的每種變化。\n",
    "\n",
    "與外部資料整合有限：\n",
    "- 在此功能之前，將應用程式其他部分的資料整合到聊天上下文中是困難的。\n",
    "\n",
    "透過標準化回應格式並實現與外部資料的無縫整合，函式呼叫簡化了開發流程，並減少了額外驗證邏輯的需求。\n",
    "\n",
    "使用者無法獲得像「斯德哥爾摩目前的天氣如何？」這樣的答案。這是因為模型的資料僅限於訓練時的時間點。\n",
    "\n",
    "讓我們看下面的範例來說明這個問題：\n",
    "\n",
    "假設我們想建立一個學生資料庫，以便能夠為他們建議合適的課程。以下有兩個學生的描述，它們所包含的資料非常相似。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們想將此內容發送給大型語言模型（LLM）以解析資料。這之後可以用於我們的應用程式，將資料發送到 API 或儲存在資料庫中。\n",
    "\n",
    "讓我們建立兩個相同的提示，指示 LLM 我們感興趣的資訊：\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我們想將此內容發送給大型語言模型（LLM），以解析對我們產品重要的部分。因此，我們可以創建兩個相同的提示來指導LLM：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在創建這兩個提示後，我們將使用 `openai.ChatCompletion` 將它們發送給大型語言模型（LLM）。我們將提示存儲在 `messages` 變數中，並將角色指定為 `user`。這是為了模擬用戶向聊天機器人發送消息。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們可以將兩個請求都發送給大型語言模型，並檢查我們收到的回應。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "即使提示相同且描述相似，我們仍可能得到不同格式的 `Grades` 屬性。\n",
    "\n",
    "如果多次執行上述儲存格，格式可能是 `3.7` 或 `3.7 GPA`。\n",
    "\n",
    "這是因為 LLM 接收以書面提示形式呈現的非結構化資料，並且也回傳非結構化資料。我們需要有結構化格式，才能在儲存或使用這些資料時知道該期待什麼。\n",
    "\n",
    "透過使用函式呼叫，我們可以確保收到結構化資料。使用函式呼叫時，LLM 並不會實際呼叫或執行任何函式。相反地，我們為 LLM 建立一個結構，讓它依此回應。接著，我們使用這些結構化回應來判斷在應用程式中該執行哪個函式。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![函數呼叫流程圖](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.tw.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然後我們可以將函數返回的結果傳回給大型語言模型（LLM）。LLM 隨後會使用自然語言來回應並回答使用者的查詢。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用函式呼叫的應用案例\n",
    "\n",
    "**呼叫外部工具**  \n",
    "聊天機器人在回答使用者問題方面表現優異。透過函式呼叫，聊天機器人可以利用使用者的訊息來完成特定任務。例如，學生可以請聊天機器人「寄信給我的講師，說我需要更多這科目的協助」。這可以呼叫函式 `send_email(to: string, body: string)`\n",
    "\n",
    "**建立 API 或資料庫查詢**  \n",
    "使用者可以使用自然語言查找資訊，並將其轉換成格式化的查詢或 API 請求。舉例來說，老師可能會請求「誰完成了最後一個作業」，這可以呼叫名為 `get_completed(student_name: string, assignment: int, current_status: string)` 的函式\n",
    "\n",
    "**建立結構化資料**  \n",
    "使用者可以將一段文字或 CSV 檔案，利用大型語言模型擷取其中的重要資訊。例如，學生可以將一篇關於和平協議的維基百科文章轉換成 AI 快速記憶卡。這可以透過呼叫函式 `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` 來完成\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 建立您的第一個函式呼叫\n",
    "\n",
    "建立函式呼叫的過程包含三個主要步驟：\n",
    "1. 使用您的函式清單和使用者訊息呼叫 Chat Completions API\n",
    "2. 讀取模型的回應以執行動作，例如執行函式或 API 呼叫\n",
    "3. 使用函式的回應再次呼叫 Chat Completions API，利用該資訊來建立對使用者的回應。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![函式呼叫流程](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.tw.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 函式呼叫的元素\n",
    "\n",
    "#### 使用者輸入\n",
    "\n",
    "第一步是建立使用者訊息。這可以透過取得文字輸入的值來動態指定，或者你也可以在此處指定一個值。如果這是你第一次使用 Chat Completions API，我們需要定義訊息的 `role` 和 `content`。\n",
    "\n",
    "`role` 可以是 `system`（建立規則）、`assistant`（模型）或 `user`（最終使用者）。對於函式呼叫，我們會將其指定為 `user` 並給出一個範例問題。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 建立函式。\n",
    "\n",
    "接下來我們將定義一個函式及該函式的參數。我們這裡只會使用一個名為 `search_courses` 的函式，但你可以建立多個函式。\n",
    "\n",
    "**重要**：函式會包含在系統訊息中傳送給 LLM，並且會計入你可用的 token 數量。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**定義**\n",
    "\n",
    "函式定義結構有多個層級，每個層級都有其自身的屬性。以下是巢狀結構的解析：\n",
    "\n",
    "**頂層函式屬性：**\n",
    "\n",
    "`name` - 我們希望被呼叫的函式名稱。\n",
    "\n",
    "`description` - 這是函式如何運作的描述。在此處，具體且清楚非常重要。\n",
    "\n",
    "`parameters` - 一份清單，列出您希望模型在回應中產生的值與格式。\n",
    "\n",
    "**參數物件屬性：**\n",
    "\n",
    "`type` - 參數物件的資料類型（通常為 \"object\"）\n",
    "\n",
    "`properties` - 模型將用於回應的具體值清單。\n",
    "\n",
    "**個別參數屬性：**\n",
    "\n",
    "`name` - 由屬性鍵隱含定義（例如 \"role\"、\"product\"、\"level\"）\n",
    "\n",
    "`type` - 此特定參數的資料類型（例如 \"string\"、\"number\"、\"boolean\"）\n",
    "\n",
    "`description` - 該特定參數的描述。\n",
    "\n",
    "**選用屬性：**\n",
    "\n",
    "`required` - 一個陣列，列出完成函式呼叫所需的參數。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 呼叫函式  \n",
    "定義函式後，我們現在需要在呼叫 Chat Completion API 時包含它。我們透過在請求中加入 `functions` 來達成這點。在此案例中為 `functions=functions`。\n",
    "\n",
    "也有一個選項可以將 `function_call` 設為 `auto`。這表示我們會讓大型語言模型根據使用者訊息決定應該呼叫哪個函式，而不是由我們自己指定。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在讓我們來看看回應的格式：\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "你可以看到函式名稱被呼叫，並且從使用者訊息中，LLM 能夠找到符合函式參數的資料。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.將函式呼叫整合到應用程式中。\n",
    "\n",
    "在我們測試完來自 LLM 的格式化回應後，現在可以將其整合到應用程式中。\n",
    "\n",
    "### 管理流程\n",
    "\n",
    "要將此整合到我們的應用程式中，讓我們採取以下步驟：\n",
    "\n",
    "首先，讓我們呼叫 OpenAI 服務並將訊息存儲在名為 `response_message` 的變數中。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們將定義一個函數，該函數將調用 Microsoft Learn API 以獲取課程列表：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "作為最佳實踐，我們接著會查看模型是否想要呼叫一個函式。之後，我們會建立一個可用的函式並將其與被呼叫的函式相匹配。  \n",
    "接著，我們會取得該函式的參數並將它們對應到來自 LLM 的參數。\n",
    "\n",
    "最後，我們會附加函式呼叫訊息以及由 `search_courses` 訊息回傳的值。這樣就能提供 LLM 所需的所有資訊，  \n",
    "以自然語言回應使用者。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在我們將發送更新後的訊息給大型語言模型，以便我們能收到自然語言的回應，而非 API JSON 格式的回應。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 程式挑戰\n",
    "\n",
    "做得好！為了繼續學習 OpenAI 函數呼叫，你可以建立：https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - 函數的更多參數，可能幫助學習者找到更多課程。你可以在這裡找到可用的 API 參數：  \n",
    " - 建立另一個函數呼叫，取得學習者更多資訊，例如他們的母語  \n",
    " - 當函數呼叫和/或 API 呼叫未回傳任何合適課程時，建立錯誤處理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**免責聲明**：  \n本文件係使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 進行翻譯。雖然我們致力於確保翻譯的準確性，但請注意，自動翻譯可能包含錯誤或不準確之處。原始文件的母語版本應視為權威來源。對於重要資訊，建議採用專業人工翻譯。我們不對因使用本翻譯而產生的任何誤解或誤譯負責。\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T09:21:38+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "tw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}