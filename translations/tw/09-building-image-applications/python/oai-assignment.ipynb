{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立影像生成應用程式\n",
    "\n",
    "大型語言模型（LLM）不僅僅能產生文字，也能根據文字描述生成圖片。影像作為一種表現形式，在醫療科技、建築、旅遊、遊戲開發等多個領域都非常有用。本章將介紹目前最受歡迎的兩個影像生成模型：DALL-E 和 Midjourney。\n",
    "\n",
    "## 前言\n",
    "\n",
    "在本課程中，我們將學習：\n",
    "\n",
    "- 影像生成及其用途。\n",
    "- DALL-E 和 Midjourney 是什麼，以及它們的運作方式。\n",
    "- 如何打造一個影像生成應用程式。\n",
    "\n",
    "## 學習目標\n",
    "\n",
    "完成本課程後，你將能夠：\n",
    "\n",
    "- 建立一個影像生成應用程式。\n",
    "- 透過 meta prompts 為你的應用程式設定界限。\n",
    "- 使用 DALL-E 和 Midjourney。\n",
    "\n",
    "## 為什麼要建立影像生成應用程式？\n",
    "\n",
    "影像生成應用程式是探索生成式 AI 能力的絕佳方式。舉例來說，它們可以用於：\n",
    "\n",
    "- **影像編輯與合成**。你可以針對各種情境產生圖片，例如影像編輯或影像合成。\n",
    "\n",
    "- **應用於多元產業**。這些應用程式也能為醫療科技、旅遊、遊戲開發等多個產業產生所需的圖片。\n",
    "\n",
    "## 情境範例：Edu4All\n",
    "\n",
    "在本課程中，我們會繼續以新創公司 Edu4All 為例。學生們可以為他們的作業創作圖片，具體要產生什麼圖片由學生自行決定，像是為自己的童話故事畫插圖、創造新角色，或是幫助他們將想法和概念具象化。\n",
    "\n",
    "舉例來說，當 Edu4All 的學生在課堂上學習世界地標時，他們可以產生如下的圖片：\n",
    "\n",
    "![Edu4All 新創公司，地標課堂，艾菲爾鐵塔](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.tw.png)\n",
    "\n",
    "使用像這樣的提示詞\n",
    "\n",
    "> 「狗狗在清晨陽光下站在艾菲爾鐵塔旁」\n",
    "\n",
    "## 什麼是 DALL-E 和 Midjourney？\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) 和 [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) 是目前最受歡迎的兩個影像生成模型，讓你可以透過提示詞來產生圖片。\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "我們先從 DALL-E 開始介紹。DALL-E 是一個能根據文字描述生成圖片的生成式 AI 模型。\n",
    "\n",
    "> [DALL-E 是由兩個模型組成，CLIP 和 diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)。\n",
    "\n",
    "- **CLIP** 是一個能從圖片和文字中產生嵌入向量（數值化資料表示）的模型。\n",
    "\n",
    "- **Diffused attention** 則是根據嵌入向量生成圖片的模型。DALL-E 以大量圖片和文字資料集訓練而成，能根據文字描述產生圖片。例如，DALL-E 可以生成戴帽子的貓，或是有莫霍克頭的狗。\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney 的運作方式和 DALL-E 類似，都是根據文字提示生成圖片。Midjourney 也能用像「戴帽子的貓」或「有莫霍克頭的狗」這樣的提示詞來產生圖片。\n",
    "\n",
    "![由 Midjourney 生成的圖片，機械鴿子](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*圖片來源：Wikipedia，圖片由 Midjourney 生成*\n",
    "\n",
    "## DALL-E 和 Midjourney 的運作原理\n",
    "\n",
    "首先來看 [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)。DALL-E 是一個基於 transformer 架構的生成式 AI 模型，採用 *自回歸 transformer*。\n",
    "\n",
    "*自回歸 transformer* 決定模型如何根據文字描述生成圖片，它會一次產生一個像素，然後利用已生成的像素來產生下一個像素。這個過程會經過神經網路的多層處理，直到整張圖片完成。\n",
    "\n",
    "透過這個流程，DALL-E 能控制生成圖片中的屬性、物件、特徵等。不過，DALL-E 2 和 3 在圖片細節的控制上更為精細，\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立你的第一個影像生成應用程式\n",
    "\n",
    "那麼，要建立一個影像生成應用程式需要什麼呢？你需要以下這些函式庫：\n",
    "\n",
    "- **python-dotenv**，強烈建議你使用這個函式庫，將你的機密資訊存放在 *.env* 檔案中，避免直接寫在程式碼裡。\n",
    "- **openai**，這個函式庫用來與 OpenAI API 互動。\n",
    "- **pillow**，用來在 Python 中處理影像。\n",
    "- **requests**，協助你發送 HTTP 請求。\n",
    "\n",
    "1. 建立一個 *.env* 檔案，內容如下：\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. 將上述的函式庫收集到一個名為 *requirements.txt* 的檔案中，如下所示：\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. 接下來，建立虛擬環境並安裝這些函式庫：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> 對於 Windows，請使用以下指令來建立並啟用你的虛擬環境：\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. 在名為 *app.py* 的檔案中加入以下程式碼：\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "我們來說明一下這段程式碼：\n",
    "\n",
    "- 首先，我們匯入所需的函式庫，包括 OpenAI 函式庫、dotenv 函式庫、requests 函式庫，以及 Pillow 函式庫。\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- 接著，我們建立物件，這個物件會從你的 ``.env`` 檔案中取得 API 金鑰。\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- 然後，我們產生圖片：\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    上面的程式碼會回傳一個包含產生圖片網址的 JSON 物件。我們可以利用這個網址下載圖片並儲存到檔案中。\n",
    "\n",
    "- 最後，我們開啟圖片，並用預設的圖片檢視器來顯示它：\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### 產生圖片的更多細節\n",
    "\n",
    "我們來更詳細地看看產生圖片的程式碼：\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**，是用來產生圖片的文字提示。在這個例子中，我們使用的提示是「Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils」（兔子騎在馬上，手拿棒棒糖，站在長滿水仙花的霧氣草原上）。\n",
    "- **size**，是產生圖片的尺寸。在這裡，我們產生的是 1024x1024 像素的圖片。\n",
    "- **n**，是產生圖片的數量。在這個例子中，我們產生了兩張圖片。\n",
    "\n",
    "關於圖片，你還可以做更多的事情，我們會在下一節介紹。\n",
    "\n",
    "## 影像產生的進階功能\n",
    "\n",
    "到目前為止，你已經看到我們只用幾行 Python 程式碼就能產生圖片。不過，其實你還可以對圖片做更多操作。\n",
    "\n",
    "你還可以做以下這些事：\n",
    "\n",
    "- **進行編輯**。你可以提供一張現有的圖片、一個遮罩和一個提示詞，來修改圖片。例如，你可以在圖片的某個區域加上東西。以我們的兔子圖片為例，你可以幫兔子加上一頂帽子。做法就是提供圖片、遮罩（標示要變更的區域），以及描述要做什麼的文字提示。\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    原始圖片只有兔子，但最後產生的圖片會讓兔子戴上帽子。\n",
    "    \n",
    "- **產生變化版本**。這個功能是讓你用一張現有的圖片，請系統產生不同的變化版本。要產生變化，只要提供一張圖片和一個文字提示，然後像這樣寫程式碼：\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**免責聲明**：  \n本文件係使用 AI 翻譯服務 [Co-op Translator](https://github.com/Azure/co-op-translator) 翻譯。雖然我們力求準確，但請注意，自動翻譯可能包含錯誤或不精確之處。原始語言版本應視為具權威性的來源。對於重要資訊，建議尋求專業人工翻譯。我們對因使用本翻譯而產生的任何誤解或誤釋不承擔任何責任。\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:33:23+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "tw"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}