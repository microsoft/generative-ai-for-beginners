# Fundamentos de Engenharia de Prompts

[![Fundamentos de Engenharia de Prompts](../../../translated_images/pt-PT/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introdu√ß√£o
Este m√≥dulo aborda conceitos e t√©cnicas essenciais para criar prompts eficazes em modelos generativos de IA. A forma como escreve o seu prompt para um LLM tamb√©m √© importante. Um prompt cuidadosamente elaborado pode alcan√ßar uma melhor qualidade de resposta. Mas o que exatamente significam termos como _prompt_ e _engenharia de prompts_? E como posso melhorar a _entrada_ do prompt que envio ao LLM? Estas s√£o as quest√µes que tentaremos responder neste cap√≠tulo e no seguinte.

A _IA Generativa_ √© capaz de criar novo conte√∫do (ex., texto, imagens, √°udio, c√≥digo, etc.) em resposta a pedidos do utilizador. Isto √© conseguido usando _Modelos de Linguagem de Grande Escala_ como a s√©rie GPT da OpenAI ("Generative Pre-trained Transformer"), que s√£o treinados para usar linguagem natural e c√≥digo.

Os utilizadores podem agora interagir com estes modelos usando paradigmas familiares como chat, sem necessidade de conhecimentos t√©cnicos ou forma√ß√£o. Os modelos s√£o _baseados em prompts_ - os utilizadores enviam uma entrada de texto (prompt) e recebem a resposta da IA (completamento). Podem ent√£o "conversar com a IA" iterativamente, em di√°logos com m√∫ltiplas intera√ß√µes, refinando o prompt at√© que a resposta v√° ao encontro das suas expectativas.

Os "prompts" passam a ser a principal _interface de programa√ß√£o_ para aplica√ß√µes de IA generativa, indicando aos modelos o que fazer e influenciando a qualidade das respostas retornadas. A "Engenharia de Prompts" √© um campo em r√°pido crescimento que se foca no _design e otimiza√ß√£o_ dos prompts para entregar respostas consistentes e de qualidade em escala.

## Objetivos de Aprendizagem

Nesta li√ß√£o, aprendemos o que √© Engenharia de Prompts, por que √© importante e como criar prompts mais eficazes para um dado modelo e objetivo de aplica√ß√£o. Vamos compreender conceitos b√°sicos e boas pr√°ticas de engenharia de prompts - e aprender sobre um ambiente interativo de Jupyter Notebooks "sandbox" onde podemos ver estes conceitos aplicados em exemplos reais.

No final desta li√ß√£o seremos capazes de:

1. Explicar o que √© engenharia de prompts e por que √© importante.
2. Descrever os componentes de um prompt e como s√£o usados.
3. Conhecer boas pr√°ticas e t√©cnicas para engenharia de prompts.
4. Aplicar t√©cnicas aprendidas em exemplos reais, usando um endpoint da OpenAI.

## Termos-chave

Engenharia de Prompts: A pr√°tica de desenhar e refinar entradas para guiar modelos de IA a produzir as sa√≠das desejadas.  
Tokeniza√ß√£o: O processo de converter texto em unidades menores, chamadas tokens, que um modelo pode entender e processar.  
LLMs Ajustados por Instru√ß√µes: Modelos de Linguagem de Grande Escala que foram ajustados com instru√ß√µes espec√≠ficas para melhorar a precis√£o e relev√¢ncia das suas respostas.

## Sandbox de Aprendizagem

A engenharia de prompts √© atualmente mais uma arte do que uma ci√™ncia. A melhor forma de melhorar a nossa intui√ß√£o √© _praticar mais_ e adotar uma abordagem de tentativa e erro que combina experi√™ncia no dom√≠nio da aplica√ß√£o com t√©cnicas recomendadas e otimiza√ß√µes espec√≠ficas do modelo.

O Jupyter Notebook que acompanha esta li√ß√£o fornece um ambiente _sandbox_ onde pode experimentar o que aprende ‚Äì √† medida que avan√ßa ou como parte do desafio de c√≥digo no final. Para executar os exerc√≠cios, vai precisar de:

1. **Uma chave da API Azure OpenAI** ‚Äì o endpoint do servi√ßo para um LLM implementado.  
2. **Um ambiente Python** ‚Äì onde o Notebook pode ser executado.  
3. **Vari√°veis de Ambiente Locais** ‚Äì _complete os passos do [CONFIGURA√á√ÉO](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) agora para estar pronto_.

O notebook vem com exerc√≠cios _inicializadores_ - mas √© incentivado a adicionar a sua pr√≥pria sec√ß√£o de _Markdown_ (descri√ß√£o) e de _C√≥digo_ (pedidos de prompts) para experimentar mais exemplos ou ideias - e desenvolver a sua intui√ß√£o para o design de prompts.

## Guia Ilustrado

Quer perceber o panorama geral do que esta li√ß√£o cobre antes de se aprofundar? Veja este guia ilustrado, que lhe d√° uma no√ß√£o dos t√≥picos principais abordados e dos pontos-chave para refletir em cada um. O roteiro da li√ß√£o leva-o a entender os conceitos e desafios principais at√© resolv√™-los com t√©cnicas relevantes de engenharia de prompts e boas pr√°ticas. Note que a se√ß√£o "T√©cnicas Avan√ßadas" neste guia refere-se ao conte√∫do do _pr√≥ximo_ cap√≠tulo deste curr√≠culo.

![Guia Ilustrado para Engenharia de Prompts](../../../translated_images/pt-PT/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## A Nossa Startup

Agora, vamos falar sobre como _este tema_ se relaciona com a miss√£o da nossa startup de [trazer inova√ß√£o em IA para a educa√ß√£o](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplica√ß√µes de IA focadas em _aprendizagem personalizada_ ‚Äì por isso vamos pensar como diferentes utilizadores da nossa aplica√ß√£o podem "desenhar" prompts:

- **Administradores** podem pedir √† IA para _analisar dados curriculares para identificar lacunas na cobertura_. A IA pode resumir resultados ou visualiz√°-los com c√≥digo.  
- **Educadores** podem pedir √† IA para _gerar um plano de aula para um p√∫blico-alvo e tema espec√≠ficos_. A IA pode construir o plano personalizado num formato especificado.  
- **Estudantes** podem pedir √† IA para _os ajudar numa disciplina dif√≠cil_. A IA pode agora guiar os estudantes com li√ß√µes, dicas e exemplos adaptados ao seu n√≠vel.

Isto √© s√≥ a ponta do iceberg. Veja [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì uma biblioteca open source de prompts selecionada por especialistas em educa√ß√£o ‚Äì para ter uma no√ß√£o mais ampla das possibilidades! _Experimente executar alguns desses prompts no sandbox ou usar o OpenAI Playground para ver o que acontece!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## O que √© Engenharia de Prompts?

Come√ß√°mos esta li√ß√£o definindo **Engenharia de Prompts** como o processo de _desenhar e otimizar_ entradas de texto (prompts) para entregar respostas consistentes e de qualidade (completamentos) para um dado objetivo de aplica√ß√£o e modelo. Podemos pensar nisto como um processo de 2 etapas:

- _desenhar_ o prompt inicial para um dado modelo e objetivo  
- _refinar_ o prompt iterativamente para melhorar a qualidade da resposta

Este √© necessariamente um processo de tentativa e erro que requer intui√ß√£o e esfor√ßo do utilizador para obter resultados √≥timos. Ent√£o, por que √© isto importante? Para responder a essa pergunta, precisamos primeiro entender tr√™s conceitos:

- _Tokeniza√ß√£o_ = como o modelo "v√™" o prompt  
- _LLMs Base_ = como o modelo base "processa" um prompt  
- _LLMs Ajustados por Instru√ß√µes_ = como o modelo consegue agora ver "tarefas"

### Tokeniza√ß√£o

Um LLM v√™ os prompts como uma _sequ√™ncia de tokens_ onde diferentes modelos (ou vers√µes de um modelo) podem tokenizar o mesmo prompt de formas diferentes. Como os LLMs s√£o treinados em tokens (e n√£o em texto cru), a forma como os prompts s√£o tokenizados tem impacto direto na qualidade da resposta gerada.

Para perceber como a tokeniza√ß√£o funciona, experimente ferramentas como o [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) mostrado abaixo. Copie o seu prompt ‚Äì e veja como ele √© convertido em tokens, prestando aten√ß√£o a como s√£o tratados os espa√ßos e os sinais de pontua√ß√£o. Note que este exemplo mostra um LLM mais antigo (GPT-3) - experimentar com um modelo mais recente pode produzir um resultado diferente.

![Tokeniza√ß√£o](../../../translated_images/pt-PT/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Conceito: Modelos Base

Depois de tokenizado, a fun√ß√£o principal do ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou modelo base) √© prever o token seguinte nessa sequ√™ncia. Como os LLMs s√£o treinados com datasets massivos de texto, t√™m uma boa no√ß√£o das rela√ß√µes estat√≠sticas entre tokens e conseguem fazer essa predi√ß√£o com alguma confian√ßa. Note que eles n√£o entendem o _significado_ das palavras no prompt ou token; apenas reconhecem um padr√£o que podem "completar" com a predi√ß√£o seguinte. Podem continuar a prever a sequ√™ncia at√© serem interrompidos por interven√ß√£o do utilizador ou alguma condi√ß√£o pr√©-estabelecida.

Quer ver como funciona o completamento por prompt? Insira o prompt acima no Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) com as defini√ß√µes padr√£o. O sistema est√° configurado para tratar prompts como pedidos de informa√ß√£o ‚Äì dever√° ver um completamento que satisfa√ßa este contexto.

Mas e se o utilizador quisesse algo espec√≠fico que correspondesse a algum crit√©rio ou objetivo de tarefa? √â aqui que os LLMs _ajustados por instru√ß√µes_ entram em cena.

![Completamento Chat LLM Base](../../../translated_images/pt-PT/04-playground-chat-base.65b76fcfde0caa67.webp)

### Conceito: LLMs Ajustados por Instru√ß√µes

Um [LLM Ajustado por Instru√ß√µes](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) parte do modelo base e √© afinado com exemplos ou pares de entrada/sa√≠da (ex., "mensagens" com m√∫ltiplas intera√ß√µes) que podem conter instru√ß√µes claras ‚Äì e a resposta da IA tenta seguir essa instru√ß√£o.

Isto usa t√©cnicas como Aprendizagem por Refor√ßo com Feedback Humano (RLHF) que podem treinar o modelo a _seguir instru√ß√µes_ e _aprender com feedback_ para produzir respostas mais adequadas a aplica√ß√µes pr√°ticas e mais relevantes para objetivos do utilizador.

Vamos experimentar ‚Äì volte ao prompt acima, mas agora mude a _mensagem do sistema_ para fornecer a seguinte instru√ß√£o como contexto:

> _Resuma o conte√∫do que lhe for fornecido para um aluno do segundo ano. Mantenha o resultado num par√°grafo com 3-5 pontos em formato de t√≥picos._

Veja como o resultado est√° agora afinado para refletir o objetivo e formato desejados? Um educador pode usar diretamente essa resposta nas suas apresenta√ß√µes para essa aula.

![Completamento Chat LLM Ajustado](../../../translated_images/pt-PT/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## Por que precisamos de Engenharia de Prompts?

Agora que sabemos como os prompts s√£o processados pelos LLMs, vamos falar sobre _porqu√™_ precisamos de engenharia de prompts. A resposta est√° no facto de que os LLMs atuais apresentam v√°rios desafios que tornam mais dif√≠cil obter _completamentos fi√°veis e consistentes_ sem esfor√ßo na constru√ß√£o e otimiza√ß√£o do prompt. Por exemplo:

1. **As respostas do modelo s√£o estoc√°sticas.** O _mesmo prompt_ provavelmente produzir√° respostas diferentes com modelos ou vers√µes de modelo diferentes. E pode mesmo produzir resultados diferentes com o _mesmo modelo_ em momentos distintos. _T√©cnicas de engenharia de prompts podem ajudar a minimizar estas varia√ß√µes fornecendo limites mais robustos_.

1. **Os modelos podem fabricar respostas.** Os modelos s√£o pr√©-treinados com conjuntos de dados _grandes mas finitos_, o que significa que lhes falta conhecimento sobre conceitos fora do √¢mbito desse treino. Como resultado, podem produzir completamentos que s√£o imprecisos, imagin√°rios ou diretamente contradit√≥rios com fatos conhecidos. _T√©cnicas de engenharia de prompts ajudam os utilizadores a identificar e mitigar essas fabrica√ß√µes, por exemplo, pedindo √† IA cita√ß√µes ou racioc√≠nios_.

1. **As capacidades dos modelos variam.** Modelos ou gera√ß√µes mais recentes ter√£o capacidades mais ricas, mas tamb√©m apresentam peculiaridades √∫nicas e trade-offs em custo e complexidade. _Engenharia de prompts pode ajudar a desenvolver boas pr√°ticas e fluxos de trabalho que abstragam diferen√ßas e adaptem-se a requisitos espec√≠ficos do modelo de forma escal√°vel e fluida_.

Vamos ver isto em a√ß√£o no OpenAI ou Azure OpenAI Playground:

- Use o mesmo prompt com diferentes implementa√ß√µes de LLM (ex., OpenAI, Azure OpenAI, Hugging Face) ‚Äì viu varia√ß√µes?  
- Use o mesmo prompt repetidamente com a _mesma_ implementa√ß√£o de LLM (ex., Azure OpenAI playground) ‚Äì como diferiram essas varia√ß√µes?

### Exemplo de Fabrica√ß√µes

Neste curso, usamos o termo **"fabrica√ß√£o"** para referir o fen√≥meno em que LLMs por vezes geram informa√ß√£o factualmente incorreta devido a limita√ß√µes no seu treino ou outras restri√ß√µes. Pode tamb√©m ter ouvido este fen√≥meno referido como _"alucina√ß√µes"_ em artigos populares ou papers de investiga√ß√£o. No entanto, recomendamos fortemente usar _"fabrica√ß√£o"_ para evitar antropomorfizar o comportamento ao atribuir tra√ßos humanos a um resultado gerado por m√°quina. Isto tamb√©m refor√ßa as [diretrizes de IA Respons√°vel](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) do ponto de vista terminol√≥gico, eliminando termos que podem ser considerados ofensivos ou n√£o inclusivos em alguns contextos.

Quer perceber como as fabrica√ß√µes funcionam? Pense num prompt que instrua a IA a gerar conte√∫do para um tema inexistente (para garantir que n√£o est√° no conjunto de treino). Por exemplo ‚Äì experimentei este prompt:

> **Prompt:** gerar um plano de aula sobre a Guerra Marciana de 2076.
Uma pesquisa na web mostrou-me que existiam relatos fict√≠cios (por exemplo, s√©ries de televis√£o ou livros) sobre guerras marcianas - mas nenhum em 2076. O senso comum tamb√©m nos diz que 2076 √© _no futuro_ e, portanto, n√£o pode ser associado a um evento real.

Ent√£o o que acontece quando executamos este prompt com diferentes fornecedores de LLM?

> **Resposta 1**: OpenAI Playground (GPT-35)

![Resposta 1](../../../translated_images/pt-PT/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Resposta 2**: Azure OpenAI Playground (GPT-35)

![Resposta 2](../../../translated_images/pt-PT/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Resposta 3**: : Hugging Face Chat Playground (LLama-2)

![Resposta 3](../../../translated_images/pt-PT/04-fabrication-huggingchat.faf82a0a51278956.webp)

Como esperado, cada modelo (ou vers√£o do modelo) produz respostas ligeiramente diferentes gra√ßas ao comportamento estoc√°stico e √†s varia√ß√µes na capacidade do modelo. Por exemplo, um modelo dirige-se a um p√∫blico de 8¬∫ ano enquanto o outro assume um estudante do ensino secund√°rio. Mas os tr√™s modelos geraram respostas que poderiam convencer um utilizador desinformado de que o evento era real.

T√©cnicas de engenharia de prompts como _metaprompting_ e _configura√ß√£o de temperatura_ podem reduzir as fabrica√ß√µes dos modelos at√© certo ponto. Novas _arquiteturas_ de engenharia de prompts tamb√©m incorporam novas ferramentas e t√©cnicas de forma fluida no fluxo do prompt, para mitigar ou reduzir alguns destes efeitos.

## Estudo de Caso: GitHub Copilot

Vamos concluir esta sec√ß√£o tendo uma no√ß√£o de como a engenharia de prompts √© usada em solu√ß√µes do mundo real, olhando para um Estudo de Caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

O GitHub Copilot √© o seu "Programador Assistente de IA" - converte prompts de texto em sugest√µes de c√≥digo e est√° integrado no seu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experi√™ncia de utilizador fluida. Conforme documentado na s√©rie de blogs abaixo, a vers√£o inicial foi baseada no modelo OpenAI Codex - com os engenheiros rapidamente a perceberem a necessidade de ajustar finamente o modelo e desenvolver melhores t√©cnicas de engenharia de prompts para melhorar a qualidade do c√≥digo. Em julho, eles [estrearam um modelo de IA melhorado que vai al√©m do Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugest√µes ainda mais r√°pidas.

Leia os posts por ordem, para seguir a sua jornada de aprendizagem.

- **Maio 2023** | [GitHub Copilot est√° a melhorar na compreens√£o do seu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maio 2023** | [Por dentro do GitHub: Trabalhar com os LLMs por tr√°s do GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Junho 2023** | [Como escrever melhores prompts para o GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Julho 2023** | [.. GitHub Copilot vai al√©m do Codex com modelo de IA melhorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Julho 2023** | [Guia do Programador para Engenharia de Prompts e LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Setembro 2023** | [Como construir uma aplica√ß√£o empresarial com LLM: Li√ß√µes do GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Pode tamb√©m navegar no seu [blog de Engenharia](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para mais posts como [este](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que mostram como estes modelos e t√©cnicas s√£o _aplicados_ no desenvolvimento de aplica√ß√µes reais.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Constru√ß√£o do Prompt

J√° vimos por que a engenharia de prompts √© importante - agora vamos perceber como os prompts s√£o _constru√≠dos_ para podermos avaliar diferentes t√©cnicas para uma cria√ß√£o de prompts mais eficaz.

### Prompt B√°sico

Vamos come√ßar com o prompt b√°sico: uma entrada de texto enviada ao modelo sem outro contexto. Aqui est√° um exemplo - quando enviamos as primeiras palavras do hino nacional dos EUA √† OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) ela instantaneamente _completa_ a resposta com as linhas seguintes, ilustrando o comportamento b√°sico de previs√£o.

| Prompt (Entrada)      | Complemento (Sa√≠da)                                                                                                                     |
| :------------------- | :------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see    | Parece que est√° a come√ßar a letra de "The Star-Spangled Banner", o hino nacional dos Estados Unidos. A letra completa √© ...            |

### Prompt Complexo

Agora vamos adicionar contexto e instru√ß√µes a esse prompt b√°sico. A [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) permite-nos construir um prompt complexo como uma cole√ß√£o de _mensagens_ com:

- Pares de entrada/sa√≠da que refletem a entrada do _utilizador_ e a resposta do _assistente_.
- Mensagem do sistema definindo o contexto para o comportamento ou personalidade do assistente.

O pedido est√° agora na forma abaixo, onde a _tokeniza√ß√£o_ captura eficazmente a informa√ß√£o relevante do contexto e da conversa. Agora, mudar o contexto do sistema pode ser t√£o impactante na qualidade das conclus√µes quanto as entradas do utilizador fornecidas.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Prompt de Instru√ß√£o

Nos exemplos acima, o prompt do utilizador era uma consulta simples que pode ser interpretada como um pedido de informa√ß√£o. Com prompts de _instru√ß√£o_, podemos usar esse texto para especificar uma tarefa em mais detalhe, fornecendo uma melhor orienta√ß√£o √† IA. Aqui est√° um exemplo:

| Prompt (Entrada)                                                                                                                                                                                                                         | Complemento (Sa√≠da)                                                                                                        | Tipo de Instru√ß√£o   |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Escreva uma descri√ß√£o da Guerra Civil                                                                                                                                                                                                  | _deu uma simples frase_                                                                                                    | Simples             |
| Escreva uma descri√ß√£o da Guerra Civil. Forne√ßa datas e eventos importantes e descreva a sua import√¢ncia                                                                                                                                | _deu uma frase seguida de uma lista de datas de eventos chave com descri√ß√µes_                                              | Complexa            |
| Escreva uma descri√ß√£o da Guerra Civil em 1 par√°grafo. Forne√ßa 3 pontos com datas importantes e a sua import√¢ncia. Forne√ßa mais 3 pontos com figuras hist√≥ricas chave e as suas contribui√ß√µes. Retorne a sa√≠da em formato JSON                      | _retorna detalhes mais extensos numa caixa de texto, formatados como JSON que pode copiar e colar num ficheiro e validar_   | Complexa. Formatada.|

## Conte√∫do Principal

Nos exemplos acima, o prompt ainda era bastante aberto, permitindo que o LLM decidisse que parte do seu conjunto de dados pr√©-treinado era relevante. Com o padr√£o de design _conte√∫do principal_, o texto de entrada √© dividido em duas partes:

- uma instru√ß√£o (a√ß√£o)
- conte√∫do relevante (que influencia a a√ß√£o)

Aqui est√° um exemplo onde a instru√ß√£o √© "resuma isto em 2 frases".

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Complemento (Sa√≠da)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa mil vezes inferior √† do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno e √© conhecido por civiliza√ß√µes antigas desde antes da hist√≥ria registada. √â nomeado em homenagem ao deus romano J√∫piter.[19] Quando visto da Terra, J√∫piter pode ser suficientemente brilhante para a luz refletida para criar sombras vis√≠veis,[20] e √© em m√©dia o terceiro objeto natural mais brilhante no c√©u noturno depois da Lua e V√©nus. <br/> **Resuma isto em 2 frases curtas** | J√∫piter, o quinto planeta a partir do Sol, √© o maior do Sistema Solar e conhecido por ser um dos objetos mais brilhantes no c√©u noturno. Nomeado em honra do deus romano J√∫piter, √© um gigante gasoso cuja massa √© duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. |

O segmento de conte√∫do principal pode ser usado de v√°rias formas para conduzir instru√ß√µes mais eficazes:

- **Exemplos** - em vez de dizer ao modelo o que fazer com uma instru√ß√£o expl√≠cita, d√™-lhe exemplos do que fazer e deixe-o inferir o padr√£o.
- **Pistas** - siga a instru√ß√£o com uma "pista" que prepare a conclus√£o, guiando o modelo para respostas mais relevantes.
- **Modelos** - s√£o 'receitas' repet√≠veis para prompts com espa√ßos reservados (vari√°veis) que podem ser personalizados com dados para casos de uso espec√≠ficos.

Vamos explorar estes em a√ß√£o.

### Usar Exemplos

Esta √© uma abordagem onde se usa o conte√∫do principal para "alimentar o modelo" com exemplos do resultado desejado para uma dada instru√ß√£o, e deix√°-lo inferir o padr√£o do resultado pretendido. Com base no n√∫mero de exemplos fornecidos, podemos ter prompting zero-shot, one-shot, few-shot, etc.

O prompt consiste agora em tr√™s componentes:

- A descri√ß√£o da tarefa
- Alguns exemplos do resultado desejado
- O in√≠cio de um novo exemplo (que passa a ser uma descri√ß√£o impl√≠cita da tarefa)

| Tipo de Aprendizagem | Prompt (Entrada)                                                                                                                                     | Complemento (Sa√≠da)          |
| :------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------- |
| Zero-shot            | "The Sun is Shining". Traduza para espanhol                                                                                                         | "El Sol est√° brillando".     |
| One-shot             | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso".  |
| Few-shot             | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk =>  | Basquetebol                 |
|                      |                                                                                                                                                      |                             |

Note como tivemos de dar uma instru√ß√£o expl√≠cita ("Traduza para espanhol") no zero-shot prompting, mas esta √© inferida no exemplo de one-shot prompting. O exemplo few-shot mostra como adicionar mais exemplos permite aos modelos fazer infer√™ncias mais precisas sem instru√ß√µes adicionais.

### Pistas no Prompt

Outra t√©cnica para usar conte√∫do principal √© fornecer _pistas_ em vez de exemplos. Neste caso, estamos a dar ao modelo uma indica√ß√£o na dire√ß√£o certa ao _come√ß√°-lo_ com um excerto que reflete o formato desejado da resposta. O modelo ent√£o "aproveita a pista" para continuar nesse sentido.

| N√∫mero de Pistas | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Complemento (Sa√≠da)                                                                                                                                                                                                                                                                                       |
| :--------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa mil vezes inferior √† do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno e √© conhecido por civiliza√ß√µes antigas desde antes da hist√≥ria registada. <br/>**Resuma Isto**                                       | J√∫piter √© o maior planeta do nosso Sistema Solar e o quinto a partir do Sol. √â um gigante gasoso com uma massa 1/1000 da do Sol, mas √© mais pesado do que todos os outros planetas juntos. Civiliza√ß√µes antigas conhecem J√∫piter h√° muito tempo, e √© facilmente vis√≠vel no c√©u noturno. |
| 1              | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa que √© um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e tem sido conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registada. <br/>**Resuma Isto** <br/> O que aprendemos √© que J√∫piter | √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa que √© um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas juntos. √â facilmente vis√≠vel a olho nu e tem sido conhecido desde tempos antigos.                        |
| 2              | J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. √â um gigante gasoso com uma massa que √© um mil√©simo da do Sol, mas duas vezes e meia a de todos os outros planetas do Sistema Solar juntos. J√∫piter √© um dos objetos mais brilhantes vis√≠veis a olho nu no c√©u noturno, e tem sido conhecido pelas civiliza√ß√µes antigas desde antes da hist√≥ria registada. <br/>**Resuma Isto** <br/> Top 3 Factos Que Aprendemos:         | 1. J√∫piter √© o quinto planeta a partir do Sol e o maior do Sistema Solar. <br/> 2. √â um gigante gasoso com uma massa que √© um mil√©simo da do Sol...<br/> 3. J√∫piter tem sido vis√≠vel a olho nu desde tempos antigos ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Prompt Templates

Um modelo de prompt √© uma _receita pr√©-definida para um prompt_ que pode ser armazenada e reutilizada conforme necess√°rio, para promover experi√™ncias de utilizador mais consistentes em grande escala. Na sua forma mais simples, √© simplesmente uma cole√ß√£o de exemplos de prompt como [este da OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que fornece tanto os componentes interativos do prompt (mensagens de utilizador e sistema) como o formato de pedido orientado por API - para suporte √† reutiliza√ß√£o.

Na sua forma mais complexa, como [este exemplo da LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), cont√©m _marcadores_ que podem ser substitu√≠dos por dados provenientes de v√°rias fontes (input do utilizador, contexto do sistema, fontes de dados externas, etc.) para gerar um prompt dinamicamente. Isto permite criar uma biblioteca de prompts reutiliz√°veis que podem ser usados para proporcionar experi√™ncias de utilizador consistentes **programaticamente** em grande escala.

Finalmente, o verdadeiro valor dos modelos est√° na capacidade de criar e publicar _bibliotecas de prompts_ para dom√≠nios de aplica√ß√£o verticais - onde o modelo de prompt √© agora _otimizado_ para refletir o contexto ou exemplos espec√≠ficos da aplica√ß√£o que tornam as respostas mais relevantes e precisas para o p√∫blico-alvo. O reposit√≥rio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √© um excelente exemplo desta abordagem, compilando uma biblioteca de prompts para o dom√≠nio da educa√ß√£o com √™nfase em objetivos-chave como planeamento de aulas, design curricular, tutoria de alunos, etc.

## Supporting Content

Se pensarmos na constru√ß√£o de prompts como tendo uma instru√ß√£o (tarefa) e um alvo (conte√∫do prim√°rio), ent√£o _conte√∫do secund√°rio_ √© como contexto adicional que fornecemos para **influenciar a sa√≠da de alguma forma**. Podem ser par√¢metros de ajuste, instru√ß√µes de formata√ß√£o, taxonomias de t√≥picos, etc. que ajudam o modelo a _adaptar_ a sua resposta para melhor servir os objetivos ou expectativas do utilizador.

Por exemplo: Dado um cat√°logo de cursos com metadados extensos (nome, descri√ß√£o, n√≠vel, etiquetas de metadados, instrutor, etc.) sobre todos os cursos dispon√≠veis no curr√≠culo:

- podemos definir uma instru√ß√£o para "resumir o cat√°logo de cursos para o Outono 2023"
- podemos usar o conte√∫do prim√°rio para fornecer alguns exemplos da sa√≠da desejada
- podemos usar o conte√∫do secund√°rio para identificar as 5 principais "etiquetas" de interesse.

Agora, o modelo pode fornecer um resumo no formato mostrado pelos poucos exemplos - mas se um resultado tiver m√∫ltiplas etiquetas, pode priorizar as 5 etiquetas identificadas no conte√∫do secund√°rio.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #3:
Prompt Engineering Techniques.
What are some basic techniques for prompt engineering?
Illustrate it with some exercises.
-->

## Prompting Best Practices

Agora que sabemos como os prompts podem ser _constru√≠dos_, podemos come√ßar a pensar em como _projet√°-los_ para refletir as melhores pr√°ticas. Podemos pensar nisso em duas partes - ter a _mentalidade_ certa e aplicar as _t√©cnicas_ corretas.

### Prompt Engineering Mindset

A engenharia de prompts √© um processo de tentativa e erro, por isso tenha em mente tr√™s fatores orientadores amplos:

1. **Compreens√£o do Dom√≠nio √© Importante.** A precis√£o e relev√¢ncia da resposta dependem do _dom√≠nio_ em que a aplica√ß√£o ou utilizador opera. Aplique a sua intui√ß√£o e especializa√ß√£o de dom√≠nio para **customizar as t√©cnicas** ainda mais. Por exemplo, defina _personalidades espec√≠ficas do dom√≠nio_ nos seus prompts de sistema, ou use _modelos espec√≠ficos do dom√≠nio_ nos prompts de utilizador. Forne√ßa conte√∫do secund√°rio que reflita contextos espec√≠ficos do dom√≠nio, ou use _ind√≠cios e exemplos espec√≠ficos do dom√≠nio_ para guiar o modelo para padr√µes de uso familiares.

2. **Compreens√£o do Modelo √© Importante.** Sabemos que os modelos s√£o estoc√°sticos por natureza. Mas as implementa√ß√µes do modelo podem tamb√©m variar em termos do conjunto de treino usado (conhecimento pr√©-treinado), das capacidades que fornecem (ex., via API ou SDK) e do tipo de conte√∫do para o qual est√£o otimizados (ex., c√≥digo vs. imagens vs. texto). Compreenda os pontos fortes e limita√ß√µes do modelo que est√° a usar e use esse conhecimento para _priorizar tarefas_ ou construir _modelos personalizados_ otimizados para as capacidades do modelo.

3. **Itera√ß√£o & Valida√ß√£o √© Importante.** Os modelos est√£o a evoluir rapidamente, assim como as t√©cnicas para engenharia de prompts. Como especialista no dom√≠nio, pode ter outros contextos ou crit√©rios para _a sua_ aplica√ß√£o espec√≠fica, que podem n√£o se aplicar √† comunidade em geral. Use ferramentas e t√©cnicas de engenharia de prompts para ‚Äúdar um ponto de partida‚Äù √† constru√ß√£o do prompt, depois itere e valide os resultados usando a sua pr√≥pria intui√ß√£o e experi√™ncia no dom√≠nio. Registe as suas perce√ß√µes e crie uma **base de conhecimento** (ex., bibliotecas de prompts) que possam ser usadas como uma nova refer√™ncia por outros, para itera√ß√µes mais r√°pidas no futuro.

## Best Practices

Agora vejamos as pr√°ticas recomendadas comuns recomendadas por praticantes da [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) e [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| O que                              | Porqu√™                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Avaliar os modelos mais recentes.       | Novas gera√ß√µes de modelos provavelmente t√™m funcionalidades e qualidade melhoradas - mas podem tamb√©m ter custos mais elevados. Avalie-os para impacto e depois tome decis√µes de migra√ß√£o.                                                                                |
| Separar instru√ß√µes e contexto   | Verifique se o seu modelo/fornecedor define _delimitadores_ para distinguir claramente instru√ß√µes, conte√∫do prim√°rio e conte√∫do secund√°rio. Isto pode ajudar os modelos a atribuir pesos aos tokens com mais precis√£o.                                                         |
| Seja espec√≠fico e claro             | D√™ mais detalhes sobre o contexto desejado, resultado, comprimento, formato, estilo, etc. Isto melhorar√° tanto a qualidade como a consist√™ncia das respostas. Capture receitas em modelos reutiliz√°veis.                                                          |
| Seja descritivo, use exemplos      | Os modelos podem responder melhor a uma abordagem de "mostrar e contar". Comece com uma abordagem `zero-shot` onde d√° uma instru√ß√£o (mas sem exemplos) e depois experimente `few-shot` como refinamento, proporcionando alguns exemplos da sa√≠da desejada. Use analogias. |
| Use ind√≠cios para iniciar conclus√µes | Impulsione o modelo rumo a um resultado desejado dando-lhe algumas palavras ou frases iniciais que ele possa usar como ponto de partida para a resposta.                                                                                                               |
| Reforce                        | √Äs vezes pode precisar de repetir-se para o modelo. D√™ instru√ß√µes antes e depois do conte√∫do prim√°rio, use uma instru√ß√£o e um ind√≠cio, etc. Itere e valide para ver o que funciona.                                                         |
| A ordem importa                     | A ordem em que apresenta a informa√ß√£o ao modelo pode impactar a sa√≠da, mesmo nos exemplos de aprendizagem, devido ao vi√©s de rec√™ncia. Experimente op√ß√µes diferentes para descobrir qual funciona melhor.                                                               |
| D√™ uma ‚Äúsa√≠da‚Äù ao modelo           | D√™ ao modelo uma resposta _de reserva_ que ele possa fornecer se n√£o conseguir completar a tarefa por qualquer motivo. Isto pode reduzir as hip√≥teses de o modelo gerar respostas falsas ou fabricadas.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Como com qualquer boa pr√°tica, lembre-se que _os seus resultados podem variar_ consoante o modelo, a tarefa e o dom√≠nio. Use estas pr√°ticas como ponto de partida, e itere para encontrar o que funciona melhor para si. Reavalie constantemente o seu processo de engenharia de prompts conforme surjam novos modelos e ferramentas, com foco na escalabilidade do processo e qualidade da resposta.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Assignment

Parab√©ns! Chegou ao fim da li√ß√£o! √â altura de p√¥r alguns desses conceitos e t√©cnicas √† prova com exemplos reais!

Para o nosso trabalho pr√°tico, vamos usar um Jupyter Notebook com exerc√≠cios que pode completar interativamente. Tamb√©m pode estender o Notebook com as suas pr√≥prias c√©lulas de Markdown e C√≥digo para explorar ideias e t√©cnicas ao seu ritmo.

### Para come√ßar, fa√ßa um fork do reposit√≥rio e depois

- (Recomendado) Inicie GitHub Codespaces
- (Alternativamente) Clone o reposit√≥rio para o seu dispositivo local e use-o com o Docker Desktop
- (Alternativamente) Abra o Notebook no seu ambiente preferido de execu√ß√£o de Notebooks.

### De seguida, configure as suas vari√°veis de ambiente

- Copie o ficheiro `.env.copy` na root do reposit√≥rio para `.env` e preencha os valores `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` e `AZURE_OPENAI_DEPLOYMENT`. Volte √† [sec√ß√£o Learning Sandbox](../../../04-prompt-engineering-fundamentals) para saber como.

### Depois, abra o Jupyter Notebook

- Selecione o kernel de execu√ß√£o. Se usar as op√ß√µes 1 ou 2, basta selecionar o kernel Python 3.10.x predefinido fornecido pelo contentor de desenvolvimento.

Est√° tudo pronto para executar os exerc√≠cios. Note que n√£o h√° respostas ‚Äúcertas‚Äù ou ‚Äúerradas‚Äù aqui - apenas explorar op√ß√µes por tentativa e erro e desenvolver intui√ß√£o sobre o que funciona para um dado modelo e dom√≠nio de aplica√ß√£o.

_Por esta raz√£o n√£o h√° segmentos de solu√ß√£o de c√≥digo nesta li√ß√£o. Em vez disso, o Notebook ter√° c√©lulas Markdown intituladas "A Minha Solu√ß√£o:" que mostram um exemplo de sa√≠da para refer√™ncia._

 <!--
LESSON TEMPLATE:
Wrap the section with a summary and resources for self-guided learning.
-->

## Knowledge check

Qual das seguintes √© uma boa prompt seguindo algumas pr√°ticas recomendadas razo√°veis?

1. Mostra-me uma imagem de um carro vermelho
2. Mostra-me uma imagem de um carro vermelho da marca Volvo e modelo XC90 estacionado junto a um penhasco com o sol a p√¥r-se
3. Mostra-me uma imagem de um carro vermelho da marca Volvo e modelo XC90

Resposta: 2, √© o melhor prompt pois fornece detalhes sobre o "qu√™" e especifica (n√£o √© qualquer carro, mas uma marca e modelo espec√≠ficos) e tamb√©m descreve o cen√°rio geral. O 3 √© o segundo melhor pois tamb√©m cont√©m muita descri√ß√£o.

## üöÄ Challenge

Veja se consegue usar a t√©cnica do ‚Äúind√≠cio‚Äù com o prompt: Complete a frase "Mostra-me uma imagem de um carro vermelho da marca Volvo e ". O que responde, e como melhoraria isso?

## Great Work! Continue Your Learning

Quer saber mais sobre diferentes conceitos de Engenharia de Prompts? V√° para a [p√°gina de aprendizagem cont√≠nua](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar outros excelentes recursos sobre este tema.

Dirija-se √† Li√ß√£o 5 onde vamos examinar [t√©cnicas avan√ßadas de prompting](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Aviso Legal**:  
Este documento foi traduzido utilizando o servi√ßo de tradu√ß√£o por IA [Co-op Translator](https://github.com/Azure/co-op-translator). Embora nos esforcemos pela precis√£o, tenha em conta que tradu√ß√µes autom√°ticas podem conter erros ou imprecis√µes. O documento original na sua l√≠ngua nativa deve ser considerado a fonte autoritativa. Para informa√ß√µes cr√≠ticas, recomenda-se tradu√ß√£o profissional realizada por um humano. N√£o nos responsabilizamos por quaisquer mal-entendidos ou interpreta√ß√µes incorretas decorrentes do uso desta tradu√ß√£o.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->