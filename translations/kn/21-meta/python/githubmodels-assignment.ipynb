{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ಮೆಟಾ ಕುಟುಂಬ ಮಾದರಿಗಳೊಂದಿಗೆ ನಿರ್ಮಾಣ\n",
    "\n",
    "## ಪರಿಚಯ\n",
    "\n",
    "ಈ ಪಾಠದಲ್ಲಿ ಒಳಗೊಂಡಿರುವುದು:\n",
    "\n",
    "- ಎರಡು ಪ್ರಮುಖ ಮೆಟಾ ಕುಟುಂಬ ಮಾದರಿಗಳನ್ನು ಅನ್ವೇಷಿಸುವುದು - ಲ್ಲಾಮಾ 3.1 ಮತ್ತು ಲ್ಲಾಮಾ 3.2\n",
    "- ಪ್ರತಿ ಮಾದರಿಯ ಬಳಕೆ ಪ್ರಕರಣಗಳು ಮತ್ತು ಸಂದರ್ಭಗಳನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವುದು\n",
    "- ಪ್ರತಿ ಮಾದರಿಯ ವಿಶಿಷ್ಟ ವೈಶಿಷ್ಟ್ಯಗಳನ್ನು ತೋರಿಸುವ ಕೋಡ್ ಉದಾಹರಣೆ\n",
    "\n",
    "## ಮೆಟಾ ಕುಟುಂಬದ ಮಾದರಿಗಳು\n",
    "\n",
    "ಈ ಪಾಠದಲ್ಲಿ, ನಾವು ಮೆಟಾ ಕುಟುಂಬ ಅಥವಾ \"ಲ್ಲಾಮಾ ಹರ್ಡ್\" ನಿಂದ 2 ಮಾದರಿಗಳನ್ನು ಅನ್ವೇಷಿಸುವೆವು - ಲ್ಲಾಮಾ 3.1 ಮತ್ತು ಲ್ಲಾಮಾ 3.2\n",
    "\n",
    "ಈ ಮಾದರಿಗಳು ವಿಭಿನ್ನ ರೂಪಾಂತರಗಳಲ್ಲಿ ಲಭ್ಯವಿದ್ದು, ಗಿಥಬ್ ಮಾದರಿ ಮಾರುಕಟ್ಟೆಯಲ್ಲಿ ಲಭ್ಯವಿವೆ. ಗಿಥಬ್ ಮಾದರಿಗಳನ್ನು ಬಳಸಿಕೊಂಡು [AI ಮಾದರಿಗಳೊಂದಿಗೆ ಪ್ರೋಟೋಟೈಪ್ ಮಾಡಲು](https://docs.github.com/en/github-models/prototyping-with-ai-models?WT.mc_id=academic-105485-koreyst) ಹೆಚ್ಚಿನ ವಿವರಗಳು ಇಲ್ಲಿವೆ.\n",
    "\n",
    "ಮಾದರಿ ರೂಪಾಂತರಗಳು:\n",
    "- ಲ್ಲಾಮಾ 3.1 - 70B ಸೂಚನೆ\n",
    "- ಲ್ಲಾಮಾ 3.1 - 405B ಸೂಚನೆ\n",
    "- ಲ್ಲಾಮಾ 3.2 - 11B ದೃಷ್ಟಿ ಸೂಚನೆ\n",
    "- ಲ್ಲಾಮಾ 3.2 - 90B ದೃಷ್ಟಿ ಸೂಚನೆ\n",
    "\n",
    "*ಗಮನಿಸಿ: ಲ್ಲಾಮಾ 3 ಕೂಡ ಗಿಥಬ್ ಮಾದರಿಗಳಲ್ಲಿ ಲಭ್ಯವಿದೆ ಆದರೆ ಈ ಪಾಠದಲ್ಲಿ ಒಳಗೊಂಡಿಲ್ಲ*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Llama 3.1\n",
    "\n",
    "405 ಬಿಲಿಯನ್ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳೊಂದಿಗೆ, Llama 3.1 ತೆರೆಯಲಾದ ಮೂಲ LLM ವರ್ಗಕ್ಕೆ ಸೇರಿದೆ.\n",
    "\n",
    "ಈ ಮಾದರಿ ಹಿಂದಿನ ಬಿಡುಗಡೆ Llama 3 ಗೆ ಹೋಲಿಸಿದರೆ ಅಪ್‌ಗ್ರೇಡ್ ಆಗಿದ್ದು:\n",
    "\n",
    "- ದೊಡ್ಡ ಕಾನ್ಟೆಕ್ಸ್ಟ್ ವಿಂಡೋ - 128k ಟೋಕನ್ಸ್ ವಿರುದ್ಧ 8k ಟೋಕನ್ಸ್\n",
    "- ದೊಡ್ಡ ಗರಿಷ್ಠ ಔಟ್‌ಪುಟ್ ಟೋಕನ್ಸ್ - 4096 ವಿರುದ್ಧ 2048\n",
    "- ಉತ್ತಮ ಬಹುಭಾಷಾ ಬೆಂಬಲ - ತರಬೇತಿ ಟೋಕನ್ಸ್ ಹೆಚ್ಚಳದಿಂದ\n",
    "\n",
    "ಇವು Llama 3.1 ಗೆ GenAI ಅಪ್ಲಿಕೇಶನ್‌ಗಳನ್ನು ನಿರ್ಮಿಸುವಾಗ ಹೆಚ್ಚು ಸಂಕೀರ್ಣ ಬಳಕೆ ಪ್ರಕರಣಗಳನ್ನು ನಿರ್ವಹಿಸಲು ಸಹಾಯ ಮಾಡುತ್ತವೆ, ಉದಾಹರಣೆಗೆ:\n",
    "- ನೇಟಿವ್ ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್ - LLM ವರ್ಕ್‌ಫ್ಲೋ ಹೊರಗಿನ ಬಾಹ್ಯ ಸಾಧನಗಳು ಮತ್ತು ಫಂಕ್ಷನ್‌ಗಳನ್ನು ಕರೆಸುವ ಸಾಮರ್ಥ್ಯ\n",
    "- ಉತ್ತಮ RAG ಕಾರ್ಯಕ್ಷಮತೆ - ಹೆಚ್ಚಿನ ಕಾನ್ಟೆಕ್ಸ್ಟ್ ವಿಂಡೋ ಕಾರಣದಿಂದ\n",
    "- ಸಿಂಥೆಟಿಕ್ ಡೇಟಾ ಜನರೇಶನ್ - ಸೂಕ್ಷ್ಮ-ಟ್ಯೂನಿಂಗ್ ಮುಂತಾದ ಕಾರ್ಯಗಳಿಗೆ ಪರಿಣಾಮಕಾರಿ ಡೇಟಾವನ್ನು ರಚಿಸುವ ಸಾಮರ್ಥ್ಯ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಸ್ಥಳೀಯ ಫಂಕ್ಷನ್ ಕರೆಮಾಡುವುದು\n",
    "\n",
    "Llama 3.1 ಅನ್ನು ಫಂಕ್ಷನ್ ಅಥವಾ ಟೂಲ್ ಕರೆಗಳನ್ನು ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಮಾಡಲು ಸೂಕ್ಷ್ಮಗೊಳಿಸಲಾಗಿದೆ. ಇದರಲ್ಲಿ ಎರಡು ಒಳಗೊಂಡಿರುವ ಟೂಲ್‌ಗಳಿವೆ, ಅವುಗಳನ್ನು ಬಳಕೆದಾರನ ಪ್ರಾಂಪ್ಟ್ ಆಧಾರವಾಗಿ ಬಳಸಬೇಕಾಗಿರುವುದಾಗಿ ಮಾದರಿ ಗುರುತಿಸಬಹುದು. ಈ ಟೂಲ್‌ಗಳು:\n",
    "\n",
    "- **Brave Search** - ವೆಬ್ ಶೋಧನೆಯನ್ನು ನಡೆಸಿ ಹವಾಮಾನದಂತಹ ನವೀಕೃತ ಮಾಹಿತಿಯನ್ನು ಪಡೆಯಲು ಬಳಸಬಹುದು\n",
    "- **Wolfram Alpha** - ಹೆಚ್ಚು ಸಂಕೀರ್ಣ ಗಣಿತೀಯ ಲೆಕ್ಕಾಚಾರಗಳಿಗೆ ಬಳಸಬಹುದು, ಆದ್ದರಿಂದ ನಿಮ್ಮದೇ ಫಂಕ್ಷನ್‌ಗಳನ್ನು ಬರೆಯಬೇಕಾಗಿಲ್ಲ.\n",
    "\n",
    "ನೀವು ನಿಮ್ಮದೇ ಕಸ್ಟಮ್ ಟೂಲ್‌ಗಳನ್ನು ಕೂಡ ರಚಿಸಬಹುದು, ಅವುಗಳನ್ನು LLM ಕರೆಮಾಡಬಹುದು.\n",
    "\n",
    "ಕೆಳಗಿನ ಕೋಡ್ ಉದಾಹರಣೆಯಲ್ಲಿ:\n",
    "\n",
    "- ನಾವು ಸಿಸ್ಟಮ್ ಪ್ರಾಂಪ್ಟ್‌ನಲ್ಲಿ ಲಭ್ಯವಿರುವ ಟೂಲ್‌ಗಳನ್ನು (brave_search, wolfram_alpha) ವ್ಯಾಖ್ಯಾನಿಸುತ್ತೇವೆ.\n",
    "- ನಿರ್ದಿಷ್ಟ ನಗರದಲ್ಲಿ ಹವಾಮಾನ ಕುರಿತು ಕೇಳುವ ಬಳಕೆದಾರ ಪ್ರಾಂಪ್ಟ್ ಅನ್ನು ಕಳುಹಿಸುತ್ತೇವೆ.\n",
    "- LLM Brave Search ಟೂಲ್‌ಗೆ `<|python_tag|>brave_search.call(query=\"Stockholm weather\")` ಎಂಬ ಟೂಲ್ ಕರೆ ಮೂಲಕ ಪ್ರತಿಕ್ರಿಯಿಸುತ್ತದೆ.\n",
    "\n",
    "*ಗಮನಿಸಿ: ಈ ಉದಾಹರಣೆ ಕೇವಲ ಟೂಲ್ ಕರೆಮಾಡುತ್ತದೆ, ಫಲಿತಾಂಶಗಳನ್ನು ಪಡೆಯಲು ನೀವು Brave API ಪುಟದಲ್ಲಿ ಉಚಿತ ಖಾತೆಯನ್ನು ರಚಿಸಿ ಫಂಕ್ಷನ್ ಅನ್ನು ವ್ಯಾಖ್ಯಾನಿಸಬೇಕಾಗುತ್ತದೆ.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import AssistantMessage, SystemMessage, UserMessage\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"meta-llama-3.1-405b-instruct\"\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "\n",
    "tool_prompt=f\"\"\"\n",
    "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "Environment: ipython\n",
    "Tools: brave_search, wolfram_alpha\n",
    "Cutting Knowledge Date: December 2023\n",
    "Today Date: 23 July 2024\n",
    "\n",
    "You are a helpful assistant<|eot_id|>\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=tool_prompt),\n",
    "    UserMessage(content=\"What is the weather in Stockholm?\"),\n",
    "\n",
    "]\n",
    "\n",
    "response = client.complete(messages=messages, model=model_name)\n",
    "\n",
    "print(response.choices[0].message.content)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಲ್ಲಾಮಾ 3.2\n",
    "\n",
    "ಒಂದು LLM ಆಗಿದ್ದರೂ, ಲ್ಲಾಮಾ 3.1 ಗೆ ಇರುವ ಒಂದು ಮಿತಿ ಎಂದರೆ ಬಹುಮಾಧ್ಯಮತೆ. ಅಂದರೆ, ಚಿತ್ರಗಳನ್ನು ಪ್ರಾಂಪ್ಟ್‌ಗಳಾಗಿ ಬಳಸಿಕೊಂಡು ಪ್ರತಿಕ್ರಿಯೆಗಳನ್ನು ನೀಡುವಂತಹ ವಿಭಿನ್ನ ರೀತಿಯ ಇನ್‌ಪುಟ್‌ಗಳನ್ನು ಬಳಸಿಕೊಳ್ಳುವ ಸಾಮರ್ಥ್ಯ. ಈ ಸಾಮರ್ಥ್ಯವು ಲ್ಲಾಮಾ 3.2 ರ ಪ್ರಮುಖ ವೈಶಿಷ್ಟ್ಯಗಳಲ್ಲಿ ಒಂದಾಗಿದೆ. ಈ ವೈಶಿಷ್ಟ್ಯಗಳಲ್ಲಿ ಇವುಗಳೂ ಸೇರಿವೆ:\n",
    "\n",
    "- ಬಹುಮಾಧ್ಯಮತೆ - ಪಠ್ಯ ಮತ್ತು ಚಿತ್ರ ಪ್ರಾಂಪ್ಟ್‌ಗಳನ್ನು ಎರಡನ್ನೂ ಮೌಲ್ಯಮಾಪನ ಮಾಡುವ ಸಾಮರ್ಥ್ಯ ಹೊಂದಿದೆ\n",
    "- ಸಣ್ಣದಿಂದ ಮಧ್ಯಮ ಗಾತ್ರದ ಬದಲಾವಣೆಗಳು (11B ಮತ್ತು 90B) - ಇದು ಲವಚಿಕ ನಿಯೋಜನೆ ಆಯ್ಕೆಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ,\n",
    "- ಪಠ್ಯ-ಮಾತ್ರ ಬದಲಾವಣೆಗಳು (1B ಮತ್ತು 3B) - ಇದು ಮಾದರಿಯನ್ನು ಎಡ್ಜ್ / ಮೊಬೈಲ್ ಸಾಧನಗಳಲ್ಲಿ ನಿಯೋಜಿಸಲು ಅನುಮತಿಸುತ್ತದೆ ಮತ್ತು ಕಡಿಮೆ ವಿಳಂಬವನ್ನು ಒದಗಿಸುತ್ತದೆ\n",
    "\n",
    "ಬಹುಮಾಧ್ಯಮ ಬೆಂಬಲವು ಮುಕ್ತ ಮೂಲ ಮಾದರಿಗಳ ಜಗತ್ತಿನಲ್ಲಿ ದೊಡ್ಡ ಹೆಜ್ಜೆಯನ್ನು ಪ್ರತಿನಿಧಿಸುತ್ತದೆ. ಕೆಳಗಿನ ಕೋಡ್ ಉದಾಹರಣೆ ಲ್ಲಾಮಾ 3.2 90B ನಿಂದ ಚಿತ್ರದ ವಿಶ್ಲೇಷಣೆಯನ್ನು ಪಡೆಯಲು ಚಿತ್ರ ಮತ್ತು ಪಠ್ಯ ಪ್ರಾಂಪ್ಟ್ ಎರಡನ್ನೂ ತೆಗೆದುಕೊಳ್ಳುತ್ತದೆ.\n",
    "\n",
    "### ಲ್ಲಾಮಾ 3.2 ಜೊತೆಗೆ ಬಹುಮಾಧ್ಯಮ ಬೆಂಬಲ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install azure-core\n",
    "%pip install azure-ai-inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from azure.ai.inference import ChatCompletionsClient\n",
    "from azure.ai.inference.models import (\n",
    "    SystemMessage,\n",
    "    UserMessage,\n",
    "    TextContentItem,\n",
    "    ImageContentItem,\n",
    "    ImageUrl,\n",
    "    ImageDetailLevel,\n",
    ")\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "\n",
    "token = os.environ[\"GITHUB_TOKEN\"]\n",
    "endpoint = \"https://models.inference.ai.azure.com\"\n",
    "model_name = \"Llama-3.2-90B-Vision-Instruct\"\n",
    "\n",
    "\n",
    "client = ChatCompletionsClient(\n",
    "    endpoint=endpoint,\n",
    "    credential=AzureKeyCredential(token),\n",
    ")\n",
    "\n",
    "response = client.complete(\n",
    "    messages=[\n",
    "        SystemMessage(\n",
    "            content=\"You are a helpful assistant that describes images in details.\"\n",
    "        ),\n",
    "        UserMessage(\n",
    "            content=[\n",
    "                TextContentItem(text=\"What's in this image?\"),\n",
    "                ImageContentItem(\n",
    "                    image_url=ImageUrl.load(\n",
    "                        image_file=\"sample.jpg\",\n",
    "                        image_format=\"jpg\",\n",
    "                        detail=ImageDetailLevel.LOW)\n",
    "                ),\n",
    "            ],\n",
    "        ),\n",
    "    ],\n",
    "    model=model_name,\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಕಲಿಕೆ ಇಲ್ಲಿ ನಿಲ್ಲುವುದಿಲ್ಲ, ಪ್ರಯಾಣವನ್ನು ಮುಂದುವರೆಸಿ\n",
    "\n",
    "ಈ ಪಾಠವನ್ನು ಪೂರ್ಣಗೊಳಿಸಿದ ನಂತರ, ನಿಮ್ಮ ಜನರೇಟಿವ್ AI ಜ್ಞಾನವನ್ನು ಮುಂದುವರೆಸಲು ನಮ್ಮ [ಜನರೇಟಿವ್ AI ಕಲಿಕೆ ಸಂಗ್ರಹ](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) ಅನ್ನು ಪರಿಶೀಲಿಸಿ!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**ಅಸ್ವೀಕರಣ**:  \nಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ದೋಷಗಳು ಅಥವಾ ಅಸತ್ಯತೆಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "coopTranslator": {
   "original_hash": "da4ecf6a45fc7f57cd1bdc8fe6847832",
   "translation_date": "2025-12-19T20:58:50+00:00",
   "source_file": "21-meta/python/githubmodels-assignment.ipynb",
   "language_code": "kn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}