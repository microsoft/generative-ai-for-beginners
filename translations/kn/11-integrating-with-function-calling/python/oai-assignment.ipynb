{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಪರಿಚಯ\n",
    "\n",
    "ಈ ಪಾಠದಲ್ಲಿ ಒಳಗೊಂಡಿರುವುದು:  \n",
    "- ಫಂಕ್ಷನ್ ಕರೆಮಾಡುವುದು ಏನು ಮತ್ತು ಅದರ ಬಳಕೆ ಪ್ರಕರಣಗಳು  \n",
    "- OpenAI ಬಳಸಿ ಫಂಕ್ಷನ್ ಕರೆ ಹೇಗೆ ರಚಿಸುವುದು  \n",
    "- ಫಂಕ್ಷನ್ ಕರೆ ಅನ್ನು ಅಪ್ಲಿಕೇಶನ್‌ಗೆ ಹೇಗೆ ಸಂಯೋಜಿಸುವುದು  \n",
    "\n",
    "## ಕಲಿಕೆಯ ಗುರಿಗಳು\n",
    "\n",
    "ಈ ಪಾಠವನ್ನು ಪೂರ್ಣಗೊಳಿಸಿದ ನಂತರ ನೀವು ತಿಳಿದುಕೊಳ್ಳುವಿರಿ ಮತ್ತು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿರಿ:\n",
    "\n",
    "- ಫಂಕ್ಷನ್ ಕರೆಮಾಡುವ ಉದ್ದೇಶ  \n",
    "- OpenAI ಸೇವೆಯನ್ನು ಬಳಸಿ ಫಂಕ್ಷನ್ ಕರೆ ಸೆಟ್‌ಅಪ್ ಮಾಡುವುದು  \n",
    "- ನಿಮ್ಮ ಅಪ್ಲಿಕೇಶನ್ ಬಳಕೆ ಪ್ರಕರಣಕ್ಕೆ ಪರಿಣಾಮಕಾರಿಯಾದ ಫಂಕ್ಷನ್ ಕರೆಗಳನ್ನು ವಿನ್ಯಾಸಗೊಳಿಸುವುದು\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಫಂಕ್ಷನ್ ಕರೆಗಳನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವುದು\n",
    "\n",
    "ಈ ಪಾಠಕ್ಕಾಗಿ, ನಾವು ನಮ್ಮ ಶಿಕ್ಷಣ ಸ್ಟಾರ್ಟ್ಅಪ್‌ಗೆ ಒಂದು ವೈಶಿಷ್ಟ್ಯವನ್ನು ನಿರ್ಮಿಸಲು ಬಯಸುತ್ತೇವೆ, ಅದು ಬಳಕೆದಾರರಿಗೆ ತಾಂತ್ರಿಕ ಕೋರ್ಸುಗಳನ್ನು ಹುಡುಕಲು ಚಾಟ್‌ಬಾಟ್ ಬಳಸಲು ಅನುಮತಿಸುತ್ತದೆ. ನಾವು ಅವರ ಕೌಶಲ್ಯ ಮಟ್ಟ, ಪ್ರಸ್ತುತ ಪಾತ್ರ ಮತ್ತು ಆಸಕ್ತಿಯ ತಂತ್ರಜ್ಞಾನಕ್ಕೆ ಹೊಂದಿಕೊಂಡ ಕೋರ್ಸುಗಳನ್ನು ಶಿಫಾರಸು ಮಾಡುತ್ತೇವೆ.\n",
    "\n",
    "ಇದನ್ನು ಪೂರ್ಣಗೊಳಿಸಲು ನಾವು ಕೆಳಗಿನ ಸಂಯೋಜನೆಯನ್ನು ಬಳಸುತ್ತೇವೆ:  \n",
    "- ಬಳಕೆದಾರರಿಗೆ ಚಾಟ್ ಅನುಭವವನ್ನು ಸೃಷ್ಟಿಸಲು `OpenAI`  \n",
    "- ಬಳಕೆದಾರರ ವಿನಂತಿಯ ಆಧಾರದ ಮೇಲೆ ಕೋರ್ಸುಗಳನ್ನು ಹುಡುಕಲು ಸಹಾಯ ಮಾಡಲು `Microsoft Learn Catalog API`  \n",
    "- ಬಳಕೆದಾರರ ಪ್ರಶ್ನೆಯನ್ನು ತೆಗೆದು ಅದನ್ನು API ವಿನಂತಿ ಮಾಡಲು ಫಂಕ್ಷನ್‌ಗೆ ಕಳುಹಿಸಲು `Function Calling`  \n",
    "\n",
    "ಪ್ರಾರಂಭಿಸಲು, ನಾವು ಮೊದಲಿಗೆ ಫಂಕ್ಷನ್ ಕರೆಗಳನ್ನು ಏಕೆ ಬಳಸಬೇಕೆಂದು ನೋಡೋಣ:\n",
    "\n",
    "print(\"ಮುಂದಿನ ವಿನಂತಿಯಲ್ಲಿನ ಸಂದೇಶಗಳು:\")  \n",
    "print(messages)  \n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(  \n",
    "    messages=messages,  \n",
    "    model=deployment,  \n",
    "    function_call=\"auto\",  \n",
    "    functions=functions,  \n",
    "    temperature=0  \n",
    "        )  # GPT ಫಂಕ್ಷನ್ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ನೋಡಬಹುದಾದ ಹೊಸ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಪಡೆಯಿರಿ\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್ ಯಾಕೆ\n",
    "\n",
    "ನೀವು ಈ ಕೋರ್ಸ್‌ನ ಯಾವುದೇ ಇತರೆ ಪಾಠವನ್ನು ಪೂರ್ಣಗೊಳಿಸಿದ್ದರೆ, ನೀವು ಬಹುಶಃ ಲಾರ್ಜ್ ಲ್ಯಾಂಗ್ವೇಜ್ ಮಾದರಿಗಳ (LLMs) ಬಳಕೆಯ ಶಕ್ತಿಯನ್ನು ಅರ್ಥಮಾಡಿಕೊಂಡಿರಬಹುದು. ಆಶಾ ಇದೆ ನೀವು ಅವುಗಳ ಕೆಲವು ಮಿತಿಗಳನ್ನು ಕೂಡ ನೋಡಬಹುದು.\n",
    "\n",
    "ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್ OpenAI ಸೇವೆಯ ಒಂದು ವೈಶಿಷ್ಟ್ಯವಾಗಿದ್ದು, ಕೆಳಗಿನ ಸವಾಲುಗಳನ್ನು ಪರಿಹರಿಸಲು ವಿನ್ಯಾಸಗೊಳಿಸಲಾಗಿದೆ:\n",
    "\n",
    "ಅಸಮಾನ ಪ್ರತಿಕ್ರಿಯೆ ಸ್ವರೂಪೀಕರಣ:\n",
    "- ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್ ಮೊದಲು, ಲಾರ್ಜ್ ಲ್ಯಾಂಗ್ವೇಜ್ ಮಾದರಿಯಿಂದ ಪ್ರತಿಕ್ರಿಯೆಗಳು ಅಸಂರಚಿತ ಮತ್ತು ಅಸಮಾನವಾಗಿದ್ದವು. ಡೆವಲಪರ್‌ಗಳು ಪ್ರತಿಯೊಂದು ಬದಲಾವಣೆಯನ್ನು ನಿರ್ವಹಿಸಲು ಸಂಕೀರ್ಣ ಮಾನ್ಯತೆ ಕೋಡ್ ಬರೆಯಬೇಕಾಗಿತ್ತು.\n",
    "\n",
    "ಬಾಹ್ಯ ಡೇಟಾ ಜೊತೆಗೆ ಸೀಮಿತ ಏಕೀಕರಣ:\n",
    "- ಈ ವೈಶಿಷ್ಟ್ಯಕ್ಕೆ ಮುಂಚೆ, ಅಪ್ಲಿಕೇಶನ್‌ನ ಇತರೆ ಭಾಗಗಳಿಂದ ಡೇಟಾವನ್ನು ಚಾಟ್ ಸನ್ನಿವೇಶಕ್ಕೆ ಸೇರಿಸುವುದು ಕಷ್ಟವಾಗಿತ್ತು.\n",
    "\n",
    "ಪ್ರತಿಕ್ರಿಯೆ ಸ್ವರೂಪಗಳನ್ನು ಮಾನಕೀಕರಿಸುವ ಮೂಲಕ ಮತ್ತು ಬಾಹ್ಯ ಡೇಟಾ ಜೊತೆಗೆ ನಿರಂತರ ಏಕೀಕರಣವನ್ನು ಸಾದ್ಯಮಾಡುವ ಮೂಲಕ, ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್ ಅಭಿವೃದ್ಧಿಯನ್ನು ಸರಳಗೊಳಿಸುತ್ತದೆ ಮತ್ತು ಹೆಚ್ಚುವರಿ ಮಾನ್ಯತೆ ಲಾಜಿಕ್ ಅಗತ್ಯವನ್ನು ಕಡಿಮೆ ಮಾಡುತ್ತದೆ.\n",
    "\n",
    "ಬಳಕೆದಾರರು \"ಸ್ಟಾಕ್‌ಹೋಲ್ಮ್‌ನಲ್ಲಿ ಪ್ರಸ್ತುತ ಹವಾಮಾನ ಏನು?\" ಎಂಬಂತಹ ಉತ್ತರಗಳನ್ನು ಪಡೆಯಲಾಗುತ್ತಿರಲಿಲ್ಲ. ಇದಕ್ಕೆ ಕಾರಣ, ಮಾದರಿಗಳು ತರಬೇತುಗೊಂಡಿರುವ ಡೇಟಾದ ಸಮಯಕ್ಕೆ ಸೀಮಿತವಾಗಿದ್ದವು.\n",
    "\n",
    "ಈ ಸಮಸ್ಯೆಯನ್ನು ವಿವರಿಸುವ ಕೆಳಗಿನ ಉದಾಹರಣೆಯನ್ನು ನೋಡೋಣ:\n",
    "\n",
    "ನಾವು ವಿದ್ಯಾರ್ಥಿಗಳ ಡೇಟಾಬೇಸ್ ರಚಿಸಿ ಅವರಿಗೆ ಸರಿಯಾದ ಕೋರ್ಸ್ ಅನ್ನು ಸೂಚಿಸಲು ಬಯಸುತ್ತೇವೆ ಎಂದು ಹೇಳೋಣ. ಕೆಳಗೆ ನಾವು ಎರಡು ವಿದ್ಯಾರ್ಥಿಗಳ ವಿವರಣೆಗಳನ್ನು ಹೊಂದಿದ್ದೇವೆ, ಅವು ಡೇಟಾದಲ್ಲಿ ಬಹಳ ಸಮಾನವಾಗಿವೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ನಾವು ಈ ಮಾಹಿತಿಯನ್ನು ವಿಶ್ಲೇಷಿಸಲು LLM ಗೆ ಕಳುಹಿಸಲು ಬಯಸುತ್ತೇವೆ. ಇದನ್ನು ನಂತರ ನಮ್ಮ ಅಪ್ಲಿಕೇಶನ್‌ನಲ್ಲಿ API ಗೆ ಕಳುಹಿಸಲು ಅಥವಾ ಡೇಟಾಬೇಸ್‌ನಲ್ಲಿ ಸಂಗ್ರಹಿಸಲು ಬಳಸಬಹುದು.\n",
    "\n",
    "ನಾವು ಆಸಕ್ತರಾಗಿರುವ ಮಾಹಿತಿಯನ್ನು LLM ಗೆ ಸೂಚಿಸುವ ಎರಡು ಸಮಾನ ಪ್ರಾಂಪ್ಟ್‌ಗಳನ್ನು ರಚಿಸೋಣ:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ನಾವು ಇದನ್ನು ನಮ್ಮ ಉತ್ಪನ್ನಕ್ಕೆ ಮುಖ್ಯವಾದ ಭಾಗಗಳನ್ನು ವಿಶ್ಲೇಷಿಸಲು LLM ಗೆ ಕಳುಹಿಸಲು ಬಯಸುತ್ತೇವೆ. ಆದ್ದರಿಂದ ನಾವು LLM ಗೆ ಸೂಚಿಸಲು ಎರಡು ಸಮಾನ ಪ್ರಾಂಪ್ಟ್‌ಗಳನ್ನು ರಚಿಸಬಹುದು:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈ ಎರಡು ಪ್ರಾಂಪ್ಟ್‌ಗಳನ್ನು ರಚಿಸಿದ ನಂತರ, ನಾವು ಅವುಗಳನ್ನು `openai.ChatCompletion` ಬಳಸಿ LLM ಗೆ ಕಳುಹಿಸುವೆವು. ನಾವು ಪ್ರಾಂಪ್ಟ್ ಅನ್ನು `messages` ಚರದಲ್ಲಿ ಸಂಗ್ರಹಿಸಿ, ಪಾತ್ರವನ್ನು `user` ಗೆ ನಿಯೋಜಿಸುತ್ತೇವೆ. ಇದು ಬಳಕೆದಾರರಿಂದ ಚಾಟ್‌ಬಾಟ್‌ಗೆ ಸಂದೇಶ ಬರೆಯಲಾಗುತ್ತಿರುವಂತೆ ಅನುಕರಿಸಲು.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈಗ ನಾವು ಎರಡೂ ವಿನಂತಿಗಳನ್ನು LLM ಗೆ ಕಳುಹಿಸಿ ನಾವು ಪಡೆದ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಪರಿಶೀಲಿಸಬಹುದು.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಪ್ರಾಂಪ್ಟ್‌ಗಳು ಒಂದೇ ಆಗಿದ್ದರೂ ಮತ್ತು ವಿವರಣೆಗಳು ಸಮಾನವಾಗಿದ್ದರೂ, ನಾವು `Grades` ಗುಣಲಕ್ಷಣದ ವಿಭಿನ್ನ ಸ್ವರೂಪಗಳನ್ನು ಪಡೆಯಬಹುದು.\n",
    "\n",
    "ಮೇಲಿನ ಸೆಲ್ ಅನ್ನು ಹಲವಾರು ಬಾರಿ ಚಾಲನೆ ಮಾಡಿದರೆ, ಸ್ವರೂಪವು `3.7` ಅಥವಾ `3.7 GPA` ಆಗಿರಬಹುದು.\n",
    "\n",
    "ಇದು ಏಕೆಂದರೆ LLM ಬರೆಯಲಾದ ಪ್ರಾಂಪ್ಟ್ ರೂಪದಲ್ಲಿ ಅಸಂರಚಿತ ಡೇಟಾವನ್ನು ತೆಗೆದುಕೊಳ್ಳುತ್ತದೆ ಮತ್ತು ಅಸಂರಚಿತ ಡೇಟಾವನ್ನೇ ಹಿಂತಿರುಗಿಸುತ್ತದೆ. ನಾವು ಸಂರಚಿತ ಸ್ವರೂಪವನ್ನು ಹೊಂದಿರಬೇಕಾಗುತ್ತದೆ, ಹೀಗಾಗಿ ನಾವು ಈ ಡೇಟಾವನ್ನು ಸಂಗ್ರಹಿಸುವಾಗ ಅಥವಾ ಬಳಸುವಾಗ ಏನು ನಿರೀಕ್ಷಿಸಬೇಕೆಂದು ತಿಳಿದುಕೊಳ್ಳಬಹುದು.\n",
    "\n",
    "ಕಾರ್ಯಾತ್ಮಕ ಕರೆಗಳನ್ನು ಬಳಸುವುದರಿಂದ, ನಾವು ಸಂರಚಿತ ಡೇಟಾವನ್ನು ಹಿಂತಿರುಗಿಸುವುದನ್ನು ಖಚಿತಪಡಿಸಿಕೊಳ್ಳಬಹುದು. ಕಾರ್ಯಾತ್ಮಕ ಕರೆಗಳನ್ನು ಬಳಸುವಾಗ, LLM ನಿಜವಾಗಿಯೂ ಯಾವುದೇ ಕಾರ್ಯಗಳನ್ನು ಕರೆಸುವುದಿಲ್ಲ ಅಥವಾ ಚಾಲನೆ ಮಾಡುವುದಿಲ್ಲ. ಬದಲಿಗೆ, ನಾವು LLM ತನ್ನ ಪ್ರತಿಕ್ರಿಯೆಗಳಿಗೆ ಅನುಸರಿಸಲು ಒಂದು ಸಂರಚನೆಯನ್ನು ರಚಿಸುತ್ತೇವೆ. ನಂತರ ಆ ಸಂರಚಿತ ಪ್ರತಿಕ್ರಿಯೆಗಳನ್ನು ಬಳಸಿಕೊಂಡು ನಮ್ಮ ಅಪ್ಲಿಕೇಶನ್‌ಗಳಲ್ಲಿ ಯಾವ ಕಾರ್ಯವನ್ನು ಚಾಲನೆ ಮಾಡಬೇಕೆಂದು ತಿಳಿದುಕೊಳ್ಳುತ್ತೇವೆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ಕಾರ್ಯಾಚರಣೆ ಕರೆ ಹರಿವು диаг್ರಾಮ್](../../../../translated_images/Function-Flow.083875364af4f4bb.kn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ನಾವು ನಂತರ ಫಂಕ್ಷನ್‌ನಿಂದ ಮರಳಿದುದನ್ನು ತೆಗೆದುಕೊಂಡು ಇದನ್ನು LLM ಗೆ ಹಿಂತಿರುಗಿಸಬಹುದು. ನಂತರ LLM ನೈಸರ್ಗಿಕ ಭಾಷೆಯನ್ನು ಬಳಸಿ ಬಳಕೆದಾರರ ಪ್ರಶ್ನೆಗೆ ಉತ್ತರ ನೀಡುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಫಂಕ್ಷನ್ ಕಾಲ್‌ಗಳನ್ನು ಬಳಸುವ ಬಳಕೆ ಪ್ರಕರಣಗಳು\n",
    "\n",
    "**ಬಾಹ್ಯ ಸಾಧನಗಳನ್ನು ಕರೆಸುವುದು**  \n",
    "ಚಾಟ್‌ಬಾಟ್‌ಗಳು ಬಳಕೆದಾರರಿಂದ ಪ್ರಶ್ನೆಗಳಿಗೆ ಉತ್ತರ ನೀಡುವಲ್ಲಿ ಅತ್ಯುತ್ತಮವಾಗಿವೆ. ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್ ಬಳಸಿ, ಚಾಟ್‌ಬಾಟ್‌ಗಳು ಬಳಕೆದಾರರ ಸಂದೇಶಗಳನ್ನು ಬಳಸಿಕೊಂಡು ಕೆಲವು ಕಾರ್ಯಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು. ಉದಾಹರಣೆಗೆ, ವಿದ್ಯಾರ್ಥಿ ಚಾಟ್‌ಬಾಟ್‌ಗೆ \"ನನ್ನ ಶಿಕ್ಷಕರಿಗೆ ಈ ವಿಷಯದಲ್ಲಿ ಹೆಚ್ಚಿನ ಸಹಾಯ ಬೇಕೆಂದು ಇಮೇಲ್ ಕಳುಹಿಸಿ\" ಎಂದು ಕೇಳಬಹುದು. ಇದು `send_email(to: string, body: string)` ಎಂಬ ಫಂಕ್ಷನ್ ಅನ್ನು ಕರೆಸಬಹುದು.\n",
    "\n",
    "**API ಅಥವಾ ಡೇಟಾಬೇಸ್ ಕ್ವೆರಿಗಳನ್ನು ರಚಿಸುವುದು**  \n",
    "ಬಳಕೆದಾರರು ನೈಸರ್ಗಿಕ ಭಾಷೆಯನ್ನು ಬಳಸಿ ಮಾಹಿತಿಯನ್ನು ಹುಡುಕಬಹುದು, ಅದು ಫಾರ್ಮ್ಯಾಟ್ ಮಾಡಿದ ಕ್ವೇರಿ ಅಥವಾ API ವಿನಂತಿಯಾಗಿ ಪರಿವರ್ತಿತವಾಗುತ್ತದೆ. ಉದಾಹರಣೆಗೆ, ಶಿಕ್ಷಕರು \"ಕೊನೆಯ ಅಸೈನ್‌ಮೆಂಟ್ ಪೂರ್ಣಗೊಳಿಸಿದ ವಿದ್ಯಾರ್ಥಿಗಳು ಯಾರು?\" ಎಂದು ಕೇಳಬಹುದು, ಇದು `get_completed(student_name: string, assignment: int, current_status: string)` ಎಂಬ ಫಂಕ್ಷನ್ ಅನ್ನು ಕರೆಸಬಹುದು.\n",
    "\n",
    "**ಸಂರಚಿತ ಡೇಟಾವನ್ನು ರಚಿಸುವುದು**  \n",
    "ಬಳಕೆದಾರರು ಪಠ್ಯದ ಬ್ಲಾಕ್ ಅಥವಾ CSV ಅನ್ನು ತೆಗೆದುಕೊಂಡು ಅದರಿಂದ ಪ್ರಮುಖ ಮಾಹಿತಿಯನ್ನು LLM ಬಳಸಿ ಹೊರತೆಗೆಯಬಹುದು. ಉದಾಹರಣೆಗೆ, ವಿದ್ಯಾರ್ಥಿ ಶಾಂತಿ ಒಪ್ಪಂದಗಳ ಬಗ್ಗೆ ವಿಕಿಪೀಡಿಯಾ ಲೇಖನವನ್ನು AI ಫ್ಲಾಶ್ ಕಾರ್ಡ್‌ಗಳಾಗಿ ಪರಿವರ್ತಿಸಬಹುದು. ಇದನ್ನು `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` ಎಂಬ ಫಂಕ್ಷನ್ ಬಳಸಿ ಮಾಡಬಹುದು.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ನಿಮ್ಮ ಮೊದಲ ಫಂಕ್ಷನ್ ಕರೆ ರಚಿಸುವುದು\n",
    "\n",
    "ಫಂಕ್ಷನ್ ಕರೆ ರಚಿಸುವ ಪ್ರಕ್ರಿಯೆಯಲ್ಲಿ 3 ಪ್ರಮುಖ ಹಂತಗಳಿವೆ:  \n",
    "1. ನಿಮ್ಮ ಫಂಕ್ಷನ್‌ಗಳ ಪಟ್ಟಿ ಮತ್ತು ಬಳಕೆದಾರ ಸಂದೇಶದೊಂದಿಗೆ ಚಾಟ್ ಪೂರ್ಣಗೊಳಿಸುವಿಕೆ API ಅನ್ನು ಕರೆ ಮಾಡುವುದು  \n",
    "2. ಕಾರ್ಯಾಚರಣೆ ಮಾಡಲು ಮಾದರಿಯ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಓದುವುದು ಅಂದರೆ ಫಂಕ್ಷನ್ ಅಥವಾ API ಕರೆ ನಿರ್ವಹಿಸುವುದು  \n",
    "3. ಬಳಕೆದಾರರಿಗೆ ಪ್ರತಿಕ್ರಿಯೆ ರಚಿಸಲು ನಿಮ್ಮ ಫಂಕ್ಷನ್‌ನಿಂದ ಬಂದ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಬಳಸಿ ಮತ್ತೊಂದು ಬಾರಿ ಚಾಟ್ ಪೂರ್ಣಗೊಳಿಸುವಿಕೆ API ಅನ್ನು ಕರೆ ಮಾಡುವುದು.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ಫಂಕ್ಷನ್ ಕರೆನ ಹರಿವು](../../../../translated_images/LLM-Flow.3285ed8caf4796d7.kn.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಫಂಕ್ಷನ್ ಕರೆಗಳ ಅಂಶಗಳು\n",
    "\n",
    "#### ಬಳಕೆದಾರರ ಇನ್‌ಪುಟ್\n",
    "\n",
    "ಮೊದಲನೆಯ ಹಂತವು ಬಳಕೆದಾರ ಸಂದೇಶವನ್ನು ರಚಿಸುವುದು. ಇದನ್ನು ಪಠ್ಯ ಇನ್‌ಪುಟ್‌ನ ಮೌಲ್ಯವನ್ನು ತೆಗೆದುಕೊಂಡು ಡೈನಾಮಿಕ್ ಆಗಿ ನಿಯೋಜಿಸಬಹುದು ಅಥವಾ ನೀವು ಇಲ್ಲಿ ಮೌಲ್ಯವನ್ನು ನಿಯೋಜಿಸಬಹುದು. ನೀವು Chat Completions API ಜೊತೆಗೆ ಮೊದಲ ಬಾರಿಗೆ ಕೆಲಸ ಮಾಡುತ್ತಿದ್ದರೆ, ಸಂದೇಶದ `role` ಮತ್ತು `content` ಅನ್ನು ನಿರ್ಧರಿಸಬೇಕಾಗುತ್ತದೆ.\n",
    "\n",
    "`role` ಆಗಿರಬಹುದು `system` (ನಿಯಮಗಳನ್ನು ರಚಿಸುವುದು), `assistant` (ಮಾದರಿ) ಅಥವಾ `user` (ಅಂತಿಮ ಬಳಕೆದಾರ). ಫಂಕ್ಷನ್ ಕರೆಗಾಗಿ, ನಾವು ಇದನ್ನು `user` ಎಂದು ನಿಯೋಜಿಸುವೆವು ಮತ್ತು ಉದಾಹರಣೆಯ ಪ್ರಶ್ನೆಯನ್ನು ನೀಡುತ್ತೇವೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಕಾರ್ಯಗಳನ್ನು ರಚಿಸುವುದು.\n",
    "\n",
    "ಮುಂದೆ ನಾವು ಒಂದು ಕಾರ್ಯವನ್ನು ಮತ್ತು ಆ ಕಾರ್ಯದ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳನ್ನು ವ್ಯಾಖ್ಯಾನಿಸುವೆವು. ಇಲ್ಲಿ ನಾವು `search_courses` ಎಂಬ ಒಂದು ಕಾರ್ಯವನ್ನು ಮಾತ್ರ ಬಳಸುತ್ತೇವೆ ಆದರೆ ನೀವು ಬಹು ಕಾರ್ಯಗಳನ್ನು ರಚಿಸಬಹುದು.\n",
    "\n",
    "**ಮುಖ್ಯ** : ಕಾರ್ಯಗಳು LLM ಗೆ ಸಿಸ್ಟಮ್ ಸಂದೇಶದಲ್ಲಿ ಸೇರಿಸಲಾಗುತ್ತವೆ ಮತ್ತು ನೀವು ಹೊಂದಿರುವ ಲಭ್ಯವಿರುವ ಟೋಕನ್‌ಗಳ ಪ್ರಮಾಣದಲ್ಲಿ ಸೇರಿಸಲಾಗುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ವ್ಯಾಖ್ಯಾನಗಳು** \n",
    "\n",
    "ಫಂಕ್ಷನ್ ವ್ಯಾಖ್ಯಾನ ರಚನೆಗೆ ಹಲವಾರು ಮಟ್ಟಗಳಿವೆ, ಪ್ರತಿ ಮಟ್ಟಕ್ಕೂ ತನ್ನದೇ ಆದ ಗುಣಲಕ್ಷಣಗಳಿವೆ. ಇಲ್ಲಿದೆ ಆ ನೆಸ್ಟೆಡ್ ರಚನೆಯ ವಿವರಣೆ:\n",
    "\n",
    "**ಮೇಲ್ಮಟ್ಟದ ಫಂಕ್ಷನ್ ಗುಣಲಕ್ಷಣಗಳು:**\n",
    "\n",
    "`name` - ನಾವು ಕರೆಮಾಡಬೇಕಾದ ಫಂಕ್ಷನ್‌ನ ಹೆಸರು.\n",
    "\n",
    "`description` - ಫಂಕ್ಷನ್ ಹೇಗೆ ಕಾರ್ಯನಿರ್ವಹಿಸುತ್ತದೆ ಎಂಬ ವಿವರಣೆ. ಇಲ್ಲಿ ಸ್ಪಷ್ಟ ಮತ್ತು ನಿಖರವಾಗಿರುವುದು ಮುಖ್ಯ.\n",
    "\n",
    "`parameters` - ನೀವು ಮಾದರಿಯಿಂದ ಉತ್ತರದಲ್ಲಿ ಉತ್ಪಾದಿಸಲು ಬಯಸುವ ಮೌಲ್ಯಗಳು ಮತ್ತು ಸ್ವರೂಪಗಳ ಪಟ್ಟಿ.\n",
    "\n",
    "**ಪ್ಯಾರಾಮೀಟರ್ ಆಬ್ಜೆಕ್ಟ್ ಗುಣಲಕ್ಷಣಗಳು:**\n",
    "\n",
    "`type` - ಪ್ಯಾರಾಮೀಟರ್ ಆಬ್ಜೆಕ್ಟ್‌ನ ಡೇಟಾ ಪ್ರಕಾರ (ಸಾಮಾನ್ಯವಾಗಿ \"object\")\n",
    "\n",
    "`properties` - ಮಾದರಿ ತನ್ನ ಉತ್ತರಕ್ಕಾಗಿ ಬಳಸುವ ನಿರ್ದಿಷ್ಟ ಮೌಲ್ಯಗಳ ಪಟ್ಟಿ.\n",
    "\n",
    "**ವೈಯಕ್ತಿಕ ಪ್ಯಾರಾಮೀಟರ್ ಗುಣಲಕ್ಷಣಗಳು:**\n",
    "\n",
    "`name` - ಪ್ರಾಪರ್ಟಿ ಕೀ ಮೂಲಕ ಅರ್ಥಮಾಡಿಕೊಳ್ಳಲ್ಪಟ್ಟಿದೆ (ಉದಾ: \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - ಈ ನಿರ್ದಿಷ್ಟ ಪ್ಯಾರಾಮೀಟರ್‌ನ ಡೇಟಾ ಪ್ರಕಾರ (ಉದಾ: \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - ನಿರ್ದಿಷ್ಟ ಪ್ಯಾರಾಮೀಟರ್‌ನ ವಿವರಣೆ.\n",
    "\n",
    "**ಐಚ್ಛಿಕ ಗುಣಲಕ್ಷಣಗಳು:**\n",
    "\n",
    "`required` - ಫಂಕ್ಷನ್ ಕರೆ ಪೂರ್ಣಗೊಳಿಸಲು ಅಗತ್ಯವಿರುವ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳ ಪಟ್ಟಿಯ ಅರೆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ಫಂಕ್ಷನ್ ಕರೆ ಮಾಡುವುದು  \n",
    "ಫಂಕ್ಷನ್ ಅನ್ನು ವ್ಯಾಖ್ಯಾನಿಸಿದ ನಂತರ, ನಾವು ಅದನ್ನು Chat Completion API ಗೆ ಕರೆ ಮಾಡಲು ಸೇರಿಸಬೇಕಾಗುತ್ತದೆ. ನಾವು ಇದನ್ನು ವಿನಂತಿಗೆ `functions` ಅನ್ನು ಸೇರಿಸುವ ಮೂಲಕ ಮಾಡುತ್ತೇವೆ. ಈ ಸಂದರ್ಭದಲ್ಲಿ `functions=functions` ಆಗಿದೆ.  \n",
    "\n",
    "`function_call` ಅನ್ನು `auto` ಗೆ ಸೆಟ್ ಮಾಡುವ ಆಯ್ಕೆಯೂ ಇದೆ. ಇದರ ಅರ್ಥ, ಬಳಕೆದಾರ ಸಂದೇಶದ ಆಧಾರದ ಮೇಲೆ ಯಾವ ಫಂಕ್ಷನ್ ಅನ್ನು ಕರೆ ಮಾಡಬೇಕು ಎಂದು LLM ತೀರ್ಮಾನಿಸುವಂತೆ ನಾವು ಬಿಡುತ್ತೇವೆ, ಅದನ್ನು ನಾವು ಸ್ವತಃ ನಿಯೋಜಿಸುವ ಬದಲು.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈಗ ನಾವು ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ನೋಡೋಣ ಮತ್ತು ಅದು ಹೇಗೆ ರೂಪುಗೊಂಡಿದೆ ಎಂದು ನೋಡೋಣ:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "ನೀವು ನೋಡಬಹುದು ಫಂಕ್ಷನ್‌ನ ಹೆಸರು ಕರೆ ಮಾಡಲಾಗಿದೆ ಮತ್ತು ಬಳಕೆದಾರ ಸಂದೇಶದಿಂದ, LLM ಫಂಕ್ಷನ್‌ನ ಆರ್ಗ್ಯುಮೆಂಟ್‌ಗಳಿಗೆ ಹೊಂದಿಕೊಳ್ಳುವ ಡೇಟಾವನ್ನು ಕಂಡುಹಿಡಿಯಲು ಸಾಧ್ಯವಾಯಿತು.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.ಅಪ್ಲಿಕೇಶನ್‌ಗೆ ಫಂಕ್ಷನ್ ಕರೆಗಳನ್ನು ಏಕೀಕರಿಸುವುದು. \n",
    "\n",
    "\n",
    "ನಾವು LLM ನಿಂದ ಸ್ವರೂಪಗೊಳಿಸಿದ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಪರೀಕ್ಷಿಸಿದ ನಂತರ, ಈಗ ನಾವು ಇದನ್ನು ಅಪ್ಲಿಕೇಶನ್‌ಗೆ ಏಕೀಕರಿಸಬಹುದು. \n",
    "\n",
    "### ಹರಿವನ್ನು ನಿರ್ವಹಿಸುವುದು \n",
    "\n",
    "ನಮ್ಮ ಅಪ್ಲಿಕೇಶನ್‌ಗೆ ಇದನ್ನು ಏಕೀಕರಿಸಲು, ಕೆಳಗಿನ ಹಂತಗಳನ್ನು ತೆಗೆದುಕೊಳ್ಳೋಣ: \n",
    "\n",
    "ಮೊದಲು, OpenAI ಸೇವೆಗಳಿಗೆ ಕರೆ ಮಾಡಿ ಮತ್ತು ಸಂದೇಶವನ್ನು `response_message` ಎಂಬ ಚರದಲ್ಲಿ ಸಂಗ್ರಹಿಸೋಣ. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈಗ ನಾವು Microsoft Learn API ಅನ್ನು ಕರೆಮಾಡಿ ಕೋರ್ಸುಗಳ ಪಟ್ಟಿಯನ್ನು ಪಡೆಯುವ ಫಂಕ್ಷನ್ ಅನ್ನು ವ್ಯಾಖ್ಯಾನಿಸುವೆವು:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಉತ್ತಮ ಅಭ್ಯಾಸವಾಗಿ, ನಂತರ ನಾವು ಮಾದರಿ ಫಂಕ್ಷನ್ ಅನ್ನು ಕರೆ ಮಾಡಲು ಇಚ್ಛಿಸುವುದೇ ಎಂದು ನೋಡುತ್ತೇವೆ. ಅದಾದ ಮೇಲೆ, ನಾವು ಲಭ್ಯವಿರುವ ಫಂಕ್ಷನ್‌ಗಳಲ್ಲಿ ಒಂದನ್ನು ರಚಿಸಿ, ಕರೆ ಮಾಡಲಾಗುತ್ತಿರುವ ಫಂಕ್ಷನ್‌ಗೆ ಅದನ್ನು ಹೊಂದಿಸುತ್ತೇವೆ.  \n",
    "ನಂತರ, ನಾವು ಫಂಕ್ಷನ್‌ನ ಆರ್ಗ್ಯುಮೆಂಟ್‌ಗಳನ್ನು ತೆಗೆದು, ಅವುಗಳನ್ನು LLM ನ ಆರ್ಗ್ಯುಮೆಂಟ್‌ಗಳಿಗೆ ನಕ್ಷೆ ಮಾಡುತ್ತೇವೆ.\n",
    "\n",
    "ಕೊನೆಗೆ, ನಾವು ಫಂಕ್ಷನ್ ಕರೆ ಸಂದೇಶ ಮತ್ತು `search_courses` ಸಂದೇಶದಿಂದ ಹಿಂತಿರುಗಿಸಿದ ಮೌಲ್ಯಗಳನ್ನು ಸೇರಿಸುತ್ತೇವೆ. ಇದು LLM ಗೆ ಬಳಕೆದಾರನಿಗೆ ಸಹಜ ಭಾಷೆಯಲ್ಲಿ ಪ್ರತಿಕ್ರಿಯಿಸಲು ಅಗತ್ಯವಿರುವ ಎಲ್ಲಾ ಮಾಹಿತಿಯನ್ನು ನೀಡುತ್ತದೆ.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ಈಗ ನಾವು ನವೀಕರಿಸಿದ ಸಂದೇಶವನ್ನು LLM ಗೆ ಕಳುಹಿಸುವೆವು, ಇದರಿಂದ ನಾವು API JSON ಸ್ವರೂಪದ ಪ್ರತಿಕ್ರಿಯೆಯ ಬದಲು ಸಹಜ ಭಾಷೆಯ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಪಡೆಯಬಹುದು.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ಕೋಡ್ ಚಾಲೆಂಜ್\n",
    "\n",
    "ಉತ್ತಮ ಕೆಲಸ! OpenAI ಫಂಕ್ಷನ್ ಕಾಲಿಂಗ್‌ನ ನಿಮ್ಮ ಅಧ್ಯಯನವನ್ನು ಮುಂದುವರಿಸಲು ನೀವು ನಿರ್ಮಿಸಬಹುದು: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - ಕಲಿಯುವವರಿಗೆ ಇನ್ನಷ್ಟು ಕೋರ್ಸ್‌ಗಳನ್ನು ಹುಡುಕಲು ಸಹಾಯ ಮಾಡುವ ಫಂಕ್ಷನ್‌ನ ಹೆಚ್ಚಿನ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳು. ಲಭ್ಯವಿರುವ API ಪ್ಯಾರಾಮೀಟರ್‌ಗಳನ್ನು ನೀವು ಇಲ್ಲಿ ಕಂಡುಹಿಡಿಯಬಹುದು:  \n",
    " - ಕಲಿಯುವವರ ಮೂಲ ಭಾಷೆ ಸೇರಿದಂತೆ ಇನ್ನಷ್ಟು ಮಾಹಿತಿಯನ್ನು ತೆಗೆದುಕೊಳ್ಳುವ ಮತ್ತೊಂದು ಫಂಕ್ಷನ್ ಕಾಲ್ ರಚಿಸಿ  \n",
    " - ಫಂಕ್ಷನ್ ಕಾಲ್ ಮತ್ತು/ಅಥವಾ API ಕಾಲ್ ಯಾವುದೇ ಸೂಕ್ತ ಕೋರ್ಸ್‌ಗಳನ್ನು ಹಿಂತಿರುಗಿಸದಿದ್ದಾಗ ದೋಷ ನಿರ್ವಹಣೆಯನ್ನು ರಚಿಸಿ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**ಅಸ್ವೀಕರಣ**:  \nಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ದೋಷಗಳು ಅಥವಾ ತಪ್ಪುಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T21:17:42+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "kn"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}