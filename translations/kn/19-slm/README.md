<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "124ad36cfe96f74038811b6e2bb93e9d",
  "translation_date": "2025-12-19T19:28:41+00:00",
  "source_file": "19-slm/README.md",
  "language_code": "kn"
}
-->
# ಜನರೇಟಿವ್ AIಗಾಗಿ ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿಗಳ ಪರಿಚಯ ಆರಂಭಿಕರಿಗಾಗಿ
ಜನರೇಟಿವ್ AI ಎಂಬುದು ಹೊಸ ವಿಷಯವನ್ನು ರಚಿಸುವ ಸಾಮರ್ಥ್ಯ ಹೊಂದಿರುವ ವ್ಯವಸ್ಥೆಗಳನ್ನು ಸೃಷ್ಟಿಸುವ ಕೃತಕ ಬುದ್ಧಿಮತ್ತೆಯ ಒಂದು ಆಕರ್ಷಕ ಕ್ಷೇತ್ರವಾಗಿದೆ. ಈ ವಿಷಯವು ಪಠ್ಯ ಮತ್ತು ಚಿತ್ರಗಳಿಂದ ಸಂಗೀತ ಮತ್ತು ಸಂಪೂರ್ಣ ವರ್ಚುವಲ್ ಪರಿಸರಗಳವರೆಗೆ ವ್ಯಾಪಿಸಬಹುದು. ಜನರೇಟಿವ್ AIಯ ಅತ್ಯಂತ ರೋಚಕ ಅನ್ವಯಿಕೆಗಳಲ್ಲಿ ಒಂದಾಗಿದೆ ಭಾಷಾ ಮಾದರಿಗಳ ಕ್ಷೇತ್ರದಲ್ಲಿ.

## ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿಗಳು ಎಂದರೆ ಏನು?

ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿ (SLM) ಎಂದರೆ ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿಯ (LLM) ಸಣ್ಣ ರೂಪವಾಗಿದೆ, LLMಗಳ معماري ತತ್ವಗಳು ಮತ್ತು ತಂತ್ರಗಳನ್ನು ಬಳಸಿಕೊಂಡು, ಆದರೆ ಗಣನೀಯವಾಗಿ ಕಡಿಮೆ ಗಣನೆ ಸಾಮರ್ಥ್ಯವನ್ನು ತೋರಿಸುತ್ತದೆ.

SLMಗಳು ಮಾನವ-ಹಾಗೆ ಪಠ್ಯವನ್ನು ರಚಿಸಲು ವಿನ್ಯಾಸಗೊಳಿಸಲಾದ ಭಾಷಾ ಮಾದರಿಗಳ ಉಪವರ್ಗವಾಗಿದೆ. GPT-4 ಮುಂತಾದ ದೊಡ್ಡ ಮಾದರಿಗಳಿಗಿಂತ ಭಿನ್ನವಾಗಿ, SLMಗಳು ಹೆಚ್ಚು ಸಂಕ್ಷಿಪ್ತ ಮತ್ತು ಪರಿಣಾಮಕಾರಿಯಾಗಿದ್ದು, ಗಣನೀಯ ಸಂಪನ್ಮೂಲಗಳು ಸೀಮಿತವಾಗಿರುವ ಅನ್ವಯಿಕೆಗಳಿಗೆ ಸೂಕ್ತವಾಗಿವೆ. ಸಣ್ಣ ಗಾತ್ರವಿದ್ದರೂ, ಅವು ವಿವಿಧ ಕಾರ್ಯಗಳನ್ನು ನಿರ್ವಹಿಸಬಹುದು. ಸಾಮಾನ್ಯವಾಗಿ, SLMಗಳನ್ನು LLMಗಳನ್ನು ಸಂಕುಚಿತಗೊಳಿಸುವ ಅಥವಾ ದ್ರವೀಕರಿಸುವ ಮೂಲಕ ರಚಿಸಲಾಗುತ್ತದೆ, ಮೂಲ ಮಾದರಿಯ ಕಾರ್ಯಕ್ಷಮತೆ ಮತ್ತು ಭಾಷಾ ಸಾಮರ್ಥ್ಯಗಳ ಬಹುಪಾಲು ಉಳಿಸುವ ಉದ್ದೇಶದಿಂದ. ಈ ಮಾದರಿ ಗಾತ್ರದ ಕಡಿತವು ಒಟ್ಟು ಸಂಕೀರ್ಣತೆಯನ್ನು ಕಡಿಮೆ ಮಾಡುತ್ತದೆ, ಇದರಿಂದ SLMಗಳು ಸ್ಮೃತಿ ಬಳಕೆ ಮತ್ತು ಗಣನೆ ಅಗತ್ಯಗಳ ದೃಷ್ಟಿಯಿಂದ ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗುತ್ತವೆ. ಈ ಸುಧಾರಣೆಗಳಿದ್ದರೂ, SLMಗಳು ವಿವಿಧ ನೈಸರ್ಗಿಕ ಭಾಷಾ ಪ್ರಕ್ರಿಯೆ (NLP) ಕಾರ್ಯಗಳನ್ನು ನಿರ್ವಹಿಸಬಹುದು:

- ಪಠ್ಯ ರಚನೆ: ಸಸಂಬಂಧಿತ ಮತ್ತು ಸಾಂದರ್ಭಿಕವಾಗಿ ಸೂಕ್ತವಾದ ವಾಕ್ಯಗಳು ಅಥವಾ ಪ್ಯಾರಾಗ್ರಾಫ್‌ಗಳನ್ನು ರಚಿಸುವುದು.
- ಪಠ್ಯ ಪೂರ್ಣಗೊಳಿಸುವಿಕೆ: ನೀಡಲಾದ ಪ್ರಾಂಪ್ಟ್ ಆಧಾರಿತವಾಗಿ ವಾಕ್ಯಗಳನ್ನು ಊಹಿಸಿ ಪೂರ್ಣಗೊಳಿಸುವುದು.
- ಅನುವಾದ: ಒಂದು ಭಾಷೆಯಿಂದ ಮತ್ತೊಂದು ಭಾಷೆಗೆ ಪಠ್ಯವನ್ನು ಪರಿವರ್ತಿಸುವುದು.
- ಸಾರಾಂಶ: ದೀರ್ಘ ಪಠ್ಯಗಳನ್ನು ಚಿಕ್ಕ, ಸುಲಭವಾಗಿ ಗ್ರಹಿಸಬಹುದಾದ ಸಾರಾಂಶಗಳಾಗಿ ಸಂಕ್ಷಿಪ್ತಗೊಳಿಸುವುದು.

ದೊಡ್ಡ ಮಾದರಿಗಳಿಗಿಂತ ಕಾರ್ಯಕ್ಷಮತೆ ಅಥವಾ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವ ಆಳತೆಯಲ್ಲಿ ಕೆಲವು ವ್ಯತ್ಯಾಸಗಳೊಂದಿಗೆ.

## ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿಗಳು ಹೇಗೆ ಕಾರ್ಯನಿರ್ವಹಿಸುತ್ತವೆ?
SLMಗಳು ಅಪಾರ ಪ್ರಮಾಣದ ಪಠ್ಯ ಡೇಟಾದ ಮೇಲೆ ತರಬೇತಿ ಪಡೆಯುತ್ತವೆ. ತರಬೇತಿ ಸಮಯದಲ್ಲಿ, ಅವು ಭಾಷೆಯ ಮಾದರಿಗಳು ಮತ್ತು ರಚನೆಗಳನ್ನು ಕಲಿಯುತ್ತವೆ, ಇದರಿಂದ ವ್ಯಾಕರಣಾತ್ಮಕವಾಗಿ ಸರಿಯಾದ ಮತ್ತು ಸಾಂದರ್ಭಿಕವಾಗಿ ಸೂಕ್ತವಾದ ಪಠ್ಯವನ್ನು ರಚಿಸಲು ಸಾಧ್ಯವಾಗುತ್ತದೆ. ತರಬೇತಿ ಪ್ರಕ್ರಿಯೆ ಒಳಗೊಂಡಿದೆ:

- ಡೇಟಾ ಸಂಗ್ರಹಣೆ: ವಿವಿಧ ಮೂಲಗಳಿಂದ ದೊಡ್ಡ ಪಠ್ಯ ಡೇಟಾಸೆಟ್‌ಗಳನ್ನು ಸಂಗ್ರಹಿಸುವುದು.
- ಪೂರ್ವಸಿದ್ಧತೆ: ತರಬೇತಿಗೆ ಸೂಕ್ತವಾಗುವಂತೆ ಡೇಟಾವನ್ನು ಶುದ್ಧೀಕರಿಸಿ ಸಂಘಟಿಸುವುದು.
- ತರಬೇತಿ: ಯಂತ್ರ ಕಲಿಕೆ ಅಲ್ಗಾರಿದಮ್ಗಳನ್ನು ಬಳಸಿಕೊಂಡು ಮಾದರಿಯನ್ನು ಪಠ್ಯವನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳಲು ಮತ್ತು ರಚಿಸಲು ಕಲಿಸುವುದು.
- ಸೂಕ್ಷ್ಮ-ಸಂಯೋಜನೆ: ನಿರ್ದಿಷ್ಟ ಕಾರ್ಯಗಳಲ್ಲಿ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ಸುಧಾರಿಸಲು ಮಾದರಿಯನ್ನು ಹೊಂದಿಸುವುದು.

SLMಗಳ ಅಭಿವೃದ್ಧಿ ಸಂಪನ್ಮೂಲ-ಸೀಮಿತ ಪರಿಸರಗಳಲ್ಲಿ, ಉದಾಹರಣೆಗೆ ಮೊಬೈಲ್ ಸಾಧನಗಳು ಅಥವಾ ಎಡ್ಜ್ ಕಂಪ್ಯೂಟಿಂಗ್ ವೇದಿಕೆಗಳಲ್ಲಿ, ಪೂರ್ಣ ಪ್ರಮಾಣದ LLMಗಳನ್ನು ಬಳಸುವುದು ಅಸಾಧ್ಯವಾಗಿರುವ ಸಂದರ್ಭಗಳಿಗೆ ಹೊಂದಿಕೊಳ್ಳುತ್ತದೆ. ಪರಿಣಾಮಕಾರಿತ್ವದ ಮೇಲೆ ಗಮನಹರಿಸುವ ಮೂಲಕ, SLMಗಳು ಕಾರ್ಯಕ್ಷಮತೆ ಮತ್ತು ಪ್ರವೇಶಾರ್ಹತೆಯನ್ನು ಸಮತೋಲಗೊಳಿಸುತ್ತವೆ, ವಿವಿಧ ಕ್ಷೇತ್ರಗಳಲ್ಲಿ ವ್ಯಾಪಕ ಅನ್ವಯಿಕೆಗೆ ಅವಕಾಶ ನೀಡುತ್ತವೆ.

![slm](../../../translated_images/kn/slm.4058842744d0444a.png)

## ಕಲಿಕೆಯ ಉದ್ದೇಶಗಳು

ಈ ಪಾಠದಲ್ಲಿ, ನಾವು SLM ಬಗ್ಗೆ ಜ್ಞಾನವನ್ನು ಪರಿಚಯಿಸಿ, ಅದನ್ನು Microsoft Phi-3 ಜೊತೆಗೆ ಸಂಯೋಜಿಸಿ ಪಠ್ಯ ವಿಷಯ, ದೃಷ್ಟಿ ಮತ್ತು MoEಯಲ್ಲಿ ವಿಭಿನ್ನ ದೃಶ್ಯಾವಳಿಗಳನ್ನು ಕಲಿಯಲು ಆಶಿಸುತ್ತೇವೆ.

ಈ ಪಾಠದ ಅಂತ್ಯಕ್ಕೆ, ನೀವು ಕೆಳಗಿನ ಪ್ರಶ್ನೆಗಳಿಗೆ ಉತ್ತರ ನೀಡಲು ಸಾಧ್ಯವಾಗಬೇಕು:

- SLM ಎಂದರೆ ಏನು
- SLM ಮತ್ತು LLM ನಡುವಿನ ವ್ಯತ್ಯಾಸವೇನು
- Microsoft Phi-3/3.5 ಕುಟುಂಬವೇನು
- Microsoft Phi-3/3.5 ಕುಟುಂಬವನ್ನು ಹೇಗೆ ಇನ್ಫರೆನ್ಸ್ ಮಾಡುವುದು

ಸಿದ್ಧರಾ? ಆರಂಭಿಸೋಣ.

## ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿಗಳು (LLMs) ಮತ್ತು ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿಗಳು (SLMs) ನಡುವಿನ ವ್ಯತ್ಯಾಸಗಳು

LLMಗಳು ಮತ್ತು SLMಗಳು ಎರಡೂ ಪ್ರಾಯೋಗಿಕ ಯಂತ್ರ ಕಲಿಕೆಯ ಮೂಲ ತತ್ವಗಳ ಮೇಲೆ ನಿರ್ಮಿತವಾಗಿದ್ದು, معماري ವಿನ್ಯಾಸ, ತರಬೇತಿ ವಿಧಾನಗಳು, ಡೇಟಾ ರಚನೆ ಪ್ರಕ್ರಿಯೆಗಳು ಮತ್ತು ಮಾದರಿ ಮೌಲ್ಯಮಾಪನ ತಂತ್ರಗಳಲ್ಲಿ ಸಮಾನ ವಿಧಾನಗಳನ್ನು ಅನುಸರಿಸುತ್ತವೆ. ಆದರೆ, ಕೆಲವು ಪ್ರಮುಖ ಅಂಶಗಳು ಈ ಎರಡು ಮಾದರಿಗಳಲ್ಲಿ ವ್ಯತ್ಯಾಸವನ್ನು ಉಂಟುಮಾಡುತ್ತವೆ.

## ಸಣ್ಣ ಭಾಷಾ ಮಾದರಿಗಳ ಅನ್ವಯಿಕೆಗಳು

SLMಗಳಿಗೆ ವ್ಯಾಪಕ ಅನ್ವಯಿಕೆಗಳಿವೆ, ಅವುಗಳಲ್ಲಿ:

- ಚಾಟ್‌ಬಾಟ್‌ಗಳು: ಗ್ರಾಹಕ ಬೆಂಬಲ ಒದಗಿಸುವುದು ಮತ್ತು ಬಳಕೆದಾರರೊಂದಿಗೆ ಸಂಭಾಷಣಾತ್ಮಕವಾಗಿ ಸಂವಹನ ಮಾಡುವುದು.
- ವಿಷಯ ಸೃಷ್ಟಿ: ಲೇಖಕರಿಗೆ ಆಲೋಚನೆಗಳನ್ನು ರಚಿಸುವುದು ಅಥವಾ ಸಂಪೂರ್ಣ ಲೇಖನಗಳನ್ನು ರಚಿಸುವಲ್ಲಿ ಸಹಾಯ ಮಾಡುವುದು.
- ಶಿಕ್ಷಣ: ವಿದ್ಯಾರ್ಥಿಗಳಿಗೆ ಬರವಣಿಗೆ ಕಾರ್ಯಗಳಲ್ಲಿ ಅಥವಾ ಹೊಸ ಭಾಷೆಗಳನ್ನು ಕಲಿಯಲು ಸಹಾಯ ಮಾಡುವುದು.
- ಪ್ರವೇಶಾರ್ಹತೆ: ಅಂಗವಿಕಲತೆ ಹೊಂದಿರುವ ವ್ಯಕ್ತಿಗಳಿಗೆ ಪಠ್ಯ-ನಿಂದ-ಧ್ವನಿ ವ್ಯವಸ್ಥೆಗಳಂತಹ ಉಪಕರಣಗಳನ್ನು ಸೃಷ್ಟಿಸುವುದು.

**ಗಾತ್ರ**

LLMಗಳು ಮತ್ತು SLMಗಳ ನಡುವಿನ ಪ್ರಮುಖ ವ್ಯತ್ಯಾಸ ಮಾದರಿಗಳ ಗಾತ್ರದಲ್ಲಿದೆ. ChatGPT (GPT-4) ಮುಂತಾದ LLMಗಳು ಅಂದಾಜು 1.76 ಟ್ರಿಲಿಯನ್ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳನ್ನು ಹೊಂದಿರಬಹುದು, ಆದರೆ Mistral 7B ಮುಂತಾದ ಓಪನ್-ಸೋರ್ಸ್ SLMಗಳು ಸುಮಾರು 7 ಬಿಲಿಯನ್ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳೊಂದಿಗೆ ವಿನ್ಯಾಸಗೊಳಿಸಲ್ಪಟ್ಟಿವೆ. ಈ ವ್ಯತ್ಯಾಸವು ಮುಖ್ಯವಾಗಿ ಮಾದರಿ معماري ಮತ್ತು ತರಬೇತಿ ಪ್ರಕ್ರಿಯೆಗಳ ಭಿನ್ನತೆಯಿಂದ ಉಂಟಾಗುತ್ತದೆ. ಉದಾಹರಣೆಗೆ, ChatGPT ಎನ್‌ಕೋಡರ್-ಡಿಕೋಡರ್ ಚಟುವಟಿಕೆಯಲ್ಲಿ ಸ್ವಯಂ-ಗಮನ ಯಂತ್ರವನ್ನು ಬಳಸುತ್ತದೆ, ಆದರೆ Mistral 7B ಡಿಕೋಡರ್-ಮಾತ್ರ ಮಾದರಿಯಲ್ಲಿ ಸ್ಲೈಡಿಂಗ್ ವಿಂಡೋ ಗಮನವನ್ನು ಬಳಸುತ್ತದೆ, ಇದು ಹೆಚ್ಚು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ತರಬೇತಿಗೆ ಸಹಾಯ ಮಾಡುತ್ತದೆ. ಈ معماري ವ್ಯತ್ಯಾಸವು ಮಾದರಿಗಳ ಸಂಕೀರ್ಣತೆ ಮತ್ತು ಕಾರ್ಯಕ್ಷಮತೆಯ ಮೇಲೆ ಗಂಭೀರ ಪರಿಣಾಮ ಬೀರುತ್ತದೆ.

**ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ**

SLMಗಳು ಸಾಮಾನ್ಯವಾಗಿ ನಿರ್ದಿಷ್ಟ ಕ್ಷೇತ್ರಗಳಲ್ಲಿ ಕಾರ್ಯಕ್ಷಮತೆಯಿಗಾಗಿ ಸುಧಾರಿಸಲ್ಪಟ್ಟಿದ್ದು, ಅವು ಅತ್ಯಂತ ವಿಶೇಷೀಕೃತವಾಗಿವೆ ಆದರೆ ವಿವಿಧ ಜ್ಞಾನ ಕ್ಷೇತ್ರಗಳಲ್ಲಿ ವ್ಯಾಪಕ ಸಾಂದರ್ಭಿಕ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆಯಲ್ಲಿ ಸೀಮಿತವಾಗಿರಬಹುದು. ಇದಕ್ಕೆ ವಿರುದ್ಧವಾಗಿ, LLMಗಳು ಮಾನವ-ಹಾಗೆ ಬುದ್ಧಿಮತ್ತೆಯನ್ನು ಸಮಗ್ರ ಮಟ್ಟದಲ್ಲಿ ಅನುಕರಿಸಲು ಉದ್ದೇಶಿತವಾಗಿವೆ. ಅಪಾರ, ವೈವಿಧ್ಯಮಯ ಡೇಟಾಸೆಟ್‌ಗಳ ಮೇಲೆ ತರಬೇತಿಗೊಂಡ LLMಗಳು ವಿವಿಧ ಕ್ಷೇತ್ರಗಳಲ್ಲಿ ಉತ್ತಮ ಕಾರ್ಯನಿರ್ವಹಣೆಗೆ ವಿನ್ಯಾಸಗೊಳಿಸಲ್ಪಟ್ಟಿದ್ದು, ಹೆಚ್ಚಿನ ಬಹುಮುಖತೆ ಮತ್ತು ಹೊಂದಾಣಿಕೆಯನ್ನು ಒದಗಿಸುತ್ತವೆ. ಆದ್ದರಿಂದ, LLMಗಳು ನೈಸರ್ಗಿಕ ಭಾಷಾ ಪ್ರಕ್ರಿಯೆ ಮತ್ತು ಪ್ರೋಗ್ರಾಮಿಂಗ್ ಮುಂತಾದ ವ್ಯಾಪಕ ಕಾರ್ಯಗಳಿಗೆ ಸೂಕ್ತವಾಗಿವೆ.

**ಗಣನೆ**

LLMಗಳ ತರಬೇತಿ ಮತ್ತು ನಿಯೋಜನೆ ಸಂಪನ್ಮೂಲ-ತೀವ್ರ ಪ್ರಕ್ರಿಯೆಗಳಾಗಿದ್ದು, ದೊಡ್ಡ ಪ್ರಮಾಣದ GPU ಕ್ಲಸ್ಟರ್‌ಗಳನ್ನು ಅಗತ್ಯವಿರುತ್ತದೆ. ಉದಾಹರಣೆಗೆ, ChatGPT ಮಾದರಿಯನ್ನು ಶೂನ್ಯದಿಂದ ತರಬೇತಿಗೊಳಿಸಲು ಸಾವಿರಾರು GPUಗಳು ದೀರ್ಘಕಾಲದ ಅವಧಿಗೆ ಬೇಕಾಗಬಹುದು. ಇದಕ್ಕೆ ವಿರುದ್ಧವಾಗಿ, SLMಗಳು ತಮ್ಮ ಸಣ್ಣ ಪ್ಯಾರಾಮೀಟರ್ ಸಂಖ್ಯೆಯಿಂದ ಗಣನೀಯ ಸಂಪನ್ಮೂಲಗಳ ದೃಷ್ಟಿಯಿಂದ ಹೆಚ್ಚು ಪ್ರವೇಶಾರ್ಹವಾಗಿವೆ. Mistral 7B ಮುಂತಾದ ಮಾದರಿಗಳನ್ನು ಮಧ್ಯಮ GPU ಸಾಮರ್ಥ್ಯಗಳೊಂದಿಗೆ ಸ್ಥಳೀಯ ಯಂತ್ರಗಳಲ್ಲಿ ತರಬೇತಿಗೊಳಿಸಿ ಚಾಲನೆ ಮಾಡಬಹುದು, ಆದರೂ ತರಬೇತಿ ಇನ್ನೂ ಹಲವಾರು ಗಂಟೆಗಳ ಕಾಲ ಬಹು GPUಗಳಲ್ಲಿ ನಡೆಯುತ್ತದೆ.

**ಪಕ್ಷಪಾತ**

ಪಕ್ಷಪಾತವು LLMಗಳಲ್ಲಿ ತಿಳಿದಿರುವ ಸಮಸ್ಯೆಯಾಗಿದ್ದು, ಮುಖ್ಯವಾಗಿ ತರಬೇತಿ ಡೇಟಾದ ಸ್ವಭಾವದಿಂದ ಉಂಟಾಗುತ್ತದೆ. ಈ ಮಾದರಿಗಳು ಸಾಮಾನ್ಯವಾಗಿ ಇಂಟರ್ನೆಟ್‌ನಿಂದ ಲಭ್ಯವಿರುವ ಕಚ್ಚಾ, ಮುಕ್ತ ಡೇಟಾವನ್ನು ಅವಲಂಬಿಸುತ್ತವೆ, ಇದು ಕೆಲವು ಗುಂಪುಗಳನ್ನು ಅಲ್ಪಪ್ರತಿನಿಧಿಸುವುದು ಅಥವಾ ತಪ್ಪಾಗಿ ಪ್ರತಿನಿಧಿಸುವುದು, ತಪ್ಪು ಲೇಬಲಿಂಗ್ ಪರಿಚಯಿಸುವುದು, ಅಥವಾ ಉಪಭಾಷೆ, ಭೌಗೋಳಿಕ ವ್ಯತ್ಯಾಸಗಳು ಮತ್ತು ವ್ಯಾಕರಣ ನಿಯಮಗಳಿಂದ ಪ್ರಭಾವಿತ ಭಾಷಾ ಪಕ್ಷಪಾತಗಳನ್ನು ಪ್ರತಿಬಿಂಬಿಸುವುದು ಸಾಧ್ಯ. ಜೊತೆಗೆ, LLM معماريಗಳ ಸಂಕೀರ್ಣತೆ ಪಕ್ಷಪಾತವನ್ನು ಅನೈಚ್ಛಿಕವಾಗಿ ಹೆಚ್ಚಿಸಬಹುದು, ಇದು ಸೂಕ್ಷ್ಮ-ಸಂಯೋಜನೆಯಿಲ್ಲದೆ ಗಮನಾರ್ಹವಾಗದೆ ಇರಬಹುದು. ಇದಕ್ಕೆ ವಿರುದ್ಧವಾಗಿ, SLMಗಳು ನಿರ್ದಿಷ್ಟ ಕ್ಷೇತ್ರ-ನಿರ್ದಿಷ್ಟ ಡೇಟಾಸೆಟ್‌ಗಳ ಮೇಲೆ ತರಬೇತಿಗೊಂಡಿರುವುದರಿಂದ ಇಂತಹ ಪಕ್ಷಪಾತಗಳಿಗೆ ಕಡಿಮೆ ಒಳಗಾಗುತ್ತವೆ, ಆದರೂ ಸಂಪೂರ್ಣ ಮುಕ್ತವಾಗಿಲ್ಲ.

**ಇನ್ಫರೆನ್ಸ್**

SLMಗಳ ಕಡಿಮೆ ಗಾತ್ರವು ಇನ್ಫರೆನ್ಸ್ ವೇಗದಲ್ಲಿ ಮಹತ್ವದ ಲಾಭವನ್ನು ನೀಡುತ್ತದೆ, ಇದರಿಂದ ಅವು ಸ್ಥಳೀಯ ಹಾರ್ಡ್‌ವೇರ್‌ನಲ್ಲಿ ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಔಟ್‌ಪುಟ್‌ಗಳನ್ನು ರಚಿಸಬಹುದು, ವ್ಯಾಪಕ ಸಮಾಂತರ ಪ್ರಕ್ರಿಯೆ ಅಗತ್ಯವಿಲ್ಲದೆ. ಇದಕ್ಕೆ ವಿರುದ್ಧವಾಗಿ, LLMಗಳು ಗಾತ್ರ ಮತ್ತು ಸಂಕೀರ್ಣತೆಯಿಂದಾಗಿ ಸ್ವೀಕಾರಾರ್ಹ ಇನ್ಫರೆನ್ಸ್ ಸಮಯಗಳನ್ನು ಸಾಧಿಸಲು ದೊಡ್ಡ ಸಮಾಂತರ ಗಣನೀಯ ಸಂಪನ್ಮೂಲಗಳನ್ನು ಅಗತ್ಯವಿರುತ್ತದೆ. ಬಹು ಬಳಕೆದಾರರ ಸಮ್ಮಿಲನವು LLMಗಳ ಪ್ರತಿಕ್ರಿಯೆ ಸಮಯವನ್ನು ಮತ್ತಷ್ಟು ನಿಧಾನಗೊಳಿಸುತ್ತದೆ, ವಿಶೇಷವಾಗಿ ವ್ಯಾಪಕವಾಗಿ ನಿಯೋಜಿಸಿದಾಗ.

ಸಾರಾಂಶವಾಗಿ, LLMಗಳು ಮತ್ತು SLMಗಳು ಎರಡೂ ಯಂತ್ರ ಕಲಿಕೆಯ ಮೂಲಭೂತ ಆಧಾರದ ಮೇಲೆ ನಿರ್ಮಿತವಾಗಿದ್ದರೂ, ಮಾದರಿ ಗಾತ್ರ, ಸಂಪನ್ಮೂಲ ಅಗತ್ಯಗಳು, ಸಾಂದರ್ಭಿಕ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ, ಪಕ್ಷಪಾತದ ಪ್ರಭಾವ ಮತ್ತು ಇನ್ಫರೆನ್ಸ್ ವೇಗದ ದೃಷ್ಟಿಯಿಂದ ಬಹುಮಾನ್ಯವಾಗಿ ಭಿನ್ನವಾಗಿವೆ. ಈ ವ್ಯತ್ಯಾಸಗಳು ಅವುಗಳ ವಿಭಿನ್ನ ಬಳಕೆಗಳಿಗೆ ಹೊಂದಿಕೊಳ್ಳುವಿಕೆಯನ್ನು ಪ್ರತಿಬಿಂಬಿಸುತ್ತವೆ, LLMಗಳು ಹೆಚ್ಚು ಬಹುಮುಖವಾಗಿದ್ದರೂ ಸಂಪನ್ಮೂಲ-ಭಾರಿಯಾಗಿವೆ, ಮತ್ತು SLMಗಳು ಕಡಿಮೆ ಗಣನೀಯ ಬೇಡಿಕೆಗಳೊಂದಿಗೆ ಕ್ಷೇತ್ರ-ನಿರ್ದಿಷ್ಟ ಪರಿಣಾಮಕಾರಿತ್ವವನ್ನು ಒದಗಿಸುತ್ತವೆ.

***ಗಮನಿಸಿ: ಈ ಅಧ್ಯಾಯದಲ್ಲಿ, ನಾವು Microsoft Phi-3 / 3.5 ಅನ್ನು ಉದಾಹರಣೆಯಾಗಿ ಬಳಸಿಕೊಂಡು SLM ಅನ್ನು ಪರಿಚಯಿಸುವೆವು.***

## Phi-3 / Phi-3.5 ಕುಟುಂಬ ಪರಿಚಯ

Phi-3 / 3.5 ಕುಟುಂಬ ಮುಖ್ಯವಾಗಿ ಪಠ್ಯ, ದೃಷ್ಟಿ ಮತ್ತು ಏಜೆಂಟ್ (MoE) ಅನ್ವಯಿಕೆ ದೃಶ್ಯಾವಳಿಗಳನ್ನು ಗುರಿಯಾಗಿಸಿಕೊಂಡಿದೆ:

### Phi-3 / 3.5 ಸೂಚನೆ

ಮುಖ್ಯವಾಗಿ ಪಠ್ಯ ರಚನೆ, ಚಾಟ್ ಪೂರ್ಣಗೊಳಿಸುವಿಕೆ ಮತ್ತು ವಿಷಯ ಮಾಹಿತಿ ಹೊರತೆಗೆಯುವಿಕೆ ಮುಂತಾದ ಕಾರ್ಯಗಳಿಗೆ.

**Phi-3-mini**

3.8B ಭಾಷಾ ಮಾದರಿ Microsoft Azure AI Studio, Hugging Face ಮತ್ತು Ollama ನಲ್ಲಿ ಲಭ್ಯವಿದೆ. Phi-3 ಮಾದರಿಗಳು ಸಮಾನ ಮತ್ತು ದೊಡ್ಡ ಗಾತ್ರದ ಭಾಷಾ ಮಾದರಿಗಳಿಗಿಂತ ಪ್ರಮುಖ ಬೆಂಚ್‌ಮಾರ್ಕ್‌ಗಳಲ್ಲಿ ಬಹುಮಾನ್ಯವಾಗಿ ಉತ್ತಮ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ತೋರಿಸುತ್ತವೆ (ಕೆಳಗಿನ ಬೆಂಚ್‌ಮಾರ್ಕ್ ಸಂಖ್ಯೆಗಳು ನೋಡಿ, ಹೆಚ್ಚಿನ ಸಂಖ್ಯೆ ಉತ್ತಮ). Phi-3-mini ತನ್ನ ಗಾತ್ರದ ಎರಡು ಪಟ್ಟು ಮಾದರಿಗಳನ್ನು ಮೀರಿಸುತ್ತದೆ, ಮತ್ತು Phi-3-small ಮತ್ತು Phi-3-medium ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು, GPT-3.5 ಸಹಿತ, ಮೀರಿಸುತ್ತವೆ.

**Phi-3-small & medium**

ಮಾತ್ರ 7B ಪ್ಯಾರಾಮೀಟರ್‌ಗಳೊಂದಿಗೆ, Phi-3-small ವಿವಿಧ ಭಾಷಾ, ತರ್ಕ, ಕೋಡಿಂಗ್ ಮತ್ತು ಗಣಿತ ಬೆಂಚ್‌ಮಾರ್ಕ್‌ಗಳಲ್ಲಿ GPT-3.5T ಅನ್ನು ಮೀರಿಸುತ್ತದೆ.

14B ಪ್ಯಾರಾಮೀಟರ್‌ಗಳ Phi-3-medium ಈ ಪ್ರವೃತ್ತಿಯನ್ನು ಮುಂದುವರೆಸುತ್ತಿದ್ದು, Gemini 1.0 Pro ಅನ್ನು ಮೀರಿಸುತ್ತದೆ.

**Phi-3.5-mini**

ಇದನ್ನು Phi-3-mini ನ ಅಪ್‌ಗ್ರೇಡ್ ಎಂದು ಪರಿಗಣಿಸಬಹುದು. ಪ್ಯಾರಾಮೀಟರ್‌ಗಳು ಬದಲಾಗದಿದ್ದರೂ, ಇದು ಬಹುಭಾಷಾ ಬೆಂಬಲವನ್ನು ಸುಧಾರಿಸುತ್ತದೆ (20+ ಭಾಷೆಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ: ಅರೇಬಿಕ್, ಚೈನೀಸ್, ಚೆಕ್, ಡ್ಯಾನಿಶ್, ಡಚ್, ಇಂಗ್ಲಿಷ್, ಫಿನ್ನಿಷ್, ಫ್ರೆಂಚ್, ಜರ್ಮನ್, ಹೀಬ್ರೂ, ಹಂಗೇರಿಯನ್, ಇಟಾಲಿಯನ್, ಜಪಾನೀಸ್, ಕೊರಿಯನ್, ನಾರ್ವೇಜಿಯನ್, ಪೋಲಿಷ್, ಪೋರ್ಚುಗೀಸ್, ರಷ್ಯನ್, ಸ್ಪ್ಯಾನಿಷ್, ಸ್ವೀಡಿಷ್, ಥಾಯ್, ಟರ್ಕಿಷ್, ಉಕ್ರೇನಿಯನ್) ಮತ್ತು ದೀರ್ಘ ಸಾಂದರ್ಭಿಕತೆಗಾಗಿ ಬಲವಾದ ಬೆಂಬಲವನ್ನು ಸೇರಿಸುತ್ತದೆ.

3.8B ಪ್ಯಾರಾಮೀಟರ್‌ಗಳ Phi-3.5-mini ಸಮಾನ ಗಾತ್ರದ ಭಾಷಾ ಮಾದರಿಗಳನ್ನು ಮೀರಿಸುತ್ತದೆ ಮತ್ತು ಎರಡು ಪಟ್ಟು ಗಾತ್ರದ ಮಾದರಿಗಳ ಸಮತೋಲನದಲ್ಲಿದೆ.

### Phi-3 / 3.5 ದೃಷ್ಟಿ

Phi-3/3.5 ಸೂಚನೆ ಮಾದರಿಯನ್ನು Phiಯ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವ ಸಾಮರ್ಥ್ಯವೆಂದು ಪರಿಗಣಿಸಬಹುದು, ಮತ್ತು ದೃಷ್ಟಿ Phiಗೆ ಜಗತ್ತನ್ನು ಅರ್ಥಮಾಡಿಕೊಳ್ಳಲು ಕಣ್ಣುಗಳನ್ನು ನೀಡುತ್ತದೆ.

**Phi-3-ದೃಷ್ಟಿ**

4.2B ಪ್ಯಾರಾಮೀಟರ್‌ಗಳ Phi-3-ದೃಷ್ಟಿ ಈ ಪ್ರವೃತ್ತಿಯನ್ನು ಮುಂದುವರೆಸುತ್ತಿದ್ದು, Claude-3 Haiku ಮತ್ತು Gemini 1.0 Pro V ಮುಂತಾದ ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು ಸಾಮಾನ್ಯ ದೃಶ್ಯ ತರ್ಕ ಕಾರ್ಯಗಳಲ್ಲಿ, OCR, ಮತ್ತು ಟೇಬಲ್ ಮತ್ತು ಚಿತ್ರಣ ಗ್ರಹಣ ಕಾರ್ಯಗಳಲ್ಲಿ ಮೀರಿಸುತ್ತದೆ.

**Phi-3.5-ದೃಷ್ಟಿ**

Phi-3.5-ದೃಷ್ಟಿ ಕೂಡ Phi-3-ದೃಷ್ಟಿಯ ಅಪ್‌ಗ್ರೇಡ್ ಆಗಿದ್ದು, ಬಹುಚಿತ್ರ ಬೆಂಬಲವನ್ನು ಸೇರಿಸಿದೆ. ಇದನ್ನು ದೃಷ್ಟಿಯಲ್ಲಿ ಸುಧಾರಣೆ ಎಂದು ಪರಿಗಣಿಸಬಹುದು, ನೀವು ಚಿತ್ರಗಳನ್ನು ಮಾತ್ರವಲ್ಲ, ವೀಡಿಯೋಗಳನ್ನೂ ನೋಡಬಹುದು.

Phi-3.5-ದೃಷ್ಟಿ Claude-3.5 Sonnet ಮತ್ತು Gemini 1.5 Flash ಮುಂತಾದ ದೊಡ್ಡ ಮಾದರಿಗಳನ್ನು OCR, ಟೇಬಲ್ ಮತ್ತು ಚಾರ್ಟ್ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವ ಕಾರ್ಯಗಳಲ್ಲಿ ಮೀರಿಸುತ್ತದೆ ಮತ್ತು ಸಾಮಾನ್ಯ ದೃಶ್ಯ ಜ್ಞಾನ ತರ್ಕ ಕಾರ್ಯಗಳಲ್ಲಿ ಸಮತೋಲನದಲ್ಲಿದೆ. ಬಹು-ಫ್ರೇಮ್ ಇನ್ಪುಟ್ ಬೆಂಬಲಿಸುತ್ತದೆ, ಅಂದರೆ ಬಹುಚಿತ್ರ ಇನ್ಪುಟ್‌ಗಳ ಮೇಲೆ ತರ್ಕ ಮಾಡುತ್ತದೆ.

### Phi-3.5-MoE

***ನಿಪುಣರ ಮಿಶ್ರಣ (MoE)*** ಮಾದರಿಗಳನ್ನು ಕಡಿಮೆ ಗಣನೆ ಬಳಕೆಯಿಂದ ಪೂರ್ವ ತರಬೇತಿಗೊಳಿಸಲು ಸಾಧ್ಯವಾಗಿಸುತ್ತದೆ, ಅಂದರೆ ನೀವು ಅದೇ ಗಣನೆ ಬಜೆಟ್‌ನೊಂದಿಗೆ ಮಾದರಿ ಅಥವಾ ಡೇಟಾಸೆಟ್ ಗಾತ್ರವನ್ನು ಬಹಳಷ್ಟು ವಿಸ್ತರಿಸಬಹುದು. ವಿಶೇಷವಾಗಿ, MoE ಮಾದರಿ ತನ್ನ ದಟ್ಟ ಮಾದರಿಯ ಸಮಾನ ಗುಣಮಟ್ಟವನ್ನು ಪೂರ್ವ ತರಬೇತಿಯಲ್ಲಿ ಬಹಳ ವೇಗವಾಗಿ ಸಾಧಿಸಬೇಕು.

Phi-3.5-MoE 16x3.8B ನಿಪುಣ ಘಟಕಗಳನ್ನು ಹೊಂದಿದೆ. 6.6B ಸಕ್ರಿಯ ಪ್ಯಾರಾಮೀಟರ್‌ಗಳೊಂದಿಗೆ Phi-3.5-MoE ದೊಡ್ಡ ಮಾದರಿಗಳಷ್ಟು ತರ್ಕ, ಭಾಷಾ ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಮತ್ತು ಗಣಿತವನ್ನು ಸಾಧಿಸುತ್ತದೆ.

ನಾವು ವಿಭಿನ್ನ ದೃಶ್ಯಾವಳಿಗಳ ಆಧಾರದಲ್ಲಿ Phi-3/3.5 ಕುಟುಂಬ ಮಾದರಿಗಳನ್ನು ಬಳಸಬಹುದು. LLMಗೆ ವಿರುದ್ಧವಾಗಿ, ನೀವು Phi-3/3.5-mini ಅಥವಾ Phi-3/3.5-ದೃಷ್ಟಿಯನ್ನು ಎಡ್ಜ್ ಸಾಧನಗಳಲ್ಲಿ ನಿಯೋಜಿಸಬಹುದು.

## Phi-3/3.5 ಕುಟುಂಬ ಮಾದರಿಗಳನ್ನು ಹೇಗೆ ಬಳಸುವುದು

ನಾವು ವಿಭಿನ್ನ ದೃಶ್ಯಾವಳಿಗಳಲ್ಲಿ Phi-3/3.5 ಅನ್ನು ಬಳಸಲು ಆಶಿಸುತ್ತೇವೆ. ಮುಂದಿನ ಭಾಗದಲ್ಲಿ, ನಾವು ವಿಭಿನ್ನ ದೃಶ್ಯಾವಳಿಗಳ ಆಧಾರದಲ್ಲಿ Phi-3/3.5 ಅನ್ನು ಬಳಸುತ್ತೇವೆ.

![phi3](../../../translated_images/kn/phi3.655208c3186ae381.png)

### ಕ್ಲೌಡ್ API ಇನ್ಫರೆನ್ಸ್ ವ್ಯತ್ಯಾಸ

**GitHub ಮಾದರಿಗಳು**

GitHub ಮಾದರಿಗಳು ಅತ್ಯಂತ ನೇರ ಮಾರ್ಗವಾಗಿದೆ. ನೀವು GitHub ಮಾದರಿಗಳ ಮೂಲಕ Phi-3/3.5-ಸೂಚನೆ ಮಾದರಿಯನ್ನು ತ್ವರಿತವಾಗಿ ಪ್ರವೇಶಿಸಬಹುದು. Azure AI ಇನ್ಫರೆನ್ಸ್ SDK / OpenAI SDK ಜೊತೆಗೆ ಸಂಯೋಜಿಸಿ, ನೀವು ಕೋಡ್ ಮೂಲಕ APIಗೆ ಪ್ರವೇಶಿಸಿ Phi-3/3.5-ಸೂಚನೆ ಕರೆಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು. ನೀವು ಪ್ಲೇಗ್ರೌಂಡ್ ಮೂಲಕ ವಿಭಿನ್ನ ಪರಿಣಾಮಗಳನ್ನು ಪರೀಕ್ಷಿಸಬಹುದು.

- ಡೆಮೋ: ಚೀನೀ ದೃಶ್ಯಾವಳಿಗಳಲ್ಲಿ Phi-3-mini ಮತ್ತು Phi-3.5-mini ಪರಿಣಾಮಗಳ ಹೋಲಿಕೆ

![phi3](../../../translated_images/kn/gh1.126c6139713b622b.png)

![phi35](../../../translated_images/kn/gh2.07d7985af66f178d.png)

**Azure AI ಸ್ಟುಡಿಯೋ**

ಅಥವಾ, ನಾವು ದೃಷ್ಟಿ ಮತ್ತು MoE ಮಾದರಿಗಳನ್ನು ಬಳಸಲು ಬಯಸಿದರೆ, Azure AI ಸ್ಟುಡಿಯೋ ಬಳಸಿ ಕರೆಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು. ಆಸಕ್ತರಾಗಿದ್ದರೆ, ನೀವು Phi-3 ಕುಕ್‌ಬುಕ್ ಓದಿ Azure AI ಸ್ಟುಡಿಯೋ ಮೂಲಕ Phi-3/3.5 ಸೂಚನೆ, ದೃಷ್ಟಿ, MoE ಕರೆಗಳನ್ನು ಹೇಗೆ ಮಾಡುವುದು ಎಂದು ಕಲಿಯಬಹುದು [ಈ ಲಿಂಕ್ ಕ್ಲಿಕ್ ಮಾಡಿ](https://github.com/microsoft/Phi-3CookBook/blob/main/md/02.QuickStart/AzureAIStudio_QuickStart.md?WT.mc_id=academic-105485-koreyst)

**NVIDIA NIM**

Azure ಮತ್ತು GitHub ನೀಡುವ ಕ್ಲೌಡ್ ಆಧಾರಿತ ಮಾದರಿ ಕ್ಯಾಟಲಾಗ್ ಪರಿಹಾರಗಳ ಹೊರತಾಗಿ, ನೀವು [NVIDIA NIM](https://developer.nvidia.com/nim?WT.mc_id=academic-105485-koreyst) ಬಳಸಿ ಸಂಬಂಧಿತ ಕರೆಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು. ನೀವು NVIDIA NIM ಗೆ ಭೇಟಿ ನೀಡಿ Phi-3/3.5 ಕುಟುಂಬದ API ಕರೆಗಳನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು. NVIDIA NIM (NVIDIA ಇನ್ಫರೆನ್ಸ್ ಮೈಕ್ರೋಸರ್ವಿಸಸ್) ವಿವಿಧ ಪರಿಸರಗಳಲ್ಲಿ, ಕ್ಲೌಡ್‌ಗಳು, ಡೇಟಾ ಸೆಂಟರ್‌ಗಳು ಮತ್ತು ವರ್ಕ್‌ಸ್ಟೇಷನ್‌ಗಳಲ್ಲಿಯೂ, AI ಮಾದರಿಗಳನ್ನು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ನಿಯೋಜಿಸಲು ಸಹಾಯ ಮಾಡುವ ವೇಗವರ್ಧಿತ ಇನ್ಫರೆನ್ಸ್ ಮೈಕ್ರೋಸರ್ವಿಸಸ್‌ಗಳ ಸಮೂಹವಾಗಿದೆ.

NVIDIA NIMನ ಕೆಲವು ಪ್ರಮುಖ ವೈಶಿಷ್ಟ್ಯಗಳು:

- **ನಿಯೋಜನೆ ಸುಲಭತೆ:** NIM ಒಂದು ಆದೇಶದಿಂದ AI ಮಾದರಿಗಳನ್ನು ನಿಯೋಜಿಸಲು ಅನುಮತಿಸುತ್ತದೆ, ಇದರಿಂದ ಇತ್ತೀಚಿನ ಕಾರ್ಯಪ್ರವಾಹಗಳಲ್ಲಿ ಸುಲಭವಾಗಿ ಸಂಯೋಜಿಸಬಹುದು.
- **ಆಪ್ಟಿಮೈಸ್ ಮಾಡಿದ ಕಾರ್ಯಕ್ಷಮತೆ:** ಇದು NVIDIAಯ ಪೂರ್ವ-ಆಪ್ಟಿಮೈಸ್ ಮಾಡಿದ ಇನ್ಫರೆನ್ಸ್ ಎಂಜಿನ್‌ಗಳು, TensorRT ಮತ್ತು TensorRT-LLM ಮುಂತಾದವುಗಳನ್ನು ಬಳಸಿಕೊಂಡು ಕಡಿಮೆ ವಿಳಂಬ ಮತ್ತು ಹೆಚ್ಚಿನ ಥ್ರೂಪುಟ್ ಅನ್ನು ಖಚಿತಪಡಿಸುತ್ತದೆ.
- **ವಿಸ್ತರಣೀಯತೆ:** NIM ಕುಬೆರ್ನೇಟಿಸ್‌ನಲ್ಲಿ ಸ್ವಯಂ-ವಿಸ್ತರಣೆ ಬೆಂಬಲಿಸುತ್ತದೆ, ಇದರಿಂದ ಬದಲಾಗುವ ಕೆಲಸದ ಭಾರವನ್ನು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ನಿರ್ವಹಿಸಬಹುದು.
- **ಭದ್ರತೆ ಮತ್ತು ನಿಯಂತ್ರಣ:** ಸಂಸ್ಥೆಗಳು ತಮ್ಮ ಸ್ವಂತ ನಿರ್ವಹಿತ ಮೂಲಸೌಕರ್ಯದಲ್ಲಿ NIM ಮೈಕ್ರೋಸರ್ವಿಸ್ಗಳನ್ನು ಸ್ವಯಂ-ಹೋಸ್ಟ್ ಮಾಡುವ ಮೂಲಕ ತಮ್ಮ ಡೇಟಾ ಮತ್ತು ಅಪ್ಲಿಕೇಶನ್‌ಗಳ ಮೇಲೆ ನಿಯಂತ್ರಣವನ್ನು ಕಾಯ್ದುಕೊಳ್ಳಬಹುದು.
- **ಪ್ರಮಾಣಿತ APIಗಳು:** NIM ಕೈಗಾರಿಕಾ ಪ್ರಮಾಣಿತ APIಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ, ಇದರಿಂದ ಚಾಟ್‌ಬಾಟ್‌ಗಳು, AI ಸಹಾಯಕರು ಮತ್ತು ಇನ್ನಷ್ಟು AI ಅಪ್ಲಿಕೇಶನ್‌ಗಳನ್ನು ಸುಲಭವಾಗಿ ನಿರ್ಮಿಸಲು ಮತ್ತು ಸಂಯೋಜಿಸಲು ಸಾಧ್ಯವಾಗುತ್ತದೆ.

NIM NVIDIA AI ಎಂಟರ್‌ಪ್ರೈಸ್‌ನ ಭಾಗವಾಗಿದ್ದು, AI ಮಾದರಿಗಳನ್ನು ನಿಯೋಜಿಸುವುದು ಮತ್ತು ಕಾರ್ಯಗತಗೊಳಿಸುವಿಕೆಯನ್ನು ಸರಳಗೊಳಿಸುವುದನ್ನು ಉದ್ದೇಶಿಸಿದೆ, ಮತ್ತು ಅವುಗಳನ್ನು NVIDIA GPUಗಳ ಮೇಲೆ ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಚಾಲನೆ ಮಾಡುತ್ತದೆ.

- ಡೆಮೋ: Nividia NIM ಬಳಸಿ Phi-3.5-Vision-API ಅನ್ನು ಕರೆಮಾಡುವುದು [[ಈ ಲಿಂಕ್ ಕ್ಲಿಕ್ ಮಾಡಿ](./python/Phi-3-Vision-Nividia-NIM.ipynb?WT.mc_id=academic-105485-koreyst)]


### ಸ್ಥಳೀಯ ಪರಿಸರದಲ್ಲಿ Phi-3/3.5 ಇನ್ಫರೆನ್ಸ್
Phi-3 ಅಥವಾ GPT-3 ಹೋಲುವ ಯಾವುದೇ ಭಾಷಾ ಮಾದರಿಯ ಇನ್ಫರೆನ್ಸ್ ಎಂದರೆ, ಅದು ಪಡೆದ ಇನ್‌ಪುಟ್ ಆಧರಿಸಿ ಪ್ರತಿಕ್ರಿಯೆಗಳು ಅಥವಾ ಭವಿಷ್ಯವಾಣಿಗಳನ್ನು ರಚಿಸುವ ಪ್ರಕ್ರಿಯೆ. ನೀವು Phi-3 ಗೆ ಪ್ರಾಂಪ್ಟ್ ಅಥವಾ ಪ್ರಶ್ನೆಯನ್ನು ನೀಡಿದಾಗ, ಅದು ತನ್ನ ತರಬೇತುಗೊಂಡ ನ್ಯೂರಲ್ ನೆಟ್‌ವರ್ಕ್ ಅನ್ನು ಬಳಸಿಕೊಂಡು ತರಬೇತುಗೊಂಡ ಡೇಟಾದಲ್ಲಿನ ಮಾದರಿಗಳು ಮತ್ತು ಸಂಬಂಧಗಳನ್ನು ವಿಶ್ಲೇಷಿಸಿ ಅತ್ಯಂತ ಸಾಧ್ಯವಿರುವ ಮತ್ತು ಸಂಬಂಧಿತ ಪ್ರತಿಕ್ರಿಯೆಯನ್ನು ಊಹಿಸುತ್ತದೆ.

**Hugging Face Transformer**
Hugging Face Transformers ಒಂದು ಶಕ್ತಿಶಾಲಿ ಗ್ರಂಥಾಲಯವಾಗಿದ್ದು, ನೈಸರ್ಗಿಕ ಭಾಷಾ ಪ್ರಕ್ರಿಯೆ (NLP) ಮತ್ತು ಇತರ ಯಂತ್ರ ಅಧ್ಯಯನ ಕಾರ್ಯಗಳಿಗೆ ವಿನ್ಯಾಸಗೊಳಿಸಲಾಗಿದೆ. ಇದರ ಪ್ರಮುಖ ಅಂಶಗಳು ಇವು:

1. **ಪೂರ್ವ-ತರಬೇತುಗೊಂಡ ಮಾದರಿಗಳು**: ಪಠ್ಯ ವರ್ಗೀಕರಣ, ಹೆಸರು ಗುರುತಿಸುವಿಕೆ, ಪ್ರಶ್ನೆ ಉತ್ತರ, ಸಾರಾಂಶ, ಅನುವಾದ ಮತ್ತು ಪಠ್ಯ ರಚನೆ ಸೇರಿದಂತೆ ವಿವಿಧ ಕಾರ್ಯಗಳಿಗೆ ಬಳಸಬಹುದಾದ ಸಾವಿರಾರು ಪೂರ್ವ-ತರಬೇತುಗೊಂಡ ಮಾದರಿಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ.

2. **ಫ್ರೇಮ್ವರ್ಕ್ ಪರಸ್ಪರ ಕಾರ್ಯಕ್ಷಮತೆ**: ಗ್ರಂಥಾಲಯವು PyTorch, TensorFlow ಮತ್ತು JAX ಸೇರಿದಂತೆ ಹಲವಾರು ಡೀಪ್ ಲರ್ನಿಂಗ್ ಫ್ರೇಮ್ವರ್ಕ್‌ಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ. ಇದರಿಂದ ನೀವು ಒಂದು ಫ್ರೇಮ್ವರ್ಕ್‌ನಲ್ಲಿ ಮಾದರಿಯನ್ನು ತರಬೇತುಗೊಂಡು ಮತ್ತೊಂದರಲ್ಲಿ ಬಳಸಬಹುದು.

3. **ಬಹುಮಾಧ್ಯಮ ಸಾಮರ್ಥ್ಯಗಳು**: NLP ಹೊರತುಪಡಿಸಿ, Hugging Face Transformers ಕಂಪ್ಯೂಟರ್ ದೃಷ್ಟಿ (ಉದಾ: ಚಿತ್ರ ವರ್ಗೀಕರಣ, ವಸ್ತು ಪತ್ತೆ) ಮತ್ತು ಧ್ವನಿ ಪ್ರಕ್ರಿಯೆ (ಉದಾ: ಮಾತು ಗುರುತಿಸುವಿಕೆ, ಧ್ವನಿ ವರ್ಗೀಕರಣ) ಕಾರ್ಯಗಳನ್ನು ಸಹ ಬೆಂಬಲಿಸುತ್ತದೆ.

4. **ಬಳಕೆ ಸುಲಭತೆ**: ಗ್ರಂಥಾಲಯವು ಮಾದರಿಗಳನ್ನು ಸುಲಭವಾಗಿ ಡೌನ್‌ಲೋಡ್ ಮಾಡಿ ಸೂಕ್ಷ್ಮಗೊಳಿಸಲು APIಗಳು ಮತ್ತು ಉಪಕರಣಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ, ಇದರಿಂದ ಆರಂಭಿಕರು ಮತ್ತು ತಜ್ಞರು ಎರಡರಿಗೂ ಸುಲಭವಾಗುತ್ತದೆ.

5. **ಸಮುದಾಯ ಮತ್ತು ಸಂಪನ್ಮೂಲಗಳು**: Hugging Face ಗೆ ಸಕ್ರಿಯ ಸಮುದಾಯ ಮತ್ತು ವ್ಯಾಪಕ ಡಾಕ್ಯುಮೆಂಟೇಶನ್, ಟ್ಯುಟೋರಿಯಲ್ಗಳು ಮತ್ತು ಮಾರ್ಗದರ್ಶಿಗಳು ಇವೆ, ಬಳಕೆದಾರರು ಪ್ರಾರಂಭಿಸಲು ಮತ್ತು ಗ್ರಂಥಾಲಯವನ್ನು ಅತ್ಯುತ್ತಮವಾಗಿ ಬಳಸಲು ಸಹಾಯ ಮಾಡುತ್ತವೆ.
[ಅಧಿಕೃತ ಡಾಕ್ಯುಮೆಂಟೇಶನ್](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) ಅಥವಾ ಅವರ [GitHub ಸಂಗ್ರಹಾಲಯ](https://github.com/huggingface/transformers?WT.mc_id=academic-105485-koreyst).

ಇದು ಅತ್ಯಂತ ಸಾಮಾನ್ಯವಾಗಿ ಬಳಸುವ ವಿಧಾನವಾಗಿದ್ದು, ಇದಕ್ಕೆ GPU ವೇಗವರ್ಧನೆ ಅಗತ್ಯವಿದೆ. ದೃಶ್ಯ ಮತ್ತು MoEಂತಹ ದೃಶ್ಯಗಳು ಬಹಳಷ್ಟು ಗಣನೆಗಳನ್ನು ಅಗತ್ಯವಿರುವುದರಿಂದ, ಅವುಗಳನ್ನು ಪ್ರಮಾಣೀಕರಿಸದಿದ್ದರೆ CPU ನಲ್ಲಿ ಬಹಳ ಮಿತಿಯಾಗಿರುತ್ತದೆ.


- ಡೆಮೋ: Transformer ಬಳಸಿ Phi-3.5-Instuct ಅನ್ನು ಕರೆಮಾಡುವುದು [ಈ ಲಿಂಕ್ ಕ್ಲಿಕ್ ಮಾಡಿ](./python/phi35-instruct-demo.ipynb?WT.mc_id=academic-105485-koreyst)

- ಡೆಮೋ: Transformer ಬಳಸಿ Phi-3.5-Vision ಅನ್ನು ಕರೆಮಾಡುವುದು [ಈ ಲಿಂಕ್ ಕ್ಲಿಕ್ ಮಾಡಿ](./python/phi35-vision-demo.ipynb?WT.mc_id=academic-105485-koreyst)

- ಡೆಮೋ: Transformer ಬಳಸಿ Phi-3.5-MoE ಅನ್ನು ಕರೆಮಾಡುವುದು [ಈ ಲಿಂಕ್ ಕ್ಲಿಕ್ ಮಾಡಿ](./python/phi35_moe_demo.ipynb?WT.mc_id=academic-105485-koreyst)

**Ollama**
[Ollama](https://ollama.com/?WT.mc_id=academic-105485-koreyst) ನಿಮ್ಮ ಯಂತ್ರದಲ್ಲಿ ಸ್ಥಳೀಯವಾಗಿ ದೊಡ್ಡ ಭಾಷಾ ಮಾದರಿಗಳನ್ನು (LLMs) ಸುಲಭವಾಗಿ ಚಾಲನೆ ಮಾಡಲು ವಿನ್ಯಾಸಗೊಳಿಸಿದ ವೇದಿಕೆ. ಇದು Llama 3.1, Phi 3, Mistral, ಮತ್ತು Gemma 2 ಸೇರಿದಂತೆ ವಿವಿಧ ಮಾದರಿಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ. ವೇದಿಕೆ ಮಾದರಿ ತೂಕಗಳು, ಸಂರಚನೆ ಮತ್ತು ಡೇಟಾವನ್ನು ಒಟ್ಟಾಗಿ ಪ್ಯಾಕೇಜ್ ಮಾಡಿ ಪ್ರಕ್ರಿಯೆಯನ್ನು ಸರಳಗೊಳಿಸುತ್ತದೆ, ಬಳಕೆದಾರರಿಗೆ ತಮ್ಮದೇ ಮಾದರಿಗಳನ್ನು ಕಸ್ಟಮೈಸ್ ಮಾಡಿ ರಚಿಸಲು ಸುಲಭವಾಗುತ್ತದೆ. Ollama macOS, Linux ಮತ್ತು Windows ಗಾಗಿ ಲಭ್ಯವಿದೆ. ಕ್ಲೌಡ್ ಸೇವೆಗಳಿಗೆ ಅವಲಂಬಿಸದೆ LLMಗಳನ್ನು ಪ್ರಯೋಗಿಸಲು ಅಥವಾ ನಿಯೋಜಿಸಲು ಇದು ಅತ್ಯುತ್ತಮ ಸಾಧನ. Ollama ನೇರವಾದ ವಿಧಾನವಾಗಿದ್ದು, ಕೆಳಗಿನ ಹೇಳಿಕೆಯನ್ನು ಕಾರ್ಯಗತಗೊಳಿಸುವುದೇ ಸಾಕು.


```bash

ollama run phi3.5

```


**GenAI ಗಾಗಿ ONNX ರನ್‌ಟೈಮ್**

[ONNX Runtime](https://github.com/microsoft/onnxruntime-genai?WT.mc_id=academic-105485-koreyst) ಒಂದು ಕ್ರಾಸ್-ಪ್ಲಾಟ್‌ಫಾರ್ಮ್ ಇನ್ಫರೆನ್ಸ್ ಮತ್ತು ತರಬೇತಿ ಯಂತ್ರ-ಅಧ್ಯಯನ ವೇಗವರ್ಧಕ. ಜನರೇಟಿವ್ AI ಗಾಗಿ ONNX Runtime (GENAI) ಒಂದು ಶಕ್ತಿಶಾಲಿ ಸಾಧನವಾಗಿದ್ದು, ವಿವಿಧ ವೇದಿಕೆಗಳಲ್ಲಿ ಜನರೇಟಿವ್ AI ಮಾದರಿಗಳನ್ನು ಪರಿಣಾಮಕಾರಿಯಾಗಿ ಚಾಲನೆ ಮಾಡಲು ಸಹಾಯ ಮಾಡುತ್ತದೆ.

## ONNX Runtime ಎಂದರೇನು?
ONNX Runtime ಒಂದು ಓಪನ್-ಸೋರ್ಸ್ ಯೋಜನೆಯಾಗಿದ್ದು, ಯಂತ್ರ-ಅಧ್ಯಯನ ಮಾದರಿಗಳ ಉನ್ನತ-ಕಾರ್ಯಕ್ಷಮ ಇನ್ಫರೆನ್ಸ್ ಅನ್ನು ಸಕ್ರಿಯಗೊಳಿಸುತ್ತದೆ. ಇದು Open Neural Network Exchange (ONNX) ಫಾರ್ಮ್ಯಾಟ್‌ನಲ್ಲಿನ ಮಾದರಿಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ, ಇದು ಯಂತ್ರ-ಅಧ್ಯಯನ ಮಾದರಿಗಳನ್ನು ಪ್ರತಿನಿಧಿಸುವ ಮಾನದಂಡವಾಗಿದೆ. ONNX Runtime ಇನ್ಫರೆನ್ಸ್ ಗ್ರಾಹಕರ ಅನುಭವಗಳನ್ನು ವೇಗಗೊಳಿಸಿ ವೆಚ್ಚಗಳನ್ನು ಕಡಿಮೆ ಮಾಡಬಹುದು, PyTorch ಮತ್ತು TensorFlow/Keras ಸೇರಿದಂತೆ ಡೀಪ್ ಲರ್ನಿಂಗ್ ಫ್ರೇಮ್ವರ್ಕ್‌ಗಳಿಂದ ಮಾದರಿಗಳನ್ನು ಮತ್ತು scikit-learn, LightGBM, XGBoost ಮುಂತಾದ ಶ್ರೇಣಿಯ ಯಂತ್ರ-ಅಧ್ಯಯನ ಗ್ರಂಥಾಲಯಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ. ONNX Runtime ವಿಭಿನ್ನ ಹಾರ್ಡ್‌ವೇರ್, ಡ್ರೈವರ್‌ಗಳು ಮತ್ತು ಕಾರ್ಯಾಚರಣಾ ವ್ಯವಸ್ಥೆಗಳೊಂದಿಗೆ ಹೊಂದಿಕೊಳ್ಳುತ್ತದೆ ಮತ್ತು ಹಾರ್ಡ್‌ವೇರ್ ವೇಗವರ್ಧಕಗಳನ್ನು ಬಳಸಿಕೊಂಡು ಗರಾಫ್ ಆಪ್ಟಿಮೈಜೆಷನ್‌ಗಳು ಮತ್ತು ಪರಿವರ್ತನೆಗಳೊಂದಿಗೆ ಅತ್ಯುತ್ತಮ ಕಾರ್ಯಕ್ಷಮತೆಯನ್ನು ಒದಗಿಸುತ್ತದೆ.

## ಜನರೇಟಿವ್ AI ಎಂದರೇನು?
ಜನರೇಟಿವ್ AI ಎಂದರೆ ತರಬೇತುಗೊಂಡ ಡೇಟಾದ ಆಧಾರದ ಮೇಲೆ ಹೊಸ ವಿಷಯವನ್ನು ರಚಿಸುವ AI ವ್ಯವಸ್ಥೆಗಳು, ಉದಾಹರಣೆಗೆ ಪಠ್ಯ, ಚಿತ್ರಗಳು ಅಥವಾ ಸಂಗೀತ. ಉದಾಹರಣೆಗಳಿಗೆ GPT-3 ಹೋಲುವ ಭಾಷಾ ಮಾದರಿಗಳು ಮತ್ತು Stable Diffusion ಹೋಲುವ ಚಿತ್ರ ರಚನಾ ಮಾದರಿಗಳು ಸೇರಿವೆ. ONNX Runtime for GenAI ಗ್ರಂಥಾಲಯವು ONNX ಮಾದರಿಗಳಿಗಾಗಿ ಜನರೇಟಿವ್ AI ಲೂಪ್ ಅನ್ನು ಒದಗಿಸುತ್ತದೆ, ಇದರಲ್ಲಿ ONNX Runtime ಇನ್ಫರೆನ್ಸ್, ಲೋಗಿಟ್ ಪ್ರಕ್ರಿಯೆ, ಹುಡುಕಾಟ ಮತ್ತು ಮಾದರಿ ಆಯ್ಕೆ, ಮತ್ತು KV ಕ್ಯಾಶೆ ನಿರ್ವಹಣೆ ಸೇರಿವೆ.

## ONNX Runtime for GENAI
ONNX Runtime for GENAI ONNX Runtime ನ ಸಾಮರ್ಥ್ಯಗಳನ್ನು ವಿಸ್ತರಿಸಿ ಜನರೇಟಿವ್ AI ಮಾದರಿಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ. ಪ್ರಮುಖ ವೈಶಿಷ್ಟ್ಯಗಳು:

- **ವಿಸ್ತೃತ ವೇದಿಕೆ ಬೆಂಬಲ:** Windows, Linux, macOS, Android ಮತ್ತು iOS ಸೇರಿದಂತೆ ವಿವಿಧ ವೇದಿಕೆಗಳಲ್ಲಿ ಕಾರ್ಯನಿರ್ವಹಿಸುತ್ತದೆ.
- **ಮಾದರಿ ಬೆಂಬಲ:** LLaMA, GPT-Neo, BLOOM ಮತ್ತು ಇನ್ನಷ್ಟು ಜನಪ್ರಿಯ ಜನರೇಟಿವ್ AI ಮಾದರಿಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ.
- **ಕಾರ್ಯಕ್ಷಮತೆ ಆಪ್ಟಿಮೈಜೆಷನ್:** NVIDIA GPUಗಳು, AMD GPUಗಳು ಮತ್ತು ಇತರ ಹಾರ್ಡ್‌ವೇರ್ ವೇಗವರ್ಧಕಗಳಿಗೆ ಆಪ್ಟಿಮೈಜೆಷನ್‌ಗಳನ್ನು ಒಳಗೊಂಡಿದೆ.
- **ಬಳಕೆ ಸುಲಭತೆ:** ಅಪ್ಲಿಕೇಶನ್‌ಗಳಲ್ಲಿ ಸುಲಭವಾಗಿ ಸಂಯೋಜಿಸಲು APIಗಳನ್ನು ಒದಗಿಸುತ್ತದೆ, ಕಡಿಮೆ ಕೋಡ್‌ನೊಂದಿಗೆ ಪಠ್ಯ, ಚಿತ್ರಗಳು ಮತ್ತು ಇತರ ವಿಷಯಗಳನ್ನು ರಚಿಸಲು ಅನುಮತಿಸುತ್ತದೆ.
- ಬಳಕೆದಾರರು generate() ಎಂಬ ಉನ್ನತ ಮಟ್ಟದ ವಿಧಾನವನ್ನು ಕರೆಮಾಡಬಹುದು ಅಥವಾ ಮಾದರಿಯ ಪ್ರತಿ ಪುನರಾವೃತ್ತಿಯನ್ನು ಲೂಪ್‌ನಲ್ಲಿ ನಡೆಸಬಹುದು, ಪ್ರತಿ ಬಾರಿ ಒಂದು ಟೋಕನ್ ರಚಿಸಿ, ಮತ್ತು ಐಚ್ಛಿಕವಾಗಿ ಲೂಪ್ ಒಳಗೆ ಜನರೇಷನ್ ಪರಿಮಾಣಗಳನ್ನು ನವೀಕರಿಸಬಹುದು.
- ONNX ರನ್‌ಟೈಮ್ ಗ್ರೀಡಿ/ಬೀಮ್ ಹುಡುಕಾಟ ಮತ್ತು TopP, TopK ಮಾದರಿ ಆಯ್ಕೆಗಳನ್ನು ಬೆಂಬಲಿಸುತ್ತದೆ ಮತ್ತು ಪುನರಾವೃತ್ತಿ ದಂಡನೆಗಳಂತಹ ಲೋಗಿಟ್ ಪ್ರಕ್ರಿಯೆಯನ್ನು ಒಳಗೊಂಡಿದೆ. ನೀವು ಸುಲಭವಾಗಿ ಕಸ್ಟಮ್ ಸ್ಕೋರಿಂಗ್ ಅನ್ನು ಕೂಡ ಸೇರಿಸಬಹುದು.

## ಪ್ರಾರಂಭಿಸುವುದು
ONNX Runtime for GENAI ಪ್ರಾರಂಭಿಸಲು, ಈ ಹಂತಗಳನ್ನು ಅನುಸರಿಸಬಹುದು:

### ONNX Runtime ಅನ್ನು ಸ್ಥಾಪಿಸಿ:
```Python
pip install onnxruntime
```
### ಜನರೇಟಿವ್ AI ವಿಸ್ತರಣೆಗಳನ್ನು ಸ್ಥಾಪಿಸಿ:
```Python
pip install onnxruntime-genai
```

### ಮಾದರಿಯನ್ನು ಚಾಲನೆ ಮಾಡಿ: Python ನಲ್ಲಿ ಸರಳ ಉದಾಹರಣೆ ಇಲ್ಲಿದೆ:
```Python
import onnxruntime_genai as og

model = og.Model('path_to_your_model.onnx')

tokenizer = og.Tokenizer(model)

input_text = "Hello, how are you?"

input_tokens = tokenizer.encode(input_text)

output_tokens = model.generate(input_tokens)

output_text = tokenizer.decode(output_tokens)

print(output_text) 
```
### ಡೆಮೋ: ONNX Runtime GenAI ಬಳಸಿ Phi-3.5-Vision ಅನ್ನು ಕರೆಮಾಡುವುದು


```python

import onnxruntime_genai as og

model_path = './Your Phi-3.5-vision-instruct ONNX Path'

img_path = './Your Image Path'

model = og.Model(model_path)

processor = model.create_multimodal_processor()

tokenizer_stream = processor.create_stream()

text = "Your Prompt"

prompt = "<|user|>\n"

prompt += "<|image_1|>\n"

prompt += f"{text}<|end|>\n"

prompt += "<|assistant|>\n"

image = og.Images.open(img_path)

inputs = processor(prompt, images=image)

params = og.GeneratorParams(model)

params.set_inputs(inputs)

params.set_search_options(max_length=3072)

generator = og.Generator(model, params)

while not generator.is_done():

    generator.compute_logits()
    
    generator.generate_next_token()

    new_token = generator.get_next_tokens()[0]
    
    code += tokenizer_stream.decode(new_token)
    
    print(tokenizer_stream.decode(new_token), end='', flush=True)

```


**ಇತರೆಗಳು**

ONNX Runtime ಮತ್ತು Ollama ಉಲ್ಲೇಖ ವಿಧಾನಗಳ ಜೊತೆಗೆ, ನಾವು ವಿವಿಧ ತಯಾರಕರಿಂದ ಒದಗಿಸಲಾದ ಮಾದರಿ ಉಲ್ಲೇಖ ವಿಧಾನಗಳ ಆಧಾರದ ಮೇಲೆ ಪ್ರಮಾಣಾತ್ಮಕ ಮಾದರಿಗಳ ಉಲ್ಲೇಖವನ್ನು ಪೂರ್ಣಗೊಳಿಸಬಹುದು. ಉದಾಹರಣೆಗೆ Apple MLX ಫ್ರೇಮ್ವರ್ಕ್ Apple Metal ಜೊತೆಗೆ, Qualcomm QNN NPU ಜೊತೆಗೆ, Intel OpenVINO CPU/GPU ಜೊತೆಗೆ ಇತ್ಯಾದಿ. ನೀವು ಇನ್ನಷ್ಟು ವಿಷಯವನ್ನು [Phi-3 Cookbook](https://github.com/microsoft/phi-3cookbook?WT.mc_id=academic-105485-koreyst) ನಿಂದ ಪಡೆಯಬಹುದು.


## ಇನ್ನಷ್ಟು

ನಾವು Phi-3/3.5 ಕುಟುಂಬದ ಮೂಲಭೂತಗಳನ್ನು ಕಲಿತಿದ್ದೇವೆ, ಆದರೆ SLM ಬಗ್ಗೆ ಇನ್ನಷ್ಟು ತಿಳಿಯಲು ಹೆಚ್ಚಿನ ಜ್ಞಾನ ಬೇಕಾಗುತ್ತದೆ. ಉತ್ತರಗಳನ್ನು ನೀವು Phi-3 Cookbook ನಲ್ಲಿ ಕಂಡುಹಿಡಿಯಬಹುದು. ನೀವು ಇನ್ನಷ್ಟು ತಿಳಿಯಲು ಬಯಸಿದರೆ, ದಯವಿಟ್ಟು [Phi-3 Cookbook](https://github.com/microsoft/phi-3cookbook?WT.mc_id=academic-105485-koreyst) ಗೆ ಭೇಟಿ ನೀಡಿ.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**ಅಸ್ವೀಕರಣ**:  
ಈ ದಸ್ತಾವೇಜು AI ಅನುವಾದ ಸೇವೆ [Co-op Translator](https://github.com/Azure/co-op-translator) ಬಳಸಿ ಅನುವಾದಿಸಲಾಗಿದೆ. ನಾವು ನಿಖರತೆಯಿಗಾಗಿ ಪ್ರಯತ್ನಿಸುತ್ತಿದ್ದರೂ, ಸ್ವಯಂಚಾಲಿತ ಅನುವಾದಗಳಲ್ಲಿ ದೋಷಗಳು ಅಥವಾ ತಪ್ಪುಗಳು ಇರಬಹುದು ಎಂದು ದಯವಿಟ್ಟು ಗಮನಿಸಿ. ಮೂಲ ಭಾಷೆಯಲ್ಲಿರುವ ಮೂಲ ದಸ್ತಾವೇಜನ್ನು ಅಧಿಕೃತ ಮೂಲವೆಂದು ಪರಿಗಣಿಸಬೇಕು. ಮಹತ್ವದ ಮಾಹಿತಿಗಾಗಿ, ವೃತ್ತಿಪರ ಮಾನವ ಅನುವಾದವನ್ನು ಶಿಫಾರಸು ಮಾಡಲಾಗುತ್ತದೆ. ಈ ಅನುವಾದ ಬಳಕೆಯಿಂದ ಉಂಟಾಗುವ ಯಾವುದೇ ತಪ್ಪು ಅರ್ಥಮಾಡಿಕೊಳ್ಳುವಿಕೆ ಅಥವಾ ತಪ್ಪು ವಿವರಣೆಗಳಿಗೆ ನಾವು ಹೊಣೆಗಾರರಾಗುವುದಿಲ್ಲ.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->