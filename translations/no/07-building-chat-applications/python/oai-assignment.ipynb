{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Kapittel 7: Bygging av chatteapplikasjoner\n",
    "## OpenAI API Hurtigstart\n",
    "\n",
    "Denne notatboken er tilpasset fra [Azure OpenAI Samples Repository](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst) som inneholder notatbøker for tilgang til [Azure OpenAI](notebook-azure-openai.ipynb)-tjenester.\n",
    "\n",
    "Python OpenAI API fungerer også med Azure OpenAI-modeller, med noen små endringer. Les mer om forskjellene her: [Hvordan bytte mellom OpenAI og Azure OpenAI-endepunkter med Python](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Oversikt  \n",
    "\"Store språkmodeller er funksjoner som kobler tekst til tekst. Gitt en inntekststreng, prøver en stor språkmodell å forutsi hvilken tekst som kommer etterpå\"(1). Dette \"kom-i-gang\"-notatarket vil gi brukere en innføring i sentrale LLM-begreper, grunnleggende pakkekrav for å komme i gang med AML, en enkel introduksjon til promptdesign, og flere korte eksempler på ulike bruksområder.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Innholdsfortegnelse  \n",
    "\n",
    "[Oversikt](../../../../07-building-chat-applications/python)  \n",
    "[Hvordan bruke OpenAI-tjenesten](../../../../07-building-chat-applications/python)  \n",
    "[1. Opprette din OpenAI-tjeneste](../../../../07-building-chat-applications/python)  \n",
    "[2. Installasjon](../../../../07-building-chat-applications/python)    \n",
    "[3. Legitimasjon](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Bruksområder](../../../../07-building-chat-applications/python)    \n",
    "[1. Oppsummere tekst](../../../../07-building-chat-applications/python)  \n",
    "[2. Klassifisere tekst](../../../../07-building-chat-applications/python)  \n",
    "[3. Generere nye produktnavn](../../../../07-building-chat-applications/python)  \n",
    "[4. Finjustere en klassifiserer](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Referanser](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Lag din første prompt  \n",
    "Denne korte øvelsen gir en grunnleggende introduksjon til hvordan du sender inn forespørsler til en OpenAI-modell for en enkel oppgave, nemlig \"oppsummering\".\n",
    "\n",
    "\n",
    "**Steg**:  \n",
    "1. Installer OpenAI-biblioteket i ditt python-miljø  \n",
    "2. Last inn vanlige hjelpebiblioteker og sett dine vanlige OpenAI-sikkerhetsnøkler for OpenAI-tjenesten du har opprettet  \n",
    "3. Velg en modell for oppgaven din  \n",
    "4. Lag en enkel prompt til modellen  \n",
    "5. Send forespørselen din til modellens API!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Finne riktig modell  \n",
    "GPT-3.5-turbo eller GPT-4-modellene kan forstå og generere naturlig språk.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Utforming av prompt  \n",
    "\n",
    "\"Magien med store språkmodeller er at ved å trene dem til å minimere denne prediksjonsfeilen over enorme mengder tekst, ender modellene opp med å lære konsepter som er nyttige for disse prediksjonene. For eksempel lærer de konsepter som\"(1):\n",
    "\n",
    "* hvordan man staver\n",
    "* hvordan grammatikk fungerer\n",
    "* hvordan man omformulerer\n",
    "* hvordan man svarer på spørsmål\n",
    "* hvordan man fører en samtale\n",
    "* hvordan man skriver på mange språk\n",
    "* hvordan man koder\n",
    "* osv.\n",
    "\n",
    "#### Hvordan styre en stor språkmodell  \n",
    "\"Av alle inputene til en stor språkmodell, er tekstprompten uten tvil den mest innflytelsesrike\"(1).\n",
    "\n",
    "Store språkmodeller kan promptes til å produsere utdata på flere måter:\n",
    "\n",
    "Instruksjon: Fortell modellen hva du vil ha\n",
    "Fullføring: Få modellen til å fullføre starten på det du ønsker\n",
    "Demonstrasjon: Vis modellen hva du vil ha, enten med:\n",
    "Noen få eksempler i prompten\n",
    "Mange hundre eller tusen eksempler i et finjusteringsdatasett\"\n",
    "\n",
    "\n",
    "\n",
    "#### Det finnes tre grunnleggende retningslinjer for å lage gode prompt:\n",
    "\n",
    "**Vis og fortell**. Gjør det tydelig hva du ønsker, enten gjennom instruksjoner, eksempler, eller en kombinasjon av begge. Hvis du vil at modellen skal rangere en liste med elementer i alfabetisk rekkefølge eller klassifisere et avsnitt etter stemning, vis at det er dette du vil.\n",
    "\n",
    "**Gi gode data**. Hvis du prøver å lage en klassifiserer eller få modellen til å følge et mønster, sørg for at det er nok eksempler. Husk å korrekturlese eksemplene dine — modellen er som regel smart nok til å overse enkle stavefeil og gi deg et svar, men den kan også anta at dette er med vilje, og det kan påvirke svaret.\n",
    "\n",
    "**Sjekk innstillingene dine.** Temperatur- og top_p-innstillingene styrer hvor deterministisk modellen er når den genererer et svar. Hvis du ber om et svar hvor det bare finnes ett riktig svar, bør du sette disse lavt. Hvis du ønsker mer varierte svar, kan du sette dem høyere. Den vanligste feilen folk gjør med disse innstillingene, er å tro at de styrer \"smarthet\" eller \"kreativitet\".\n",
    "\n",
    "\n",
    "Kilde: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Oppsummer tekst  \n",
    "#### Utfordring  \n",
    "Oppsummer tekst ved å legge til en 'tl;dr:' på slutten av et tekstavsnitt. Legg merke til hvordan modellen forstår å utføre flere oppgaver uten ekstra instruksjoner. Du kan eksperimentere med mer beskrivende oppfordringer enn tl;dr for å endre modellens oppførsel og tilpasse oppsummeringen du får(3).  \n",
    "\n",
    "Nylig arbeid har vist betydelige forbedringer på mange NLP-oppgaver og -benchmarker ved å forhåndstrene på et stort tekstkorpus, etterfulgt av finjustering på en spesifikk oppgave. Selv om denne metoden vanligvis er oppgaveuavhengig i arkitekturen, krever den fortsatt oppgavespesifikke finjusteringsdatasett med tusenvis eller titusenvis av eksempler. Til sammenligning kan mennesker vanligvis utføre en ny språklig oppgave med bare noen få eksempler eller enkle instruksjoner – noe dagens NLP-systemer fortsatt i stor grad sliter med. Her viser vi at å skalere opp språkmodeller gir betydelig bedre oppgaveuavhengig ytelse med få eksempler, og noen ganger til og med kan konkurrere med tidligere toppmoderne finjusteringsmetoder. \n",
    "\n",
    "\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Øvelser for flere brukstilfeller  \n",
    "1. Oppsummer tekst  \n",
    "2. Klassifiser tekst  \n",
    "3. Lag nye produktnavn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Klassifiser tekst  \n",
    "#### Utfordring  \n",
    "Klassifiser elementer i kategorier som oppgis ved forespørselstidspunktet. I eksempelet under gir vi både kategoriene og teksten som skal klassifiseres i prompten (*playground_reference).\n",
    "\n",
    "Kundehenvendelse: Hei, en av tastene på tastaturet mitt har gått i stykker nylig, og jeg trenger en erstatning:\n",
    "\n",
    "Klassifisert kategori:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Generer nye produktnavn\n",
    "#### Utfordring\n",
    "Lag produktnavn ut fra eksempler på ord. Her inkluderer vi informasjon om produktet vi skal lage navn til i prompten. Vi gir også et lignende eksempel for å vise mønsteret vi ønsker å få. Vi har også satt temperaturverdien høyt for å øke tilfeldigheten og få mer innovative svar.\n",
    "\n",
    "Produktbeskrivelse: En milkshake-maskin for hjemmebruk\n",
    "Stikkord: rask, sunn, kompakt.\n",
    "Produktnavn: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Produktbeskrivelse: Et par sko som passer alle fotstørrelser.\n",
    "Stikkord: tilpasningsdyktig, passform, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Referanser  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Eksempler](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Beste praksis for finjustering av GPT-3 for tekstklassifisering](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# For mer hjelp  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Bidragsytere\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber nøyaktighet, vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på sitt originale språk bør anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell, menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:19:54+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "no"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}