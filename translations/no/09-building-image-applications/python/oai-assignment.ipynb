{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bygge en applikasjon for bildegenerering\n",
    "\n",
    "LLMer handler om mer enn bare tekstgenerering. Det er også mulig å lage bilder ut fra tekstbeskrivelser. Å ha bilder som en modalitet kan være svært nyttig innen alt fra MedTech, arkitektur, turisme, spillutvikling og mye mer. I dette kapittelet skal vi se nærmere på de to mest populære modellene for bildegenerering, DALL-E og Midjourney.\n",
    "\n",
    "## Innledning\n",
    "\n",
    "I denne leksjonen skal vi gå gjennom:\n",
    "\n",
    "- Bildegenerering og hvorfor det er nyttig.\n",
    "- DALL-E og Midjourney, hva de er og hvordan de fungerer.\n",
    "- Hvordan du kan bygge en app for bildegenerering.\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Etter å ha fullført denne leksjonen skal du kunne:\n",
    "\n",
    "- Lage en applikasjon for bildegenerering.\n",
    "- Sette rammer for applikasjonen din med metaprompt.\n",
    "- Jobbe med DALL-E og Midjourney.\n",
    "\n",
    "## Hvorfor lage en applikasjon for bildegenerering?\n",
    "\n",
    "Applikasjoner for bildegenerering er en flott måte å utforske mulighetene med Generativ AI. De kan brukes til for eksempel:\n",
    "\n",
    "- **Bildebehandling og syntese**. Du kan generere bilder til ulike formål, som redigering og syntetisering av bilder.\n",
    "\n",
    "- **Brukes i mange bransjer**. De kan også brukes til å lage bilder for ulike bransjer som MedTech, turisme, spillutvikling og mer.\n",
    "\n",
    "## Scenario: Edu4All\n",
    "\n",
    "I denne leksjonen fortsetter vi å jobbe med vår startup, Edu4All. Studentene skal lage bilder til sine oppgaver, akkurat hvilke bilder de lager er opp til dem, men det kan være illustrasjoner til eventyret sitt, en ny karakter til historien, eller for å visualisere ideer og konsepter.\n",
    "\n",
    "Her er et eksempel på hva Edu4Alls elever kan lage hvis de jobber med monumenter i klassen:\n",
    "\n",
    "![Edu4All startup, klasse om monumenter, Eiffeltårnet](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.no.png)\n",
    "\n",
    "ved å bruke en prompt som\n",
    "\n",
    "> \"Hund ved Eiffeltårnet i tidlig morgensol\"\n",
    "\n",
    "## Hva er DALL-E og Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) og [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) er to av de mest populære modellene for bildegenerering, og lar deg bruke prompts for å lage bilder.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "La oss starte med DALL-E, som er en generativ AI-modell som lager bilder ut fra tekstbeskrivelser.\n",
    "\n",
    "> [DALL-E er en kombinasjon av to modeller, CLIP og diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** er en modell som lager embeddings, altså numeriske representasjoner av data, fra bilder og tekst.\n",
    "\n",
    "- **Diffused attention** er en modell som lager bilder ut fra embeddings. DALL-E er trent på et datasett med bilder og tekst, og kan brukes til å generere bilder fra tekstbeskrivelser. For eksempel kan DALL-E lage bilder av en katt med hatt, eller en hund med mohawk.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney fungerer på lignende måte som DALL-E, og lager bilder ut fra tekstprompter. Midjourney kan også brukes til å generere bilder med prompts som “en katt med hatt” eller “en hund med mohawk”.\n",
    "\n",
    "![Bilde generert av Midjourney, mekanisk due](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Bildekilde Wikipedia, bilde generert av Midjourney*\n",
    "\n",
    "## Hvordan fungerer DALL-E og Midjourney\n",
    "\n",
    "Først, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E er en generativ AI-modell basert på transformer-arkitektur med en *autoregressiv transformer*.\n",
    "\n",
    "En *autoregressiv transformer* definerer hvordan en modell lager bilder fra tekstbeskrivelser, den lager én piksel om gangen, og bruker de genererte pikslene til å lage neste piksel. Dette skjer gjennom flere lag i et nevralt nettverk, helt til bildet er ferdig.\n",
    "\n",
    "Med denne prosessen kan DALL-E styre attributter, objekter, egenskaper og mer i bildet den lager. DALL-E 2 og 3 har enda mer kontroll over det genererte bildet,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bygg din første bildegenereringsapplikasjon\n",
    "\n",
    "Hva trenger du for å lage en applikasjon som genererer bilder? Du trenger følgende biblioteker:\n",
    "\n",
    "- **python-dotenv**, det anbefales sterkt å bruke dette biblioteket for å holde hemmeligheter i en *.env*-fil, adskilt fra koden.\n",
    "- **openai**, dette biblioteket bruker du for å kommunisere med OpenAI API.\n",
    "- **pillow**, for å jobbe med bilder i Python.\n",
    "- **requests**, for å gjøre HTTP-forespørsler.\n",
    "\n",
    "1. Lag en fil som heter *.env* med følgende innhold:\n",
    "\n",
    "    ```text\n",
    "    OPENAI_API_KEY='<add your OpenAI key here>'\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Samle bibliotekene ovenfor i en fil kalt *requirements.txt* slik:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. Opprett deretter et virtuelt miljø og installer bibliotekene:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> For Windows, bruk følgende kommandoer for å opprette og aktivere ditt virtuelle miljø:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Legg til følgende kode i en fil som heter *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "\n",
    "    # Create OpenAI object\n",
    "    client = OpenAI()\n",
    "\n",
    "\n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = client.images.generate(\n",
    "            model=\"dall-e-3\",\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=1\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "\n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "\n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "\n",
    "        # Retrieve the generated image\n",
    "        print(generation_response)\n",
    "\n",
    "        image_url = generation_response.data[0].url # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "\n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "\n",
    "    # catch exceptions\n",
    "    except client.error.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "La oss forklare denne koden:\n",
    "\n",
    "- Først importerer vi bibliotekene vi trenger, inkludert OpenAI-biblioteket, dotenv-biblioteket, requests-biblioteket og Pillow-biblioteket.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv \n",
    "    ```\n",
    "\n",
    "- Deretter oppretter vi objektet, som henter API-nøkkelen fra din ``.env``.\n",
    "\n",
    "    ```python\n",
    "        # Create OpenAI object\n",
    "        client = OpenAI()\n",
    "    ```\n",
    "\n",
    "- Så genererer vi bildet:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Koden over svarer med et JSON-objekt som inneholder URL-en til det genererte bildet. Vi kan bruke URL-en til å laste ned bildet og lagre det i en fil.\n",
    "\n",
    "- Til slutt åpner vi bildet og bruker standard bildeviser for å vise det:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "    \n",
    "### Mer om hvordan bildet genereres\n",
    "\n",
    "La oss se nærmere på koden som genererer bildet:\n",
    "\n",
    "```python\n",
    "generation_response = client.images.generate(\n",
    "        model=\"dall-e-3\",\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=1\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** er tekstbeskrivelsen som brukes for å generere bildet. I dette tilfellet bruker vi prompten \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".\n",
    "- **size** er størrelsen på bildet som genereres. Her lager vi et bilde som er 1024x1024 piksler.\n",
    "- **n** er antall bilder som genereres. I dette eksempelet lager vi to bilder.\n",
    "\n",
    "Det finnes flere ting du kan gjøre med bilder, som vi skal se på i neste del.\n",
    "\n",
    "## Flere muligheter med bildegenerering\n",
    "\n",
    "Du har nå sett hvordan vi kan generere et bilde med noen få linjer Python-kode. Men det finnes flere ting du kan gjøre med bilder.\n",
    "\n",
    "Du kan også gjøre følgende:\n",
    "\n",
    "- **Gjøre endringer**. Ved å gi et eksisterende bilde, en maske og en prompt, kan du endre et bilde. For eksempel kan du legge til noe på en del av bildet. Tenk deg vårt kaninbilde – du kan legge til en hatt på kaninen. Dette gjør du ved å gi bildet, en maske (som markerer området som skal endres) og en tekstprompt som beskriver hva som skal gjøres.\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n",
    "\n",
    "    Grunnbildet vil bare inneholde kaninen, men det endelige bildet vil ha en hatt på kaninen.\n",
    "    \n",
    "- **Lage variasjoner**. Tanken er at du tar et eksisterende bilde og ber om at det lages variasjoner. For å lage en variasjon gir du et bilde og en tekstprompt, og koden ser slik ut:\n",
    "\n",
    "    ```python\n",
    "    response = openai.images.create_variation(\n",
    "      image=open(\"bunny-lollipop.png\", \"rb\"),\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response.data[0].url\n",
    "    ```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber nøyaktighet, vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på sitt originale språk bør anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "967a3421f1d34546352f2ce877d74bbb",
   "translation_date": "2025-08-25T19:41:29+00:00",
   "source_file": "09-building-image-applications/python/oai-assignment.ipynb",
   "language_code": "no"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}