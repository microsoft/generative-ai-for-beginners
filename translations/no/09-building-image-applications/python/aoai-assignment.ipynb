{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bygge en applikasjon for bildegenerering\n",
    "\n",
    "LLMer handler om mer enn bare tekstgenerering. Det er også mulig å generere bilder fra tekstbeskrivelser. Å ha bilder som en modalitet kan være svært nyttig innen alt fra MedTech, arkitektur, turisme, spillutvikling og mye mer. I dette kapittelet skal vi se nærmere på de to mest populære modellene for bildegenerering, DALL-E og Midjourney.\n",
    "\n",
    "## Introduksjon\n",
    "\n",
    "I denne leksjonen skal vi gå gjennom:\n",
    "\n",
    "- Bildegenerering og hvorfor det er nyttig.\n",
    "- DALL-E og Midjourney, hva de er og hvordan de fungerer.\n",
    "- Hvordan du kan bygge en applikasjon for bildegenerering.\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Etter å ha fullført denne leksjonen skal du kunne:\n",
    "\n",
    "- Lage en applikasjon for bildegenerering.\n",
    "- Sette rammer for applikasjonen din med metaprompt.\n",
    "- Jobbe med DALL-E og Midjourney.\n",
    "\n",
    "## Hvorfor lage en applikasjon for bildegenerering?\n",
    "\n",
    "Applikasjoner for bildegenerering er en flott måte å utforske mulighetene med Generativ AI. De kan brukes til for eksempel:\n",
    "\n",
    "- **Bildebehandling og syntese**. Du kan generere bilder til ulike formål, som bildebehandling og bildesyntese.\n",
    "\n",
    "- **Brukes i mange bransjer**. De kan også brukes til å generere bilder for ulike bransjer som MedTech, turisme, spillutvikling og mer.\n",
    "\n",
    "## Scenario: Edu4All\n",
    "\n",
    "I denne leksjonen fortsetter vi å jobbe med vår startup, Edu4All. Studentene skal lage bilder til sine oppgaver, akkurat hvilke bilder de lager er opp til dem, men det kan være illustrasjoner til eventyret sitt, lage en ny karakter til historien sin, eller hjelpe dem med å visualisere ideer og konsepter.\n",
    "\n",
    "Her er et eksempel på hva Edu4Alls elever kan generere hvis de jobber med monumenter i klassen:\n",
    "\n",
    "![Edu4All startup, klasse om monumenter, Eiffeltårnet](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.no.png)\n",
    "\n",
    "ved å bruke en prompt som\n",
    "\n",
    "> \"Hund ved Eiffeltårnet i tidlig morgensol\"\n",
    "\n",
    "## Hva er DALL-E og Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) og [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) er to av de mest populære modellene for bildegenerering, og lar deg bruke prompts for å lage bilder.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "La oss starte med DALL-E, som er en generativ AI-modell som lager bilder fra tekstbeskrivelser.\n",
    "\n",
    "> [DALL-E er en kombinasjon av to modeller, CLIP og diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** er en modell som lager embeddings, altså numeriske representasjoner av data, fra bilder og tekst.\n",
    "\n",
    "- **Diffused attention** er en modell som lager bilder fra embeddings. DALL-E er trent på et datasett med bilder og tekst, og kan brukes til å generere bilder fra tekstbeskrivelser. For eksempel kan DALL-E lage bilder av en katt med hatt, eller en hund med mohawk.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney fungerer på lignende måte som DALL-E, og lager bilder fra tekstprompter. Midjourney kan også brukes til å generere bilder med prompts som “en katt med hatt” eller “en hund med mohawk”.\n",
    "\n",
    "![Bilde generert av Midjourney, mekanisk due](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Bildekilde Wikipedia, bilde generert av Midjourney*\n",
    "\n",
    "## Hvordan fungerer DALL-E og Midjourney\n",
    "\n",
    "Først, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E er en generativ AI-modell basert på transformer-arkitektur med en *autoregressiv transformer*.\n",
    "\n",
    "En *autoregressiv transformer* definerer hvordan en modell lager bilder fra tekstbeskrivelser, den genererer én piksel om gangen, og bruker de genererte pikslene til å lage neste piksel. Dette skjer gjennom flere lag i et nevralt nettverk, helt til bildet er ferdig.\n",
    "\n",
    "Med denne prosessen kan DALL-E kontrollere attributter, objekter, egenskaper og mer i bildet den lager. DALL-E 2 og 3 har enda mer kontroll over det genererte bildet,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bygg din første bildegenereringsapplikasjon\n",
    "\n",
    "Hva trenger du for å lage en applikasjon som genererer bilder? Du trenger følgende biblioteker:\n",
    "\n",
    "- **python-dotenv**, det anbefales sterkt å bruke dette biblioteket for å holde hemmeligheter i en *.env*-fil, adskilt fra koden.\n",
    "- **openai**, dette biblioteket bruker du for å kommunisere med OpenAI API.\n",
    "- **pillow**, for å jobbe med bilder i Python.\n",
    "- **requests**, for å gjøre HTTP-forespørsler.\n",
    "\n",
    "1. Lag en fil som heter *.env* med følgende innhold:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Du finner denne informasjonen i Azure Portal for ressursen din under \"Keys and Endpoint\"-seksjonen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Samle bibliotekene ovenfor i en fil kalt *requirements.txt* slik:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. Opprett deretter et virtuelt miljø og installer bibliotekene:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> For Windows, bruk følgende kommandoer for å opprette og aktivere ditt virtuelle miljø:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Legg til følgende kode i en fil kalt *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "La oss forklare denne koden:\n",
    "\n",
    "- Først importerer vi bibliotekene vi trenger, inkludert OpenAI-biblioteket, dotenv-biblioteket, requests-biblioteket og Pillow-biblioteket.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Deretter laster vi inn miljøvariablene fra *.env*-filen.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Etter det setter vi endepunktet, nøkkelen for OpenAI API, versjon og type.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Så genererer vi bildet:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Koden over svarer med et JSON-objekt som inneholder URL-en til det genererte bildet. Vi kan bruke URL-en til å laste ned bildet og lagre det til en fil.\n",
    "\n",
    "- Til slutt åpner vi bildet og bruker standard bildeviser for å vise det:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Mer om hvordan bildet genereres\n",
    "\n",
    "La oss se nærmere på koden som genererer bildet:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** er tekstbeskrivelsen som brukes for å generere bildet. I dette tilfellet bruker vi prompten \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".\n",
    "- **size** er størrelsen på bildet som genereres. Her lager vi et bilde som er 1024x1024 piksler.\n",
    "- **n** er antall bilder som genereres. I dette eksempelet lager vi to bilder.\n",
    "- **temperature** er en parameter som styrer hvor tilfeldig resultatet fra en generativ AI-modell blir. Verdien er mellom 0 og 1, der 0 betyr at resultatet er deterministisk og 1 betyr at det er helt tilfeldig. Standardverdien er 0,7.\n",
    "\n",
    "Det finnes flere ting du kan gjøre med bilder, som vi skal se på i neste del.\n",
    "\n",
    "## Flere muligheter med bildegenerering\n",
    "\n",
    "Du har nå sett hvordan vi kan generere et bilde med noen få linjer Python-kode. Men det finnes flere ting du kan gjøre med bilder.\n",
    "\n",
    "Du kan også gjøre følgende:\n",
    "\n",
    "- **Redigere bilder**. Ved å gi et eksisterende bilde, en maske og en prompt, kan du endre et bilde. For eksempel kan du legge til noe på en del av bildet. Tenk deg vårt kaninbilde – du kan legge til en hatt på kaninen. Dette gjør du ved å gi bildet, en maske (som markerer området som skal endres) og en tekstprompt som sier hva som skal gjøres.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    Grunnbildet vil bare inneholde kaninen, men det endelige bildet vil ha en hatt på kaninen.\n",
    "\n",
    "- **Lage variasjoner**.\n",
    "    Se vår [OpenAI-notatbok for mer informasjon](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Ansvarsfraskrivelse**:  \nDette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber nøyaktighet, vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på sitt originale språk skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell, menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:18:59+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "no"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}