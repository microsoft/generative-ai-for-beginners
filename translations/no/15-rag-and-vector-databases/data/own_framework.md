<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "df98b2c59f87d8543135301e87969f70",
  "translation_date": "2025-07-09T16:47:48+00:00",
  "source_file": "15-rag-and-vector-databases/data/own_framework.md",
  "language_code": "no"
}
-->
# Introduksjon til nevrale nettverk. Flerlaget perceptron

I forrige seksjon lÃ¦rte du om den enkleste modellen for nevrale nettverk â€“ enlaget perceptron, en lineÃ¦r to-klasses klassifiseringsmodell.

I denne seksjonen vil vi utvide denne modellen til en mer fleksibel rammeverk som lar oss:

* utfÃ¸re **flere-klasse klassifisering** i tillegg til to-klasses
* lÃ¸se **regresjonsproblemer** i tillegg til klassifisering
* skille klasser som ikke er lineÃ¦rt separerbare

Vi vil ogsÃ¥ utvikle vÃ¥rt eget modulÃ¦re rammeverk i Python som gjÃ¸r det mulig Ã¥ bygge ulike nevrale nettverksarkitekturer.

## Formalisering av maskinlÃ¦ring

La oss starte med Ã¥ formalisere maskinlÃ¦ringsproblemet. Anta at vi har et treningsdatasett **X** med etiketter **Y**, og vi trenger Ã¥ bygge en modell *f* som gir mest nÃ¸yaktige prediksjoner. Kvaliteten pÃ¥ prediksjonene mÃ¥les med en **tapfunksjon** â„’. FÃ¸lgende tapfunksjoner brukes ofte:

* For regresjonsproblemer, nÃ¥r vi skal forutsi et tall, kan vi bruke **absolutt feil** âˆ‘<sub>i</sub>|f(x<sup>(i)</sup>)-y<sup>(i)</sup>|, eller **kvadratisk feil** âˆ‘<sub>i</sub>(f(x<sup>(i)</sup>)-y<sup>(i)</sup>)<sup>2</sup>
* For klassifisering bruker vi **0-1 tap** (som i praksis tilsvarer **modellens nÃ¸yaktighet**), eller **logistisk tap**.

For en ett-lags perceptron var funksjonen *f* definert som en lineÃ¦r funksjon *f(x)=wx+b* (her er *w* vektmatrisen, *x* er vektor av input-funksjoner, og *b* er bias-vektoren). For ulike nevrale nettverksarkitekturer kan denne funksjonen ha en mer kompleks form.

> I klassifisering er det ofte Ã¸nskelig Ã¥ fÃ¥ sannsynligheter for de respektive klassene som nettverksutgang. For Ã¥ konvertere vilkÃ¥rlige tall til sannsynligheter (f.eks. for Ã¥ normalisere output), bruker vi ofte **softmax**-funksjonen Ïƒ, og funksjonen *f* blir *f(x)=Ïƒ(wx+b)*

I definisjonen av *f* over kalles *w* og *b* for **parametere** Î¸=âŸ¨*w,b*âŸ©. Gitt datasettet âŸ¨**X**,**Y**âŸ© kan vi beregne total feil pÃ¥ hele datasettet som en funksjon av parametrene Î¸.

> âœ… **MÃ¥let med trening av nevrale nettverk er Ã¥ minimere feilen ved Ã¥ justere parametrene Î¸**

## Gradientnedstigning-optimalisering

Det finnes en velkjent metode for funksjonsoptimalisering kalt **gradientnedstigning**. Ideen er at vi kan beregne en deriverte (i flerdimensjonalt tilfelle kalt **gradient**) av tapfunksjonen med hensyn til parametrene, og justere parametrene slik at feilen reduseres. Dette kan formaliseres slik:

* Initialiser parametrene med noen tilfeldige verdier w<sup>(0)</sup>, b<sup>(0)</sup>
* Gjenta fÃ¸lgende steg mange ganger:
    - w<sup>(i+1)</sup> = w<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚w
    - b<sup>(i+1)</sup> = b<sup>(i)</sup>-Î·âˆ‚â„’/âˆ‚b

Under trening skal optimaliseringsstegene beregnes med tanke pÃ¥ hele datasettet (husk at tapet beregnes som summen over alle treningsprÃ¸ver). I praksis tar vi imidlertid smÃ¥ deler av datasettet kalt **minibatcher**, og beregner gradienter basert pÃ¥ et delsett av data. Fordi delsettet tas tilfeldig hver gang, kalles denne metoden **stokastisk gradientnedstigning** (SGD).

## Flerlagede perceptroner og bakoverpropagasjon

En ett-lags nettverk, som vi har sett over, kan klassifisere lineÃ¦rt separerbare klasser. For Ã¥ bygge en rikere modell kan vi kombinere flere lag i nettverket. Matematisk betyr det at funksjonen *f* fÃ¥r en mer kompleks form, og beregnes i flere steg:
* z<sub>1</sub>=w<sub>1</sub>x+b<sub>1</sub>
* z<sub>2</sub>=w<sub>2</sub>Î±(z<sub>1</sub>)+b<sub>2</sub>
* f = Ïƒ(z<sub>2</sub>)

Her er Î± en **ikke-lineÃ¦r aktiveringsfunksjon**, Ïƒ er softmax-funksjonen, og parametrene Î¸=<*w<sub>1</sub>,b<sub>1</sub>,w<sub>2</sub>,b<sub>2</sub>*>.

Gradientnedstigningsalgoritmen er den samme, men det blir vanskeligere Ã¥ beregne gradientene. Ved hjelp av kjerneregelen for derivasjon kan vi beregne deriverte som:

* âˆ‚â„’/âˆ‚w<sub>2</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚w<sub>2</sub>)
* âˆ‚â„’/âˆ‚w<sub>1</sub> = (âˆ‚â„’/âˆ‚Ïƒ)(âˆ‚Ïƒ/âˆ‚z<sub>2</sub>)(âˆ‚z<sub>2</sub>/âˆ‚Î±)(âˆ‚Î±/âˆ‚z<sub>1</sub>)(âˆ‚z<sub>1</sub>/âˆ‚w<sub>1</sub>)

> âœ… Kjerneregelen brukes for Ã¥ beregne deriverte av tapfunksjonen med hensyn til parametrene.

Merk at den venstre delen av alle disse uttrykkene er den samme, og derfor kan vi effektivt beregne deriverte ved Ã¥ starte fra tapfunksjonen og gÃ¥ "bakover" gjennom beregningsgrafen. Metoden for Ã¥ trene et flerlaget perceptron kalles derfor **bakoverpropagasjon**, eller 'backprop'.



> TODO: bildehenvisning

> âœ… Vi vil gÃ¥ mer i detalj pÃ¥ backprop i vÃ¥rt notatbok-eksempel.  

## Konklusjon

I denne leksjonen har vi bygget vÃ¥rt eget nevrale nettverksbibliotek, og brukt det til en enkel todimensjonal klassifiseringsoppgave.

## ğŸš€ Utfordring

I den medfÃ¸lgende notatboken skal du implementere ditt eget rammeverk for Ã¥ bygge og trene flerlagede perceptroner. Du vil kunne se i detalj hvordan moderne nevrale nettverk fungerer.

GÃ¥ videre til OwnFramework-notatboken og jobb deg gjennom den.



## Gjennomgang & Selvstudium

Bakoverpropagasjon er en vanlig algoritme brukt i AI og ML, og det er verdt Ã¥ studere den nÃ¦rmere.

## Oppgave

I denne labben skal du bruke rammeverket du bygde i denne leksjonen for Ã¥ lÃ¸se MNIST hÃ¥ndskriftgjenkjenningsoppgave.

* Instruksjoner
* Notatbok

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nÃ¸yaktighet, vennligst vÃ¦r oppmerksom pÃ¥ at automatiske oversettelser kan inneholde feil eller unÃ¸yaktigheter. Det opprinnelige dokumentet pÃ¥ originalsprÃ¥ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforstÃ¥elser eller feiltolkninger som oppstÃ¥r ved bruk av denne oversettelsen.