<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "e2f686f2eb794941761252ac5e8e090b",
  "translation_date": "2025-05-19T14:06:54+00:00",
  "source_file": "02-exploring-and-comparing-different-llms/README.md",
  "language_code": "no"
}
-->
# Utforsking og sammenligning av ulike LLM-er

[![Utforsking og sammenligning av ulike LLM-er](../../../translated_images/02-lesson-banner.722fb0fdf701564d4479112ef4c4fa964c98dce0c241decbe12aae32e9fb4659.no.png)](https://aka.ms/gen-ai-lesson2-gh?WT.mc_id=academic-105485-koreyst)

> _Klikk p√• bildet over for √• se videoen av denne leksjonen_

I den forrige leksjonen s√• vi hvordan Generativ AI endrer teknologilandskapet, hvordan Store Spr√•kmodeller (LLM-er) fungerer og hvordan en bedrift - som v√•r oppstart - kan bruke dem til sine bruksomr√•der og vokse! I dette kapittelet skal vi sammenligne og kontrastere ulike typer store spr√•kmodeller (LLM-er) for √• forst√• deres fordeler og ulemper.

Neste steg i v√•r oppstartsreise er √• utforske det n√•v√¶rende landskapet av LLM-er og forst√• hvilke som er egnet for v√•rt bruksomr√•de.

## Introduksjon

Denne leksjonen vil dekke:

- Ulike typer LLM-er i det n√•v√¶rende landskapet.
- Testing, iterering og sammenligning av ulike modeller for ditt bruksomr√•de i Azure.
- Hvordan distribuere en LLM.

## L√¶ringsm√•l

Etter √• ha fullf√∏rt denne leksjonen, vil du kunne:

- Velge riktig modell for ditt bruksomr√•de.
- Forst√• hvordan du tester, itererer og forbedrer ytelsen til modellen din.
- Vite hvordan bedrifter distribuerer modeller.

## Forst√• ulike typer LLM-er

LLM-er kan ha flere kategoriseringer basert p√• deres arkitektur, treningsdata og bruksomr√•de. √Ö forst√• disse forskjellene vil hjelpe v√•r oppstart med √• velge riktig modell for scenariet, og forst√• hvordan man tester, itererer og forbedrer ytelsen.

Det finnes mange forskjellige typer LLM-modeller, og valget ditt av modell avhenger av hva du √∏nsker √• bruke dem til, dine data, hvor mye du er villig til √• betale og mer.

Avhengig av om du √∏nsker √• bruke modellene for tekst, lyd, video, bildegenerering osv., kan du velge en annen type modell.

- **Lyd og talegjenkjenning**. For dette form√•let er Whisper-typen modeller et godt valg da de er generelle og rettet mot talegjenkjenning. Den er trent p√• variert lyd og kan utf√∏re flerspr√•klig talegjenkjenning. L√¶r mer om [Whisper-typen modeller her](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-koreyst).

- **Bildefremstilling**. For bildegenerering er DALL-E og Midjourney to sv√¶rt kjente valg. DALL-E tilbys av Azure OpenAI. [Les mer om DALL-E her](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-koreyst) og ogs√• i kapittel 9 av denne l√¶replanen.

- **Tekstgenerering**. De fleste modeller er trent p√• tekstgenerering, og du har et stort utvalg av valg fra GPT-3.5 til GPT-4. De kommer til forskjellige kostnader, hvor GPT-4 er den dyreste. Det er verdt √• se innom [Azure OpenAI-lekeplassen](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-koreyst) for √• evaluere hvilke modeller som best passer dine behov n√•r det gjelder kapasitet og kostnad.

- **Multimodalitet**. Hvis du √∏nsker √• h√•ndtere flere typer data i input og output, kan du se p√• modeller som [gpt-4 turbo med visjon eller gpt-4o](https://learn.microsoft.com/azure/ai-services/openai/concepts/models#gpt-4-and-gpt-4-turbo-models?WT.mc_id=academic-105485-koreyst) - de nyeste utgivelsene av OpenAI-modeller - som er i stand til √• kombinere naturlig spr√•kbehandling med visuell forst√•else, slik at interaksjoner kan skje gjennom multimodale grensesnitt.

√Ö velge en modell betyr at du f√•r noen grunnleggende evner, som kanskje ikke er nok. Ofte har du selskaps-spesifikke data som du p√• en eller annen m√•te m√• fortelle LLM om. Det finnes noen forskjellige valg p√• hvordan man kan n√¶rme seg det, mer om det i de kommende avsnittene.

### Grunnmodeller versus LLM-er

Begrepet Grunnmodell ble [laget av Stanford-forskere](https://arxiv.org/abs/2108.07258?WT.mc_id=academic-105485-koreyst) og definert som en AI-modell som f√∏lger noen kriterier, som:

- **De er trent ved bruk av usupervisert l√¶ring eller selv-supervisert l√¶ring**, noe som betyr at de er trent p√• umerkede multimodale data, og de krever ikke menneskelig annotering eller merking av data for treningsprosessen.
- **De er veldig store modeller**, basert p√• veldig dype nevrale nettverk trent p√• milliarder av parametere.
- **De er normalt ment √• tjene som et ‚Äògrunnlag‚Äô for andre modeller**, noe som betyr at de kan brukes som et utgangspunkt for andre modeller som kan bygges p√• toppen av, noe som kan gj√∏res ved finjustering.

For √• ytterligere klargj√∏re dette skillet, la oss ta ChatGPT som et eksempel. For √• bygge den f√∏rste versjonen av ChatGPT, fungerte en modell kalt GPT-3.5 som grunnmodellen. Dette betyr at OpenAI brukte noe chat-spesifikke data for √• lage en finjustert versjon av GPT-3.5 som var spesialisert i √• prestere godt i konversasjonelle scenarier, som chatbots.

### √Öpen kildekode versus propriet√¶re modeller

En annen m√•te √• kategorisere LLM-er p√• er om de er √•pen kildekode eller propriet√¶re.

√Öpen kildekode-modeller er modeller som gj√∏res tilgjengelige for offentligheten og kan brukes av hvem som helst. De gj√∏res ofte tilgjengelige av selskapet som opprettet dem, eller av forskningsmilj√∏et. Disse modellene kan inspiseres, modifiseres og tilpasses for de ulike bruksomr√•dene i LLM-er. Imidlertid er de ikke alltid optimalisert for produksjonsbruk, og kan v√¶re mindre ytelsesdyktige enn propriet√¶re modeller. I tillegg kan finansiering for √•pen kildekode-modeller v√¶re begrenset, og de kan ikke bli vedlikeholdt p√• lang sikt eller oppdatert med den nyeste forskningen. Eksempler p√• popul√¶re √•pen kildekode-modeller inkluderer [Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-koreyst), [Bloom](https://huggingface.co/bigscience/bloom) og [LLaMA](https://llama.meta.com).

Propriet√¶re modeller er modeller som eies av et selskap og ikke gj√∏res tilgjengelige for offentligheten. Disse modellene er ofte optimalisert for produksjonsbruk. Imidlertid kan de ikke inspiseres, modifiseres eller tilpasses for forskjellige bruksomr√•der. I tillegg er de ikke alltid tilgjengelige gratis, og kan kreve abonnement eller betaling for √• bruke. Ogs√•, brukere har ikke kontroll over dataene som brukes til √• trene modellen, noe som betyr at de m√• stole p√• at modelleieren sikrer forpliktelse til databeskyttelse og ansvarlig bruk av AI. Eksempler p√• popul√¶re propriet√¶re modeller inkluderer [OpenAI-modeller](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-koreyst), [Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-koreyst) eller [Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-koreyst).

### Innebygging versus bildegenerering versus tekst- og kodegenerering

LLM-er kan ogs√• kategoriseres etter outputen de genererer.

Innebygginger er et sett med modeller som kan konvertere tekst til en numerisk form, kalt innebygging, som er en numerisk representasjon av input-teksten. Innebygginger gj√∏r det lettere for maskiner √• forst√• forholdet mellom ord eller setninger og kan brukes som input av andre modeller, som klassifikasjonsmodeller, eller klyngemodeller som har bedre ytelse p√• numeriske data. Innebyggingsmodeller brukes ofte til overf√∏ringsl√¶ring, der en modell bygges for en surrogatoppgave for hvilken det er en overflod av data, og deretter gjenbrukes modellvektene (innebygginger) for andre nedstr√∏ms oppgaver. Et eksempel p√• denne kategorien er [OpenAI innebygginger](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-koreyst).

Bildefremstillingsmodeller er modeller som genererer bilder. Disse modellene brukes ofte til bildeforbedring, bildesyntese og bildetranslasjon. Bildefremstillingsmodeller trenes ofte p√• store datasett av bilder, som [LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-koreyst), og kan brukes til √• generere nye bilder eller til √• redigere eksisterende bilder med innmaling, superoppl√∏sning og fargeleggingsteknikker. Eksempler inkluderer [DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-koreyst) og [Stable Diffusion-modeller](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-koreyst).

Tekst- og kodegenereringsmodeller er modeller som genererer tekst eller kode. Disse modellene brukes ofte til tekstsammendrag, oversettelse og sp√∏rsm√•lsbesvarelse. Tekstgenereringsmodeller trenes ofte p√• store datasett av tekst, som [BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-koreyst), og kan brukes til √• generere ny tekst, eller til √• besvare sp√∏rsm√•l. Kodegenereringsmodeller, som [CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-koreyst), trenes ofte p√• store datasett av kode, som GitHub, og kan brukes til √• generere ny kode, eller til √• fikse feil i eksisterende kode.

### Koder-dekoder versus kun dekoder

For √• snakke om de forskjellige typene arkitekturer av LLM-er, la oss bruke en analogi.

Tenk deg at lederen din ga deg en oppgave med √• lage en quiz for studentene. Du har to kolleger; en som har ansvaret for √• lage innholdet og en annen som har ansvaret for √• gjennomg√• dem.

Innholdsskaperen er som en modell som kun dekoder, de kan se p√• emnet og se hva du allerede har skrevet, og deretter kan de skrive et kurs basert p√• det. De er veldig gode til √• skrive engasjerende og informativt innhold, men de er ikke veldig gode til √• forst√• emnet og l√¶ringsm√•lene. Noen eksempler p√• dekodermodeller er GPT-familien modeller, som GPT-3.

Gjennomleseren er som en modell som kun koder, de ser p√• kurset som er skrevet og svarene, legger merke til forholdet mellom dem og forst√•r konteksten, men de er ikke gode til √• generere innhold. Et eksempel p√• en modell som kun koder ville v√¶re BERT.

Tenk deg at vi ogs√• kan ha noen som kunne lage og gjennomg√• quizen, dette er en koder-dekoder-modell. Noen eksempler ville v√¶re BART og T5.

### Tjeneste versus modell

La oss n√• snakke om forskjellen mellom en tjeneste og en modell. En tjeneste er et produkt som tilbys av en skyleverand√∏r, og er ofte en kombinasjon av modeller, data og andre komponenter. En modell er kjernen i en tjeneste, og er ofte en grunnmodell, som en LLM.

Tjenester er ofte optimalisert for produksjonsbruk og er ofte enklere √• bruke enn modeller, via et grafisk brukergrensesnitt. Imidlertid er tjenester ikke alltid tilgjengelige gratis, og kan kreve abonnement eller betaling for √• bruke, i bytte for √• utnytte tjenesteeierens utstyr og ressurser, optimalisere utgifter og skalere enkelt. Et eksempel p√• en tjeneste er [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-koreyst), som tilbyr en pay-as-you-go-plan, noe som betyr at brukere belastes proporsjonalt med hvor mye de bruker tjenesten. I tillegg tilbyr Azure OpenAI Service sikkerhet p√• bedriftsniv√• og et ansvarlig AI-rammeverk p√• toppen av modellenes evner.

Modeller er bare det nevrale nettverket, med parametrene, vektene og andre. Dette gj√∏r at selskaper kan kj√∏re lokalt, men de m√• kj√∏pe utstyr, bygge en struktur for √• skalere og kj√∏pe en lisens eller bruke en √•pen kildekode-modell. En modell som LLaMA er tilgjengelig for √• brukes, og krever datakraft for √• kj√∏re modellen.

## Hvordan teste og iterere med forskjellige modeller for √• forst√• ytelse p√• Azure

N√•r teamet v√•rt har utforsket det n√•v√¶rende LLM-landskapet og identifisert noen gode kandidater for sine scenarier, er neste steg √• teste dem p√• deres data og p√• deres arbeidsmengde. Dette er en iterativ prosess, gjort ved eksperimenter og m√•linger. De fleste av modellene vi nevnte i tidligere avsnitt (OpenAI-modeller, √•pen kildekode-modeller som Llama2 og Hugging Face-transformatorer) er tilgjengelige i [Model Catalog](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview?WT.mc_id=academic-105485-koreyst) i [Azure AI Studio](https://ai.azure.com/?WT.mc_id=academic-105485-koreyst).

[Azure AI Studio](https://learn.microsoft.com/azure/ai-studio/what-is-ai-studio?WT.mc_id=academic-105485-koreyst) er en skyplattform designet for utviklere for √• bygge generative AI-applikasjoner og administrere hele utviklingslivssyklusen - fra eksperimentering til evaluering - ved √• kombinere alle Azure AI-tjenester i et enkelt nav med et brukervennlig GUI. Modellkatalogen i Azure AI Studio gj√∏r det mulig for brukeren √•:

- Finne grunnmodellen av interesse i katalogen - enten propriet√¶r eller √•pen kildekode, filtrert etter oppgave, lisens eller navn. For √• forbedre s√∏kbarheten er modellene organisert i samlinger, som Azure OpenAI-samling, Hugging Face-samling og mer.

- G√• gjennom modellkortet, inkludert en detaljert beskrivelse av tiltenkt bruk og treningsdata, kodeeksempler og evalueringsresultater p√• det interne evalueringsbiblioteket.
- Sammenlign benchmarks p√• tvers av modeller og datasett tilgjengelig i bransjen for √• vurdere hvilken som passer best til forretningsscenariet, gjennom [Model Benchmarks](https://learn.microsoft.com/azure/ai-studio/how-to/model-benchmarks?WT.mc_id=academic-105485-koreyst)-panelet.

![Model benchmarks](../../../translated_images/ModelBenchmarks.b3b4182f762db04b59267af64ce77cc936d38adf40fb032f12acec9063578008.no.png)

- Finjuster modellen p√• egendefinerte treningsdata for √• forbedre modellens ytelse i en spesifikk arbeidsbelastning, ved √• bruke eksperimenterings- og sporingsfunksjonene i Azure AI Studio.

![Model fine-tuning](../../../translated_images/FineTuning.f93db4ecbdc85b4a20ff1198fb82f5e2daa3a1ee328733b17d603727db20f5c0.no.png)

- Distribuer den originale forh√•ndstrente modellen eller den finjusterte versjonen til en ekstern sanntidsinfrastruktur - administrert databehandling - eller serverl√∏s API-endepunkt - [betal etter bruk](https://learn.microsoft.com/azure/ai-studio/how-to/model-catalog-overview#model-deployment-managed-compute-and-serverless-api-pay-as-you-go?WT.mc_id=academic-105485-koreyst) - for √• gj√∏re den tilgjengelig for applikasjoner.

![Model deployment](../../../translated_images/ModelDeploy.7c78c2c5841567abf820d5da8354be454d3f20b62168905645aeac99e50c2562.no.png)

> [!NOTE]
> Ikke alle modeller i katalogen er for √∏yeblikket tilgjengelige for finjustering og/eller betal-etter-bruk distribusjon. Sjekk modellkortet for detaljer om modellens evner og begrensninger.

## Forbedre LLM-resultater

Vi har utforsket ulike typer LLM-er med v√•rt oppstartsteam og en skyplattform (Azure Machine Learning) som gj√∏r det mulig for oss √• sammenligne ulike modeller, evaluere dem p√• testdata, forbedre ytelsen og distribuere dem p√• inferensendepunkter.

Men n√•r b√∏r de vurdere √• finjustere en modell i stedet for √• bruke en forh√•ndstrent en? Finnes det andre tiln√¶rminger for √• forbedre modellens ytelse p√• spesifikke arbeidsbelastninger?

Det er flere tiln√¶rminger en bedrift kan bruke for √• oppn√• de resultatene de trenger fra en LLM. Du kan velge forskjellige typer modeller med ulike grader av trening n√•r du distribuerer en LLM i produksjon, med ulike niv√•er av kompleksitet, kostnad og kvalitet. Her er noen forskjellige tiln√¶rminger:

- **Prompt engineering med kontekst**. Ideen er √• gi nok kontekst n√•r du gir et prompt for √• sikre at du f√•r de svarene du trenger.

- **Retrieval Augmented Generation, RAG**. Dataene dine kan for eksempel eksistere i en database eller et nettendepunkt, for √• sikre at disse dataene, eller en del av dem, inkluderes ved prompting, kan du hente de relevante dataene og gj√∏re dem til en del av brukerens prompt.

- **Finjustert modell**. Her har du trent modellen videre p√• dine egne data, noe som har f√∏rt til at modellen er mer n√∏yaktig og responsiv p√• dine behov, men det kan v√¶re kostbart.

![LLMs deployment](../../../translated_images/Deploy.09224ecfe6a5ef47996fd0a44288772990139305451440c430662d43ac323ecd.no.png)

Bildekilde: [Fire m√•ter bedrifter distribuerer LLM-er | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-koreyst)

### Prompt Engineering med Kontekst

Forh√•ndstrente LLM-er fungerer veldig bra p√• generelle oppgaver innen naturlig spr√•k, selv ved √• kalle dem med et kort prompt, som en setning √• fullf√∏re eller et sp√∏rsm√•l ‚Äì den s√•kalte "zero-shot" l√¶ringen.

Jo mer brukeren kan ramme inn sp√∏rsm√•let sitt med en detaljert foresp√∏rsel og eksempler ‚Äì konteksten ‚Äì desto mer n√∏yaktig og n√¶rmere brukerens forventninger vil svaret v√¶re. I dette tilfellet snakker vi om "one-shot" l√¶ring hvis prompten inkluderer bare ett eksempel og "few-shot learning" hvis det inkluderer flere eksempler. Prompt engineering med kontekst er den mest kostnadseffektive tiln√¶rmingen √• starte med.

### Retrieval Augmented Generation (RAG)

LLM-er har den begrensningen at de kun kan bruke dataene som ble brukt under treningen deres for √• generere et svar. Dette betyr at de ikke vet noe om fakta som skjedde etter treningsprosessen, og de kan ikke f√• tilgang til ikke-offentlig informasjon (som bedriftsdata). Dette kan overvinnes gjennom RAG, en teknikk som forsterker prompten med ekstern data i form av dokumentutdrag, med tanke p√• promptens lengdebegrensninger. Dette st√∏ttes av Vektor-databaseverkt√∏y (som [Azure Vector Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-koreyst)) som henter de nyttige utdragene fra varierte forh√•ndsdefinerte datakilder og legger dem til i prompt-konteksten.

Denne teknikken er sv√¶rt nyttig n√•r en bedrift ikke har nok data, tid eller ressurser til √• finjustere en LLM, men likevel √∏nsker √• forbedre ytelsen p√• en spesifikk arbeidsbelastning og redusere risikoen for fabrikasjoner, det vil si mystifikasjon av virkeligheten eller skadelig innhold.

### Finjustert modell

Finjustering er en prosess som utnytter overf√∏ringsl√¶ring for √• 'tilpasse' modellen til en nedstr√∏ms oppgave eller for √• l√∏se et spesifikt problem. I motsetning til f√•-skudd l√¶ring og RAG, resulterer det i en ny modell som genereres, med oppdaterte vekter og skjevheter. Det krever et sett med trenings-eksempler best√•ende av en enkelt input (prompten) og dens tilknyttede output (fullf√∏ringen). Dette ville v√¶re den foretrukne tiln√¶rmingen hvis:

- **Bruk av finjusterte modeller**. En bedrift √∏nsker √• bruke finjusterte mindre kapable modeller (som innebyggingsmodeller) i stedet for h√∏yytelsesmodeller, noe som resulterer i en mer kostnadseffektiv og rask l√∏sning.

- **Vurdering av latens**. Latens er viktig for en spesifikk brukstilfelle, s√• det er ikke mulig √• bruke veldig lange prompt eller antallet eksempler som skal l√¶res av modellen passer ikke med promptens lengdebegrensning.

- **Holde seg oppdatert**. En bedrift har mye h√∏ykvalitetsdata og sannhetsverdier og ressursene som kreves for √• holde disse dataene oppdatert over tid.

### Trenet modell

√Ö trene en LLM fra bunnen av er uten tvil den mest utfordrende og komplekse tiln√¶rmingen √• adoptere, som krever enorme mengder data, dyktige ressurser og passende beregningskraft. Dette alternativet b√∏r bare vurderes i et scenario der en bedrift har et domene-spesifikt brukstilfelle og en stor mengde domenesentriske data.

## Kunnskapssjekk

Hva kan v√¶re en god tiln√¶rming for √• forbedre LLM-fullf√∏ringsresultater?

1. Prompt engineering med kontekst
1. RAG
1. Finjustert modell

A:3, hvis du har tid og ressurser og h√∏ykvalitetsdata, er finjustering det bedre alternativet for √• holde seg oppdatert. Men hvis du √∏nsker √• forbedre ting og mangler tid, er det verdt √• vurdere RAG f√∏rst.

## üöÄ Utfordring

Les mer om hvordan du kan [bruke RAG](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-koreyst) for din bedrift.

## Flott arbeid, fortsett l√¶ringen din

Etter √• ha fullf√∏rt denne leksjonen, sjekk ut v√•r [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for √• fortsette √• styrke kunnskapen din om Generativ AI!

G√• videre til Leksjon 3 hvor vi vil se p√• hvordan du kan [bygge med Generativ AI ansvarlig](../03-using-generative-ai-responsibly/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokumentet har blitt oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r betraktes som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r fra bruken av denne oversettelsen.