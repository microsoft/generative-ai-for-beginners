{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For å kjøre de følgende notatbøkene, hvis du ikke har gjort det ennå, må du sette openai-nøkkelen inne i .env-filen som `OPENAI_API_KEY`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n",
    "\n",
    "model = 'text-embedding-ada-002'\n",
    "\n",
    "SIMILARITIES_RESULTS_THRESHOLD = 0.75\n",
    "DATASET_NAME = \"../embedding_index_3m.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deretter skal vi laste inn Embedding-indeksen i en Pandas Dataframe. Embedding-indeksen er lagret i en JSON-fil kalt `embedding_index_3m.json`. Embedding-indeksen inneholder embeddingene for hver av YouTube-transkripsjonene frem til slutten av oktober 2023.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(source: str) -> pd.core.frame.DataFrame:\n",
    "    # Load the video session index\n",
    "    pd_vectors = pd.read_json(source)\n",
    "    return pd_vectors.drop(columns=[\"text\"], errors=\"ignore\").fillna(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deretter skal vi lage en funksjon kalt `get_videos` som søker i Embedding-indeksen etter spørringen. Funksjonen vil returnere de 5 beste videoene som er mest like spørringen. Funksjonen fungerer som følger:\n",
    "\n",
    "1. Først opprettes en kopi av Embedding-indeksen.\n",
    "2. Deretter beregnes Embedding for spørringen ved hjelp av OpenAI Embedding API.\n",
    "3. Så opprettes en ny kolonne i Embedding-indeksen kalt `similarity`. `similarity`-kolonnen inneholder cosinuslikheten mellom spørringens Embedding og Embedding for hvert videosegment.\n",
    "4. Deretter filtreres Embedding-indeksen etter `similarity`-kolonnen. Embedding-indeksen filtreres for kun å inkludere videoer som har en cosinuslikhet større enn eller lik 0,75.\n",
    "5. Til slutt sorteres Embedding-indeksen etter `similarity`-kolonnen, og de 5 beste videoene returneres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def get_videos(\n",
    "    query: str, dataset: pd.core.frame.DataFrame, rows: int\n",
    ") -> pd.core.frame.DataFrame:\n",
    "    # create a copy of the dataset\n",
    "    video_vectors = dataset.copy()\n",
    "\n",
    "    # get the embeddings for the query    \n",
    "    query_embeddings = client.embeddings.create(input=query, model=model).data[0].embedding\n",
    "\n",
    "    # create a new column with the calculated similarity for each row\n",
    "    video_vectors[\"similarity\"] = video_vectors[\"ada_v2\"].apply(\n",
    "        lambda x: cosine_similarity(np.array(query_embeddings), np.array(x))\n",
    "    )\n",
    "\n",
    "    # filter the videos by similarity\n",
    "    mask = video_vectors[\"similarity\"] >= SIMILARITIES_RESULTS_THRESHOLD\n",
    "    video_vectors = video_vectors[mask].copy()\n",
    "\n",
    "    # sort the videos by similarity\n",
    "    video_vectors = video_vectors.sort_values(by=\"similarity\", ascending=False).head(\n",
    "        rows\n",
    "    )\n",
    "\n",
    "    # return the top rows\n",
    "    return video_vectors.head(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denne funksjonen er veldig enkel, den skriver bare ut resultatene av søkespørringen.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_results(videos: pd.core.frame.DataFrame, query: str):\n",
    "    def _gen_yt_url(video_id: str, seconds: int) -> str:\n",
    "        \"\"\"convert time in format 00:00:00 to seconds\"\"\"\n",
    "        return f\"https://youtu.be/{video_id}?t={seconds}\"\n",
    "\n",
    "    print(f\"\\nVideos similar to '{query}':\")\n",
    "    for _, row in videos.iterrows():\n",
    "        youtube_url = _gen_yt_url(row[\"videoId\"], row[\"seconds\"])\n",
    "        print(f\" - {row['title']}\")\n",
    "        print(f\"   Summary: {' '.join(row['summary'].split()[:15])}...\")\n",
    "        print(f\"   YouTube: {youtube_url}\")\n",
    "        print(f\"   Similarity: {row['similarity']}\")\n",
    "        print(f\"   Speakers: {row['speaker']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Først lastes Embedding-indeksen inn i en Pandas Dataframe.  \n",
    "2. Deretter blir brukeren bedt om å skrive inn en forespørsel.  \n",
    "3. Så kalles funksjonen `get_videos` for å søke i Embedding-indeksen etter forespørselen.  \n",
    "4. Til slutt kalles funksjonen `display_results` for å vise resultatene til brukeren.  \n",
    "5. Brukeren blir deretter bedt om å skrive inn en ny forespørsel. Denne prosessen fortsetter til brukeren skriver `exit`.  \n",
    "\n",
    "![](../../../../translated_images/notebook-search.1e320b9c7fcbb0bc.no.png)  \n",
    "\n",
    "Du vil bli bedt om å skrive inn en forespørsel. Skriv inn en forespørsel og trykk enter. Applikasjonen vil returnere en liste over videoer som er relevante for forespørselen. Applikasjonen vil også returnere en lenke til stedet i videoen hvor svaret på spørsmålet finnes.  \n",
    "\n",
    "Her er noen forespørsler du kan prøve:  \n",
    "\n",
    "- Hva er Azure Machine Learning?  \n",
    "- Hvordan fungerer konvolusjonelle nevrale nettverk?  \n",
    "- Hva er et nevralt nettverk?  \n",
    "- Kan jeg bruke Jupyter Notebooks med Azure Machine Learning?  \n",
    "- Hva er ONNX?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd_vectors = load_dataset(DATASET_NAME)\n",
    "\n",
    "# get user query from input\n",
    "while True:\n",
    "    query = input(\"Enter a query: \")\n",
    "    if query == \"exit\":\n",
    "        break\n",
    "    videos = get_videos(query, pd_vectors, 5)\n",
    "    display_results(videos, query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Ansvarsfraskrivelse**:\nDette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter nøyaktighet, vennligst vær oppmerksom på at automatiske oversettelser kan inneholde feil eller unøyaktigheter. Det opprinnelige dokumentet på originalspråket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforståelser eller feiltolkninger som oppstår ved bruk av denne oversettelsen.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "afb84920098ad1e6e4ca63ee9a61d9b8",
   "translation_date": "2025-12-19T10:36:37+00:00",
   "source_file": "08-building-search-applications/python/oai-solution.ipynb",
   "language_code": "no"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}