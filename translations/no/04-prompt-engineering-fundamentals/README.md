<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "8b3cb38518cf4fe7714d2f5e74dfa3eb",
  "translation_date": "2025-10-03T09:41:08+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "no"
}
-->
# Grunnleggende om Prompt Engineering

[![Grunnleggende om Prompt Engineering](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.no.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduksjon
Denne modulen dekker essensielle konsepter og teknikker for √• lage effektive prompts i generative AI-modeller. M√•ten du skriver din prompt til en LLM har stor betydning. En n√∏ye utformet prompt kan gi bedre kvalitet p√• responsen. Men hva betyr egentlig begreper som _prompt_ og _prompt engineering_? Og hvordan kan jeg forbedre prompt _input_ som jeg sender til LLM? Dette er sp√∏rsm√•lene vi skal fors√∏ke √• besvare i dette kapittelet og det neste.

_Generativ AI_ er i stand til √• skape nytt innhold (f.eks. tekst, bilder, lyd, kode osv.) som svar p√• brukerforesp√∏rsler. Den oppn√•r dette ved hjelp av _Large Language Models_ som OpenAIs GPT ("Generative Pre-trained Transformer")-serien, som er trent til √• bruke naturlig spr√•k og kode.

Brukere kan n√• samhandle med disse modellene gjennom kjente paradigmer som chat, uten behov for teknisk ekspertise eller oppl√¶ring. Modellene er _prompt-baserte_ - brukere sender en tekstinput (prompt) og f√•r tilbake AI-responsen (completion). De kan deretter "chatte med AI-en" iterativt, i samtaler med flere runder, og finjustere sin prompt til responsen samsvarer med forventningene.

"Prompts" blir n√• det prim√¶re _programmeringsgrensesnittet_ for generative AI-applikasjoner, som forteller modellene hva de skal gj√∏re og p√•virker kvaliteten p√• de returnerte svarene. "Prompt Engineering" er et raskt voksende fagfelt som fokuserer p√• _design og optimalisering_ av prompts for √• levere konsistente og kvalitetsmessige svar i stor skala.

## L√¶ringsm√•l

I denne leksjonen l√¶rer vi hva Prompt Engineering er, hvorfor det er viktig, og hvordan vi kan lage mer effektive prompts for en gitt modell og applikasjonsm√•l. Vi vil forst√• kjernebegreper og beste praksis for prompt engineering - og l√¶re om et interaktivt Jupyter Notebooks "sandbox"-milj√∏ hvor vi kan se disse konseptene anvendt p√• virkelige eksempler.

Ved slutten av denne leksjonen vil vi kunne:

1. Forklare hva prompt engineering er og hvorfor det er viktig.
2. Beskrive komponentene i en prompt og hvordan de brukes.
3. L√¶re beste praksis og teknikker for prompt engineering.
4. Anvende l√¶rte teknikker p√• virkelige eksempler, ved bruk av en OpenAI-endepunkt.

## Viktige begreper

Prompt Engineering: Praksisen med √• designe og finjustere inputs for √• veilede AI-modeller mot √• produsere √∏nskede outputs.  
Tokenisering: Prosessen med √• konvertere tekst til mindre enheter, kalt tokens, som en modell kan forst√• og prosessere.  
Instruksjons-tilpassede LLM-er: Store spr√•kmodeller (LLMs) som har blitt finjustert med spesifikke instruksjoner for √• forbedre n√∏yaktigheten og relevansen av svarene.

## L√¶ringsmilj√∏

Prompt engineering er for √∏yeblikket mer kunst enn vitenskap. Den beste m√•ten √• forbedre v√•r intuisjon for det er √• _√∏ve mer_ og adoptere en pr√∏ving-og-feiling-tiln√¶rming som kombinerer ekspertise innen applikasjonsdomener med anbefalte teknikker og modellspesifikke optimaliseringer.

Jupyter Notebook som f√∏lger med denne leksjonen gir et _sandbox_-milj√∏ hvor du kan pr√∏ve ut det du l√¶rer - enten underveis eller som en del av kodeutfordringen p√• slutten. For √• utf√∏re √∏velsene, trenger du:

1. **En Azure OpenAI API-n√∏kkel** - tjenesteendepunktet for en distribuert LLM.  
2. **Et Python-runtime** - hvor Notebook kan kj√∏res.  
3. **Lokale milj√∏variabler** - _fullf√∏r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst)-trinnene n√• for √• bli klar_.  

Notebooken kommer med _start√∏velser_ - men du oppfordres til √• legge til dine egne _Markdown_- (beskrivelse) og _Code_- (promptforesp√∏rsler) seksjoner for √• pr√∏ve ut flere eksempler eller ideer - og bygge din intuisjon for promptdesign.

## Illustrert guide

Vil du f√• et overblikk over hva denne leksjonen dekker f√∏r du dykker inn? Sjekk ut denne illustrerte guiden, som gir deg en f√∏lelse av hovedtemaene som dekkes og de viktigste l√¶ringspunktene du b√∏r tenke p√• i hver av dem. Leksjonsveikartet tar deg fra √• forst√• kjernebegreper og utfordringer til √• adressere dem med relevante teknikker og beste praksis for prompt engineering. Merk at "Avanserte teknikker"-seksjonen i denne guiden refererer til innhold som dekkes i _neste_ kapittel av dette pensumet.

![Illustrert guide til Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.no.png)

## V√•r oppstart

La oss n√• snakke om hvordan _dette temaet_ relaterer seg til v√•r oppstartsoppdrag om √• [bringe AI-innovasjon til utdanning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi √∏nsker √• bygge AI-drevne applikasjoner for _personlig l√¶ring_ - s√• la oss tenke p√• hvordan ulike brukere av v√•r applikasjon kan "designe" prompts:

- **Administratorer** kan be AI om √• _analysere pensumdata for √• identifisere mangler i dekningen_. AI kan oppsummere resultater eller visualisere dem med kode.  
- **L√¶rere** kan be AI om √• _lage en leksjonsplan for en m√•lgruppe og et emne_. AI kan bygge den personlige planen i et spesifisert format.  
- **Studenter** kan be AI om √• _veilede dem i et vanskelig emne_. AI kan n√• veilede studenter med leksjoner, hint og eksempler tilpasset deres niv√•.  

Dette er bare toppen av isfjellet. Sjekk ut [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - et √•pen kildekode-bibliotek med prompts kuratert av utdanningseksperter - for √• f√• en bredere forst√•else av mulighetene! _Pr√∏v √• kj√∏re noen av disse prompts i sandkassen eller ved bruk av OpenAI Playground for √• se hva som skjer!_

<!--
LEKSJONSMAL:
Denne enheten b√∏r dekke kjernebegrep #1.
Forsterk begrepet med eksempler og referanser.

KJERNEBEGREP #1:
Prompt Engineering.
Definer det og forklar hvorfor det er n√∏dvendig.
-->

## Hva er Prompt Engineering?

Vi startet denne leksjonen med √• definere **Prompt Engineering** som prosessen med √• _designe og optimalisere_ tekstinputs (prompts) for √• levere konsistente og kvalitetsmessige svar (completions) for et gitt applikasjonsm√•l og modell. Vi kan tenke p√• dette som en 2-trinns prosess:

- _designe_ den innledende prompten for en gitt modell og m√•l  
- _finjustere_ prompten iterativt for √• forbedre kvaliteten p√• responsen  

Dette er n√∏dvendigvis en pr√∏ving-og-feiling-prosess som krever brukerintuisjon og innsats for √• oppn√• optimale resultater. S√• hvorfor er det viktig? For √• svare p√• det sp√∏rsm√•let, m√• vi f√∏rst forst√• tre konsepter:

- _Tokenisering_ = hvordan modellen "ser" prompten  
- _Base LLMs_ = hvordan grunnmodellen "prosesserer" en prompt  
- _Instruksjons-tilpassede LLMs_ = hvordan modellen n√• kan se "oppgaver"  

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ der ulike modeller (eller versjoner av en modell) kan tokenisere den samme prompten p√• forskjellige m√•ter. Siden LLM-er er trent p√• tokens (og ikke p√• r√• tekst), har m√•ten prompts blir tokenisert direkte innvirkning p√• kvaliteten p√• den genererte responsen.

For √• f√• en intuisjon for hvordan tokenisering fungerer, pr√∏v verkt√∏y som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist nedenfor. Kopier inn din prompt - og se hvordan den blir konvertert til tokens, og legg merke til hvordan mellomrom og tegnsetting h√•ndteres. Merk at dette eksemplet viser en eldre LLM (GPT-3) - s√• √• pr√∏ve dette med en nyere modell kan gi et annet resultat.

![Tokenisering](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.no.png)

### Konsept: Grunnmodeller

N√•r en prompt er tokenisert, er den prim√¶re funksjonen til ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grunnmodellen) √• forutsi token i den sekvensen. Siden LLM-er er trent p√• massive tekstdatasett, har de en god forst√•else av de statistiske relasjonene mellom tokens og kan gj√∏re den forutsigelsen med en viss grad av selvtillit. Merk at de ikke forst√•r _meningen_ med ordene i prompten eller token; de ser bare et m√∏nster de kan "fullf√∏re" med sin neste forutsigelse. De kan fortsette √• forutsi sekvensen til de blir stoppet av brukerintervensjon eller en forh√•ndsdefinert betingelse.

Vil du se hvordan prompt-basert fullf√∏ring fungerer? Skriv inn den ovennevnte prompten i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinnstillingene. Systemet er konfigurert til √• behandle prompts som foresp√∏rsler om informasjon - s√• du b√∏r se en fullf√∏ring som tilfredsstiller denne konteksten.

Men hva om brukeren √∏nsket √• se noe spesifikt som oppfylte visse kriterier eller oppgaveform√•l? Det er her _instruksjons-tilpassede_ LLM-er kommer inn i bildet.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.no.png)

### Konsept: Instruksjons-tilpassede LLMs

En [Instruksjons-tilpasset LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grunnmodellen og finjusterer den med eksempler eller input/output-par (f.eks. meldinger med flere runder) som kan inneholde klare instruksjoner - og responsen fra AI fors√∏ker √• f√∏lge den instruksjonen.

Dette bruker teknikker som Reinforcement Learning with Human Feedback (RLHF) som kan trene modellen til √• _f√∏lge instruksjoner_ og _l√¶re av tilbakemeldinger_ slik at den produserer svar som er bedre egnet til praktiske applikasjoner og mer relevante for brukerens m√•l.

La oss pr√∏ve det - g√• tilbake til den ovennevnte prompten, men endre n√• _systemmeldingen_ for √• gi f√∏lgende instruksjon som kontekst:

> _Oppsummer innholdet du f√•r for en andreklassing. Hold resultatet til ett avsnitt med 3-5 punktlister._

Se hvordan resultatet n√• er tilpasset for √• reflektere det √∏nskede m√•let og formatet? En l√¶rer kan n√• direkte bruke denne responsen i sine lysbilder for den klassen.

![Instruksjons-tilpasset LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.no.png)

## Hvorfor trenger vi Prompt Engineering?

N√• som vi vet hvordan prompts behandles av LLM-er, la oss snakke om _hvorfor_ vi trenger prompt engineering. Svaret ligger i det faktum at n√•v√¶rende LLM-er har en rekke utfordringer som gj√∏r _p√•litelig og konsistent fullf√∏ring_ mer utfordrende √• oppn√• uten √• legge innsats i utformingen og optimaliseringen av prompts. For eksempel:

1. **Modellresponser er stokastiske.** Den _samme prompten_ vil sannsynligvis produsere forskjellige svar med forskjellige modeller eller modellversjoner. Og den kan til og med produsere forskjellige resultater med _samme modell_ p√• forskjellige tidspunkter. _Prompt engineering-teknikker kan hjelpe oss med √• minimere disse variasjonene ved √• gi bedre retningslinjer_.  

1. **Modeller kan fabrikere svar.** Modeller er forh√•ndstrent med _store, men begrensede_ datasett, noe som betyr at de mangler kunnskap om konsepter utenfor det treningsomr√•det. Som et resultat kan de produsere fullf√∏ringer som er un√∏yaktige, oppdiktede eller direkte motstridende med kjente fakta. _Prompt engineering-teknikker hjelper brukere med √• identifisere og redusere slike fabrikasjoner, f.eks. ved √• be AI om sitater eller resonnement_.  

1. **Modellers evner vil variere.** Nyere modeller eller modellgenerasjoner vil ha rikere evner, men ogs√• bringe unike s√¶regenheter og avveininger i kostnad og kompleksitet. _Prompt engineering kan hjelpe oss med √• utvikle beste praksis og arbeidsflyter som abstraherer bort forskjeller og tilpasser seg modellspesifikke krav p√• skalerbare, s√∏ml√∏se m√•ter_.  

La oss se dette i aksjon i OpenAI eller Azure OpenAI Playground:

- Bruk den samme prompten med forskjellige LLM-distribusjoner (f.eks. OpenAI, Azure OpenAI, Hugging Face) - s√• du variasjonene?  
- Bruk den samme prompten gjentatte ganger med den _samme_ LLM-distribusjonen (f.eks. Azure OpenAI Playground) - hvordan skilte disse variasjonene seg?  

### Eksempel p√• fabrikasjoner

I dette kurset bruker vi begrepet **"fabrikasjon"** for √• referere til fenomenet der LLM-er noen ganger genererer faktuelt feil informasjon p√• grunn av begrensninger i treningen eller andre faktorer. Du har kanskje ogs√• h√∏rt dette omtalt som _"hallusinasjoner"_ i popul√¶re artikler eller forskningsartikler. Vi anbefaler imidlertid sterkt √• bruke _"fabrikasjon"_ som begrep slik at vi ikke utilsiktet tillegger en menneskelignende egenskap til et maskindrevet resultat. Dette forsterker ogs√• [Retningslinjer for ansvarlig AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologiperspektiv, ved √• fjerne begreper som kan anses som st√∏tende eller ikke-inkluderende i visse kontekster.

Vil du f√• en f√∏lelse av hvordan fabrikasjoner fungerer? Tenk p√• en prompt som instruerer AI til √• generere innhold for et ikke-eksisterende tema (for √• sikre at det ikke finnes i treningsdatasettet). For eksempel - jeg pr√∏vde denne prompten:

> **Prompt:** lag en leksjonsplan om den marsianske krigen i 2076.  
Et netts√∏k viste at det finnes fiktive beretninger (f.eks. TV-serier eller b√∏ker) om kriger p√• Mars ‚Äì men ingen fra 2076. Sunn fornuft forteller oss ogs√• at 2076 er _i fremtiden_ og derfor ikke kan knyttes til en virkelig hendelse.

S√• hva skjer n√•r vi tester denne prompten med ulike LLM-leverand√∏rer?

> **Respons 1**: OpenAI Playground (GPT-35)

![Respons 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.no.png)

> **Respons 2**: Azure OpenAI Playground (GPT-35)

![Respons 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.no.png)

> **Respons 3**: Hugging Face Chat Playground (LLama-2)

![Respons 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.no.png)

Som forventet gir hver modell (eller modellversjon) litt forskjellige svar, takket v√¶re stokastisk oppf√∏rsel og variasjoner i modellens evner. For eksempel retter √©n modell seg mot et publikum p√• 8. klassetrinn, mens en annen antar en videreg√•ende elev. Men alle tre modellene genererte svar som kunne overbevise en uinformert bruker om at hendelsen var ekte.

Teknikker for promptutforming, som _metaprompting_ og _konfigurasjon av temperatur_, kan redusere modellens fabrikasjoner til en viss grad. Nye arkitekturer for promptutforming integrerer ogs√• nye verkt√∏y og teknikker s√∏ml√∏st i promptflyten for √• dempe eller redusere noen av disse effektene.

## Case Study: GitHub Copilot

La oss avslutte denne delen med √• f√• en forst√•else av hvordan promptutforming brukes i virkelige l√∏sninger ved √• se p√• en case study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI-parprogrammerer" ‚Äì den konverterer tekstprompter til kodeforslag og er integrert i ditt utviklingsmilj√∏ (f.eks. Visual Studio Code) for en s√∏ml√∏s brukeropplevelse. Som dokumentert i serien av blogger nedenfor, var den tidligste versjonen basert p√• OpenAI Codex-modellen ‚Äì med ingeni√∏rer som raskt inns√• behovet for √• finjustere modellen og utvikle bedre teknikker for promptutforming for √• forbedre kodekvaliteten. I juli [lanserte de en forbedret AI-modell som g√•r utover Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for enda raskere forslag.

Les innleggene i rekkef√∏lge for √• f√∏lge deres l√¶ringsreise.

- **Mai 2023** | [GitHub Copilot blir bedre til √• forst√• koden din](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mai 2023** | [Inne i GitHub: Arbeid med LLM-ene bak GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juni 2023** | [Hvordan skrive bedre promter for GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juli 2023** | [.. GitHub Copilot g√•r utover Codex med forbedret AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [En utviklers guide til promptutforming og LLM-er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **September 2023** | [Hvordan bygge en bedrifts-LLM-app: L√¶rdom fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• bla gjennom deres [ingeni√∏rblogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere innlegg som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som viser hvordan disse modellene og teknikkene _brukes_ for √• drive virkelige applikasjoner.

---

## Promptkonstruksjon

Vi har sett hvorfor promptutforming er viktig ‚Äì n√• skal vi forst√• hvordan promter _konstrueres_ slik at vi kan evaluere ulike teknikker for mer effektiv utforming av promter.

### Grunnleggende prompt

La oss starte med den grunnleggende prompten: en tekstinput sendt til modellen uten annen kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste ordene av den amerikanske nasjonalsangen til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), fullf√∏rer den umiddelbart responsen med de neste linjene, som illustrerer den grunnleggende prediksjonsatferden.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det h√∏res ut som du starter teksten til "The Star-Spangled Banner," USAs nasjonalsang. Den fullstendige teksten er ...                     |

### Kompleks prompt

N√• legger vi til kontekst og instruksjoner til den grunnleggende prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) lar oss konstruere en kompleks prompt som en samling av _meldinger_ med:

- Input/output-par som reflekterer _brukerens_ input og _assistentens_ respons.
- Systemmelding som setter konteksten for assistentens oppf√∏rsel eller personlighet.

Foresp√∏rselen er n√• i formen nedenfor, hvor _tokeniseringen_ effektivt fanger relevant informasjon fra kontekst og samtale. N√• kan endring av systemkonteksten ha like stor innvirkning p√• kvaliteten p√• responsene som brukerens input.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```


### Instruksjonsprompt

I eksemplene ovenfor var brukerens prompt en enkel tekstforesp√∏rsel som kan tolkes som en informasjonsforesp√∏rsel. Med _instruksjonspromter_ kan vi bruke teksten til √• spesifisere en oppgave mer detaljert, og gi bedre veiledning til AI-en. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruksjonstype    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivelse av den amerikanske borgerkrigen                                                                                                                                                                                   | _returnerte et enkelt avsnitt_                                                                                            | Enkel               |
| Skriv en beskrivelse av den amerikanske borgerkrigen. Oppgi viktige datoer og hendelser og beskriv deres betydning                                                                                                                      | _returnerte et avsnitt etterfulgt av en liste over viktige datoer med beskrivelser_                                       | Kompleks            |
| Skriv en beskrivelse av den amerikanske borgerkrigen i ett avsnitt. Oppgi 3 punktlister med viktige datoer og deres betydning. Oppgi 3 flere punktlister med viktige historiske personer og deres bidrag. Returner output som en JSON-fil | _returnerte mer omfattende detaljer i en tekstboks, formatert som JSON som du kan kopiere og validere etter behov_         | Kompleks. Formatert |

## Prim√¶rinnhold

I eksemplene ovenfor var prompten fortsatt ganske √•pen, og lot LLM-en avgj√∏re hvilken del av dens forh√•ndstrente datasett som var relevant. Med designm√∏nsteret _prim√¶rinnhold_ deles inputteksten i to deler:

- en instruksjon (handling)
- relevant innhold (som p√•virker handlingen)

Her er et eksempel der instruksjonen er "oppsummer dette i 2 setninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gassgigant med en masse som er en tusendel av solens, men to og en halv gang s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historien ble nedskrevet. Den er oppkalt etter den romerske guden Jupiter. N√•r den ses fra jorden, kan Jupiter v√¶re lys nok til at det reflekterte lyset kaster synlige skygger, og er i gjennomsnitt det tredje lyseste naturlige objektet p√• nattehimmelen etter m√•nen og Venus. <br/> **Oppsummer dette i 2 korte setninger** | Jupiter, den femte planeten fra solen, er den st√∏rste i solsystemet og kjent for √• v√¶re et av de lyseste objektene p√• nattehimmelen. Oppkalt etter den romerske guden Jupiter, er det en gassgigant med en masse som er to og en halv gang s√• stor som alle de andre planetene til sammen. |

Segmentet med prim√¶rinnhold kan brukes p√• ulike m√•ter for √• drive mer effektive instruksjoner:

- **Eksempler** ‚Äì i stedet for √• fortelle modellen hva den skal gj√∏re med en eksplisitt instruksjon, gi den eksempler p√• hva den skal gj√∏re og la den utlede m√∏nsteret.
- **Hint** ‚Äì f√∏lg instruksjonen med et "hint" som gir modellen en retning, og guider den mot mer relevante svar.
- **Maler** ‚Äì dette er repeterbare "oppskrifter" for promter med plassholdere (variabler) som kan tilpasses med data for spesifikke bruksomr√•der.

La oss utforske disse i praksis.

### Bruk av eksempler

Dette er en tiln√¶rming der du bruker prim√¶rinnholdet til √• "mate modellen" med noen eksempler p√• √∏nsket output for en gitt instruksjon, og lar den utlede m√∏nsteret for √∏nsket output. Basert p√• antall eksempler som gis, kan vi ha zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r n√• av tre komponenter:

- En oppgavebeskrivelse
- Noen eksempler p√• √∏nsket output
- Starten p√• et nytt eksempel (som blir en implisitt oppgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot   | "Solen skinner". Oversett til spansk                                                                                                                  | "El Sol est√° brillando".    |
| One-shot    | "Solen skinner" => ""El Sol est√° brillando". <br> "Det er en kald og vindfull dag" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot    | Spilleren l√∏p basene => Baseball <br/> Spilleren slo en ess => Tennis <br/> Spilleren slo en sekser => Cricket <br/> Spilleren gjorde en slam-dunk => | Basketball                  |
|             |                                                                                                                                                       |                             |

Legg merke til hvordan vi m√•tte gi eksplisitt instruksjon ("Oversett til spansk") i zero-shot prompting, men det blir utledet i one-shot prompting-eksemplet. Few-shot-eksemplet viser hvordan flere eksempler gir modellen mulighet til √• gj√∏re mer n√∏yaktige utledninger uten ekstra instruksjoner.

### Prompt-hint

En annen teknikk for bruk av prim√¶rinnhold er √• gi _hint_ i stedet for eksempler. I dette tilfellet gir vi modellen et dytt i riktig retning ved √• _starte den_ med et utdrag som reflekterer √∏nsket responsformat. Modellen "tar hintet" og fortsetter i samme stil.

| Antall hint | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :---------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0           | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gassgigant med en masse som er en tusendel av solens, men to og en halv gang s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historien ble nedskrevet. <br/>**Oppsummer dette**                                       | Jupiter er den st√∏rste planeten i solsystemet og den femte fra solen. Den er en gassgigant med en masse som er 1/1000 av solens, men tyngre enn alle de andre planetene til sammen. Gamle sivilisasjoner har kjent til Jupiter lenge, og den er lett synlig p√• nattehimmelen. |
| 1              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Det er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger massen av alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historien ble nedskrevet. <br/>**Oppsummer dette** <br/> Det vi l√¶rte er at Jupiter | er den femte planeten fra solen og den st√∏rste i solsystemet. Det er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger massen av alle de andre planetene til sammen. Den er lett synlig for det blotte √∏ye og har v√¶rt kjent siden antikken.                        |
| 2              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Det er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger massen av alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historien ble nedskrevet. <br/>**Oppsummer dette** <br/> Topp 3 fakta vi l√¶rte:         | 1. Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. <br/> 2. Det er en gasskjempe med en masse som er en tusendel av solens...<br/> 3. Jupiter har v√¶rt synlig for det blotte √∏ye siden antikken ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Maler for oppgaver

En oppgavemal er en _forh√•ndsdefinert oppskrift for en oppgave_ som kan lagres og brukes p√• nytt etter behov, for √• sikre mer konsistente brukeropplevelser i stor skala. I sin enkleste form er det bare en samling av oppgaveeksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som gir b√•de interaktive oppgavekomponenter (bruker- og systemmeldinger) og API-drevet foresp√∏rselsformat - for √• st√∏tte gjenbruk.

I sin mer komplekse form, som [dette eksemplet fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), inneholder den _plassholdere_ som kan erstattes med data fra ulike kilder (brukerinndata, systemkontekst, eksterne datakilder osv.) for √• generere en oppgave dynamisk. Dette lar oss lage et bibliotek med gjenbrukbare oppgaver som kan brukes til √• sikre konsistente brukeropplevelser **programmatisk** i stor skala.

Til slutt ligger den virkelige verdien av maler i evnen til √• lage og publisere _oppgavebiblioteker_ for vertikale applikasjonsdomener - der oppgavemalen n√• er _optimalisert_ for √• reflektere applikasjonsspesifikke kontekster eller eksempler som gj√∏r svarene mer relevante og n√∏yaktige for den m√•lrettede brukergruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst)-repoet er et godt eksempel p√• denne tiln√¶rmingen, som kuraterer et bibliotek med oppgaver for utdanningssektoren med vekt p√• n√∏kkelm√•l som leksjonsplanlegging, l√¶replanutforming, studentveiledning osv.

## St√∏ttende innhold

Hvis vi tenker p√• oppgavekonstruksjon som √• ha en instruksjon (oppgave) og et m√•l (prim√¶rt innhold), s√• er _sekund√¶rt innhold_ som ekstra kontekst vi gir for √• **p√•virke resultatet p√• en eller annen m√•te**. Det kan v√¶re justeringsparametere, formateringsinstruksjoner, emnetaksonomier osv. som kan hjelpe modellen med √• _tilpasse_ svaret til √• passe de √∏nskede brukerbehovene eller forventningene.

For eksempel: Gitt en kurskatalog med omfattende metadata (navn, beskrivelse, niv√•, metadatakoder, instrukt√∏r osv.) om alle tilgjengelige kurs i l√¶replanen:

- vi kan definere en instruksjon for √• "oppsummere kurskatalogen for h√∏sten 2023"
- vi kan bruke det prim√¶re innholdet til √• gi noen eksempler p√• √∏nsket resultat
- vi kan bruke det sekund√¶re innholdet til √• identifisere de 5 viktigste "kodene" av interesse.

N√• kan modellen gi en oppsummering i formatet vist av de f√• eksemplene - men hvis et resultat har flere koder, kan den prioritere de 5 kodene identifisert i det sekund√¶re innholdet.

---

<!--
LEKSJONSMAL:
Denne enheten b√∏r dekke kjernekonsept #1.
Forsterk konseptet med eksempler og referanser.

KONSEPT #3:
Teknikker for oppgaveutforming.
Hva er noen grunnleggende teknikker for oppgaveutforming?
Illustrer det med noen √∏velser.
-->

## Beste praksis for oppgaveutforming

N√• som vi vet hvordan oppgaver kan _konstrueres_, kan vi begynne √• tenke p√• hvordan vi kan _designe_ dem for √• reflektere beste praksis. Vi kan tenke p√• dette i to deler - √• ha riktig _tankesett_ og bruke riktige _teknikker_.

### Tankesett for oppgaveutforming

Oppgaveutforming er en pr√∏ving-og-feiling-prosess, s√• husk tre brede retningslinjer:

1. **Forst√•else av domenet er viktig.** Svarets n√∏yaktighet og relevans er en funksjon av _domenet_ der applikasjonen eller brukeren opererer. Bruk din intuisjon og domenekunnskap til √• **tilpasse teknikker** ytterligere. For eksempel, definer _domenespesifikke personligheter_ i systemoppgavene dine, eller bruk _domenespesifikke maler_ i brukeroppgavene dine. Gi sekund√¶rt innhold som reflekterer domenespesifikke kontekster, eller bruk _domenespesifikke ledetr√•der og eksempler_ for √• veilede modellen mot kjente bruksm√∏nstre.

2. **Forst√•else av modellen er viktig.** Vi vet at modeller er stokastiske av natur. Men modellimplementeringer kan ogs√• variere n√•r det gjelder treningsdatasettet de bruker (forh√•ndstrent kunnskap), funksjonene de gir (f.eks. via API eller SDK) og typen innhold de er optimalisert for (f.eks. kode vs. bilder vs. tekst). Forst√• styrkene og begrensningene til modellen du bruker, og bruk den kunnskapen til √• _prioritere oppgaver_ eller bygge _tilpassede maler_ som er optimalisert for modellens funksjoner.

3. **Iterasjon og validering er viktig.** Modeller utvikler seg raskt, og det gj√∏r ogs√• teknikkene for oppgaveutforming. Som domenekspert kan du ha annen kontekst eller kriterier for _din_ spesifikke applikasjon, som kanskje ikke gjelder for det bredere samfunnet. Bruk verkt√∏y og teknikker for oppgaveutforming for √• "komme i gang" med oppgavekonstruksjon, og iterer og valider resultatene ved hjelp av din egen intuisjon og domenekunnskap. Registrer innsiktene dine og opprett en **kunnskapsbase** (f.eks. oppgavebiblioteker) som kan brukes som en ny baseline av andre, for raskere iterasjoner i fremtiden.

## Beste praksis

La oss n√• se p√• vanlige beste praksiser som anbefales av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst)-praktikere.

| Hva                               | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Evaluer de nyeste modellene.      | Nye modellgenerasjoner har sannsynligvis forbedrede funksjoner og kvalitet - men kan ogs√• medf√∏re h√∏yere kostnader. Evaluer dem for innvirkning, og ta deretter migreringsbeslutninger.                                                               |
| Skill instruksjoner og kontekst   | Sjekk om modellen/leverand√∏ren din definerer _avgrensere_ for √• skille instruksjoner, prim√¶rt og sekund√¶rt innhold tydeligere. Dette kan hjelpe modeller med √• tildele vekter mer n√∏yaktig til tokens.                                                  |
| V√¶r spesifikk og tydelig          | Gi flere detaljer om √∏nsket kontekst, resultat, lengde, format, stil osv. Dette vil forbedre b√•de kvaliteten og konsistensen i svarene. Fang oppskrifter i gjenbrukbare maler.                                                                         |
| V√¶r beskrivende, bruk eksempler   | Modeller kan respondere bedre p√• en "vis og fortell"-tiln√¶rming. Start med en `zero-shot`-tiln√¶rming der du gir en instruksjon (men ingen eksempler), og pr√∏v deretter `few-shot` som en forbedring, ved √• gi noen eksempler p√• √∏nsket resultat. Bruk analogier. |
| Bruk ledetr√•der for √• starte svar | Gi det noen ledende ord eller fraser som det kan bruke som utgangspunkt for svaret, for √• styre det mot et √∏nsket resultat.                                                                                                                           |
| Gjenta                           | Noen ganger kan det v√¶re n√∏dvendig √• gjenta seg selv til modellen. Gi instruksjoner f√∏r og etter ditt prim√¶re innhold, bruk en instruksjon og en ledetr√•d osv. Iterer og valider for √• se hva som fungerer.                                              |
| Rekkef√∏lge betyr noe              | Rekkef√∏lgen du presenterer informasjon til modellen i, kan p√•virke resultatet, selv i l√¶ringseksemplene, takket v√¶re nylighetsskjevhet. Pr√∏v forskjellige alternativer for √• se hva som fungerer best.                                                  |
| Gi modellen en "utvei"            | Gi modellen et _fallback_-svar den kan gi hvis den ikke kan fullf√∏re oppgaven av en eller annen grunn. Dette kan redusere sjansen for at modellen genererer falske eller oppdiktede svar.                                                              |
|                                   |                                                                                                                                                                                                                                                       |

Som med enhver beste praksis, husk at _resultatene kan variere_ avhengig av modellen, oppgaven og domenet. Bruk disse som et utgangspunkt, og iterer for √• finne hva som fungerer best for deg. Evaluer kontinuerlig prosessen for oppgaveutforming etter hvert som nye modeller og verkt√∏y blir tilgjengelige, med fokus p√• prosessskalerbarhet og svarkvalitet.

<!--
LEKSJONSMAL:
Denne enheten b√∏r gi en kodeutfordring hvis aktuelt

UTFORDRING:
Lenke til en Jupyter Notebook med kun kodekommentarer i instruksjonene (kodeseksjonene er tomme).

L√òSNING:
Lenke til en kopi av den Notebook med oppgavene fylt ut og kj√∏rt, som viser hva ett eksempel kan v√¶re.
-->

## Oppgave

Gratulerer! Du har kommet til slutten av leksjonen! Det er p√• tide √• teste noen av disse konseptene og teknikkene med ekte eksempler!

For oppgaven v√•r skal vi bruke en Jupyter Notebook med √∏velser du kan fullf√∏re interaktivt. Du kan ogs√• utvide Notebook med dine egne Markdown- og kodeceller for √• utforske ideer og teknikker p√• egen h√•nd.

### For √• komme i gang, fork repoet, deretter

- (Anbefalt) Start GitHub Codespaces
- (Alternativt) Klon repoet til din lokale enhet og bruk det med Docker Desktop
- (Alternativt) √Öpne Notebook med ditt foretrukne Notebook-runtime-milj√∏.

### Deretter, konfigurer milj√∏variablene dine

- Kopier `.env.copy`-filen i repo-roten til `.env` og fyll inn verdiene for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. Kom tilbake til [Learning Sandbox-seksjonen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) for √• l√¶re hvordan.

### Deretter, √•pne Jupyter Notebook

- Velg runtime-kjernen. Hvis du bruker alternativ 1 eller 2, velg bare standard Python 3.10.x-kjernen som tilbys av utviklingscontaineren.

Du er klar til √• kj√∏re √∏velsene. Merk at det ikke finnes _riktige eller gale_ svar her - bare utforsking av alternativer gjennom pr√∏ving-og-feiling og bygging av intuisjon for hva som fungerer for en gitt modell og applikasjonsdomene.

_Av denne grunn er det ingen kode-l√∏sningssegmenter i denne leksjonen. I stedet vil Notebook ha Markdown-celler med tittelen "Min l√∏sning:" som viser ett eksempel p√• resultat for referanse._

 <!--
LEKSJONSMAL:
Avslutt seksjonen med en oppsummering og ressurser for selvstyrt l√¶ring.
-->

## Kunnskapssjekk

Hvilken av f√∏lgende er en god oppgave som f√∏lger noen rimelige beste praksiser?

1. Vis meg et bilde av en r√∏d bil
2. Vis meg et bilde av en r√∏d bil av merke Volvo og modell XC90 parkert ved en klippe med solnedgang
3. Vis meg et bilde av en r√∏d bil av merke Volvo og modell XC90

A: 2, det er den beste oppgaven da den gir detaljer om "hva" og g√•r inn i spesifikasjoner (ikke bare en bil, men et spesifikt merke og modell), og den beskriver ogs√• den generelle settingen. 3 er nest best da den ogs√• inneholder mye beskrivelse.

## üöÄ Utfordring

Se om du kan bruke "ledetr√•d"-teknikken med oppgaven: Fullf√∏r setningen "Vis meg et bilde av en r√∏d bil av merke Volvo og ". Hva svarer den med, og hvordan ville du forbedret det?

## Flott arbeid! Fortsett l√¶ringen din

Vil du l√¶re mer om ulike konsepter innen oppgaveutforming? G√• til [siden for videre l√¶ring](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for √• finne andre flotte ressurser om dette emnet.

G√• videre til leksjon 5 der vi skal se p√• [avanserte oppgaveteknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n√∏yaktighet, v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.