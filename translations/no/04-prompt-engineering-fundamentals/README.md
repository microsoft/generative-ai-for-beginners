<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a45c318dc6ebc2604f35b8b829f93af2",
  "translation_date": "2025-07-09T10:27:17+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "no"
}
-->
# Grunnleggende om Prompt Engineering

[![Prompt Engineering Fundamentals](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.no.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduksjon
Denne modulen dekker viktige konsepter og teknikker for √• lage effektive prompts i generative AI-modeller. M√•ten du skriver prompten din til en LLM p√•, har ogs√• betydning. En n√∏ye utformet prompt kan gi bedre kvalitet p√• svaret. Men hva betyr egentlig begrepene _prompt_ og _prompt engineering_? Og hvordan kan jeg forbedre prompt-_inputen_ jeg sender til LLM-en? Dette er sp√∏rsm√•lene vi skal pr√∏ve √• svare p√• i dette kapittelet og det neste.

_Generativ AI_ kan lage nytt innhold (f.eks. tekst, bilder, lyd, kode osv.) som svar p√• brukerforesp√∏rsler. Den gj√∏r dette ved hjelp av _Large Language Models_ som OpenAIs GPT ("Generative Pre-trained Transformer")-serie, som er trent til √• bruke naturlig spr√•k og kode.

Brukere kan n√• samhandle med disse modellene ved hjelp av kjente paradigmer som chat, uten √• trenge teknisk ekspertise eller oppl√¶ring. Modellene er _prompt-baserte_ ‚Äì brukere sender inn tekst (prompt) og f√•r tilbake AI-svaret (completion). De kan deretter "chatte med AI-en" iterativt, i samtaler med flere runder, og forbedre prompten sin til svaret matcher forventningene.

"Prompter" blir n√• det prim√¶re _programmeringsgrensesnittet_ for generative AI-apper, som forteller modellene hva de skal gj√∏re og p√•virker kvaliteten p√• svarene som returneres. "Prompt Engineering" er et raskt voksende fagfelt som fokuserer p√• _design og optimalisering_ av prompter for √• levere konsistente og kvalitetsmessige svar i stor skala.

## L√¶ringsm√•l

I denne leksjonen l√¶rer vi hva Prompt Engineering er, hvorfor det er viktig, og hvordan vi kan lage mer effektive prompter for en gitt modell og applikasjonsm√•l. Vi skal forst√• kjernebegreper og beste praksis for prompt engineering ‚Äì og l√¶re om et interaktivt Jupyter Notebook-"sandbox"-milj√∏ hvor vi kan se disse konseptene anvendt p√• ekte eksempler.

Ved slutten av denne leksjonen skal vi kunne:

1. Forklare hva prompt engineering er og hvorfor det er viktig.
2. Beskrive komponentene i en prompt og hvordan de brukes.
3. L√¶re beste praksis og teknikker for prompt engineering.
4. Anvende l√¶rte teknikker p√• ekte eksempler, ved bruk av en OpenAI-endepunkt.

## N√∏kkelbegreper

Prompt Engineering: Praksisen med √• designe og forbedre input for √• styre AI-modeller mot √• produsere √∏nskede resultater.  
Tokenisering: Prosessen med √• konvertere tekst til mindre enheter, kalt tokens, som en modell kan forst√• og behandle.  
Instruction-Tuned LLMs: Store spr√•kmodeller (LLMs) som er finjustert med spesifikke instruksjoner for √• forbedre n√∏yaktighet og relevans i svarene.

## L√¶ringssandbox

Prompt engineering er forel√∏pig mer kunst enn vitenskap. Den beste m√•ten √• forbedre intuisjonen p√• er √• _√∏ve mer_ og bruke en pr√∏ving-og-feiling-tiln√¶rming som kombinerer fagkunnskap med anbefalte teknikker og modellspesifikke optimaliseringer.

Jupyter Notebook-en som f√∏lger med denne leksjonen, gir et _sandbox_-milj√∏ hvor du kan pr√∏ve ut det du l√¶rer ‚Äì enten underveis eller som en del av kodeutfordringen p√• slutten. For √• kj√∏re √∏velsene trenger du:

1. **En Azure OpenAI API-n√∏kkel** ‚Äì tjenesteendepunkt for en distribuert LLM.  
2. **Et Python-runtime** ‚Äì hvor Notebook-en kan kj√∏res.  
3. **Lokale milj√∏variabler** ‚Äì _fullf√∏r [SETUP](./../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) n√• for √• v√¶re klar_.

Notebook-en kommer med _start√∏velser_ ‚Äì men du oppfordres til √• legge til egne _Markdown_ (beskrivelse) og _Code_ (prompt-foresp√∏rsler) seksjoner for √• pr√∏ve flere eksempler eller ideer ‚Äì og bygge opp intuisjonen din for promptdesign.

## Illustrert guide

Vil du f√• en oversikt over hva denne leksjonen dekker f√∏r du g√•r i gang? Sjekk ut denne illustrerte guiden, som gir deg en f√∏lelse av hovedtemaene og viktige punkter √• tenke p√• i hver del. Leksjonsplanen tar deg fra √• forst√• kjernebegrepene og utfordringene til √• m√∏te dem med relevante prompt engineering-teknikker og beste praksis. Merk at delen "Avanserte teknikker" i denne guiden refererer til innhold som dekkes i _neste_ kapittel i dette kurset.

![Illustrert guide til Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.no.png)

## V√•r startup

La oss n√• snakke om hvordan _dette temaet_ henger sammen med v√•r startup-misjon om √• [bringe AI-innovasjon til utdanning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi √∏nsker √• bygge AI-drevne applikasjoner for _personlig tilpasset l√¶ring_ ‚Äì s√• la oss tenke p√• hvordan ulike brukere av applikasjonen v√•r kan "designe" prompter:

- **Administratorer** kan be AI om √• _analysere l√¶replandata for √• identifisere hull i dekningen_. AI-en kan oppsummere resultater eller visualisere dem med kode.  
- **L√¶rere** kan be AI om √• _generere en leksjonsplan for en m√•lgruppe og et tema_. AI-en kan lage den personlige planen i et spesifisert format.  
- **Studenter** kan be AI om √• _veilede dem i et vanskelig fag_. AI-en kan n√• hjelpe studenter med leksjoner, hint og eksempler tilpasset deres niv√•.

Dette er bare toppen av isfjellet. Sjekk ut [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì et √•pent kildekode-bibliotek med prompter kuratert av utdanningseksperter ‚Äì for √• f√• en bredere forst√•else av mulighetene! _Pr√∏v √• kj√∏re noen av disse promptene i sandboxen eller i OpenAI Playground for √• se hva som skjer!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Hva er Prompt Engineering?

Vi startet denne leksjonen med √• definere **Prompt Engineering** som prosessen med √• _designe og optimalisere_ tekstinput (prompter) for √• levere konsistente og kvalitetsmessige svar (completions) for et gitt applikasjonsm√•l og modell. Vi kan tenke p√• dette som en to-trinns prosess:

- _designe_ den opprinnelige prompten for en gitt modell og m√•l  
- _forbedre_ prompten iterativt for √• √∏ke kvaliteten p√• svaret

Dette er n√∏dvendigvis en pr√∏ving-og-feiling-prosess som krever brukerintuisjon og innsats for √• oppn√• optimale resultater. S√• hvorfor er det viktig? For √• svare p√• det m√• vi f√∏rst forst√• tre konsepter:

- _Tokenisering_ = hvordan modellen "ser" prompten  
- _Base LLMs_ = hvordan grunnmodellen "behandler" en prompt  
- _Instruction-Tuned LLMs_ = hvordan modellen n√• kan forst√• "oppgaver"

### Tokenisering

En LLM ser p√• prompter som en _sekvens av tokens_, hvor forskjellige modeller (eller versjoner av en modell) kan tokenisere samme prompt p√• ulike m√•ter. Siden LLM-er er trent p√• tokens (og ikke r√• tekst), har m√•ten prompten tokeniseres p√• direkte innvirkning p√• kvaliteten p√• det genererte svaret.

For √• f√• en f√∏lelse av hvordan tokenisering fungerer, pr√∏v verkt√∏y som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist nedenfor. Lim inn prompten din ‚Äì og se hvordan den konverteres til tokens, med oppmerksomhet p√• hvordan mellomrom og tegnsetting h√•ndteres. Merk at dette eksempelet viser en eldre LLM (GPT-3) ‚Äì s√• √• pr√∏ve dette med en nyere modell kan gi et annet resultat.

![Tokenisering](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.no.png)

### Konsept: Grunnmodeller

N√•r en prompt er tokenisert, er hovedfunksjonen til ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grunnmodellen) √• forutsi token i sekvensen. Siden LLM-er er trent p√• enorme tekstdatasett, har de god forst√•else for statistiske sammenhenger mellom tokens og kan gj√∏re denne forutsigelsen med en viss sikkerhet. Merk at de ikke forst√•r _meningen_ med ordene i prompten eller token; de ser bare et m√∏nster de kan "fullf√∏re" med neste forutsigelse. De kan fortsette √• forutsi sekvensen til de stoppes av bruker eller en forh√•ndsdefinert betingelse.

Vil du se hvordan prompt-basert fullf√∏ring fungerer? Skriv inn prompten ovenfor i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinnstillinger. Systemet er konfigurert til √• behandle prompter som informasjonsforesp√∏rsler ‚Äì s√• du b√∏r se et svar som tilfredsstiller denne konteksten.

Men hva om brukeren √∏nsket √• se noe spesifikt som oppfyller visse kriterier eller oppgave? Her kommer _instruction-tuned_ LLM-er inn i bildet.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.no.png)

### Konsept: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grunnmodellen og finjusterer den med eksempler eller input/output-par (f.eks. samtaler med flere runder) som kan inneholde klare instruksjoner ‚Äì og AI-svaret fors√∏ker √• f√∏lge disse instruksjonene.

Dette bruker teknikker som Reinforcement Learning with Human Feedback (RLHF) som kan trene modellen til √• _f√∏lge instruksjoner_ og _l√¶re av tilbakemeldinger_ slik at den produserer svar som er bedre tilpasset praktiske bruksomr√•der og mer relevante for brukerens m√•l.

La oss pr√∏ve ‚Äì g√• tilbake til prompten ovenfor, men endre n√• _systemmeldingen_ til √• gi f√∏lgende instruksjon som kontekst:

> _Oppsummer innholdet du f√•r for en elev p√• andre trinn. Hold resultatet til ett avsnitt med 3-5 punkter._

Ser du hvordan resultatet n√• er tilpasset det √∏nskede m√•let og formatet? En l√¶rer kan n√• bruke dette svaret direkte i sine presentasjoner for den klassen.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.no.png)

## Hvorfor trenger vi Prompt Engineering?

N√• som vi vet hvordan prompter behandles av LLM-er, la oss snakke om _hvorfor_ vi trenger prompt engineering. Svaret ligger i at dagens LLM-er har flere utfordringer som gj√∏r det vanskeligere √• oppn√• _p√•litelige og konsistente svar_ uten √• legge innsats i konstruksjon og optimalisering av prompten. For eksempel:

1. **Modellens svar er stokastiske.** _Samme prompt_ vil sannsynligvis gi ulike svar med forskjellige modeller eller modellversjoner. Og det kan til og med gi ulike resultater med _samme modell_ til forskjellige tider. _Prompt engineering-teknikker kan hjelpe oss √• minimere disse variasjonene ved √• gi bedre rammer_.

1. **Modeller kan finne p√• svar.** Modellene er forh√•ndstrent p√• _store, men begrensede_ datasett, noe som betyr at de mangler kunnskap om konsepter utenfor treningsomr√•det. Som f√∏lge kan de produsere svar som er un√∏yaktige, oppdiktede eller direkte i strid med kjente fakta. _Prompt engineering hjelper brukere √• identifisere og redusere slike fabrikasjoner, for eksempel ved √• be AI om kilder eller begrunnelser_.

1. **Modellers evner vil variere.** Nyere modeller eller modellgenerasjoner vil ha rikere evner, men ogs√• unike s√¶rtrekk og kompromisser i kostnad og kompleksitet. _Prompt engineering kan hjelpe oss √• utvikle beste praksis og arbeidsflyter som skjuler forskjeller og tilpasser seg modellspesifikke krav p√• en skalerbar og s√∏ml√∏s m√•te_.

La oss se dette i praksis i OpenAI eller Azure OpenAI Playground:

- Bruk samme prompt med ulike LLM-distribusjoner (f.eks. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√• du variasjonene?  
- Bruk samme prompt flere ganger med _samme_ LLM-distribusjon (f.eks. Azure OpenAI playground) ‚Äì hvordan var variasjonene da?

### Eksempel p√• fabrikasjoner

I dette kurset bruker vi begrepet **"fabrikasjon"** for √• referere til fenomenet der LLM-er noen ganger genererer faktuelt feilaktig informasjon p√• grunn av begrensninger i treningen eller andre forhold. Du har kanskje ogs√• h√∏rt dette omtalt som _"hallusinasjoner"_ i popul√¶re artikler eller forskningsartikler. Vi anbefaler imidlertid sterkt √• bruke _"fabrikasjon"_ som begrep for √• unng√• √• tillegge maskindrevne resultater menneskelige egenskaper. Dette underst√∏tter ogs√• [Retningslinjer for ansvarlig AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologisk perspektiv, ved √• fjerne begreper som kan oppfattes som st√∏tende eller ikke inkluderende i noen sammenhenger.

Vil du f√• en f√∏lelse av hvordan fabrikasjoner fungerer? Tenk p√• en prompt som instruerer AI-en til √• generere innhold om et ikke-eksisterende tema (for √• sikre at det ikke finnes i treningsdataene). For eksempel ‚Äì jeg pr√∏vde denne prompten:
# Leksjonsplan: Den marsianske krigen i 2076

## Introduksjon
I denne leksjonen skal vi utforske den marsianske krigen som fant sted i 2076. Vi vil se p√• bakgrunnen for konflikten, hovedhendelsene under krigen, og konsekvensene for b√•de Mars og Jorden.

## M√•l
- Forst√• √•rsakene til den marsianske krigen
- Analysere viktige slag og strategier brukt under krigen
- Diskutere krigens innvirkning p√• fremtidig romfart og diplomati

## Tidsplan

### 1. Bakgrunn og √•rsaker (15 minutter)
- Kort gjennomgang av Mars-kolonisering fram til 2076
- Spenninger mellom jordiske myndigheter og marsianske kolonister
- Ressurskamp og politiske uenigheter

### 2. Hovedhendelser i krigen (30 minutter)
- Starten p√• konflikten: de f√∏rste sammenst√∏tene
- Viktige slag og taktikker brukt av begge sider
- Teknologiske nyvinninger under krigen

### 3. Konsekvenser og etterspill (15 minutter)
- Avtaler og fredsforhandlinger
- Endringer i romfartslover og kolonipolitikk
- Langsiktige effekter p√• Mars og Jorden

## Aktiviteter
- Diskusjon: Hva kunne v√¶rt gjort annerledes for √• unng√• krigen?
- Gruppearbeid: Lag en tidslinje over de viktigste hendelsene i krigen
- Individuell oppgave: Skriv et brev fra perspektivet til en marsiansk kolonist under krigen

## Ressurser
- Historiske dokumenter og rapporter fra 2076
- Interaktive kart over slagomr√•dene
- Videoer med intervjuer av overlevende og eksperter

## Oppsummering
Avslutt leksjonen med en oppsummering av de viktigste punktene og √•pne for sp√∏rsm√•l fra deltakerne. Diskuter hvordan forst√•elsen av denne konflikten kan hjelpe oss med √• h√•ndtere fremtidige utfordringer i romfart og internasjonale relasjoner.
Et netts√∏k viste meg at det fantes fiktive beretninger (f.eks. TV-serier eller b√∏ker) om marskriger ‚Äì men ingen i 2076. Sunn fornuft forteller oss ogs√• at 2076 er _i fremtiden_ og derfor ikke kan knyttes til en virkelig hendelse.

S√• hva skjer n√•r vi kj√∏rer denne prompten med forskjellige LLM-leverand√∏rer?

> **Respons 1**: OpenAI Playground (GPT-35)

![Respons 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.no.png)

> **Respons 2**: Azure OpenAI Playground (GPT-35)

![Respons 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.no.png)

> **Respons 3**: : Hugging Face Chat Playground (LLama-2)

![Respons 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.no.png)

Som forventet gir hver modell (eller modellversjon) litt forskjellige svar takket v√¶re stokastisk oppf√∏rsel og variasjoner i modellens evner. For eksempel retter √©n modell seg mot et 8. klasses publikum, mens en annen antar en videreg√•ende elev. Men alle tre modellene genererte svar som kunne overbevise en uinformert bruker om at hendelsen var ekte.

Prompt engineering-teknikker som _metaprompting_ og _temperature configuration_ kan redusere modellens fabrikasjoner til en viss grad. Nye prompt engineering-_arkitekturer_ integrerer ogs√• s√∏ml√∏st nye verkt√∏y og teknikker i promptflyten for √• dempe eller redusere noen av disse effektene.

## Case Study: GitHub Copilot

La oss avslutte denne delen med √• f√• en forst√•else av hvordan prompt engineering brukes i virkelige l√∏sninger ved √• se p√• en Case Study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI Pair Programmer" ‚Äì den omdanner tekstprompter til kodefullf√∏ringer og er integrert i utviklingsmilj√∏et ditt (f.eks. Visual Studio Code) for en s√∏ml√∏s brukeropplevelse. Som dokumentert i bloggserien nedenfor, var den tidligste versjonen basert p√• OpenAI Codex-modellen ‚Äì med ingeni√∏rer som raskt inns√• behovet for √• finjustere modellen og utvikle bedre prompt engineering-teknikker for √• forbedre kodekvaliteten. I juli [lanserte de en forbedret AI-modell som g√•r utover Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for enda raskere forslag.

Les innleggene i rekkef√∏lge for √• f√∏lge deres l√¶ringsreise.

- **Mai 2023** | [GitHub Copilot blir bedre til √• forst√• koden din](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mai 2023** | [Innsiden av GitHub: Arbeid med LLM-ene bak GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Juni 2023** | [Hvordan skrive bedre prompter for GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [.. GitHub Copilot g√•r utover Codex med forbedret AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [En utviklers guide til prompt engineering og LLM-er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hvordan bygge en enterprise LLM-app: L√¶rdom fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• bla gjennom deres [Engineering-blogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere innlegg som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som viser hvordan disse modellene og teknikkene _brukes_ til √• drive virkelige applikasjoner.

---

<!--
LESSON TEMPLATE:
Denne enheten skal dekke kjernebegrep #2.
Forsterk begrepet med eksempler og referanser.

CONCEPT #2:
Prompt Design.
Illustrert med eksempler.
-->

## Promptkonstruksjon

Vi har sett hvorfor prompt engineering er viktig ‚Äì n√• skal vi forst√• hvordan prompter _konstrueres_ slik at vi kan evaluere ulike teknikker for mer effektiv promptdesign.

### Enkel prompt

La oss starte med den enkle prompten: en tekstinput sendt til modellen uten annen kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste ordene i USAs nasjonalsang til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), fullf√∏rer den umiddelbart svaret med de neste linjene, noe som illustrerer grunnleggende prediksjonsatferd.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det h√∏res ut som du begynner p√• teksten til "The Star-Spangled Banner," USAs nasjonalsang. Hele teksten er ...                             |

### Kompleks prompt

N√• legger vi til kontekst og instruksjoner til den enkle prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) lar oss bygge en kompleks prompt som en samling av _meldinger_ med:

- Input/output-par som reflekterer _bruker_-input og _assistent_-respons.
- Systemmelding som setter konteksten for assistentens oppf√∏rsel eller personlighet.

Foresp√∏rselen er n√• i formen nedenfor, hvor _tokenisering_ effektivt fanger relevant informasjon fra kontekst og samtale. √Ö endre systemkonteksten kan ha like stor innvirkning p√• kvaliteten p√• fullf√∏ringene som brukerinputtene som gis.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruksjonsprompt

I eksemplene over var brukerprompten en enkel tekstforesp√∏rsel som kan tolkes som en informasjonsforesp√∏rsel. Med _instruksjonsprompter_ kan vi bruke teksten til √• spesifisere en oppgave mer detaljert, og gi AI bedre veiledning. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruksjonstype    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Write a description of the Civil War                                                                                                                                                                                                   | _returnerte et enkelt avsnitt_                                                                                            | Enkel              |
| Write a description of the Civil War. Provide key dates and events and describe their significance                                                                                                                                     | _returnerte et avsnitt etterfulgt av en liste med viktige datoer og beskrivelser_                                         | Kompleks           |
| Write a description of the Civil War in 1 paragraph. Provide 3 bullet points with key dates and their significance. Provide 3 more bullet points with key historical figures and their contributions. Return the output as a JSON file | _returnerer mer omfattende detaljer i en tekstboks, formatert som JSON som du kan kopiere og lime inn i en fil og validere_ | Kompleks. Formatert.|

## Prim√¶rt innhold

I eksemplene over var prompten fortsatt ganske √•pen, noe som lot LLM bestemme hvilken del av det forh√•ndstrente datasettet som var relevant. Med designm√∏nsteret _prim√¶rt innhold_ deles inputteksten i to deler:

- en instruksjon (handling)
- relevant innhold (som p√•virker handlingen)

Her er et eksempel der instruksjonen er √• "oppsummere dette i 2 setninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger massen til alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. Den er oppkalt etter den romerske guden Jupiter.[19] N√•r man ser p√• Jupiter fra jorden, kan den v√¶re s√• lyssterk at det reflekterte lyset kaster synlige skygger,[20] og er i gjennomsnitt det tredje lyseste naturlige objektet p√• nattehimmelen etter m√•nen og Venus. <br/> **Oppsummer dette i 2 korte setninger** | Jupiter, den femte planeten fra solen, er den st√∏rste i solsystemet og kjent for √• v√¶re et av de lyseste objektene p√• nattehimmelen. Oppkalt etter den romerske guden Jupiter, er det en gasskjempe med en masse som er to og en halv ganger massen til alle de andre planetene i solsystemet til sammen. |

Segmentet med prim√¶rt innhold kan brukes p√• ulike m√•ter for √• gi mer effektive instruksjoner:

- **Eksempler** ‚Äì i stedet for √• fortelle modellen hva den skal gj√∏re med en eksplisitt instruksjon, gi den eksempler p√• hva den skal gj√∏re og la den slutte seg til m√∏nsteret.
- **Ledetr√•der** ‚Äì f√∏lg instruksjonen med en "ledetr√•d" som forbereder fullf√∏ringen og guider modellen mot mer relevante svar.
- **Malverk** ‚Äì dette er repeterbare 'oppskrifter' for prompter med plassholdere (variabler) som kan tilpasses med data for spesifikke bruksomr√•der.

La oss utforske disse i praksis.

### Bruke eksempler

Dette er en tiln√¶rming der du bruker det prim√¶re innholdet til √• "mate modellen" med noen eksempler p√• √∏nsket output for en gitt instruksjon, og lar den slutte seg til m√∏nsteret for √∏nsket output. Basert p√• antall eksempler kan vi ha zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r n√• av tre komponenter:

- En oppgavebeskrivelse
- Noen eksempler p√• √∏nsket output
- Begynnelsen p√• et nytt eksempel (som blir en implisitt oppgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :----------- | :--------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot    | "The Sun is Shining". Oversett til spansk                                                                                                          | "El Sol est√° brillando".    |
| One-shot     | "The Sun is Shining" => "El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot     | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk => | Basketball                  |
|              |                                                                                                                                                      |                             |

Legg merke til at vi m√•tte gi eksplisitt instruksjon ("Oversett til spansk") i zero-shot prompting, men det blir underforst√•tt i one-shot eksemplet. Few-shot-eksemplet viser hvordan flere eksempler gj√∏r at modeller kan gj√∏re mer presise slutninger uten ekstra instruksjoner.

### Prompt-ledetr√•der

En annen teknikk for √• bruke prim√¶rt innhold er √• gi _ledetr√•der_ i stedet for eksempler. I dette tilfellet gir vi modellen et dytt i riktig retning ved √• _starte den_ med et utdrag som reflekterer √∏nsket svarformat. Modellen "tar ledetr√•den" og fortsetter i samme stil.

| Antall ledetr√•der | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :---------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                 | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger massen til alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. |

**Oppsummer Dette**                                       | Jupiter er den st√∏rste planeten i v√•rt solsystem og den femte fra solen. Den er en gasskjempe med en masse som er 1/1000 av solens, men den er tyngre enn alle de andre planetene til sammen. Gamle sivilisasjoner har kjent til Jupiter lenge, og den er lett synlig p√• nattehimmelen. |
| 1              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. <br/>**Oppsummer Dette** <br/> Det vi l√¶rte er at Jupiter | er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene til sammen. Den er lett synlig for det blotte √∏ye og har v√¶rt kjent siden oldtiden.                        |
| 2              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de lyseste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. <br/>**Oppsummer Dette** <br/> Topp 3 fakta vi l√¶rte:         | 1. Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. <br/> 2. Den er en gasskjempe med en masse som er en tusendel av solens...<br/> 3. Jupiter har v√¶rt synlig for det blotte √∏ye siden oldtiden ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Maler for Prompt

En prompt-mal er en _forh√•ndsdefinert oppskrift for en prompt_ som kan lagres og gjenbrukes etter behov, for √• skape mer konsistente brukeropplevelser i stor skala. I sin enkleste form er det rett og slett en samling av prompt-eksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som gir b√•de de interaktive prompt-komponentene (bruker- og systemmeldinger) og API-drevne foresp√∏rselsformatet ‚Äì for √• st√∏tte gjenbruk.

I en mer kompleks form som [dette eksempelet fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) inneholder den _plassholdere_ som kan erstattes med data fra ulike kilder (brukerinput, systemkontekst, eksterne datakilder osv.) for √• generere en prompt dynamisk. Dette gj√∏r at vi kan lage et bibliotek av gjenbrukbare prompts som kan brukes til √• skape konsistente brukeropplevelser **programmatisk** i stor skala.

Til slutt ligger den virkelige verdien i maler i muligheten til √• lage og publisere _prompt-biblioteker_ for vertikale applikasjonsdomener ‚Äì hvor prompt-malen n√• er _optimalisert_ for √• reflektere applikasjonsspesifikk kontekst eller eksempler som gj√∏r svarene mer relevante og presise for den m√•lrettede brukergruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) er et godt eksempel p√• denne tiln√¶rmingen, med et bibliotek av prompts for utdanningssektoren med fokus p√• viktige m√•l som leksjonsplanlegging, l√¶replanutforming, studentveiledning osv.

## St√∏ttende Innhold

Hvis vi ser p√• prompt-konstruksjon som √• ha en instruksjon (oppgave) og et m√•l (prim√¶rt innhold), s√• er _sekund√¶rt innhold_ som ekstra kontekst vi gir for √• **p√•virke resultatet p√• en eller annen m√•te**. Det kan v√¶re justeringsparametere, formateringsinstruksjoner, emnetaksonomier osv. som hjelper modellen med √• _skreddersy_ svaret slik at det passer de √∏nskede brukerbehovene eller forventningene.

For eksempel: Gitt en kurskatalog med omfattende metadata (navn, beskrivelse, niv√•, metadata-tagger, instrukt√∏r osv.) for alle tilgjengelige kurs i l√¶replanen:

- kan vi definere en instruksjon om √• "oppsummere kurskatalogen for h√∏sten 2023"
- vi kan bruke det prim√¶re innholdet til √• gi noen eksempler p√• √∏nsket resultat
- vi kan bruke det sekund√¶re innholdet til √• identifisere de 5 viktigste "taggene" av interesse.

N√• kan modellen gi en oppsummering i formatet vist av de f√• eksemplene ‚Äì men hvis et resultat har flere tagger, kan den prioritere de 5 taggene som er identifisert i det sekund√¶re innholdet.

---

<!--
LEKSJONSMAL:
Denne enheten skal dekke kjernebegrep #1.
Forsterk begrepet med eksempler og referanser.

BEGREP #3:
Prompt Engineering-teknikker.
Hva er noen grunnleggende teknikker for prompt engineering?
Illustrer med noen √∏velser.
-->

## Beste praksis for prompting

N√• som vi vet hvordan prompts kan _konstrueres_, kan vi begynne √• tenke p√• hvordan vi kan _designe_ dem for √• f√∏lge beste praksis. Vi kan dele det i to deler ‚Äì √• ha riktig _tankesett_ og √• bruke riktige _teknikker_.

### Tankesett for Prompt Engineering

Prompt Engineering er en pr√∏ving-og-feiling-prosess, s√• husk disse tre brede retningslinjene:

1. **Domeneinnsikt er viktig.** Svarenes n√∏yaktighet og relevans avhenger av _domenet_ der applikasjonen eller brukeren opererer. Bruk din intuisjon og domeneekspertise for √• **tilpasse teknikker** videre. For eksempel, definer _domene-spesifikke personligheter_ i systemprompter, eller bruk _domene-spesifikke maler_ i brukerprompter. Gi sekund√¶rt innhold som reflekterer domene-spesifikke kontekster, eller bruk _domene-spesifikke hint og eksempler_ for √• styre modellen mot kjente bruksomr√•der.

2. **Modellforst√•else er viktig.** Vi vet at modeller er stokastiske av natur. Men modellimplementasjoner kan ogs√• variere med hensyn til treningsdatasettet de bruker (forh√•ndstrent kunnskap), hvilke funksjoner de tilbyr (f.eks. via API eller SDK) og typen innhold de er optimalisert for (f.eks. kode vs. bilder vs. tekst). Forst√• styrker og begrensninger ved modellen du bruker, og bruk den kunnskapen til √• _prioritere oppgaver_ eller bygge _tilpassede maler_ som er optimalisert for modellens evner.

3. **Iterasjon og validering er viktig.** Modeller utvikler seg raskt, og det gj√∏r ogs√• teknikkene for prompt engineering. Som domeneekspert kan du ha annen kontekst eller kriterier for _din_ spesifikke applikasjon, som kanskje ikke gjelder for det bredere fellesskapet. Bruk verkt√∏y og teknikker for prompt engineering for √• "komme i gang" med prompt-konstruksjon, deretter iterer og valider resultatene med din egen intuisjon og domeneekspertise. Dokumenter innsiktene dine og lag en **kunnskapsbase** (f.eks. prompt-biblioteker) som kan brukes som ny referanse for andre, for raskere iterasjoner i fremtiden.

## Beste praksis

La oss n√• se p√• vanlige beste praksiser som anbefales av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) eksperter.

| Hva                              | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evaluer de nyeste modellene.       | Nye modellgenerasjoner har sannsynligvis forbedrede funksjoner og kvalitet ‚Äì men kan ogs√• medf√∏re h√∏yere kostnader. Evaluer dem for effekt, og ta deretter beslutninger om migrering.                                                                |
| Skill instruksjoner og kontekst   | Sjekk om modellen/leverand√∏ren din definerer _avgrensere_ for √• tydelig skille instruksjoner, prim√¶rt og sekund√¶rt innhold. Dette kan hjelpe modeller med √• tildele vekter mer n√∏yaktig til tokens.                                                   |
| V√¶r spesifikk og tydelig           | Gi flere detaljer om √∏nsket kontekst, resultat, lengde, format, stil osv. Dette forbedrer b√•de kvalitet og konsistens i svarene. Lag oppskrifter i gjenbrukbare maler.                                                                                |
| V√¶r beskrivende, bruk eksempler    | Modeller kan svare bedre p√• en "vis og fortell"-tiln√¶rming. Start med en `zero-shot`-tiln√¶rming der du gir en instruksjon (men ingen eksempler), og pr√∏v deretter `few-shot` som en forbedring, med noen eksempler p√• √∏nsket resultat. Bruk analogier. |
| Bruk hint for √• starte fullf√∏ringer | Gi modellen noen ledende ord eller fraser den kan bruke som utgangspunkt for svaret, for √• styre mot √∏nsket resultat.                                                                                                                               |
| Gjenta om n√∏dvendig                | Noen ganger m√• du gjenta deg for modellen. Gi instruksjoner f√∏r og etter det prim√¶re innholdet, bruk en instruksjon og et hint, osv. Iterer og valider for √• se hva som fungerer.                                                                     |
| Rekkef√∏lge betyr noe              | Rekkef√∏lgen du presenterer informasjon for modellen kan p√•virke resultatet, ogs√• i l√¶ringseksempler, p√• grunn av nyere bias. Pr√∏v ulike alternativer for √• finne det som fungerer best.                                                              |
| Gi modellen en ‚Äúutvei‚Äù            | Gi modellen et _tilbakefalls_-svar den kan bruke hvis den ikke kan fullf√∏re oppgaven av en eller annen grunn. Dette kan redusere sjansen for at modellen genererer feilaktige eller fabrikerte svar.                                                  |
|                                   |                                                                                                                                                                                                                                                   |

Som med all beste praksis, husk at _dine erfaringer kan variere_ basert p√• modell, oppgave og domene. Bruk disse som et utgangspunkt, og iterer for √• finne det som fungerer best for deg. Evaluer kontinuerlig prompt engineering-prosessen din etter hvert som nye modeller og verkt√∏y blir tilgjengelige, med fokus p√• skalerbarhet og svar-kvalitet.

<!--
LEKSJONSMAL:
Denne enheten skal gi en kodeutfordring hvis aktuelt

UTFORDRING:
Lenke til en Jupyter Notebook med kun kodekommentarer i instruksjonene (kodeavsnitt er tomme).

L√òSNING:
Lenke til en kopi av den Notebooken med promptene fylt inn og kj√∏rt, som viser ett eksempel p√• resultat.
-->

## Oppgave

Gratulerer! Du har kommet til slutten av leksjonen! N√• er det p√• tide √• teste noen av de konseptene og teknikkene med ekte eksempler!

For oppgaven bruker vi en Jupyter Notebook med √∏velser du kan gj√∏re interaktivt. Du kan ogs√• utvide Notebooken med dine egne Markdown- og kodeceller for √• utforske ideer og teknikker p√• egen h√•nd.

### For √• komme i gang, fork repoet, deretter

- (Anbefalt) Start GitHub Codespaces
- (Alternativt) Klon repoet til din lokale maskin og bruk det med Docker Desktop
- (Alternativt) √Öpne Notebooken i ditt foretrukne Notebook-milj√∏.

### Deretter, konfigurer milj√∏variablene dine

- Kopier `.env.copy`-filen i repoets rot til `.env` og fyll inn verdiene for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. G√• tilbake til [Learning Sandbox-seksjonen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) for √• l√¶re hvordan.

### S√•, √•pne Jupyter Notebook

- Velg runtime-kjernen. Hvis du bruker alternativ 1 eller 2, velg bare standard Python 3.10.x-kjerne som tilbys av utviklingscontaineren.

Du er klar til √• kj√∏re √∏velsene. Merk at det ikke finnes _riktige eller gale_ svar her ‚Äì bare utforske muligheter gjennom pr√∏ving og feiling og bygge intuisjon for hva som fungerer for en gitt modell og applikasjonsdomene.

_For denne grunn finnes det ingen kode-l√∏sningssegmenter i denne leksjonen. I stedet vil Notebooken ha Markdown-celler med tittelen "Min l√∏sning:" som viser ett eksempel p√• resultat til referanse._

 <!--
LEKSJONSMAL:
Avslutt seksjonen med en oppsummering og ressurser for selvstyrt l√¶ring.
-->

## Kunnskapssjekk

Hvilken av f√∏lgende er en god prompt som f√∏lger noen rimelige beste praksiser?

1. Vis meg et bilde av en r√∏d bil  
2. Vis meg et bilde av en r√∏d bil av merke Volvo og modell XC90 parkert ved en klippe med solnedgang  
3. Vis meg et bilde av en r√∏d bil av merke Volvo og modell XC90

Svar: 2, det er den beste prompten fordi den gir detaljer om "hva" og g√•r i spesifikasjoner (ikke bare en hvilken som helst bil, men et spesifikt merke og modell) og beskriver ogs√• omgivelsene. 3 er nest best fordi den ogs√• inneholder mye beskrivelse.

## üöÄ Utfordring

Se om du kan bruke "hint"-teknikken med prompten: Fullf√∏r setningen "Vis meg et bilde av en r√∏d bil av merke Volvo og ". Hva svarer den, og hvordan ville du forbedre det?

## Flott jobba! Fortsett l√¶ringen din

Vil du l√¶re mer om ulike konsepter innen Prompt Engineering? G√• til [siden for videre l√¶ring](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for √• finne flere gode ressurser om dette temaet.

G√• videre til leksjon 5 hvor vi ser p√• [avanserte prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• originalspr√•ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.