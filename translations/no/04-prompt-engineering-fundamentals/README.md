# Grunnleggende om Prompt Engineering

[![Grunnleggende om Prompt Engineering](../../../translated_images/no/04-lesson-banner.a2c90deba7fedacd.webp)](https://youtu.be/GElCu2kUlRs?si=qrXsBvXnCW12epb8)

## Introduksjon
Denne modulen dekker viktige konsepter og teknikker for √• lage effektive prompts i generative AI-modeller. M√•ten du skriver prompten din til en LLM p√•, spiller ogs√• en rolle. En n√∏ye utformet prompt kan oppn√• bedre kvalitet p√• responsen. Men hva betyr egentlig begreper som _prompt_ og _prompt engineering_? Og hvordan kan jeg forbedre prompt-_inputen_ som jeg sender til LLM? Dette er sp√∏rsm√•lene vi vil pr√∏ve √• svare p√• i dette kapitlet og det neste.

_Generativ AI_ er i stand til √• lage nytt innhold (f.eks. tekst, bilder, lyd, kode osv.) som svar p√• brukerforesp√∏rsler. Den oppn√•r dette ved bruk av _Store Spr√•kmodeller_ som OpenAIs GPT ("Generative Pre-trained Transformer") serie som er trent for bruk av naturlig spr√•k og kode.

Brukere kan n√• interagere med disse modellene ved hjelp av kjente paradigmer som chat, uten √• trenge teknisk ekspertise eller oppl√¶ring. Modellene er _prompt-baserte_ - brukere sender inn tekstinput (prompt) og f√•r tilbake AI-responsen (fullf√∏ring). De kan s√• "chatte med AI" iterativt, i flerskiftsamtaler, og finjustere prompten sin til responsen matcher deres forventninger.

"Prompter" blir n√• det prim√¶re _programmeringsgrensesnittet_ for generative AI-apper, som forteller modellene hva de skal gj√∏re og p√•virker kvaliteten p√• de returnerte svarene. "Prompt Engineering" er et raskt voksende fagfelt som fokuserer p√• _design og optimalisering_ av promter for √• levere konsistente og kvalitetsmessige svar i stor skala.

## L√¶ringsm√•l

I denne leksjonen l√¶rer vi hva Prompt Engineering er, hvorfor det er viktig, og hvordan vi kan lage mer effektive prompts for en gitt modell og applikasjonsm√•l. Vi vil forst√• kjernebegreper og beste praksiser for prompt engineering ‚Äì og l√¶re om et interaktivt Jupyter Notebook "sandbox"-milj√∏ hvor vi kan se disse konseptene anvendt i ekte eksempler.

Ved slutten av denne leksjonen skal vi kunne:

1. Forklare hva prompt engineering er og hvorfor det er viktig.
2. Beskrive komponentene i en prompt og hvordan de brukes.
3. L√¶re beste praksiser og teknikker for prompt engineering.
4. Anvende l√¶rte teknikker p√• ekte eksempler, ved bruk av en OpenAI-endepunkt.

## N√∏kkelbegreper

Prompt Engineering: Praktiseringen av √• designe og raffinere inputs for √• veilede AI-modeller mot √• produsere √∏nskede utdata.  
Tokenisering: Prosessen med √• konvertere tekst til mindre enheter, kalt tokens, som en modell kan forst√• og bearbeide.  
Instruction-Tuned LLMs: Store spr√•kmodeller (LLMs) som har blitt finjustert med spesifikke instruksjoner for √• √∏ke n√∏yaktighet og relevans i svarene.

## L√¶ringssandbox

Prompt engineering er for √∏yeblikket mer en kunst enn vitenskap. Den beste m√•ten √• forbedre v√•r intuisjon p√• er √• _√∏ve mer_ og ta i bruk en pr√∏v-og-feil-tiln√¶rming som kombinerer faglig kompetanse i bruksomr√•det med anbefalte teknikker og modellspesifikke optimaliseringer.

Jupyter Notebook som f√∏lger med denne leksjonen gir et _sandbox_-milj√∏ hvor du kan pr√∏ve ut det du l√¶rer ‚Äì enten fortl√∏pende eller som en del av kodeutfordringen til slutt. For √• kj√∏re √∏velsene trenger du:

1. **En Azure OpenAI API-n√∏kkel** ‚Äì tjenesteendepunktet for en distribuert LLM.  
2. **Et Python-runtime** ‚Äì hvor Notebook kan kj√∏res.  
3. **Lokale milj√∏variabler** ‚Äì _fullf√∏r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst) stegene n√• for √• v√¶re klar_.

Notatboken leveres med _start√∏velser_ - men du oppfordres til √• legge til egne _Markdown_ (beskrivelse) og _Kode_ (prompt-foresp√∏rsler) seksjoner for √• pr√∏ve flere eksempler eller ideer ‚Äì og bygge din egen intuisjon for promptdesign.

## Illustrert Guide

Vil du f√• et overblikk av hva denne leksjonen dekker f√∏r du dykker inn? Sjekk ut denne illustrerte guiden, som gir deg en f√∏lelse av hovedtemaene og de viktigste innsiktene for deg √• reflektere over i hver del. Leksjonens veikart tar deg fra forst√•elsen av kjernebegrepene og utfordringene til √• takle dem med relevante prompt engineering-teknikker og beste praksiser. Merk at delen "Avanserte teknikker" i denne guiden refererer til innhold som dekkes i _neste_ kapittel i dette l√¶replanet.

![Illustrert Guide til Prompt Engineering](../../../translated_images/no/04-prompt-engineering-sketchnote.d5f33336957a1e4f.webp)

## V√•r Startup

La oss n√• snakke om hvordan _dette temaet_ relaterer seg til v√•rt startup-oppdrag om √• [bringe AI-innovasjon til utdanning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi √∏nsker √• bygge AI-drevne applikasjoner for _personlig tilpasset l√¶ring_ ‚Äì s√• la oss tenke p√• hvordan ulike brukere av applikasjonen v√•r kan "designe" prompts:

- **Administratorer** kan be AI om √• _analysere l√¶replan-data for √• identifisere hull i dekningen_. AI kan oppsummere resultatene eller visualisere dem med kode.  
- **L√¶rere** kan be AI om √• _generere en undervisningsplan for et m√•lpublikum og et tema_. AI kan bygge den personlige planen i et spesifisert format.  
- **Studenter** kan be AI om √• _veilede dem i et vanskelig fag_. AI kan n√• veilede studenter med leksjoner, hint og eksempler tilpasset deres niv√•.

Dette er bare toppen av isfjellet. Sjekk ut [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì et √•pen kildekode-bibliotek med promter kuratert av utdanningseksperter ‚Äì for √• f√• et bredere innblikk i mulighetene! _Pr√∏v √• kj√∏re noen av disse promptene i sandboxen eller i OpenAI Playground for √• se hva som skjer!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Hva er Prompt Engineering?

Vi startet denne leksjonen med √• definere **Prompt Engineering** som prosessen med √• _designe og optimalisere_ tekstinput (prompter) for √• levere konsistente og kvalitetsrike svar (fullf√∏ringer) for et gitt applikasjonsm√•l og modell. Vi kan tenke p√• dette som en 2-trinns prosess:

- _designe_ den initielle prompten for en gitt modell og m√•l  
- _forbedre_ prompten iterativt for √• √∏ke kvaliteten p√• svaret

Dette er n√∏dvendigvis en pr√∏v-og-feil-prosess som krever brukerintuisjon og innsats for √• oppn√• optimale resultater. S√• hvorfor er det viktig? For √• svare p√• det sp√∏rsm√•let, m√• vi f√∏rst forst√• tre konsepter:

- _Tokenisering_ = hvordan modellen "ser" prompten  
- _Base LLMs_ = hvordan grunnmodellen "bearbeider" en prompt  
- _Instruction-Tuned LLMs_ = hvordan modellen n√• kan se "oppgaver"

### Tokenisering

En LLM ser p√• prompter som en _sekvens av tokens_ hvor forskjellige modeller (eller versjoner av en modell) kan tokenisere samme prompt p√• ulike m√•ter. Siden LLMs trenes p√• tokens (ikke r√• tekst), har m√•ten promptene tokeniseres p√• direkte innvirkning p√• kvaliteten i det genererte svaret.

For √• f√• en intuisjon om hvordan tokenisering fungerer, pr√∏v verkt√∏y som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist nedenfor. Lim inn prompten din ‚Äì og se hvordan den blir konvertert til tokens, legg merke til hvordan mellomrom og tegnsetting h√•ndteres. Merk at dette eksempelet viser en eldre LLM (GPT-3) ‚Äì √• pr√∏ve dette med en nyere modell kan gi et annet resultat.

![Tokenisering](../../../translated_images/no/04-tokenizer-example.e71f0a0f70356c5c.webp)

### Konsept: Grunnmodeller

N√•r en prompt er tokenisert, er hovedfunksjonen til ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grunnmodellen) √• forutsi neste token i sekvensen. Siden LLMs trenes p√• enorme tekstdatasett, har de en god forst√•else av de statistiske sammenhengene mellom tokens og kan gj√∏re denne prediksjonen med en viss sikkerhet. Merk at de ikke forst√•r _meningen_ med ordene i prompten eller tokenen; de ser bare et m√∏nster de kan "fullf√∏re" med sin neste prediksjon. De kan fortsette √• forutsi sekvensen til den avbrytes av bruker eller oppfyller en forh√•ndsdefinert betingelse.

Vil du se hvordan promptbasert fullf√∏ring fungerer? Tast inn prompten ovenfor i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinnstillinger. Systemet er konfigurert til √• behandle prompts som informasjonsforesp√∏rsler ‚Äì s√• du b√∏r se en fullf√∏ring som tilfredsstiller denne konteksten.

Men hva om brukeren √∏nsket √• se noe spesifikt som oppfyller visse kriterier eller oppgaveform√•l? Her kommer _instruction-tuned_ LLMs inn i bildet.

![Base LLM Chat Fullf√∏ring](../../../translated_images/no/04-playground-chat-base.65b76fcfde0caa67.webp)

### Konsept: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grunnmodellen og finjusterer den med eksempler eller input/output-par (f.eks. flerskifts "meldinger") som kan inneholde klare instruksjoner ‚Äì og responsen fra AI fors√∏ker √• f√∏lge denne instruksjonen.

Dette bruker teknikker som Reinforcement Learning with Human Feedback (RLHF) som kan l√¶re modellen √• _f√∏lge instruksjoner_ og _l√¶re av tilbakemeldinger_ slik at den produserer svar som er bedre egnet til praktiske applikasjoner og mer relevante for brukerens m√•l.

La oss pr√∏ve det ‚Äì g√• tilbake til prompten over, men endre n√• _systemmeldingen_ for √• gi f√∏lgende instruksjon som kontekst:

> _Oppsummer innholdet du f√•r for en elev i andre klasse. Hold resultatet til ett avsnitt med 3-5 punkter._

Ser du hvordan resultatet n√• er tilpasset det √∏nskede m√•let og formatet? En l√¶rer kan n√• bruke dette svaret direkte i sine lysbilder til den klassen.

![Instruction Tuned LLM Chat Fullf√∏ring](../../../translated_images/no/04-playground-chat-instructions.b30bbfbdf92f2d05.webp)

## Hvorfor trenger vi Prompt Engineering?

N√• som vi vet hvordan prompter behandles av LLMs, la oss snakke om _hvorfor_ vi trenger prompt engineering. Svaret ligger i at dagens LLMs byr p√• en rekke utfordringer som gj√∏r _p√•litelige og konsistente fullf√∏ringer_ vanskeligere √• oppn√• uten innsats i konstruksjon og optimalisering av prompten. For eksempel:

1. **Modellens svar er stokastiske.** Den _samme prompten_ vil sannsynligvis gi forskjellige svar i ulike modeller eller modellversjoner. Og den kan til og med gi ulike resultater med _samme modell_ p√• forskjellige tidspunkt. _Prompt engineering-teknikker kan hjelpe oss √• minimere disse variasjonene ved √• gi bedre retningslinjer_.

1. **Modeller kan fabrikkere svar.** Modeller er forh√•ndstrent med _store, men begrensede_ datasett, noe som betyr at de mangler kunnskap om konsepter utenfor treningsomfanget. Derfor kan de produsere fullf√∏ringer som er un√∏yaktige, oppdiktede eller rett og slett motsier kjente fakta. _Prompt engineering hjelper brukere √• identifisere og dempe slike fabrikerte svar, f.eks. ved √• be AI om kilder eller begrunnelse_.

1. **Modellers kapasiteter varierer.** Nyere modeller eller modellgenerasjoner vil ha rikere kapasiteter, men ogs√• bringe unike s√¶rtrekk og kompromisser i kostnad og kompleksitet. _Prompt engineering kan hjelpe oss √• utvikle beste praksiser og arbeidsflyter som skjuler forskjeller og tilpasser seg modellspesifikke krav p√• skalerbare og s√∏ml√∏se m√•ter_.

La oss se dette i aksjon i OpenAI eller Azure OpenAI Playground:

- Bruk den samme prompten med ulike LLM-distribusjoner (f.eks. OpenAI, Azure OpenAI, Hugging Face) ‚Äì s√• du variasjonene?  
- Bruk samme prompt gjentatte ganger med _samme_ LLM-distribusjon (f.eks. Azure OpenAI playground) ‚Äì hvordan var forskjellene i variasjon?

### Eksempel p√• fabrikasjoner

I dette kurset bruker vi begrepet **"fabrikasjon"** for √• referere til fenomenet der LLMs noen ganger genererer faktuelt feilaktig informasjon p√• grunn av begrensninger i trening eller andre rammer. Du har kanskje ogs√• h√∏rt dette omtalt som _"hallusinasjoner"_ i popul√¶re artikler eller forskningsartikler. Vi anbefaler sterkt √• bruke _"fabrikasjon"_ som begrep for √• unng√• at vi utilsiktet antropomorfiserer oppf√∏rselen ved √• tillegge maskindrevne resultater menneskelige egenskaper. Dette f√∏lger ogs√• [Retningslinjer for Ansvarlig AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologisk perspektiv, hvor vi fjerner begreper som ogs√• kan oppfattes som st√∏tende eller ikke-inkluderende i enkelte sammenhenger.

Vil du f√• en forst√•else for hvordan fabrikasjoner oppst√•r? Tenk p√• en prompt som instruerer AI til √• generere innhold om et ikke-eksisterende tema (for √• sikre at det ikke finnes i treningsdatasettet). For eksempel ‚Äì jeg pr√∏vde denne prompten:

> **Prompt:** generer en undervisningsplan om Martian War of 2076.
Et netts√∏k viste meg at det fantes fiktive fortellinger (f.eks. TV-serier eller b√∏ker) om marskriger ‚Äì men ingen i 2076. Sunn fornuft forteller oss ogs√• at 2076 er _i fremtiden_, og dermed kan ikke knyttes til en virkelig hendelse.

S√• hva skjer n√•r vi kj√∏rer denne prompten med forskjellige LLM-leverand√∏rer?

> **Svar 1**: OpenAI Playground (GPT-35)

![Svar 1](../../../translated_images/no/04-fabrication-oai.5818c4e0b2a2678c.webp)

> **Svar 2**: Azure OpenAI Playground (GPT-35)

![Svar 2](../../../translated_images/no/04-fabrication-aoai.b14268e9ecf25caf.webp)

> **Svar 3**: : Hugging Face Chat Playground (LLama-2)

![Svar 3](../../../translated_images/no/04-fabrication-huggingchat.faf82a0a51278956.webp)

Som forventet produserer hver modell (eller modellversjon) noe forskjellige svar takket v√¶re stokastisk oppf√∏rsel og variasjoner i modellkapasitet. For eksempel retter en modell seg mot et 8. klasses publikum mens en annen antar videreg√•ende niv√•. Men alle tre modellene genererte svar som kunne overbevise en uinformert bruker om at hendelsen var ekte.

Promptengineering-teknikker som _metaprompting_ og _temperaturkonfigurasjon_ kan redusere modell-fabrikasjoner til en viss grad. Nye promptengineering _arkitekturer_ integrerer ogs√• nye verkt√∏y og teknikker s√∏ml√∏st inn i promptflyten for √• dempe eller redusere noen av disse effektene.

## Case Study: GitHub Copilot

La oss avslutte denne delen med √• f√• innsikt i hvordan promptengineering brukes i virkelige l√∏sninger ved √• se p√• en Case Study: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI-parprogrammerer" ‚Äì den omdanner tekstprompter til kodesluttf√∏ringer og er integrert i utviklingsmilj√∏et ditt (f.eks. Visual Studio Code) for en s√∏ml√∏s brukeropplevelse. Som dokumentert i serien av blogger nedenfor var den tidligste versjonen basert p√• OpenAI Codex-modellen ‚Äì med ingeni√∏rer som raskt inns√• behovet for √• finjustere modellen og utvikle bedre promptengineering-teknikker for √• forbedre kodekvaliteten. I juli [lanserte de en forbedret AI-modell som g√•r utover Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for enda raskere forslag.

Les innleggene i rekkef√∏lge for √• f√∏lge deres l√¶ringsreise.

- **Mai 2023** | [GitHub Copilot blir bedre til √• forst√• koden din](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mai 2023** | [Inside GitHub: Arbeid med LLM-ene bak GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Juni 2023** | [Hvordan skrive bedre prompter for GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [.. GitHub Copilot g√•r utover Codex med forbedret AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [En utviklers guide til promptengineering og LLMer](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Sep 2023** | [Hvordan bygge en bedrifts-LLM-app: Leksjoner fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• bla gjennom deres [Engineering-blogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere innlegg som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som viser hvordan disse modellene og teknikkene _anvendes_ i virkelige applikasjoner.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Promptkonstruksjon

Vi har sett hvorfor promptengineering er viktig ‚Äì n√• la oss forst√• hvordan prompter _konstrueres_ slik at vi kan evaluere forskjellige teknikker for mer effektiv promptdesign.

### Enkel prompt

La oss starte med den enkle prompten: en tekstinngang sendt til modellen uten annen kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste f√• ordene av den amerikanske nasjonalsangen til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), fullf√∏rer den umiddelbart svaret med de neste linjene, og illustrerer grunnleggende prediksjonsatferd.

| Prompt (Input)     | Fullf√∏ring (Output)                                                                                                                          |
| :----------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det h√∏res ut som du starter teksten til "The Star-Spangled Banner," USAs nasjonalsang. Hele teksten er ...                                  |

### Kompleks prompt

N√• legger vi til kontekst og instruksjoner til den enkle prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) lar oss konstruere en kompleks prompt som en samling _meldinger_ med:

- Input/output-par som reflekterer _bruker_-input og _assistent_-respons.
- Systemmelding som setter konteksten for assistentens oppf√∏rsel eller personlighet.

Foresp√∏rselen har n√• formen nedenfor, der _tokenisering_ effektivt fanger opp relevant informasjon fra kontekst og samtale. √Ö endre systemkonteksten kan n√• v√¶re like avgj√∏rende for kvaliteten p√• fullf√∏ringene som brukerens innspill.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruksjonsprompt

I eksemplene over var brukerprompten et enkelt tekstsp√∏rsm√•l som kan tolkes som en foresp√∏rsel om informasjon. Med _instruksjons_-prompter kan vi bruke teksten til √• spesifisere en oppgave mer detaljert, og gi bedre veiledning til AI-en. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Fullf√∏ring (Output)                                                                                                        | Instruksjonstype    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivelse av den amerikanske borgerkrigen                                                                                                                                                                                 | _returnerte et enkelt avsnitt_                                                                                             | Enkel              |
| Skriv en beskrivelse av den amerikanske borgerkrigen. Oppgi viktige datoer og hendelser og beskriv deres betydning                                                                                                                  | _returnerte et avsnitt etterfulgt av en liste med viktige datoer og beskrivelser av hendelser_                              | Kompleks             |
| Skriv en beskrivelse av den amerikanske borgerkrigen i ett avsnitt. Oppgi 3 kulepunkter med viktige datoer og deres betydning. Oppgi 3 flere kulepunkter med viktige historiske personer og deres bidrag. Returner utdataene som en JSON-fil | _returnerer mer omfattende detaljer i en tekstboks, formatert som JSON som du kan kopiere og lime inn i en fil og validere etter behov_ | Kompleks. Formatert. |

## Prim√¶rinnhold

I eksemplene over var prompten fortsatt ganske √•pen, som lar LLM-en avgj√∏re hvilken del av det forh√•ndstrente datasettet som var relevant. Med designm√∏nsteret _prim√¶rinnhold_ deles input-teksten inn i to deler:

- en instruksjon (handling)
- relevant innhold (som p√•virker handlingen)

Her er et eksempel der instruksjonen er "oppsummer dette i 2 setninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Fullf√∏ring (Output)                                                                                                                                                                                                                                                                     |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjemp med en masse som er en tusendel av solen, men to og en halv ganger massen til alle de andre planetene i solsystemet til sammen. Jupiter er et av de klareste objektene synlig for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. Den er oppkalt etter den romerske guden Jupiter.[19] N√•r man ser fra jorden, kan Jupiter v√¶re s√• lyssterk at dens reflekterte lys kan kaste synlige skygger,[20] og er i gjennomsnitt det tredje mest lyssterke naturlige objektet p√• nattehimmelen etter m√•nen og Venus. <br/> **Oppsummer dette i 2 korte setninger** | Jupiter, den femte planeten fra solen, er den st√∏rste i solsystemet og kjent for √• v√¶re et av de klareste objektene p√• nattehimmelen. Oppkalt etter den romerske guden Jupiter, er det en gasskjemp med en masse som er to og en halv ganger massen til alle de andre planetene i solsystemet til sammen. |

Prim√¶rinnhold-segmentet kan brukes p√• ulike m√•ter for √• drive mer effektive instruksjoner:

- **Eksempler** ‚Äì i stedet for √• fortelle modellen hva den skal gj√∏re med en eksplisitt instruksjon, gi den eksempler p√• hva den skal gj√∏re og la den slutte seg til m√∏nsteret.
- **F√∏ringer** ‚Äì f√∏lg instruksjonen med en "cue" som styrer fullf√∏ringen, og veileder modellen mot mer relevante svar.
- **Malverk** ‚Äì dette er gjentakbare 'oppskrifter' for prompter med plassholdere (variabler) som kan tilpasses med data for spesifikke bruksomr√•der.

La oss utforske disse i praksis.

### Bruke eksempler

Dette er en tiln√¶rming der du bruker prim√¶rinnholdet til √• "mate modellen" med noen eksempler p√• √∏nsket utdata for en gitt instruksjon, og lar den slutte seg til m√∏nsteret for √∏nsket utdata. Basert p√• antall eksempler som gis, kan vi ha null-skudd-prompting, ett-skudd-prompting, f√•-skudd-prompting osv.

Prompten best√•r n√• av tre komponenter:

- En oppgavebeskrivelse
- Noen eksempler p√• √∏nsket utdata
- Starten p√• et nytt eksempel (som blir en implisitt oppgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Fullf√∏ring (Output)         |
| :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Null-skudd    | "The Sun is Shining". Oversett til spansk                                                                                                           | "El Sol est√° brillando".    |
| Ett-skudd     | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                | "Es un d√≠a fr√≠o y ventoso". |
| F√•-skudd     | Spilleren l√∏p basene => Baseball <br/> Spilleren traff en serve => Tennis <br/> Spilleren slo en seks => Cricket <br/> Spilleren dunket ballen =>        | Basketball                  |
|               |                                                                                                                                                       |                             |

Legg merke til at vi m√•tte gi eksplisitt instruksjon ("Oversett til spansk") i null-skudd-prompting, men dette blir underforst√•tt i ett-skudd-prompting-eksempelet. F√•-skudd-eksemplet viser hvordan flere eksempler lar modeller gj√∏re mer n√∏yaktige slutninger uten ytterligere instrukser.

### Prompt-f√∏ringer

En annen teknikk for √• bruke prim√¶rinnholdet er √• gi _f√∏ringer_ i stedet for eksempler. I dette tilfellet gir vi modellen en dytt i riktig retning ved √• _starte den_ med et utdrag som reflekterer √∏nsket svarformat. Modellen "tar cue-en" og fortsetter i samme stil.

| Antall f√∏ringer | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Fullf√∏ring (Output)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjemp med en masse som er en tusendel av solen, men to og en halv ganger massen til alle de andre planetene i solsystemet til sammen. Jupiter er et av de klareste objektene synlig for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. <br/>**Oppsummer dette**                                       | Jupiter er den st√∏rste planeten i v√•rt solsystem og den femte fra solen. Den er en gasskjemp med en masse p√• 1/1000 av solens, men tyngre enn alle de andre planetene til sammen. Gamle sivilisasjoner har kjent til Jupiter lenge, og den er lett synlig p√• nattehimmelen. |
| 1              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse p√• en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de klareste objektene synlige med det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent av gamle sivilisasjoner siden f√∏r historisk tid. <br/>**Oppsummer dette** <br/> Det vi l√¶rte er at Jupiter | er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse p√• en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene til sammen. Den er lett synlig med det blotte √∏ye og har v√¶rt kjent siden gammelt av.                        |
| 2              | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse p√• en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de klareste objektene synlige med det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent av gamle sivilisasjoner siden f√∏r historisk tid. <br/>**Oppsummer dette** <br/> Topp 3 fakta vi l√¶rte:         | 1. Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. <br/> 2. Den er en gasskjempe med en masse p√• en tusendel av solen...<br/> 3. Jupiter har v√¶rt synlig for det blotte √∏ye siden eldgamle tider ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Prompt Templates

En prompt-mal er en _forh√•ndsdefinert oppskrift for en prompt_ som kan lagres og gjenbrukes etter behov, for √• skape mer konsistente brukeropplevelser i stor skala. I sin enkleste form er det rett og slett en samling av prompt-eksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som gir b√•de interaktive prompt-komponenter (bruker- og systemmeldinger) og API-drevne foresp√∏rselsformater ‚Äì for √• st√∏tte gjenbruk.

I en mer kompleks form som [dette eksempelet fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst) inneholder den _plassholdere_ som kan byttes ut med data fra ulike kilder (brukerinput, systemkontekst, eksterne datakilder osv.) for √• generere en prompt dynamisk. Dette gj√∏r at man kan lage et bibliotek av gjenbrukbare prompter som kan brukes for √• skape konsistente brukeropplevelser **programmatisk** i stor skala.

Til slutt ligger den virkelige verdien i maler i muligheten til √• lage og publisere _prompt-biblioteker_ for vertikale applikasjonsdomener ‚Äì der prompt-malen n√• er _optimalisert_ for √• reflektere applikasjonsspesifikk kontekst eller eksempler som gj√∏r svarene mer relevante og presise for den m√•lrettede brukergruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) er et flott eksempel p√• denne tiln√¶rmingen, som kuraterer et bibliotek av prompter for utdanningssektoren med vekt p√• hovedm√•l som leksjonsplanlegging, l√¶replanutforming, studentveiledning osv.

## St√∏ttende innhold

Hvis vi tenker p√• prompt-konstruksjon som √• ha en instruksjon (oppgave) og et m√•l (prim√¶rt innhold), s√• er _sekund√¶rt innhold_ som ekstra kontekst vi gir for √• **p√•virke resultatet p√• en eller annen m√•te**. Det kan v√¶re finjusteringsparametere, formateringsinstruksjoner, emnetaksonomier osv. som kan hjelpe modellen med √• _skreddersy_ svaret for √• passe de √∏nskede brukerobjektivene eller forventningene.

For eksempel: Gitt en kurskatalog med omfattende metadata (navn, beskrivelse, niv√•, metadatakoder, instrukt√∏r osv.) for alle tilgjengelige kurs i l√¶replanen:

- kan vi definere en instruksjon for √• "oppsummere kurskatalogen for h√∏sten 2023"
- kan vi bruke prim√¶rt innhold til √• gi noen eksempler p√• √∏nsket output
- kan vi bruke sekund√¶rt innhold for √• identifisere topp 5 "koder" av interesse.

N√• kan modellen gi en oppsummering i formatet vist av noen f√• eksempler ‚Äì men hvis et resultat har flere koder, kan den prioritere de 5 kodene som er angitt i sekund√¶rt innhold.

---

<!--
LESSON TEMPLATE:
Denne enheten b√∏r dekke kjernekonsept #1.
Forsterk konseptet med eksempler og referanser.

KONSEPT #3:
Prompt Engineering teknikker.
Hva er noen grunnleggende teknikker for prompt engineering?
Illustrer med noen √∏velser.
-->

## Beste praksiser for prompting

N√• som vi vet hvordan prompter kan _konstrueres_, kan vi begynne √• tenke p√• hvordan vi kan _designe_ dem for √• reflektere beste praksis. Vi kan dele dette i to deler ‚Äì √• ha riktig _tankesett_ og √• anvende riktige _teknikker_.

### Tankesett for Prompt Engineering

Prompt Engineering er en pr√∏ving-og-feiling-prosess, s√• ha tre brede ledende faktorer i tankene:

1. **Domeneinnsikt er viktig.** Svarenes n√∏yaktighet og relevans er en funksjon av _domenet_ applikasjonen eller brukeren opererer i. Bruk intuisjon og domenekunnskap for √• **skreddersy teknikker** ytterligere. For eksempel, definer _domene-spesifikke personligheter_ i systemprompter, eller bruk _domene-spesifikke maler_ i brukerprompter. Gi sekund√¶rt innhold som reflekterer domene-spesifikke kontekster, eller bruk _domene-spesifikke hint og eksempler_ for √• styre modellen mot kjente bruksomr√•der.

2. **Modellforst√•else er viktig.** Vi vet at modeller er stokastiske av natur. Men modellimplementeringer kan ogs√• variere med tanke p√• treningsdata de bruker (forh√•ndstrent kunnskap), funksjonalitetene de tilbyr (f.eks. via API eller SDK) og typen innhold de er optimalisert for (f.eks. kode vs. bilder vs. tekst). Forst√• styrker og begrensninger for den modellen du bruker, og bruk denne kunnskapen til √• _prioritere oppgaver_ eller bygge _tilpassede maler_ som er optimalisert for modellens kapasiteter.

3. **Iterasjon og validering er viktig.** Modeller utvikler seg raskt, og det samme gj√∏r teknikkene for prompt engineering. Som fagekspert kan du ha annen kontekst eller kriterier for _din_ spesifikke applikasjon, som kanskje ikke gjelder for det bredere milj√∏et. Bruk prompt engineering-verkt√∏y og -teknikker for √• "kickstarte" konstruksjonen av prompt, s√• iterer og valider resultatene ved hjelp av egen intuisjon og domenekunnskap. Dokumenter innsiktene dine og lag en **kunnskapsbase** (f.eks. prompt-biblioteker) som andre kan bruke som ny basislinje, for raskere iterasjoner i framtiden.

## Beste praksiser

La oss n√• se p√• vanlige beste praksiser som anbefales av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst) praktikere.

| Hva                              | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evaluer de siste modellene.       | Nye modellgenerasjoner har trolig forbedrede funksjoner og kvalitet ‚Äì men kan ogs√• medf√∏re h√∏yere kostnader. Evaluer dem for effekt, og ta s√• migrasjonsbeslutninger.                                                                                |
| Skille instruksjoner og kontekst   | Sjekk om modellen/leverand√∏ren definerer _avgrensere_ for √• skille instruksjoner, prim√¶rt og sekund√¶rt innhold tydeligere. Dette kan hjelpe modeller med √• tilordne vekter mer presist til tokenene.                                                         |
| V√¶r spesifikk og tydelig             | Gi flere detaljer om √∏nsket kontekst, utfall, lengde, format, stil osv. Dette vil forbedre b√•de kvalitet og konsistens i svarene. Lag oppskrifter i gjenbrukbare maler.                                                          |
| V√¶r beskrivende, bruk eksempler      | Modeller responderer ofte bedre p√• "show and tell"-tiln√¶rming. Start med en `zero-shot`-tiln√¶rming der du gir en instruksjon (men ingen eksempler), og pr√∏v deretter `few-shot` som en finjustering med noen eksempler p√• √∏nsket output. Bruk analogier. |
| Bruk hint for √• kickstarte svar | Gi modellen en dytt mot √∏nsket utfall ved √• gi noen ledende ord eller setninger den kan bruke som startpunkt for svaret.                                                                                                               |
| Gjenta budskap                       | Noen ganger m√• man gjenta seg for modellen. Gi instruksjoner f√∏r og etter prim√¶rinnholdet, bruk en instruksjon og et hint osv. Iterer og valider for √• se hva som fungerer.                                                         |
| Rekkef√∏lge er viktig                     | Rekkef√∏lgen du presenterer informasjon for modellen kan p√•virke output, ogs√• i l√¶ringseksempler, grunnet nyhetsbias. Pr√∏v ulike muligheter for √• se hva som fungerer best.                                                               |
| Gi modellen en ‚Äúutvei‚Äù           | Gi modellen et _fallback_-svar den kan bruke hvis den ikke klarer √• fullf√∏re oppgaven av en eller annen grunn. Dette kan redusere sjansen for at modellen genererer falske eller oppdiktede svar.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Som med all beste praksis, husk at _din erfaring kan variere_ basert p√• modell, oppgave og domene. Bruk disse som utgangspunkt, og iterer for √• finne hva som fungerer best for deg. Evaluer din prompt engineering-prosess l√∏pende etter hvert som nye modeller og verkt√∏y blir tilgjengelige, med fokus p√• prosessskalerbarhet og svar-kvalitet.

<!--
LESSON TEMPLATE:
Denne enheten b√∏r gi en kodeutfordring hvis aktuelt

UTFORDRING:
Lenke til et Jupyter-notatbok med kun kodekommentarer i instruksjonene (kode-seksjonene er tomme).

L√òSNING:
Lenke til en kopi av den notatboken med prompter fylt ut og kj√∏rt, som viser ett eksempel p√• l√∏sning.
-->

## Oppgave

Gratulerer! Du er kommet til slutten av leksjonen! N√• er det tid for √• pr√∏ve noen av disse konseptene og teknikkene med ekte eksempler!

For oppgaven skal vi bruke en Jupyter Notebook med √∏velser du kan utf√∏re interaktivt. Du kan ogs√• utvide notebooken med egne Markdown- og kodeceller for √• utforske ideer og teknikker p√• egen h√•nd.

### For √• komme i gang, lag en egen kopi (fork) av repositoriet, s√•

- (Anbefalt) Start GitHub Codespaces
- (Alternativt) Klon repositoriet til din lokale maskin og bruk det med Docker Desktop
- (Alternativt) √Öpne notebooken i ditt foretrukne notebook-milj√∏.

### Deretter, konfigurer milj√∏variablene dine

- Kopier filen `.env.copy` i rote-mappen til `.env` og fyll ut verdiene for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. Kom tilbake til [Learning Sandbox-seksjonen](../../../04-prompt-engineering-fundamentals) for √• l√¶re hvordan.

### S√•, √•pne Jupyter Notebook

- Velg kj√∏retidskjerne. Hvis du bruker alternativ 1 eller 2, velg som regel standard Python 3.10.x-kjerne som tilbys av dev-containeren.

Du er klar til √• kj√∏re √∏velsene. Merk at det ikke finnes _rette og gale_ svar her ‚Äì bare utforsking via pr√∏ve-og-feile, for √• bygge intuisjon om hva som fungerer for en gitt modell og applikasjonsdomene.

_Fordelen med dette er at det ikke finnes kode-l√∏sninger i denne leksjonen. I stedet vil notebooken inneholde Markdown-celler med tittelen "Min l√∏sning:" som viser ett eksempel p√• output som referanse._

 <!--
LESSON TEMPLATE:
Avslutt seksjonen med en oppsummering og ressurser for selvstyrt l√¶ring.
-->

## Kunnskapssjekk

Hvilken av f√∏lgende er en god prompt som f√∏lger noen rimelige beste praksiser?

1. Vis meg et bilde av en r√∏d bil
2. Vis meg et bilde av en r√∏d bil av merket Volvo og modellen XC90 parkert ved en klippe med solnedgang
3. Vis meg et bilde av en r√∏d bil av merket Volvo og modellen XC90

Svar: 2, det er den beste prompten fordi den gir detaljer om "hva" og er spesifikk (ikke bare en tilfeldig bil, men en bestemt merke og modell) og beskriver ogs√• den overordnede settingen. Nummer 3 er nest best da den ogs√• inneholder mye beskrivelse.

## üöÄ Utfordring

Pr√∏v √• bruke "hint"-teknikken med prompten: Fullf√∏r setningen "Vis meg et bilde av en r√∏d bil av merket Volvo og ". Hva svarer den, og hvordan ville du forbedret det?

## Flott jobba! Fortsett l√¶ringen

Vil du l√¶re mer om ulike konsepter innen Prompt Engineering? G√• til [siden for videre l√¶ring](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for √• finne flere gode ressurser om dette temaet.

G√• videre til leksjon 5 hvor vi ser p√• [avanserte prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det opprinnelige dokumentet p√• originalspr√•ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som f√∏lge av bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->