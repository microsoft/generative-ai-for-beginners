<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "dcbaaae026cb50fee071e690685b5843",
  "translation_date": "2025-08-26T17:37:03+00:00",
  "source_file": "04-prompt-engineering-fundamentals/README.md",
  "language_code": "no"
}
-->
# Grunnleggende om Prompt Engineering

[![Prompt Engineering Fundamentals](../../../translated_images/04-lesson-banner.a2c90deba7fedacda69f35b41636a8951ec91c2e33f5420b1254534ac85bc18e.no.png)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introduksjon
Dette modulen dekker viktige konsepter og teknikker for √• lage effektive prompt til generative AI-modeller. M√•ten du skriver prompten til en LLM p√• har ogs√• mye √• si. En n√∏ye utformet prompt kan gi bedre kvalitet p√• svaret. Men hva betyr egentlig begreper som _prompt_ og _prompt engineering_? Og hvordan kan jeg forbedre prompt-_inputen_ jeg sender til LLM-en? Dette er sp√∏rsm√•lene vi skal pr√∏ve √• svare p√• i dette og neste kapittel.

_Generativ AI_ kan lage nytt innhold (f.eks. tekst, bilder, lyd, kode osv.) som svar p√• brukerforesp√∏rsler. Dette gj√∏res ved hjelp av _Large Language Models_ som OpenAIs GPT-serie ("Generative Pre-trained Transformer") som er trent til √• bruke naturlig spr√•k og kode.

Brukere kan n√• samhandle med disse modellene gjennom kjente grensesnitt som chat, uten √• trenge teknisk kunnskap eller oppl√¶ring. Modellene er _prompt-baserte_ ‚Äì brukeren sender inn en tekst (prompt) og f√•r AI-svaret (completion) tilbake. De kan s√• "chatte med AI-en" i flere runder, og forbedre prompten til svaret matcher forventningene.

"Prompts" har dermed blitt det viktigste _programmeringsgrensesnittet_ for generative AI-apper, og forteller modellene hva de skal gj√∏re og p√•virker kvaliteten p√• svarene. "Prompt Engineering" er et raskt voksende fagfelt som handler om _design og optimalisering_ av prompts for √• levere konsistente og gode svar i stor skala.

## L√¶ringsm√•l

I denne leksjonen l√¶rer vi hva Prompt Engineering er, hvorfor det er viktig, og hvordan vi kan lage mer effektive prompts for en gitt modell og applikasjonsm√•l. Vi g√•r gjennom sentrale konsepter og beste praksis for prompt engineering ‚Äì og blir kjent med et interaktivt Jupyter Notebooks "sandbox"-milj√∏ hvor vi kan se disse konseptene i praksis med ekte eksempler.

Etter denne leksjonen skal du kunne:

1. Forklare hva prompt engineering er og hvorfor det er viktig.
2. Beskrive komponentene i en prompt og hvordan de brukes.
3. L√¶re beste praksis og teknikker for prompt engineering.
4. Bruke l√¶rte teknikker p√• ekte eksempler, med en OpenAI-endepunkt.

## Viktige begreper

Prompt Engineering: Praksisen med √• designe og forbedre input for √• styre AI-modeller mot √∏nskede resultater.
Tokenisering: Prosessen med √• gj√∏re om tekst til mindre enheter, kalt tokens, som en modell kan forst√• og behandle.
Instruction-Tuned LLMs: Store spr√•kmodeller (LLMs) som er finjustert med spesifikke instruksjoner for √• forbedre n√∏yaktighet og relevans i svarene.

## L√¶rings-sandkasse

Prompt engineering er forel√∏pig mer kunst enn vitenskap. Den beste m√•ten √• utvikle intuisjon p√•, er √• _√∏ve mye_ og bruke en pr√∏v-og-feil-tiln√¶rming som kombinerer domenekunnskap med anbefalte teknikker og modellspesifikke optimaliseringer.

Jupyter-notebooken som f√∏lger med denne leksjonen gir deg et _sandkasse_-milj√∏ hvor du kan teste det du l√¶rer ‚Äì underveis eller som del av kodeutfordringen til slutt. For √• kj√∏re √∏velsene trenger du:

1. **En Azure OpenAI API-n√∏kkel** ‚Äì tjenesteendepunktet for en utplassert LLM.
2. **Et Python-milj√∏** ‚Äì hvor notebooken kan kj√∏res.
3. **Lokale milj√∏variabler** ‚Äì _fullf√∏r [SETUP](./../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst)-stegene n√• for √• bli klar_.

Notatboken har _start√∏velser_ ‚Äì men du oppfordres til √• legge til egne _Markdown_- (beskrivelse) og _Kode_- (prompt-foresp√∏rsler) seksjoner for √• teste flere eksempler eller ideer ‚Äì og bygge opp din egen intuisjon for prompt-design.

## Illustrert guide

Vil du f√• oversikt over hva denne leksjonen dekker f√∏r du setter i gang? Ta en titt p√• denne illustrerte guiden, som gir deg et inntrykk av hovedtemaene og viktige poenger du b√∏r tenke p√• i hver del. Leksjonskartet tar deg fra √• forst√• kjernebegrepene og utfordringene til √• l√∏se dem med relevante prompt engineering-teknikker og beste praksis. Merk at delen "Advanced Techniques" i denne guiden viser til innhold som dekkes i _neste_ kapittel av dette kurset.

![Illustrated Guide to Prompt Engineering](../../../translated_images/04-prompt-engineering-sketchnote.d5f33336957a1e4f623b826195c2146ef4cc49974b72fa373de6929b474e8b70.no.png)

## V√•r startup

La oss se hvordan _dette temaet_ henger sammen med v√•r startup-misjon om √• [bringe AI-innovasjon til utdanning](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Vi √∏nsker √• bygge AI-drevne applikasjoner for _personlig tilpasset l√¶ring_ ‚Äì s√• la oss tenke p√• hvordan ulike brukere av appen v√•r kan "designe" prompts:

- **Administratorer** kan be AI-en _analysere l√¶replan-data for √• finne hull i dekningen_. AI-en kan oppsummere resultatene eller visualisere dem med kode.
- **L√¶rere** kan be AI-en _lage en undervisningsplan for en bestemt m√•lgruppe og tema_. AI-en kan lage en personlig plan i √∏nsket format.
- **Elever** kan be AI-en _hjelpe dem med et vanskelig fag_. AI-en kan n√• veilede eleven med leksjoner, hint og eksempler tilpasset deres niv√•.

Dette er bare starten. Sjekk ut [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) ‚Äì et √•pent bibliotek med prompts kuratert av utdanningseksperter ‚Äì for √• f√• et bredere inntrykk av mulighetene! _Pr√∏v √• kj√∏re noen av disse promptene i sandkassen eller i OpenAI Playground for √• se hva som skjer!_

<!--
LESSON TEMPLATE:
Denne enheten b√∏r dekke kjernebegrep #1.
Forsterk begrepet med eksempler og referanser.

KONSEPT #1:
Prompt Engineering.
Definer det og forklar hvorfor det trengs.
-->

## Hva er Prompt Engineering?

Vi startet denne leksjonen med √• definere **Prompt Engineering** som prosessen med √• _designe og optimalisere_ tekstinput (prompts) for √• levere konsistente og gode svar (completions) for et gitt applikasjonsm√•l og modell. Vi kan se p√• dette som en 2-stegs prosess:

- _designe_ den f√∏rste prompten for en gitt modell og m√•l
- _forbedre_ prompten stegvis for √• √∏ke kvaliteten p√• svaret

Dette er n√∏dvendigvis en pr√∏v-og-feil-prosess som krever brukerens intuisjon og innsats for √• f√• best mulig resultat. Men hvorfor er det viktig? For √• svare p√• det m√• vi f√∏rst forst√• tre begreper:

- _Tokenisering_ = hvordan modellen "ser" prompten
- _Base LLMs_ = hvordan grunnmodellen "behandler" en prompt
- _Instruction-Tuned LLMs_ = hvordan modellen n√• kan se "oppgaver"

### Tokenisering

En LLM ser prompts som en _sekvens av tokens_ der ulike modeller (eller versjoner av en modell) kan tokenisere samme prompt p√• ulike m√•ter. Siden LLM-er er trent p√• tokens (og ikke r√• tekst), har m√•ten prompts blir tokenisert p√• direkte innvirkning p√• kvaliteten p√• det genererte svaret.

For √• f√• en f√∏lelse av hvordan tokenisering fungerer, kan du pr√∏ve verkt√∏y som [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) vist under. Lim inn prompten din ‚Äì og se hvordan den blir gjort om til tokens, og legg merke til hvordan mellomrom og tegnsetting h√•ndteres. Merk at dette eksempelet viser en eldre LLM (GPT-3) ‚Äì s√• √• pr√∏ve dette med en nyere modell kan gi et annet resultat.

![Tokenization](../../../translated_images/04-tokenizer-example.e71f0a0f70356c5c7d80b21e8753a28c18a7f6d4aaa1c4b08e65d17625e85642.no.png)

### Konsept: Grunnmodeller

N√•r en prompt er tokenisert, er hovedfunksjonen til ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (eller grunnmodell) √• forutsi neste token i sekvensen. Siden LLM-er er trent p√• enorme tekstmengder, har de god oversikt over statistiske sammenhenger mellom tokens og kan gj√∏re denne forutsigelsen med en viss sikkerhet. Merk at de ikke forst√•r _meningen_ med ordene i prompten eller tokenet; de ser bare et m√∏nster de kan "fullf√∏re" med neste forutsigelse. De kan fortsette √• forutsi sekvensen til brukeren stopper dem eller en forh√•ndsdefinert betingelse er oppfylt.

Vil du se hvordan prompt-basert fullf√∏ring fungerer? Skriv inn prompten over i Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) med standardinnstillinger. Systemet er satt opp til √• behandle prompts som foresp√∏rsler om informasjon ‚Äì s√• du b√∏r f√• et svar som passer til denne konteksten.

Men hva om brukeren √∏nsker √• se noe spesifikt som oppfyller visse kriterier eller oppgavem√•l? Det er her _instruction-tuned_ LLMs kommer inn i bildet.

![Base LLM Chat Completion](../../../translated_images/04-playground-chat-base.65b76fcfde0caa6738e41d20f1a6123f9078219e6f91a88ee5ea8014f0469bdf.no.png)

### Konsept: Instruction Tuned LLMs

En [Instruction Tuned LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) starter med grunnmodellen og finjusterer den med eksempler eller input/output-par (f.eks. samtaler med flere meldinger) som kan inneholde tydelige instruksjoner ‚Äì og AI-svaret pr√∏ver √• f√∏lge denne instruksjonen.

Dette bruker teknikker som Reinforcement Learning with Human Feedback (RLHF) som kan trene modellen til √• _f√∏lge instruksjoner_ og _l√¶re av tilbakemeldinger_ slik at den gir svar som er bedre egnet til praktiske bruksomr√•der og mer relevante for brukerens m√•l.

La oss pr√∏ve det ‚Äì bruk prompten over igjen, men endre n√• _systemmeldingen_ til √• gi f√∏lgende instruksjon som kontekst:

> _Oppsummer innholdet du f√•r for en andreklassing. Hold resultatet til ett avsnitt med 3-5 punktlister._

Ser du hvordan resultatet n√• er tilpasset √∏nsket m√•l og format? En l√¶rer kan n√• bruke dette svaret direkte i presentasjonen for den klassen.

![Instruction Tuned LLM Chat Completion](../../../translated_images/04-playground-chat-instructions.b30bbfbdf92f2d051639c9bc23f74a0e2482f8dc7f0dafc6cc6fda81b2b00534.no.png)

## Hvorfor trenger vi Prompt Engineering?

N√• som vi vet hvordan prompts behandles av LLM-er, la oss snakke om _hvorfor_ vi trenger prompt engineering. Svaret ligger i at dagens LLM-er har flere utfordringer som gj√∏r det _vanskeligere √• f√• p√•litelige og konsistente svar_ uten √• legge innsats i utforming og optimalisering av prompts. For eksempel:

1. **Modellsvar er stokastiske.** _Samme prompt_ vil sannsynligvis gi ulike svar med forskjellige modeller eller modellversjoner. Og det kan til og med gi ulike resultater med _samme modell_ til forskjellige tider. _Prompt engineering-teknikker kan hjelpe oss √• minimere disse variasjonene ved √• gi bedre rammer._

1. **Modeller kan finne p√• svar.** Modellene er forh√•ndstrent p√• _store, men begrensede_ datasett, noe som betyr at de mangler kunnskap om konsepter utenfor treningsgrunnlaget. Derfor kan de gi svar som er un√∏yaktige, oppdiktede eller direkte i strid med kjente fakta. _Prompt engineering-teknikker hjelper brukere √• oppdage og redusere slike oppdiktede svar, for eksempel ved √• be AI-en om kilder eller resonnement._

1. **Modellenes evner vil variere.** Nyere modeller eller generasjoner har flere muligheter, men kan ogs√• ha egne s√¶regenheter og kompromisser i kostnad og kompleksitet. _Prompt engineering kan hjelpe oss √• utvikle beste praksis og arbeidsflyter som skjuler forskjeller og tilpasser seg modellspesifikke krav p√• en skalerbar og s√∏ml√∏s m√•te._

La oss se dette i praksis i OpenAI eller Azure OpenAI Playground:

- Bruk samme prompt med ulike LLM-implementasjoner (f.eks. OpenAI, Azure OpenAI, Hugging Face) ‚Äì ser du variasjonene?
- Bruk samme prompt flere ganger med _samme_ LLM-implementasjon (f.eks. Azure OpenAI playground) ‚Äì hvordan varierte svarene?

### Eksempel p√• oppdiktede svar

I dette kurset bruker vi begrepet **"fabrication"** for √• beskrive fenomenet der LLM-er noen ganger genererer faktuelt feil informasjon p√• grunn av begrensninger i treningen eller andre forhold. Du har kanskje ogs√• h√∏rt dette omtalt som _"hallusinasjoner"_ i artikler eller forskningsartikler. Vi anbefaler imidlertid √• bruke _"fabrication"_ for √• unng√• √• tillegge maskinen menneskelige egenskaper. Dette st√∏tter ogs√• [Retningslinjer for ansvarlig AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) fra et terminologiperspektiv, og fjerner begreper som kan oppfattes som st√∏tende eller ekskluderende i noen sammenhenger.

Vil du se hvordan oppdiktede svar fungerer? Tenk ut en prompt som ber AI-en lage innhold om et ikke-eksisterende tema (slik at det ikke finnes i treningsdataene). For eksempel ‚Äì jeg pr√∏vde denne prompten:
# Undervisningsplan: Den martianske krigen i 2076

## M√•l

- Forst√• de viktigste hendelsene og √•rsakene til den martianske krigen i 2076.
- Utforske de politiske, sosiale og teknologiske konsekvensene av konflikten.
- Analysere hvordan krigen p√•virket forholdet mellom Jorden og Mars.

## Introduksjon

Den martianske krigen i 2076 var en avgj√∏rende konflikt mellom koloniene p√• Mars og myndighetene p√• Jorden. Krigen endret maktbalansen i solsystemet og f√∏rte til store endringer i b√•de teknologi og samfunn.

## Leksjonens innhold

### 1. Bakgrunn og √•rsaker

- Diskuter de √∏konomiske og politiske spenningene mellom Mars og Jorden.
- Unders√∏k hvordan ressursmangel og √∏kende uavhengighetsbevegelser p√• Mars bidro til konflikten.
- Se p√• de f√∏rste tegnene til oppr√∏r og hvordan de ble h√•ndtert av jordiske myndigheter.

### 2. Viktige hendelser under krigen

- G√• gjennom de st√∏rste slagene, inkludert Slaget om Olympus Mons og beleiringen av New Valles.
- Diskuter bruken av avansert teknologi, som autonome droner og energiv√•pen.
- Analyser strategiene til begge sider og hvordan de p√•virket krigens utfall.

### 3. Konsekvenser og etterspill

- Utforsk de politiske endringene etter krigen, inkludert Mars‚Äô uavhengighetserkl√¶ring.
- Diskuter de sosiale og √∏konomiske effektene p√• b√•de Mars og Jorden.
- Vurder hvordan krigen f√∏rte til nye diplomatiske og teknologiske samarbeid.

## Aktiviteter

- Grupperefleksjon: Del klassen inn i grupper for √• diskutere hvordan krigen kunne v√¶rt unng√•tt.
- Tidslinje: Lag en tidslinje over de viktigste hendelsene under krigen.
- Debatt: Arranger en debatt om hvorvidt Mars burde ha f√•tt uavhengighet.

## Vurdering

- Skriftlig oppgave: Skriv en rapport om en av de sentrale hendelsene i krigen og dens betydning.
- Presentasjon: Presenter en analyse av krigens langsiktige konsekvenser for solsystemet.

## Ressurser

- Anbefalte b√∏ker og artikler om den martianske krigen i 2076.
- Dokumentarer og intervjuer med historikere og eksperter p√• rompolitikk.

## Oppsummering

Den martianske krigen i 2076 var en milep√¶l i menneskehetens historie. Gjennom denne leksjonen har vi sett p√• √•rsakene, hendelsene og konsekvensene av konflikten, og reflektert over hvordan den har formet fremtiden for b√•de Mars og Jorden.
Et netts√∏k viste meg at det finnes fiktive beretninger (f.eks. TV-serier eller b√∏ker) om kriger p√• Mars ‚Äì men ingen fra 2076. Sunn fornuft tilsier ogs√• at 2076 er _i fremtiden_, og derfor ikke kan knyttes til en virkelig hendelse.

S√• hva skjer n√•r vi kj√∏rer denne prompten hos ulike LLM-leverand√∏rer?

> **Respons 1**: OpenAI Playground (GPT-35)

![Respons 1](../../../translated_images/04-fabrication-oai.5818c4e0b2a2678c40e0793bf873ef4a425350dd0063a183fb8ae02cae63aa0c.no.png)

> **Respons 2**: Azure OpenAI Playground (GPT-35)

![Respons 2](../../../translated_images/04-fabrication-aoai.b14268e9ecf25caf613b7d424c16e2a0dc5b578f8f960c0c04d4fb3a68e6cf61.no.png)

> **Respons 3**: : Hugging Face Chat Playground (LLama-2)

![Respons 3](../../../translated_images/04-fabrication-huggingchat.faf82a0a512789565e410568bce1ac911075b943dec59b1ef4080b61723b5bf4.no.png)

Som forventet gir hver modell (eller modellversjon) litt ulike svar, takket v√¶re stokastisk oppf√∏rsel og variasjoner i modellens evner. For eksempel retter √©n modell seg mot et publikum p√• ungdomsskolen, mens en annen antar at brukeren er videreg√•ende elev. Men alle tre modellene genererte svar som kunne overbevise en uvitende bruker om at hendelsen var ekte.

Teknikker innen prompt engineering som _metaprompting_ og _temperaturinnstillinger_ kan redusere modellens tendens til √• dikte opp ting til en viss grad. Nye _arkitekturer_ for prompt engineering integrerer ogs√• nye verkt√∏y og metoder s√∏ml√∏st i promptflyten, for √• motvirke eller redusere noen av disse effektene.

## Case Study: GitHub Copilot

La oss avslutte denne delen med √• se hvordan prompt engineering brukes i virkelige l√∏sninger, ved √• se p√• ett case: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot er din "AI-parprogrammerer" ‚Äì den gj√∏r tekstprompter om til kodeforslag og er integrert i utviklingsmilj√∏et ditt (f.eks. Visual Studio Code) for en s√∏ml√∏s brukeropplevelse. Som dokumentert i bloggserien under, var den f√∏rste versjonen basert p√• OpenAI Codex-modellen ‚Äì og ingeni√∏rene inns√• raskt behovet for √• finjustere modellen og utvikle bedre prompt engineering-teknikker for √• forbedre kodekvaliteten. I juli [lanserte de en forbedret AI-modell som g√•r utover Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) for enda raskere forslag.

Les innleggene i rekkef√∏lge for √• f√∏lge deres l√¶ringsreise.

- **Mai 2023** | [GitHub Copilot blir bedre til √• forst√• koden din](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mai 2023** | [Inne i GitHub: Arbeid med LLM-ene bak GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juni 2023** | [Slik skriver du bedre promter for GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Juli 2023** | [.. GitHub Copilot g√•r utover Codex med forbedret AI-modell](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Juli 2023** | [En utviklers guide til prompt engineering og LLM-er](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **September 2023** | [Slik bygger du en bedriftsapp med LLM: L√¶rdom fra GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Du kan ogs√• bla gjennom deres [Engineering-blogg](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) for flere innlegg som [dette](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) som viser hvordan disse modellene og teknikkene _brukes_ for √• drive reelle applikasjoner.

---

<!--
LEKSJONSMAL:
Denne enheten skal dekke kjernebegrep #2.
Styrk begrepet med eksempler og referanser.

KONSEPT #2:
Promptdesign.
Illustrert med eksempler.
-->

## Oppbygging av promter

Vi har sett hvorfor prompt engineering er viktig ‚Äì n√• skal vi forst√• hvordan promter _bygges opp_ slik at vi kan vurdere ulike teknikker for mer effektiv promptdesign.

### Enkel prompt

La oss starte med den enkle prompten: et tekstinnspill sendt til modellen uten annen kontekst. Her er et eksempel ‚Äì n√•r vi sender de f√∏rste ordene fra USAs nasjonalsang til OpenAI [Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) fullf√∏rer den straks svaret med de neste linjene, og illustrerer den grunnleggende prediksjonsatferden.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Det h√∏res ut som du begynner p√• teksten til "The Star-Spangled Banner", USAs nasjonalsang. Hele teksten er ... |

### Kompleks prompt

N√• legger vi til kontekst og instruksjoner til den enkle prompten. [Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) lar oss bygge en kompleks prompt som en samling _meldinger_ med:

- Input/output-par som gjenspeiler _brukerens_ innspill og _assistentens_ svar.
- Systemmelding som setter konteksten for assistentens oppf√∏rsel eller personlighet.

Foresp√∏rselen ser n√• ut som under, der _tokeniseringen_ effektivt fanger relevant informasjon fra kontekst og samtale. √Ö endre systemkonteksten kan n√• ha like stor innvirkning p√• kvaliteten p√• svarene som brukerens innspill.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Who won the world series in 2020?"},
        {"role": "assistant", "content": "The Los Angeles Dodgers won the World Series in 2020."},
        {"role": "user", "content": "Where was it played?"}
    ]
)
```

### Instruksjonsprompt

I eksemplene over var brukerens prompt et enkelt tekstsp√∏rsm√•l som kan tolkes som en foresp√∏rsel om informasjon. Med _instruksjonspromter_ kan vi bruke teksten til √• spesifisere en oppgave mer detaljert, og gi bedre veiledning til AI-en. Her er et eksempel:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruction Type    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Skriv en beskrivelse av den amerikanske borgerkrigen                                                                                                                                                                                   | _returnerte et enkelt avsnitt_                                                                                             | Enkel               |
| Skriv en beskrivelse av den amerikanske borgerkrigen. Oppgi viktige datoer og hendelser og beskriv deres betydning                                                                                                                     | _returnerte et avsnitt etterfulgt av en liste med viktige datoer og beskrivelser_                                          | Kompleks            |
| Skriv en beskrivelse av den amerikanske borgerkrigen i ett avsnitt. Oppgi 3 punkter med viktige datoer og deres betydning. Oppgi 3 punkter med sentrale historiske personer og deres bidrag. Returner svaret som en JSON-fil            | _returnerer mer omfattende detaljer i en tekstboks, formatert som JSON som du kan kopiere til en fil og validere ved behov_ | Kompleks. Formatert. |

## Prim√¶rt innhold

I eksemplene over var prompten fortsatt ganske √•pen, og lot LLM-en bestemme hvilken del av det forh√•ndstrente datasettet som var relevant. Med _prim√¶rt innhold_-m√∏nsteret deles innholdet i to deler:

- en instruksjon (handling)
- relevant innhold (som p√•virker handlingen)

Her er et eksempel der instruksjonen er "oppsummer dette i 2 setninger".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene til sammen. Jupiter er et av de klareste objektene synlig for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid. Den er oppkalt etter den romerske guden Jupiter.[19] Sett fra jorden kan Jupiter v√¶re s√• lyssterk at det reflekterte lyset kaster synlige skygger,[20] og er i snitt det tredje klareste naturlige objektet p√• nattehimmelen etter m√•nen og Venus. <br/> **Oppsummer dette i 2 korte setninger** | Jupiter, den femte planeten fra solen, er den st√∏rste i solsystemet og kjent for √• v√¶re et av de klareste objektene p√• nattehimmelen. Oppkalt etter den romerske guden Jupiter, er den en gasskjempe med en masse som er to og en halv ganger s√• stor som alle de andre planetene til sammen. |

Segmentet med prim√¶rt innhold kan brukes p√• ulike m√•ter for √• gi mer effektive instruksjoner:

- **Eksempler** ‚Äì i stedet for √• fortelle modellen hva den skal gj√∏re med en eksplisitt instruksjon, gir du den eksempler p√• √∏nsket utdata og lar den utlede m√∏nsteret.
- **Cues** ‚Äì f√∏lg instruksjonen med et "hint" som gir modellen et startpunkt, og leder den mot mer relevante svar.
- **Maler** ‚Äì dette er repeterbare 'oppskrifter' for promter med plassholdere (variabler) som kan tilpasses med data for spesifikke bruksomr√•der.

La oss se n√¶rmere p√• disse i praksis.

### Bruk av eksempler

Dette er en metode der du bruker prim√¶rt innhold til √• "mate modellen" med noen eksempler p√• √∏nsket utdata for en gitt instruksjon, og lar den utlede m√∏nsteret for √∏nsket utdata. Avhengig av antall eksempler kan vi ha zero-shot prompting, one-shot prompting, few-shot prompting osv.

Prompten best√•r n√• av tre komponenter:

- En oppgavebeskrivelse
- Noen eksempler p√• √∏nsket utdata
- Starten p√• et nytt eksempel (som blir en implisitt oppgavebeskrivelse)

| L√¶ringstype | Prompt (Input)                                                                                                                                        | Completion (Output)         |
| :---------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot   | "The Sun is Shining". Oversett til spansk                                                                                                             | "El Sol est√° brillando".    |
| One-shot    | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot    | Spilleren l√∏p basene => Baseball <br/> Spilleren slo et ess => Tennis <br/> Spilleren slo en sekser => Cricket <br/> Spilleren gjorde en slam-dunk => | Basketball                  |
|             |                                                                                                                                                       |                             |

Legg merke til at vi m√•tte gi eksplisitt instruksjon ("Oversett til spansk") i zero-shot prompting, men at det blir utledet i one-shot eksempelet. Few-shot eksempelet viser hvordan flere eksempler gir modellen mulighet til √• gj√∏re mer presise slutninger uten ekstra instruksjoner.

### Prompt-hint

En annen teknikk for √• bruke prim√¶rt innhold er √• gi _hint_ i stedet for eksempler. Her gir vi modellen et lite dytt i riktig retning ved √• _starte_ med et utdrag som gjenspeiler √∏nsket svarformat. Modellen "tar hintet" og fortsetter i samme stil.

| Antall hint | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :---------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0           | Jupiter er den femte planeten fra solen og den st√∏rste i solsystemet. Den er en gasskjempe med en masse som er en tusendel av solens, men to og en halv ganger s√• stor som alle de andre planetene til sammen. Jupiter er et av de klareste objektene synlig for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historisk tid.

**Oppsummer Dette**                                       | Jupiter er den st√∏rste planeten i v√•rt solsystem og den femte fra sola. Det er en gasskjempe med en masse p√• 1/1000 av solas, men den er tyngre enn alle de andre planetene til sammen. Gamle sivilisasjoner har kjent til Jupiter i lang tid, og den er lett synlig p√• nattehimmelen. |
| 1              | Jupiter er den femte planeten fra sola og den st√∏rste i solsystemet. Det er en gasskjempe med en masse som er en tusendel av solas, men to og en halv ganger s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de klareste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historien ble skrevet. <br/>**Oppsummer Dette** <br/> Det vi l√¶rte er at Jupiter | er den femte planeten fra sola og den st√∏rste i solsystemet. Det er en gasskjempe med en masse som er en tusendel av solas, men to og en halv ganger s√• stor som alle de andre planetene til sammen. Den er lett synlig for det blotte √∏ye og har v√¶rt kjent siden oldtiden.                        |
| 2              | Jupiter er den femte planeten fra sola og den st√∏rste i solsystemet. Det er en gasskjempe med en masse som er en tusendel av solas, men to og en halv ganger s√• stor som alle de andre planetene i solsystemet til sammen. Jupiter er et av de klareste objektene som er synlige for det blotte √∏ye p√• nattehimmelen, og har v√¶rt kjent for gamle sivilisasjoner siden f√∏r historien ble skrevet. <br/>**Oppsummer Dette** <br/> Topp 3 fakta vi l√¶rte:         | 1. Jupiter er den femte planeten fra sola og den st√∏rste i solsystemet. <br/> 2. Det er en gasskjempe med en masse som er en tusendel av solas...<br/> 3. Jupiter har v√¶rt synlig for det blotte √∏ye siden oldtiden ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

### Promptmaler

En promptmal er en _forh√•ndsdefinert oppskrift p√• en prompt_ som kan lagres og gjenbrukes etter behov, for √• skape mer konsistente brukeropplevelser i stor skala. I sin enkleste form er det bare en samling av prompteksempler som [dette fra OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) som gir b√•de de interaktive promptkomponentene (bruker- og systemmeldinger) og det API-drevne foresp√∏rselsformatet ‚Äì for √• st√∏tte gjenbruk.

I en mer avansert form, som [dette eksempelet fra LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), inneholder den _plassholdere_ som kan erstattes med data fra ulike kilder (brukerinndata, systemkontekst, eksterne datakilder osv.) for √• generere en prompt dynamisk. Dette lar oss lage et bibliotek av gjenbrukbare prompts som kan brukes til √• skape konsistente brukeropplevelser **programmatisk** i stor skala.

Den virkelige verdien av maler ligger til slutt i muligheten til √• lage og publisere _promptbiblioteker_ for spesifikke bruksomr√•der ‚Äì der promptmalen n√• er _optimalisert_ for √• reflektere applikasjonsspesifikk kontekst eller eksempler som gj√∏r svarene mer relevante og presise for den tiltenkte brukergruppen. [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) er et godt eksempel p√• denne tiln√¶rmingen, og samler et bibliotek av prompts for utdanningssektoren med vekt p√• n√∏kkelm√•l som leksjonsplanlegging, l√¶replanutforming, elevveiledning osv.

## St√∏tteinnhold

Hvis vi ser p√• promptkonstruksjon som √• ha en instruksjon (oppgave) og et m√•l (hovedinnhold), s√• er _sekund√¶rt innhold_ som ekstra kontekst vi gir for √• **p√•virke svaret p√• en eller annen m√•te**. Det kan v√¶re justeringsparametere, formateringsinstruksjoner, tematiske taksonomier osv. som kan hjelpe modellen √• _tilpasse_ svaret sitt slik at det passer brukerens m√•l eller forventninger.

For eksempel: Gitt en emnekatalog med omfattende metadata (navn, beskrivelse, niv√•, metadatamerker, instrukt√∏r osv.) p√• alle tilgjengelige kurs i l√¶replanen:

- vi kan definere en instruksjon om √• "oppsummere emnekatalogen for h√∏sten 2023"
- vi kan bruke hovedinnholdet til √• gi noen eksempler p√• √∏nsket utdata
- vi kan bruke sekund√¶rt innhold til √• identifisere de 5 viktigste "taggene" av interesse.

N√• kan modellen gi en oppsummering i formatet vist av eksemplene ‚Äì men hvis et resultat har flere tagger, kan den prioritere de 5 som er identifisert i sekund√¶rt innhold.

---

<!--
LEKSJONSMAL:
Denne enheten b√∏r dekke kjernebegrep #1.
Forsterk begrepet med eksempler og referanser.

BEGREP #3:
Prompt Engineering-teknikker.
Hva er noen grunnleggende teknikker for prompt engineering?
Illustrer med noen √∏velser.
-->

## Beste praksis for prompting

N√• som vi vet hvordan prompts kan _bygges opp_, kan vi begynne √• tenke p√• hvordan vi kan _designe_ dem for √• f√∏lge beste praksis. Vi kan se p√• dette i to deler ‚Äì √• ha riktig _tankesett_ og bruke riktige _teknikker_.

### Tankesett for Prompt Engineering

Prompt Engineering er en pr√∏ving-og-feiling-prosess, s√• husk tre brede retningslinjer:

1. **Domeneinnsikt er viktig.** Svarets n√∏yaktighet og relevans avhenger av _domenet_ applikasjonen eller brukeren opererer i. Bruk din intuisjon og fagkunnskap til √• **tilpasse teknikker** ytterligere. For eksempel, definer _domene-spesifikke personligheter_ i systemprompts, eller bruk _domene-spesifikke maler_ i brukerprompts. Gi sekund√¶rt innhold som reflekterer domene-spesifikk kontekst, eller bruk _domene-spesifikke signaler og eksempler_ for √• veilede modellen mot kjente bruksm√∏nstre.

2. **Forst√•else av modellen er viktig.** Vi vet at modeller er stokastiske av natur. Men modellimplementasjoner kan ogs√• variere n√•r det gjelder treningsdatasettet de bruker (forh√•ndstrent kunnskap), hvilke muligheter de gir (f.eks. via API eller SDK) og hvilken type innhold de er optimalisert for (f.eks. kode vs. bilder vs. tekst). Forst√• styrker og begrensninger ved modellen du bruker, og bruk den kunnskapen til √• _prioritere oppgaver_ eller bygge _tilpassede maler_ som er optimalisert for modellens egenskaper.

3. **Iterasjon og validering er viktig.** Modeller utvikler seg raskt, og det gj√∏r ogs√• teknikkene for prompt engineering. Som fagekspert har du kanskje annen kontekst eller kriterier for _din_ spesifikke applikasjon, som ikke gjelder for resten av milj√∏et. Bruk verkt√∏y og teknikker for prompt engineering for √• "kickstarte" promptkonstruksjon, og iterer og valider resultatene med din egen intuisjon og fagkunnskap. Noter innsiktene dine og lag en **kunnskapsbase** (f.eks. promptbiblioteker) som andre kan bruke som et nytt utgangspunkt for raskere iterasjoner i fremtiden.

## Beste praksis

La oss se p√• vanlige beste praksiser som anbefales av [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) og [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Hva                              | Hvorfor                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evaluer de nyeste modellene.       | Nye modellgenerasjoner har sannsynligvis bedre funksjoner og kvalitet ‚Äì men kan ogs√• koste mer. Vurder effekten, og ta deretter en beslutning om √• bytte.                                                                                |
| Skill instruksjoner og kontekst   | Sjekk om modellen/leverand√∏ren din definerer _avgrensere_ for √• skille instruksjoner, hoved- og sekund√¶rinnhold tydeligere. Dette kan hjelpe modeller √• tildele vekt mer n√∏yaktig til tokens.                                                         |
| V√¶r spesifikk og tydelig             | Gi flere detaljer om √∏nsket kontekst, resultat, lengde, format, stil osv. Dette vil forbedre b√•de kvaliteten og konsistensen p√• svarene. Ta vare p√• oppskrifter i gjenbrukbare maler.                                                          |
| V√¶r beskrivende, bruk eksempler      | Modeller kan svare bedre p√• en "vis og fortell"-tiln√¶rming. Start med en `zero-shot`-tiln√¶rming der du gir en instruksjon (men ingen eksempler), og pr√∏v deretter `few-shot` som en forbedring, med noen eksempler p√• √∏nsket utdata. Bruk analogier. |
| Bruk signaler for √• starte svar | Dytt modellen mot √∏nsket resultat ved √• gi noen ledende ord eller fraser som den kan bruke som utgangspunkt for svaret.                                                                                                               |
| Gjenta instruksjoner                       | Noen ganger m√• du kanskje gjenta deg selv for modellen. Gi instruksjoner b√•de f√∏r og etter hovedinnholdet, bruk en instruksjon og et signal, osv. Iterer og valider for √• se hva som fungerer.                                                         |
| Rekkef√∏lge har betydning                     | Rekkef√∏lgen du presenterer informasjon til modellen i, kan p√•virke svaret, ogs√• i eksemplene, p√• grunn av "recency bias". Pr√∏v ulike alternativer for √• se hva som fungerer best.                                                               |
| Gi modellen en ‚Äúutvei‚Äù           | Gi modellen et _fallback_-svar den kan bruke hvis den ikke kan fullf√∏re oppgaven. Dette kan redusere sjansen for at modellen genererer feilaktige eller oppdiktede svar.                                                         |
|                                   |                                                                                                                                                                                                                                                   |

Som med all beste praksis, husk at _dine erfaringer kan variere_ avhengig av modell, oppgave og domene. Bruk dette som et utgangspunkt, og iterer for √• finne det som fungerer best for deg. Evaluer prompt engineering-prosessen din jevnlig etter hvert som nye modeller og verkt√∏y blir tilgjengelige, med fokus p√• skalerbarhet og kvalitet p√• svarene.

<!--
LEKSJONSMAL:
Denne enheten b√∏r gi en kodeutfordring hvis aktuelt

UTFORDRING:
Lenke til en Jupyter Notebook med kun kodekommentarer i instruksjonene (kodene er tomme).

L√òSNING:
Lenke til en kopi av den Notebooken med prompts fylt ut og kj√∏rt, som viser et eksempel p√• l√∏sning.
-->

## Oppgave

Gratulerer! Du har kommet til slutten av leksjonen! N√• er det p√• tide √• teste ut noen av konseptene og teknikkene med ekte eksempler!

I denne oppgaven bruker vi en Jupyter Notebook med √∏velser du kan l√∏se interaktivt. Du kan ogs√• utvide Notebooken med egne Markdown- og kodeceller for √• utforske ideer og teknikker p√• egenh√•nd.

### For √• komme i gang, lag en fork av repoet, og deretter

- (Anbefalt) Start GitHub Codespaces
- (Alternativt) Klon repoet til din lokale enhet og bruk det med Docker Desktop
- (Alternativt) √Öpne Notebooken med ditt foretrukne Notebook-milj√∏.

### Deretter, konfigurer milj√∏variablene dine

- Kopier `.env.copy`-filen i rotmappen til `.env` og fyll inn verdiene for `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` og `AZURE_OPENAI_DEPLOYMENT`. G√• tilbake til [Learning Sandbox-delen](../../../04-prompt-engineering-fundamentals/04-prompt-engineering-fundamentals) for √• l√¶re hvordan.

### Deretter, √•pne Jupyter Notebooken

- Velg runtime-kjernen. Hvis du bruker alternativ 1 eller 2, velg bare standard Python 3.10.x-kjernen som f√∏lger med dev-containeren.

N√• er du klar til √• kj√∏re √∏velsene. Merk at det ikke finnes _riktige eller gale_ svar her ‚Äì det handler om √• utforske alternativer gjennom pr√∏ving og feiling og bygge opp intuisjon for hva som fungerer for en gitt modell og applikasjonsdomene.

_Derfor er det ingen kodefasit-segmenter i denne leksjonen. I stedet vil Notebooken ha Markdown-celler med tittelen "Min l√∏sning:" som viser ett eksempel p√• utdata til referanse._

 <!--
LEKSJONSMAL:
Avslutt seksjonen med en oppsummering og ressurser for selvstudium.
-->

## Kunnskapssjekk

Hvilken av f√∏lgende er en god prompt som f√∏lger noen fornuftige beste praksiser?

1. Vis meg et bilde av en r√∏d bil
2. Vis meg et bilde av en r√∏d bil av merket Volvo og modellen XC90 parkert ved en klippe med solnedgang
3. Vis meg et bilde av en r√∏d bil av merket Volvo og modellen XC90

A: 2, det er den beste prompten fordi den gir detaljer om "hva" og g√•r i dybden (ikke bare hvilken som helst bil, men et spesifikt merke og modell) og den beskriver ogs√• omgivelsene. 3 er nest best fordi den ogs√• inneholder mye beskrivelse.

## üöÄ Utfordring

Se om du kan bruke "signal"-teknikken med prompten: Fullf√∏r setningen "Vis meg et bilde av en r√∏d bil av merket Volvo og ". Hva svarer den, og hvordan ville du forbedret det?

## Flott jobbet! Fortsett l√¶ringen din

Vil du l√¶re mer om ulike konsepter innen Prompt Engineering? G√• til [videre l√¶ring-siden](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for √• finne flere gode ressurser om dette emnet.

G√• videre til leksjon 5 hvor vi ser p√• [avanserte prompting-teknikker](../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!

---

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi tilstreber n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiserte oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• sitt opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.