[![Open Source Models](../../../translated_images/no/18-lesson-banner.f30176815b1a5074.webp)](https://youtu.be/6UAwhL9Q-TQ?si=5jJd8yeQsCfJ97em)

# Finjustering av din LLM

Bruk av store spr√•kmodeller for √• bygge generative AI-applikasjoner kommer med nye utfordringer. Et sentralt sp√∏rsm√•l er √• sikre responskvalitet (n√∏yaktighet og relevans) i innhold generert av modellen for en gitt brukerforesp√∏rsel. I tidligere leksjoner har vi diskutert teknikker som prompt-engineering og hentetilleggsgenerering som pr√∏ver √• l√∏se problemet ved √• _endre prompt-inputen_ til den eksisterende modellen.

I dagens leksjon diskuterer vi en tredje teknikk, **finjustering**, som pr√∏ver √• m√∏te utfordringen ved √• _omtrentrene modellen selv_ med tillegg av data. La oss dykke inn i detaljene.

## L√¶ringsm√•l

Denne leksjonen introduserer konseptet finjustering for forh√•ndstrente spr√•kmodeller, utforsker fordelene og utfordringene ved denne tiln√¶rmingen, og gir veiledning om n√•r og hvordan man kan bruke finjustering for √• forbedre ytelsen til dine generative AI-modeller.

Etter denne leksjonen skal du kunne svare p√• f√∏lgende sp√∏rsm√•l:

- Hva er finjustering for spr√•kmodeller?
- N√•r, og hvorfor, er finjustering nyttig?
- Hvordan kan jeg finjustere en forh√•ndstrent modell?
- Hva er begrensningene ved finjustering?

Klar? La oss komme i gang.

## Illustrert guide

Vil du f√• oversikten over hva vi skal dekke f√∏r vi dykker ned? Sjekk ut denne illustrerte guiden som beskriver l√¶reprosessen for denne leksjonen ‚Äì fra √• l√¶re kjernebegrepene og motivasjonen for finjustering, til √• forst√• prosessen og beste praksis for √• utf√∏re finjusteringsoppgaven. Dette er et fascinerende tema for utforskning, s√• ikke glem √• sjekke [Ressurser](./RESOURCES.md?WT.mc_id=academic-105485-koreyst)-siden for flere lenker som st√∏tter din selvstyrte l√¶ringsreise!

![Illustrert guide til finjustering av spr√•kmodeller](../../../translated_images/no/18-fine-tuning-sketchnote.11b21f9ec8a70346.webp)

## Hva er finjustering for spr√•kmodeller?

Per definisjon er store spr√•kmodeller _forh√•ndstrent_ p√• store mengder tekst hentet fra ulike kilder inkludert internett. Som vi har l√¶rt i tidligere leksjoner, trenger vi teknikker som _prompt engineering_ og _retrieval-augmented generation_ for √• forbedre kvaliteten p√• modellens svar til brukerens sp√∏rsm√•l ("prompts").

En popul√¶r prompt-engineeringsteknikk inneb√¶rer √• gi modellen mer veiledning om hva som forventes i svaret enten ved √• gi _instruksjoner_ (eksplisitt veiledning) eller _gi den noen f√• eksempler_ (implisitt veiledning). Dette kalles _few-shot learning_, men det har to begrensninger:

- Modellens token-begrensninger kan begrense antallet eksempler du kan gi, og dermed begrense effektiviteten.
- Kostnaden for modell-token kan gj√∏re det dyrt √• legge til eksempler i hver prompt, og begrense fleksibiliteten.

Finjustering er en vanlig praksis i maskinl√¶ringssystemer hvor man tar en forh√•ndstrent modell og trener den p√• nytt med nye data for √• forbedre ytelsen p√• en spesifikk oppgave. I konteksten av spr√•kmodeller kan vi finjustere den forh√•ndstrente modellen _med et kuratert sett av eksempler for en gitt oppgave eller anvendelsesomr√•de_ for √• lage en **tilpasset modell** som kan v√¶re mer n√∏yaktig og relevant for akkurat den oppgaven eller domenet. En ekstra fordel med finjustering er at det ogs√• kan redusere antallet eksempler som trengs til few-shot learning ‚Äì noe som reduserer token-bruk og relaterte kostnader.

## N√•r og hvorfor b√∏r vi finjustere modeller?

I _denne_ konteksten, n√•r vi snakker om finjustering, refererer vi til **overv√•ket** finjustering hvor ny trening utf√∏res ved √• **legge til nye data** som ikke var en del av det opprinnelige treningssettet. Dette skiller seg fra en uoverv√•ket finjusteringsmetode hvor modellen trenes p√• nytt med originaldata, men med forskjellige hyperparametere.

Det viktigste √• huske er at finjustering er en avansert teknikk som krever et visst niv√• av ekspertise for √• oppn√• √∏nskede resultater. Utf√∏res det feil, kan det hende du ikke f√•r de forventede forbedringene, og det kan til og med forringe ytelsen til modellen for ditt m√•lrettede domene.

S√• f√∏r du l√¶rer "hvordan" du finjusterer spr√•kmodeller, m√• du vite "hvorfor" du skal ta denne ruten, og "n√•r" du skal starte prosessen med finjustering. Begynn med √• stille deg selv disse sp√∏rsm√•lene:

- **Brukstilfelle**: Hva er ditt _brukstilfelle_ for finjustering? Hvilket aspekt ved den n√•v√¶rende forh√•ndstrente modellen √∏nsker du √• forbedre?
- **Alternativer**: Har du pr√∏vd _andre teknikker_ for √• oppn√• √∏nskede resultater? Bruk dem til √• lage en referanseverdi for sammenligning.
  - Prompt engineering: Pr√∏v teknikker som few-shot prompting med eksempler p√• relevante prompt-svar. Evaluer kvaliteten p√• svarene.
  - Hentetilleggsgenerering: Pr√∏v √• styrke promptene med sp√∏rringsresultater hentet ved √• s√∏ke i dine data. Evaluer kvaliteten p√• svarene.
- **Kostnader**: Har du identifisert kostnadene for finjustering?
  - Justerbarhet ‚Äì er den forh√•ndstrente modellen tilgjengelig for finjustering?
  - Innsats ‚Äì for √• forberede treningsdata, evaluere og forbedre modellen.
  - Regnekraft ‚Äì for √• kj√∏re finjusteringsjobber og distribuere den finjusterte modellen.
  - Data ‚Äì tilgang til eksempler av tilstrekkelig kvalitet for finjusteringseffekt.
- **Fordeler**: Har du bekreftet fordelene ved finjustering?
  - Kvalitet ‚Äì overgikk den finjusterte modellen baseline?
  - Kostnad ‚Äì reduserer den token-bruken ved √• forenkle prompts?
  - Utvidbarhet ‚Äì kan du bruke grunnmodellen for nye domener?

Ved √• svare p√• disse sp√∏rsm√•lene, b√∏r du kunne avgj√∏re om finjustering er riktig tiln√¶rming for ditt brukstilfelle. Ideelt sett er tiln√¶rmingen gyldig bare hvis fordelene oppveier kostnadene. N√•r du bestemmer deg for √• g√• videre, er det p√• tide √• tenke p√• _hvordan_ du kan finjustere den forh√•ndstrente modellen.

Vil du ha flere innsikter i beslutningsprosessen? Se [To fine-tune or not to fine-tune](https://www.youtube.com/watch?v=0Jo-z-MFxJs)

## Hvordan kan vi finjustere en forh√•ndstrent modell?

For √• finjustere en forh√•ndstrent modell trenger du:

- en forh√•ndstrent modell √• finjustere
- et datasett til bruk for finjustering
- et treningsmilj√∏ for √• kj√∏re finjusteringsjobben
- et hostingmilj√∏ for √• distribuere den finjusterte modellen

## Finjustering i praksis

F√∏lgende ressurser gir trinnvise veiledninger for √• g√• gjennom et ekte eksempel med en valgt modell og et kuratert datasett. For √• jobbe deg gjennom disse veiledningene, trenger du en konto hos den aktuelle leverand√∏ren, samt tilgang til den relevante modellen og datasettene.

| Leverand√∏r   | Veiledning                                                                                                                                                                    | Beskrivelse                                                                                                                                                                                                                                                                                                                                                                                                                        |
| ------------ | ----------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| OpenAI       | [Hvordan finjustere chat-modeller](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst)            | L√¶r √• finjustere en `gpt-35-turbo` for et spesifikt domene ("oppskriftsassistent") ved √• forberede treningsdata, kj√∏re finjusteringsjobben, og bruke den finjusterte modellen for inferens.                                                                                                                                                                                                                                      |
| Azure OpenAI | [GPT 3.5 Turbo finjusteringsveiledning](https://learn.microsoft.com/azure/ai-services/openai/tutorials/fine-tune?tabs=python-new%2Ccommand-line?WT.mc_id=academic-105485-koreyst) | L√¶r √• finjustere en `gpt-35-turbo-0613` modell **p√• Azure** ved √• ta steg for √• lage og laste opp treningsdata, kj√∏re finjusteringsjobben. Distribuer og bruk den nye modellen.                                                                                                                                                                                                                                                      |
| Hugging Face | [Finjustering av LLMs med Hugging Face](https://www.philschmid.de/fine-tune-llms-in-2024-with-trl?WT.mc_id=academic-105485-koreyst)                                             | Dette blogginnlegget veileder deg gjennom finjustering av en _√•pen LLM_ (for eksempel `CodeLlama 7B`) ved hjelp av [transformers](https://huggingface.co/docs/transformers/index?WT.mc_id=academic-105485-koreyst) biblioteket og [Transformer Reinforcement Learning (TRL)](https://huggingface.co/docs/trl/index?WT.mc_id=academic-105485-koreyst) med √•pne [datasett](https://huggingface.co/docs/datasets/index?WT.mc_id=academic-105485-koreyst) p√• Hugging Face. |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ü§ó AutoTrain | [Finjustering av LLMs med AutoTrain](https://github.com/huggingface/autotrain-advanced/?WT.mc_id=academic-105485-koreyst)                                                     | AutoTrain (eller AutoTrain Advanced) er et python-bibliotek utviklet av Hugging Face som lar deg finjustere mange ulike oppgaver, inkludert LLM-fintuning. AutoTrain er en l√∏sning uten kode og finjustering kan gj√∏res i din egen sky, p√• Hugging Face Spaces eller lokalt. Den st√∏tter b√•de et web-basert GUI, CLI og trening via yaml-konfigurasjonsfiler.                                                                                      |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
| ü¶• Unsloth   | [Finjustering av LLMs med Unsloth](https://github.com/unslothai/unsloth)                                                                                                      | Unsloth er et open-source rammeverk som st√∏tter LLM-fintuning og forsterkende l√¶ring (RL). Unsloth forenkler lokal trening, evaluering og distribusjon med ferdige [notebooks](https://github.com/unslothai/notebooks). Den st√∏tter ogs√• tekst-til-tale (TTS), BERT og multimodale modeller. For √• komme i gang, les deres trinnvise [Finjustering av LLMs-guide](https://docs.unsloth.ai/get-started/fine-tuning-llms-guide).                                        |
|              |                                                                                                                                                                               |                                                                                                                                                                                                                                                                                                                                                                                                                                  |
## Oppgave

Velg en av veiledningene ovenfor og g√• gjennom dem. _Vi kan eventuelt lage en versjon av disse veiledningene i Jupyter Notebooks i dette repoet for referanse. Vennligst bruk de originale kildene direkte for √• f√• de nyeste versjonene_.

## Flott jobb! Fortsett l√¶ringen din.

Etter √• ha fullf√∏rt denne leksjonen, sjekk ut v√•r [Generative AI Learning-samling](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for √• fortsette √• √∏ke kunnskapen din om generativ AI!

Gratulerer!! Du har fullf√∏rt siste leksjon i v2-serien for dette kurset! Ikke slutt √• l√¶re og bygge. \*\*Sjekk ut [RESSURSER](RESOURCES.md?WT.mc_id=academic-105485-koreyst)-siden for en liste over flere forslag kun for dette temaet.

V√•r v1-serie av leksjoner er ogs√• oppdatert med flere oppgaver og konsepter. S√• ta et minutt til √• friske opp kunnskapen din ‚Äì og vennligst [del dine sp√∏rsm√•l og tilbakemeldinger](https://github.com/microsoft/generative-ai-for-beginners/issues?WT.mc_id=academic-105485-koreyst) for √• hjelpe oss med √• forbedre disse leksjonene for fellesskapet.

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**Ansvarsfraskrivelse**:
Dette dokumentet er oversatt ved bruk av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n√∏yaktighet, vennligst v√¶r oppmerksom p√• at automatiske oversettelser kan inneholde feil eller un√∏yaktigheter. Det originale dokumentet p√• dets opprinnelige spr√•k b√∏r anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst√•elser eller feiltolkninger som oppst√•r ved bruk av denne oversettelsen.
<!-- CO-OP TRANSLATOR DISCLAIMER END -->