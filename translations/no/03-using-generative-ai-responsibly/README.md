<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "7f8f4c11f8c1cb6e1794442dead414ea",
  "translation_date": "2025-07-09T08:58:01+00:00",
  "source_file": "03-using-generative-ai-responsibly/README.md",
  "language_code": "no"
}
-->
# Bruke Generativ AI Ansvarlig

[![Using Generative AI Responsibly](../../../translated_images/03-lesson-banner.1ed56067a452d97709d51f6cc8b6953918b2287132f4909ade2008c936cd4af9.no.png)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Klikk p친 bildet over for 친 se videoen til denne leksjonen_

Det er lett 친 bli fascinert av AI, og spesielt generativ AI, men du m친 tenke p친 hvordan du bruker det p친 en ansvarlig m친te. Du m친 vurdere ting som hvordan sikre at resultatene er rettferdige, ikke skadelige og mer. Dette kapitlet har som m친l 친 gi deg den n칮dvendige konteksten, hva du b칮r tenke p친, og hvordan du kan ta aktive steg for 친 forbedre bruken av AI.

## Introduksjon

Denne leksjonen vil dekke:

- Hvorfor du b칮r prioritere Ansvarlig AI n친r du bygger generative AI-applikasjoner.
- Kjerneprinsippene for Ansvarlig AI og hvordan de relaterer seg til generativ AI.
- Hvordan sette disse prinsippene for Ansvarlig AI ut i praksis gjennom strategi og verkt칮y.

## L칝ringsm친l

Etter 친 ha fullf칮rt denne leksjonen vil du vite:

- Hvor viktig Ansvarlig AI er n친r du bygger generative AI-applikasjoner.
- N친r du b칮r tenke p친 og anvende kjerneprinsippene for Ansvarlig AI i utviklingen av generative AI-applikasjoner.
- Hvilke verkt칮y og strategier som er tilgjengelige for 친 sette konseptet Ansvarlig AI ut i praksis.

## Prinsipper for Ansvarlig AI

Spenningsniv친et rundt generativ AI har aldri v칝rt h칮yere. Denne entusiasmen har tiltrukket mange nye utviklere, oppmerksomhet og finansiering til dette feltet. Selv om dette er veldig positivt for alle som 칮nsker 친 bygge produkter og selskaper med generativ AI, er det ogs친 viktig at vi g친r frem p친 en ansvarlig m친te.

Gjennom dette kurset fokuserer vi p친 친 bygge v친r startup og v친rt AI-utdanningsprodukt. Vi vil bruke prinsippene for Ansvarlig AI: Rettferdighet, Inkludering, P친litelighet/Sikkerhet, Sikkerhet & Personvern, 칀penhet og Ansvarlighet. Med disse prinsippene vil vi utforske hvordan de relaterer seg til v친r bruk av generativ AI i produktene v친re.

## Hvorfor b칮r du prioritere Ansvarlig AI

N친r du bygger et produkt, gir en menneskesentrert tiln칝rming med brukerens beste i tankene de beste resultatene.

Det unike med generativ AI er dens evne til 친 skape nyttige svar, informasjon, veiledning og innhold for brukerne. Dette kan gj칮res uten mange manuelle steg, noe som kan gi sv칝rt imponerende resultater. Uten riktig planlegging og strategier kan det dessverre ogs친 f칮re til skadelige resultater for brukerne dine, produktet ditt og samfunnet som helhet.

La oss se p친 noen (men ikke alle) av disse potensielt skadelige resultatene:

### Hallusinasjoner

Hallusinasjoner er et begrep som brukes for 친 beskrive n친r en LLM produserer innhold som enten er helt meningsl칮st eller noe vi vet er faktuelt feil basert p친 andre informasjonskilder.

La oss for eksempel si at vi bygger en funksjon for v친r startup som lar studenter stille historiske sp칮rsm친l til en modell. En student sp칮r: `Hvem var den eneste overlevende fra Titanic?`

Modellen gir et svar som dette:

![Prompt saying "Who was the sole survivor of the Titanic"](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp)

> _(Kilde: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Dette er et veldig selvsikkert og grundig svar. Dessverre er det feil. Selv med en minimal mengde research ville man oppdaget at det var mer enn 칠n overlevende fra Titanic-ulykken. For en student som nettopp har begynt 친 unders칮ke dette emnet, kan dette svaret v칝re overbevisende nok til at det ikke blir stilt sp칮rsm친l ved og behandlet som fakta. Konsekvensene av dette kan f칮re til at AI-systemet oppfattes som up친litelig og skade omd칮mmet til v친r startup.

Med hver iterasjon av en gitt LLM har vi sett forbedringer i 친 minimere hallusinasjoner. Selv med denne forbedringen m친 vi som applikasjonsutviklere og brukere fortsatt v칝re bevisste p친 disse begrensningene.

### Skadelig innhold

Vi dekket i forrige seksjon n친r en LLM produserer feilaktige eller meningsl칮se svar. En annen risiko vi m친 v칝re oppmerksomme p친, er n친r en modell svarer med skadelig innhold.

Skadelig innhold kan defineres som:

- 칀 gi instruksjoner eller oppfordre til selvskading eller skade mot visse grupper.
- Hatefulle eller nedsettende ytringer.
- Veiledning i planlegging av angrep eller voldshandlinger.
- Instruksjoner om hvordan man finner ulovlig innhold eller beg친r ulovlige handlinger.
- Vise seksuelt eksplisitt innhold.

For v친r startup 칮nsker vi 친 sikre at vi har riktige verkt칮y og strategier p친 plass for 친 forhindre at denne typen innhold blir sett av studentene.

### Mangel p친 rettferdighet

Rettferdighet defineres som 춺친 sikre at et AI-system er fritt for skjevheter og diskriminering, og at det behandler alle rettferdig og likt.췉 I generativ AI-verdenen 칮nsker vi 친 sikre at ekskluderende verdenssyn p친 marginaliserte grupper ikke forsterkes av modellens output.

Denne typen output er ikke bare 칮deleggende for 친 bygge positive produktopplevelser for brukerne v친re, men de for친rsaker ogs친 ytterligere skade p친 samfunnet. Som applikasjonsutviklere b칮r vi alltid ha et bredt og mangfoldig brukergrunnlag i tankene n친r vi bygger l칮sninger med generativ AI.

## Hvordan bruke generativ AI ansvarlig

N친 som vi har identifisert viktigheten av Ansvarlig Generativ AI, la oss se p친 4 steg vi kan ta for 친 bygge AI-l칮sningene v친re p친 en ansvarlig m친te:

![Mitigate Cycle](../../../translated_images/mitigate-cycle.babcd5a5658e1775d5f2cb47f2ff305cca090400a72d98d0f9e57e9db5637c72.no.png)

### M친l potensielle skader

I programvaretesting tester vi forventede handlinger fra en bruker i en applikasjon. P친 samme m친te er det en god m친te 친 m친le potensiell skade p친 친 teste et variert sett med sp칮rsm친l brukerne mest sannsynlig vil stille.

Siden v친r startup bygger et utdanningsprodukt, vil det v칝re lurt 친 forberede en liste med utdanningsrelaterte sp칮rsm친l. Dette kan dekke et bestemt fag, historiske fakta og sp칮rsm친l om studentlivet.

### Reduser potensielle skader

N친 er det p친 tide 친 finne m친ter 친 forhindre eller begrense potensiell skade for친rsaket av modellen og dens svar. Vi kan se p친 dette i 4 forskjellige lag:

![Mitigation Layers](../../../translated_images/mitigation-layers.377215120b9a1159a8c3982c6bbcf41b6adf8c8fa04ce35cbaeeb13b4979cdfc.no.png)

- **Modell**. Velge riktig modell for riktig brukstilfelle. St칮rre og mer komplekse modeller som GPT-4 kan medf칮re st칮rre risiko for skadelig innhold n친r de brukes i mindre og mer spesifikke tilfeller. 칀 bruke treningsdata til finjustering reduserer ogs친 risikoen for skadelig innhold.

- **Sikkerhetssystem**. Et sikkerhetssystem er et sett med verkt칮y og konfigurasjoner p친 plattformen som betjener modellen, og som hjelper til med 친 redusere skade. Et eksempel p친 dette er innholdsfiltreringssystemet i Azure OpenAI-tjenesten. Systemer b칮r ogs친 oppdage jailbreak-angrep og u칮nsket aktivitet som foresp칮rsler fra roboter.

- **Metaprompt**. Metaprompter og grounding er m친ter vi kan styre eller begrense modellen basert p친 visse atferder og informasjon. Dette kan v칝re 친 bruke systeminput for 친 definere visse begrensninger for modellen. I tillegg kan det gi output som er mer relevant for systemets omfang eller domene.

Det kan ogs친 v칝re 친 bruke teknikker som Retrieval Augmented Generation (RAG) for at modellen kun henter informasjon fra et utvalg av p친litelige kilder. Det finnes en leksjon senere i dette kurset om [친 bygge s칮keapplikasjoner](../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Brukeropplevelse**. Det siste laget er der brukeren interagerer direkte med modellen gjennom applikasjonens grensesnitt p친 en eller annen m친te. P친 denne m친ten kan vi designe UI/UX for 친 begrense hvilke typer input brukeren kan sende til modellen, samt tekst eller bilder som vises til brukeren. N친r vi lanserer AI-applikasjonen, m친 vi ogs친 v칝re 친pne om hva v친r generative AI-applikasjon kan og ikke kan gj칮re.

Vi har en hel leksjon dedikert til [Design av UX for AI-applikasjoner](../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst).

- **Evaluer modellen**. 칀 jobbe med LLM-er kan v칝re utfordrende fordi vi ikke alltid har kontroll over dataene modellen er trent p친. Uansett b칮r vi alltid evaluere modellens ytelse og output. Det er fortsatt viktig 친 m친le modellens n칮yaktighet, likhet, forankring og relevans i output. Dette bidrar til 친 gi 친penhet og tillit til interessenter og brukere.

### Drift av en ansvarlig generativ AI-l칮sning

칀 bygge en operasjonell praksis rundt AI-applikasjonene dine er det siste steget. Dette inkluderer samarbeid med andre deler av v친r startup som juridisk avdeling og sikkerhet for 친 sikre at vi f칮lger alle regelverk. F칮r lansering 칮nsker vi ogs친 친 lage planer for levering, h친ndtering av hendelser og rollback for 친 forhindre at skade p친 brukerne eskalerer.

## Verkt칮y

Selv om arbeidet med 친 utvikle Ansvarlige AI-l칮sninger kan virke omfattende, er det vel verdt innsatsen. Etter hvert som generativ AI-omr친det vokser, vil flere verkt칮y som hjelper utviklere med 친 integrere ansvarlighet effektivt i arbeidsflyten, modnes. For eksempel kan [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hjelpe med 친 oppdage skadelig innhold og bilder via en API-foresp칮rsel.

## Kunnskapssjekk

Hva er noen ting du m친 ta hensyn til for 친 sikre ansvarlig bruk av AI?

1. At svaret er korrekt.  
1. Skadelig bruk, at AI ikke brukes til kriminelle form친l.  
1. Sikre at AI er fri for skjevheter og diskriminering.

A: 2 og 3 er riktige. Ansvarlig AI hjelper deg 친 vurdere hvordan du kan redusere skadelige effekter, skjevheter og mer.

## 游 Utfordring

Les om [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) og se hva du kan ta i bruk for din bruk.

## Flott jobba, fortsett l칝ringen din

Etter 친 ha fullf칮rt denne leksjonen, sjekk ut v친r [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) for 친 fortsette 친 utvikle kunnskapen din om generativ AI!

G친 videre til leksjon 4 hvor vi ser p친 [Grunnleggende om Prompt Engineering](../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst)!

**Ansvarsfraskrivelse**:  
Dette dokumentet er oversatt ved hjelp av AI-oversettelsestjenesten [Co-op Translator](https://github.com/Azure/co-op-translator). Selv om vi streber etter n칮yaktighet, vennligst v칝r oppmerksom p친 at automatiske oversettelser kan inneholde feil eller un칮yaktigheter. Det opprinnelige dokumentet p친 originalspr친ket skal anses som den autoritative kilden. For kritisk informasjon anbefales profesjonell menneskelig oversettelse. Vi er ikke ansvarlige for eventuelle misforst친elser eller feiltolkninger som oppst친r ved bruk av denne oversettelsen.