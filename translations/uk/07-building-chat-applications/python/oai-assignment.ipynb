{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Розділ 7: Створення чат-додатків\n",
    "## Швидкий старт з OpenAI API\n",
    "\n",
    "Цей ноутбук адаптовано з [репозиторію зразків Azure OpenAI](https://github.com/Azure/azure-openai-samples?WT.mc_id=academic-105485-koreyst), який містить ноутбуки для роботи з сервісами [Azure OpenAI](notebook-azure-openai.ipynb).\n",
    "\n",
    "Python OpenAI API також працює з моделями Azure OpenAI, але з деякими змінами. Дізнайтеся більше про відмінності тут: [Як перемикатися між OpenAI та Azure OpenAI endpoint у Python](https://learn.microsoft.com/azure/ai-services/openai/how-to/switching-endpoints?WT.mc_id=academic-109527-jasmineg)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Огляд  \n",
    "«Великі мовні моделі — це функції, які перетворюють текст у текст. Отримавши вхідний рядок тексту, велика мовна модель намагається передбачити, який текст буде наступним»(1). Цей «швидкий старт» допоможе ознайомитися з основними поняттями LLM, базовими вимогами до пакетів для початку роботи з AML, дасть легке уявлення про створення запитів, а також містить кілька коротких прикладів різних сценаріїв використання.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Зміст\n",
    "\n",
    "[Огляд](../../../../07-building-chat-applications/python)  \n",
    "[Як користуватися OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[1. Створення вашого OpenAI Service](../../../../07-building-chat-applications/python)  \n",
    "[2. Встановлення](../../../../07-building-chat-applications/python)  \n",
    "[3. Облікові дані](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Варіанти використання](../../../../07-building-chat-applications/python)  \n",
    "[1. Стислий виклад тексту](../../../../07-building-chat-applications/python)  \n",
    "[2. Класифікація тексту](../../../../07-building-chat-applications/python)  \n",
    "[3. Генерація нових назв продуктів](../../../../07-building-chat-applications/python)  \n",
    "[4. Тонке налаштування класифікатора](../../../../07-building-chat-applications/python)  \n",
    "\n",
    "[Джерела](../../../../07-building-chat-applications/python)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Створіть свій перший запит  \n",
    "Ця коротка вправа допоможе вам ознайомитися з основами надсилання запитів до моделі OpenAI для виконання простої задачі — \"стислий виклад\".\n",
    "\n",
    "**Кроки**:  \n",
    "1. Встановіть бібліотеку OpenAI у своєму середовищі Python  \n",
    "2. Завантажте стандартні допоміжні бібліотеки та вкажіть свої типові облікові дані безпеки OpenAI для створеного вами сервісу OpenAI  \n",
    "3. Оберіть модель для своєї задачі  \n",
    "4. Сформулюйте простий запит для моделі  \n",
    "5. Надішліть свій запит до API моделі!\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674254990318
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "%pip install openai python-dotenv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674829434433
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
    "assert API_KEY, \"ERROR: OpenAI Key is missing\"\n",
    "\n",
    "client = OpenAI(\n",
    "    api_key=API_KEY\n",
    "    )\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### 3. Вибір відповідної моделі  \n",
    "Моделі GPT-3.5-turbo або GPT-4 можуть розуміти та генерувати природну мову.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674742720788
    },
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Select the General Purpose curie model for text\n",
    "model = \"gpt-3.5-turbo\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## 4. Проєктування підказок  \n",
    "\n",
    "\"Чарівність великих мовних моделей полягає в тому, що, навчаючись мінімізувати помилку передбачення на величезних обсягах тексту, моделі зрештою опановують поняття, корисні для цих передбачень. Наприклад, вони засвоюють такі поняття, як\"(1):\n",
    "\n",
    "* як правильно писати слова\n",
    "* як працює граматика\n",
    "* як перефразовувати\n",
    "* як відповідати на запитання\n",
    "* як підтримувати розмову\n",
    "* як писати багатьма мовами\n",
    "* як програмувати\n",
    "* тощо\n",
    "\n",
    "#### Як керувати великою мовною моделлю  \n",
    "\"Серед усіх вхідних даних для великої мовної моделі найбільший вплив має текстова підказка(1).\n",
    "\n",
    "Великі мовні моделі можна спонукати до створення результату кількома способами:\n",
    "\n",
    "Інструкція: Скажіть моделі, що саме ви хочете\n",
    "Завершення: Спонукайте модель завершити початок того, що вам потрібно\n",
    "Демонстрація: Покажіть моделі, що ви хочете, використовуючи:\n",
    "Кілька прикладів у підказці\n",
    "Сотні або тисячі прикладів у навчальному датасеті для донавчання\"\n",
    "\n",
    "\n",
    "\n",
    "#### Є три основні правила створення підказок:\n",
    "\n",
    "**Пояснюйте і показуйте**. Чітко дайте зрозуміти, чого ви хочете — через інструкції, приклади або їх поєднання. Якщо ви хочете, щоб модель впорядкувала список елементів за алфавітом або класифікувала абзац за настроєм, покажіть їй, що саме це вам потрібно.\n",
    "\n",
    "**Надавайте якісні дані**. Якщо ви намагаєтеся створити класифікатор або змусити модель дотримуватися певного шаблону, переконайтеся, що прикладів достатньо. Обов’язково перевіряйте свої приклади — модель зазвичай достатньо розумна, щоб ігнорувати прості орфографічні помилки й дати відповідь, але вона також може вирішити, що це зроблено навмисно, і це вплине на результат.\n",
    "\n",
    "**Перевіряйте налаштування.** Параметри temperature і top_p визначають, наскільки детерміновано модель генерує відповідь. Якщо ви очікуєте відповідь, де є лише один правильний варіант, ці параметри варто знизити. Якщо ж вам потрібні різноманітніші відповіді, їх можна підвищити. Найпоширеніша помилка з цими налаштуваннями — вважати, що вони відповідають за \"кмітливість\" чи \"креативність\" моделі.\n",
    "\n",
    "\n",
    "Джерело: https://learn.microsoft.com/azure/ai-services/openai/overview\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494935186
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Create your first prompt\n",
    "text_prompt = \"Should oxford commas always be used?\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674494940872
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":text_prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Підсумувати текст  \n",
    "#### Завдання  \n",
    "Підсумуйте текст, додавши 'tl;dr:' наприкінці уривка. Зверніть увагу, як модель розуміє, як виконувати різні завдання без додаткових інструкцій. Ви можете експериментувати з більш описовими підказками, ніж tl;dr, щоб змінити поведінку моделі та налаштувати отримане резюме(3).\n",
    "\n",
    "Останні дослідження показали значний прогрес у багатьох NLP-завданнях і бенчмарках завдяки попередньому навчанні на великому корпусі тексту з подальшим донавчанням під конкретне завдання. Хоча архітектура зазвичай не залежить від завдання, цей підхід все одно потребує спеціальних датасетів для донавчання, що містять тисячі або десятки тисяч прикладів. Для порівняння, люди зазвичай можуть виконувати нове мовне завдання, маючи лише кілька прикладів або прості інструкції — з чим сучасні NLP-системи все ще переважно не справляються. Тут ми показуємо, що масштабування мовних моделей значно покращує універсальну продуктивність у режимі few-shot, іноді навіть досягаючи рівня конкурентності з попередніми найкращими підходами до донавчання.\n",
    "\n",
    "Tl;dr\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Вправи для різних випадків використання  \n",
    "1. Підсумувати текст  \n",
    "2. Класифікувати текст  \n",
    "3. Генерувати нові назви продуктів\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495198534
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Recent work has demonstrated substantial gains on many NLP tasks and benchmarks by pre-training on a large corpus of text followed by fine-tuning on a specific task. While typically task-agnostic in architecture, this method still requires task-specific fine-tuning datasets of thousands or tens of thousands of examples. By contrast, humans can generally perform a new language task from only a few examples or from simple instructions - something that current NLP systems still largely struggle to do. Here we show that scaling up language models greatly improves task-agnostic, few-shot performance, sometimes even reaching competitiveness with prior state-of-the-art fine-tuning approaches.\\n\\nTl;dr\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674495201868
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Класифікувати текст  \n",
    "#### Завдання  \n",
    "Розподіліть елементи за категоріями, які задаються під час виконання. У наступному прикладі ми вказуємо і категорії, і текст для класифікації у підказці (*playground_reference).\n",
    "\n",
    "Запит клієнта: Вітаю, одна з клавіш на моїй клавіатурі ноутбука нещодавно зламалась, і мені потрібна заміна:\n",
    "\n",
    "Віднесена категорія:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499424645
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Classify the following inquiry into one of the following: categories: [Pricing, Hardware Support, Software Support]\\n\\ninquiry: Hello, one of the keys on my laptop keyboard broke recently and I'll need a replacement:\\n\\nClassified category:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674499378518
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt},])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Генеруйте нові назви продуктів\n",
    "#### Завдання\n",
    "Створіть назви продуктів на основі прикладів слів. У цьому завданні ми додаємо інформацію про продукт, для якого потрібно придумати назви. Також надаємо схожий приклад, щоб показати бажаний шаблон. Ми встановили високе значення температури, щоб отримати більш випадкові та креативні відповіді.\n",
    "\n",
    "Опис продукту: Домашній апарат для приготування молочних коктейлів\n",
    "Ключові слова: швидко, корисно, компактно.\n",
    "Назви продукту: HomeShaker, Fit Shaker, QuickShake, Shake Maker\n",
    "\n",
    "Опис продукту: Пара взуття, яка підходить на будь-який розмір ноги.\n",
    "Ключові слова: адаптивний, підходить, omni-fit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gather": {
     "logged": 1674257087279
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "prompt = \"Product description: A home milkshake maker\\nSeed words: fast, healthy, compact.\\nProduct names: HomeShaker, Fit Shaker, QuickShake, Shake Maker\\n\\nProduct description: A pair of shoes that can fit any foot size.\\nSeed words: adaptable, fit, omni-fit.\"\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "#Setting a few additional, typical parameters during API Call\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "  model=model,\n",
    "  messages = [{\"role\":\"system\", \"content\":\"You are a helpful assistant.\"},\n",
    "               {\"role\":\"user\",\"content\":prompt}])\n",
    "\n",
    "response.choices[0].message.content"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Джерела  \n",
    "- [Openai Cookbook](https://github.com/openai/openai-cookbook?WT.mc_id=academic-105485-koreyst)  \n",
    "- [OpenAI Studio Examples](https://oai.azure.com/portal?WT.mc_id=academic-105485-koreyst)  \n",
    "- [Найкращі практики для донавчання GPT-3 для класифікації тексту](https://docs.google.com/document/d/1rqj7dkuvl7Byd5KQPUJRxc19BJt8wo0yHNwK84KfU3Q/edit#?WT.mc_id=academic-105485-koreyst)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Для додаткової допомоги  \n",
    "[OpenAI Commercialization Team](AzureOpenAITeam@microsoft.com)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Учасники\n",
    "* Louis Li\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Відмова від відповідальності**:  \nЦей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичний переклад може містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для отримання критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильне тлумачення, що виникли внаслідок використання цього перекладу.\n"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python310-sdkv2"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "coopTranslator": {
   "original_hash": "1854bdde1dd56b366f1f6c9122f7d304",
   "translation_date": "2025-08-25T18:34:07+00:00",
   "source_file": "07-building-chat-applications/python/oai-assignment.ipynb",
   "language_code": "uk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}