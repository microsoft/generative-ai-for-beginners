{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тонке налаштування моделей Open AI\n",
    "\n",
    "Цей нотатник базується на поточних рекомендаціях, наданих у документації [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) від Open AI.\n",
    "\n",
    "Тонке налаштування покращує продуктивність базових моделей для вашого застосунку шляхом їх повторного навчання з додатковими даними та контекстом, релевантним для конкретного випадку використання або сценарію. Зверніть увагу, що техніки інженерії підказок, такі як _few shot learning_ та _retrieval augmented generation_, дозволяють покращити стандартну підказку за допомогою релевантних даних для підвищення якості. Однак ці підходи обмежені максимальним розміром вікна токенів цільової базової моделі.\n",
    "\n",
    "За допомогою тонкого налаштування ми фактично повторно навчаємо саму модель з необхідними даними (що дозволяє використовувати набагато більше прикладів, ніж може вмістити максимальне вікно токенів) — і розгортаємо _кастомізовану_ версію моделі, якій більше не потрібно надавати приклади під час інференсу. Це не лише покращує ефективність нашого дизайну підказок (ми маємо більше гнучкості у використанні вікна токенів для інших речей), але й потенційно знижує наші витрати (за рахунок зменшення кількості токенів, які потрібно надсилати моделі під час інференсу).\n",
    "\n",
    "Тонке налаштування має 4 кроки:\n",
    "1. Підготувати навчальні дані та завантажити їх.\n",
    "1. Запустити навчальну задачу, щоб отримати тонко налаштовану модель.\n",
    "1. Оцінити тонко налаштовану модель і повторювати для покращення якості.\n",
    "1. Розгорнути тонко налаштовану модель для інференсу, коли будете задоволені.\n",
    "\n",
    "Зверніть увагу, що не всі базові моделі підтримують тонке налаштування — [перевірте документацію OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) для останньої інформації. Ви також можете тонко налаштувати раніше тонко налаштовану модель. У цьому посібнику ми використаємо `gpt-35-turbo` як цільову базову модель для тонкого налаштування.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 1.1: Підготуйте свій набір даних\n",
    "\n",
    "Давайте створимо чат-бота, який допоможе вам зрозуміти періодичну таблицю елементів, відповідаючи на запитання про елемент у вигляді лимерика. У _цьому_ простому посібнику ми просто створимо набір даних для навчання моделі з кількома прикладами відповідей, які показують очікуваний формат даних. У реальному випадку використання вам потрібно буде створити набір даних з набагато більшою кількістю прикладів. Також ви можете скористатися відкритим набором даних (для вашої предметної області), якщо він існує, і переформатувати його для використання у тонкому налаштуванні.\n",
    "\n",
    "Оскільки ми зосереджуємося на `gpt-35-turbo` і шукаємо відповідь за один крок (чат-завершення), ми можемо створити приклади, використовуючи [цей рекомендований формат](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), що відповідає вимогам OpenAI до чат-завершень. Якщо ви очікуєте багатокроковий розмовний контент, ви б використали [формат прикладів для багатокрокового чату](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), який включає параметр `weight` для позначення, які повідомлення слід використовувати (або ні) у процесі тонкого налаштування.\n",
    "\n",
    "Ми використаємо простіший формат з одним кроком для нашого посібника тут. Дані у форматі [jsonl](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) з 1 записом на рядок, кожен представлений у вигляді об’єкта у форматі JSON. Наведений нижче фрагмент показує 2 записи як приклад — дивіться [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl) для повного набору прикладів (10 прикладів), які ми використаємо для нашого посібника з тонкого налаштування. **Примітка:** Кожен запис _повинен_ бути визначений в одному рядку (не розбитий на кілька рядків, як це зазвичай у форматованому JSON-файлі)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "У реальному випадку використання вам знадобиться набагато більший набір прикладів для хороших результатів — компроміс буде між якістю відповідей і часом/витратами на тонке налаштування. Ми використовуємо невеликий набір, щоб швидко завершити тонке налаштування і проілюструвати процес. Дивіться [цей приклад з OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) для більш складного посібника з тонкого налаштування.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Крок 1.2 Завантажте свій набір даних\n",
    "\n",
    "Завантажте дані за допомогою Files API [як описано тут](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Зверніть увагу, що для запуску цього коду ви повинні спочатку виконати наступні кроки:\n",
    " - Встановити пакет `openai` для Python (переконайтеся, що ви використовуєте версію >=0.28.0 для останніх функцій)\n",
    " - Встановити змінну середовища `OPENAI_API_KEY` зі своїм ключем API OpenAI\n",
    "Щоб дізнатися більше, дивіться [Посібник з налаштування](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), наданий для курсу.\n",
    "\n",
    "Тепер запустіть код, щоб створити файл для завантаження з вашого локального файлу JSONL.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Крок 2.1: Створення завдання тонкого налаштування за допомогою SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Крок 2.2: Перевірка статусу завдання\n",
    "\n",
    "Ось кілька речей, які ви можете зробити за допомогою API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` - Перелік останніх n завдань тонкого налаштування\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` - Отримати деталі конкретного завдання тонкого налаштування\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` - Скасувати завдання тонкого налаштування\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` - Перелік до n подій із завдання\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Першим кроком процесу є _перевірка файлу навчання_, щоб переконатися, що дані мають правильний формат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Крок 2.3: Відстежуйте події для моніторингу прогресу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 2.4: Переглянути статус у панелі керування OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ви також можете переглянути статус, відвідавши вебсайт OpenAI та дослідивши розділ _Fine-tuning_ платформи. Це покаже вам статус поточної задачі, а також дозволить відстежувати історію попередніх запусків задач. На цьому скріншоті ви можете побачити, що попередній запуск завершився з помилкою, а другий запуск був успішним. Для контексту, це сталося, коли перший запуск використовував JSON-файл з неправильно відформатованими записами — після виправлення другий запуск завершився успішно і зробив модель доступною для використання.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.uk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ви також можете переглянути статусні повідомлення та метрики, прокрутивши вниз у візуальній панелі, як показано:\n",
    "\n",
    "| Messages | Metrics |\n",
    "|:---|:---|\n",
    "| ![Messages](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.uk.png) |  ![Metrics](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.uk.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Крок 3.1: Отримайте ID та протестуйте тонко налаштовану модель у коді\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Крок 3.2: Завантаження та тестування донавченої моделі у Playground\n",
    "\n",
    "Тепер ви можете протестувати донавчену модель двома способами. По-перше, ви можете відвідати Playground і за допомогою випадаючого списку Models вибрати вашу нову донавчену модель зі списку варіантів. Інший варіант — скористатися опцією \"Playground\", що показана у панелі Fine-tuning (див. скріншот вище), яка запускає наступний _порівняльний_ вигляд, що показує версії базової та донавченої моделей поруч для швидкої оцінки.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.uk.png)\n",
    "\n",
    "Просто заповніть системний контекст, який використовувався у ваших тренувальних даних, і введіть тестове питання. Ви помітите, що обидві сторони оновлюються з однаковим контекстом і питанням. Запустіть порівняння, і ви побачите різницю у відповідях між ними. _Зверніть увагу, як донавчена модель форматує відповідь у форматі, який ви надали у своїх прикладах, тоді як базова модель просто слідує системному підказу_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.uk.png)\n",
    "\n",
    "Ви помітите, що порівняння також надає кількість токенів для кожної моделі та час, витрачений на інференс. **Цей конкретний приклад є спрощеним і призначений для демонстрації процесу, але не відображає реальний набір даних чи сценарій**. Ви можете помітити, що обидва зразки показують однакову кількість токенів (системний контекст і підказка користувача ідентичні), при цьому донавчена модель витрачає більше часу на інференс (кастомна модель).\n",
    "\n",
    "У реальних сценаріях ви не будете використовувати такий простий приклад, а донавчати модель на реальних даних (наприклад, каталог продуктів для служби підтримки клієнтів), де якість відповіді буде значно помітнішою. У _цьому_ контексті отримання еквівалентної якості відповіді з базовою моделлю вимагатиме більш складного налаштування підказок, що збільшить використання токенів і потенційно час обробки для інференсу. _Щоб спробувати це, ознайомтеся з прикладами донавчання в OpenAI Cookbook для початку._\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**Відмова від відповідальності**:  \nЦей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для критично важливої інформації рекомендується звертатися до професійного людського перекладу. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникли внаслідок використання цього перекладу.\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "1725725c956564056baf895e6ca92aa5",
   "translation_date": "2025-12-19T12:04:46+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "uk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}