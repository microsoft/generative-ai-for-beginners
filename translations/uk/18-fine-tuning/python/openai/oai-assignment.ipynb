{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Тонке налаштування моделей Open AI\n",
    "\n",
    "Цей ноутбук базується на актуальних рекомендаціях із [Fine Tuning](https://platform.openai.com/docs/guides/fine-tuning?WT.mc_id=academic-105485-koreyst) від Open AI.\n",
    "\n",
    "Тонке налаштування покращує роботу базових моделей для вашого застосування шляхом додаткового навчання на даних і контексті, що стосуються конкретного випадку використання. Зверніть увагу, що такі техніки, як _few shot learning_ та _retrieval augmented generation_, дозволяють підсилити стандартний запит релевантними даними для підвищення якості. Проте ці підходи обмежені максимальною кількістю токенів, яку підтримує обрана базова модель.\n",
    "\n",
    "Завдяки тонкому налаштуванню ми фактично перенавчаємо саму модель на потрібних даних (що дозволяє використати набагато більше прикладів, ніж вміщується у вікно токенів) — і розгортаємо _кастомізовану_ версію моделі, якій більше не потрібно надавати приклади під час виконання запиту. Це не лише підвищує ефективність нашого дизайну запитів (ми отримуємо більше гнучкості у використанні вікна токенів для інших цілей), а й потенційно знижує наші витрати (зменшуючи кількість токенів, які потрібно надсилати моделі під час виконання запиту).\n",
    "\n",
    "Тонке налаштування складається з 4 етапів:\n",
    "1. Підготувати тренувальні дані та завантажити їх.\n",
    "1. Запустити навчання, щоб отримати модель із тонким налаштуванням.\n",
    "1. Оцінити модель із тонким налаштуванням і повторити для покращення якості.\n",
    "1. Розгорнути модель із тонким налаштуванням для використання, коли результат вас влаштовує.\n",
    "\n",
    "Зверніть увагу, що не всі базові моделі підтримують тонке налаштування — [перевіряйте документацію OpenAI](https://platform.openai.com/docs/guides/fine-tuning/what-models-can-be-fine-tuned?WT.mc_id=academic-105485-koreyst) для отримання найсвіжішої інформації. Також можна виконати тонке налаштування вже налаштованої моделі. У цьому уроці ми будемо використовувати `gpt-35-turbo` як цільову базову модель для тонкого налаштування.\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 1.1: Підготуйте свій датасет\n",
    "\n",
    "Давайте створимо чат-бота, який допоможе вам розібратися в періодичній таблиці елементів, відповідаючи на запитання про елемент у формі лимерика. У _цьому_ простому уроці ми просто створимо датасет для навчання моделі з кількома прикладами відповідей, які демонструють очікуваний формат даних. У реальному випадку використання вам потрібно буде створити датасет із набагато більшою кількістю прикладів. Також ви можете скористатися відкритим датасетом (для вашої предметної області), якщо такий існує, і відформатувати його для використання у донавчанні.\n",
    "\n",
    "Оскільки ми зосереджуємось на `gpt-35-turbo` і очікуємо одноразову відповідь (chat completion), ми можемо створити приклади, використовуючи [цей рекомендований формат](https://platform.openai.com/docs/guides/fine-tuning/preparing-your-dataset?WT.mc_id=academic-105485-koreyst), який відповідає вимогам OpenAI для завершення чату. Якщо ви очікуєте багатокрокову розмову, слід використовувати [формат для багатокрокових прикладів](https://platform.openai.com/docs/guides/fine-tuning/multi-turn-chat-examples?WT.mc_id=academic-105485-koreyst), який містить параметр `weight`, щоб вказати, які повідомлення слід використовувати (або ні) під час донавчання.\n",
    "\n",
    "У цьому уроці ми використаємо простіший формат для одноразових відповідей. Дані зберігаються у [jsonl-форматі](https://jsonlines.org/?WT.mc_id=academic-105485-koreyst) — 1 запис на рядок, кожен представлений як об’єкт у форматі JSON. Нижче наведено фрагмент із 2 записів як приклад — повний набір прикладів (10 штук), який ми використаємо для нашого уроку з донавчання, дивіться у [training-data.jsonl](../../../../../18-fine-tuning/python/openai/training-data.jsonl). **Зверніть увагу:** Кожен запис _має_ бути визначений в одному рядку (не розбитий на кілька рядків, як це зазвичай буває у форматованому JSON-файлі)\n",
    "\n",
    "```json\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Gallium\"}, {\"role\": \"assistant\", \"content\": \"Gallium, oh gallium, so light - Melts in your hand, oh what a sight - At 86 degrees - Its liquid with ease - And in semiconductors, it's out of sight\"}]}\n",
    "{ \"messages\": [{\"role\": \"system\", \"content\": \"Elle is a factual chatbot that answers questions about elements in the periodic table with a limerick\"}, {\"role\": \"user\", \"content\": \"Tell me about Hydrogen\"}, {\"role\": \"assistant\", \"content\": \"Hydrogen, the first in the line - The lightest of all, so divine - It's in water, you see - And in stars, it's the key - The universe's most common sign\"}]}\n",
    "```\n",
    "\n",
    "У реальному випадку використання вам знадобиться набагато більший набір прикладів для отримання якісних результатів — тут потрібно знайти баланс між якістю відповідей і часом/витратами на донавчання. Ми використовуємо невеликий набір, щоб швидко пройти процес і показати, як це працює. Дивіться [цей приклад з OpenAI Cookbook](https://github.com/openai/openai-cookbook/blob/main/examples/How_to_finetune_chat_models.ipynb?WT.mc_id=academic-105485-koreyst) для більш складного уроку з донавчання.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 1.2 Завантаження вашого датасету\n",
    "\n",
    "Завантажте дані за допомогою Files API [як описано тут](https://platform.openai.com/docs/guides/fine-tuning/upload-a-training-file). Зверніть увагу, що для запуску цього коду спочатку потрібно виконати такі дії:\n",
    " - Встановити Python-пакет `openai` (переконайтеся, що використовуєте версію >=0.28.0 для нових можливостей)\n",
    " - Встановити змінну середовища `OPENAI_API_KEY` зі своїм OpenAI API ключем\n",
    "Щоб дізнатися більше, перегляньте [інструкцію з налаштування](./../../../00-course-setup/02-setup-local.md?WT.mc_id=academic-105485-koreyst), яка надається для цього курсу.\n",
    "\n",
    "Тепер запустіть код, щоб створити файл для завантаження зі свого локального JSONL-файлу.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FileObject(id='file-JdAJcagdOTG6ACNlFWzuzmyV', bytes=4021, created_at=1715566183, filename='training-data.jsonl', object='file', purpose='fine-tune', status='processed', status_details=None)\n",
      "Training File ID: file-JdAJcagdOTG6ACNlFWzuzmyV\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_file = client.files.create(\n",
    "  file=open(\"./training-data.jsonl\", \"rb\"),\n",
    "  purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "print(ft_file)\n",
    "print(\"Training File ID: \" + ft_file.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 2.1: Створіть завдання для донавчання за допомогою SDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FineTuningJob(id='ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', created_at=1715566184, error=Error(code=None, message=None, param=None), fine_tuned_model=None, finished_at=None, hyperparameters=Hyperparameters(n_epochs='auto', batch_size='auto', learning_rate_multiplier='auto'), model='gpt-3.5-turbo-0125', object='fine_tuning.job', organization_id='org-EZ6ag0n0S6Zm8eV9BSWKmE6l', result_files=[], seed=830529052, status='validating_files', trained_tokens=None, training_file='file-JdAJcagdOTG6ACNlFWzuzmyV', validation_file=None, estimated_finish=None, integrations=[], user_provided_suffix=None)\n",
      "Fine-tuning Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "ft_filejob = client.fine_tuning.jobs.create(\n",
    "  training_file=ft_file.id, \n",
    "  model=\"gpt-3.5-turbo\"\n",
    ")\n",
    "\n",
    "print(ft_filejob)\n",
    "print(\"Fine-tuning Job ID: \" + ft_filejob.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 2.2: Перевірте статус завдання\n",
    "\n",
    "Ось кілька дій, які можна виконати за допомогою API `client.fine_tuning.jobs`:\n",
    "- `client.fine_tuning.jobs.list(limit=<n>)` – Показати останні n завдань тонкого налаштування\n",
    "- `client.fine_tuning.jobs.retrieve(<job_id>)` – Отримати деталі конкретного завдання тонкого налаштування\n",
    "- `client.fine_tuning.jobs.cancel(<job_id>)` – Скасувати завдання тонкого налаштування\n",
    "- `client.fine_tuning.jobs.list_events(fine_tuning_job_id=<job_id>, limit=<b>)` – Показати до n подій із завдання\n",
    "- `client.fine_tuning.jobs.create(model=\"gpt-35-turbo\", training_file=\"your-training-file.jsonl\", ...)`\n",
    "\n",
    "Перший крок цього процесу — _перевірка навчального файлу_, щоб переконатися, що дані мають правильний формат.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[FineTuningJobEvent](data=[FineTuningJobEvent(id='ftevent-GkWiDgZmOsuv4q5cSTEGscY6', created_at=1715566184, level='info', message='Validating training file: file-JdAJcagdOTG6ACNlFWzuzmyV', object='fine_tuning.job.event', data={}, type='message'), FineTuningJobEvent(id='ftevent-3899xdVTO3LN7Q7LkKLMJUnb', created_at=1715566184, level='info', message='Created fine-tuning job: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh', object='fine_tuning.job.event', data={}, type='message')], object='list', has_more=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "# List 10 fine-tuning jobs\n",
    "client.fine_tuning.jobs.list(limit=10)\n",
    "\n",
    "# Retrieve the state of a fine-tune\n",
    "client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "# List up to 10 events from a fine-tuning job\n",
    "client.fine_tuning.jobs.list_events(fine_tuning_job_id=ft_filejob.id, limit=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job ID: ftjob-Usfb9RjasncaZ5Cjbuh1XSCh\n",
      "Status: running\n",
      "Trained Tokens: None\n"
     ]
    }
   ],
   "source": [
    "# Once the training data is validated\n",
    "# Track the job status to see if it is running and when it is complete\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "\n",
    "print(\"Job ID:\", response.id)\n",
    "print(\"Status:\", response.status)\n",
    "print(\"Trained Tokens:\", response.trained_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 2.3: Відстежуйте події для моніторингу прогресу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 85/100: training loss=0.14\n",
      "Step 86/100: training loss=0.00\n",
      "Step 87/100: training loss=0.00\n",
      "Step 88/100: training loss=0.07\n",
      "Step 89/100: training loss=0.00\n",
      "Step 90/100: training loss=0.00\n",
      "Step 91/100: training loss=0.00\n",
      "Step 92/100: training loss=0.00\n",
      "Step 93/100: training loss=0.00\n",
      "Step 94/100: training loss=0.00\n",
      "Step 95/100: training loss=0.08\n",
      "Step 96/100: training loss=0.05\n",
      "Step 97/100: training loss=0.00\n",
      "Step 98/100: training loss=0.00\n",
      "Step 99/100: training loss=0.00\n",
      "Step 100/100: training loss=0.00\n",
      "Checkpoint created at step 80 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyyF2:ckpt-step-80\n",
      "Checkpoint created at step 90 with Snapshot ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWyzhK:ckpt-step-90\n",
      "New fine-tuned model created: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n",
      "The job has successfully completed\n"
     ]
    }
   ],
   "source": [
    "# You can also track progress in a more granular way by checking for events\n",
    "# Refresh this code till you get the `The job has successfully completed` message\n",
    "response = client.fine_tuning.jobs.list_events(ft_filejob.id)\n",
    "\n",
    "events = response.data\n",
    "events.reverse()\n",
    "\n",
    "for event in events:\n",
    "    print(event.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 2.4: Перегляньте статус у панелі керування OpenAI\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ви також можете переглянути статус, відвідавши сайт OpenAI та відкривши розділ _Fine-tuning_ на платформі. Тут ви побачите статус поточного завдання, а також зможете відстежувати історію попередніх запусків. На цьому скріншоті видно, що попередній запуск завершився невдало, а другий — успішно. Для розуміння: це сталося тому, що під час першого запуску був використаний JSON-файл з неправильно відформатованими записами — після виправлення другий запуск завершився успішно, і модель стала доступною для використання.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-model-status.563271727bf7bfba7e3f73a201f8712fae3cea1c08f7c7f12ca469c06d234122.uk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ви також можете переглядати статусні повідомлення та метрики, прокручуючи далі вниз у візуальній панелі приладів, як показано нижче:\n",
    "\n",
    "| Повідомлення | Метрики |\n",
    "|:---|:---|\n",
    "| ![Повідомлення](../../../../../translated_images/fine-tuned-messages-panel.4ed0c2da5ea1313b3a706a66f66bf5007c379cd9219cfb74cb30c0b04b90c4c8.uk.png) |  ![Метрики](../../../../../translated_images/fine-tuned-metrics-panel.700d7e4995a652299584ab181536a6cfb67691a897a518b6c7a2aa0a17f1a30d.uk.png)|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 3.1: Отримайте ID і протестуйте донавчану модель у коді\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned Model ID: ft:gpt-3.5-turbo-0125:bitnbot::9OFWzNjz\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the identity of the fine-tuned model once ready\n",
    "response = client.fine_tuning.jobs.retrieve(ft_filejob.id)\n",
    "fine_tuned_model_id = response.fine_tuned_model\n",
    "print(\"Fine-tuned Model ID:\", fine_tuned_model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatCompletionMessage(content=\"Strontium, a metal so bright - It's in fireworks, a dazzling sight - It's in bones, you see - And in tea, it's the key - It's the fortieth, so pure, that's the right\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "# You can then use that model to generate completions from the SDK as shown\n",
    "# Or you can load that model into the OpenAI Playground (in the UI) to validate it from there.\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=fine_tuned_model_id,\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are Elle, a factual chatbot that answers questions about elements in the periodic table with a limerick\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me about Strontium\"},\n",
    "  ]\n",
    ")\n",
    "print(completion.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Крок 3.2: Завантаження та тестування донавченого моделі у Playground\n",
    "\n",
    "Тепер ви можете протестувати донавчену модель двома способами. По-перше, ви можете відвідати Playground і скористатися випадаючим списком Models, щоб обрати вашу нову донавчену модель із запропонованих варіантів. Інший спосіб — скористатися опцією \"Playground\", яка відображається у панелі Fine-tuning (див. скріншот вище). Вона відкриває _порівняльний_ режим, у якому версії базової та донавченої моделі показані поруч для швидкої оцінки.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-compare.56e06f0ad8922016497d39ced3d84ea296eec89073503f2bf346ec9718f913b5.uk.png)\n",
    "\n",
    "Просто заповніть системний контекст, який ви використовували у своїх тренувальних даних, і введіть тестове питання. Ви помітите, що обидві сторони оновлюються з однаковим контекстом і питанням. Запустіть порівняння, і ви побачите різницю у відповідях між ними. _Зверніть увагу, як донавчена модель формує відповідь у тому форматі, який ви задали у своїх прикладах, тоді як базова модель просто слідує системному запиту_.\n",
    "\n",
    "![Fine-tuning job status](../../../../../translated_images/fine-tuned-playground-launch.5a26495c983c6350c227e05700a47a89002d132949a56fa4ff37f266ebe997b2.uk.png)\n",
    "\n",
    "Ви також помітите, що під час порівняння відображається кількість токенів для кожної моделі та час, витрачений на інференцію. **Цей конкретний приклад є спрощеним і призначений лише для демонстрації процесу, але не відображає реальний набір даних чи сценарій**. Можливо, ви помітите, що в обох прикладах однакова кількість токенів (системний контекст і запит користувача ідентичні), але донавчена модель витрачає більше часу на інференцію (кастомна модель).\n",
    "\n",
    "У реальних сценаріях ви не будете використовувати такий простий приклад, а будете донавчати модель на реальних даних (наприклад, каталог товарів для служби підтримки клієнтів), де якість відповіді буде набагато помітнішою. У _такому_ випадку, щоб отримати таку ж якість відповіді від базової моделі, доведеться більше працювати над інженерією підказок, що збільшить використання токенів і, можливо, час обробки для інференції. _Щоб спробувати це на практиці, перегляньте приклади донавчання в OpenAI Cookbook._\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Відмова від відповідальності**:  \nЦей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичний переклад може містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для отримання критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильне тлумачення, що виникли внаслідок використання цього перекладу.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "coopTranslator": {
   "original_hash": "69b527f1e605a10fb9c7e00ae841021d",
   "translation_date": "2025-08-25T21:59:52+00:00",
   "source_file": "18-fine-tuning/python/openai/oai-assignment.ipynb",
   "language_code": "uk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}