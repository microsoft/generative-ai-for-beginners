<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "a8b2d4bb727c877ebf9edff8623d16b9",
  "translation_date": "2025-09-06T10:26:35+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "uk"
}
-->
[![Open Source Models](../../../translated_images/16-lesson-banner.6b56555e8404fda1716382db4832cecbe616ccd764de381f0af6cfd694d05f74.uk.png)](https://aka.ms/gen-ai-lesson16-gh?WT.mc_id=academic-105485-koreyst)

## Вступ

Світ відкритих LLM-моделей захоплюючий і постійно змінюється. Цей урок має на меті надати детальний огляд відкритих моделей. Якщо ви шукаєте інформацію про те, як порівняти пропрієтарні моделі з відкритими, перейдіть до уроку ["Дослідження та порівняння різних LLM"](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst). У цьому уроці також буде розглянута тема тонкого налаштування, але більш детальне пояснення можна знайти в уроці ["Тонке налаштування LLM"](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst).

## Цілі навчання

- Зрозуміти відкриті моделі
- Усвідомити переваги роботи з відкритими моделями
- Дослідити доступні відкриті моделі на Hugging Face та Azure AI Studio

## Що таке відкриті моделі?

Відкрите програмне забезпечення відіграло ключову роль у розвитку технологій у різних галузях. Ініціатива Open Source (OSI) визначила [10 критеріїв для програмного забезпечення](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst), щоб класифікувати його як відкрите. Вихідний код має бути відкрито доступним під ліцензією, затвердженою OSI.

Хоча розробка LLM має схожі елементи з розробкою програмного забезпечення, процес не є абсолютно однаковим. Це викликало багато дискусій у спільноті щодо визначення відкритого коду в контексті LLM. Щоб модель відповідала традиційному визначенню відкритого коду, наступна інформація має бути доступною для загального користування:

- Набори даних, використані для навчання моделі.
- Повні ваги моделі як частина навчання.
- Код для оцінки.
- Код для тонкого налаштування.
- Повні ваги моделі та метрики навчання.

На даний момент лише кілька моделей відповідають цим критеріям. [Модель OLMo, створена Інститутом штучного інтелекту Аллена (AllenAI)](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst) є однією з таких.

У цьому уроці ми будемо використовувати термін "відкриті моделі", оскільки вони можуть не відповідати вищезазначеним критеріям на момент написання.

## Переваги відкритих моделей

**Висока налаштовуваність** - Оскільки відкриті моделі випускаються з детальною інформацією про навчання, дослідники та розробники можуть змінювати внутрішню структуру моделі. Це дозволяє створювати високоспеціалізовані моделі, які тонко налаштовані для конкретного завдання або області дослідження. Деякі приклади включають генерацію коду, математичні операції та біологію.

**Вартість** - Вартість за токен при використанні та розгортанні цих моделей нижча, ніж у пропрієтарних моделей. При створенні додатків на основі генеративного AI слід враховувати співвідношення продуктивності та ціни для вашого випадку використання.

![Model Cost](../../../translated_images/model-price.3f5a3e4d32ae00b465325159e1f4ebe7b5861e95117518c6bfc37fe842950687.uk.png)  
Джерело: Artificial Analysis

**Гнучкість** - Робота з відкритими моделями дозволяє бути гнучким у використанні різних моделей або їх комбінуванні. Прикладом цього є [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst), де користувач може вибрати модель, яка використовується, безпосередньо в інтерфейсі:

![Choose Model](../../../translated_images/choose-model.f095d15bbac922141591fd4fac586dc8d25e69b42abf305d441b84c238e293f2.uk.png)

## Дослідження різних відкритих моделей

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), розроблена Meta, є відкритою моделлю, оптимізованою для додатків на основі чатів. Це стало можливим завдяки методу тонкого налаштування, який включав велику кількість діалогів і зворотного зв'язку від людей. Завдяки цьому методу модель генерує результати, які більше відповідають очікуванням людей, що забезпечує кращий досвід користувача.

Деякі приклади тонко налаштованих версій Llama включають [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst), яка спеціалізується на японській мові, та [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), яка є покращеною версією базової моделі.

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) є відкритою моделлю, яка зосереджена на високій продуктивності та ефективності. Вона використовує підхід Mixture-of-Experts, який об'єднує групу спеціалізованих експертних моделей в одну систему, де залежно від введення вибираються певні моделі для використання. Це робить обчислення більш ефективними, оскільки моделі обробляють лише ті введення, в яких вони спеціалізуються.

Деякі приклади тонко налаштованих версій Mistral включають [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst), яка зосереджена на медичній сфері, та [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), яка виконує математичні обчислення.

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) є LLM, створеною Інститутом технологічних інновацій (**TII**). Falcon-40B була навчена на 40 мільярдах параметрів, що показало її кращу продуктивність порівняно з GPT-3 при меншому обчислювальному бюджеті. Це стало можливим завдяки використанню алгоритму FlashAttention та багатозапитної уваги, що дозволяє зменшити вимоги до пам'яті під час виконання. Завдяки зменшеному часу виконання Falcon-40B підходить для додатків на основі чатів.

Деякі приклади тонко налаштованих версій Falcon включають [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst), асистент, побудований на відкритих моделях, та [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), який забезпечує вищу продуктивність, ніж базова модель.

## Як обрати

Немає єдиної правильної відповіді на питання, як обрати відкриту модель. Хорошим місцем для початку є використання функції фільтрації за завданням в Azure AI Studio. Це допоможе вам зрозуміти, для яких типів завдань модель була навчена. Hugging Face також підтримує рейтинг LLM, який показує найкращі моделі за певними метриками.

Якщо ви хочете порівняти LLM між різними типами, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) є ще одним чудовим ресурсом:

![Model Quality](../../../translated_images/model-quality.aaae1c22e00f7ee1cd9dc186c611ac6ca6627eabd19e5364dce9e216d25ae8a5.uk.png)  
Джерело: Artificial Analysis

Якщо ви працюєте над конкретним випадком використання, пошук тонко налаштованих версій, які зосереджені на тій самій області, може бути ефективним. Експериментування з кількома відкритими моделями, щоб побачити, як вони працюють відповідно до ваших очікувань і очікувань ваших користувачів, також є хорошою практикою.

## Наступні кроки

Найкраще у відкритих моделях те, що ви можете швидко почати працювати з ними. Ознайомтеся з [каталогом моделей Azure AI Foundry](https://ai.azure.com?WT.mc_id=academic-105485-koreyst), який містить спеціальну колекцію Hugging Face з моделями, які ми обговорювали тут.

## Навчання не закінчується тут, продовжуйте подорож

Після завершення цього уроку ознайомтеся з нашою [колекцією навчання Generative AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), щоб продовжити вдосконалювати свої знання про Generative AI!

---

**Відмова від відповідальності**:  
Цей документ був перекладений за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, будь ласка, майте на увазі, що автоматичні переклади можуть містити помилки або неточності. Оригінальний документ на його рідній мові слід вважати авторитетним джерелом. Для критичної інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильні тлумачення, що виникають внаслідок використання цього перекладу.