{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Вступ\n",
    "\n",
    "У цьому уроці розглянемо:\n",
    "- Що таке виклик функції та для чого він використовується\n",
    "- Як створити виклик функції за допомогою OpenAI\n",
    "- Як інтегрувати виклик функції у додаток\n",
    "\n",
    "## Навчальні цілі\n",
    "\n",
    "Після завершення цього уроку ви знатимете та розумітимете:\n",
    "\n",
    "- Мету використання виклику функції\n",
    "- Налаштування виклику функції за допомогою сервісу OpenAI\n",
    "- Як розробити ефективні виклики функцій для вашого застосування\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Розуміння викликів функцій\n",
    "\n",
    "У цьому уроці ми створюємо функцію для нашого освітнього стартапу, яка дозволяє користувачам знаходити технічні курси за допомогою чат-бота. Ми будемо рекомендувати курси, які відповідають їхньому рівню знань, поточній ролі та цікавій технології.\n",
    "\n",
    "Для цього ми використаємо комбінацію:\n",
    " - `OpenAI` для створення чат-досвіду для користувача\n",
    " - `Microsoft Learn Catalog API` для допомоги у пошуку курсів на основі запиту користувача\n",
    " - `Function Calling` для того, щоб взяти запит користувача і передати його у функцію для виконання API-запиту\n",
    "\n",
    "Щоб розпочати, давайте розглянемо, навіщо взагалі використовувати виклик функцій:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # отримати нову відповідь від GPT, яка вже бачить відповідь функції\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чому варто використовувати Function Calling\n",
    "\n",
    "Якщо ви вже проходили інші уроки цього курсу, ви, ймовірно, розумієте, наскільки потужними є великі мовні моделі (LLMs). Сподіваємось, ви також помітили й деякі їхні обмеження.\n",
    "\n",
    "Function Calling — це функція в OpenAI Service, створена для вирішення таких проблем:\n",
    "\n",
    "Нестабільний формат відповідей:\n",
    "- До появи function calling відповіді від великих мовних моделей були неструктурованими та непослідовними. Розробникам доводилося писати складний код для перевірки, щоб обробляти всі можливі варіації у відповідях.\n",
    "\n",
    "Обмежена інтеграція із зовнішніми даними:\n",
    "- Раніше було складно підключати дані з інших частин застосунку до контексту чату.\n",
    "\n",
    "Завдяки стандартизації форматів відповідей і простій інтеграції із зовнішніми даними, function calling спрощує розробку та зменшує потребу у додатковій логіці перевірки.\n",
    "\n",
    "Користувачі не могли отримати відповіді на запитання на кшталт \"Яка зараз погода у Стокгольмі?\". Це тому, що моделі обмежені даними, на яких їх навчали.\n",
    "\n",
    "Розгляньмо приклад нижче, який ілюструє цю проблему:\n",
    "\n",
    "Уявімо, що ми хочемо створити базу даних студентів, щоб рекомендувати їм відповідні курси. Нижче наведено два описи студентів, які містять дуже схожі дані.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми хочемо надіслати це LLM для обробки даних. Пізніше це можна використати в нашому додатку для надсилання до API або зберігання в базі даних.\n",
    "\n",
    "Давайте створимо два однакових запити, якими ми пояснюємо LLM, яка саме інформація нас цікавить:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ми хочемо надіслати це LLM, щоб проаналізувати частини, які важливі для нашого продукту. Тому ми можемо створити два ідентичні підказки, щоб дати інструкції LLM:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Після створення цих двох підказок ми надішлемо їх до LLM, використовуючи `openai.ChatCompletion`. Ми зберігаємо підказку у змінній `messages` і призначаємо роль `user`. Це потрібно для імітації повідомлення від користувача, яке надсилається чат-боту.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хоча підказки однакові, а описи схожі, ми можемо отримати різні формати властивості `Grades`.\n",
    "\n",
    "Якщо запустити цю комірку кілька разів, формат може бути як `3.7`, так і `3.7 GPA`.\n",
    "\n",
    "Це відбувається тому, що LLM працює з неструктурованими даними у вигляді текстової підказки і повертає також неструктуровані дані. Нам потрібно мати структурований формат, щоб знати, чого очікувати при зберіганні чи використанні цих даних.\n",
    "\n",
    "Використовуючи функціональні виклики, ми можемо бути впевнені, що отримуємо структуровані дані. При використанні функціональних викликів LLM насправді не викликає і не запускає жодних функцій. Натомість ми створюємо структуру, якої LLM має дотримуватися у своїх відповідях. Потім ми використовуємо ці структуровані відповіді, щоб знати, яку функцію запускати у наших додатках.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Схема потоку виклику функції](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.uk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Варіанти використання викликів функцій\n",
    "\n",
    "**Виклик зовнішніх інструментів**  \n",
    "Чат-боти чудово відповідають на запитання користувачів. Завдяки виклику функцій, чат-боти можуть використовувати повідомлення від користувачів для виконання певних завдань. Наприклад, студент може попросити чат-бота: \"Надішли лист моєму викладачу з проханням допомогти мені з цією темою\". Для цього можна викликати функцію `send_email(to: string, body: string)`\n",
    "\n",
    "**Створення API або запитів до бази даних**  \n",
    "Користувачі можуть знаходити інформацію, використовуючи природну мову, яка перетворюється у форматований запит або API-запит. Наприклад, вчитель може запитати: \"Хто з учнів виконав останнє завдання?\", і це може викликати функцію з назвою `get_completed(student_name: string, assignment: int, current_status: string)`\n",
    "\n",
    "**Створення структурованих даних**  \n",
    "Користувачі можуть взяти фрагмент тексту або CSV і за допомогою LLM виділити з нього важливу інформацію. Наприклад, студент може перетворити статтю з Вікіпедії про мирні угоди на AI-картки для навчання. Це можна зробити за допомогою функції `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Створення вашого першого виклику функції\n",
    "\n",
    "Процес створення виклику функції складається з 3 основних кроків:\n",
    "1. Виклик API Chat Completions зі списком ваших функцій і повідомленням користувача\n",
    "2. Зчитування відповіді моделі для виконання дії, наприклад, запуску функції або API-запиту\n",
    "3. Здійснення ще одного виклику до API Chat Completions з відповіддю від вашої функції, щоб використати цю інформацію для створення відповіді користувачу.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Потік виклику функції](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.uk.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Елементи виклику функції\n",
    "\n",
    "#### Введення користувача\n",
    "\n",
    "Перший крок — створити повідомлення користувача. Його можна динамічно призначити, взявши значення з текстового поля, або задати тут вручну. Якщо ви вперше працюєте з Chat Completions API, потрібно визначити `role` та `content` повідомлення.\n",
    "\n",
    "`role` може бути або `system` (створення правил), або `assistant` (модель), або `user` (кінцевий користувач). Для виклику функції ми призначаємо роль `user` і додаємо приклад запитання.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Створення функцій.\n",
    "\n",
    "Далі ми визначимо функцію та її параметри. Тут ми використаємо лише одну функцію під назвою `search_courses`, але ви можете створювати кілька функцій.\n",
    "\n",
    "**Важливо**: Функції додаються до системного повідомлення для LLM і враховуються у загальній кількості доступних вам токенів.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Визначення**\n",
    "\n",
    "Структура визначення функції має кілька рівнів, кожен з яких має свої властивості. Ось детальний опис вкладеної структури:\n",
    "\n",
    "**Властивості функції верхнього рівня:**\n",
    "\n",
    "`name` - Назва функції, яку потрібно викликати.\n",
    "\n",
    "`description` - Опис того, як працює функція. Тут важливо бути конкретним і зрозумілим.\n",
    "\n",
    "`parameters` - Список значень і формат, які ви хочете отримати у відповіді моделі.\n",
    "\n",
    "**Властивості об’єкта параметрів:**\n",
    "\n",
    "`type` - Тип даних об’єкта параметрів (зазвичай \"object\")\n",
    "\n",
    "`properties` - Список конкретних значень, які модель використає у своїй відповіді\n",
    "\n",
    "**Властивості окремого параметра:**\n",
    "\n",
    "`name` - Неявно визначається ключем властивості (наприклад, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - Тип даних цього конкретного параметра (наприклад, \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - Опис цього конкретного параметра\n",
    "\n",
    "**Необов’язкові властивості:**\n",
    "\n",
    "`required` - Масив, у якому перелічені параметри, обов’язкові для виконання виклику функції\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Виклик функції\n",
    "Після того, як ми визначили функцію, тепер потрібно додати її до виклику Chat Completion API. Для цього ми додаємо `functions` до запиту. У цьому випадку це виглядає як `functions=functions`.\n",
    "\n",
    "Також є можливість встановити `function_call` у значення `auto`. Це означає, що ми дозволяємо LLM самостійно обрати, яку функцію викликати, виходячи з повідомлення користувача, замість того щоб призначати її вручну.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер давайте подивимось на відповідь і побачимо, як вона відформатована:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "Ви можете побачити, що викликається функція з певною назвою, і з повідомлення користувача LLM зміг знайти дані для підстановки в аргументи функції.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Інтеграція викликів функцій у додаток.\n",
    "\n",
    "Після того, як ми протестували відформатовану відповідь від LLM, тепер можемо інтегрувати це у додаток.\n",
    "\n",
    "### Керування процесом\n",
    "\n",
    "Щоб інтегрувати це у наш додаток, виконаймо наступні кроки:\n",
    "\n",
    "Спочатку зробимо запит до сервісів OpenAI і збережемо повідомлення у змінній з назвою `response_message`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тепер ми визначимо функцію, яка викликатиме API Microsoft Learn для отримання списку курсів:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Як найкращу практику, ми спочатку перевіримо, чи модель хоче викликати функцію. Після цього ми створимо одну з доступних функцій і зіставимо її з тією, яку викликає модель.\n",
    "\n",
    "Далі ми візьмемо аргументи функції та зіставимо їх з аргументами від LLM.\n",
    "\n",
    "Нарешті, ми додамо повідомлення про виклик функції та значення, які були повернуті повідомленням `search_courses`. Це дає LLM всю необхідну інформацію, щоб відповісти користувачу природною мовою.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Завдання з кодування\n",
    "\n",
    "Чудова робота! Щоб продовжити вивчення OpenAI Function Calling, ви можете створити: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - Додайте більше параметрів до функції, які можуть допомогти учням знаходити більше курсів. Доступні параметри API можна знайти тут:\n",
    " - Створіть ще один виклик функції, який враховує додаткову інформацію від учня, наприклад, його рідну мову\n",
    " - Додайте обробку помилок на випадок, якщо виклик функції та/або API не повертає жодного відповідного курсу\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Відмова від відповідальності**:  \nЦей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичний переклад може містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для отримання критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильне тлумачення, що виникли внаслідок використання цього перекладу.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T21:26:16+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "uk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}