{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Створення застосунку для генерації зображень\n",
    "\n",
    "Можливості LLM не обмежуються лише генерацією тексту. Також можна створювати зображення на основі текстових описів. Використання зображень як ще одного виду даних може бути дуже корисним у багатьох сферах: від медичних технологій, архітектури, туризму, розробки ігор тощо. У цьому розділі ми розглянемо дві найпопулярніші моделі для генерації зображень — DALL-E та Midjourney.\n",
    "\n",
    "## Вступ\n",
    "\n",
    "У цьому уроці ми розглянемо:\n",
    "\n",
    "- Генерацію зображень і чому це корисно.\n",
    "- DALL-E та Midjourney: що це таке і як вони працюють.\n",
    "- Як створити власний застосунок для генерації зображень.\n",
    "\n",
    "## Навчальні цілі\n",
    "\n",
    "Після проходження цього уроку ви зможете:\n",
    "\n",
    "- Створити застосунок для генерації зображень.\n",
    "- Визначати межі вашого застосунку за допомогою мета-промптів.\n",
    "- Працювати з DALL-E та Midjourney.\n",
    "\n",
    "## Навіщо створювати застосунок для генерації зображень?\n",
    "\n",
    "Застосунки для генерації зображень — чудовий спосіб дослідити можливості генеративного ШІ. Їх можна використовувати, наприклад, для:\n",
    "\n",
    "- **Редагування та синтезу зображень**. Можна створювати зображення для різних задач, таких як редагування чи синтез зображень.\n",
    "\n",
    "- **Використання у різних галузях**. Також їх можна застосовувати для створення зображень у різних сферах: медтех, туризм, розробка ігор тощо.\n",
    "\n",
    "## Сценарій: Edu4All\n",
    "\n",
    "У цьому уроці ми продовжимо працювати з нашим стартапом Edu4All. Учні створюватимуть зображення для своїх завдань — які саме зображення, вирішують самі учні: це можуть бути ілюстрації до власної казки, новий персонаж для історії або візуалізація ідей та концепцій.\n",
    "\n",
    "Ось приклад, що можуть створити учні Edu4All, якщо вони працюють на уроці над темою пам’яток:\n",
    "\n",
    "![Стартап Edu4All, урок про пам’ятки, Ейфелева вежа](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.uk.png)\n",
    "\n",
    "використовуючи такий промпт:\n",
    "\n",
    "> \"Собака біля Ейфелевої вежі на ранковому сонці\"\n",
    "\n",
    "## Що таке DALL-E та Midjourney?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) та [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) — це дві найпопулярніші моделі для генерації зображень, які дозволяють створювати зображення за допомогою промптів.\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "Почнемо з DALL-E — це генеративна модель ШІ, яка створює зображення на основі текстових описів.\n",
    "\n",
    "> [DALL-E — це поєднання двох моделей: CLIP та diffused attention](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst).\n",
    "\n",
    "- **CLIP** — це модель, яка створює ембедінги, тобто числові представлення даних, зображень і тексту.\n",
    "\n",
    "- **Diffused attention** — це модель, яка генерує зображення з ембедінгів. DALL-E навчена на великій кількості зображень і текстів, і може створювати зображення за текстовими описами. Наприклад, DALL-E може створити зображення кота в капелюсі або собаки з ірокезом.\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney працює схожим чином до DALL-E: генерує зображення за текстовими промптами. Midjourney також можна використовувати для створення зображень за запитами на кшталт “кіт у капелюсі” або “собака з ірокезом”.\n",
    "\n",
    "![Зображення, створене Midjourney, механічний голуб](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*Джерело: Wikipedia, зображення створене Midjourney*\n",
    "\n",
    "## Як працюють DALL-E та Midjourney\n",
    "\n",
    "Почнемо з [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst). DALL-E — це генеративна модель ШІ, побудована на архітектурі трансформерів з *авторегресивним трансформером*.\n",
    "\n",
    "*Авторегресивний трансформер* визначає, як модель створює зображення з текстових описів: вона генерує по одному пікселю за раз, використовуючи вже створені пікселі для наступних, проходячи через кілька шарів нейронної мережі, поки зображення не буде завершене.\n",
    "\n",
    "Завдяки цьому процесу DALL-E може контролювати атрибути, об’єкти, характеристики та інші деталі на створюваному зображенні. Проте DALL-E 2 та 3 дають ще більше контролю над результатом,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Створення вашого першого застосунку для генерації зображень\n",
    "\n",
    "Що потрібно для створення застосунку для генерації зображень? Вам знадобляться такі бібліотеки:\n",
    "\n",
    "- **python-dotenv** — дуже рекомендується використовувати цю бібліотеку, щоб зберігати ваші секрети у файлі *.env* окремо від коду.\n",
    "- **openai** — ця бібліотека потрібна для взаємодії з OpenAI API.\n",
    "- **pillow** — для роботи із зображеннями у Python.\n",
    "- **requests** — допоможе робити HTTP-запити.\n",
    "\n",
    "1. Створіть файл *.env* з таким вмістом:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    Знайдіть цю інформацію в Azure Portal для вашого ресурсу у розділі \"Keys and Endpoint\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Зберіть вищезазначені бібліотеки у файл під назвою *requirements.txt* ось так:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "1. Далі створіть віртуальне середовище та встановіть бібліотеки:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Для Windows використовуйте наступні команди, щоб створити та активувати віртуальне середовище:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. Додайте наступний код у файл з назвою *app.py*:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "Пояснимо цей код:\n",
    "\n",
    "- Спочатку імпортуємо необхідні бібліотеки, зокрема бібліотеку OpenAI, dotenv, requests та Pillow.\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- Далі завантажуємо змінні середовища з файлу *.env*.\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- Після цього задаємо endpoint, ключ для OpenAI API, версію та тип.\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- Далі генеруємо зображення:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    Наведений вище код повертає JSON-об'єкт, який містить URL згенерованого зображення. Ми можемо використати цей URL, щоб завантажити зображення та зберегти його у файл.\n",
    "\n",
    "- Нарешті, відкриваємо зображення та використовуємо стандартний переглядач зображень, щоб його показати:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### Детальніше про генерацію зображення\n",
    "\n",
    "Розглянемо детальніше код, який генерує зображення:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt** — це текстовий запит, який використовується для генерації зображення. У цьому випадку ми використовуємо запит \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\".\n",
    "- **size** — це розмір згенерованого зображення. У цьому прикладі ми створюємо зображення розміром 1024x1024 пікселів.\n",
    "- **n** — це кількість згенерованих зображень. У цьому випадку ми генеруємо два зображення.\n",
    "- **temperature** — це параметр, який визначає ступінь випадковості результату генеративної AI-моделі. Temperature — це значення від 0 до 1, де 0 означає детермінований результат, а 1 — повністю випадковий. Значення за замовчуванням — 0.7.\n",
    "\n",
    "Є ще багато можливостей роботи із зображеннями, які ми розглянемо у наступному розділі.\n",
    "\n",
    "## Додаткові можливості генерації зображень\n",
    "\n",
    "Ви вже побачили, як можна згенерувати зображення за допомогою кількох рядків коду на Python. Проте, з зображеннями можна робити ще більше.\n",
    "\n",
    "Ви також можете:\n",
    "\n",
    "- **Редагувати зображення**. Якщо надати існуюче зображення, маску та текстовий запит, можна змінити зображення. Наприклад, можна додати щось до певної частини зображення. Уявіть наше зображення з кроликом — ви можете додати кролику капелюха. Для цього потрібно надати саме зображення, маску (яка визначає область для змін) і текстовий запит, що описує, що потрібно зробити.\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    Базове зображення міститиме лише кролика, а фінальне — вже з капелюхом на кролику.\n",
    "\n",
    "- **Створювати варіації**.\n",
    "    Дивіться наш [OpenAI notebook для додаткової інформації](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**Відмова від відповідальності**:  \nЦей документ було перекладено за допомогою сервісу автоматичного перекладу [Co-op Translator](https://github.com/Azure/co-op-translator). Хоча ми прагнемо до точності, звертаємо вашу увагу, що автоматичний переклад може містити помилки або неточності. Оригінальний документ рідною мовою слід вважати авторитетним джерелом. Для отримання критично важливої інформації рекомендується професійний людський переклад. Ми не несемо відповідальності за будь-які непорозуміння або неправильне тлумачення, що виникли внаслідок використання цього перекладу.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:27:40+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "uk"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}