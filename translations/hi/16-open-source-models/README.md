<!--
CO_OP_TRANSLATOR_METADATA:
{
  "original_hash": "85b754d4dc980f270f264d17116d9a5f",
  "translation_date": "2025-12-19T13:54:39+00:00",
  "source_file": "16-open-source-models/README.md",
  "language_code": "hi"
}
-->
[![Open Source Models](../../../translated_images/hi/16-lesson-banner.6b56555e8404fda1.webp)](https://youtu.be/CuICgfuHFSg?si=x8SpFRUsIxM9dohN)

## परिचय

ओपन-सोर्स LLMs की दुनिया रोमांचक और लगातार विकसित हो रही है। यह पाठ ओपन सोर्स मॉडल्स पर गहराई से नजर डालने का उद्देश्य रखता है। यदि आप यह जानना चाहते हैं कि मालिकाना मॉडल्स की तुलना में ओपन सोर्स मॉडल्स कैसे हैं, तो ["Exploring and Comparing Different LLMs" पाठ](../02-exploring-and-comparing-different-llms/README.md?WT.mc_id=academic-105485-koreyst) पर जाएं। यह पाठ फाइन-ट्यूनिंग के विषय को भी कवर करेगा, लेकिन अधिक विस्तृत व्याख्या ["Fine-Tuning LLMs" पाठ](../18-fine-tuning/README.md?WT.mc_id=academic-105485-koreyst) में पाई जा सकती है।

## सीखने के लक्ष्य

- ओपन सोर्स मॉडल्स की समझ प्राप्त करना
- ओपन सोर्स मॉडल्स के साथ काम करने के लाभों को समझना
- Hugging Face और Azure AI Studio पर उपलब्ध ओपन मॉडल्स का अन्वेषण करना

## ओपन सोर्स मॉडल्स क्या हैं?

ओपन सोर्स सॉफ़्टवेयर ने विभिन्न क्षेत्रों में प्रौद्योगिकी के विकास में महत्वपूर्ण भूमिका निभाई है। ओपन सोर्स इनिशिएटिव (OSI) ने [10 मानदंड](https://web.archive.org/web/20241126001143/https://opensource.org/osd?WT.mc_id=academic-105485-koreyst) निर्धारित किए हैं जिनके आधार पर सॉफ़्टवेयर को ओपन सोर्स के रूप में वर्गीकृत किया जाता है। स्रोत कोड को OSI द्वारा अनुमोदित लाइसेंस के तहत खुले रूप में साझा किया जाना चाहिए।

जहां LLMs का विकास सॉफ़्टवेयर विकास के समान तत्वों पर आधारित है, प्रक्रिया बिल्कुल समान नहीं है। इसने समुदाय में LLMs के संदर्भ में ओपन सोर्स की परिभाषा पर काफी चर्चा को जन्म दिया है। एक मॉडल को पारंपरिक ओपन सोर्स परिभाषा के अनुरूप माना जाने के लिए निम्नलिखित जानकारी सार्वजनिक रूप से उपलब्ध होनी चाहिए:

- मॉडल को प्रशिक्षित करने के लिए उपयोग किए गए डेटासेट।
- प्रशिक्षण के हिस्से के रूप में पूर्ण मॉडल वज़न।
- मूल्यांकन कोड।
- फाइन-ट्यूनिंग कोड।
- पूर्ण मॉडल वज़न और प्रशिक्षण मेट्रिक्स।

वर्तमान में केवल कुछ मॉडल ही इस मानदंड से मेल खाते हैं। [Allen Institute for Artificial Intelligence (AllenAI) द्वारा बनाया गया OLMo मॉडल](https://huggingface.co/allenai/OLMo-7B?WT.mc_id=academic-105485-koreyst) इस श्रेणी में आता है।

इस पाठ के लिए, हम आगे "ओपन मॉडल्स" शब्द का उपयोग करेंगे क्योंकि ये मॉडल लेखन के समय ऊपर दिए गए मानदंडों से मेल नहीं खा सकते हैं।

## ओपन मॉडल्स के लाभ

**अत्यधिक अनुकूलन योग्य** - चूंकि ओपन मॉडल्स विस्तृत प्रशिक्षण जानकारी के साथ जारी किए जाते हैं, शोधकर्ता और डेवलपर्स मॉडल के आंतरिक हिस्सों को संशोधित कर सकते हैं। इससे विशिष्ट कार्य या अध्ययन क्षेत्र के लिए फाइन-ट्यून किए गए अत्यधिक विशेषज्ञ मॉडल बनाने में मदद मिलती है। इसके कुछ उदाहरण हैं कोड जनरेशन, गणितीय संचालन और जीवविज्ञान।

**लागत** - इन मॉडल्स का उपयोग और तैनाती करने की प्रति टोकन लागत मालिकाना मॉडल्स की तुलना में कम होती है। जनरेटिव AI अनुप्रयोगों का निर्माण करते समय, अपने उपयोग मामले पर इन मॉडल्स के प्रदर्शन बनाम मूल्य को देखना चाहिए।

![Model Cost](../../../translated_images/hi/model-price.3f5a3e4d32ae00b4.webp)
स्रोत: Artificial Analysis

**लचीलापन** - ओपन मॉडल्स के साथ काम करने से आप विभिन्न मॉडल्स का उपयोग करने या उन्हें संयोजित करने में लचीले होते हैं। इसका एक उदाहरण [HuggingChat Assistants](https://huggingface.co/chat?WT.mc_id=academic-105485-koreyst) है जहां उपयोगकर्ता सीधे यूजर इंटरफेस में उपयोग किए जा रहे मॉडल का चयन कर सकता है:

![Choose Model](../../../translated_images/hi/choose-model.f095d15bbac92214.webp)

## विभिन्न ओपन मॉडल्स का अन्वेषण

### Llama 2

[LLama2](https://huggingface.co/meta-llama?WT.mc_id=academic-105485-koreyst), मेटा द्वारा विकसित, एक ओपन मॉडल है जो चैट आधारित अनुप्रयोगों के लिए अनुकूलित है। इसका कारण इसका फाइन-ट्यूनिंग तरीका है, जिसमें बड़ी मात्रा में संवाद और मानव प्रतिक्रिया शामिल थी। इस विधि से मॉडल अधिक ऐसे परिणाम उत्पन्न करता है जो मानव अपेक्षा के अनुरूप होते हैं, जिससे बेहतर उपयोगकर्ता अनुभव मिलता है।

Llama के फाइन-ट्यून किए गए संस्करणों के कुछ उदाहरण हैं [Japanese Llama](https://huggingface.co/elyza/ELYZA-japanese-Llama-2-7b?WT.mc_id=academic-105485-koreyst), जो जापानी भाषा में विशेषज्ञता रखता है, और [Llama Pro](https://huggingface.co/TencentARC/LLaMA-Pro-8B?WT.mc_id=academic-105485-koreyst), जो बेस मॉडल का एक उन्नत संस्करण है।

### Mistral

[Mistral](https://huggingface.co/mistralai?WT.mc_id=academic-105485-koreyst) एक ओपन मॉडल है जो उच्च प्रदर्शन और दक्षता पर केंद्रित है। यह Mixture-of-Experts दृष्टिकोण का उपयोग करता है, जो विशेषज्ञ मॉडल्स के समूह को एक सिस्टम में संयोजित करता है, जहां इनपुट के आधार पर कुछ मॉडल्स का चयन किया जाता है। इससे गणना अधिक प्रभावी होती है क्योंकि मॉडल केवल उन इनपुट्स को संबोधित करते हैं जिनमें वे विशेषज्ञ होते हैं।

Mistral के फाइन-ट्यून किए गए संस्करणों के कुछ उदाहरण हैं [BioMistral](https://huggingface.co/BioMistral/BioMistral-7B?text=Mon+nom+est+Thomas+et+mon+principal?WT.mc_id=academic-105485-koreyst), जो चिकित्सा क्षेत्र पर केंद्रित है, और [OpenMath Mistral](https://huggingface.co/nvidia/OpenMath-Mistral-7B-v0.1-hf?WT.mc_id=academic-105485-koreyst), जो गणितीय गणना करता है।

### Falcon

[Falcon](https://huggingface.co/tiiuae?WT.mc_id=academic-105485-koreyst) एक LLM है जिसे Technology Innovation Institute (**TII**) ने बनाया है। Falcon-40B को 40 बिलियन पैरामीटर पर प्रशिक्षित किया गया था, जिसे GPT-3 की तुलना में कम कंप्यूट बजट के साथ बेहतर प्रदर्शन करने वाला दिखाया गया है। इसका कारण FlashAttention एल्गोरिदम और मल्टीक्वेरी अटेंशन का उपयोग है, जो अनुमान समय पर मेमोरी आवश्यकताओं को कम करता है। इस कम अनुमान समय के साथ, Falcon-40B चैट अनुप्रयोगों के लिए उपयुक्त है।

Falcon के फाइन-ट्यून किए गए संस्करणों के कुछ उदाहरण हैं [OpenAssistant](https://huggingface.co/OpenAssistant/falcon-40b-sft-top1-560?WT.mc_id=academic-105485-koreyst), जो ओपन मॉडल्स पर आधारित एक सहायक है, और [GPT4ALL](https://huggingface.co/nomic-ai/gpt4all-falcon?WT.mc_id=academic-105485-koreyst), जो बेस मॉडल की तुलना में उच्च प्रदर्शन प्रदान करता है।

## कैसे चुनें

ओपन मॉडल चुनने का कोई एक उत्तर नहीं है। शुरू करने के लिए एक अच्छा स्थान Azure AI Studio के टास्क द्वारा फ़िल्टर फीचर का उपयोग करना है। इससे आपको यह समझने में मदद मिलेगी कि मॉडल को किन प्रकार के कार्यों के लिए प्रशिक्षित किया गया है। Hugging Face भी एक LLM लीडरबोर्ड बनाए रखता है जो आपको कुछ मेट्रिक्स के आधार पर सर्वश्रेष्ठ प्रदर्शन करने वाले मॉडल दिखाता है।

विभिन्न प्रकारों के बीच LLMs की तुलना करते समय, [Artificial Analysis](https://artificialanalysis.ai/?WT.mc_id=academic-105485-koreyst) एक और उत्कृष्ट संसाधन है:

![Model Quality](../../../translated_images/hi/model-quality.aaae1c22e00f7ee1.webp)
स्रोत: Artificial Analysis

यदि आप किसी विशिष्ट उपयोग मामले पर काम कर रहे हैं, तो उसी क्षेत्र पर केंद्रित फाइन-ट्यून किए गए संस्करणों की खोज प्रभावी हो सकती है। कई ओपन मॉडल्स के साथ प्रयोग करना यह देखने के लिए कि वे आपकी और आपके उपयोगकर्ताओं की अपेक्षाओं के अनुसार कैसे प्रदर्शन करते हैं, एक अच्छी प्रथा है।

## अगले कदम

ओपन मॉडल्स का सबसे अच्छा हिस्सा यह है कि आप उनके साथ काम करना काफी जल्दी शुरू कर सकते हैं। [Azure AI Foundry Model Catalog](https://ai.azure.com?WT.mc_id=academic-105485-koreyst) देखें, जिसमें Hugging Face का एक विशेष संग्रह है जिसमें ये मॉडल शामिल हैं जिन पर हमने यहां चर्चा की है।

## सीखना यहीं नहीं रुकता, यात्रा जारी रखें

इस पाठ को पूरा करने के बाद, हमारे [Generative AI Learning collection](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) को देखें ताकि आप अपनी जनरेटिव AI ज्ञान को और बढ़ा सकें!

---

<!-- CO-OP TRANSLATOR DISCLAIMER START -->
**अस्वीकरण**:  
यह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ अपनी मूल भाषा में प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सलाह दी जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।
<!-- CO-OP TRANSLATOR DISCLAIMER END -->