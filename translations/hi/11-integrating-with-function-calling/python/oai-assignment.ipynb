{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिचय\n",
    "\n",
    "इस पाठ में शामिल हैं:\n",
    "- फंक्शन कॉलिंग क्या है और इसके उपयोग\n",
    "- OpenAI का उपयोग करके फंक्शन कॉल कैसे बनाएं\n",
    "- किसी एप्लिकेशन में फंक्शन कॉल को कैसे जोड़ें\n",
    "\n",
    "## सीखने के लक्ष्य\n",
    "\n",
    "इस पाठ को पूरा करने के बाद आप जानेंगे और समझेंगे:\n",
    "\n",
    "- फंक्शन कॉलिंग का उद्देश्य क्या है\n",
    "- OpenAI सर्विस का उपयोग करके फंक्शन कॉल सेटअप करना\n",
    "- अपनी एप्लिकेशन के उपयोग के अनुसार प्रभावी फंक्शन कॉल डिज़ाइन करना\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## फ़ंक्शन कॉल्स को समझना\n",
    "\n",
    "इस पाठ के लिए, हम अपनी एजुकेशन स्टार्टअप के लिए एक फीचर बनाना चाहते हैं जिससे यूज़र्स चैटबॉट का इस्तेमाल करके टेक्निकल कोर्स ढूंढ सकें। हम ऐसे कोर्स सुझाएंगे जो उनके स्किल लेवल, मौजूदा रोल और उनकी पसंदीदा टेक्नोलॉजी के अनुसार हों।\n",
    "\n",
    "इसे पूरा करने के लिए हम इनका कॉम्बिनेशन इस्तेमाल करेंगे:\n",
    " - `OpenAI` जिससे यूज़र के लिए चैट एक्सपीरियंस बनाया जा सके\n",
    " - `Microsoft Learn Catalog API` जिससे यूज़र्स अपनी रिक्वेस्ट के आधार पर कोर्स ढूंढ सकें\n",
    " - `Function Calling` जिससे यूज़र की क्वेरी को एक फ़ंक्शन में भेजा जा सके और API रिक्वेस्ट की जा सके\n",
    "\n",
    "शुरुआत करने के लिए, चलिए समझते हैं कि हमें सबसे पहले फ़ंक्शन कॉलिंग की ज़रूरत क्यों पड़ती है:\n",
    "\n",
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT से नया रिस्पॉन्स लें जिसमें वह फ़ंक्शन का रिस्पॉन्स देख सकता है\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फंक्शन कॉलिंग क्यों\n",
    "\n",
    "अगर आपने इस कोर्स का कोई और पाठ पूरा किया है, तो आप शायद समझते होंगे कि बड़े लैंग्वेज मॉडल्स (LLMs) का इस्तेमाल कितना ताकतवर है। उम्मीद है, आप उनकी कुछ सीमाएँ भी देख पाए होंगे।\n",
    "\n",
    "फंक्शन कॉलिंग, OpenAI सर्विस की एक ऐसी सुविधा है जिसे निम्नलिखित चुनौतियों को हल करने के लिए बनाया गया है:\n",
    "\n",
    "असंगत प्रतिक्रिया फॉर्मेटिंग:\n",
    "- फंक्शन कॉलिंग से पहले, बड़े लैंग्वेज मॉडल से मिलने वाली प्रतिक्रियाएँ बिना किसी संरचना के और असंगत होती थीं। डेवलपर्स को हर बार आउटपुट के अलग-अलग रूपों को संभालने के लिए जटिल वैलिडेशन कोड लिखना पड़ता था।\n",
    "\n",
    "बाहरी डेटा के साथ सीमित एकीकरण:\n",
    "- इस सुविधा से पहले, किसी एप्लिकेशन के दूसरे हिस्सों से डेटा को चैट संदर्भ में शामिल करना मुश्किल था।\n",
    "\n",
    "प्रतिक्रिया फॉर्मेट को मानकीकृत करके और बाहरी डेटा के साथ सहज एकीकरण की सुविधा देकर, फंक्शन कॉलिंग डेवलपमेंट को आसान बनाता है और अतिरिक्त वैलिडेशन लॉजिक की जरूरत को कम करता है।\n",
    "\n",
    "यूज़र्स ऐसे सवालों के जवाब नहीं पा सकते थे जैसे \"स्टॉकहोम में अभी मौसम कैसा है?\"। इसका कारण यह था कि मॉडल्स केवल उस समय तक के डेटा तक सीमित थे, जब तक उन पर ट्रेनिंग हुई थी।\n",
    "\n",
    "आइए नीचे दिए गए उदाहरण को देखें, जो इस समस्या को दर्शाता है:\n",
    "\n",
    "मान लीजिए हम छात्रों का एक डेटाबेस बनाना चाहते हैं ताकि हम उन्हें सही कोर्स सुझा सकें। नीचे हमारे पास दो छात्रों के विवरण हैं, जिनमें मौजूद डेटा काफी हद तक समान है।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finshing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम इसे एक LLM को भेजना चाहते हैं ताकि वह डेटा को पार्स कर सके। बाद में इसका उपयोग हमारी एप्लिकेशन में इसे किसी API को भेजने या डेटाबेस में स्टोर करने के लिए किया जा सकता है।\n",
    "\n",
    "आइए दो एक जैसे प्रॉम्प्ट बनाते हैं जिनमें हम LLM को यह निर्देश देते हैं कि हमें किस जानकारी में रुचि है:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम इसे एक LLM को भेजना चाहते हैं ताकि वह हमारे उत्पाद के लिए महत्वपूर्ण हिस्सों को पार्स कर सके। इसलिए हम दो समान प्रॉम्प्ट बना सकते हैं ताकि LLM को निर्देशित किया जा सके:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "इन दो प्रॉम्प्ट्स को बनाने के बाद, हम उन्हें LLM को `openai.ChatCompletion` का उपयोग करके भेजेंगे। हम प्रॉम्प्ट को `messages` वेरिएबल में स्टोर करते हैं और भूमिका को `user` असाइन करते हैं। यह एक उपयोगकर्ता द्वारा चैटबॉट को लिखा गया संदेश दिखाने के लिए किया जाता है।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हालाँकि प्रॉम्प्ट एक जैसे हैं और विवरण भी मिलते-जुलते हैं, फिर भी हमें `Grades` प्रॉपर्टी के अलग-अलग फॉर्मेट मिल सकते हैं।\n",
    "\n",
    "अगर आप ऊपर दिए गए सेल को कई बार चलाएँ, तो फॉर्मेट `3.7` या `3.7 GPA` हो सकता है।\n",
    "\n",
    "ऐसा इसलिए होता है क्योंकि LLM बिना संरचना वाले डेटा को लिखित प्रॉम्प्ट के रूप में लेता है और बिना संरचना वाला डेटा ही लौटाता है। हमें एक संरचित फॉर्मेट की ज़रूरत है ताकि जब हम इस डेटा को स्टोर या इस्तेमाल करें, तो हमें पता हो कि क्या उम्मीद करनी है।\n",
    "\n",
    "फंक्शनल कॉलिंग का इस्तेमाल करके, हम यह सुनिश्चित कर सकते हैं कि हमें वापस संरचित डेटा ही मिले। फंक्शन कॉलिंग का इस्तेमाल करते समय, LLM असल में कोई फंक्शन कॉल या रन नहीं करता। इसके बजाय, हम LLM के जवाबों के लिए एक संरचना बनाते हैं, जिसे उसे फॉलो करना होता है। फिर हम उन्हीं संरचित जवाबों का इस्तेमाल यह जानने के लिए करते हैं कि अपनी एप्लिकेशन में कौन सा फंक्शन चलाना है।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन कॉल्स के उपयोग के मामले\n",
    "\n",
    "**बाहरी टूल्स को कॉल करना**  \n",
    "चैटबॉट्स यूज़र्स के सवालों के जवाब देने में बहुत अच्छे होते हैं। फ़ंक्शन कॉलिंग का इस्तेमाल करके, चैटबॉट्स यूज़र के मैसेज का इस्तेमाल कुछ काम पूरे करने के लिए कर सकते हैं। उदाहरण के लिए, एक छात्र चैटबॉट से कह सकता है, \"मेरे शिक्षक को ईमेल भेजो कि मुझे इस विषय में और मदद चाहिए।\" यह `send_email(to: string, body: string)` नामक फ़ंक्शन को कॉल कर सकता है।\n",
    "\n",
    "**API या डेटाबेस क्वेरी बनाना**  \n",
    "यूज़र्स सामान्य भाषा में जानकारी ढूंढ सकते हैं, जिसे एक फॉर्मेटेड क्वेरी या API रिक्वेस्ट में बदला जा सकता है। उदाहरण के लिए, एक शिक्षक पूछ सकता है, \"कौन से छात्र हैं जिन्होंने पिछला असाइनमेंट पूरा किया?\" यह `get_completed(student_name: string, assignment: int, current_status: string)` नामक फ़ंक्शन को कॉल कर सकता है।\n",
    "\n",
    "**संरचित डेटा बनाना**  \n",
    "यूज़र्स किसी टेक्स्ट ब्लॉक या CSV से महत्वपूर्ण जानकारी निकालने के लिए LLM का इस्तेमाल कर सकते हैं। उदाहरण के लिए, एक छात्र शांति समझौतों पर विकिपीडिया लेख को AI फ्लैश कार्ड्स में बदल सकता है। यह `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` नामक फ़ंक्शन का उपयोग करके किया जा सकता है।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. अपनी पहली फ़ंक्शन कॉल बनाना\n",
    "\n",
    "फ़ंक्शन कॉल बनाने की प्रक्रिया में 3 मुख्य चरण होते हैं:\n",
    "1. अपनी फ़ंक्शनों की सूची और एक उपयोगकर्ता संदेश के साथ Chat Completions API को कॉल करना\n",
    "2. मॉडल की प्रतिक्रिया पढ़ना ताकि कोई कार्रवाई की जा सके, जैसे कि कोई फ़ंक्शन या API कॉल चलाना\n",
    "3. अपने फ़ंक्शन की प्रतिक्रिया के साथ Chat Completions API को फिर से कॉल करना, ताकि उस जानकारी का उपयोग करके उपयोगकर्ता को उत्तर दिया जा सके\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### एक फंक्शन कॉल के तत्व\n",
    "\n",
    "#### उपयोगकर्ता इनपुट\n",
    "\n",
    "पहला कदम है एक उपयोगकर्ता संदेश बनाना। इसे आप टेक्स्ट इनपुट का मान लेकर डायनामिक रूप से असाइन कर सकते हैं या यहां कोई मान असाइन कर सकते हैं। अगर आप पहली बार Chat Completions API के साथ काम कर रहे हैं, तो हमें संदेश का `role` और `content` परिभाषित करना होगा।\n",
    "\n",
    "`role` या तो `system` (नियम बनाना), `assistant` (मॉडल) या `user` (अंतिम उपयोगकर्ता) हो सकता है। फंक्शन कॉलिंग के लिए, हम इसे `user` और एक उदाहरण प्रश्न के रूप में असाइन करेंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन बनाना\n",
    "\n",
    "अब हम एक फ़ंक्शन और उसके पैरामीटर निर्धारित करेंगे। यहाँ हम सिर्फ एक फ़ंक्शन का उपयोग करेंगे जिसका नाम है `search_courses`, लेकिन आप कई फ़ंक्शन बना सकते हैं।\n",
    "\n",
    "**महत्वपूर्ण** : फ़ंक्शन सिस्टम संदेश में LLM को शामिल किए जाते हैं और यह आपके पास उपलब्ध टोकन की संख्या में शामिल होंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**परिभाषाएँ**\n",
    "\n",
    "फंक्शन डिफिनिशन स्ट्रक्चर में कई स्तर होते हैं, और हर स्तर की अपनी कुछ विशेषताएँ होती हैं। यहाँ इस नेस्टेड स्ट्रक्चर का विवरण दिया गया है:\n",
    "\n",
    "**टॉप लेवल फंक्शन प्रॉपर्टीज़:**\n",
    "\n",
    "`name` - उस फंक्शन का नाम जिसे हम कॉल करना चाहते हैं।\n",
    "\n",
    "`description` - यह बताता है कि फंक्शन कैसे काम करता है। यहाँ स्पष्ट और सटीक होना ज़रूरी है।\n",
    "\n",
    "`parameters` - उन मानों और फॉर्मेट की सूची जिन्हें आप चाहते हैं कि मॉडल अपनी प्रतिक्रिया में दे।\n",
    "\n",
    "**Parameters ऑब्जेक्ट की विशेषताएँ:**\n",
    "\n",
    "`type` - पैरामीटर्स ऑब्जेक्ट का डेटा टाइप (आमतौर पर \"object\")\n",
    "\n",
    "`properties` - उन खास मानों की सूची जिन्हें मॉडल अपनी प्रतिक्रिया के लिए इस्तेमाल करेगा\n",
    "\n",
    "**व्यक्तिगत पैरामीटर की विशेषताएँ:**\n",
    "\n",
    "`name` - प्रॉपर्टी की (जैसे \"role\", \"product\", \"level\") के रूप में परोक्ष रूप से परिभाषित\n",
    "\n",
    "`type` - इस खास पैरामीटर का डेटा टाइप (जैसे \"string\", \"number\", \"boolean\")\n",
    "\n",
    "`description` - इस खास पैरामीटर का विवरण\n",
    "\n",
    "**वैकल्पिक विशेषताएँ:**\n",
    "\n",
    "`required` - एक एरे जिसमें वे पैरामीटर्स सूचीबद्ध होते हैं जो फंक्शन कॉल को पूरा करने के लिए ज़रूरी हैं\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन कॉल करना\n",
    "एक फ़ंक्शन परिभाषित करने के बाद, अब हमें इसे Chat Completion API की कॉल में शामिल करना है। हम यह `functions` को अनुरोध में जोड़कर करते हैं। इस मामले में `functions=functions`।\n",
    "\n",
    "यह विकल्प भी है कि `function_call` को `auto` पर सेट किया जाए। इसका मतलब है कि हम LLM को यह तय करने देंगे कि यूज़र के संदेश के आधार पर कौन सा फ़ंक्शन कॉल किया जाए, बजाय इसके कि हम खुद तय करें।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब चलिए प्रतिक्रिया को देखें और देखें कि यह कैसे स्वरूपित है:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "आप देख सकते हैं कि फंक्शन का नाम कॉल किया गया है और उपयोगकर्ता संदेश से, LLM ने फंक्शन के तर्कों के लिए डेटा ढूंढ लिया है।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.एक एप्लिकेशन में फ़ंक्शन कॉल्स को एकीकृत करना\n",
    "\n",
    "जब हमने LLM से प्राप्त फॉर्मेटेड रिस्पॉन्स को टेस्ट कर लिया है, अब हम इसे अपनी एप्लिकेशन में जोड़ सकते हैं।\n",
    "\n",
    "### फ्लो को मैनेज करना\n",
    "\n",
    "इसे अपनी एप्लिकेशन में जोड़ने के लिए, चलिए निम्नलिखित कदम उठाते हैं:\n",
    "\n",
    "सबसे पहले, OpenAI सेवाओं को कॉल करते हैं और संदेश को `response_message` नामक वेरिएबल में स्टोर करते हैं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हम उस फ़ंक्शन को परिभाषित करेंगे जो Microsoft Learn API को कॉल करके पाठ्यक्रमों की सूची प्राप्त करेगा:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "एक सर्वोत्तम अभ्यास के रूप में, हम देखेंगे कि क्या मॉडल कोई फ़ंक्शन कॉल करना चाहता है। इसके बाद, हम उपलब्ध फ़ंक्शनों में से किसी एक को बनाएंगे और उसे उस फ़ंक्शन से मिलाएंगे जिसे कॉल किया जा रहा है।\n",
    "\n",
    "फिर हम फ़ंक्शन के आर्ग्युमेंट्स लेंगे और उन्हें LLM से प्राप्त आर्ग्युमेंट्स से जोड़ेंगे।\n",
    "\n",
    "अंत में, हम फ़ंक्शन कॉल संदेश और `search_courses` संदेश द्वारा लौटाए गए मानों को जोड़ देंगे। इससे LLM को उपयोगकर्ता को प्राकृतिक भाषा में उत्तर देने के लिए सारी जानकारी मिल जाती है।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कोड चैलेंज\n",
    "\n",
    "बहुत बढ़िया! OpenAI Function Calling के बारे में अपनी सीख को आगे बढ़ाने के लिए आप यह बना सकते हैं: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst\n",
    " - फंक्शन के और पैरामीटर जोड़ें, जिससे सीखने वालों को और कोर्स ढूंढने में मदद मिल सके। उपलब्ध API पैरामीटर आप यहाँ देख सकते हैं:\n",
    " - एक और फंक्शन कॉल बनाएं, जिसमें सीखने वाले की मातृभाषा जैसी और जानकारी ली जाए\n",
    " - एरर हैंडलिंग जोड़ें, ताकि अगर फंक्शन कॉल या API कॉल से कोई उपयुक्त कोर्स न मिले, तो सही प्रतिक्रिया दी जा सके\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nयह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। यद्यपि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या गलतियाँ हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को ही प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "09e1959b012099c552c48fe94d66a64b",
   "translation_date": "2025-08-25T20:53:14+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "hi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}