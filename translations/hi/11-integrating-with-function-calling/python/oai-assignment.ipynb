{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## परिचय\n",
    "\n",
    "यह पाठ निम्नलिखित विषयों को कवर करेगा:  \n",
    "- फ़ंक्शन कॉलिंग क्या है और इसके उपयोग के मामले  \n",
    "- OpenAI का उपयोग करके फ़ंक्शन कॉल कैसे बनाएं  \n",
    "- एक एप्लिकेशन में फ़ंक्शन कॉल को कैसे एकीकृत करें  \n",
    "\n",
    "## सीखने के लक्ष्य\n",
    "\n",
    "इस पाठ को पूरा करने के बाद आप जानेंगे और समझेंगे:  \n",
    "\n",
    "- फ़ंक्शन कॉलिंग का उपयोग करने का उद्देश्य  \n",
    "- OpenAI सेवा का उपयोग करके फ़ंक्शन कॉल सेटअप करना  \n",
    "- आपके एप्लिकेशन के उपयोग के मामले के लिए प्रभावी फ़ंक्शन कॉल डिज़ाइन करना\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## फ़ंक्शन कॉल को समझना\n",
    "\n",
    "इस पाठ के लिए, हम अपनी शिक्षा स्टार्टअप के लिए एक फीचर बनाना चाहते हैं जो उपयोगकर्ताओं को तकनीकी पाठ्यक्रम खोजने के लिए एक चैटबॉट का उपयोग करने की अनुमति देता है। हम ऐसे पाठ्यक्रमों की सिफारिश करेंगे जो उनकी कौशल स्तर, वर्तमान भूमिका और रुचि की तकनीक के अनुरूप हों।\n",
    "\n",
    "इसे पूरा करने के लिए हम निम्नलिखित का संयोजन उपयोग करेंगे:\n",
    " - `OpenAI` उपयोगकर्ता के लिए एक चैट अनुभव बनाने के लिए\n",
    " - `Microsoft Learn Catalog API` उपयोगकर्ताओं को उनके अनुरोध के आधार पर पाठ्यक्रम खोजने में मदद करने के लिए\n",
    " - `Function Calling` उपयोगकर्ता के प्रश्न को लेकर उसे एक फ़ंक्शन को भेजने के लिए ताकि API अनुरोध किया जा सके।\n",
    "\n",
    "शुरू करने के लिए, आइए देखें कि हम सबसे पहले फ़ंक्शन कॉलिंग का उपयोग क्यों करना चाहेंगे:\n",
    "\n",
    "print(\"अगले अनुरोध में संदेश:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # GPT से एक नया उत्तर प्राप्त करें जहाँ वह फ़ंक्शन प्रतिक्रिया देख सकता है\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन कॉलिंग क्यों\n",
    "\n",
    "यदि आपने इस कोर्स में कोई अन्य पाठ पूरा किया है, तो आप शायद बड़े भाषा मॉडल (LLMs) का उपयोग करने की शक्ति को समझते हैं। उम्मीद है कि आप उनकी कुछ सीमाओं को भी देख सकते हैं।\n",
    "\n",
    "फ़ंक्शन कॉलिंग OpenAI सेवा की एक विशेषता है जिसे निम्नलिखित चुनौतियों को संबोधित करने के लिए डिज़ाइन किया गया है:\n",
    "\n",
    "असंगत प्रतिक्रिया स्वरूपण:\n",
    "- फ़ंक्शन कॉलिंग से पहले, बड़े भाषा मॉडल से प्रतिक्रियाएँ असंरचित और असंगत होती थीं। डेवलपर्स को आउटपुट में प्रत्येक भिन्नता को संभालने के लिए जटिल सत्यापन कोड लिखना पड़ता था।\n",
    "\n",
    "बाहरी डेटा के साथ सीमित एकीकरण:\n",
    "- इस सुविधा से पहले, किसी चैट संदर्भ में एप्लिकेशन के अन्य हिस्सों से डेटा को शामिल करना कठिन था।\n",
    "\n",
    "प्रतिक्रिया स्वरूपों को मानकीकृत करके और बाहरी डेटा के साथ सहज एकीकरण सक्षम करके, फ़ंक्शन कॉलिंग विकास को सरल बनाता है और अतिरिक्त सत्यापन तर्क की आवश्यकता को कम करता है।\n",
    "\n",
    "उपयोगकर्ता ऐसे उत्तर नहीं प्राप्त कर सकते थे जैसे \"स्टॉकहोम में वर्तमान मौसम क्या है?\"। ऐसा इसलिए था क्योंकि मॉडल केवल उस समय तक के डेटा तक सीमित थे जब उन्हें प्रशिक्षित किया गया था।\n",
    "\n",
    "आइए नीचे दिए गए उदाहरण को देखें जो इस समस्या को दर्शाता है:\n",
    "\n",
    "मान लीजिए हम छात्रों के डेटा का एक डेटाबेस बनाना चाहते हैं ताकि हम उन्हें सही कोर्स सुझा सकें। नीचे हमारे पास दो छात्रों के विवरण हैं जो उनके डेटा में बहुत समान हैं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "student_1_description=\"Emily Johnson is a sophomore majoring in computer science at Duke University. She has a 3.7 GPA. Emily is an active member of the university's Chess Club and Debate Team. She hopes to pursue a career in software engineering after graduating.\"\n",
    " \n",
    "student_2_description = \"Michael Lee is a sophomore majoring in computer science at Stanford University. He has a 3.8 GPA. Michael is known for his programming skills and is an active member of the university's Robotics Club. He hopes to pursue a career in artificial intelligence after finishing his studies.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम इसे डेटा पार्स करने के लिए एक LLM को भेजना चाहते हैं। इसे बाद में हमारे एप्लिकेशन में API को भेजने या डेटाबेस में स्टोर करने के लिए उपयोग किया जा सकता है।\n",
    "\n",
    "आइए दो समान प्रॉम्प्ट बनाएं जिनमें हम LLM को यह निर्देश दें कि हम किस जानकारी में रुचि रखते हैं:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम इसे एक LLM को भेजना चाहते हैं ताकि वह हमारे उत्पाद के लिए महत्वपूर्ण भागों को पार्स कर सके। इसलिए हम LLM को निर्देश देने के लिए दो समान प्रॉम्प्ट बना सकते हैं:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt1 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_1_description}\n",
    "'''\n",
    "\n",
    "\n",
    "prompt2 = f'''\n",
    "Please extract the following information from the given text and return it as a JSON object:\n",
    "\n",
    "name\n",
    "major\n",
    "school\n",
    "grades\n",
    "club\n",
    "\n",
    "This is the body of text to extract the information from:\n",
    "{student_2_description}\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "इन दो प्रॉम्प्ट्स को बनाने के बाद, हम उन्हें `openai.ChatCompletion` का उपयोग करके LLM को भेजेंगे। हम प्रॉम्प्ट को `messages` वेरिएबल में स्टोर करते हैं और भूमिका को `user` असाइन करते हैं। यह एक उपयोगकर्ता द्वारा चैटबॉट को भेजे जाने वाले संदेश की नकल करने के लिए है।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with '/opt/homebrew/bin/python3' requires the ipykernel package.\n",
      "\u001b[1;31mRun the following command to install 'ipykernel' into the Python environment. \n",
      "\u001b[1;31mCommand: '/opt/homebrew/bin/python3 -m pip install ipykernel -U --user --force-reinstall'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "deployment=\"gpt-3.5-turbo\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हम दोनों अनुरोधों को LLM को भेज सकते हैं और प्राप्त प्रतिक्रिया की जांच कर सकते हैं।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response1 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt1}]\n",
    ")\n",
    "openai_response1.choices[0].message.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response2 = client.chat.completions.create(\n",
    " model=deployment,    \n",
    " messages = [{'role': 'user', 'content': prompt2}]\n",
    ")\n",
    "openai_response2.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response1 = json.loads(openai_response1.choices[0].message.content)\n",
    "json_response1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the response as a JSON object\n",
    "json_response2 = json.loads(openai_response2.choices[0].message.content )\n",
    "json_response2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हालांकि प्रॉम्प्ट समान हैं और विवरण भी समान हैं, हम `Grades` प्रॉपर्टी के विभिन्न प्रारूप प्राप्त कर सकते हैं।\n",
    "\n",
    "यदि आप ऊपर दिए गए सेल को कई बार चलाते हैं, तो प्रारूप `3.7` या `3.7 GPA` हो सकता है।\n",
    "\n",
    "यह इसलिए है क्योंकि LLM लिखित प्रॉम्प्ट के रूप में असंरचित डेटा लेता है और असंरचित डेटा भी लौटाता है। हमें एक संरचित प्रारूप चाहिए ताकि हमें पता चले कि इस डेटा को संग्रहित या उपयोग करते समय क्या अपेक्षा करनी है।\n",
    "\n",
    "फंक्शनल कॉलिंग का उपयोग करके, हम सुनिश्चित कर सकते हैं कि हमें संरचित डेटा वापस मिले। फंक्शन कॉलिंग का उपयोग करते समय, LLM वास्तव में कोई फंक्शन कॉल या रन नहीं करता। इसके बजाय, हम LLM के लिए उसके उत्तरों के लिए एक संरचना बनाते हैं। फिर हम उन संरचित उत्तरों का उपयोग यह जानने के लिए करते हैं कि हमारे एप्लिकेशन में कौन सा फंक्शन चलाना है।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![फ़ंक्शन कॉलिंग फ्लो डायग्राम](../../../../translated_images/Function-Flow.083875364af4f4bb69bd6f6ed94096a836453183a71cf22388f50310ad6404de.hi.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "हम फिर उस फ़ंक्शन से प्राप्त परिणाम को लेकर इसे LLM को वापस भेज सकते हैं। LLM तब प्राकृतिक भाषा का उपयोग करके उपयोगकर्ता के प्रश्न का उत्तर देगा।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन कॉल का उपयोग करने के लिए उपयोग के मामले\n",
    "\n",
    "**बाहरी टूल कॉल करना**  \n",
    "चैटबॉट उपयोगकर्ताओं के प्रश्नों के उत्तर प्रदान करने में उत्कृष्ट होते हैं। फ़ंक्शन कॉलिंग का उपयोग करके, चैटबॉट उपयोगकर्ताओं के संदेशों का उपयोग कुछ कार्यों को पूरा करने के लिए कर सकते हैं। उदाहरण के लिए, एक छात्र चैटबॉट से कह सकता है \"मेरे शिक्षक को ईमेल भेजो कि मुझे इस विषय में अधिक सहायता चाहिए\"। यह `send_email(to: string, body: string)` नामक फ़ंक्शन कॉल कर सकता है।\n",
    "\n",
    "**एपीआई या डेटाबेस क्वेरी बनाना**  \n",
    "उपयोगकर्ता प्राकृतिक भाषा का उपयोग करके जानकारी खोज सकते हैं जिसे एक स्वरूपित क्वेरी या एपीआई अनुरोध में परिवर्तित किया जाता है। इसका एक उदाहरण एक शिक्षक हो सकता है जो पूछता है \"वे छात्र कौन हैं जिन्होंने अंतिम असाइनमेंट पूरा किया है\" जो `get_completed(student_name: string, assignment: int, current_status: string)` नामक फ़ंक्शन कॉल कर सकता है।\n",
    "\n",
    "**संरचित डेटा बनाना**  \n",
    "उपयोगकर्ता एक टेक्स्ट ब्लॉक या CSV लेकर LLM का उपयोग करके उसमें से महत्वपूर्ण जानकारी निकाल सकते हैं। उदाहरण के लिए, एक छात्र शांति समझौतों के बारे में विकिपीडिया लेख को AI फ्लैश कार्ड बनाने के लिए परिवर्तित कर सकता है। यह `get_important_facts(agreement_name: string, date_signed: string, parties_involved: list)` नामक फ़ंक्शन का उपयोग करके किया जा सकता है।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. अपनी पहली फ़ंक्शन कॉल बनाना\n",
    "\n",
    "फ़ंक्शन कॉल बनाने की प्रक्रिया में 3 मुख्य चरण शामिल हैं:  \n",
    "1. अपनी फ़ंक्शंस की सूची और एक उपयोगकर्ता संदेश के साथ Chat Completions API को कॉल करना  \n",
    "2. मॉडल की प्रतिक्रिया पढ़ना ताकि कोई क्रिया की जा सके जैसे कि फ़ंक्शन या API कॉल को निष्पादित करना  \n",
    "3. अपनी फ़ंक्शन से प्राप्त प्रतिक्रिया के साथ Chat Completions API को फिर से कॉल करना ताकि उस जानकारी का उपयोग करके उपयोगकर्ता को प्रतिक्रिया बनाई जा सके।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![फंक्शन कॉल का प्रवाह](../../../../translated_images/LLM-Flow.3285ed8caf4796d7343c02927f52c9d32df59e790f6e440568e2e951f6ffa5fd.hi.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### एक फ़ंक्शन कॉल के तत्व\n",
    "\n",
    "#### उपयोगकर्ता इनपुट\n",
    "\n",
    "पहला कदम एक उपयोगकर्ता संदेश बनाना है। इसे एक टेक्स्ट इनपुट के मान को लेकर गतिशील रूप से असाइन किया जा सकता है या आप यहाँ एक मान असाइन कर सकते हैं। यदि यह आपकी पहली बार है जब आप Chat Completions API के साथ काम कर रहे हैं, तो हमें संदेश की `role` और `content` को परिभाषित करना होगा।\n",
    "\n",
    "`role` या तो `system` (नियम बनाना), `assistant` (मॉडल) या `user` (अंत उपयोगकर्ता) हो सकता है। फ़ंक्शन कॉलिंग के लिए, हम इसे `user` के रूप में असाइन करेंगे और एक उदाहरण प्रश्न देंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages= [ {\"role\": \"user\", \"content\": \"Find me a good course for a beginner student to learn Azure.\"} ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन बनाना।\n",
    "\n",
    "अगले चरण में हम एक फ़ंक्शन और उस फ़ंक्शन के पैरामीटर को परिभाषित करेंगे। यहाँ हम केवल एक फ़ंक्शन `search_courses` का उपयोग करेंगे, लेकिन आप कई फ़ंक्शन बना सकते हैं।\n",
    "\n",
    "**महत्वपूर्ण** : फ़ंक्शन सिस्टम संदेश में LLM को शामिल किए जाते हैं और आपके उपलब्ध टोकन की मात्रा में शामिल होंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions = [\n",
    "   {\n",
    "      \"name\":\"search_courses\",\n",
    "      \"description\":\"Retrieves courses from the search index based on the parameters provided\",\n",
    "      \"parameters\":{\n",
    "         \"type\":\"object\",\n",
    "         \"properties\":{\n",
    "            \"role\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The role of the learner (i.e. developer, data scientist, student, etc.)\"\n",
    "            },\n",
    "            \"product\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The product that the lesson is covering (i.e. Azure, Power BI, etc.)\"\n",
    "            },\n",
    "            \"level\":{\n",
    "               \"type\":\"string\",\n",
    "               \"description\":\"The level of experience the learner has prior to taking the course (i.e. beginner, intermediate, advanced)\"\n",
    "            }\n",
    "         },\n",
    "         \"required\":[\n",
    "            \"role\"\n",
    "         ]\n",
    "      }\n",
    "   }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**परिभाषाएँ** \n",
    "\n",
    "फ़ंक्शन परिभाषा संरचना में कई स्तर होते हैं, जिनमें से प्रत्येक की अपनी विशेषताएँ होती हैं। यहाँ नेस्टेड संरचना का एक विवरण है:\n",
    "\n",
    "**शीर्ष स्तर फ़ंक्शन गुण:**\n",
    "\n",
    "`name` - उस फ़ंक्शन का नाम जिसे हम कॉल करना चाहते हैं। \n",
    "\n",
    "`description` - यह फ़ंक्शन कैसे काम करता है इसका विवरण। यहाँ स्पष्ट और विशिष्ट होना महत्वपूर्ण है। \n",
    "\n",
    "`parameters` - उन मानों और प्रारूपों की सूची जो आप चाहते हैं कि मॉडल अपनी प्रतिक्रिया में उत्पन्न करे। \n",
    "\n",
    "**पैरामीटर ऑब्जेक्ट गुण:**\n",
    "\n",
    "`type` - पैरामीटर ऑब्जेक्ट का डेटा प्रकार (आमतौर पर \"object\")\n",
    "\n",
    "`properties` - विशिष्ट मानों की सूची जिन्हें मॉडल अपनी प्रतिक्रिया के लिए उपयोग करेगा। \n",
    "\n",
    "**व्यक्तिगत पैरामीटर गुण:**\n",
    "\n",
    "`name` - प्रॉपर्टी कुंजी द्वारा निहित रूप से परिभाषित (जैसे, \"role\", \"product\", \"level\")\n",
    "\n",
    "`type` - इस विशिष्ट पैरामीटर का डेटा प्रकार (जैसे, \"string\", \"number\", \"boolean\") \n",
    "\n",
    "`description` - विशिष्ट पैरामीटर का विवरण \n",
    "\n",
    "**वैकल्पिक गुण:**\n",
    "\n",
    "`required` - एक सूची जो बताती है कि फ़ंक्शन कॉल को पूरा करने के लिए कौन से पैरामीटर आवश्यक हैं।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### फ़ंक्शन कॉल करना  \n",
    "एक फ़ंक्शन को परिभाषित करने के बाद, अब हमें इसे Chat Completion API कॉल में शामिल करना होगा। हम ऐसा अनुरोध में `functions` जोड़कर करते हैं। इस मामले में `functions=functions`।  \n",
    "\n",
    "`function_call` को `auto` सेट करने का भी विकल्प है। इसका मतलब है कि हम यह तय करने के बजाय कि कौन सा फ़ंक्शन कॉल किया जाना चाहिए, इसे उपयोगकर्ता संदेश के आधार पर LLM पर छोड़ देंगे।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(model=deployment, \n",
    "                                        messages=messages,\n",
    "                                        functions=functions, \n",
    "                                        function_call=\"auto\") \n",
    "\n",
    "print(response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब आइए प्रतिक्रिया को देखें और देखें कि यह कैसे स्वरूपित है:\n",
    "\n",
    "{\n",
    "  \"role\": \"assistant\",\n",
    "  \"function_call\": {\n",
    "    \"name\": \"search_courses\",\n",
    "    \"arguments\": \"{\\n  \\\"role\\\": \\\"student\\\",\\n  \\\"product\\\": \\\"Azure\\\",\\n  \\\"level\\\": \\\"beginner\\\"\\n}\"\n",
    "  }\n",
    "}\n",
    "\n",
    "आप देख सकते हैं कि फ़ंक्शन का नाम कॉल किया गया है और उपयोगकर्ता संदेश से, LLM फ़ंक्शन के तर्कों के लिए डेटा खोजने में सक्षम था।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.एक एप्लिकेशन में फ़ंक्शन कॉल्स को एकीकृत करना।\n",
    "\n",
    "\n",
    "जब हमने LLM से प्राप्त स्वरूपित प्रतिक्रिया का परीक्षण कर लिया है, तो अब हम इसे एक एप्लिकेशन में एकीकृत कर सकते हैं।\n",
    "\n",
    "### प्रवाह का प्रबंधन\n",
    "\n",
    "इसे हमारे एप्लिकेशन में एकीकृत करने के लिए, आइए निम्नलिखित कदम उठाएं:\n",
    "\n",
    "सबसे पहले, OpenAI सेवाओं को कॉल करें और संदेश को `response_message` नामक एक वेरिएबल में संग्रहीत करें।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_message = response.choices[0].message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हम वह फ़ंक्शन परिभाषित करेंगे जो Microsoft Learn API को कॉल करेगा ताकि पाठ्यक्रमों की सूची प्राप्त की जा सके:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_courses(role, product, level):\n",
    "    url = \"https://learn.microsoft.com/api/catalog/\"\n",
    "    params = {\n",
    "        \"role\": role,\n",
    "        \"product\": product,\n",
    "        \"level\": level\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    modules = response.json()[\"modules\"]\n",
    "    results = []\n",
    "    for module in modules[:5]:\n",
    "        title = module[\"title\"]\n",
    "        url = module[\"url\"]\n",
    "        results.append({\"title\": title, \"url\": url})\n",
    "    return str(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "एक सर्वोत्तम अभ्यास के रूप में, हम तब देखेंगे कि क्या मॉडल किसी फ़ंक्शन को कॉल करना चाहता है। उसके बाद, हम उपलब्ध फ़ंक्शनों में से एक बनाएंगे और उसे उस फ़ंक्शन से मिलाएंगे जिसे कॉल किया जा रहा है।  \n",
    "फिर हम फ़ंक्शन के तर्क लेंगे और उन्हें LLM के तर्कों से मैप करेंगे।\n",
    "\n",
    "अंत में, हम फ़ंक्शन कॉल संदेश और `search_courses` संदेश द्वारा लौटाए गए मानों को जोड़ेंगे। इससे LLM को वह सारी जानकारी मिल जाती है जिसकी उसे उपयोगकर्ता को प्राकृतिक भाषा में उत्तर देने के लिए आवश्यकता होती है।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the model wants to call a function\n",
    "if response_message.function_call.name:\n",
    "    print(\"Recommended Function call:\")\n",
    "    print(response_message.function_call.name)\n",
    "    print()\n",
    "\n",
    "    # Call the function. \n",
    "    function_name = response_message.function_call.name\n",
    "\n",
    "    available_functions = {\n",
    "            \"search_courses\": search_courses,\n",
    "    }\n",
    "    function_to_call = available_functions[function_name] \n",
    "\n",
    "    function_args = json.loads(response_message.function_call.arguments)\n",
    "    function_response = function_to_call(**function_args)\n",
    "\n",
    "    print(\"Output of function call:\")\n",
    "    print(function_response)\n",
    "    print(type(function_response))\n",
    "\n",
    "\n",
    "    # Add the assistant response and function response to the messages\n",
    "    messages.append( # adding assistant response to messages\n",
    "        {\n",
    "            \"role\": response_message.role,\n",
    "            \"function_call\": {\n",
    "                \"name\": function_name,\n",
    "                \"arguments\": response_message.function_call.arguments,\n",
    "            },\n",
    "            \"content\": None\n",
    "        }\n",
    "    )\n",
    "    messages.append( # adding function response to messages\n",
    "        {\n",
    "            \"role\": \"function\",\n",
    "            \"name\": function_name,\n",
    "            \"content\":function_response,\n",
    "        }\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "अब हम अपडेट किया गया संदेश LLM को भेजेंगे ताकि हमें API JSON स्वरूपित प्रतिक्रिया के बजाय एक प्राकृतिक भाषा प्रतिक्रिया प्राप्त हो सके।\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Messages in next request:\")\n",
    "print(messages)\n",
    "print()\n",
    "\n",
    "second_response = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=deployment,\n",
    "    function_call=\"auto\",\n",
    "    functions=functions,\n",
    "    temperature=0\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "\n",
    "\n",
    "print(second_response.choices[0].message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## कोड चुनौती\n",
    "\n",
    "शानदार काम! OpenAI फ़ंक्शन कॉलिंग सीखना जारी रखने के लिए आप बना सकते हैं: https://learn.microsoft.com/training/support/catalog-api-developer-reference?WT.mc_id=academic-105485-koreyst  \n",
    " - फ़ंक्शन के और भी पैरामीटर जो शिक्षार्थियों को और अधिक पाठ्यक्रम खोजने में मदद कर सकते हैं। आप उपलब्ध API पैरामीटर यहाँ पा सकते हैं:  \n",
    " - एक और फ़ंक्शन कॉल बनाएं जो शिक्षार्थी से उनकी मातृभाषा जैसी अधिक जानकारी ले  \n",
    " - जब फ़ंक्शन कॉल और/या API कॉल कोई उपयुक्त पाठ्यक्रम वापस न करे तो त्रुटि हैंडलिंग बनाएं\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n\n<!-- CO-OP TRANSLATOR DISCLAIMER START -->\n**अस्वीकरण**:  \nयह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। जबकि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या अशुद्धियाँ हो सकती हैं। मूल दस्तावेज़ अपनी मूल भाषा में ही अधिकारिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सलाह दी जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम जिम्मेदार नहीं हैं।\n<!-- CO-OP TRANSLATOR DISCLAIMER END -->\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "5c4a2a2529177c571be9a5a371d7242b",
   "translation_date": "2025-12-19T09:35:14+00:00",
   "source_file": "11-integrating-with-function-calling/python/oai-assignment.ipynb",
   "language_code": "hi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}