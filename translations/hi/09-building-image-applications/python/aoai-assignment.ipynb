{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# इमेज जेनरेशन एप्लिकेशन बनाना\n",
    "\n",
    "LLMs सिर्फ टेक्स्ट जेनरेशन तक सीमित नहीं हैं। आप टेक्स्ट डिस्क्रिप्शन से इमेज भी बना सकते हैं। इमेज को एक मोडालिटी के रूप में इस्तेमाल करना कई क्षेत्रों में बहुत फायदेमंद हो सकता है, जैसे मेडटेक, आर्किटेक्चर, टूरिज्म, गेम डेवलपमेंट आदि। इस चैप्टर में हम दो सबसे लोकप्रिय इमेज जेनरेशन मॉडल्स, DALL-E और Midjourney के बारे में जानेंगे।\n",
    "\n",
    "## परिचय\n",
    "\n",
    "इस लेसन में हम कवर करेंगे:\n",
    "\n",
    "- इमेज जेनरेशन और यह क्यों उपयोगी है।\n",
    "- DALL-E और Midjourney, ये क्या हैं और कैसे काम करते हैं।\n",
    "- आप इमेज जेनरेशन ऐप कैसे बना सकते हैं।\n",
    "\n",
    "## लर्निंग गोल्स\n",
    "\n",
    "इस लेसन को पूरा करने के बाद, आप सक्षम होंगे:\n",
    "\n",
    "- एक इमेज जेनरेशन एप्लिकेशन बनाना।\n",
    "- अपने एप्लिकेशन के लिए मेटा प्रॉम्प्ट्स के साथ सीमाएँ तय करना।\n",
    "- DALL-E और Midjourney के साथ काम करना।\n",
    "\n",
    "## इमेज जेनरेशन एप्लिकेशन क्यों बनाएं?\n",
    "\n",
    "इमेज जेनरेशन एप्लिकेशन जनरेटिव एआई की क्षमताओं को एक्सप्लोर करने का शानदार तरीका हैं। इन्हें कई तरह से इस्तेमाल किया जा सकता है, जैसे:\n",
    "\n",
    "- **इमेज एडिटिंग और सिंथेसिस**। आप कई यूज़ केस के लिए इमेज बना सकते हैं, जैसे इमेज एडिटिंग और इमेज सिंथेसिस।\n",
    "\n",
    "- **कई इंडस्ट्रीज़ में इस्तेमाल**। इन्हें मेडटेक, टूरिज्म, गेम डेवलपमेंट जैसी कई इंडस्ट्रीज़ के लिए इमेज बनाने में भी इस्तेमाल किया जा सकता है।\n",
    "\n",
    "## परिदृश्य: Edu4All\n",
    "\n",
    "इस लेसन के हिस्से के रूप में, हम अपने स्टार्टअप Edu4All के साथ काम करना जारी रखेंगे। छात्र अपनी असाइनमेंट्स के लिए इमेज बनाएंगे, कौन सी इमेज बनानी है यह छात्रों पर निर्भर है, वे अपनी खुद की परियों की कहानी के लिए इलस्ट्रेशन बना सकते हैं, अपनी कहानी के लिए नया कैरेक्टर बना सकते हैं या अपने आइडियाज और कॉन्सेप्ट्स को विज़ुअलाइज़ करने में मदद ले सकते हैं।\n",
    "\n",
    "उदाहरण के लिए, अगर Edu4All के छात्र क्लास में मोन्युमेंट्स पर काम कर रहे हैं, तो वे कुछ ऐसा बना सकते हैं:\n",
    "\n",
    "![Edu4All स्टार्टअप, मोन्युमेंट्स पर क्लास, एफिल टॉवर](../../../../translated_images/startup.94d6b79cc4bb3f5afbf6e2ddfcf309aa5d1e256b5f30cc41d252024eaa9cc5dc.hi.png)\n",
    "\n",
    "ऐसे प्रॉम्प्ट का इस्तेमाल करते हुए\n",
    "\n",
    "> \"सुबह की हल्की धूप में एफिल टॉवर के पास कुत्ता\"\n",
    "\n",
    "## DALL-E और Midjourney क्या हैं?\n",
    "\n",
    "[DALL-E](https://openai.com/dall-e-2?WT.mc_id=academic-105485-koreyst) और [Midjourney](https://www.midjourney.com/?WT.mc_id=academic-105485-koreyst) दो सबसे लोकप्रिय इमेज जेनरेशन मॉडल्स हैं, जो आपको प्रॉम्प्ट्स का इस्तेमाल करके इमेज बनाने की सुविधा देते हैं।\n",
    "\n",
    "### DALL-E\n",
    "\n",
    "आइए DALL-E से शुरू करते हैं, जो एक जनरेटिव एआई मॉडल है जो टेक्स्ट डिस्क्रिप्शन से इमेज बनाता है।\n",
    "\n",
    "> [DALL-E दो मॉडल्स, CLIP और डिफ्यूज्ड अटेंशन का कॉम्बिनेशन है](https://towardsdatascience.com/openais-dall-e-and-clip-101-a-brief-introduction-3a4367280d4e?WT.mc_id=academic-105485-koreyst)।\n",
    "\n",
    "- **CLIP**, एक ऐसा मॉडल है जो इमेज और टेक्स्ट से एम्बेडिंग्स बनाता है, जो डेटा का न्यूमेरिकल रिप्रेजेंटेशन होता है।\n",
    "\n",
    "- **डिफ्यूज्ड अटेंशन**, एक ऐसा मॉडल है जो एम्बेडिंग्स से इमेज बनाता है। DALL-E को इमेज और टेक्स्ट के डेटासेट पर ट्रेन किया गया है और इसे टेक्स्ट डिस्क्रिप्शन से इमेज बनाने के लिए इस्तेमाल किया जा सकता है। उदाहरण के लिए, DALL-E का इस्तेमाल टोपी पहने बिल्ली या मोहॉक वाले कुत्ते की इमेज बनाने के लिए किया जा सकता है।\n",
    "\n",
    "### Midjourney\n",
    "\n",
    "Midjourney भी DALL-E की तरह ही काम करता है, यह टेक्स्ट प्रॉम्प्ट्स से इमेज बनाता है। Midjourney का इस्तेमाल भी ऐसे प्रॉम्प्ट्स के साथ किया जा सकता है जैसे “टोपी में बिल्ली” या “मोहॉक वाला कुत्ता”।\n",
    "\n",
    "![Midjourney द्वारा बनाई गई इमेज, मैकेनिकल कबूतर](https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png/440px-Rupert_Breheny_mechanical_dove_eca144e7-476d-4976-821d-a49c408e4f36.png?WT.mc_id=academic-105485-koreyst)\n",
    "\n",
    "*इमेज क्रेडिट: विकिपीडिया, इमेज Midjourney द्वारा जनरेट की गई*\n",
    "\n",
    "## DALL-E और Midjourney कैसे काम करते हैं\n",
    "\n",
    "सबसे पहले, [DALL-E](https://arxiv.org/pdf/2102.12092.pdf?WT.mc_id=academic-105485-koreyst)। DALL-E एक जनरेटिव एआई मॉडल है जो ट्रांसफॉर्मर आर्किटेक्चर पर आधारित है, जिसमें *ऑटोरिग्रेसिव ट्रांसफॉर्मर* होता है।\n",
    "\n",
    "*ऑटोरिग्रेसिव ट्रांसफॉर्मर* यह तय करता है कि मॉडल टेक्स्ट डिस्क्रिप्शन से इमेज कैसे बनाएगा, यह एक बार में एक पिक्सल बनाता है, और फिर बने हुए पिक्सल्स का इस्तेमाल अगला पिक्सल बनाने के लिए करता है। यह न्यूरल नेटवर्क की कई लेयर्स से गुजरता है, जब तक इमेज पूरी नहीं हो जाती।\n",
    "\n",
    "इस प्रक्रिया के साथ, DALL-E इमेज में एट्रिब्यूट्स, ऑब्जेक्ट्स, कैरेक्टरिस्टिक्स आदि को कंट्रोल करता है। हालांकि, DALL-E 2 और 3 में जनरेट की गई इमेज पर और भी ज्यादा कंट्रोल होता है,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## अपनी पहली इमेज जनरेशन एप्लिकेशन बनाना\n",
    "\n",
    "तो इमेज जनरेशन एप्लिकेशन बनाने के लिए आपको क्या चाहिए? आपको ये लाइब्रेरीज़ चाहिए:\n",
    "\n",
    "- **python-dotenv**, इस लाइब्रेरी का इस्तेमाल करना बहुत फायदेमंद है ताकि आप अपने सीक्रेट्स को कोड से अलग *.env* फाइल में रख सकें।\n",
    "- **openai**, इस लाइब्रेरी की मदद से आप OpenAI API के साथ इंटरैक्ट कर सकते हैं।\n",
    "- **pillow**, Python में इमेज के साथ काम करने के लिए।\n",
    "- **requests**, HTTP रिक्वेस्ट भेजने में मदद करता है।\n",
    "\n",
    "1. एक *.env* फाइल बनाएं जिसमें ये कंटेंट हो:\n",
    "\n",
    "    ```text\n",
    "    AZURE_OPENAI_ENDPOINT=<your endpoint>\n",
    "    AZURE_OPENAI_API_KEY=<your key>\n",
    "    ```\n",
    "\n",
    "    यह जानकारी अपने Azure Portal में अपने रिसोर्स के \"Keys and Endpoint\" सेक्शन में देखें।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ऊपर दी गई लाइब्रेरीज़ को *requirements.txt* नाम की एक फाइल में इस तरह इकट्ठा करें:\n",
    "\n",
    "    ```text\n",
    "    python-dotenv\n",
    "    openai\n",
    "    pillow\n",
    "    requests\n",
    "    ```\n",
    "\n",
    "\n",
    "1. अब, वर्चुअल एनवायरनमेंट बनाएं और लाइब्रेरीज़ इंस्टॉल करें:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# create virtual env\n",
    "! python3 -m venv venv\n",
    "# activate environment\n",
    "! source venv/bin/activate\n",
    "# install libraries\n",
    "# pip install -r requirements.txt, if using a requirements.txt file \n",
    "! pip install python-dotenv openai pillow requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> [!NOTE]\n",
    "> Windows के लिए, अपनी वर्चुअल एनवायरनमेंट बनाने और एक्टिवेट करने के लिए निम्नलिखित कमांड्स का उपयोग करें:\n",
    "\n",
    "    ```bash\n",
    "    python3 -m venv venv\n",
    "    venv\\Scripts\\activate.bat\n",
    "    ```\n",
    "\n",
    "1. *app.py* नाम की फाइल में निम्नलिखित कोड जोड़ें:\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    \n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    \n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY']     \n",
    "    \n",
    "    # Assign the API version (DALL-E is currently supported for the 2023-06-01-preview API version only)\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    \n",
    "    \n",
    "    try:\n",
    "        # Create an image by using the image generation API\n",
    "        generation_response = openai.Image.create(\n",
    "            prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "            size='1024x1024',\n",
    "            n=2,\n",
    "            temperature=0,\n",
    "        )\n",
    "        # Set the directory for the stored image\n",
    "        image_dir = os.path.join(os.curdir, 'images')\n",
    "    \n",
    "        # If the directory doesn't exist, create it\n",
    "        if not os.path.isdir(image_dir):\n",
    "            os.mkdir(image_dir)\n",
    "    \n",
    "        # Initialize the image path (note the filetype should be png)\n",
    "        image_path = os.path.join(image_dir, 'generated-image.png')\n",
    "    \n",
    "        # Retrieve the generated image\n",
    "        image_url = generation_response[\"data\"][0][\"url\"]  # extract image URL from response\n",
    "        generated_image = requests.get(image_url).content  # download the image\n",
    "        with open(image_path, \"wb\") as image_file:\n",
    "            image_file.write(generated_image)\n",
    "    \n",
    "        # Display the image in the default image viewer\n",
    "        image = Image.open(image_path)\n",
    "        image.show()\n",
    "    \n",
    "    # catch exceptions\n",
    "    except openai.InvalidRequestError as err:\n",
    "        print(err)\n",
    "\n",
    "    ```\n",
    "\n",
    "आइए इस कोड को समझते हैं:\n",
    "\n",
    "- सबसे पहले, हम जिन लाइब्रेरीज़ की ज़रूरत है, उन्हें इम्पोर्ट करते हैं, जिसमें OpenAI लाइब्रेरी, dotenv लाइब्रेरी, requests लाइब्रेरी और Pillow लाइब्रेरी शामिल हैं।\n",
    "\n",
    "    ```python\n",
    "    import openai\n",
    "    import os\n",
    "    import requests\n",
    "    from PIL import Image\n",
    "    import dotenv\n",
    "    ```\n",
    "\n",
    "- इसके बाद, हम *.env* फाइल से environment variables लोड करते हैं।\n",
    "\n",
    "    ```python\n",
    "    # import dotenv\n",
    "    dotenv.load_dotenv()\n",
    "    ```\n",
    "\n",
    "- उसके बाद, हम OpenAI API के लिए endpoint, key, version और type सेट करते हैं।\n",
    "\n",
    "    ```python\n",
    "    # Get endpoint and key from environment variables\n",
    "    openai.api_base = os.environ['AZURE_OPENAI_ENDPOINT']\n",
    "    openai.api_key = os.environ['AZURE_OPENAI_API_KEY'] \n",
    "\n",
    "    # add version and type, Azure specific\n",
    "    openai.api_version = '2023-06-01-preview'\n",
    "    openai.api_type = 'azure'\n",
    "    ```\n",
    "\n",
    "- अब, हम इमेज जेनरेट करते हैं:\n",
    "\n",
    "    ```python\n",
    "    # Create an image by using the image generation API\n",
    "    generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "    ```\n",
    "\n",
    "    ऊपर दिया गया कोड एक JSON ऑब्जेक्ट के साथ रिस्पॉन्ड करता है जिसमें जेनरेट की गई इमेज का URL होता है। हम इस URL का उपयोग करके इमेज डाउनलोड कर सकते हैं और उसे फाइल में सेव कर सकते हैं।\n",
    "\n",
    "- अंत में, हम इमेज को खोलते हैं और उसे देखने के लिए स्टैंडर्ड इमेज व्यूअर का उपयोग करते हैं:\n",
    "\n",
    "    ```python\n",
    "    image = Image.open(image_path)\n",
    "    image.show()\n",
    "    ```\n",
    "\n",
    "### इमेज जेनरेट करने के बारे में और जानकारी\n",
    "\n",
    "आइए उस कोड को विस्तार से देखें जो इमेज जेनरेट करता है:\n",
    "\n",
    "```python\n",
    "generation_response = openai.Image.create(\n",
    "        prompt='Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils',    # Enter your prompt text here\n",
    "        size='1024x1024',\n",
    "        n=2,\n",
    "        temperature=0,\n",
    "    )\n",
    "```\n",
    "\n",
    "- **prompt**, वह टेक्स्ट प्रॉम्प्ट है जिसका उपयोग इमेज जेनरेट करने के लिए किया जाता है। इस उदाहरण में, हम \"Bunny on horse, holding a lollipop, on a foggy meadow where it grows daffodils\" प्रॉम्प्ट का उपयोग कर रहे हैं।\n",
    "- **size**, वह साइज है जो जेनरेट की गई इमेज का होगा। इस केस में, हम 1024x1024 पिक्सल की इमेज बना रहे हैं।\n",
    "- **n**, वह संख्या है जितनी इमेजेज जेनरेट होंगी। इस केस में, हम दो इमेजेज बना रहे हैं।\n",
    "- **temperature**, यह एक पैरामीटर है जो Generative AI मॉडल के आउटपुट की रैंडमनेस को कंट्रोल करता है। temperature 0 और 1 के बीच एक वैल्यू होती है, जहाँ 0 का मतलब है आउटपुट पूरी तरह डिटरमिनिस्टिक है और 1 का मतलब है आउटपुट पूरी तरह रैंडम है। डिफ़ॉल्ट वैल्यू 0.7 है।\n",
    "\n",
    "इमेजेज के साथ आप और भी बहुत कुछ कर सकते हैं, जिसे हम अगले सेक्शन में कवर करेंगे।\n",
    "\n",
    "## इमेज जेनरेशन की अतिरिक्त क्षमताएँ\n",
    "\n",
    "अब तक आपने देखा कि कैसे हम कुछ लाइनों के कोड से Python में इमेज जेनरेट कर सकते हैं। लेकिन, इमेजेज के साथ आप और भी बहुत कुछ कर सकते हैं।\n",
    "\n",
    "आप निम्नलिखित भी कर सकते हैं:\n",
    "\n",
    "- **एडिट्स करें**। किसी मौजूदा इमेज, एक मास्क और एक प्रॉम्प्ट देकर, आप इमेज को बदल सकते हैं। उदाहरण के लिए, आप इमेज के किसी हिस्से में कुछ जोड़ सकते हैं। मान लीजिए हमारे बनी वाली इमेज है, आप बनी को एक हैट पहना सकते हैं। ऐसा करने के लिए आपको इमेज, एक मास्क (जो उस हिस्से को दर्शाता है जहाँ बदलाव करना है) और एक टेक्स्ट प्रॉम्प्ट देना होगा कि क्या बदलाव करना है।\n",
    "\n",
    "    ```python\n",
    "    response = openai.Image.create_edit(\n",
    "      image=open(\"base_image.png\", \"rb\"),\n",
    "      mask=open(\"mask.png\", \"rb\"),\n",
    "      prompt=\"An image of a rabbit with a hat on its head.\",\n",
    "      n=1,\n",
    "      size=\"1024x1024\"\n",
    "    )\n",
    "    image_url = response['data'][0]['url']\n",
    "    ```\n",
    "\n",
    "    बेस इमेज में सिर्फ खरगोश होगा, लेकिन फाइनल इमेज में खरगोश के सिर पर हैट भी होगा।\n",
    "\n",
    "- **वेरिएशन्स बनाएं**।\n",
    "    अधिक जानकारी के लिए हमारे [OpenAI नोटबुक देखें](./oai-assignment.ipynb?WT.mc_id=academic-105485-koreyst)।\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n---\n\n**अस्वीकरण**:  \nयह दस्तावेज़ AI अनुवाद सेवा [Co-op Translator](https://github.com/Azure/co-op-translator) का उपयोग करके अनुवादित किया गया है। यद्यपि हम सटीकता के लिए प्रयासरत हैं, कृपया ध्यान दें कि स्वचालित अनुवादों में त्रुटियाँ या गलतियाँ हो सकती हैं। मूल भाषा में उपलब्ध मूल दस्तावेज़ को ही प्रामाणिक स्रोत माना जाना चाहिए। महत्वपूर्ण जानकारी के लिए, पेशेवर मानव अनुवाद की सिफारिश की जाती है। इस अनुवाद के उपयोग से उत्पन्न किसी भी गलतफहमी या गलत व्याख्या के लिए हम उत्तरदायी नहीं हैं।\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4,
  "coopTranslator": {
   "original_hash": "d5c5bc8d857e5cb63e313beac9fa6402",
   "translation_date": "2025-08-25T19:11:50+00:00",
   "source_file": "09-building-image-applications/python/aoai-assignment.ipynb",
   "language_code": "hi"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}