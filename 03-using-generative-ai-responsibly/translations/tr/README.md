# Ãœretici Yapay ZekayÄ± Sorumlu Kullanma

[![Ãœretici Yapay ZekayÄ± Sorumlu Kullanma](../../images/03-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Bu dersin videosunu izlemek iÃ§in yukarÄ±daki gÃ¶rsele tÄ±klayÄ±n_

Yapay zeka ve Ã¶zellikle Ã¼retici yapay zekaya hayran kalmak kolaydÄ±r, ancak bunu nasÄ±l sorumlu bir ÅŸekilde kullanacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmeniz gerekir. Ã‡Ä±ktÄ±nÄ±n adil, zararsÄ±z ve daha fazlasÄ± olmasÄ±nÄ± nasÄ±l saÄŸlayacaÄŸÄ±nÄ±z gibi ÅŸeyleri dÃ¼ÅŸÃ¼nmeniz gerekir. Bu bÃ¶lÃ¼m, size bahsedilen baÄŸlamÄ±, neyi dÃ¼ÅŸÃ¼nmeniz gerektiÄŸini ve yapay zeka kullanÄ±mÄ±nÄ±zÄ± iyileÅŸtirmek iÃ§in aktif adÄ±mlar atmayÄ± nasÄ±l saÄŸlayacaÄŸÄ±nÄ±zÄ± anlatmayÄ± amaÃ§lamaktadÄ±r.

## GiriÅŸ

Bu ders ÅŸunlarÄ± kapsayacak:

- Ãœretici Yapay Zeka uygulamalarÄ± oluÅŸtururken Sorumlu Yapay Zekaya neden Ã¶ncelik vermelisiniz.
- Sorumlu Yapay ZekanÄ±n temel ilkeleri ve bunlarÄ±n Ãœretici Yapay Zeka ile nasÄ±l iliÅŸkili olduÄŸu.
- Bu Sorumlu Yapay Zeka ilkelerini strateji ve araÃ§lar yoluyla pratiÄŸe nasÄ±l dÃ¶kebilirsiniz.

## Ã–ÄŸrenme Hedefleri

Bu dersi tamamladÄ±ktan sonra ÅŸunlarÄ± bileceksiniz:

- Ãœretici Yapay Zeka uygulamalarÄ± oluÅŸtururken Sorumlu Yapay ZekanÄ±n Ã¶nemi.
- Ãœretici Yapay Zeka uygulamalarÄ± oluÅŸtururken Sorumlu Yapay ZekanÄ±n temel ilkelerini ne zaman dÃ¼ÅŸÃ¼nÃ¼p uygulayacaÄŸÄ±nÄ±z.
- Sorumlu Yapay Zeka kavramÄ±nÄ± pratiÄŸe dÃ¶kmek iÃ§in hangi araÃ§ ve stratejilerin mevcut olduÄŸu.

## Sorumlu Yapay Zeka Ä°lkeleri

Ãœretici Yapay Zekaya olan heyecan hiÃ§ bu kadar yÃ¼ksek olmamÄ±ÅŸtÄ±. Bu heyecan, bu alana birÃ§ok yeni geliÅŸtirici, dikkat ve finansman getirdi. Bu, Ãœretici Yapay ZekayÄ± kullanarak Ã¼rÃ¼n ve ÅŸirket kurmak isteyen herkes iÃ§in Ã§ok olumlu olsa da, sorumlu bir ÅŸekilde ilerlememiz de Ã¶nemlidir.

Bu kurs boyunca, startup'Ä±mÄ±zÄ± ve yapay zeka eÄŸitim Ã¼rÃ¼nÃ¼mÃ¼zÃ¼ oluÅŸturmaya odaklanÄ±yoruz. Sorumlu Yapay ZekanÄ±n ilkelerini kullanacaÄŸÄ±z: Adillik, KapsayÄ±cÄ±lÄ±k, GÃ¼venilirlik/GÃ¼venlik, GÃ¼venlik ve Gizlilik, ÅeffaflÄ±k ve Hesap Verebilirlik. Bu ilkelerle, Ã¼rÃ¼nlerimizde Ãœretici Yapay ZekayÄ± kullanÄ±mÄ±mÄ±zla nasÄ±l iliÅŸkili olduklarÄ±nÄ± keÅŸfedeceÄŸiz.

## Neden Sorumlu Yapay Zekaya Ã–ncelik Vermelisiniz

Bir Ã¼rÃ¼n oluÅŸtururken, kullanÄ±cÄ±larÄ±nÄ±zÄ±n Ã§Ä±karlarÄ±nÄ± gÃ¶z Ã¶nÃ¼nde bulundurarak insan merkezli bir yaklaÅŸÄ±m benimsemek en iyi sonuÃ§larÄ± verir.

Ãœretici Yapay ZekanÄ±n benzersizliÄŸi, kullanÄ±cÄ±lar iÃ§in yararlÄ± yanÄ±tlar, bilgiler, rehberlik ve iÃ§erik oluÅŸturma gÃ¼cÃ¼dÃ¼r. Bu, Ã§ok etkileyici sonuÃ§lara yol aÃ§abilecek birÃ§ok manuel adÄ±m olmadan yapÄ±labilir. Uygun planlama ve stratejiler olmadan, ne yazÄ±k ki kullanÄ±cÄ±larÄ±nÄ±z, Ã¼rÃ¼nÃ¼nÃ¼z ve bir bÃ¼tÃ¼n olarak toplum iÃ§in bazÄ± zararlÄ± sonuÃ§lara da yol aÃ§abilir.

Bu potansiyel zararlÄ± sonuÃ§lardan bazÄ±larÄ±na (hepsine deÄŸil) bakalÄ±m:

### HalÃ¼sinasyonlar

HalÃ¼sinasyonlar, bir LLM'nin ya tamamen anlamsÄ±z ya da diÄŸer bilgi kaynaklarÄ±na dayanarak faktÃ¼el olarak yanlÄ±ÅŸ olduÄŸunu bildiÄŸimiz iÃ§erik Ã¼rettiÄŸinde kullanÄ±lan bir terimdir.

Ã–rneÄŸin, startup'Ä±mÄ±z iÃ§in Ã¶ÄŸrencilerin bir modele tarihsel sorular sormasÄ±na izin veren bir Ã¶zellik oluÅŸturduÄŸumuzu dÃ¼ÅŸÃ¼nelim. Bir Ã¶ÄŸrenci `Titanic'in tek hayatta kalanÄ± kimdi?` sorusunu soruyor.

Model aÅŸaÄŸÄ±daki gibi bir yanÄ±t Ã¼retiyor:

![Titanic'in tek hayatta kalanÄ± kimdi" diyen istem](../../../03-using-generative-ai-responsibly/images/ChatGPT-titanic-survivor-prompt.webp?WT.mc_id=academic-105485-koreyst)

> _(Kaynak: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Bu Ã§ok gÃ¼venli ve kapsamlÄ± bir yanÄ±t. Ne yazÄ±k ki, yanlÄ±ÅŸ. Minimal bir araÅŸtÄ±rmayla bile, Titanic felaketinden birden fazla hayatta kalan olduÄŸu ortaya Ã§Ä±kardÄ±. Bu konuyu yeni araÅŸtÄ±rmaya baÅŸlayan bir Ã¶ÄŸrenci iÃ§in, bu yanÄ±t sorgulanmayacak ve gerÃ§ek olarak kabul edilecek kadar ikna edici olabilir. Bunun sonuÃ§larÄ±, yapay zeka sisteminin gÃ¼venilmez olmasÄ±na ve startup'Ä±mÄ±zÄ±n itibarÄ±nÄ± olumsuz etkilemesine yol aÃ§abilir.

Herhangi bir LLM'nin her iterasyonunda, halÃ¼sinasyonlarÄ± en aza indirme konusunda performans iyileÅŸtirmeleri gÃ¶rdÃ¼k. Bu iyileÅŸtirmeye raÄŸmen, uygulama geliÅŸtiricileri ve kullanÄ±cÄ±lar olarak bu sÄ±nÄ±rlamalarÄ±n farkÄ±nda olmaya devam etmeliyiz.

### ZararlÄ± Ä°Ã§erik

Daha Ã¶nceki bÃ¶lÃ¼mde bir LLM'nin yanlÄ±ÅŸ veya anlamsÄ±z yanÄ±tlar Ã¼rettiÄŸi durumlarÄ± ele aldÄ±k. FarkÄ±nda olmamÄ±z gereken bir diÄŸer risk de modelin zararlÄ± iÃ§erikle yanÄ±t vermesidir.

ZararlÄ± iÃ§erik ÅŸÃ¶yle tanÄ±mlanabilir:

- Kendine zarar verme veya belirli gruplara zarar verme talimatlarÄ± verme veya teÅŸvik etme.
- Nefret dolu veya aÅŸaÄŸÄ±layÄ±cÄ± iÃ§erik.
- Her tÃ¼rlÃ¼ saldÄ±rÄ± veya ÅŸiddet eyleminin planlanmasÄ±na rehberlik etme.
- Yasa dÄ±ÅŸÄ± iÃ§erik bulma veya yasa dÄ±ÅŸÄ± eylemler gerÃ§ekleÅŸtirme konusunda talimatlar verme.
- Cinsel aÃ§Ä±dan aÃ§Ä±k iÃ§erik gÃ¶sterme.

Startup'Ä±mÄ±z iÃ§in, Ã¶ÄŸrencilerin bu tÃ¼r iÃ§erikleri gÃ¶rmesini engellemek iÃ§in doÄŸru araÃ§ ve stratejilere sahip olduÄŸumuzdan emin olmak istiyoruz.

### Adillik EksikliÄŸi

Adillik, "bir yapay zeka sisteminin Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±ndÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± ve herkese adil ve eÅŸit davranmasÄ±nÄ± saÄŸlamak" olarak tanÄ±mlanÄ±r. Ãœretici Yapay Zeka dÃ¼nyasÄ±nda, marjinalleÅŸtirilmiÅŸ gruplarÄ±n dÄ±ÅŸlayÄ±cÄ± dÃ¼nya gÃ¶rÃ¼ÅŸlerinin model Ã§Ä±ktÄ±sÄ± tarafÄ±ndan pekiÅŸtirilmemesini saÄŸlamak istiyoruz.

Bu tÃ¼r Ã§Ä±ktÄ±lar sadece kullanÄ±cÄ±larÄ±mÄ±z iÃ§in olumlu Ã¼rÃ¼n deneyimleri oluÅŸturmada yÄ±kÄ±cÄ± olmakla kalmaz, aynÄ± zamanda toplumsal zarara da neden olur. Uygulama geliÅŸtiricileri olarak, Ãœretici Yapay Zeka ile Ã§Ã¶zÃ¼mler oluÅŸtururken her zaman geniÅŸ ve Ã§eÅŸitli bir kullanÄ±cÄ± tabanÄ±nÄ± akÄ±lda tutmalÄ±yÄ±z.

## Ãœretici Yapay ZekayÄ± Sorumlu Bir Åekilde NasÄ±l KullanÄ±lÄ±r

Åimdi Sorumlu Ãœretici Yapay ZekanÄ±n Ã¶nemini belirlediÄŸimize gÃ¶re, yapay zeka Ã§Ã¶zÃ¼mlerimizi sorumlu bir ÅŸekilde oluÅŸturmak iÃ§in atabileceÄŸimiz 4 adÄ±ma bakalÄ±m:

![Azaltma DÃ¶ngÃ¼sÃ¼](../../images/mitigate-cycle.png?WT.mc_id=academic-105485-koreyst)

### Potansiyel ZararlarÄ± Ã–lÃ§me

YazÄ±lÄ±m testinde, bir uygulamada kullanÄ±cÄ±nÄ±n beklenen eylemlerini test ederiz. Benzer ÅŸekilde, kullanÄ±cÄ±larÄ±n en Ã§ok kullanmasÄ± muhtemel Ã§eÅŸitli istemleri test etmek, potansiyel zararÄ± Ã¶lÃ§mek iÃ§in iyi bir yoldur.

Startup'Ä±mÄ±z bir eÄŸitim Ã¼rÃ¼nÃ¼ oluÅŸturduÄŸu iÃ§in, eÄŸitimle ilgili istemler listesi hazÄ±rlamak iyi olacaktÄ±r. Bu, belirli bir konuyu, tarihsel gerÃ§ekleri ve Ã¶ÄŸrenci yaÅŸamÄ± hakkÄ±ndaki istemleri kapsayabilir.

### Potansiyel ZararlarÄ± Azaltma

Åimdi model ve yanÄ±tlarÄ±nÄ±n neden olabileceÄŸi potansiyel zararÄ± Ã¶nlemenin veya sÄ±nÄ±rlamanÄ±n yollarÄ±nÄ± bulma zamanÄ±. Buna 4 farklÄ± katmanda bakabiliriz:

![Azaltma KatmanlarÄ±](../../images/mitigation-layers.png?WT.mc_id=academic-105485-koreyst)

- **Model**. DoÄŸru kullanÄ±m senaryosu iÃ§in doÄŸru modeli seÃ§mek. GPT-4 gibi daha bÃ¼yÃ¼k ve karmaÅŸÄ±k modeller, daha kÃ¼Ã§Ã¼k ve spesifik kullanÄ±m senaryolarÄ±na uygulandÄ±ÄŸÄ±nda zararlÄ± iÃ§erik riski oluÅŸturabilir. EÄŸitim verilerinizi ince ayar iÃ§in kullanmak da zararlÄ± iÃ§erik riskini azaltÄ±r.

- **GÃ¼venlik Sistemi**. GÃ¼venlik sistemi, modele hizmet veren platformda zararÄ± azaltmaya yardÄ±mcÄ± olan bir dizi araÃ§ ve yapÄ±landÄ±rmadÄ±r. Buna Ã¶rnek olarak Azure OpenAI hizmetindeki iÃ§erik filtreleme sistemi verilebilir. Sistemler ayrÄ±ca jailbreak saldÄ±rÄ±larÄ±nÄ± ve botlardan gelen istekler gibi istenmeyen aktiviteleri tespit etmelidir.

- **Meta Ä°stem**. Meta istemler ve temellendirme, modeli belirli davranÄ±ÅŸlara ve bilgilere gÃ¶re yÃ¶nlendirmenin veya sÄ±nÄ±rlamanÄ±n yollarÄ±dÄ±r. Bu, modelin belirli sÄ±nÄ±rlarÄ±nÄ± tanÄ±mlamak iÃ§in sistem girdilerini kullanmak olabilir. AyrÄ±ca, sistemin kapsamÄ±na veya alanÄ±na daha uygun Ã§Ä±ktÄ±lar saÄŸlamak da olabilir.

AyrÄ±ca, modelin yalnÄ±zca gÃ¼venilir kaynaklardan bilgi Ã§ekmesini saÄŸlamak iÃ§in Geri Alma ArtÄ±rÄ±lmÄ±ÅŸ Ãœretim (RAG) gibi teknikleri kullanmak da olabilir. Bu kursta daha sonra [arama uygulamalarÄ± oluÅŸturma](../../../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst) hakkÄ±nda bir ders var.

- **KullanÄ±cÄ± Deneyimi**. Son katman, kullanÄ±cÄ±nÄ±n uygulamamÄ±zÄ±n arayÃ¼zÃ¼ Ã¼zerinden bir ÅŸekilde modelle doÄŸrudan etkileÅŸime girdiÄŸi yerdir. Bu ÅŸekilde, kullanÄ±cÄ±nÄ±n modele gÃ¶nderebileceÄŸi girdi tÃ¼rlerini ve kullanÄ±cÄ±ya gÃ¶sterilen metin veya gÃ¶rselleri sÄ±nÄ±rlamak iÃ§in UI/UX'i tasarlayabiliriz. Yapay zeka uygulamasÄ±nÄ± daÄŸÄ±tÄ±rken, Ãœretici Yapay ZekA uygulamamÄ±zÄ±n neler yapÄ±p yapamayacaÄŸÄ± konusunda da ÅŸeffaf olmalÄ±yÄ±z.

[Yapay Zeka UygulamalarÄ± iÃ§in UX TasarÄ±mÄ±](../../../12-designing-ux-for-ai-applications/README.md?WT.mc_id=academic-105485-koreyst) konusuna adanmÄ±ÅŸ bir dersimiz var.

- **Modeli deÄŸerlendirme**. LLM'lerle Ã§alÄ±ÅŸmak zor olabilir Ã§Ã¼nkÃ¼ modelin eÄŸitildiÄŸi veriler Ã¼zerinde her zaman kontrolÃ¼mÃ¼z olmaz. Yine de, modelin performansÄ±nÄ± ve Ã§Ä±ktÄ±larÄ±nÄ± her zaman deÄŸerlendirmeliyiz. Modelin doÄŸruluÄŸunu, benzerliÄŸini, temellendirilmiÅŸliÄŸini ve Ã§Ä±ktÄ±nÄ±n uygunluÄŸunu Ã¶lÃ§mek hala Ã¶nemlidir. Bu, paydaÅŸlara ve kullanÄ±cÄ±lara ÅŸeffaflÄ±k ve gÃ¼ven saÄŸlamaya yardÄ±mcÄ± olur.

### Sorumlu Bir Ãœretici Yapay Zeka Ã‡Ã¶zÃ¼mÃ¼nÃ¼ Ä°ÅŸletme

Yapay zeka uygulamalarÄ±nÄ±z etrafÄ±nda operasyonel bir uygulama oluÅŸturmak son aÅŸamadÄ±r. Bu, tÃ¼m dÃ¼zenleyici politikalara uygun olduÄŸumuzdan emin olmak iÃ§in startup'Ä±mÄ±zÄ±n Hukuk ve GÃ¼venlik gibi diÄŸer bÃ¶lÃ¼mleriyle ortaklÄ±k kurmayÄ± iÃ§erir. Lansmandan Ã¶nce, kullanÄ±cÄ±larÄ±mÄ±za yÃ¶nelik herhangi bir zararÄ±n bÃ¼yÃ¼mesini Ã¶nlemek iÃ§in teslimat, olaylarÄ± ele alma ve geri alma planlarÄ± da oluÅŸturmak istiyoruz.

## AraÃ§lar

Sorumlu Yapay Zeka Ã§Ã¶zÃ¼mleri geliÅŸtirme iÅŸi Ã§ok gibi gÃ¶rÃ¼nse de, bu Ã§aba deÄŸer. Ãœretici Yapay ZekA alanÄ± bÃ¼yÃ¼dÃ¼kÃ§e, geliÅŸtiricilerin sorumluluÄŸu iÅŸ akÄ±ÅŸlarÄ±na verimli bir ÅŸekilde entegre etmelerine yardÄ±mcÄ± olacak daha fazla araÃ§ olgunlaÅŸacaktÄ±r. Ã–rneÄŸin, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) bir API isteÄŸi aracÄ±lÄ±ÄŸÄ±yla zararlÄ± iÃ§erik ve gÃ¶rselleri tespit etmeye yardÄ±mcÄ± olabilir.

## Bilgi KontrolÃ¼

Sorumlu yapay zeka kullanÄ±mÄ±nÄ± saÄŸlamak iÃ§in nelere dikkat etmeniz gerekir?

1. YanÄ±tÄ±n doÄŸru olmasÄ±.
2. ZararlÄ± kullanÄ±m, yapay zekanÄ±n suÃ§ amaÃ§lÄ± kullanÄ±lmamasÄ±.
3. Yapay zekanÄ±n Ã¶nyargÄ± ve ayrÄ±mcÄ±lÄ±ktan arÄ±ndÄ±rÄ±lmÄ±ÅŸ olmasÄ±nÄ± saÄŸlamak.

C: 2 ve 3 doÄŸrudur. Sorumlu Yapay ZekA, zararlÄ± etkileri ve Ã¶nyargÄ±larÄ± ve daha fazlasÄ±nÄ± nasÄ±l azaltacaÄŸÄ±nÄ±zÄ± dÃ¼ÅŸÃ¼nmenize yardÄ±mcÄ± olur.

## ğŸš€ Challenge

[Azure AI Ä°Ã§erik GÃ¼venliÄŸi](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) hakkÄ±nda bilgi edinin ve kullanÄ±mÄ±nÄ±z iÃ§in neler benimseyebileceÄŸinize bakÄ±n.

## Harika Ä°ÅŸ, Ã–ÄŸrenmeye Devam Edin

Bu dersi tamamladÄ±ktan sonra, Ãœretici Yapay ZekA bilginizi artÄ±rmaya devam etmek iÃ§in [Ãœretici Yapay ZekA Ã–ÄŸrenme koleksiyonumuza](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) gÃ¶z atÄ±n!

[Ä°stem MÃ¼hendisliÄŸi Temelleri](../../../04-prompt-engineering-fundamentals/README.md?WT.mc_id=academic-105485-koreyst) konusunu inceleyeceÄŸimiz Ders 4'e geÃ§in!
