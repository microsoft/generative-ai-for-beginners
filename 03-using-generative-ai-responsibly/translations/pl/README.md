# Odpowiedzialne Korzystanie z Generatywnej SI

[![Odpowiedzialne Korzystanie z Generatywnej SI](../../images/03-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson3-gh?WT.mc_id=academic-105485-koreyst)

> _Kliknij powy偶szy obraz, aby obejrze wideo tej lekcji_

atwo jest by zafascynowanym sztuczn inteligencj, a w szczeg贸lnoci generatywn SI, ale musisz rozwa偶y, jak odpowiedzialnie z niej korzysta. Musisz wzi pod uwag takie kwestie jak zapewnienie, 偶e rezultat jest sprawiedliwy, nie szkodliwy i wicej. Ten rozdzia ma na celu dostarczenie ci wspomnianego kontekstu, co wzi pod uwag i jak podj aktywne kroki w celu poprawy twojego korzystania z SI.

## Wprowadzenie

Ta lekcja obejmie:

- Dlaczego powiniene priorytetowo traktowa Odpowiedzialn SI podczas budowania aplikacji Generatywnej SI.
- Podstawowe zasady Odpowiedzialnej SI i jak odnosz si one do Generatywnej SI.
- Jak wprowadzi te zasady Odpowiedzialnej SI w praktyce poprzez strategi i narzdzia.

## Cele Nauki

Po ukoczeniu tej lekcji bdziesz wiedzie:

- Znaczenie Odpowiedzialnej SI podczas budowania aplikacji Generatywnej SI.
- Kiedy myle i stosowa podstawowe zasady Odpowiedzialnej SI podczas budowania aplikacji Generatywnej SI.
- Jakie narzdzia i strategie s dostpne, aby wprowadzi koncepcj Odpowiedzialnej SI w praktyce.

## Zasady Odpowiedzialnej SI

Ekscytacja Generatywn SI nigdy nie bya wiksza. Ta ekscytacja przycigna wielu nowych deweloper贸w, uwag i finansowanie do tej przestrzeni. Cho jest to bardzo pozytywne dla ka偶dego, kto chce budowa produkty i firmy korzystajce z Generatywnej SI, wa偶ne jest r贸wnie偶, abymy postpowali odpowiedzialnie.

W caym tym kursie skupiamy si na budowaniu naszego startupu i naszego produktu edukacyjnego SI. Bdziemy korzysta z zasad Odpowiedzialnej SI: Uczciwo, Inkluzywno, Niezawodno/Bezpieczestwo, Ochrona i Prywatno, Przejrzysto i Odpowiedzialno. Z tymi zasadami zbadamy, jak odnosz si one do naszego korzystania z Generatywnej SI w naszych produktach.

## Dlaczego Powiniene Priorytetowo Traktowa Odpowiedzialn SI

Podczas budowania produktu, przyjcie podejcia skoncentrowanego na czowieku, majc na uwadze najlepszy interes u偶ytkownika, prowadzi do najlepszych rezultat贸w.

Wyjtkowo Generatywnej SI polega na jej mocy tworzenia pomocnych odpowiedzi, informacji, wskaz贸wek i treci dla u偶ytkownik贸w. Mo偶na to zrobi bez wielu rcznych krok贸w, co mo偶e prowadzi do bardzo imponujcych rezultat贸w. Bez odpowiedniego planowania i strategii mo偶e to r贸wnie偶 niestety prowadzi do pewnych szkodliwych rezultat贸w dla twoich u偶ytkownik贸w, twojego produktu i spoeczestwa jako caoci.

Przyjrzyjmy si niekt贸rym (ale nie wszystkim) z tych potencjalnie szkodliwych rezultat贸w:

### Halucynacje

Halucynacje to termin u偶ywany do opisania sytuacji, gdy LLM produkuje tre, kt贸ra jest albo cakowicie bezsensowna, albo co, co wiemy, 偶e jest faktycznie bdne na podstawie innych 藕r贸de informacji.

We藕my na przykad, 偶e budujemy funkcj dla naszego startupu, kt贸ra pozwala uczniom zadawa pytania historyczne do modelu. Ucze zadaje pytanie `Kto by jedynym ocalaym z Titanica?`

Model generuje odpowied藕 tak jak poni偶sza:

![Prompt m贸wicy "Kto by jedynym ocalaym z Titanica"](../../images/ChatGPT-titanic-survivor-prompt.webp?WT.mc_id=academic-105485-koreyst)

> _(殴r贸do: [Flying bisons](https://flyingbisons.com?WT.mc_id=academic-105485-koreyst))_

Jest to bardzo pewna i dokadna odpowied藕. Niestety, jest niepoprawna. Nawet przy minimalnej iloci bada odkryoby si, 偶e byo wicej ni偶 jeden ocalay z katastrofy Titanica. Dla ucznia, kt贸ry dopiero zaczyna bada ten temat, ta odpowied藕 mo偶e by wystarczajco przekonujca, aby nie by kwestionowana i traktowana jako fakt. Konsekwencje tego mog prowadzi do tego, 偶e system SI jest niewiarygodny i negatywnie wpywa na reputacj naszego startupu.

Z ka偶d iteracj dowolnego modelu LLM widzielimy popraw wydajnoci w zakresie minimalizacji halucynacji. Nawet z t popraw, my jako tw贸rcy aplikacji i u偶ytkownicy musimy pozosta wiadomi tych ogranicze.

### Szkodliwa Tre

Om贸wilimy w poprzedniej sekcji, kiedy LLM produkuje niepoprawne lub bezsensowne odpowiedzi. Innym ryzykiem, kt贸rego musimy by wiadomi, jest sytuacja, gdy model odpowiada szkodliw treci.

Szkodliwa tre mo偶e by zdefiniowana jako:

- Dostarczanie instrukcji lub zachcanie do samookaleczenia lub szkodzenia okrelonym grupom.
- Nienawistna lub poni偶ajca tre.
- Prowadzenie planowania jakiegokolwiek ataku lub akt贸w przemocy.
- Dostarczanie instrukcji, jak znale藕 nielegalne treci lub popeni nielegalne czyny.
- Wywietlanie treci o charakterze seksualnym.

Dla naszego startupu chcemy upewni si, 偶e mamy odpowiednie narzdzia i strategie, aby zapobiec temu rodzajowi treci przed jej zobaczeniem przez uczni贸w.

### Brak Uczciwoci

Uczciwo jest definiowana jako "zapewnienie, 偶e system SI jest wolny od uprzedze i dyskryminacji i 偶e traktuje wszystkich sprawiedliwie i r贸wno." W wiecie Generatywnej SI chcemy zapewni, 偶e wykluczajce wiatopogldy marginalizowanych grup nie s wzmacniane przez rezultat modelu.

Tego typu rezultaty s nie tylko destrukcyjne dla budowania pozytywnych dowiadcze produktowych dla naszych u偶ytkownik贸w, ale tak偶e powoduj dalsze szkody spoeczne. Jako tw贸rcy aplikacji powinnimy zawsze mie na uwadze szerok i zr贸偶nicowan baz u偶ytkownik贸w podczas budowania rozwiza z Generatywn SI.

## Jak Odpowiedzialnie Korzysta z Generatywnej SI

Teraz, gdy zidentyfikowalimy znaczenie Odpowiedzialnej Generatywnej SI, przyjrzyjmy si 4 krokom, kt贸re mo偶emy podj, aby odpowiedzialnie budowa nasze rozwizania SI:

![Cykl agodzenia](../../images/mitigate-cycle.png?WT.mc_id=academic-105485-koreyst)

### Mierzenie Potencjalnych Szk贸d

W testowaniu oprogramowania testujemy oczekiwane dziaania u偶ytkownika na aplikacji. Podobnie, testowanie r贸偶norodnego zestawu prompt贸w, kt贸rych u偶ytkownicy najprawdopodobniej bd u偶ywa, jest dobrym sposobem na mierzenie potencjalnych szk贸d.

Poniewa偶 nasz startup buduje produkt edukacyjny, dobrze byoby przygotowa list prompt贸w zwizanych z edukacj. Mogoby to obejmowa okrelony przedmiot, fakty historyczne i prompty dotyczce 偶ycia studenckiego.

### agodzenie Potencjalnych Szk贸d

Teraz czas znale藕 sposoby, w jakie mo偶emy zapobiec lub ograniczy potencjalne szkody spowodowane przez model i jego odpowiedzi. Mo偶emy spojrze na to w 4 r贸偶nych warstwach:

![Warstwy agodzenia](../../images/mitigation-layers.png?WT.mc_id=academic-105485-koreyst)

- **Model**. Wyb贸r odpowiedniego modelu do odpowiedniego przypadku u偶ycia. Wiksze i bardziej zo偶one modele, takie jak GPT-4, mog powodowa wiksze ryzyko szkodliwych treci, gdy s stosowane do mniejszych i bardziej specyficznych przypadk贸w u偶ycia. U偶ywanie danych treningowych do dostrajania r贸wnie偶 zmniejsza ryzyko szkodliwych treci.

- **System Bezpieczestwa**. System bezpieczestwa to zestaw narzdzi i konfiguracji na platformie obsugujcej model, kt贸re pomagaj agodzi szkody. Przykadem tego jest system filtrowania treci w usudze Azure OpenAI. Systemy powinny r贸wnie偶 wykrywa ataki jailbreak i niepo偶dan aktywno, tak jak 偶dania od bot贸w.

- **Metaprompt**. Metaprompty i ugruntowanie s sposobami, w jakie mo偶emy kierowa lub ogranicza model na podstawie pewnych zachowa i informacji. Mo偶e to by u偶ywanie danych wejciowych systemu do definiowania pewnych ogranicze modelu. Dodatkowo, dostarczanie rezultat贸w, kt贸re s bardziej odpowiednie dla zakresu lub domeny systemu.

Mo偶e to by r贸wnie偶 u偶ywanie technik takich jak Retrieval Augmented Generation (RAG), aby model pobiera informacje tylko z wyboru zaufanych 藕r贸de. Jest lekcja p贸藕niej w tym kursie o [budowaniu aplikacji wyszukiwania](../../../08-building-search-applications/README.md?WT.mc_id=academic-105485-koreyst)

- **Dowiadczenie U偶ytkownika**. Ostatnia warstwa to miejsce, gdzie u偶ytkownik bezporednio wchodzi w interakcj z modelem poprzez interfejs naszej aplikacji w jaki spos贸b. W ten spos贸b mo偶emy zaprojektowa UI/UX, aby ograniczy u偶ytkownika w zakresie rodzaj贸w danych wejciowych, kt贸re mog wysa do modelu, a tak偶e tekstu lub obraz贸w wywietlanych u偶ytkownikowi. Podczas wdra偶ania aplikacji SI musimy r贸wnie偶 by przejrzyci co do tego, co nasza aplikacja Generatywnej SI mo偶e i czego nie mo偶e zrobi.

Mamy ca lekcj powicon [Projektowaniu UX dla Aplikacji SI](../../../12-designing-ux-for-ai-applications/translations/pl/README.md?WT.mc_id=academic-105485-koreyst)

- **Ocena modelu**. Praca z modelami LLM mo偶e by trudna, poniewa偶 nie zawsze mamy kontrol nad danymi, na kt贸rych model by trenowany. Niezale偶nie od tego, zawsze powinnimy ocenia wydajno modelu i jego rezultaty. Nadal wa偶ne jest mierzenie dokadnoci modelu, podobiestwa, ugruntowania i istotnoci rezultatu. Pomaga to zapewni przejrzysto i zaufanie dla interesariuszy i u偶ytkownik贸w.

### Prowadzenie Odpowiedzialnego Rozwizania Generatywnej SI

Budowanie praktyki operacyjnej wok贸 twoich aplikacji SI jest ostatnim etapem. Obejmuje to partnerstwo z innymi czciami naszego startupu, takimi jak Prawne i Bezpieczestwo, aby zapewni, 偶e jestemy zgodni ze wszystkimi politykami regulacyjnymi. Przed uruchomieniem chcemy r贸wnie偶 budowa plany dotyczce dostarczania, obsugi incydent贸w i wycofywania, aby zapobiec narastaniu szk贸d dla naszych u偶ytkownik贸w.

## Narzdzia

Chocia偶 praca nad rozwijaniem rozwiza Odpowiedzialnej SI mo偶e wydawa si du偶ym wysikiem, jest to praca warta wysiku. Wraz z rozwojem obszaru Generatywnej SI, bd dojrzewa narzdzia pomagajce deweloperom efektywnie integrowa odpowiedzialno w ich przepywach pracy. Na przykad, [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) mo偶e pom贸c wykry szkodliwe treci i obrazy poprzez 偶danie API.

## Sprawdzenie wiedzy

O co musisz dba, aby zapewni odpowiedzialne korzystanie z SI?

1. 呕e odpowied藕 jest poprawna.
1. Szkodliwe u偶ytkowanie, 偶e SI nie jest u偶ywana do cel贸w przestpczych.
1. Zapewnienie, 偶e SI jest wolna od uprzedze i dyskryminacji.

A: 2 i 3 s poprawne. Odpowiedzialna SI pomaga rozwa偶y, jak agodzi szkodliwe efekty i uprzedzenia oraz wicej.

##  Wyzwanie

Przeczytaj wicej o [Azure AI Content Safety](https://learn.microsoft.com/azure/ai-services/content-safety/overview?WT.mc_id=academic-105485-koreyst) i zobacz, co mo偶esz adoptowa do swojego u偶ytku.

## wietna Praca, Kontynuuj Nauk

Po ukoczeniu tej lekcji, sprawd藕 nasz [kolekcj materia贸w do nauki Generatywnej SI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby kontynuowa podnoszenie swojej wiedzy o Generatywnej SI!

Przejd藕 do Lekcji 4, gdzie przyjrzymy si [Podstawom In偶ynierii Prompt贸w](../../../04-prompt-engineering-fundamentals/translations/pl/README.md?WT.mc_id=academic-105485-koreyst)!
