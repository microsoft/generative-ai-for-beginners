# Tworzenie Zaawansowanych Prompt贸w

[![Tworzenie Zaawansowanych Prompt贸w](../../images/05-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst?WT.mc_id=academic-105485-koreyst)

Przypomnijmy kilka wniosk贸w z poprzedniego rozdziau:

> In偶ynieria prompt贸w to proces, w kt贸rym **kierujemy model w stron bardziej trafnych odpowiedzi** poprzez dostarczanie bardziej u偶ytecznych instrukcji lub kontekstu.

Istniej te偶 dwa kroki w tworzeniu prompt贸w: konstruowanie promptu poprzez dostarczanie odpowiedniego kontekstu, oraz druga cz - _optymalizacja_, czyli jak stopniowo ulepsza prompt.

Na tym etapie mamy podstawowe zrozumienie, jak pisa prompty, ale musimy zagbi si bardziej. W tym rozdziale przejdziesz od wypr贸bowywania r贸偶nych prompt贸w do zrozumienia, dlaczego jeden prompt jest lepszy od drugiego. Nauczysz si konstruowa prompty, stosujc podstawowe techniki, kt贸re mo偶na zastosowa do dowolnego LLM.

## Wprowadzenie

W tym rozdziale om贸wimy nastpujce tematy:

- Rozszerzenie wiedzy o in偶ynierii prompt贸w poprzez zastosowanie r贸偶nych technik do Twoich prompt贸w.
- Konfigurowanie prompt贸w w celu zr贸偶nicowania wynik贸w.

## Cele nauki

Po ukoczeniu tej lekcji bdziesz potrafi:

- Stosowa techniki in偶ynierii prompt贸w, kt贸re poprawiaj wyniki Twoich prompt贸w.
- Wykonywa promptowanie, kt贸re jest zr贸偶nicowane lub deterministyczne.

## In偶ynieria prompt贸w

In偶ynieria prompt贸w to proces tworzenia prompt贸w, kt贸re przynios po偶dany rezultat. In偶ynieria prompt贸w to wicej ni偶 tylko pisanie tekstowego promptu. In偶ynieria prompt贸w nie jest dyscyplin in偶ynieryjn, to raczej zestaw technik, kt贸re mo偶na zastosowa, aby uzyska po偶dany wynik.

### Przykad promptu

We藕my podstawowy prompt, taki jak ten:

> Wygeneruj 10 pyta dotyczcych geografii.

W tym prompcie stosujesz w rzeczywistoci zestaw r贸偶nych technik promptowania.

Roz贸偶my to na czci.

- **Kontekst**, okrelasz, 偶e powinno to dotyczy "geografii".
- **Ograniczenie wynik贸w**, chcesz nie wicej ni偶 10 pyta.

### Ograniczenia prostego promptowania

Mo偶esz otrzyma lub nie otrzyma po偶danego wyniku. Pytania zostan wygenerowane, ale geografia to du偶y temat i mo偶esz nie dosta tego, czego chcesz, z nastpujcych powod贸w:

- **Du偶y temat**, nie wiesz, czy bdzie to o krajach, stolicach, rzekach i tak dalej.
- **Format**, co jeli chciae, aby pytania byy sformatowane w okrelony spos贸b?

Jak wida, jest wiele do rozwa偶enia przy tworzeniu prompt贸w.

Do tej pory widzielimy prosty przykad promptu, ale generatywna sztuczna inteligencja jest zdolna do znacznie wicej, aby pom贸c ludziom w r贸偶nych rolach i bran偶ach. Przyjrzyjmy si teraz kilku podstawowym technikom.

### Techniki promptowania

Najpierw musimy zrozumie, 偶e promptowanie jest _emergentn_ waciwoci LLM, co oznacza, 偶e nie jest to funkcja wbudowana w model, a raczej co, co odkrywamy w trakcie korzystania z modelu.

Istnieje kilka podstawowych technik, kt贸rych mo偶emy u偶ywa do promptowania LLM. Przyjrzyjmy si im.

- **Promptowanie zero-shot**, to najbardziej podstawowa forma promptowania. Jest to pojedynczy prompt 偶dajcy odpowiedzi od LLM wycznie na podstawie jego danych treningowych.
- **Promptowanie few-shot**, ten rodzaj promptowania kieruje LLM poprzez dostarczenie 1 lub wicej przykad贸w, na kt贸rych mo偶e bazowa przy generowaniu odpowiedzi.
- **Chain-of-thought (acuch mylowy)**, ten rodzaj promptowania m贸wi LLM, jak rozbi problem na kroki.
- **Generated knowledge (wygenerowana wiedza)**, aby poprawi odpowied藕 promptu, mo偶esz dodatkowo dostarczy wygenerowane fakty lub wiedz do swojego promptu.
- **Least to most (od najmniejszego do najwikszego)**, podobnie jak chain-of-thought, ta technika polega na rozbiciu problemu na seri krok贸w, a nastpnie probie o wykonanie tych krok贸w po kolei.
- **Self-refine (samodoskonalenie)**, ta technika polega na krytykowaniu wynik贸w LLM, a nastpnie probie o ich ulepszenie.
- **Maieutic prompting (promptowanie majeutyczne)**. Chodzi tu o to, aby upewni si, 偶e odpowied藕 LLM jest poprawna, proszc o wyjanienie r贸偶nych czci odpowiedzi. Jest to forma samodoskonalenia.

### Promptowanie zero-shot

Ten styl promptowania jest bardzo prosty, skada si z pojedynczego promptu. Ta technika to prawdopodobnie to, czego u偶ywasz, gdy zaczynasz uczy si o LLM. Oto przykad:

- Prompt: "Czym jest algebra?"
- Odpowied藕: "Algebra to ga藕 matematyki, kt贸ra bada symbole matematyczne i reguy manipulowania tymi symbolami."

### Promptowanie few-shot

Ten styl promptowania pomaga modelowi poprzez dostarczenie kilku przykad贸w wraz z prob. Skada si z pojedynczego promptu z dodatkowymi danymi specyficznymi dla zadania. Oto przykad:

- Prompt: "Napisz wiersz w stylu Szekspira. Oto kilka przykad贸w sonet贸w szekspirowskich.:
  Sonet 18: 'Shall I compare thee to a summer's day? Thou art more lovely and more temperate...'
  Sonet 116: 'Let me not to the marriage of true minds Admit impediments. Love is not love Which alters when it alteration finds...'
  Sonet 132: 'Thine eyes I love, and they, as pitying me, Knowing thy heart torment me with disdain,...'
  Teraz napisz sonet o piknie ksi偶yca."
- Odpowied藕: "Upon the sky, the moon doth softly gleam, In silv'ry light that casts its gentle grace,..."

Przykady dostarczaj LLM kontekstu, formatu lub stylu po偶danego wyniku. Pomagaj modelowi zrozumie konkretne zadanie i generowa dokadniejsze i bardziej odpowiednie odpowiedzi.

### Chain-of-thought (acuch mylowy)

Chain-of-thought to bardzo interesujca technika, poniewa偶 polega na przeprowadzeniu LLM przez seri krok贸w. Idea polega na instruowaniu LLM w taki spos贸b, aby zrozumia, jak co zrobi. Rozwa偶my nastpujcy przykad, z i bez chain-of-thought:

    - Prompt: "Alicja ma 5 jabek, wyrzuca 3 jabka, daje 2 Bobowi, a Bob oddaje jej jedno, ile jabek ma Alicja?"
    - Odpowied藕: 5

LLM odpowiada 5, co jest niepoprawne. Prawidowa odpowied藕 to 1 jabko, biorc pod uwag obliczenie (5 -3 -2 + 1 = 1).

Jak wic mo偶emy nauczy LLM, aby robi to poprawnie?

Spr贸bujmy chain-of-thought. Zastosowanie chain-of-thought oznacza:

1. Daj LLM podobny przykad.
1. Poka偶 obliczenie i jak obliczy to poprawnie.
1. Podaj oryginalny prompt.

Oto jak:

- Prompt: "Lisa ma 7 jabek, wyrzuca 1 jabko, daje 4 jabka Bartowi, a Bart oddaje jej jedno:
  7 -1 = 6
  6 -4 = 2
  2 +1 = 3
  Alicja ma 5 jabek, wyrzuca 3 jabka, daje 2 Bobowi, a Bob oddaje jej jedno, ile jabek ma Alicja?"
  Odpowied藕: 1

Zauwa偶, jak piszemy znacznie du偶sze prompty z innym przykadem, obliczeniem, a nastpnie oryginalnym promptem i dochodzimy do poprawnej odpowiedzi 1.

Jak wida, chain-of-thought to bardzo pot偶na technika.

### Generated knowledge (wygenerowana wiedza)

Czsto, gdy chcesz skonstruowa prompt, chcesz to zrobi, u偶ywajc wasnych danych firmy. Chcesz, aby cz promptu pochodzia z firmy, a druga cz powinna by faktycznym promptem, kt贸rym jeste zainteresowany.

Na przykad, tak mo偶e wyglda Tw贸j prompt, jeli dziaasz w bran偶y ubezpieczeniowej:

```text
{{company}}: {{company_name}}
{{products}}:
{{products_list}}
Prosz zaproponowa ubezpieczenie przy nastpujcym bud偶ecie i wymaganiach:
Bud偶et: {{budget}}
Wymagania: {{requirements}}
```

Powy偶ej wida, jak prompt jest skonstruowany przy u偶yciu szablonu. W szablonie znajduje si szereg zmiennych, oznaczonych przez `{{zmienna}}`, kt贸re zostan zastpione rzeczywistymi wartociami z API firmy.

Oto przykad, jak mo偶e wyglda prompt po zastpieniu zmiennych treci z Twojej firmy:

```text
Firma ubezpieczeniowa: ACME Insurance
Produkty ubezpieczeniowe (koszt miesiczny):
- Samoch贸d, tani, 500 USD
- Samoch贸d, drogi, 1100 USD
- Dom, tani, 600 USD
- Dom, drogi, 1200 USD
- 呕ycie, tanie, 100 USD

Prosz zaproponowa ubezpieczenie przy nastpujcym bud偶ecie i wymaganiach:
Bud偶et: $1000
Wymagania: Ubezpieczenie samochodu, domu i 偶ycia
```

Uruchomienie tego promptu przez LLM spowoduje wygenerowanie odpowiedzi takiej jak ta:

```output
Biorc pod uwag bud偶et i wymagania, proponujemy nastpujcy pakiet ubezpieczeniowy od ACME Insurance:
- Samoch贸d, tani, 500 USD
- Dom, tani, 600 USD
- 呕ycie, tanie, 100 USD
Cakowity koszt: $1,200 USD
```

Jak wida, sugeruje r贸wnie偶 ubezpieczenie na 偶ycie, czego nie powinien robi. Ten wynik jest wskaz贸wk, 偶e musimy zoptymalizowa prompt, zmieniajc go, aby by janiejszy w tym, na co mo偶e pozwoli. Po kilku _pr贸bach i bdach_, dochodzimy do nastpujcego promptu:

```text
Firma ubezpieczeniowa: ACME Insurance
Produkty ubezpieczeniowe (koszt miesiczny):
- typ: Samoch贸d, tani, koszt: 500 USD
- typ: Samoch贸d, drogi, koszt: 1100 USD
- typ: Dom, tani, koszt: 600 USD
- typ: Dom, drogi, koszt: 1200 USD
- typ: 呕ycie, tanie, koszt: 100 USD

Prosz zaproponowa ubezpieczenie przy nastpujcym bud偶ecie i wymaganiach:
Bud偶et: $1000 ogranicz wyb贸r do typ贸w: Samoch贸d, Dom
```

Zauwa偶, jak dodanie _typ_ i _koszt_, a tak偶e u偶ycie sowa kluczowego _ogranicz_ pomaga LLM zrozumie, czego chcemy.

Teraz otrzymujemy nastpujc odpowied藕:

```output
Biorc pod uwag bud偶et i wymagania, proponujemy ubezpieczenie Samoch贸d, Tanie, kt贸re kosztuje 500 USD miesicznie.
```

Celem tego przykadu byo pokazanie, 偶e nawet przy u偶yciu podstawowej techniki, takiej jak _wygenerowana wiedza_, nadal musimy w wikszoci przypadk贸w optymalizowa prompt, aby uzyska po偶dany wynik.

### Least-to-most (od najmniejszego do najwikszego)

Idea promptowania Least-to-most polega na rozbiciu wikszego problemu na podproblemy. W ten spos贸b pomagasz kierowa LLM, jak "pokona" wikszy problem. Dobrym przykadem mogaby by analiza danych, gdzie mo偶esz poprosi LLM o podzielenie problemu w nastpujcy spos贸b:

> Prompt: Jak wykona analiz danych w 5 krokach?

Tw贸j asystent AI odpowie:

1. Zbierz dane
1. Oczy dane
1. Przeanalizuj dane
1. Wizualizuj dane
1. Zaprezentuj dane

### Self-refine (samodoskonalenie), krytyka wynik贸w

W przypadku generatywnych AI i LLM nie mo偶esz ufa wynikom. Musisz je weryfikowa. Ostatecznie, LLM po prostu przedstawia Ci to, co jest najbardziej prawdopodobne do powiedzenia, a nie to, co jest poprawne. Dlatego dobrym pomysem jest poproszenie LLM o skrytykowanie samego siebie, co prowadzi nas do techniki self-refine.

Dziaa to w nastpujcy spos贸b:

1. Pocztkowy prompt proszcy LLM o rozwizanie problemu
1. LLM odpowiada
1. Krytykujesz odpowied藕 i prosisz AI o ulepszenie
1. LLM odpowiada ponownie, tym razem uwzgldniajc krytyk i sugerujc rozwizania, kt贸re wymyli

Mo偶esz powtarza ten proces tyle razy, ile chcesz.

Oto przykad wykorzystujcy t technik:

> Prompt: "Stw贸rz API webowe w Pythonie z trasami products i customers"

Odpowied藕 AI:

```python
import flask
app = Flask(__name__)

@app.route('/products')
def products():
    return 'Products'

@app.route('/customers')
def customers():
    return 'Customers'
```

> Prompt: zaproponuj 3 ulepszenia powy偶szego kodu

Odpowied藕 AI:

```text
Oczywicie, oto trzy sugestie ulepsze kodu:

Zaimportuj prawidowy modu: Pierwsza linia powinna importowa Flask zamiast flask. Prawidowa instrukcja importu powinna brzmie from flask import Flask.

Dodaj funkcj main: Dodaj blok if __name__ == '__main__': na kocu pliku, aby uruchomi aplikacj po wykonaniu pliku.

U偶yj f-strings: U偶yj f-strings do formatowania instrukcji return w funkcjach tras. Na przykad, return 'Products' mo偶na zmieni na return f'To jest strona {request.path}'.
```

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/products')
def products():
    return f'To jest strona {request.path}'

@app.route('/customers')
def customers():
    return f'To jest strona {request.path}'

if __name__ == '__main__':
    app.run()
```

Jak wida, powy偶sza odpowied藕 AI ulepsza pierwszy sugerowany kod dziki krytyce pierwszej odpowiedzi.

### Maieutic prompting (promptowanie majeutyczne)

Promptowanie majeutyczne to technika podobna do self-refine, ale bardziej skupia si na probie o wyjanienie przez LLM. Celem jest zmniejszenie niesp贸jnoci w wynikach LLM, aby upewni si, 偶e dochodzi do poprawnej odpowiedzi. Proces do naladowania to:

1. Popro LLM o odpowied藕 na pytanie
1. Dla ka偶dej czci odpowiedzi popro LLM o bardziej szczeg贸owe wyjanienie.
1. Jeli istniej niesp贸jnoci, odrzu czci, kt贸re s niesp贸jne.

Powtarzaj kroki 2 i 3, a偶 przejdziesz przez wszystkie czci i bdziesz zadowolony z odpowiedzi.

Oto przykadowy prompt:

> prompt: Jak mog stworzy plan kryzysowy, aby zagodzi skutki pandemii w 5 krokach?
> Odpowied藕 LLM:

```text
1. Zidentyfikuj ryzyka
1. Zidentyfikuj interesariuszy
1. Zidentyfikuj zasoby
1. Zidentyfikuj dziaania
1. Zidentyfikuj kanay komunikacji
```

Zidentyfikowano 5 krok贸w, ale czy mo偶emy ustali, czy jest to poprawne? Popromy LLM o wyjanienie ka偶dego kroku:

> prompt: Wyjanij pierwszy krok bardziej szczeg贸owo, jakie s ryzyka szczeg贸owo zwizane z pandemi?

```text
Ryzyka s nastpujce:

- Utrata 偶ycia
- Utrata biznesu
- Utrata reputacji
- Utrata klient贸w
- Utrata pracownik贸w
```

Na tym etapie chcemy upewni si, 偶e LLM jest poprawny, wic prosimy go o bardziej szczeg贸owe wyjanienie pierwszego ryzyka i mamy nadziej, 偶e jest zgodne z powy偶sz odpowiedzi:

> prompt: W pandemii, kt贸re ryzyko jest najwiksze i dlaczego?

```text
Najwikszym ryzykiem jest utrata 偶ycia, poniewa偶 jest to najwa偶niejsza rzecz do ochrony.
```

> Jakie s dwa najwiksze ryzyka w pandemii?

```text
Dwa najwiksze ryzyka to utrata 偶ycia i utrata biznesu.
```

Na tym etapie LLM jest sp贸jny i wymienia "偶ycie" i "biznes" jako dwa najwiksze ryzyka. Mo偶emy teraz przej do nastpnego kroku i czu si do pewnie. Jednak nie powinnimy lepo ufa LLM, zawsze powinnimy weryfikowa wyniki.

## R贸偶nicowanie wynik贸w

LLM s z natury niedeterministyczne, co oznacza, 偶e za ka偶dym razem, gdy uruchamiasz ten sam prompt, otrzymasz r贸偶ne wyniki. Wypr贸buj na przykad nastpujcy prompt:

> "Wygeneruj kod dla API webowego w Pythonie"

```python
# Importuj niezbdne moduy
import flask
from flask import request, jsonify

# Utw贸rz aplikacj Flask
app = flask.Flask(__name__)

# Utw贸rz tras dla API
@app.route('/api', methods=['GET'])
def api():
    # Pobierz dane z 偶dania
    data = request.args

    # Przetw贸rz dane
    result = process_data(data)

    # Zwr贸 wynik jako JSON
    return jsonify(result)

# Funkcja do przetwarzania danych
def process_data(data):
    # Zr贸b co z danymi
    result = data + 1

    # Zwr贸 wynik
    return result

# Uruchom aplikacj
if __name__ == '__main__':
    app.run()

```

Uruchomienie tego samego promptu ponownie generuje nieco inn odpowied藕:

```python
#importuj niezbdne pakiety
import flask
from flask import request, jsonify

#utw贸rz aplikacj Flask
app = flask.Flask(__name__)
app.config["DEBUG"] = True

#utw贸rz list ksi偶ek
books = [
    {'id': 0,
     'title': 'A Fire Upon the Deep',
     'author': 'Vernor Vinge',
     'first_sentence': 'The coldsleep itself was dreamless.',
     'year_published': '1992'},
    {'id': 1,
     'title': 'The Ones Who Walk Away From Omelas',
     'author': 'Ursula K. Le Guin',
     'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.',
     'published': '1973'},
    {'id': 2,
     'title': 'Dhalgren',
     'author': 'Samuel R. Delany',
     'first_sentence': 'to wound the autumnal city.',
     'published': '1975'}
]

#utw贸rz endpoint dla API
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Books API</h1>
<p>A prototype API for retrieving books.</p>'''

#utw贸rz endpoint, aby zwr贸ci wszystkie ksi偶ki
@app.route('/api/v1/resources/books/all', methods=['GET'])
def api_all():
    return jsonify(books)

#utw贸rz endpoint, aby zwr贸ci pojedyncz ksi偶k
@app.route('/api/v1/resources/books', methods=['GET'])
def api_id():
    #sprawd藕, czy ID zostao podane jako cz URL
    #jeli ID jest podane, przypisz je do zmiennej
    #jeli nie podano ID, wywietl bd
    if 'id' in request.args:
        id = int(request.args['id'])
    else:
        return "Error: No id field provided. Please specify an id."

    #utw贸rz pust list dla naszych wynik贸w
    results = []

    #przejd藕 przez dane i dopasuj wyniki, kt贸re pasuj do 偶danego ID
    #ID s unikalne, ale inne pola mog zwr贸ci wiele wynik贸w
    for book in books:
        if book['id'] == id:
            results.append(book)

    #u偶yj funkcji jsonify z Flask, aby przekonwertowa nasz list
    #sownik贸w Pythona na format JSON
    return jsonify(results)

app.run()
```

> Czy zr贸偶nicowane wyniki to problem?

Zale偶y od tego, co pr贸bujesz zrobi. Jeli chcesz konkretnej odpowiedzi, to jest to problem. Jeli nie masz nic przeciwko zr贸偶nicowanym wynikom, takim jak "Wygeneruj dowolne 3 pytania dotyczce geografii", to nie jest to problem.

### U偶ywanie temperatury do r贸偶nicowania wynik贸w

Ok, wic zdecydowalimy, 偶e chcemy ograniczy wyniki, aby byy bardziej przewidywalne, czyli bardziej deterministyczne. Jak to zrobi?

Temperatura to warto midzy 0 a 1, gdzie 0 jest najbardziej deterministyczna, a 1 najbardziej zr贸偶nicowana. Domylna warto to 0,7. Zobaczmy, co si stanie przy dw贸ch uruchomieniach tego samego promptu z temperatur ustawion na 0,1:

> "Wygeneruj kod dla API webowego w Pythonie"

```python
#importuj niezbdne biblioteki
import flask
from flask import request, jsonify

#utw贸rz instancj klasy Flask
app = flask.Flask(__name__)

#utw贸rz endpoint dla API
@app.route('/api/v1/endpoint', methods=['GET'])
def api_endpoint():
    #pobierz dane 偶dania
    data = request.get_json()

    #przetw贸rz dane
    result = process_data(data)

    #zwr贸 wynik
    return jsonify(result)

#funkcja do przetwarzania danych
def process_data(data):
    #przetw贸rz dane
    result = {'result': 'success'}

    #zwr贸 wynik
    return result

#uruchom aplikacj Flask
if __name__ == '__main__':
    app.run()

```

Uruchomienie promptu ponownie daje nam taki wynik:

```python
#importuj niezbdne biblioteki
import flask
from flask import request, jsonify

#utw贸rz aplikacj Flask
app = flask.Flask(__name__)

#utw贸rz tras dla API
@app.route('/api', methods=['GET'])
def api_call():
    #pobierz dane z 偶dania
    data = request.get_json()

    #przetw贸rz dane
    result = process_data(data)

    #zwr贸 wynik
    return jsonify(result)

#zdefiniuj funkcj process_data
def process_data(data):
    #zr贸b co z danymi
    result = data + 1

    #zwr贸 wynik
    return result

#uruchom aplikacj
if __name__ == '__main__':
    app.run()

```

Midzy tymi dwoma wynikami jest tylko niewielka r贸偶nica. Zr贸bmy teraz odwrotnie, ustawmy temperatur na 0,9:

```python
# Importuj niezbdne biblioteki
import flask
from flask import request, jsonify

# Utw贸rz aplikacj Flask
app = flask.Flask(__name__)

# Utw贸rz tras dla API
@app.route('/api', methods=['GET'])
def api_call():
    # Pobierz dane z 偶dania
    data = request.args

    # Przetw贸rz dane
    result = process_data(data)

    # Zwr贸 wynik
    return jsonify(result)

# Funkcja do przetwarzania danych
def process_data(data):
    # Zr贸b co z danymi
    result = data + 1

    # Zwr贸 wynik
    return result

# Uruchom aplikacj
if __name__ == '__main__':
    app.run()

```

a druga pr贸ba przy wartoci temperatury 0,9:

```python
import flask
from flask import request, jsonify

# utw贸rz aplikacj Flask
app = flask.Flask(__name__)
app.config['DEBUG'] = True

# utw贸rz przykadowe dane
books = [
    {'id': 0, 'title': 'A Fire Upon The Deep', 'author': 'Vernor Vinge', 'first_sentence': 'The coldsleep itself was dreamless.', 'year_published': '1992'},
    {'id': 1, 'title': 'The Ones Who Walk Away From Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'With a clamor of bells that set the swallows soaring, the Festival of Summer came to the city Omelas, bright-towered by the sea.', 'published': '1973'},
    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'to wound the autumnal city.', 'published': '1975'}
]

# utw贸rz endpoint
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Welcome to our book API!</h1>'''

@app.route('/api/v1/resources/books

```

Jak wida, wyniki nie mogyby by bardziej zr贸偶nicowane.

> Uwaga, istnieje wicej parametr贸w, kt贸re mo偶na zmieni, aby zr贸偶nicowa wyniki, takie jak top-k, top-p, kara za powt贸rzenia, kara za dugo i kara za r贸偶norodno, ale s one poza zakresem tego programu nauczania.

## Dobre praktyki

Istnieje wiele praktyk, kt贸re mo偶esz zastosowa, aby uzyska to, czego chcesz. Znajdziesz sw贸j wasny styl w miar korzystania z promptowania coraz czciej.

Opr贸cz technik, kt贸re om贸wilimy, istnieje kilka dobrych praktyk, kt贸re warto wzi pod uwag podczas promptowania LLM.

Oto kilka dobrych praktyk do rozwa偶enia:

- **Okrel kontekst**. Kontekst ma znaczenie, im wicej mo偶esz okreli, takich jak domena, temat itp., tym lepiej.
- **Ogranicz wyniki**. Jeli chcesz okrelonej liczby element贸w lub okrelonej dugoci, okrel to.
- **Okrel zar贸wno co, jak i jak**. Pamitaj, aby wspomnie zar贸wno o tym, czego chcesz, jak i jak to chcesz, na przykad "Stw贸rz API webowe w Pythonie z trasami products i customers, podziel je na 3 pliki".
- **U偶ywaj szablon贸w**. Czsto bdziesz chcia wzbogaci swoje prompty o dane z Twojej firmy. U偶yj szablon贸w, aby to zrobi. Szablony mog mie zmienne, kt贸re zastpujesz rzeczywistymi danymi.
- **Pisz poprawnie**. LLM mog dostarczy Ci poprawn odpowied藕, ale jeli piszesz poprawnie, uzyskasz lepsz odpowied藕.

## Zadanie

Oto kod w Pythonie pokazujcy, jak zbudowa proste API przy u偶yciu Flask:

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/')
def hello():
    name = request.args.get('name', 'World')
    return f'Hello, {name}!'

if __name__ == '__main__':
    app.run()
```

U偶yj asystenta AI, takiego jak GitHub Copilot lub ChatGPT, i zastosuj technik "self-refine", aby ulepszy kod.

## Rozwizanie

Prosz spr贸buj rozwiza zadanie, dodajc odpowiednie prompty do kodu.

> [!TIP]
> Sformuuj prompt proszc o ulepszenie, dobrym pomysem jest ograniczenie liczby ulepsze. Mo偶esz r贸wnie偶 poprosi o ulepszenie w okrelony spos贸b, na przykad architektur, wydajno, bezpieczestwo itp.

[Rozwizanie](../../python/aoai-solution.py?WT.mc_id=academic-105485-koreyst)

## Sprawdzenie wiedzy

Dlaczego miabym u偶y promptowania chain-of-thought? Poka偶 mi 1 poprawn odpowied藕 i 2 niepoprawne odpowiedzi.

1. Aby nauczy LLM, jak rozwiza problem.
1. B, Aby nauczy LLM znajdowania bd贸w w kodzie.
1. C, Aby poinstruowa LLM, aby znalaz r贸偶ne rozwizania.

A: 1, poniewa偶 chain-of-thought polega na pokazaniu LLM, jak rozwiza problem, dostarczajc mu seri krok贸w oraz podobnych problem贸w i sposob贸w ich rozwizania.

##  Wyzwanie

Wanie u偶ye techniki self-refine w zadaniu. We藕 dowolny program, kt贸ry zbudowae, i zastan贸w si, jakie ulepszenia chciaby w nim wprowadzi. Teraz u偶yj techniki self-refine, aby zastosowa proponowane zmiany. Co sdzisz o wyniku, lepszy czy gorszy?

## wietna Praca! Kontynuuj Nauk

Po ukoczeniu tej lekcji sprawd藕 nasz [kolekcj materia贸w dydaktycznych dotyczcych Generatywnej AI](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby kontynuowa podnoszenie swojej wiedzy o Generatywnej AI!

Przejd藕 do Lekcji 6, aby zobaczy, jak mo偶esz zacz [budowa aplikacje generujce tekst](../../../06-text-generation-apps/translations/pl/README.md?WT.mc_id=academic-105485-koreyst)!
