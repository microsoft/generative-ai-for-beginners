# Creaci√≥n de Indicaciones Avanzados

[![Creaci√≥n de Indicaciones Avanzados](../../images/05-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson5-gh?WT.mc_id=academic-105485-koreyst?WT.mc_id=academic-105485-koreyst)

Repasemos algunos aprendizajes del cap√≠tulo anterior:

> La _ingenier√≠a de indicaciones_ es el proceso mediante el cual **guiamos al modelo hacia respuestas m√°s relevantes** proporcionando instrucciones o contexto m√°s √∫tiles.

Tambi√©n hay dos pasos para escribir indicaciones: construir la indicacion proporcionando contexto relevante y la segunda parte es la _optimizaci√≥n_, c√≥mo mejorar gradualmente el indicacion.

En este punto, tenemos una comprensi√≥n b√°sica de c√≥mo escribir indicaciones, pero necesitamos profundizar. En este cap√≠tulo, pasar√°s de probar varios indicaciones a entender por qu√© un indicacion es mejor que otro. Aprender√°s a construir indicaciones siguiendo algunas t√©cnicas b√°sicas que se pueden aplicar a cualquier LLM.

## Introducci√≥n

En este cap√≠tulo, cubriremos los siguientes temas:

- Ampliar tu conocimiento de la ingenier√≠a de indicaciones aplicando diferentes t√©cnicas a tus indicaciones.
- Configurar tus indicaciones para variar la salida.

## Objetivos de aprendizaje

Despu√©s de completar esta lecci√≥n, podr√°s:

- Aplicar t√©cnicas de ingenier√≠a de indicacion que mejoran el resultado de tus indicaciones.
- Realizar indicaciones que sea variado o determinista.

## Ingenier√≠a de Indicaciones

La ingenier√≠a de indicaciones es el proceso de crear indicaciones que produzcan el resultado deseado. Hay m√°s en la ingenier√≠a de indicaciones que simplemente escribir un texto. La ingenier√≠a de indicaciones no es una disciplina de ingenier√≠a, sino un conjunto de t√©cnicas que puedes aplicar para obtener el resultado deseado.

### Un ejemplo de indicacion

Tomemos una indicacion b√°sica como esta:

> Genera 10 preguntas sobre geograf√≠a.

En este indicacion, en realidad est√°s aplicando un conjunto de t√©cnicas diferentes.

Analicemos esto por partes.

- **Contexto**: especificas que debe ser sobre "geograf√≠a".
- **Limitar la salida**: quieres no m√°s de 10 preguntas.

### Limitaciones de la indicacion simple

Puede que obtengas o no el resultado deseado. Obtendr√°s preguntas generadas, pero la geograf√≠a es un tema amplio y puede que no consigas lo que deseas por las siguientes razones:

- **Tema amplio**: no sabes si ser√° sobre pa√≠ses, capitales, r√≠os, etc.
- **Formato**: y si quer√≠as que las preguntas se formatearan de cierta manera?

Como puedes ver, hay mucho que considerar al crear indicaciones.

Hasta ahora, hemos visto un ejemplo de indicacion simple, pero la IA generativa es capaz de mucho m√°s para ayudar a personas en una variedad de roles e industrias. Exploremos algunas t√©cnicas b√°sicas a continuaci√≥n.

### T√©cnicas para indicaciones

Primero, debemos entender que el indicaciones es una propiedad _emergente_ de un LLM, lo que significa que no es una funci√≥n integrada en el modelo, sino algo que descubrimos al usar el modelo.

Hay algunas t√©cnicas b√°sicas que podemos usar para hacer indicaciones a un LLM. Vamos a explorarlas.

- **Indicacion de cero ejemplos**: esta es la forma m√°s b√°sica de indicaciones. Es un solo indicacion que solicita una respuesta del LLM basada √∫nicamente en sus datos de entrenamiento.
- **Indicacion de pocos ejemplos**: este tipo de indicaciones gu√≠a al LLM proporcionando 1 o m√°s ejemplos en los que puede basarse para generar su respuesta.
- **Cadena de pensamiento**: este tipo de indicaciones le indica al LLM c√≥mo descomponer un problema en pasos.
- **Conocimiento generado**: para mejorar la respuesta de un indicacion, puedes proporcionar hechos o conocimientos generados adem√°s de tu indicacion.
- **De lo m√≠nimo a lo m√°ximo**: al igual que la cadena de pensamiento, esta t√©cnica consiste en dividir un problema en una serie de pasos y luego pedir que se ejecuten en orden.
- **Auto-mejora**: esta t√©cnica consiste en criticar la salida del LLM y luego pedirle que la mejore.
- **Indicacion may√©utico**: lo que quieres aqu√≠ es asegurarte de que la respuesta del LLM sea correcta y le pides que explique varias partes de la respuesta. Esta es una forma de auto-mejora.

### Indicacion de cero ejemplos

Este estilo de indicaciones es muy simple, consiste en un solo indicacion. Esta t√©cnica es probablemente la que est√°s usando cuando empiezas a aprender sobre LLMs. Aqu√≠ tienes un ejemplo:

- indicacion: "Qu√© es el √Ålgebra?"
- Respuesta: "El √°lgebra es una rama de las matem√°ticas que estudia los s√≠mbolos matem√°ticos y las reglas para manipular estos s√≠mbolos."

### indicacion de pocos ejemplos

Este estilo de indicaciones ayuda al modelo proporcionando algunos ejemplos junto con la solicitud. Consiste en un solo indicacion con datos adicionales espec√≠ficos de la tarea. Aqu√≠ tienes un ejemplo:

- Indicacion: "Escribe un poema al estilo de Shakespeare. Aqu√≠ tienes algunos ejemplos de sonetos shakesperianos:
  Soneto 18: 'Compararte con un d√≠a de verano? Eres m√°s hermoso y m√°s templado...'
  Soneto 116: 'No admitir√© impedimentos en la uni√≥n de almas verdaderas. El amor no es amor que cambia cuando encuentra cambios...'
  Soneto 132: 'Tus ojos amo, y ellos, como compadeci√©ndose de m√≠, sabiendo que tu coraz√≥n me atormenta con desd√©n,...'
  Ahora, escribe un soneto sobre la belleza de la luna."
- Respuesta: "Sobre el cielo, la luna suavemente brilla, En luz de plata que lanza su gracia gentil,..."

Los ejemplos le proporcionan al LLM el contexto, formato o estilo de la salida deseada. Ayudan al modelo a entender la tarea espec√≠fica y a generar respuestas m√°s precisas y relevantes.

### Cadena de pensamiento

La cadena de pensamiento es una t√©cnica muy interesante ya que se trata de guiar al LLM a trav√©s de una serie de pasos. La idea es instruir al LLM de tal manera que entienda c√≥mo hacer algo. Considera el siguiente ejemplo, con y sin cadena de pensamiento:

- Indicacion: "Alicia tiene 5 manzanas, lanza 3, da 2 a Bob y Bob le devuelve una. Cu√°ntas manzanas tiene Alicia?"
- Respuesta: 5

El LLM responde con 5, lo cual es incorrecto. La respuesta correcta es 1 manzana, dado el c√°lculo (5 - 3 - 2 + 1 = 1).

Entonces, c√≥mo podemos ense√±arle al LLM a hacer esto correctamente?

Probemos con cadena de pensamiento. Aplicar esta t√©cnica significa:

1. Dar al LLM un ejemplo similar.
2. Mostrar el c√°lculo y c√≥mo se realiza correctamente.
3. Proporcionar el indicacion original.

As√≠ ser√≠a:

- Indicacion: "Lisa tiene 7 manzanas, lanza 1 manzana, da 4 a Bart y Bart le devuelve una:
  7 - 1 = 6  
  6 - 4 = 2  
  2 + 1 = 3  
  Alicia tiene 5 manzanas, lanza 3, da 2 a Bob y Bob le devuelve una. Cu√°ntas manzanas tiene Alicia?"
- Respuesta: 1

Nota c√≥mo escribimos indicaciones sustancialmente m√°s largos con otro ejemplo, un c√°lculo y luego el indicacion original, y llegamos a la respuesta correcta: 1.

Como puedes ver, la cadena de pensamiento es una t√©cnica muy poderosa.

### Conocimiento generado

Muchas veces, cuando quieres construir un indicacion, deseas hacerlo usando los datos de tu propia empresa. Quieres que parte del indicacion provenga de la empresa y la otra parte sea el indicacion en s√≠.

Como ejemplo, as√≠ podr√≠a lucir tu indicacion si trabajas en el sector de seguros:

```text
{{empresa}}: {{nombre_empresa}}
{{productos}}:
{{lista_productos}}
Por favor sugiere un seguro dado el siguiente presupuesto y requisitos:
Presupuesto: {{presupuesto}}
Requisitos: {{requisitos}}
```

Arriba, puede ver c√≥mo se construye la solicitud usando una plantilla. En la plantilla hay varias variables, denotadas por `{{variable}}`, que se reemplazar√°n con valores reales de la API de la empresa.

A continuaci√≥n, se muestra un ejemplo de c√≥mo se ver√≠a la solicitud una vez que las variables se hayan reemplazado con el contenido de su empresa:

```texto
Compa√±√≠a de seguros: ACME Insurance
Productos de seguro (costo mensual):
- Auto, econ√≥mico, 500 USD
- Auto, caro, 1100 USD
- Hogar, econ√≥mico, 600 USD
- Hogar, caro, 1200 USD
- Vida, econ√≥mico, 100 USD

Sugiera un seguro seg√∫n el siguiente presupuesto y requisitos:
Presupuesto: $1000
Requisitos: Seguro de auto, hogar y vida
```

Al ejecutar esta solicitud en un LLM, se obtendr√° una respuesta como esta:

```resultado
Dados el presupuesto y los requisitos, sugerimos el siguiente paquete de seguros de ACME Insurance:
- Auto, econ√≥mico, $500 USD
- Hogar, econ√≥mico, $600 USD
- Vida, econ√≥mico, $100 USD
Costo total: $1,200 USD
```

Como puede ver, tambi√©n sugiere el seguro de vida, lo cual no deber√≠a ocurrir. Este resultado indica que debemos optimizar la solicitud modific√°ndola para que sea m√°s clara sobre lo que permite. Tras varias pruebas, llegamos a la siguiente solicitud:

```texto
Compa√±√≠a de seguros: ACME Insurance
Productos de seguro (costo mensual):
- Tipo: Auto, econ√≥mico, costo: 500 USD
- Tipo: Auto, caro, costo: 1100 USD
- Tipo: Hogar, econ√≥mico, costo: 600 USD
- Tipo: Hogar, caro, costo: 1200 USD
- Tipo: Vida, econ√≥mico, costo: 100 USD

Por favor, sugiera un seguro seg√∫n el siguiente presupuesto y requisitos:
Presupuesto: $1000. Limite la elecci√≥n a los tipos: Auto, Hogar.
```

Observe c√≥mo a√±adir _typo_ y _costo_, as√≠ como usar la palabra clave _restringir_, ayuda al LLM a comprender lo que queremos.

Ahora obtenemos la siguiente respuesta:

```output
Dados el presupuesto y los requisitos, sugerimos el seguro de coche econ√≥mico, que cuesta 500 USD al mes.
```

El objetivo de este ejemplo era mostrar que, aunque utilizamos una t√©cnica b√°sica como el _conocimiento generado_, en la mayor√≠a de los casos necesitamos optimizar la solicitud para obtener el resultado deseado.

### De menor a mayor

La idea de la incitaci√≥n de menor a mayor es descomponer un problema mayor en subproblemas. De esta manera, se ayuda al estudiante de maestr√≠a en c√≥mo abordar el problema principal. Un buen ejemplo podr√≠a ser la ciencia de datos, donde se le puede pedir al estudiante de maestr√≠a que divida un problema de la siguiente manera:

> Incitaci√≥n: C√≥mo realizar ciencia de datos en 5 pasos?

Con la respuesta de tu asistente de IA:

1. Recopilar datos
2. Limpiar datos
3. Analizar datos
4. Graficar datos
5. Presentar datos

### Autorefinar, criticar los resultados

Con las IA generativas y los LLM, no se puede confiar en el resultado. Es necesario verificarlo. Despu√©s de todo, el LLM solo presenta lo que probablemente se diga a continuaci√≥n, no lo que es correcto. Por lo tanto, es recomendable pedirle al LLM que se autocritique, lo que nos lleva a la t√©cnica de autorefinar.

El proceso funciona de la siguiente manera:

1. Indicaci√≥n inicial: pedirle al LLM que resuelva un problema
2. El LLM responde
3. Se critica la respuesta y se le pide a la IA que mejore
4. El LLM responde de nuevo, esta vez considerando la cr√≠tica y sugiriendo las soluciones que encontr√≥

Puede repetir este proceso tantas veces como desee.

Aqu√≠ hay un ejemplo de esta t√©cnica:

> Indicacion: "Crear una API web de Python con rutas de productos y clientes"

Respuesta de la IA:

```python
import flask
app = Flask(__name__)

@app.route('/products')
def products():
    return 'Products'

@app.route('/customers')
def customers():
    return 'Customers'
```

> Indicacion: Sugiera 3 mejoras al c√≥digo anterior

Respuesta de la IA:

```texto
Claro, aqu√≠ tienes tres sugerencias para mejorar el c√≥digo:

Importar el m√≥dulo correcto: La primera l√≠nea deber√≠a importar Flask en lugar de flask. La sentencia de importaci√≥n correcta deber√≠a ser `from flask import Flask`.

A√±adir una funci√≥n principal: A√±adir un bloque `if __name__ == '__main__':` al final del archivo para ejecutar la aplicaci√≥n cuando se ejecute el archivo.

Usar cadenas f: Usar cadenas f para dar formato a las sentencias de retorno en las funciones de ruta. Por ejemplo, `return 'Products'` se puede cambiar a `return f'This is the {request.path} page'. 
```

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/products')
def products():
    return f'Esta es la p√°gina {request.path}'

@app.route('/customers')
def customers():
    return f'Esta es la p√°gina {request.path}'

if __name__ == '__main__':
    app.run()
```

Como puede ver, la respuesta de IA anterior mejora el primer c√≥digo sugerido gracias a la cr√≠tica de la primera respuesta.

### Incitaci√≥n may√©utica

La incitaci√≥n may√©utica es una t√©cnica similar al autorefinamiento, pero consiste m√°s en pedirle al LLM que se explique. El objetivo es reducir las inconsistencias en la salida del LLM para garantizar que llegue a la respuesta correcta. El flujo de trabajo a seguir es:

1. Pedirle al LLM que responda una pregunta.
2. Para cada parte de la respuesta, pedirle al LLM que la explique con m√°s detalle.
3. Si hay inconsistencias, descartar las partes inconsistentes.

Repetir los pasos 2 y 3 hasta que haya revisado todas las partes y est√© satisfecho con la respuesta.

Aqu√≠ hay un ejemplo de incitaci√≥n:

> Incitaci√≥n: C√≥mo puedo crear un plan de crisis para mitigar una pandemia en 5 pasos?

Respuesta del LLM:

```texto
1. Identificar los riesgos
2. Identificar a las partes interesadas
3. Identificar los recursos
4. Identificar las acciones
5. Identificar los canales de comunicaci√≥n
```

Se identifican 5 pasos, pero podemos determinar si es correcto? Pidamos al LLM que explique cada paso:

> Pregunta: Explique el primer paso con m√°s detalle. Cu√°les son los riesgos espec√≠ficos de una pandemia?

```texto
Los riesgos son los siguientes:

- P√©rdida de vidas
- P√©rdida de negocios
- P√©rdida de reputaci√≥n
- P√©rdida de clientes
- P√©rdida de empleados
```

En este punto, queremos asegurarnos de que el LLM sea correcto, por lo que le solicitamos que explique el primer riesgo con m√°s detalle y esperamos que sea coherente con la respuesta anterior:

> Pregunta: En una pandemia, cu√°l es el mayor riesgo y por qu√©?

``texto
El mayor riesgo es la p√©rdida de vidas, ya que es lo m√°s importante que debemos proteger.
```

> Cu√°les son los dos mayores riesgos en una pandemia?

``texto
Los dos mayores riesgos son la p√©rdida de vidas y la p√©rdida de negocios.
```

En este punto, el LLM es coherente y menciona "vida" y "negocios" como los dos riesgos principales. Ahora podemos continuar con el siguiente paso con bastante confianza. Sin embargo, no debemos confiar ciegamente en el LLM; siempre debemos verificar el resultado.

## Var√≠a tu salida

Los LLM no son deterministas por naturaleza, lo que significa que obtendr√° resultados diferentes cada vez que ejecute el mismo mensaje. Pruebe el siguiente mensaje, por ejemplo:

> "Generar c√≥digo para una API web de Python"

```python
# Importar los m√≥dulos necesarios
import flask
from flask import request, jsonify

# Crear una aplicaci√≥n Flask
app = flask.Flask(__name__)

# Crear una ruta para la API
@app.route('/api', methods=['GET'])
def api():
    # Obtener los datos de la solicitud
    data = request.args

    # Procesar los datos
    result = process_data(data)

    # Devolver el resultado como JSON
    return jsonify(result)

# Funci√≥n para procesar los datos
def process_data(data):
    # Hacer algo con los datos
    result = data + 1

    # Devolver el resultado
    return result

# Ejecutar la aplicaci√≥n
if __name__ == '__main__':
    app.run()

```

Al ejecutar el mismo mensaje de nuevo, se genera un resultado ligeramente diferente. Respuesta:

```python
#importar paquetes necesarios
import flask
from flask import request, jsonify

#crear la aplicaci√≥n Flask
app = flask.Flask(__name__)
app.config["DEBUG"] = True

#crear una lista de libros
books = [
    {'id': 0,
        'title': 'Un fuego en las profundidades',
        'author': 'Vernor Vinge',
        'first_sentence': 'El criosue√±o en s√≠ mismo no tuvo sue√±os.',
        'year_published': '1992'},
    {'id': 1,
        'title': 'Los que se alejan de Omelas',
        'author': 'Ursula K. Le Guin',
        'first_sentence': 'Con un clamor de campanas que hizo remontar el vuelo a las golondrinas, el Festival de Verano lleg√≥ a la ciudad de Omelas, con sus brillantes torres junto al mar.',
        'year_published': 1973},
    {'id': 2,
        'title': Dhalgren,
        'author': Samuel R. Delany,
        'first_sentence': herir la ciudad oto√±al,
        'year_published': 1975},
]

#Crear un punto de conexi√≥n para la API
@app.route('/', methods=['GET'])
def home():
    return '''<h1>API de Libros</h1>
<p>Un prototipo de API para recuperar libros.</p>'''

#Crear un punto de conexi√≥n para devolver todos los libros
@app.route('/api/v1/resources/books/all', methods=['GET'])
def api_all():
    return jsonify(books)

#Crear un punto de conexi√≥n para devolver un solo libro
@app.route('/api/v1/resources/books', methods=['GET'])
def api_id():
    #Comprobar si se proporcion√≥ un ID como parte de la URL
    #Si se proporciona un ID, asignarlo a una variable
    #Si no se proporciona un ID, mostrar un error
    if 'id' in request.args:
        id = int(request.args['id'])
    else:
        return "Error: No se proporcion√≥ el campo id. Por favor, especifique un id."

    #crear una lista vac√≠a para nuestros resultados
    results = []

    #recorrer los datos y encontrar los resultados que coincidan con el id solicitado
    #Los id son √∫nicos, pero otros campos pueden devolver muchos resultados
    for book in books:
        if book['id'] == id:
            results.append(book)

    #usar la funci√≥n jsonify de Flask para convertir nuestra lista de #diccionarios de Python al formato JSON
    return jsonify(results)

app.run()
```

> Entonces, la salida variada es un problema?

Depende de lo que intentes hacer. Si quieres una respuesta espec√≠fica, es un problema. Si te parece bien una salida variada como "Generar 3 preguntas cualesquiera sobre geograf√≠a", entonces no es un problema.

### Uso de la temperatura para variar la salida

Bien, hemos decidido limitar la salida para que sea m√°s predecible, es decir, m√°s determinista. C√≥mo lo hacemos?

La temperatura es un valor entre 0 y 1, donde 0 es el m√°s determinista y 1 el m√°s variable. El valor predeterminado es 0,7. Veamos qu√© sucede con dos ejecuciones del mismo indicacion con la temperatura establecida en 0,1:

> "Generar c√≥digo para una API web de Python"

```python
#importar bibliotecas necesarias
import flask
from flask import request, jsonify
#Crear una instancia de la clase Flask
app = flask.Flask(__name__)

#Crear un endpoint para la API
@app.route('/api/v1/endpoint', methods=['GET'])
def api_endpoint():
    #Obtener los datos de la solicitud
    data = request.get_json()

    #Procesar los datos
    result = process_data(data)

    #Devolver el resultado
    return jsonify(result)

#Funci√≥n para procesar los datos
def process_data(data):
    #Procesar los datos
    result = {'result': 'success'}

    #Devolver el resultado
    return result

#Ejecutar la aplicaci√≥n Flask
if __name__ == '__main__':
    app.run()

```

Al ejecutar el indicacion de nuevo, obtenemos este resultado:

```python
#Importar las bibliotecas necesarias
import flask
from flask import request, jsonify

#Crear una aplicaci√≥n Flask
app = flask.Flask(__name__)

#Crear una ruta para la API
@app.route('/api', methods=['GET'])
def api_call():
    #Obtener los datos de la solicitud
    data = request.get_json()

    #Procesar los datos
    result = process_data(data)

    #Devolver el resultado
    return jsonify(result)

#Definir la funci√≥n process_data
def process_data(data):
    #Hacer algo con los datos
    result = data + 1

    #Devolver el resultado
    return result

#Ejecutar la aplicaci√≥n
if __name__ == '__main__':
    app.run()

```

Hay solo una peque√±a diferencia entre estas dos salidas. Esta vez, hagamos lo contrario: establezcamos la temperatura en 0.9:

```python
# Importar las bibliotecas necesarias
import flask
from flask import request, jsonify

# Crear una aplicaci√≥n Flask
app = flask.Flask(__name__)

# Crear una ruta para la API
@app.route('/api', methods=['GET'])
def api_call():
    # Obtener los datos de la solicitud
    data = request.args

    # Procesar los datos
    result = process_data(data)

    # Devolver el resultado
    return jsonify(result)

# Funci√≥n para procesar los datos
def process_data(data):
    # Hacer algo con los datos
    result = data + 1
    # Devuelve el resultado
    return result

# Ejecuta la aplicaci√≥n
if __name__ == '__main__':
    app.run()

```

y el segundo intento con 0.9 como valor de temperatura:

```python
import flask
from flask import request, jsonify

# Crea la aplicaci√≥n Flask
app = flask.Flask(__name__)
app.config['DEBUG'] = True

# Crea algunos datos de prueba
books = [
    {'id': 0, 'title': 'Un fuego en las profundidades', 'author': 'Vernor Vinge', 'first_sentence': 'El criosue√±o en s√≠ no ten√≠a sue√±os', 'year_published': '1992'},
    {'id': 1, 'title': 'Los que se alejan de Omelas', 'author': 'Ursula K. Le Guin', 'first_sentence': 'Con un El clamor de las campanas hizo remontar el vuelo a las golondrinas; el Festival de Verano lleg√≥ a la ciudad de Omelas, coronada de brillantes torres por el mar.', 'published': '1973'},
    {'id': 2, 'title': 'Dhalgren', 'author': 'Samuel R. Delany', 'first_sentence': 'para herir la ciudad oto√±al.', 'published': '1975'}
]

# crear un punto final
@app.route('/', methods=['GET'])
def home():
    return '''<h1>Bienvenido a nuestra API de libros!</h1>'''

@app.route('/api/v1/resources/books')

```

Como puede ver, los resultados son muy variados.

> Tenga en cuenta que hay m√°s par√°metros que puede cambiar para variar la salida, como top-k, top-p y repetici√≥n. Penalizaci√≥n por extensi√≥n, penalizaci√≥n por diversidad y penalizaci√≥n por incitaci√≥n, pero estas quedan fuera del alcance de este programa.

## Buenas pr√°cticas

Hay muchas pr√°cticas que puedes aplicar para intentar conseguir lo que quieres. Encontrar√°s tu propio estilo a medida que uses m√°s las indicaciones.

Adem√°s de las t√©cnicas que hemos visto, hay algunas buenas pr√°cticas que debes considerar al incitar a un LLM.

Aqu√≠ tienes algunas buenas pr√°cticas:

- **Especificar el contexto**. El contexto es importante; cuanto m√°s especifiques, como el dominio, el tema, etc., mejor.
- Limitar el resultado. Si deseas un n√∫mero espec√≠fico de elementos o una longitud espec√≠fica, especif√≠calo.
- **Especificar qu√© y c√≥mo**. Recuerda mencionar qu√© quieres y c√≥mo lo quieres, por ejemplo, "Crear una API web de Python con rutas, productos y clientes, dividi√©ndola en 3 archivos".
- **Usar plantillas**. A menudo, querr√°s enriquecer tus indicaciones con datos de tu empresa. Usa plantillas para ello. Las plantillas pueden tener variables que puedes reemplazar con datos reales.
- **Escribir correctamente**. Los LLM pueden proporcionarte Una respuesta correcta, pero si escribes correctamente, obtendr√°s una mejor respuesta.

## Tarea
Aqu√≠ tienes un c√≥digo en Python que muestra c√≥mo crear una API sencilla con Flask:

```python
from flask import Flask, request

app = Flask(__name__)

@app.route('/')
def hello():
    name = request.args.get('name', 'World')
    return f'Hello, {name}!'

if __name__ == '__main__':
    app.run()
```

Usa un asistente de IA como GitHub Copilot o ChatGPT y aplica la t√©cnica de autorefinamiento para mejorar el c√≥digo.

## Soluci√≥n

Intenta resolver la tarea a√±adiendo indicaciones adecuadas al c√≥digo.

> [!TIP]
> Crea una indicaci√≥n para pedirle que mejore. Es recomendable limitar el n√∫mero de mejoras. Tambi√©n puedes pedir que se mejore de alguna manera, por ejemplo, la arquitectura, el rendimiento, la seguridad, etc.

[Soluci√≥n](../../python/aoai-solution.py?WT.mc_id=academic-105485-koreyst)

## Prueba de conocimientos

Por qu√© deber√≠a usar la t√©cnica de cadena de pensamiento? Mu√©strame una respuesta correcta y dos incorrectas.

1. Para ense√±ar al LLM a resolver un problema.
2. Para ense√±ar al LLM a encontrar errores en el c√≥digo.
3. Para indicar al LLM que proponga diferentes soluciones.

R: 1. Porque la t√©cnica de cadena de pensamiento consiste en mostrar al LLM c√≥mo resolver un problema, proporcion√°ndole una serie de pasos, problemas similares y c√≥mo se resolvieron.

## üöÄ Desaf√≠o

Acabas de usar la t√©cnica de autorefinamiento en la tarea. Considera cualquier programa que hayas creado y qu√© mejoras te gustar√≠a aplicarle. Ahora usa la t√©cnica de autorefinamiento para aplicar los cambios propuestos. Qu√© te pareci√≥ el resultado, mejor o peor?

## Buen trabajo! Contin√∫a aprendiendo.

Despu√©s de completar esta lecci√≥n, consulta nuestra [colecci√≥n de aprendizaje de IA generativa](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para seguir mejorando tus conocimientos de IA generativa.

Dir√≠gete a la Lecci√≥n 6, donde aplicaremos nuestros conocimientos de Ingenier√≠a de [indicacion creando aplicaciones de generaci√≥n de texto](../../../06-text-generation-apps/translations/es-mx/README.md?WT.mc_id=academic-105485-koreyst)