# Fundamentos de Engenharia de Prompt

[![Prompt Engineering Fundamentals](../../images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://learn.microsoft.com/_themes/docs.theme/master/en-us/_themes/global/video-embed.html?id=d54c0c69-b183-4a6c-80ed-8b1a8f299cff?WT.mc_id=academic-105485-koreyst)

A forma como voc√™ escreve seu prompt para o LLM importa. Um prompt cuidadosamente elaborado pode alcan√ßar um resultado melhor do que um que n√£o √©. Mas o que s√£o esses conceitos, prompt, Engenharia de Prompt e como posso melhorar o que envio para o LLM? Perguntas como essas s√£o o que este cap√≠tulo e o pr√≥ximo est√£o procurando responder.

_A IA Generativa_ √© capaz de criar novo conte√∫do (por exemplo, texto, imagens, √°udio, c√≥digo etc.) em resposta a solicita√ß√µes do usu√°rio. Isso √© alcan√ßado usando _Modelos de Linguagem Grandes_ (LLMs) como a s√©rie GPT ("Generative Pre-trained Transformer") da OpenAI, que s√£o treinados para usar linguagem natural e c√≥digo.

Os usu√°rios agora podem interagir com esses modelos usando paradigmas familiares como chat, sem precisar de nenhuma experi√™ncia t√©cnica ou treinamento. Os modelos s√£o _baseados em prompt_ - os usu√°rios enviam uma entrada de texto (prompt) e recebem a resposta da IA (completa√ß√£o). Eles podem ent√£o "conversar com a IA" de forma iterativa, em conversas de v√°rias rodadas, refinando seu prompt at√© que a resposta atenda √†s suas expectativas.

"Prompts" agora se tornam a principal _interface de programa√ß√£o_ para aplicativos de IA generativa, indicando aos modelos o que fazer e influenciando a qualidade das respostas retornadas. "Engenharia de Prompt" √© um campo de estudo em r√°pido crescimento que se concentra no _design e otimiza√ß√£o_ de prompts para fornecer respostas consistentes e de qualidade em escala.

## Metas de Aprendizado

Nesta li√ß√£o, aprenderemos o que √© Engenharia de Prompt, por que isso √© importante e como podemos criar prompts mais eficazes para um modelo e objetivo de aplicativo espec√≠ficos. Compreenderemos os conceitos centrais e as melhores pr√°ticas para a Engenharia de Prompt - e conheceremos um ambiente interativo de Jupyter Notebooks "sandbox" onde podemos ver esses conceitos aplicados a exemplos reais.

Ao final desta li√ß√£o, seremos capazes de:

1. Explicar o que √© Engenharia de Prompt e por que isso importa.
2. Descrever os componentes de um prompt e como eles s√£o usados.
3. Aprender melhores pr√°ticas e t√©cnicas para a Engenharia de Prompt.
4. Aplicar t√©cnicas aprendidas a exemplos reais, usando um endpoint da OpenAI.

## Sandbox de Aprendizado

A Engenharia de Prompt √© atualmente mais uma arte do que uma ci√™ncia. A melhor maneira de aprimorar nossa intui√ß√£o √© _praticar mais_ e adotar uma abordagem de tentativa e erro que combine experi√™ncia no dom√≠nio de aplica√ß√£o com t√©cnicas recomendadas e otimiza√ß√µes espec√≠ficas do modelo.

O Jupyter Notebook que acompanha esta li√ß√£o, fornece um ambiente _sandbox_ onde voc√™ pode experimentar o que aprende - √† medida que avan√ßa ou como parte do desafio de c√≥digo no final. Para executar os exerc√≠cios, voc√™ precisar√° de:

1. Uma chave de API da OpenAI - o endpoint de servi√ßo para um LLM implantado.

2. Um tempo de execu√ß√£o Python - no qual o Notebook pode ser executado.

N√≥s instrumentamos este reposit√≥rio com um _cont√™iner de desenvolvimento_ (_dev container_) que vem com um tempo de execu√ß√£o Python 3. Abra simplesmente o reposit√≥rio no GitHub Codespaces ou no seu Docker Desktop localmente para ativar o tempo de execu√ß√£o automaticamente. Em seguida, abra o notebook e selecione o kernel Python 3.x para preparar o Notebook para execu√ß√£o.

O notebook padr√£o est√° configurado para uso com uma chave de API da OpenAI. Basta copiar o arquivo `.env.copy` na raiz da pasta para `.env` e atualizar a linha `OPENAI_API_KEY=` com sua chave de API - e voc√™ estar√° pronto.

O notebook vem com exerc√≠cios _iniciais_, mas voc√™ √© incentivado a adicionar suas pr√≥prias se√ß√µes de _Markdown_ (descri√ß√£o) e _C√≥digo_ (solicita√ß√µes de prompt) para experimentar mais exemplos ou ideias - e construir sua intui√ß√£o para o design de prompt.

## Nossa Startup

Agora, vamos falar sobre como _esse t√≥pico_ se relaciona com a miss√£o de nossa startup de [trazer inova√ß√£o de IA para a educa√ß√£o](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos criar aplica√ß√µes de aprendizado personalizado impulsionados por IA. Ent√£o, vamos pensar em como diferentes usu√°rios da nossa aplica√ß√£o podem "projetar" prompts:

- **Administradores** podem pedir √† IA para _analisar dados do curr√≠culo para identificar lacunas na cobertura_. A IA pode resumir os resultados ou visualiz√°-los com c√≥digo.
- **Educadores** podem pedir √† IA para _gerar um plano de aula para um p√∫blico-alvo e t√≥pico_. A IA pode criar o plano personalizado em um formato especificado.
- **Alunos** podem pedir √† IA para _ajud√°-los em uma disciplina dif√≠cil_. A IA pode orientar os alunos com li√ß√µes, dicas e exemplos adaptados ao seu n√≠vel.

Isso √© apenas a ponta do iceberg. Confira [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - uma biblioteca de prompts de c√≥digo aberto curada por especialistas em educa√ß√£o - para ter uma vis√£o mais ampla das possibilidades! _Experimente executar alguns desses prompts na sandbox ou usando o OpenAI Playground para ver o que acontece!_

<!--
MODELO DE LI√á√ÉO:
Esta unidade deve abordar o conceito principal #1.
Reforce o conceito com exemplos e refer√™ncias.

CONCEITO #1:
Engenharia de Prompt.
Defina-o e explique por que √© necess√°rio.
-->

## O que √© Engenharia de Prompt?

Come√ßamos esta li√ß√£o definindo **Engenharia de Prompt** como o processo de _projetar e otimizar_ entradas de texto (prompts) para fornecer respostas consistentes e de qualidade (completions) para um objetivo de aplicativo e modelo espec√≠ficos. Podemos pensar nisso como um processo de 2 etapas:

- _projetar_ o prompt inicial para um modelo e objetivo espec√≠ficos
- _refinar_ iterativamente o prompt para melhorar a qualidade da resposta

Isso √© necessariamente um processo de tentativa e erro que requer intui√ß√£o do usu√°rio e esfor√ßo para obter resultados √≥timos. Ent√£o, por que √© importante? Para responder a essa pergunta, primeiro precisamos entender tr√™s conceitos:

- _Tokeniza√ß√£o_ = como o modelo "enxerga" o prompt
- _Base LLMs_ = como o modelo fundamental "processa" um prompt
- _Instruction-Tuned LLMs_ = como o modelo agora pode ver "tarefas"

### Tokeniza√ß√£o

Um LLM v√™ prompts como uma _sequ√™ncia de tokens_ onde diferentes modelos (ou vers√µes de um modelo) podem tokenizar o mesmo prompt de maneiras diferentes. Como os LLMs s√£o treinados em tokens (n√£o em texto bruto), a forma como os prompts s√£o tokenizados tem um impacto direto na qualidade da resposta gerada.

Para ter uma intui√ß√£o de como a tokeniza√ß√£o funciona, experimente ferramentas como o [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) mostrado abaixo. Copie seu prompt e veja como ele √© convertido em tokens, prestando aten√ß√£o em como caracteres de espa√ßo em branco e pontua√ß√µes s√£o tratados. Note que este exemplo mostra um LLM mais antigo (GPT-3) - ent√£o, tentar isso com um modelo mais recente pode produzir um resultado diferente.

![Tokenization](../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

### Conceito: Modelos Fundamentais

Uma vez que um prompt √© tokenizado, a fun√ß√£o principal do ["Base LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (ou modelo fundamental) √© prever o token nessa sequ√™ncia. Como os LLMs s√£o treinados em conjuntos massivos de dados de texto, eles t√™m uma boa compreens√£o das rela√ß√µes estat√≠sticas entre tokens e podem fazer essa previs√£o com alguma confian√ßa.

> Observa√ß√£o: eles n√£o compreendem o _significado_ das palavras no prompt ou token; eles apenas veem um padr√£o que podem "completar" com sua pr√≥xima previs√£o. Eles podem continuar prevendo a sequ√™ncia at√© serem interrompidos pela interven√ß√£o do usu√°rio ou alguma condi√ß√£o preestabelecida.

Desejam ver como a conclus√£o baseada em prompts funciona? Insira o prompt acima no [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) do Azure OpenAI Studio com as configura√ß√µes padr√£o. O sistema est√° configurado para tratar prompts como solicita√ß√µes de informa√ß√£o - ent√£o, voc√™ deve ver uma conclus√£o que atende a esse contexto.

Mas e se o usu√°rio quiser ver algo espec√≠fico que atenda a alguns crit√©rios ou objetivos de tarefa? √â aqui que os LLMs _instru√≠dos_ entram em cena.

![Base LLM Chat Completion](../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst)

### Conceito: LLMs Instru√≠dos

Um [LLM Instru√≠do](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) come√ßa com o modelo fundamental e o ajusta com exemplos ou pares de entrada/sa√≠da (por exemplo, "mensagens" de v√°rias rodadas) que podem conter instru√ß√µes claras - e a resposta da IA tenta seguir essa instru√ß√£o.

Isso usa t√©cnicas como Aprendizado por Refor√ßo com Feedback Humano (ARFH) que podem treinar o modelo a _seguir instru√ß√µes_ e _aprender com feedback_ para que produza respostas mais adequadas a aplica√ß√µes pr√°ticas e mais relevantes para objetivos do usu√°rio.

Vamos experimentar - revisite o prompt acima, mas agora altere a _mensagem do sistema_ para fornecer a seguinte instru√ß√£o como contexto:

> _Summarize content you are provided with for a second-grade student. Keep the result to one paragraph with 3-5 bullet points._

Veja como o resultado agora est√° ajustado para refletir o objetivo desejado e o formato? Um educador pode agora usar diretamente essa resposta em seus slides para aquela aula.

![Instruction Tuned LLM Chat Completion](../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)

## Por que precisamos de Engenharia de Prompt?

Agora que sabemos como os prompts s√£o processados pelos LLMs, vamos falar sobre _por que_ precisamos de Engenharia de Prompt. A resposta est√° no fato de que os LLMs atuais apresentam uma s√©rie de desafios que tornam as _completions confi√°veis e consistentes_ mais dif√≠ceis de alcan√ßar sem esfor√ßo na cria√ß√£o e otimiza√ß√£o do prompt. Por exemplo:

1. **As respostas do modelo s√£o estoc√°sticas.** O _mesmo prompt_ provavelmente produzir√° respostas diferentes com modelos ou vers√µes diferentes do modelo. E pode at√© mesmo produzir resultados diferentes com o _mesmo modelo_ em momentos diferentes. _T√©cnicas de Wngenharia de Prompt podem nos ajudar a minimizar essas varia√ß√µes fornecendo melhores diretrizes_.

1. **Os modelos podem criar respostas imagin√°rias.** Os modelos s√£o pr√©-treinados com conjuntos de dados _grandes, mas finitos_, o que significa que eles n√£o t√™m conhecimento sobre conceitos fora desse escopo de treinamento. Como resultado, podem produzir completions imprecisas, imagin√°rias ou diretamente contradit√≥rias aos fatos conhecidos. _T√©cnicas de Engenharia de Prompt ajudam os usu√°rios a identificar e mitigar alucina√ß√µes, por exemplo, pedindo √† IA por cita√ß√µes ou racioc√≠nio_.

1. **As capacidades dos modelos variar√£o.** Modelos ou gera√ß√µes de modelos mais recentes ter√£o capacidades mais ricas, mas tamb√©m trar√£o peculiaridades e compensa√ß√µes √∫nicas em termos de custo e complexidade. _A Engenharia de Prompt pode nos ajudar a desenvolver melhores pr√°ticas e fluxos de trabalho que abstraem diferen√ßas e se adaptam aos requisitos espec√≠ficos do modelo de maneira escal√°vel e cont√≠nua_.

Vamos ver isso em a√ß√£o no OpenAI ou Azure OpenAI Playground:

- Use o mesmo prompt com diferentes implanta√ß√µes de LLM (por exemplo, OpenAI, Azure OpenAI, Hugging Face) - voc√™ viu as varia√ß√µes?
- Use o mesmo prompt repetidamente com a _mesma_ implanta√ß√£o de LLM (por exemplo, Azure OpenAI Playground) - como essas varia√ß√µes diferiram?

### Exemplo de Alucina√ß√µes

Quer ter uma ideia de como as alucina√ß√µes funcionam? Pense em um prompt que instrua a IA a gerar conte√∫do para um t√≥pico inexistente (para garantir que n√£o seja encontrado no conjunto de dados de treinamento). Por exemplo - eu tentei este prompt:

> **Prompt:** generate a lesson plan on the Martian War of 2076.

Uma busca na web mostrou que havia relatos fict√≠cios (por exemplo, s√©ries de televis√£o ou livros) sobre guerras marcianas - mas nenhuma em 2076. O bom senso tamb√©m nos diz que 2076 est√° _no futuro_ e, portanto, n√£o pode ser associado a um evento real.

Ent√£o, o que acontece quando executamos este prompt com diferentes provedores de LLM?

> **Resposta 1**: OpenAI Playground (GPT-35)

![Resposta 1](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)

> **Resposta 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)

> **Resposta 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)

Como esperado, cada modelo (ou vers√£o do modelo) produz respostas ligeiramente diferentes devido ao comportamento estoc√°stico e varia√ß√µes nas capacidades do modelo. Por exemplo, um modelo tem como alvo uma audi√™ncia do 8¬∫ ano, enquanto o outro assume um estudante do ensino m√©dio. Mas os tr√™s modelos geraram respostas que poderiam convencer um usu√°rio desinformado de que o evento era real.

T√©cnicas de engenharia de prompt como _metaprompting_ e _configura√ß√£o de temperatura_ podem reduzir as alucina√ß√µes do modelo em certa medida. Novas _arquiteturas_ de engenharia de prompt tamb√©m incorporam novas ferramentas e t√©cnicas de maneira cont√≠nua no fluxo do prompt, para mitigar ou reduzir alguns desses efeitos.

## Estudo de Caso: GitHub Copilot

Vamos concluir esta se√ß√£o entendendo como a engenharia de prompt √© utilizada em solu√ß√µes do mundo real ao analisar um Estudo de Caso: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

O GitHub Copilot √© seu "Programador de Par IA" - ele converte prompts de texto em conclus√µes de c√≥digo e est√° integrado ao seu ambiente de desenvolvimento (por exemplo, Visual Studio Code) para uma experi√™ncia do usu√°rio sem interrup√ß√µes. Como documentado na s√©rie de blogs abaixo, a vers√£o mais antiga era baseada no modelo OpenAI Codex - com os engenheiros percebendo rapidamente a necessidade de ajustar o modelo e desenvolver t√©cnicas melhores de engenharia de prompt para melhorar a qualidade do c√≥digo. Em julho, eles [apresentaram um modelo de IA aprimorado que vai al√©m do Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugest√µes ainda mais r√°pidas.

Leia as postagens na ordem para seguir a jornada de aprendizado deles.

- **Maio de 2023** | [GitHub Copilot est√° Melhorando na Compreens√£o do Seu C√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maio de 2023** | [Dentro do GitHub: Trabalhando com os LLMs por tr√°s do GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Junho de 2023** | [Como Escrever Melhores Prompts para o GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Julho de 2023** | [.. GitHub Copilot vai al√©m do Codex com modelo de IA aprimorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Julho de 2023** | [Guia do Desenvolvedor para Engenharia de Prompt e LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Setembro de 2023** | [Como construir um aplicativo empresarial LLM: Li√ß√µes do GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Voc√™ tamb√©m pode navegar pelo [blog de Engenharia deles](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para mais postagens como [esta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que mostra como esses modelos e t√©cnicas s√£o _aplicados_ para impulsionar aplica√ß√µes do mundo real.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Constru√ß√£o de Prompt

Vimos por que a Engenharia de Prompt √© importante - agora vamos entender como os prompts s√£o _constru√≠dos_ para que possamos avaliar diferentes t√©cnicas para um design de prompt mais eficaz.

### Prompt B√°sico

Vamos come√ßar com o prompt b√°sico: uma entrada de texto enviada ao modelo sem nenhum outro contexto. Aqui est√° um exemplo - quando enviamos as primeiras palavras do hino nacional dos EUA para a [API de Completions da OpenAI](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), ela instantaneamente _completa_ a resposta com as pr√≥ximas linhas, ilustrando o comportamento b√°sico de previs√£o.

| Prompt (Input)     | Completion (Output)                                                                                                                        |
| :----------------- | :----------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | It sounds like you're starting the lyrics to "The Star-Spangled Banner," the national anthem of the United States. The full lyrics are ... |

### Prompt Complexo

Agora, vamos adicionar contexto e instru√ß√µes a esse prompt b√°sico. A [API de Completions de Chat](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir um prompt complexo como uma cole√ß√£o de _mensagens_ com:

- Pares de entrada/sa√≠da refletindo a entrada do _usu√°rio_ e a resposta do _assistente_.
- Mensagem do sistema definindo o contexto para o comportamento ou personalidade do assistente.

A solicita√ß√£o agora est√° na forma abaixo, onde a _tokeniza√ß√£o_ captura efetivamente informa√ß√µes relevantes do contexto e da conversa. Agora, alterar o contexto do sistema pode ter um impacto significativo na qualidade dos completamentos, assim como as entradas do usu√°rio fornecidas.

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "Voc√™ √© um assistente prestativo."},
        {"role": "user", "content": "Quem ganhou a s√©rie mundial em 2020?"},
        {"role": "assistant", "content": "O Los Angeles Dodgers venceu a S√©rie Mundial em 2020."},
        {"role": "user", "content": "Onde foi jogado?"}
    ]
)
```

### Prompt de Instru√ß√£o

Nos exemplos acima, o prompt do usu√°rio era uma simples consulta de texto que pode ser interpretada como uma solicita√ß√£o de informa√ß√µes. Com prompts de _instru√ß√£o_, podemos usar esse texto para especificar uma tarefa de maneira mais detalhada, fornecendo orienta√ß√µes melhores para a IA. Aqui est√° um exemplo:

| Prompt (Input)                                                                                                                                                                                                                         | Completion (Output)                                                                                                        | Instruction Type    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Write a description of the Civil War                                                                                                                                                                                                   | _returned a simple paragraph_                                                                                              | Simple              |
| Write a description of the Civil War. Provide key dates and events and describe their significance                                                                                                                                     | _returned a paragraph followed by a list of key event dates with descriptions_                                             | Complex             |
| Write a description of the Civil War in 1 paragraph. Provide 3 bullet points with key dates and their significance. Provide 3 more bullet points with key historical figures and their contributions. Return the output as a JSON file | _returns more extensive details in a text box, formatted as JSON that you can copy-paste to a file and validate as needed_ | Complex. Formatted. |

## Conte√∫do Prim√°rio

Nos exemplos acima, o prompt ainda era bastante aberto, permitindo que o LLM decidisse qual parte de seu conjunto de dados pr√©-treinado era relevante. Com o padr√£o de design de _conte√∫do prim√°rio_, o texto de entrada √© dividido em duas partes:

- uma instru√ß√£o (a√ß√£o)
- conte√∫do relevante (que influencia a a√ß√£o)

Aqui est√° um exemplo em que a instru√ß√£o √©: "resuma isso em 2 frases".

| Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Completion (Output)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. It is named after the Roman god Jupiter.[19] When viewed from Earth, Jupiter can be bright enough for its reflected light to cast visible shadows,[20] and is on average the third-brightest natural object in the night sky after the Moon and Venus. <br/> **Summarize this in 2 short sentences** | Jupiter, the fifth planet from the Sun, is the largest in the Solar System and is known for being one of the brightest objects in the night sky. Named after the Roman god Jupiter, it's a gas giant whose mass is two-and-a-half times that of all other planets in the Solar System combined. |

O segmento de conte√∫do prim√°rio pode ser usado de v√°rias maneiras para impulsionar instru√ß√µes mais eficazes:

- **Exemplos** - em vez de dizer explicitamente ao modelo o que fazer com uma instru√ß√£o expl√≠cita, d√™ a ele exemplos do que fazer e deixe-o inferir o padr√£o.
- **Dicas** - siga a instru√ß√£o com uma "dica" que prepara o completamento, orientando o modelo para respostas mais relevantes.
- **Modelos** - s√£o 'receitas' repet√≠veis de prompts com espa√ßos reservados (vari√°veis) que podem ser personalizados com dados para casos de uso espec√≠ficos.

Vamos explorar esses conceitos na pr√°tica.

### Usando Exemplos

Esta √© uma abordagem em que voc√™ usa o conte√∫do prim√°rio para "alimentar o modelo" com alguns exemplos da sa√≠da desejada para uma determinada instru√ß√£o e permite que ele infera o padr√£o para a sa√≠da desejada. Com base no n√∫mero de exemplos fornecidos, podemos ter prompting de `zero-shot`, `one-shot`, `few-shot`, etc.

O prompt agora consiste em tr√™s componentes:

- Uma descri√ß√£o da tarefa
- Alguns exemplos da sa√≠da desejada
- O in√≠cio de um novo exemplo (que se torna uma descri√ß√£o impl√≠cita da tarefa)

  | Learning Type | Prompt (Input)                                                                                                                                        | Completion (Output)         |
  | :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
  | Zero-shot     | "The Sun is Shining". Translate to Spanish                                                                                                            | "El Sol est√° brillando".    |
  | One-shot      | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
  | Few-shot      | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk => | Basketball                  |
  |               |                                                                                                                                                       |                             |

Observe como tivemos que fornecer instru√ß√µes expl√≠citas ("Traduza para o espanhol") no prompting de `zero-shot`, mas isso √© inferido no exemplo de `one-shot`. O exemplo `few-shot` mostra como adicionar mais exemplos permite que os modelos fa√ßam infer√™ncias mais precisas sem instru√ß√µes adicionais.

### Dicas de Prompt

Outra t√©cnica para usar conte√∫do prim√°rio √© fornecer _dicas_ em vez de exemplos. Neste caso, estamos dando ao modelo um empurr√£o na dire√ß√£o certa ao _inici√°-lo_ com um trecho que reflete o formato da resposta desejada. O modelo ent√£o "pega a dica" para continuar nessa linha.

| Number of Cues | Prompt (Input)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Completion (Output)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. <br/>**Summarize This**                                       | Jupiter is the largest planet in our Solar System and the fifth one from the Sun. It is a gas giant with a mass 1/1000th of the Sun's, but it is heavier than all the other planets combined. Ancient civilizations have known about Jupiter for a long time, and it is easily visible in the night sky.. |
| 1              | Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. <br/>**Summarize This** <br/> What we learned is that Jupiter | is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets combined. It is easily visible to the naked eye and has been known since ancient times.                        |
| 2              | Jupiter is the fifth planet from the Sun and the largest in the Solar System. It is a gas giant with a mass one-thousandth that of the Sun, but two-and-a-half times that of all the other planets in the Solar System combined. Jupiter is one of the brightest objects visible to the naked eye in the night sky, and has been known to ancient civilizations since before recorded history. <br/>**Summarize This** <br/> Top 3 Facts We Learned:         | 1. Jupiter is the fifth planet from the Sun and the largest in the Solar System. <br/> 2. It is a gas giant with a mass one-thousandth that of the Sun...<br/> 3. Jupiter has been visible to the naked eye since ancient times ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |

Observe como tivemos que fornecer uma instru√ß√£o expl√≠cita ("Resuma Isso") no exemplo de zero dicas, mas isso √© inferido no exemplo de uma dica. O exemplo de duas dicas mostra como adicionar mais dicas permite que os modelos fa√ßam infer√™ncias mais precisas sem instru√ß√µes adicionais.

### Modelos de Prompt

Um modelo de prompt √© uma _receita pr√©-definida para um prompt_ que pode ser armazenada e reutilizada conforme necess√°rio, para proporcionar experi√™ncias do usu√°rio mais consistentes em escala. Em sua forma mais simples, √© apenas uma cole√ß√£o de exemplos de prompt como [este da OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que fornece tanto os componentes interativos do prompt (mensagens do usu√°rio e do sistema) quanto o formato de solicita√ß√£o impulsionado por API - para suportar a reutiliza√ß√£o.

Em sua forma mais complexa, como [este exemplo em LangChain](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/?WT.mc_id=academic-105485-koreyst), cont√©m _placeholders_ que podem ser substitu√≠dos por dados de diversas fontes (entrada do usu√°rio, contexto do sistema, fontes de dados externas etc.) para gerar um prompt dinamicamente. Isso nos permite criar uma biblioteca de prompts reutiliz√°veis que podem ser usados para impulsionar experi√™ncias do usu√°rio consistentes **programaticamente** em escala.

Finalmente, o real valor dos modelos est√° na capacidade de criar e publicar _bibliotecas de prompts_ para dom√≠nios de aplica√ß√£o verticais - onde o modelo de prompt √© agora _otimizado_ para refletir o contexto ou exemplos espec√≠ficos do dom√≠nio da aplica√ß√£o que tornam as respostas mais relevantes e precisas para o p√∫blico-alvo.

A [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) √© um √≥timo exemplo dessa abordagem, criando uma biblioteca de prompts para o dom√≠nio da educa√ß√£o com √™nfase em objetivos-chave como planejamento de aulas, design de curr√≠culo, tutoria de estudantes etc.

## Conte√∫do de Suporte

Se pensarmos na cria√ß√£o do prompt como tendo uma instru√ß√£o (tarefa) e um alvo (conte√∫do principal), ent√£o o _conte√∫do secund√°rio_ √© como um contexto adicional que fornecemos para **influenciar a sa√≠da de alguma forma**. Pode ser par√¢metros de ajuste, instru√ß√µes de formata√ß√£o, taxonomias de t√≥picos etc. que podem ajudar o modelo a _adequar_ sua resposta para atender aos objetivos ou expectativas desejados do usu√°rio.

Por exemplo: Dado um cat√°logo de cursos com metadados extensivos (nome, descri√ß√£o, n√≠vel, tags de metadados, instrutor etc.) de todos os cursos dispon√≠veis no curr√≠culo:

- podemos definir uma instru√ß√£o para "resumir o cat√°logo de cursos para o outono de 2023"
- podemos usar o conte√∫do principal para fornecer alguns exemplos da sa√≠da desejada
- podemos usar o conte√∫do secund√°rio para identificar as 5 principais "tags" de interesse.

Agora, o modelo pode fornecer um resumo no formato mostrado pelos poucos exemplos - mas se um resultado tiver v√°rias tags, pode priorizar as 5 tags identificadas no conte√∫do secund√°rio.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #3:
Prompt Engineering Techniques.
What are some basic techniques for prompt engineering?
Illustrate it with some exercises.
-->

## Melhores Pr√°ticas para Prompts

Agora que sabemos como os prompts podem ser _constru√≠dos_, podemos come√ßar a pensar em como _projet√°-los_ para refletir as melhores pr√°ticas. Podemos pensar nisso em duas partes - ter a _mentalidade_ certa e aplicar as _t√©cnicas_ certas.

### Mentalidade de Engenharia de Prompt

A Engenharia de Prompt √© um processo de tentativa e erro, ent√£o tenha em mente tr√™s fatores amplos:

1. **Entender o Dom√≠nio √© Importante.** A precis√£o e relev√¢ncia da resposta √© uma fun√ß√£o do _dom√≠nio_ no qual a aplica√ß√£o ou usu√°rio opera. Aplique sua intui√ß√£o e experi√™ncia de dom√≠nio para **personalizar t√©cnicas** ainda mais. Por exemplo, defina _personalidades espec√≠ficas do dom√≠nio_ em seus prompts de sistema, ou use _modelos espec√≠ficos do dom√≠nio_ em seus prompts de usu√°rio. Forne√ßa conte√∫do secund√°rio que reflita contextos espec√≠ficos do dom√≠nio, ou use _cues e exemplos espec√≠ficos do dom√≠nio_ para orientar o modelo em dire√ß√£o a padr√µes de uso familiares.

2. **Entender o Modelo √© Importante.** Sabemos que os modelos s√£o estoc√°sticos por natureza. Mas as implementa√ß√µes do modelo tamb√©m podem variar em termos do conjunto de dados de treinamento que eles usam (conhecimento pr√©-treinado), as capacidades que eles fornecem (por exemplo, via API ou SDK) e o tipo de conte√∫do para o qual s√£o otimizados (por exemplo, c√≥digo vs. imagens vs. texto). Compreenda as for√ßas e limita√ß√µes do modelo que voc√™ est√° usando e use esse conhecimento para _priorizar tarefas_ ou construir _modelos personalizados_ otimizados para as capacidades do modelo.

3. **Itera√ß√£o e Valida√ß√£o S√£o Importantes.** Os modelos est√£o evoluindo rapidamente, e as t√©cnicas de engenharia de prompt tamb√©m. Como especialista no dom√≠nio, voc√™ pode ter outros contextos ou crit√©rios _espec√≠ficos de sua_ aplica√ß√£o, que podem n√£o se aplicar √† comunidade em geral. Use ferramentas e t√©cnicas de engenharia de prompt para "iniciar" a constru√ß√£o do prompt, depois itere e valide os resultados usando sua pr√≥pria intui√ß√£o e experi√™ncia de dom√≠nio. Registre suas percep√ß√µes e crie uma **base de conhecimento** (por exemplo, bibliotecas de prompts) que pode ser usada como uma nova linha de base por outras pessoas, para itera√ß√µes mais r√°pidas no futuro.

## Melhores Pr√°ticas

Agora, vamos dar uma olhada nas pr√°ticas recomendadas comuns pela [Open AI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) e pelos praticantes da [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| What                              | Why                                                                                                                                                                                                                                               |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Evaluate the latest models.       | New model generations are likely to have improved features and quality - but may also incur higher costs. Evaluate them for impact, then make migration decisions.                                                                                |
| Separate instructions & context   | Check if your model/provider defines _delimiters_ to distinguish instructions, primary and secondary content more clearly. This can help models assign weights more accurately to tokens.                                                         |
| Be specific and clear             | Give more details about the desired context, outcome, length, format, style etc. This will improve both the quality and consistency of responses. Capture recipes in reusable templates.                                                          |
| Be descriptive, use examples      | Models may respond better to a "show and tell" approach. Start with a `zero-shot` approach where you give it an instruction (but no examples) then try `few-shot` as a refinement, providing a few examples of the desired output. Use analogies. |
| Use cues to jumpstart completions | Nudge it towards a desired outcome by giving it some leading words or phrases that it can use as a starting point for the response.                                                                                                               |
| Double Down                       | Sometimes you may need to repeat yourself to the model. Give instructions before and after your primary content, use an instruction and a cue, etc. Iterate & validate to see what works.                                                         |
| Order Matters                     | The order in which you present information to the model may impact the output, even in the learning examples, thanks to recency bias. Try different options to see what works best.                                                               |
| Give the model an ‚Äúout‚Äù           | Give the model a _fallback_ completion response it can provide if it cannot complete the task for any reason. This can reduce chances of models generating false or hallucinatory responses.                                                      |
|                                   |                                                                                                                                                                                                                                                   |

Como em qualquer pr√°tica recomendada, lembre-se de que _seus resultados podem variar_ com base no modelo, na tarefa e no dom√≠nio. Use essas pr√°ticas como ponto de partida e itere para encontrar o que funciona melhor para voc√™. Reavalie constantemente seu processo de engenharia de prompt √† medida que novos modelos e ferramentas se tornam dispon√≠veis, com foco na escalabilidade do processo e na qualidade das respostas.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the prompts filled in and run, showing what one example could be.
-->

## Tarefa

Parab√©ns! Voc√™ chegou ao final da li√ß√£o! √â hora de colocar alguns desses conceitos e t√©cnicas √† prova com exemplos reais!

Para a nossa tarefa, usaremos um Jupyter Notebook com exerc√≠cios que voc√™ pode completar interativamente. Voc√™ tamb√©m pode estender o Notebook com suas pr√≥prias c√©lulas de Markdown e c√≥digo para explorar ideias e t√©cnicas por conta pr√≥pria.

### Para come√ßar, fa√ßa um fork do reposit√≥rio, depois

- (Recomendado) Inicie o GitHub Codespaces
- (Opcional) Clone o reposit√≥rio em seu dispositivo local e use-o com o Docker Desktop
- (Opcional) Abra o Notebook com seu ambiente de execu√ß√£o de notebook preferido.

### Em seguida, configure suas vari√°veis de ambiente

- Copie o arquivo `.env.copy` na raiz do reposit√≥rio para `.env` e preencha o valor `OPENAI_API_KEY`. Voc√™ pode encontrar sua chave de API em seu [OpenAI Dashboard](https://beta.openai.com/account/api-keys?WT.mc_id=academic-105485-koreyst).

### Em seguida, abra o Jupyter Notebook

- Selecione o kernel de execu√ß√£o. Se estiver usando as op√ß√µes 1 ou 2, basta selecionar o kernel Python 3.10.x padr√£o fornecido pelo cont√™iner de desenvolvimento.

Voc√™ est√° pronto para executar os exerc√≠cios. Lembre-se de que n√£o h√° respostas _certas ou erradas_ aqui - apenas explorando op√ß√µes por tentativa e erro e construindo intui√ß√£o sobre o que funciona para um determinado modelo e dom√≠nio de aplica√ß√£o.

_Por esse motivo, n√£o h√° segmentos de Solu√ß√£o de C√≥digo nesta li√ß√£o. Em vez disso, o Notebook ter√° c√©lulas de Markdown intituladas "Minha Solu√ß√£o:" que mostram um exemplo de sa√≠da para refer√™ncia._

<!--
LESSON TEMPLATE:
Wrap the section with a summary and resources for self-guided learning.
-->

## Verifica√ß√£o de Conhecimento

Qual das seguintes op√ß√µes seria uma boa instru√ß√£o seguindo as melhores pr√°ticas razo√°veis?

1. Mostre-me uma imagem de um carro vermelho.
2. Mostre-me uma imagem de um carro vermelho da marca Volvo e modelo XC90 estacionado √† beira de um penhasco com o sol se pondo.
3. Mostre-me uma imagem de um carro vermelho da marca Volvo e modelo XC90.

**Resposta:** 2, √© a melhor instru√ß√£o, pois fornece detalhes sobre "o que" e vai para especificidades (n√£o apenas qualquer carro, mas uma marca e modelo espec√≠ficos) e tamb√©m descreve o ambiente geral. A op√ß√£o 3 √© a pr√≥xima melhor, pois tamb√©m cont√©m muita descri√ß√£o.

## üöÄ Desafio

Veja se voc√™ consegue aproveitar a t√©cnica de "dica" com a instru√ß√£o: Complete a frase "Mostre-me uma imagem de um carro vermelho da marca Volvo e ". O que ela responde e como voc√™ melhoraria?

## √ìtimo Trabalho! Continue Sua Aprendizagem

Quer aprender mais sobre diferentes conceitos de Engenharia de Instru√ß√µes? V√° para a [p√°gina de aprendizado cont√≠nuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar outros √≥timos recursos sobre este tema.

Agora, vamos para a Li√ß√£o 5, onde exploraremos [t√©cnicas avan√ßadas de instru√ß√£o](../../../05-advanced-prompts/translations/pt-br/README.md?WT.mc_id=academic-105485-koreyst)!
