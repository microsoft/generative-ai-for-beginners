# Fundamentos de la Ingenier√≠a de Indicaciones

[![Fundamentos de la Ingenier√≠a de Indicaciones](../../images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Introducci√≥n
Este m√≥dulo cubre conceptos y t√©cnicas esenciales para crear indicaciones efectivos en modelos de IA generativa. La forma en que escribes tu prompt para un LLM tambi√©n importa. Un prompt cuidadosamente dise√±ado puede lograr respuestas de mayor calidad. Pero qu√© significan exactamente t√©rminos como _prompt_ e _ingenier√≠a de indicaciones_? Y c√≥mo puedo mejorar el _input_ que env√≠o al LLM? Estas son las preguntas que intentaremos responder en este cap√≠tulo y el siguiente.

La _IA generativa_ es capaz de crear contenido nuevo (por ejemplo, texto, im√°genes, audio, c√≥digo, etc.) en respuesta a solicitudes de los usuarios. Lo logra utilizando _Modelos de Lenguaje Extenso_ (LLM, por sus siglas en ingl√©s) como la serie GPT ("Transformador Generativo Preentrenado") de OpenAI, entrenados para comprender lenguaje natural y c√≥digo.

Los usuarios pueden interactuar ahora con estos modelos usando paradigmas familiares como el chat, sin necesidad de conocimientos t√©cnicos ni entrenamiento. Los modelos se basan en _indicaciones_ ‚Äî los usuarios env√≠an una entrada de texto (prompt) y reciben la respuesta de la IA (completado). Pueden "chatear con la IA" de forma iterativa, en conversaciones de varios turnos, refinando el prompt hasta que la respuesta cumpla sus expectativas.

Los "indicaciones" se convierten ahora en la principal _interfaz de programaci√≥n_ para las aplicaciones de IA generativa, indicando a los modelos qu√© hacer e influyendo en la calidad de las respuestas devueltas. La _Ingenier√≠a de indicaciones_ es un campo de estudio en r√°pido crecimiento que se enfoca en el _dise√±o y la optimizaci√≥n_ de indicaciones para ofrecer respuestas consistentes y de calidad a escala.

## Objetivos de Aprendizaje

En esta lecci√≥n, aprenderemos qu√© es la Ingenier√≠a de Indicaciones, por qu√© es importante y c√≥mo podemos redactar indicaciones m√°s efectivos para un modelo y objetivo espec√≠fico. Comprenderemos los conceptos fundamentales y las buenas pr√°cticas para la ingenier√≠a de indicaciones, y conoceremos un entorno interactivo de Jupyter Notebooks donde veremos estos conceptos aplicados a ejemplos reales.

Al final de esta lecci√≥n, ser√°s capaz de:

1. Explicar qu√© es la ingenier√≠a de indicaciones y por qu√© importa.
2. Describir los componentes de un prompt y c√≥mo se usan.
3. Conocer buenas pr√°cticas y t√©cnicas para la ingenier√≠a de indicaciones.
4. Aplicar t√©cnicas aprendidas a ejemplos reales, usando un endpoint de OpenAI.

## T√©rminos Clave

Ingenier√≠a de Indicaciones: La pr√°ctica de dise√±ar y refinar entradas para guiar a los modelos de IA hacia la producci√≥n de salidas deseadas.  
Tokenizaci√≥n: El proceso de convertir texto en unidades m√°s peque√±as, llamadas tokens, que un modelo puede entender y procesar.  
LLMs Afinados con Instrucciones: Modelos de Lenguaje Extenso (LLMs) que han sido afinados con instrucciones espec√≠ficas para mejorar la precisi√≥n y relevancia de sus respuestas.

## Entorno de Pr√°ctica

La ingenier√≠a de indicaciones es actualmente m√°s un arte que una ciencia. La mejor forma de mejorar nuestra intuici√≥n es _practicar m√°s_ y adoptar un enfoque de prueba y error que combine conocimiento del dominio con t√©cnicas recomendadas y optimizaciones espec√≠ficas del modelo.

El Jupyter Notebook que acompa√±a esta lecci√≥n proporciona un entorno tipo _sandbox_ donde puedes probar lo que vas aprendiendo ‚Äî a medida que avanzas o como parte del desaf√≠o de c√≥digo al final. Para ejecutar los ejercicios, necesitar√°s:

1. **Una clave API de Azure OpenAI** ‚Äì el endpoint del servicio para un LLM desplegado.
2. **Un entorno de ejecuci√≥n de Python** ‚Äì donde se pueda ejecutar el Notebook.
3. **Variables de entorno locales** ‚Äì _completa los pasos del [SETUP](../../../00-course-setup/SETUP.md?WT.mc_id=academic-105485-koreyst) ahora para estar listo_.

El Notebook incluye ejercicios _iniciales_ ‚Äî pero se te anima a a√±adir tus propias secciones de _Markdown_ (descripci√≥n) y _C√≥digo_ (solicitudes de indicaciones) para probar m√°s ejemplos o ideas ‚Äî y desarrollar tu intuici√≥n sobre el dise√±o de indicaciones.

## Gu√≠a Ilustrada

Quieres tener una idea general de lo que cubre esta lecci√≥n antes de comenzar? Mira esta gu√≠a ilustrada, que te da una visi√≥n general de los temas principales y los puntos clave que debes tener en cuenta en cada uno. El recorrido de la lecci√≥n te lleva desde la comprensi√≥n de los conceptos fundamentales y los desaf√≠os, hasta c√≥mo abordarlos con t√©cnicas y buenas pr√°cticas de ingenier√≠a de indicaciones. Ten en cuenta que la secci√≥n de ‚ÄúT√©cnicas Avanzadas‚Äù en esta gu√≠a hace referencia al contenido del _pr√≥ximo_ cap√≠tulo de este plan de estudios.

![Gu√≠a Ilustrada sobre Ingenier√≠a de Indicaciones](../../images/04-prompt-engineering-sketchnote.png?WT.mc_id=academic-105485-koreyst)

## Nuestra Startup

Ahora hablemos de c√≥mo _este tema_ se relaciona con nuestra misi√≥n como startup de [llevar la innovaci√≥n en IA a la educaci√≥n](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos construir aplicaciones impulsadas por IA para el _aprendizaje personalizado_, as√≠ que pensemos en c√≥mo distintos usuarios de nuestra aplicaci√≥n podr√≠an "dise√±ar" indicaciones:

- **Administradores** podr√≠an pedir a la IA que _analice datos curriculares para identificar vac√≠os en la cobertura_. La IA puede resumir los resultados o visualizarlos con c√≥digo.
- **Educadores** podr√≠an pedir a la IA que _genere un plan de lecci√≥n para una audiencia y tema espec√≠ficos_. La IA puede crear el plan personalizado en un formato definido.
- **Estudiantes** podr√≠an pedir a la IA que _les ense√±e un tema dif√≠cil_. La IA ahora puede guiarlos con lecciones, pistas y ejemplos adaptados a su nivel.

Y eso es solo la punta del iceberg. Revisa [Indicaciones para Educacion](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst), una biblioteca de indicaciones de c√≥digo abierto curada por expertos en educaci√≥n, para tener una visi√≥n m√°s amplia de las posibilidades! _Prueba algunos de esos indicaciones en el sandbox o usando el OpenAI Playground para ver qu√© ocurre!_

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #1:
Prompt Engineering.
Define it and explain why it is needed.
-->

## Qu√© es la Ingenier√≠a de Indicaciones?

Comenzamos esta lecci√≥n definiendo la **Ingenier√≠a de Indicaciones** como el proceso de _dise√±ar y optimizar_ entradas de texto (indicaciones) para generar respuestas (completions) consistentes y de calidad para un objetivo y modelo determinados. Podemos pensar en esto como un proceso de 2 pasos:

- _Dise√±ar_ el prompt inicial para un modelo y objetivo espec√≠ficos
- _Refinar_ el prompt de forma iterativa para mejorar la calidad de la respuesta

Este proceso requiere necesariamente prueba y error, intuici√≥n del usuario y esfuerzo para obtener los mejores resultados. Entonces, por qu√© es importante? Para responder a esa pregunta, primero debemos entender tres conceptos:

- _Tokenizaci√≥n_ = c√≥mo el modelo ‚Äúve‚Äù el prompt
- _Modelos base_ (Base LLMs) = c√≥mo el modelo procesa el prompt
- _LLMs afinados con instrucciones_ = c√≥mo el modelo puede ahora ver ‚Äútareas‚Äù

### Tokenizaci√≥n

Un LLM ve los indicaciones como una _secuencia de tokens_, y diferentes modelos (o versiones del mismo) pueden tokenizar el mismo prompt de distintas formas. Como los LLMs est√°n entrenados con tokens (y no con texto en bruto), la forma en que un prompt se tokeniza impacta directamente en la calidad de la respuesta generada.

Para entender mejor c√≥mo funciona la tokenizaci√≥n, prueba herramientas como el [Tokenizer de OpenAI](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst). Copia tu prompt y observa c√≥mo se convierte en tokens, prestando atenci√≥n a c√≥mo se tratan los espacios y signos de puntuaci√≥n. Este ejemplo usa un modelo antiguo (GPT-3), as√≠ que al usar un modelo m√°s nuevo podr√≠as obtener resultados diferentes.

![Tokenizaci√≥n](../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

### Concepto: Modelos Base

Una vez tokenizado el prompt, la funci√≥n principal del ["LLM base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (o modelo fundacional) es predecir el siguiente token en la secuencia. Como estos modelos est√°n entrenados con grandes cantidades de texto, tienen una buena comprensi√≥n estad√≠stica de la relaci√≥n entre tokens y pueden predecir con cierto nivel de confianza. Es importante notar que no entienden el _significado_ de las palabras; simplemente reconocen patrones que pueden ‚Äúcompletar‚Äù.

Quieres ver c√≥mo funciona esta predicci√≥n basada en indicaciones? Ingresa el prompt anterior en Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) con la configuraci√≥n predeterminada. El sistema tratar√° el prompt como una solicitud de informaci√≥n y deber√≠a generar una respuesta que se ajuste al contexto.

Pero qu√© pasa si el usuario quiere algo m√°s espec√≠fico que cumpla con ciertos criterios o un objetivo de tarea? Aqu√≠ es donde entran los _LLMs afinados con instrucciones_.

![Chat completado con modelo base](../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst)

### Concepto: LLMs Afinados con Instrucciones

Un [LLM afinado con instrucciones](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) parte del modelo fundacional y se entrena adicionalmente con ejemplos o pares de entrada/salida (por ejemplo, ‚Äúmensajes‚Äù en conversaciones) que contienen instrucciones claras, y el modelo intenta seguirlas.

Esto se logra con t√©cnicas como Aprendizaje por Refuerzo con Retroalimentaci√≥n Humana (RLHF), que entrena al modelo para _seguir instrucciones_ y _aprender del feedback_, generando respuestas m√°s relevantes y √∫tiles para casos de uso reales.

Prob√©moslo: vuelve al prompt anterior, pero ahora cambia el _mensaje del sistema_ para incluir la siguiente instrucci√≥n como contexto:

> _Resume el contenido que se te proporcione como si se lo explicaras a un estudiante de segundo grado. Limita la respuesta a un p√°rrafo con 3‚Äì5 vi√±etas._

Observa c√≥mo el resultado ahora se ajusta al objetivo y formato deseado. Un educador puede usar esta respuesta directamente en sus presentaciones para esa clase.

![Completado con modelo afinado](../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)

## Por qu√© necesitamos Ingenier√≠a de Indicaciones?

Ahora que sabemos c√≥mo los LLMs procesan los indicaciones, hablemos de _por qu√©_ necesitamos ingenier√≠a de indicaciones. La respuesta est√° en el hecho de que los modelos actuales presentan varios desaf√≠os que hacen m√°s dif√≠cil obtener _respuestas confiables y consistentes_ sin dedicar esfuerzo a la construcci√≥n y optimizaci√≥n del prompt. Por ejemplo:

1. **Las respuestas del modelo son estoc√°sticas.** El _mismo prompt_ puede producir respuestas distintas con diferentes modelos o versiones del modelo. Incluso puede generar resultados diferentes con el _mismo modelo_ en diferentes momentos. _Las t√©cnicas de ingenier√≠a de indicaciones pueden ayudarnos a minimizar estas variaciones proporcionando mejores estructuras de control_.

2. **Los modelos pueden inventar informaci√≥n.** Aunque los modelos fueron preentrenados con _grandes cantidades de datos_, estos siguen siendo limitados. Como resultado, pueden generar respuestas que son inexactas, inventadas o incluso contradictorias con hechos conocidos. _Las t√©cnicas de ingenier√≠a de indicaciones ayudan a mitigar estas invenciones, por ejemplo, pidiendo citas o razonamientos al modelo_.

3. **Las capacidades del modelo var√≠an.** Los modelos m√°s nuevos pueden tener mejores habilidades, pero tambi√©n presentan desaf√≠os √∫nicos en cuanto a costo o complejidad. _La ingenier√≠a de indicaciones puede ayudarnos a desarrollar pr√°cticas y flujos de trabajo que se adapten a cada modelo, ocultando las diferencias y haciendo las soluciones m√°s escalables y reutilizables_.

Ve√°moslo en acci√≥n en el OpenAI o Azure OpenAI Playground:

- Usa el mismo prompt con diferentes implementaciones de LLM (por ejemplo, OpenAI, Azure OpenAI, Hugging Face). Viste las diferencias?
- Usa el mismo prompt varias veces con la _misma_ implementaci√≥n (por ejemplo, en Azure OpenAI Playground). Las respuestas fueron iguales o diferentes?

### Ejemplo de Fabricaciones

En este curso, usamos el t√©rmino **"fabricaci√≥n"** para referirnos al fen√≥meno en el cual los LLMs generan informaci√≥n incorrecta debido a limitaciones en su entrenamiento u otros factores. Puede que hayas visto este comportamiento llamado _‚Äúalucinaciones‚Äù_ en art√≠culos o investigaciones, pero recomendamos usar ‚Äúfabricaci√≥n‚Äù para evitar atribuir caracter√≠sticas humanas a un modelo de IA. Esto tambi√©n respeta las [gu√≠as de IA Responsable](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst), que recomiendan evitar t√©rminos potencialmente ofensivos o no inclusivos.

Quieres ver un ejemplo de fabricaci√≥n? Intenta un prompt que le pida a la IA generar contenido sobre un tema ficticio (que sabemos que no existe). Por ejemplo:

> **Prompt:** genera un plan de clase sobre la Guerra Marciana del 2076.

Una b√∫squeda web muestra que existen relatos ficticios (series o libros) sobre guerras marcianas, pero ninguna en 2076. Adem√°s, el sentido com√∫n nos dice que 2076 es _el futuro_, por lo tanto no puede referirse a un evento real.

Veamos qu√© ocurre al usar este prompt en distintos modelos:

> **Respuesta 1**: OpenAI Playground (GPT-3.5)

![Respuesta 1](../../images/04-fabrication-oai.png?WT.mc_id=academic-105485-koreyst)

> **Respuesta 2**: Azure OpenAI Playground (GPT-3.5)

![Respuesta 2](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)

> **Respuesta 3**: Hugging Face Chat Playground (LLama-2)

![Respuesta 3](../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)

Como era de esperarse, cada modelo (o versi√≥n) produce respuestas ligeramente distintas debido al comportamiento estoc√°stico y a las variaciones entre modelos. Por ejemplo, un modelo puede adaptar la respuesta a un p√∫blico de octavo grado, mientras otro la dirige a estudiantes de secundaria. Pero todos generan respuestas _aparentemente plausibles_ sobre un evento que no ocurri√≥.

T√©cnicas de ingenier√≠a de indicaciones como _indicaciones meta_ o la configuraci√≥n de _temperature_ pueden ayudar a reducir las fabricaciones. Tambi√©n existen nuevas _arquitecturas_ para ingenier√≠a de indicaciones que integran herramientas y t√©cnicas directamente en el flujo del prompt para mitigar estos efectos.

## Estudio de Caso: GitHub Copilot

Para cerrar esta secci√≥n, veamos c√≥mo se aplica la ingenier√≠a de indicaciones en soluciones del mundo real a trav√©s de un caso pr√°ctico: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot es tu "programador asistente con IA" ‚Äî convierte indicaciones de texto en sugerencias de c√≥digo y se integra directamente en tu entorno de desarrollo (por ejemplo, Visual Studio Code) para una experiencia fluida. Seg√∫n documenta esta serie de publicaciones, la primera versi√≥n se basaba en el modelo OpenAI Codex, y los ingenieros r√°pidamente se dieron cuenta de la necesidad de afinar el modelo y desarrollar mejores t√©cnicas de ingenier√≠a de indicaciones para mejorar la calidad del c√≥digo generado. En julio, [presentaron un modelo de IA mejorado que va m√°s all√° de Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para generar sugerencias m√°s r√°pidas y eficientes.

Lee las siguientes publicaciones en orden cronol√≥gico para seguir su recorrido de aprendizaje:

- **Mayo 2023** | [GitHub Copilot mejora en la comprensi√≥n de tu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mayo 2023** | [Dentro de GitHub: c√≥mo trabajan con los LLMs detr√°s de Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Junio 2023** | [C√≥mo escribir mejores indicaciones para GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst)
- **Julio 2023** | [Copilot va m√°s all√° de Codex con un modelo de IA mejorado](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Julio 2023** | [Gu√≠a para desarrolladores sobre ingenier√≠a de indicaciones y LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Septiembre 2023** | [C√≥mo construir una aplicaci√≥n empresarial con LLMs: lecciones de GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Tambi√©n puedes explorar el [blog de Ingenier√≠a de GitHub](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para encontrar m√°s publicaciones como [esta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), que muestra c√≥mo estos modelos y t√©cnicas se _aplican_ en aplicaciones del mundo real.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #2.
Reinforce the concept with examples and references.

CONCEPT #2:
Prompt Design.
Illustrated with examples.
-->

## Construcci√≥n de Indicaciones

Ya vimos por qu√© la ingenier√≠a de indicaciones es importante ‚Äî ahora entendamos c√≥mo se _construyen_ los indicaciones para evaluar diferentes t√©cnicas que permitan dise√±arlos de manera m√°s efectiva.

### Prompt B√°sico

Comencemos con el prompt m√°s b√°sico: una entrada de texto enviada al modelo sin ning√∫n contexto adicional. Por ejemplo, cuando enviamos las primeras palabras del himno nacional de EE. UU. al [API de Completion de OpenAI](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst), el modelo completa la secuencia con las siguientes l√≠neas, ilustrando el comportamiento b√°sico de predicci√≥n.

| Prompt (Entrada)     | Completion (Salida)                                                                                                                                   |
| :------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see   | Parece que est√°s comenzando la letra de "The Star-Spangled Banner", el himno nacional de los Estados Unidos. La letra completa es...                |

### Prompt Complejo

Ahora agreguemos contexto e instrucciones al prompt b√°sico. El [API de Chat Completion](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir indicaciones complejos como una colecci√≥n de _mensajes_ que incluyen:

- Pares de entrada/salida que reflejan la interacci√≥n _usuario-asistente_.
- Un mensaje del sistema que establece el contexto o comportamiento deseado del asistente.

La solicitud ahora tiene este formato, donde la _tokenizaci√≥n_ captura la informaci√≥n relevante del contexto y de la conversaci√≥n. Cambiar el mensaje del sistema puede impactar tanto como las entradas del usuario.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "Eres un asistente √∫til."},
        {"role": "user", "content": "Qui√©n gan√≥ la Serie Mundial en 2020?"},
        {"role": "assistant", "content": "Los Dodgers de Los √Ångeles ganaron la Serie Mundial en 2020."},
        {"role": "user", "content": "D√≥nde se jug√≥?"}
    ]
)
```

### Instrucci√≥n

En los ejemplos anteriores, la instrucci√≥n del usuario era una consulta de texto simple que puede interpretarse como una solicitud de informaci√≥n. Con las instrucciones _instruction_, podemos usar ese texto para especificar una tarea con m√°s detalle, proporcionando una mejor gu√≠a a la IA. Ejemplo:

| Instrucci√≥n (Entrada) | Finalizaci√≥n (Salida) | Tipo de instrucci√≥n |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------- | :----------------------------------- |
| Escribir una descripci√≥n de la Guerra Civil | _devolvi√≥ un p√°rrafo simple_ | Simple |
| Escribir una descripci√≥n de la Guerra Civil. Indique fechas y eventos clave y describa su importancia | _devolvi√≥ un p√°rrafo seguido de una lista de fechas de eventos clave con descripciones_ | Complejo |
| Escribir una descripci√≥n de la Guerra Civil en un p√°rrafo. Indique tres vi√±etas con fechas clave y su importancia. Indique tres vi√±etas m√°s con figuras hist√≥ricas clave y sus contribuciones. Devuelva el resultado como un archivo JSON | _devuelve detalles m√°s extensos en un cuadro de texto, con formato JSON, que puedes copiar y pegar en un archivo y validar seg√∫n sea necesario_ | Complejo. Formato. |

## Contenido Primario

En los ejemplos anteriores, el prompt era bastante abierto, lo que permit√≠a al LLM decidir qu√© parte de su conjunto de entrenamiento era relevante. Con el dise√±o de _contenido primario_, la entrada se divide en dos partes:

- una instrucci√≥n (acci√≥n)
- contenido relevante (que influye en la acci√≥n)

Aqu√≠ tienes un ejemplo donde la instrucci√≥n es "resume esto en 2 oraciones":

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           | Completion (Salida)                                                                                                                                                                                                                                                                             |
| :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil veces menor que la del Sol, pero dos veces y media la masa de todos los dem√°s planetas juntos. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por las civilizaciones antiguas desde antes de la historia escrita. Lleva el nombre del dios romano J√∫piter.[19] Cuando se observa desde la Tierra, J√∫piter puede ser lo suficientemente brillante como para proyectar sombras visibles,[20] y es en promedio el tercer objeto natural m√°s brillante en el cielo nocturno despu√©s de la Luna y Venus. <br/> **Resume esto en 2 oraciones.** | J√∫piter, el quinto planeta desde el Sol, es el m√°s grande del Sistema Solar y uno de los objetos m√°s brillantes del cielo nocturno. Nombrado en honor al dios romano J√∫piter, es un gigante gaseoso cuya masa supera la de todos los dem√°s planetas combinados. |

El segmento de contenido primario se puede usar de varias formas para generar instrucciones m√°s efectivas:

- **Ejemplos** ‚Äì en lugar de decirle expl√≠citamente al modelo qu√© hacer, le das ejemplos de lo que debe generar y permites que infiera el patr√≥n.
- **Se√±ales** ‚Äì despu√©s de la instrucci√≥n, agregas una "se√±al" que inicia el tipo de respuesta deseada.
- **Plantillas** ‚Äì recetas reutilizables para indicaciones con espacios reservados (variables) que se pueden personalizar para casos de uso espec√≠ficos.

Exploremos estos enfoques en acci√≥n.

### Uso de Ejemplos

Este enfoque consiste en alimentar al modelo con algunos ejemplos del resultado deseado para una tarea, permiti√©ndole inferir el patr√≥n. Seg√∫n cu√°ntos ejemplos proporciones, puedes tener prompting de tipo cero, uno o pocos disparos (zero-shot, one-shot, few-shot).

El prompt ahora tiene tres componentes:

- Una descripci√≥n de la tarea
- Unos pocos ejemplos del resultado deseado
- El comienzo de un nuevo ejemplo (que se convierte en una descripci√≥n impl√≠cita de la tarea)

| Tipo de Aprendizaje | Prompt (Entrada)                                                                                                                      | Completion (Salida)           |
| :------------------ | :------------------------------------------------------------------------------------------------------------------------------------ | :---------------------------- |
| Zero-shot           | "The Sun is Shining". Trad√∫celo al espa√±ol                                                                                           | "El Sol est√° brillando".      |
| One-shot            | "The Sun is Shining" => "El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                 | "Es un d√≠a fr√≠o y ventoso".   |
| Few-shot            | The player ran the bases => B√©isbol <br/> The player hit an ace => Tenis <br/> The player hit a six => Cr√≠quet <br/> The player made a slam-dunk => | Baloncesto                    |

Nota c√≥mo en el ejemplo zero-shot tuvimos que dar una instrucci√≥n expl√≠cita ("Trad√∫celo al espa√±ol"), pero en el one-shot el modelo infiri√≥ el patr√≥n. En el few-shot, al darle m√°s ejemplos, el modelo puede inferir con m√°s precisi√≥n sin necesidad de instrucciones adicionales.

### Cues en Indicaciones

Otra t√©cnica es proporcionar _se√±ales_ (cues) en lugar de ejemplos. En este caso, estamos dando al modelo una pista o "inicio" de c√≥mo debe continuar la respuesta.

| N¬∫ de Cues | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                       | Completion (Salida)                                                                                                                                                                                                                                                                               |
| :--------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| 0          | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil veces menor que la del Sol, pero dos veces y media la de todos los dem√°s planetas. Es visible a simple vista y conocido desde tiempos antiguos. <br/>**Res√∫melo**                                                                                           | J√∫piter es el planeta m√°s grande del Sistema Solar y el quinto desde el Sol. Es un gigante gaseoso visible en el cielo nocturno desde la antig√ºedad.                                                                                                                                             |
| 1          | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil veces menor que la del Sol, pero dos veces y media la de todos los dem√°s planetas. <br/>**Res√∫melo** <br/> Lo que aprendimos es que J√∫piter...                                                                     | es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es visible desde la Tierra y ha sido conocido desde la antig√ºedad.                                                                                                                                                         |
| 2          | J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa mil veces menor que la del Sol, pero dos veces y media la de todos los dem√°s planetas. <br/>**Res√∫melo** <br/> Top 3 datos que aprendimos:                                              | 1. J√∫piter es el quinto planeta desde el Sol y el m√°s grande del Sistema Solar. <br/> 2. Es un gigante gaseoso cuya masa supera la de todos los otros planetas combinados. <br/> 3. Ha sido conocido desde tiempos antiguos y es muy visible en el cielo nocturno.                               |

### Plantillas de Indicaciones

Una plantilla de prompt es una _receta predefinida_ que puede guardarse y reutilizarse para generar experiencias consistentes. En su forma m√°s simple, es una colecci√≥n de ejemplos como [este de OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), que incluye tanto los componentes del prompt como el formato de solicitud por API.

En su forma m√°s compleja, como [esta en LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), incluye _variables_ que pueden reemplazarse con datos de distintas fuentes (input del usuario, contexto del sistema, fuentes externas, etc.) para generar el prompt din√°micamente.

El verdadero valor de las plantillas est√° en la posibilidad de crear y publicar _bibliotecas de indicaciones_ para dominios espec√≠ficos ‚Äî donde cada plantilla est√° _optimizadamente dise√±ada_ para reflejar el contexto o ejemplos m√°s relevantes para ese tipo de aplicaci√≥n. El repositorio [Indicaciones para Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) es un excelente ejemplo, con una colecci√≥n curada para educaci√≥n centrada en planificaci√≥n de lecciones, dise√±o curricular, tutor√≠a estudiantil, etc.

## Contenido de Apoyo

Si pensamos en la construcci√≥n de indicaciones como una combinaci√≥n de instrucci√≥n (tarea) y contenido principal (contenido base), entonces el _contenido secundario_ es informaci√≥n adicional que proporcionamos para **influenciar la salida de alguna manera**. Puede tratarse de par√°metros de ajuste, instrucciones de formato, taxonom√≠as tem√°ticas, etc., que ayudan al modelo a _adaptar_ su respuesta para que se alinee con los objetivos o expectativas del usuario.

Por ejemplo: dado un cat√°logo de cursos con meta datos extensos (nombre, descripci√≥n, nivel, etiquetas, instructor, etc.) sobre todos los cursos disponibles en el plan de estudios:

- Podemos definir una instrucci√≥n como "resume el cat√°logo de cursos para el semestre de oto√±o 2023".
- Podemos usar contenido primario para proporcionar algunos ejemplos del formato de salida deseado.
- Podemos usar contenido secundario para indicar las 5 etiquetas tem√°ticas m√°s importantes.

As√≠, el modelo puede generar un resumen que siga el formato mostrado en los ejemplos, pero si hay m√∫ltiples etiquetas por curso, puede priorizar aquellas que coincidan con las 5 etiquetas destacadas en el contenido secundario.

---

<!--
LESSON TEMPLATE:
This unit should cover core concept #1.
Reinforce the concept with examples and references.

CONCEPT #3:
Prompt Engineering Techniques.
What are some basic techniques for prompt engineering?
Illustrate it with some exercises.
-->

## Buenas Pr√°cticas para Indicaciones

Ahora que sabemos c√≥mo se pueden _construir_ los indicaciones, podemos comenzar a pensar en c√≥mo _dise√±arlos_ siguiendo buenas pr√°cticas. Podemos dividir esto en dos partes: tener la _mentalidad correcta_ y aplicar las _t√©cnicas adecuadas_.

### Mentalidad para la Ingenier√≠a de Indicaciones

La Ingenier√≠a de Indicaciones es un proceso de prueba y error, por lo que debes tener en cuenta tres principios generales:

1. **Entender el dominio es importante.** La precisi√≥n y relevancia de la respuesta dependen del _dominio_ en el que opera la aplicaci√≥n o el usuario. Usa tu intuici√≥n y experiencia para **personalizar las t√©cnicas**. Por ejemplo, define _personalidades espec√≠ficas del dominio_ en los mensajes del sistema, o usa _plantillas espec√≠ficas del dominio_ en los indicaciones del usuario. Proporciona contenido secundario que refleje ese contexto o usa _cues y ejemplos del dominio_ para guiar al modelo.

2. **Comprender el modelo es importante.** Sabemos que los modelos son estoc√°sticos por naturaleza. Pero adem√°s, cada implementaci√≥n puede variar en el conjunto de datos de entrenamiento, en sus capacidades (por ejemplo, API o SDK) y en el tipo de contenido que mejor manejan (texto, c√≥digo, im√°genes, etc.). Conoce las fortalezas y limitaciones del modelo que est√°s usando y aplica ese conocimiento para _priorizar tareas_ o construir _plantillas optimizadas_.

3. **La iteraci√≥n y validaci√≥n importan.** Los modelos evolucionan r√°pidamente, al igual que las t√©cnicas de prompting. Como experto en el dominio, puedes tener criterios √∫nicos que no aplican a otros usuarios. Usa las herramientas de ingenier√≠a de indicaciones para arrancar el proceso, luego itera y valida con tu intuici√≥n. Documenta tus hallazgos y crea una **base de conocimiento** (como bibliotecas de indicaciones) que sirva de punto de partida para otros.

### Buenas Pr√°cticas

Estas son algunas recomendaciones comunes sugeridas por [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) y [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst):

| Qu√© hacer                          | Por qu√©                                                                                                                                                                                                                                       |
| :--------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Eval√∫a los modelos m√°s recientes   | Las generaciones m√°s nuevas suelen tener mejores resultados y caracter√≠sticas, aunque tambi√©n pueden tener mayor costo. Eval√∫alos antes de hacer la migraci√≥n.                                                                              |
| Separa instrucciones y contexto    | Algunos proveedores o modelos usan _delimitadores_ para distinguir claramente la instrucci√≥n, el contenido primario y el contenido secundario. Esto puede ayudar al modelo a asignar mejor el peso a los tokens.                            |
| S√© espec√≠fico y claro              | Brinda m√°s detalles sobre el contexto, resultado deseado, longitud, formato, estilo, etc. Esto mejora la calidad y coherencia de la respuesta. Captura estos formatos en plantillas reutilizables.                                         |
| Usa descripciones y ejemplos       | Los modelos responden mejor al enfoque de "mostrar y contar". Comienza con `zero-shot` (solo instrucciones) y luego mejora con `few-shot` (instrucciones + ejemplos). Usa analog√≠as si es √∫til.                                           |
| Usa cues para iniciar respuestas   | Da al modelo un empuj√≥n con palabras o frases que inicien la salida deseada.                                                                                                                                                                 |
| Refuerza instrucciones importantes | A veces hay que repetir la instrucci√≥n. Puedes ponerla antes y despu√©s del contenido primario, o combinar una instrucci√≥n con un cue. Prueba diferentes formas.                                                                             |
| El orden importa                   | El orden de la informaci√≥n puede afectar la salida, incluso dentro de los ejemplos. La _recencia_ puede influir. Experimenta.                                                                                                                |
| Dale al modelo una ‚Äúsalida‚Äù        | Proporciona una respuesta alternativa si el modelo no puede completar la tarea. Esto reduce el riesgo de respuestas falsas o fabricadas.                                                                                                     |

Como toda buena pr√°ctica, recuerda que _tu experiencia puede variar_ seg√∫n el modelo, la tarea y el dominio. Usa estas recomendaciones como punto de partida y ajusta seg√∫n tus necesidades. Revisa constantemente tu proceso de prompting a medida que aparezcan nuevos modelos y herramientas, priorizando escalabilidad y calidad en las respuestas.

<!--
LESSON TEMPLATE:
This unit should provide a code challenge if applicable

CHALLENGE:
Link to a Jupyter Notebook with only the code comments in the instructions (code sections are empty).

SOLUTION:
Link to a copy of that Notebook with the indicaciones filled in and run, showing what one example could be.
-->

## Asignaci√≥n

Felicidades! Llegaste al final de la lecci√≥n. Es hora de poner en pr√°ctica algunos de los conceptos y t√©cnicas con ejemplos reales.

Para esta actividad, usaremos un Jupyter Notebook con ejercicios que puedes completar de forma interactiva. Tambi√©n puedes extender el Notebook con tus propias celdas de Markdown y C√≥digo para explorar ideas y t√©cnicas por tu cuenta.

### Para comenzar, haz un fork del repositorio y luego:

- (Recomendado) Lanza un GitHub Codespace
- (Alternativa) Clona el repositorio en tu dispositivo local y √∫salo con Docker Desktop
- (Alternativa) Abre el Notebook con tu entorno de ejecuci√≥n preferido

### Luego, configura tus variables de entorno

- Copia el archivo `.env.copy` ubicado en la ra√≠z del repositorio y ren√≥mbralo a `.env`. Llena los valores de `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` y `AZURE_OPENAI_DEPLOYMENT`. Si no sabes c√≥mo hacerlo, vuelve a la secci√≥n [Entorno de Pr√°ctica](./04-prompt-engineering-fundamentals#learning-sandbox).

### Por √∫ltimo, abre el Notebook

- Selecciona el kernel de ejecuci√≥n. Si usas Codespaces o Docker, selecciona el kernel de Python 3.10.x proporcionado por el contenedor de desarrollo.

Ya est√°s listo para ejecutar los ejercicios. Nota que no hay respuestas ‚Äúcorrectas o incorrectas‚Äù ‚Äî solo est√°s explorando mediante prueba y error para desarrollar tu intuici√≥n seg√∫n el modelo y el dominio de tu aplicaci√≥n.

_Por esta raz√≥n, esta lecci√≥n no incluye secciones de "Soluci√≥n de C√≥digo". En su lugar, el Notebook tendr√° celdas de Markdown tituladas "Mi soluci√≥n:" que mostrar√°n un ejemplo de salida como referencia._

## Verificaci√≥n de Conocimiento

Cu√°l de los siguientes es un buen prompt siguiendo buenas pr√°cticas razonables?

1. Mu√©strame una imagen de un carro rojo  
2. Mu√©strame una imagen de un carro rojo, marca Volvo y modelo XC90, estacionado junto a un acantilado con el atardecer de fondo  
3. Mu√©strame una imagen de un carro rojo, marca Volvo y modelo XC90

**Respuesta**: 2 ‚Äî es el mejor prompt porque proporciona detalles sobre "qu√©" se desea y va m√°s all√°: no es cualquier carro, sino una marca y modelo espec√≠ficos, adem√°s de describir el entorno. El n√∫mero 3 tambi√©n es bueno, ya que contiene una descripci√≥n detallada.

## üöÄ Desaf√≠o

Prueba la t√©cnica de "cue" con el siguiente prompt:

> Completa la frase: "Mu√©strame una imagen de un carro rojo, marca Volvo y "

Qu√© respuesta te da? C√≥mo la mejorar√≠as?

## Buen trabajo! Contin√∫a aprendiendo

Quieres seguir aprendiendo m√°s sobre conceptos de Ingenier√≠a de Indicaciones? Visita la [p√°gina de aprendizaje continuo](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst) para encontrar otros recursos sobre este tema.

Ve al cap√≠tulo 5, donde exploraremos [t√©cnicas avanzadas de prompting](../../../05-advanced-prompts/translations/es-mx/README.md?WT.mc_id=academic-105485-koreyst).
