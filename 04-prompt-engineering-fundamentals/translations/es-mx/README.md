# Fundamentos de Prompt Engineering

[![Fundamentos de Prompt Engineering](../../images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://youtu.be/r2ItK3UMVTk?WT.mc_id=academic-105485-koreyst)

La forma en que escribes tu prompt al LLM importa; un prompt cuidadosamente elaborado puede lograr un mejor resultado que uno que no lo sea. Pero, ¬øqu√© son estos conceptos, prompt, prompt engineering y c√≥mo puedo mejorar lo que env√≠o al LLM? Preguntas como √©stas son las que este cap√≠tulo y el pr√≥ximo buscan responder.

La _IA Generativa_ es capaz de crear contenido nuevo (por ejemplo, texto, im√°genes, audio, c√≥digo, etc.) en respuesta a las solicitudes de los usuarios. Lo logra utilizando _Modelos de Lenguaje Grande_ (LLMs) como la serie GPT ("Transformador Generativo Pre-entrenado") de OpenAI que est√°n entrenados para usar lenguaje y c√≥digo natural.

Los usuarios ahora pueden interactuar con estos modelos utilizando paradigmas familiares como el chat, sin necesidad de experiencia t√©cnica ni entrenamiento. Los modelos est√°n _basados en prompts_- los usuarios env√≠an una entrada de texto (prompt) y reciben la respuesta de la IA (finalizaci√≥n). Luego pueden "chatear con la IA" de forma iterativa, en conversaciones de varios turnos, refinando su prompt hasta que la respuesta coincida con sus expectativas.

Los "prompts" ahora se convierten en la principal _interfaz de programaci√≥n_ para aplicaciones de IA generativa, indicando a los modelos qu√© hacer e influyendo en la calidad de las respuestas devueltas. "Prompt Engineering" es un campo de estudio de r√°pido crecimiento que se centra en el _dise√±o y optimizaci√≥n_ de prompts para ofrecer respuestas consistentes y de calidad a escala.

## Metas de Aprendizaje

En esta lecci√≥n, aprenderemos qu√© es Prompt Engineering, por qu√© es importante y c√≥mo podemos crear prompts m√°s efectivos para un modelo y un objetivo de aplicaci√≥n determinados. Comprenderemos los conceptos b√°sicos y las mejores pr√°cticas para prompt engineering y aprenderemos sobre un entorno "sandbox" interactivo de Jupyter Notebooks donde podemos ver estos conceptos aplicados a ejemplos reales.

Al final de esta lecci√≥n seremos capaces de:

1. Explique qu√© es prompt engineering y por qu√© es importante.
2. Describir los componentes de un prompt y c√≥mo se utilizan.
3. Aprender las mejores pr√°cticas y t√©cnicas para prompt engineering.
4. Aplicar las t√©cnicas aprendidas a ejemplos reales, utilizando un punto de conexi√≥n de OpenAI.

## Sandbox de Aprendizaje

Prompt engineering es actualmente m√°s un arte que una ciencia. La mejor manera de mejorar nuestra intuici√≥n es _practicar m√°s_ y adoptar un enfoque de prueba y error que combine la experiencia en el dominio de la aplicaci√≥n con t√©cnicas recomendadas y optimizaciones espec√≠ficas del modelo.

El Jupyter Notebook que acompa√±a a esta lecci√≥n proporciona un entorno _sandbox_ donde puedes probar lo que aprendes - sobre la marcha, o como parte del desaf√≠o de c√≥digo al final. Para ejecutar los ejercicios necesitar√°s:

1. Una clave API de Azure OpenAI - el punto de conexi√≥n de servicio para un LLM implementado.

2. Un runtime de Python - en el que se puede ejecutar el Notebook.

Hemos instrumentado este repositorio con un _contenedor de desarrollo_ que viene con un runtime de Python 3. Simplemente abre el repositorio en GitHub Codespaces o en tu Docker Desktop local para activar el runtime autom√°ticamente. Luego abre el notebook y selecciona el kernel Python 3.x para preparar el Notebook para su ejecuci√≥n.

El notebook predeterminado est√° configurado para usarse con un recurso del servicio Azure OpenAI. Simplemente copia el archivo `.env.copy` en la ra√≠z de la carpeta a `.env` y actualiza las l√≠neas `AZURE_OPENAI_API_KEY=` y `AZURE_OPENAI_API_ENDPOINT=` con tu clave API y punto de conexi√≥n. Puedes verificar tus credenciales en el [portal de Azure](https://portal.azure.com?WT.mc_id=academic-105485-koreyst), navegando a tu recurso Azure OpenAI y luego abriendo la pesta√±a _Claves y punto de conexi√≥n_ en el men√∫ de la izquierda. Adem√°s, agrega el nombre que asignaste a tu modelo cuando creaste la implementaci√≥n a la variable `AZURE_OPENAI_DEPLOYMENT`. El modelo recomendado para este ejercicio es 'gpt-35-turbo'.

El notebook viene con ejercicios _de inicio_ - pero te recomendamos que agregues tus propias secciones _Markdown_ (descripci√≥n) y _C√≥digo_ (solicitudes de prompts) para probar m√°s ejemplos o ideas - y desarrollar tu intuici√≥n para dise√±ar de prompts.

## Nuestra Startup

Ahora, hablemos de c√≥mo _este tema_ se relaciona con nuestra misi√≥n inicial de [llevar la innovaci√≥n de la IA a la educaci√≥n](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Queremos crear aplicaciones de _aprendizaje personalizado_ impulsadas por IA - as√≠ que pensemos en c√≥mo los diferentes usuarios de nuestra aplicaci√≥n podr√≠an "dise√±ar" prompts:

- **Administradores** podr√≠an pedirle a la IA que _analice los datos del plan de estudios para identificar brechas en la cobertura_. La IA puede resumir los resultados o visualizarlos con c√≥digo.
- **Educadores** podr√≠an pedirle a la IA que _genere un plan de lecci√≥n para un p√∫blico y un tema objetivo_. La IA puede crear el plan personalizado en un formato espec√≠fico. 
- **Estudiantes** podr√≠an pedirle a la IA que _les d√© tutor√≠a en un tema dif√≠cil_. La IA ahora puede guiar a los estudiantes con lecciones, consejos y ejemplos adaptados a su nivel.

Eso es s√≥lo la punta del iceberg. Consulta [Prompts para la Educaci√≥n](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - una biblioteca de prompts de c√≥digo abierto seleccionada por expertos en educaci√≥n - para tener una idea m√°s amplia de las posibilidades! _¬°Intenta ejecutar algunos de esos prompts en el sandbox o usa OpenAI Playground para ver qu√© sucede!_

<!--
PLANTILLA DE LA LECCI√ìN:
Esta unidad deber√≠a cubrir el concepto central #1.
Refuerza el concepto con ejemplos y referencias.

CONCEPTO #1:
Prompt Engineering.
Def√≠nelo y explica por qu√© es necesario.
-->

## ¬øQu√© es Prompt Engineering?

Comenzamos esta lecci√≥n definiendo **Prompt Engineering** como el proceso de _dise√±ar y optimizar_ entradas de texto (prompts) para ofrecer respuestas consistentes y de calidad (finalizaciones) para un objetivo y modelo de aplicaci√≥n determinado. Podemos pensar en esto como un proceso de 2 pasos:

- _dise√±ar_ el prompt inicial para un modelo y objetivo determinado
- _refinar_ el prompt iterativamente para mejorar la calidad de la respuesta

Este es necesariamente un proceso de prueba y error que requiere la intuici√≥n del usuario y el esfuerzo para obtener resultados √≥ptimos. Entonces, ¬øpor qu√© es importante? Para responder a esa pregunta, primero debemos entender tres conceptos:

- _Tokenizaci√≥n_ = c√≥mo el modelo "ve" el prompt
- _LLMs base_ = c√≥mo el modelo fundacional "procesa" un prompt
- _LLMs de Instrucciones Afinadas_ = c√≥mo el modelo ahora puede ver "tareas"

### Tokenizaci√≥n

Un LLM considera a los prompts como una _sequencia de tokens_ donde diferentes modelos (o versiones de un modelo) pueden tokenizar el mismo prompt de diferentes maneras. Dado que los LLMs est√°n entrenados en tokens (y no en texto sin procesar), la forma en que se tokenizan los prompts tiene un impacto directo en la calidad de la respuesta generada.

Para obtener una intuici√≥n sobre c√≥mo funciona la tokenizaci√≥n, prueba herramientas como [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) que se muestra a continuaci√≥n. Copia tu prompt - y observa c√≥mo eso se convierte en tokens, prestando atenci√≥n a c√≥mo se manejan los caracteres de espacios en blanco y los signos de puntuaci√≥n. Ten en cuenta que este ejemplo muestra un LLM m√°s antiguo (GPT-3), por lo que probar esto con un modelo m√°s nuevo puede producir un resultado diferente.

![Tokenizaci√≥n](../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

### Concepto: Modelos Fundacionales

Una vez que un prompt es tokenizado, la funci√≥n principal del ["LLM Base"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (o Modelo Fundacional) es predecir el token en esa secuencia. Dado que los LLMs est√°n entrenados en conjuntos de datos de texto masivos, tienen un buen sentido de las relaciones estad√≠sticas entre los tokens y pueden hacer esa predicci√≥n con cierta confianza. Ten en cuenta que no entienden el _significado_ de las palabras en el prompt o token; solo ven un patr√≥n que pueden "completar" con su pr√≥xima predicci√≥n. Pueden continuar prediciendo la secuencia hasta que se termine mediante la intervenci√≥n del usuario o por alguna condici√≥n preestablecida.

¬øQuieres ver c√≥mo funciona la finalizaci√≥n basada en prompts? Ingresa el prompt anterior en Azure OpenAI Studio [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) con la configuraci√≥n predeterminada. El sistema est√° configurado para tratar los prompts como solicitudes de informaci√≥n - por lo que deber√≠as ver una finalizaci√≥n que satisfaga este contexto.

Pero, ¬øqu√© pasar√≠a si el usuario quisiera ver algo espec√≠fico que cumpliera algunos criterios u objetivos de la tarea? Aqu√≠ es donde los LLMS de _instrucciones afinadas_ entran en escena.

![Finalizaci√≥n de Chat de un LLM Base](../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst)

### Concepto: LLMs de Instrucci√≥n Afinada

Un [LLM de Instrucci√≥n Afinada](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) comienza con el modelo fundacional y lo afina con ejemplos o pares de entrada/salida (por ejemplo, "mensajes" de varios turnos) que pueden contener instrucciones claras - y la respuesta de la IA intenta seguir esa instrucci√≥n.

Esto utiliza t√©cnicas como el Aprendizaje por Refuerzo con Retroalimentaci√≥n Humana (RLHF) que pueden entrenar al modelo a _seguir instrucciones_ y _aprender de la retroalimentaci√≥n_ para que produzca respuestas que sean m√°s adecuadas para aplicaciones pr√°cticas y m√°s relevantes para los objetivos del usuario.

Vamos a intentarlo - reutiliza el prompt anterior, pero ahora cambia el _mensaje de sistema_ para proporcionar la siguiente instrucci√≥n como contexto:

> _Summarize content you are provided with for a second-grade student. Keep the result to one paragraph with 3-5 bullet points._

¬øVes c√≥mo ahora el resultado se ajusta para reflejar el objetivo y el formato deseados? Un educador ahora puede usar directamente esta respuesta en sus diapositivas para esa clase.

![Finalizaci√≥n de Chat de un LLM de Instrucci√≥n Afinada](../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)

## ¬øPor qu√© necesitamos Prompt Engineering?

Ahora que sabemos c√≥mo los prompts son procesados por los LLMs, hablemos de _por qu√©_ necesitamos prompt engineering. La respuesta radica en el hecho de que los LLMs actuales plantean una serie de desaf√≠os que hacen que las _finalizaciones confiables y consistentes_ sean m√°s dif√≠ciles de lograr sin esforzarse en una construcci√≥n y optimizaci√≥n del prompt. Por ejemplo:

1. **Las respuestas del modelo son estoc√°sticas.** El _mismo prompt_ muy probablemente producir√° diferentes respuestas con diferentes modelos o versiones de modelo. E incluso puede producir diferentes resultados con el _mismo_ modelo en diferentes momentos. _Las t√©cnicas de Prompt engineering pueden ayudarnos a minimizar estas variaciones proporcionando mejores l√≠mites_.

2. **Los modelos pueden fabricar respuestas.** Los modelos son pre-entrenados con conjuntos de datos _grandes pero finitos_, lo que significa que carecen de conocimiento sobre conceptos fuera de ese alcance de entrenamiento. Como resultado, pueden producir finalizaciones que sean inexactas, imaginarias o directamente contradictorias con hechos conocidos. _Las t√©cnicas de Prompt engineering ayudan a los usuarios a identificar y mitigar tales fabricaciones, por ejemplo, pidiendo a la IA citas o razonamiento_.

3. **Las capacidades de los modelos variar√°n.** Los modelos o generaciones de modelos m√°s nuevas tendr√°n capacidades m√°s enriquecidas, pero tambi√©n traer√°n peculiaridades y compensaciones √∫nicas en el costo y la complejidad. _Prompt engineering puede ayudarnos a desarrollar las mejores pr√°cticas y flujos de trabajo que eliminen las diferencias y se adapten a los requisitos espec√≠ficos del modelo en formas escalables y perfectas_.

Veamos esto en acci√≥n en el Playground de OpenAI o el de Azure OpenAI:

- Usa el mismo prompt con diferentes implementaciones de LLM (por ejemplo, OpenAI, Azure OpenAI, Hugging Face) - ¬øViste las variaciones?
- Usa el mismo prompt repetidamente con la _misma_ implementaci√≥n de LLM (por ejemplo, Azure OpenAI Playground) - ¬øC√≥mo difer√≠an estas variaciones?

### Ejemplo de Fabricaciones

En este curso, utilizamos el t√©rmino **"fabricaci√≥n"** para hacer referencia al fen√≥meno donde los LLMs en ocasiones generan informaci√≥n factualmente incorrecta debido a limitaciones en su entrenamiento u otras restricciones. Tambi√©n puedes haber escuchado esto referido como _"alucinaciones"_ en art√≠culos o trabajos de investigaci√≥n populares. Sin embargo, recomendamos encarecidamente usar _"fabricaci√≥n"_ como el t√©rmino a fin de no antropomorfizar accidentalmente el comportamiento al atribuir un rasgo de un resultado humano a un resultado impulsado por una m√°quina. Esto tambi√©n refuerza [las gu√≠as de IA Responsable](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) desde una perspectiva de terminolog√≠a, eliminando t√©rminos que tambi√©n pueden considerarse ofensivos o no inclusivos en algunos contextos.

¬øQuieres tener una idea de c√≥mo funcionan las fabricaciones? Piensa en un prompt que instruya a la IA a generar contenido para un tema inexistente (para asegurarse de que no se encuentre en el conjunto de datos de entrenamiento). Por ejemplo, prob√© este prompt:

> **Prompt:** generate a lesson plan on the Martian War of 2076.

Una b√∫squeda web me mostr√≥ que hab√≠a cuentas ficticias (por ejemplo, series de televisi√≥n o libros) sobre guerras Marcianas - pero ninguna en 2076. El sentido com√∫n tambi√©n nos dice que 2076 est√° _en el futuro_ y, por lo tanto, no puede ser asociado con un evento real.

Entonces, ¬øqu√© sucede cuando ejecutamos este prompt con diferentes proveedores de LLM?

> **Respuesta 1**: OpenAI Playground (GPT-35)

![Respuesta 1](../../images/04-fabrication-oai.png?WT.mc_id=academic-105485-koreyst)

> **Respuesta 2**: Azure OpenAI Playground (GPT-35)

![Respuesta 2](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)

> **Respuesta 3**: : Hugging Face Chat Playground (LLama-2)

![Respuesta 3](../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)

Como se esperaba, cada modelo (o versi√≥n del modelo) produce respuestas ligeramente diferentes gracias al comportamiento estoc√°stico y las variaciones de capacidad del modelo. Por ejemplo, un modelo se dirige a una audiencia de 8¬∫ grado, mientras que el otro asume a un estudiante de bachillerato. Pero los tres modelos generaron respuestas que podr√≠an convencer a un usuario desinformado de que el evento era real.

Las t√©cnicas de Prompt engineering como _metaprompting_ y _configuraci√≥n de temperatura_ pueden reducir las fabricaciones de modelos hasta cierto punto. Nuevas _arquitecturas_ de prompt engineering tambi√©n incorporan nuevas herramientas y t√©cnicas sin problemas en el flujo del prompt, para mitigar o reducir algunos de estos efectos.

## Caso de Estudio: GitHub Copilot

Concluyamos esta secci√≥n obteniendo una idea de c√≥mo prompt engineering es usado en soluciones del mundo real observando un Caso de Estudio: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot es tu "Programador de Pares de IA" - convierte los prompts de texto en finalizaciones de c√≥digo y est√° integrado en tu entorno de desarrollo (por ejemplo, Visual Studio Code) para una experiencia de usuario perfecta. Como se documenta en la serie de blogs mostrados a continuaci√≥n, la primer versi√≥n se bas√≥ en el modelo OpenAI Codex - con los ingenieros d√°ndose cuenta r√°pidamente de la necesidad de ajustar el modelo y desarrollar mejores t√©cnicas de prompt engineering, para mejorar la calidad del c√≥digo. En Julio, [debutaron un mejorado modelo de IA que va m√°s all√° del Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) para sugerencias a√∫n m√°s r√°pidas.

Lee las publicaciones en orden para seguir su viaje de aprendizaje.

- **Mayo 2023** | [GitHub Copilot se est√° Volviendo Mejor en Comprender Tu c√≥digo](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Mayo 2023** | [Dentro de GitHub: Trabajando con los LLMs detr√°s de GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Junio 2023** | [C√≥mo escribir mejores prompts para GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Julio 2023** | [.. GitHub Copilot va m√°s all√° del Codex con un mejorado modelo de AI](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Julio 2023** | [Una Gu√≠a del Desarrollador para Prompt Engineering y LLMs](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Septiembre 2023** | [C√≥mo crear una aplicaci√≥n LLM empresarial: Lecciones de GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Tambi√©n puedes navegar por su [blog de Ingenier√≠a](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) para m√°s publicaciones como [esta](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst) que muestra c√≥mo estos modelos y t√©cnicas son _aplicados_ para dirigir aplicaciones del mundo real.

---

<!--
PLANTILLA DE LA LECCI√ìN:
Esta unidad deber√≠a cubrir el concepto central #2.
Refuerza el concepto con ejemplos y referencias.

CONCEPTO #2:
Dise√±o de Prompts.
Ilustrado con ejemplos.
-->

## Construcci√≥n de Prompts

Hemos visto por qu√© prompt engineering es importante - ahora comprendamos c√≥mo los prompts son _construidos_ a fin de poder evaluar diferentes t√©cnicas para un dise√±o de prompts m√°s efectivo.

### Prompt B√°sico

Comencemos con el prompt b√°sico: una entrada de texto enviada al modelo sin ning√∫n contexto. Aqu√≠ hay un ejemplo - cuando enviamos las primeras palabras del himno nacional de Estados Unidos al [API de Completions](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) de OpenAI, instant√°neamente _completa_ la respuesta con las siguientes l√≠neas, ilustrando el comportamiento b√°sico de predicci√≥n.

| Prompt (Entrada)     | Finalizaci√≥n (Salida)                                                                                                                        |
| :------------------- | :------------------------------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see   | It sounds like you're starting the lyrics to "The Star-Spangled Banner," the national anthem of the United States. The full lyrics are ...   |

### Prompt Complejo

Ahora agregemos contexto e instrucciones a ese prompt b√°sico. El [API de Chat Completion](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) nos permite construir un prompt complejo como una colecci√≥n de _mensajes_ com:

- Pares de entrada/salida que reflejan la entrada del _usuario_ y la respuesta del _asistente_.
- Mensaje del sistema que establece el contexto para el comportamiento o la personalidad del asistente.

La solicitud ahora est√° en el formulario mostrado a continuaci√≥n, donde la _tokenizaci√≥n_ captura efectivamente informaci√≥n relevante del contexto y la conversaci√≥n. Ahora, cambiar el contexto del sistema puede ser tan impactante en la calidad de las finalizaciones como las entradas del usuario proporcionadas.

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "Eres un asistente √∫til."},
        {"role": "user", "content": "¬øQui√©n gan√≥ la Serie Mundial en 2020?"},
        {"role": "assistant", "content": "Los Angeles Dodgers ganaron la Serie Mundial en 2020."},
        {"role": "user", "content": "¬øD√≥nde se jug√≥?"}
    ]
)
```

### Prompt de Instrucci√≥n

En los ejemplos anteriores, el prompt del usuario era una consulta de texto simple que puede interpretarse como una solicitud de informaci√≥n. Con los prompts de _instrucci√≥n_, podemos usar ese texto para especificar una tarea con m√°s detalle, proporcionando una mejor orientaci√≥n a la IA. Aqu√≠ hay un ejemplo:

| Prompt (Entrada)                                                                                                                                                                                                                         | Finalizaci√≥n (Salida)                                                                                                        | Tipo de Instrucci√≥n    |
| :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------- | :------------------ |
| Escribe una descripci√≥n de la Guerra Civil                                                                                                                                                                                                   | _devolvi√≥ un p√°rrafo simple_                                                                                              | Simple              |
| Escribe una descripci√≥n de la Guerra Civil. Proporciona fechas y eventos clave y describe su importancia.                                                                                                                                      | _devolvi√≥ un p√°rrafo seguido de una lista de fechas de eventos clave con descripciones_                                             | Complejo             |
| Escribe una descripci√≥n de la Guerra Civil en 1 p√°rrafo. Proporciona 3 vi√±etas con fechas clave y su significado. Proporciona 3 vi√±etas m√°s con figuras hist√≥ricas clave y sus contribuciones. Devuelve el resultado como un archivo JSON. | _devolvi√≥ detalles m√°s extensos en un cuadro de texto, formateado como JSON que puedes copiar y pegar a un archivo y validar seg√∫n sea necesario_ | Complejo. Formateado. |

## Contenido Principal

En los ejemplos anteriores, el prompt todav√≠a estaba bastante abierto, lo que permiti√≥ que el LLM decidiera qu√© parte de su conjunto de datos pre-entrenado era relevante. Con el patr√≥n de dise√±o _contenido principal_, el texto de entrada se divide en dos partes:

- una instrucci√≥n (acci√≥n)
- contenido relevante (que influye en la acci√≥n)

Aqu√≠ hay un ejemplo en el que la instrucci√≥n es "resumir esto en 2 oraciones".

| Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      | Finalizaci√≥n (Salida)                                                                                                                                                                                                                                                                             |
| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| J√∫piter es el quinto planeta a partir del Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte del sol, pero dos veces y media m√°s que la de todos los dem√°s planetas en el Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. Recibe su nombre del dios romano J√∫piter.[19] Cuando se observa desde la Tierra, J√∫piter puede ser lo suficientemente brillante como para que su luz reflejada proyecte sombras visibles,[20] y es en promedio el tercer objeto natural m√°s brillante en el cielo nocturno despu√©s de la Luna y Venus. <br/> **Resume esto en 2 oraciones cortas** | J√∫piter, el quinto planeta a partir del Sol, es el m√°s grande del Sistema Solar y es conocido por ser uno de los objetos m√°s brillantes del cielo nocturno. Llamado as√≠ por el dios romano J√∫piter, es un gigante gaseoso cuya masa es dos veces y media la de todos los dem√°s planetas del Sistema Solar juntos. |

El segmento de contenido primario se puede utilizar de varias maneras para impulsar instrucciones m√°s efectivas:

- **Ejemplos** - en lugar de decirle al modelo qu√© hacer con una instrucci√≥n expl√≠cita, dale ejemplos de qu√© hacer y d√©jalo que infiera el patr√≥n.
- **Se√±ales** - acompa√±a la instrucci√≥n con una "se√±al" que prepare la finalizaci√≥n, guiando el modelo hacia respuestas m√°s relevantes.
- **Plantillas** - estas son 'recetas' repetibles para prompts con marcadores de posici√≥n (variables) que pueden personalizarse con datos para casos de uso espec√≠ficos.

Ve√°moslos en acci√≥n.

### Usando Ejemplos

Este es un enfoque en el que usas el contenido principal para "alimentar el modelo" con algunos ejemplos de la salida deseada para una instrucci√≥n dada, dejando as√≠ que infiera el patr√≥n para la salida deseada. Seg√∫n el n√∫mero de ejemplos proporcionados, podemos tener zero-shot prompting, one-shot prompting, few-shot prompting, etc.

El prompt ahora consta de tres componentes:

- La descripci√≥n de una tarea
- Unos cuantos ejemplos de la salida deseada
- El inicio de un nuevo ejemplo (el cual se convierte en una descripci√≥n impl√≠cita de la tarea) 

| Tipo de Aprendizaje | Prompt (Entrada)                                                                                                                                        | Finalizaci√≥n (Salida)         |
| :------------ | :---------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------- |
| Zero-shot     | "The Sun is Shining". Translate to Spanish                                                                                                            | "El Sol est√° brillando".    |
| One-shot      | "The Sun is Shining" => ""El Sol est√° brillando". <br> "It's a Cold and Windy Day" =>                                                                 | "Es un d√≠a fr√≠o y ventoso". |
| Few-shot      | The player ran the bases => Baseball <br/> The player hit an ace => Tennis <br/> The player hit a six => Cricket <br/> The player made a slam-dunk => | Basketball                  |
|               |                                                                                                                                                       |                             |

Observa c√≥mo tuvimos que proporcionar instrucci√≥n expl√≠cita ("Translate to Spanish") en zero-shot prompting, pero dicha tarea es inferida en el ejemplo de one-shot prompting. El ejemplo de few-shot prompting muestra c√≥mo agregar m√°s ejemplos permite a los modelos hacer inferencias m√°s precisas sin instrucciones adicionales.

### Se√±ales de Prompt

Otra t√©cnica para usar contenido primario es proporcionar _se√±ales_ en lugar de ejemplos. En este caso, estamos dando al modelo un empuj√≥n en la direcci√≥n correcta al _inicializarlo_ con un fragmento que refleja el formato de respuesta deseado. El modelo luego "toma la se√±al" para continuar en esa l√≠nea.

| N√∫mero de Se√±ales | Prompt (Entrada)                                                                                                                                                                                                                                                                                                                                                                                                                                               | Finalizaci√≥n (Salida)                                                                                                                                                                                                                                                                                       |
| :------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0              | J√∫piter es el quinto planeta a partir del Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte del sol, pero dos veces y media m√°s que la de todos los dem√°s planetas en el Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Resume esto**                                       | J√∫piter es el planeta m√°s grande de nuestro Sistema Solar y el quinto a partir del Sol. Es un gigante gaseoso con una masa 1/1000 la del Sol, pero es m√°s pesado que todos los dem√°s planetas combinados. Las civilizaciones antiguas han sabido sobre J√∫piter durante mucho tiempo, y es f√°cilmente visible en el cielo nocturno.. |
| 1              | J√∫piter es el quinto planeta a partir del Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte del sol, pero dos veces y media m√°s que la de todos los dem√°s planetas en el Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Resume esto** <br/> Lo que aprendimos es que J√∫piter | es el quinto planeta a partir del Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa igual a la mil√©sima parte del sol, pero dos veces y media m√°s que la de todos los dem√°s planetas combinados. Es f√°cilmente visible a simple vista y ha sido conocido desde la antig√ºedad.                        |
| 2              | J√∫piter es el quinto planeta a partir del Sol y el m√°s grande del Sistema Solar. Es un gigante gaseoso con una masa de una mil√©sima parte del sol, pero dos veces y media m√°s que la de todos los dem√°s planetas en el Sistema Solar combinados. J√∫piter es uno de los objetos m√°s brillantes visibles a simple vista en el cielo nocturno, y ha sido conocido por las civilizaciones antiguas desde antes de la historia registrada. <br/>**Resume esto** <br/> Los 3 Hechos Principales Que Aprendimos:         | 1. J√∫piter es el quinto planeta a partir del Sol y el m√°s grande del Sistema Solar. <br/> 2. Es un gigante gaseoso con una masa de una mil√©sima parte del Sol...<br/> 3. J√∫piter ha sido visible a simple vista desde la antig√ºedad ...                                                                       |
|                |                                                                                                                                                                                                                                                                                                                                                                                                                                                              |                                                                                                                                                                                                                                                                                                           |



### Plantillas de Prompt

Una plantilla de prompt es una _receta predefinida para un prompt_ que puede almacenarse y reutilizarse seg√∫n sea necesario, para impulsar experiencias de usuario m√°s consistentes a escala. En su forma m√°s simple, es simplemente una colecci√≥n de ejemplos de prompt como [este de OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst) que proporciona tanto los componentes interactivos de un prompt (mensajes de usuario y de sistema) como el formato de solicitud impulsado por la API - para admitir la reutilizaci√≥n.

En su forma m√°s compleja como [este ejemplo de LangChain](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/?WT.mc_id=academic-105485-koreyst) contiene _marcadores de posici√≥n_ que pueden ser reemplazados por datos de una variedad de fuentes (entrada del usuario, contexto del sistema, fuentes de datos externas, etc.) para generar un prompt de manera din√°mica. Esto nos permite crear una biblioteca de prompts reutilizables que se pueden usar para impulsar experiencias de usuario consistentes **de forma program√°tica** a escala.

Finalmente, el valor real de las plantillas radica en la capacidad de crear y publicar _bibliotecas de prompts_ para dominios de aplicaciones verticales - donde la plantilla de prompt ahora est√° _optimizada_ para reflejar el contexto o ejemplos espec√≠ficos de la aplicaci√≥n que hacen que las respuestas sean m√°s relevantes y precisas para la audiencia de usuarios objetivo. El repositorio [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) es un gran ejemplo de este enfoque, ya que re√∫ne una biblioteca de prompts para el √°mbito educativo con √©nfasis en objetivos clave como la planificaci√≥n de clases, el dise√±o de planes de estudios, la tutor√≠a de estudiantes, etc.

## Contenido de Apoyo

Si pensamos en la construcci√≥n de prompts como algo que tiene una instrucci√≥n (tarea) y un objetivo (contenido primario), entonces el _contenido secundario_ es como un contexto adicional que proporcionamos para **influir en el resultado de alguna manera**. Podr√≠a tratarse de ajuste de par√°metros, instrucciones de formato, taxonom√≠as tem√°ticas, etc., que pueden ayudar al modelo a _adaptar_ su respuesta de acuerdo a los objetivos o expectativas del usuario.

Por ejemplo: Dado un cat√°logo de cursos con metadatos extensos (nombre, descripci√≥n, nivel, etiquetas de metadatos, instructor, etc.) en todos los cursos disponibles en el plan de estudios:

- podemos definir una instrucci√≥n para "resumir el cat√°logo de cursos para el Oto√±o 2023"
- podemos usar el contenido principal para proporcionar algunos ejemplos de la salida deseada
- podemos usar el contenido secundario para identificar las 5 "etiquetas" principales de inter√©s.

Ahora, el modelo puede proporcionar un resumen en el formato mostrado por los pocos ejemplos - pero si un resultado tiene varias etiquetas, puede priorizar las 5 etiquetas identificadas en el contenido secundario.

---

<!--
PLANTILLA DE LA LECCI√ìN:
Esta unidad deber√≠a cubrir el concepto central #2.
Refuerza el concepto con ejemplos y referencias.

CONCEPT #3:
T√©cnicas de Prompt Engineering.
¬øCu√°les son algunas t√©cnicas b√°sicas para prompt engineering?
Il√∫stralo con algunos ejercicios.
-->

## Mejores Pr√°cticas de Prompting

Ahora que sabemos c√≥mo se pueden _construir_ los prompts, podemos empezar a pensar en c√≥mo _dise√±arlos_ para que reflejen las mejores pr√°cticas. Esto puede dividirse en dos partes - tener la _mentalidad_ adecuada y aplicar las _t√©cnicas_ adecuadas.

### Mentalidad de Prompt Engineering

Prompt Engineering es un proceso de prueba-y-error, por lo que hay que tener en cuenta tres grandes factores orientativos:

1. **La Comprensi√≥n del Dominio Importa.** La precisi√≥n y relevancia de la respuesta es una funci√≥n del _dominio_ en el que opera esa aplicaci√≥n o usuario. Aplica tu intuici√≥n y experiencia en el campo para **personalizar t√©cnicas** a√∫n m√°s. Por ejemplo, define _personalidades espec√≠ficas del dominio_ en los prompts del sistema, o utiliza _plantillas espec√≠ficas del dominio_ en los prompts del usuario. Proporciona contenido secundario que refleje contextos espec√≠ficos del dominio o utiliza _se√±ales y ejemplos espec√≠ficos del dominio_ para guiar el modelo hacia patrones de uso familiares.

2. **La Comprensi√≥n del Modelo Importa.** Sabemos que los modelos son estoc√°sticos por naturaleza. Pero las implementaciones de modelos tambi√©n pueden variar en t√©rminos del conjunto de datos de entrenamiento que utilizan (conocimientos pre-entrenados), las capacidades que proporcionan (por ejemplo, a trav√©s de API o SDK) y el tipo de contenido para el que est√°n optimizados (por ejemplo, c√≥digo vs im√°genes vs texto). Comprende las fortalezas y limitaciones del modelo que est√°s utilizando y utiliza ese conocimiento para _priorizar tareas_ o crear _plantillas personalizadas_ que est√©n optimizadas para las capacidades del modelo.

3. **La Iteraci√≥n y la Validaci√≥n Importan.** Los modelos est√°n evolucionando r√°pidamente, al igual que las t√©cnicas para prompt engineering. Como experto en un dominio, es posible que tengas otro contexto o criterio para _tu_ aplicaci√≥n espec√≠fica, que puede no aplicarse a la comunidad en general. Utiliza herramientas y t√©cnicas de prompt engineering para "iniciar" la construcci√≥n de prompts, luego itera y valida los resultados utilizando tu propia intuici√≥n y experiencia en el dominio. Registra tus observaciones y crea una **base de conocimientos** (por ejemplo, bibliotecas de prompts) que otros puedan utilizar como nueva base de referencia para iteraciones m√°s r√°pidas en el futuro.

## Mejores Pr√°cticas

Ahora veamos las mejores pr√°cticas comunes recomendadas por los profesionales de [Open AI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) y [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Qu√©                              | Por Qu√©                                                                                                                                                                                                                                            |
| :-------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Eval√∫a los √∫ltimos modelos.       | Es probable que las nuevas generaciones de modelos tengan mejores caracter√≠sticas y calidad - pero tambi√©n pueden incurrir en costos m√°s elevados. Eval√∫a su impacto y luego toma decisiones sobre la migraci√≥n.                                                                                    |
| Separa instrucciones y contexto.  | Comprueba si tu modelo/proveedor define _delimitadores_ para distinguir las instrucciones y el contenido primario y secundario con mayor claridad. Esto puede ayudar a los modelos a asignar pesos a los tokens con mayor precisi√≥n.                                                                |
| S√© espec√≠fico y claro.            | Proporciona m√°s detalles sobre el contexto deseado, el resultado, la longitud, el formato, el estilo, etc. Esto mejorar√° tanto la calidad como la coherencia de las respuestas. Captura recetas en plantillas reutilizables.                                                                         |
| S√© descriptivo, usa ejemplos.     | Los modelos pueden responder mejor a un enfoque de "mostrar y contar". Comienza con un enfoque "zero-shot" en el que le das una instrucci√≥n (pero sin ejemplos) y luego prueba con "few-shot" como refinamiento, proporcionando algunos ejemplos del resultado deseado. Utiliza analog√≠as. |
| Utiliza se√±ales para impulsar las finalizaciones.  | Emp√∫jalo hacia el resultado deseado d√°ndole algunas palabras o frases clave que pueda usar como punto de partida para la respuesta.                                                                                                                                                 |
| Dobla la Apuesta.                 | A veces es posible que necesites repetir lo mismo que el modelo. Da instrucciones antes y despu√©s de tu contenido principal, usa una instrucci√≥n y una se√±al, etc. Itera y valida para ver qu√© funciona.                                                                                        |
| El Orden Importa.                 | El orden en el que presentas la informaci√≥n al modelo puede afectar el resultado, incluso en los ejemplos de aprendizaje, gracias al sesgo de actualidad. Prueba diferentes opciones para ver cu√°l funciona mejor.                                                                                    |
| Dale una "salida" al modelo.      | Proporciona al modelo una respuesta de finalizaci√≥n _alternativa_ que pueda proporcionar si no puede completar la tarea por alg√∫n motivo. Esto puede reducir las posibilidades de que los modelos generen respuestas falsas o fabricadas.                                                            |
|                                   |                                                                                                                                                                                                                                                   |

Como con cualquier otra mejor pr√°ctica, recuerda que _tu kilometraje puede variar_ en funci√≥n del modelo, la tarea y el dominio. Util√≠zalos como punto de partida e itera para encontrar lo que funciona mejor para t√≠. Reeval√∫a constantemente tu proceso de prompt engineering a medida que dispongas de nuevos modelos y herramientas, centr√°ndote en la escalabilidad del proceso y la calidad de la respuesta.

<!--
PLANTILLA DE LECCI√ìN:
Esta unidad deber√≠a proporcionar un desaf√≠o de c√≥digo si corresponde

DESAF√çO:
Enlace a un Jupyter Notebook con solo los comentarios de c√≥digo en las instrucciones (las secciones de c√≥digo est√°n vac√≠as).

SOLUCI√ìN:
Enlace a una copia de ese Notebook con los prompts completados y ejecutados, mostrando lo que un ejemplo podr√≠a ser.
-->

## Tarea

¬°Felicidades! ¬°Llegaste al final de la lecci√≥n! ¬°Es hora de poner a prueba algunos de esos conceptos y t√©cnicas con ejemplos reales!

Para nuestra tarea, utilizaremos un Jupyter Notebook con ejercicios que puedes completar de manera interactiva. Tambi√©n puedes extender el Notebook con tus propias celdas de Markdown y C√≥digo para explorar ideas y t√©cnicas por tu cuenta.

### Para comenzar, haz fork al repo, luego

- (Recomendado) Inicia GitHub Codespaces
- (Alternativamente) Clona el repositorio a tu dispositivo local y √∫salo con Docker Desktop
- (Alternativamente) Abre el Notebook con tu entorno de runtime de Notebook preferido.

### Siguiente, configura tus variables de entorno

- Copia el archivo `.env.copy` en la raiz del repositorio a `.env` y actualiza los valores de `AZURE_OPENAI_KEY`, `AZURE_OPENAI_ENDPOINT` y `AZURE_OPENAI_DEPLOYMENT`. Consulta la [secci√≥n de Sandbox de Aprendizaje](../../../04-prompt-engineering-fundamentals#learning-sandbox) para aprender c√≥mo.

### Siguiente, abre el Jupyter Notebook

- Selecciona el runtime kernel. Si est√°s usando las opciones 1 o 2, simplemente selecciona el kernel predeterminado Python 3.10.x proporcionado por el contenedor de desarrollo.

Est√°s listo para realizar los ejercicios. Ten en cuenta que no hay respuestas _correctas o incorrectas_ aqu√≠ - sino que se trata de explorar opciones por prueba y error y de desarrollar la intuici√≥n de lo que funciona para un modelo y un dominio de aplicaci√≥n determinados.

_Por esta raz√≥n, no hay segmento de C√≥digo de Soluci√≥n en esta lecci√≥n. En su lugar, el Notebook tendr√° celdas de Markdown tituladas "Mi Soluci√≥n:" que muestra una salida de ejemplo para referencia._

 <!--
PLANTILLA DE LA LECCI√ìN:
Concluye la secci√≥n con un resumen y recursos para el aprendizaje autoguiado.
-->

## Verificaci√≥n de Conocimientos

¬øCu√°l de los siguientes es un buen prompt que sigue algunas mejores pr√°cticas razonables?

1. Mu√©strame una imagen del auto rojo
2. Mu√©strame una imagen del auto rojo de marca Volvo y modelo XC90 estacionado cerca de un acantilado con la puesta de sol
3. Mu√©strame una imagen del auto rojo de marca Volvo y modelo XC90

R: 2, es el mejor prompt, ya que proporciona detalles sobre "qu√©" y entra en detalles (no cualquier autom√≥vil sino una marca y modelo espec√≠ficos) y tambi√©n describe la configuraci√≥n general. 3 es el siguiente mejor, ya que tambi√©n contiene mucha descripci√≥n.

## üöÄ Desaf√≠o

Ve si puedes aprovechar la t√©cnica de la "se√±al" con el siguiente prompt: Completa la oraci√≥n "Mu√©strame una imagen del auto rojo de la marca Volvo y ". ¬øCon qu√© responde y c√≥mo lo mejorar√≠as?

## ¬°Buen trabajo! Contin√∫a tu Aprendizaje

¬øQuieres obtener m√°s informaci√≥n sobre los diferentes conceptos de Prompt Engineering? Ve a la [p√°gina de aprendizaje continuo](../../../13-continued-learning/README.md?WT.mc_id=academic-105485-koreyst) para encontrar otros grandes recursos sobre este tema.

Dir√≠gete a la Lecci√≥n 6 donde veremos ¬°[t√©cnicas avanzadas de prompting](../../../05-advanced-prompts/README.md?WT.mc_id=academic-105485-koreyst)!
