# Podstawy In偶ynierii Prompt贸w

[![Podstawy In偶ynierii Prompt贸w](../../images/04-lesson-banner.png?WT.mc_id=academic-105485-koreyst)](https://aka.ms/gen-ai-lesson4-gh?WT.mc_id=academic-105485-koreyst)

## Wprowadzenie

Ten modu obejmuje podstawowe koncepcje i techniki tworzenia skutecznych prompt贸w dla modeli generatywnej sztucznej inteligencji. Spos贸b, w jaki piszesz prompt do modelu LLM, ma du偶e znaczenie. Starannie opracowany prompt mo偶e zapewni lepsz jako odpowiedzi. Ale co dokadnie oznaczaj terminy takie jak _prompt_ i _in偶ynieria prompt贸w_? I jak mog ulepszy _dane wejciowe_ prompta, kt贸re wysyam do LLM? To pytania, na kt贸re postaramy si odpowiedzie w tym rozdziale i nastpnym.

_Generatywna sztuczna inteligencja_ jest zdolna do tworzenia nowych treci (np. tekstu, obraz贸w, d藕wiku, kodu itp.) w odpowiedzi na proby u偶ytkownika. Osiga to za pomoc _Du偶ych Modeli Jzykowych_, takich jak seria GPT firmy OpenAI ("Generative Pre-trained Transformer"), kt贸re s trenowane do u偶ywania jzyka naturalnego i kodu.

U偶ytkownicy mog teraz wchodzi w interakcje z tymi modelami, korzystajc z dobrze znanych paradygmat贸w, takich jak czat, bez koniecznoci posiadania wiedzy technicznej czy specjalistycznego szkolenia. Modele te s _oparte na promptach_ - u偶ytkownicy wysyaj wejcie tekstowe (prompt) i otrzymuj odpowied藕 AI (uzupenienie). Nastpnie mog "rozmawia z AI" iteracyjnie, w wieloturowych konwersacjach, dopracowujc sw贸j prompt, a偶 odpowied藕 bdzie zgodna z ich oczekiwaniami.

"Prompty" staj si teraz g贸wnym _interfejsem programistycznym_ dla aplikacji generatywnej AI, m贸wic modelom, co maj robi i wpywajc na jako zwracanych odpowiedzi. "In偶ynieria Prompt贸w" to szybko rozwijajca si dziedzina bada, kt贸ra koncentruje si na _projektowaniu i optymalizacji_ prompt贸w w celu dostarczania sp贸jnych i jakociowych odpowiedzi na du偶 skal.

## Cele Nauki

W tej lekcji dowiemy si, czym jest in偶ynieria prompt贸w, dlaczego jest wa偶na i jak mo偶emy tworzy bardziej efektywne prompty dla danego modelu i celu aplikacji. Zrozumiemy podstawowe koncepcje i najlepsze praktyki w in偶ynierii prompt贸w - oraz poznamy interaktywne rodowisko Jupyter Notebooks "sandbox", w kt贸rym zobaczymy zastosowanie tych koncepcji na prawdziwych przykadach.

Do koca tej lekcji bdziemy potrafili:

1. Wyjani, czym jest in偶ynieria prompt贸w i dlaczego jest wa偶na.
2. Opisa komponenty promptu i spos贸b ich wykorzystania.
3. Pozna najlepsze praktyki i techniki in偶ynierii prompt贸w.
4. Zastosowa poznane techniki na rzeczywistych przykadach, korzystajc z punktu kocowego OpenAI.

## Kluczowe Pojcia

In偶ynieria Prompt贸w: Praktyka projektowania i udoskonalania danych wejciowych w celu naprowadzania modeli AI na generowanie po偶danych wynik贸w.
Tokenizacja: Proces konwersji tekstu na mniejsze jednostki, zwane tokenami, kt贸re model mo偶e zrozumie i przetwarza.
LLM dostrojone instrukcyjnie: Du偶e Modele Jzykowe (LLM), kt贸re zostay dostrojone za pomoc okrelonych instrukcji w celu poprawy dokadnoci i trafnoci ich odpowiedzi.

## Sandbox do Nauki

In偶ynieria prompt贸w jest obecnie bardziej sztuk ni偶 nauk. Najlepszym sposobem na popraw naszej intuicji w tej dziedzinie jest _wicej praktyki_ i przyjcie podejcia pr贸b i bd贸w, kt贸re czy wiedz eksperck z zakresu dziedziny zastosowania z zalecanymi technikami i optymalizacjami specyficznymi dla modelu.

Notebook Jupyter towarzyszcy tej lekcji zapewnia rodowisko _sandbox_, w kt贸rym mo偶esz wypr贸bowa to, czego si uczysz - w trakcie nauki lub jako cz wyzwania kodowego na kocu. Aby wykona wiczenia, bdziesz potrzebowa:

1. **Klucza API Azure OpenAI** - punktu kocowego usugi dla wdro偶onego LLM.
2. **rodowiska Wykonawczego Python** - w kt贸rym mo偶na uruchomi Notebook.
3. **Lokalnych Zmiennych rodowiskowych** - _wykonaj teraz kroki [SETUP](../../../00-course-setup/translations/pl/SETUP.md?WT.mc_id=academic-105485-koreyst), aby by gotowym_.

Notebook zawiera wiczenia _startowe_ - ale zachcamy do dodawania wasnych sekcji _Markdown_ (opis) i _Code_ (偶dania prompt贸w), aby wypr贸bowa wicej przykad贸w lub pomys贸w - i zbudowa swoj intuicj dotyczc projektowania prompt贸w.

## Ilustrowany Przewodnik

Chcesz pozna og贸lny obraz tego, co obejmuje ta lekcja, zanim si w ni zagbisz? Sprawd藕 ten ilustrowany przewodnik, kt贸ry daje ci pojcie o g贸wnych tematach i kluczowych wnioskach do przemylenia w ka偶dym z nich. Mapa lekcji prowadzi ci od zrozumienia podstawowych koncepcji i wyzwa do rozwizywania ich za pomoc odpowiednich technik in偶ynierii prompt贸w i najlepszych praktyk. Zauwa偶, 偶e sekcja "Zaawansowane Techniki" w tym przewodniku odnosi si do treci zawartych w _nastpnym_ rozdziale tego programu nauczania.

![Ilustrowany Przewodnik do In偶ynierii Prompt贸w](../../images/04-prompt-engineering-sketchnote.png?WT.mc_id=academic-105485-koreyst)

## Nasz Startup

Teraz porozmawiajmy o tym, jak _ten temat_ odnosi si do misji naszego startupu [wprowadzania innowacji AI do edukacji](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-koreyst). Chcemy budowa aplikacje AI wspomagajce _spersonalizowane uczenie si_ - zastan贸wmy si wic, jak r贸偶ni u偶ytkownicy naszej aplikacji mogliby "projektowa" prompty:

- **Administratorzy** mogliby poprosi AI o _analiz danych programowych w celu identyfikacji luk w zakresie materiau_. AI mo偶e podsumowa wyniki lub wizualizowa je za pomoc kodu.
- **Edukatorzy** mogliby poprosi AI o _wygenerowanie planu lekcji dla okrelonej grupy docelowej i tematu_. AI mo偶e stworzy spersonalizowany plan w okrelonym formacie.
- **Studenci** mogliby poprosi AI o _pomoc w trudnym przedmiocie_. AI mo偶e teraz prowadzi student贸w poprzez lekcje, wskaz贸wki i przykady dostosowane do ich poziomu.

To tylko wierzchoek g贸ry lodowej. Sprawd藕 [Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-koreyst) - bibliotek prompt贸w open-source, stworzon przez ekspert贸w edukacyjnych - aby uzyska szersze pojcie o mo偶liwociach! _Spr贸buj uruchomi niekt贸re z tych prompt贸w w sandboxie lub korzystajc z OpenAI Playground, aby zobaczy, co si stanie!_

## Czym jest In偶ynieria Prompt贸w?

Rozpoczlimy t lekcj od zdefiniowania **In偶ynierii Prompt贸w** jako procesu _projektowania i optymalizacji_ wej tekstowych (prompt贸w) w celu dostarczania sp贸jnych i jakociowych odpowiedzi (uzupenie) dla danego celu aplikacji i modelu. Mo偶emy myle o tym jako o procesie 2-etapowym:

- _projektowanie_ pocztkowego promptu dla danego modelu i celu
- _doskonalenie_ promptu iteracyjnie w celu poprawy jakoci odpowiedzi

Jest to z koniecznoci proces pr贸b i bd贸w, kt贸ry wymaga intuicji i wysiku u偶ytkownika, aby uzyska optymalne wyniki. Dlaczego wic jest to wa偶ne? Aby odpowiedzie na to pytanie, musimy najpierw zrozumie trzy koncepcje:

- _Tokenizacja_ = jak model "widzi" prompt
- _Bazowe LLM_ = jak model podstawowy "przetwarza" prompt
- _LLM Dostrojone Instrukcyjnie_ = jak model mo偶e teraz widzie "zadania"

### Tokenizacja

LLM widzi prompty jako _sekwencj token贸w_, gdzie r贸偶ne modele (lub wersje modelu) mog tokenizowa ten sam prompt na r贸偶ne sposoby. Poniewa偶 LLM s trenowane na tokenach (a nie na surowym tekcie), spos贸b tokenizacji prompt贸w ma bezporedni wpyw na jako generowanej odpowiedzi.

Aby zrozumie intuicyjnie, jak dziaa tokenizacja, wypr贸buj narzdzia takie jak [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-koreyst) pokazany poni偶ej. Skopiuj sw贸j prompt - i zobacz, jak zostaje on przeksztacony w tokeny, zwracajc uwag na to, jak s obsugiwane znaki biaych spacji i znaki interpunkcyjne. Zauwa偶, 偶e ten przykad pokazuje starszy LLM (GPT-3) - wic wypr贸bowanie tego z nowszym modelem mo偶e da inny wynik.

![Tokenizacja](../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-koreyst)

### Koncepcja: Modele Podstawowe

Po tokenizacji promptu, g贸wn funkcj ["Bazowego LLM"](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) (lub modelu podstawowego) jest przewidywanie tokenu w tej sekwencji. Poniewa偶 LLM s trenowane na ogromnych zbiorach danych tekstowych, maj dobre zrozumienie statystycznych relacji midzy tokenami i mog dokonywa tych przewidywa z pewnym stopniem pewnoci. Zauwa偶, 偶e nie rozumiej one _znaczenia_ s贸w w promptcie lub tokenie; widz jedynie wzorzec, kt贸ry mog "uzupeni" swoj nastpn prognoz. Mog kontynuowa przewidywanie sekwencji, a偶 do zakoczenia przez interwencj u偶ytkownika lub jaki wczeniej ustalony warunek.

Chcesz zobaczy, jak dziaa uzupenianie oparte na promptach? Wprowad藕 powy偶szy prompt do [_Chat Playground_](https://oai.azure.com/playground?WT.mc_id=academic-105485-koreyst) w Azure OpenAI Studio z domylnymi ustawieniami. System jest skonfigurowany do traktowania prompt贸w jako pr贸b o informacje - wic powiniene zobaczy uzupenienie, kt贸re spenia ten kontekst.

Ale co jeli u偶ytkownik chciaby zobaczy co konkretnego, co spenia pewne kryteria lub cel zadania? Tutaj do gry wchodz _LLM dostrojone instrukcyjnie_.

![Uzupenianie Chatu Bazowego LLM](../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-koreyst)

### Koncepcja: LLM Dostrojone Instrukcyjnie

[LLM Dostrojone Instrukcyjnie](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-koreyst) zaczyna od modelu podstawowego i dostosowuje go za pomoc przykad贸w lub par wejcie/wyjcie (np. wieloturowych "wiadomoci"), kt贸re mog zawiera jasne instrukcje - a odpowied藕 AI stara si pod偶a za t instrukcj.

Wykorzystuje to techniki takie jak Uczenie si przez Wzmacnianie z Ludzkim Feedbackiem (RLHF), kt贸re mog trenowa model do _pod偶ania za instrukcjami_ i _uczenia si z feedbacku_, dziki czemu generuje odpowiedzi, kt贸re s lepiej dostosowane do praktycznych zastosowa i bardziej odpowiednie dla cel贸w u偶ytkownika.

Wypr贸bujmy to - wr贸 do powy偶szego promptu, ale teraz zmie _wiadomo systemow_, aby zapewni nastpujc instrukcj jako kontekst:

> _Podsumuj dostarczony Ci materia dla ucznia drugiej klasy. Ogranicz wynik do jednego akapitu z 3-5 punktami._

Zobacz, jak wynik jest teraz dostosowany do po偶danego celu i formatu? Nauczyciel mo偶e teraz bezporednio u偶y tej odpowiedzi w swoich slajdach dla tej klasy.

![Uzupenianie Chatu LLM Dostrojonego Instrukcyjnie](../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-koreyst)

## Dlaczego potrzebujemy In偶ynierii Prompt贸w?

Teraz, gdy wiemy, jak prompty s przetwarzane przez LLM, porozmawiajmy o tym, _dlaczego_ potrzebujemy in偶ynierii prompt贸w. Odpowied藕 le偶y w fakcie, 偶e obecne LLM stawiaj przed nami szereg wyzwa, kt贸re czyni _uzyskiwanie wiarygodnych i sp贸jnych uzupenie_ trudniejsze bez wysiku wo偶onego w konstrukcj i optymalizacj prompt贸w. Na przykad:

1. **Odpowiedzi modeli s stochastyczne.** _Ten sam prompt_ prawdopodobnie wygeneruje r贸偶ne odpowiedzi z r贸偶nymi modelami lub wersjami modelu. A mo偶e nawet generowa r贸偶ne wyniki z _tym samym modelem_ w r贸偶nym czasie. _Techniki in偶ynierii prompt贸w mog pom贸c nam zminimalizowa te wariacje, zapewniajc lepsze zabezpieczenia_.

1. **Modele mog wymyla odpowiedzi.** Modele s wstpnie trenowane na _du偶ych, ale skoczonych_ zbiorach danych, co oznacza, 偶e brakuje im wiedzy o koncepcjach spoza zakresu tego treningu. W rezultacie mog generowa uzupenienia, kt贸re s niedokadne, zmylone lub bezporednio sprzeczne ze znanymi faktami. _Techniki in偶ynierii prompt贸w pomagaj u偶ytkownikom zidentyfikowa i zagodzi takie zmylenia, np. proszc AI o cytaty lub uzasadnienie_.

1. **Mo偶liwoci modeli bd si r贸偶ni.** Nowsze modele lub generacje modeli bd miay bogatsze mo偶liwoci, ale r贸wnie偶 przynios unikalne dziwactwa i kompromisy w zakresie koszt贸w i zo偶onoci. _In偶ynieria prompt贸w mo偶e pom贸c nam opracowa najlepsze praktyki i przepywy pracy, kt贸re abstrahuj od r贸偶nic i dostosowuj si do wymaga specyficznych dla modelu w skalowalny, bezproblemowy spos贸b_.

Zobaczmy to w akcji w OpenAI lub Azure OpenAI Playground:

- U偶yj tego samego promptu z r贸偶nymi wdro偶eniami LLM (np. OpenAI, Azure OpenAI, Hugging Face) - czy zauwa偶ye r贸偶nice?
- U偶yj wielokrotnie tego samego promptu z _tym samym_ wdro偶eniem LLM (np. Azure OpenAI playground) - jak r贸偶niy si te wariacje?

### Przykad Konfabulacji

W tym kursie u偶ywamy terminu **"konfabulacja"** do okrelenia zjawiska, gdzie LLM czasami generuj informacje faktycznie niepoprawne z powodu ogranicze w ich treningu lub innych ogranicze. By mo偶e syszae o tym zjawisku jako o _"halucynacjach"_ w popularnych artykuach lub pracach badawczych. Jednak zdecydowanie zalecamy u偶ywanie terminu _"konfabulacja"_, abymy przypadkowo nie przypisywali maszynie cech ludzkich. Wzmacnia to r贸wnie偶 [wytyczne Odpowiedzialnej AI](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-koreyst) z perspektywy terminologicznej, usuwajc terminy, kt贸re mog by r贸wnie偶 uznane za obra藕liwe lub niewczajce w niekt贸rych kontekstach.

Chcesz zrozumie, jak dziaaj konfabulacje? Wymyl prompt, kt贸ry instruuje AI do generowania treci na nieistniejcy temat (aby upewni si, 偶e nie znajduje si on w zestawie treningowym). Na przykad - wypr贸bowaem ten prompt:

> **Prompt:** wygeneruj plan lekcji o Wojnie Marsjaskiej z 2076 roku.

Wyszukiwanie w sieci pokazao mi, 偶e istniay fikcyjne opowieci (np. seriale telewizyjne lub ksi偶ki) o wojnach marsjaskich - ale 偶adne w 2076 roku. Zdrowy rozsdek r贸wnie偶 m贸wi nam, 偶e rok 2076 jest _w przyszoci_, a wic nie mo偶e by zwizany z rzeczywistym wydarzeniem.

Co wic si dzieje, gdy uruchamiamy ten prompt z r贸偶nymi dostawcami LLM?

> **Odpowied藕 1**: OpenAI Playground (GPT-35)

![Odpowied藕 1](../../images/04-fabrication-oai.png?WT.mc_id=academic-105485-koreyst)

> **Odpowied藕 2**: Azure OpenAI Playground (GPT-35)

![Odpowied藕 2](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-koreyst)

> **Odpowied藕 3**: : Hugging Face Chat Playground (LLama-2)

![Odpowied藕 3](../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-koreyst)

Zgodnie z oczekiwaniami, ka偶dy model (lub wersja modelu) generuje nieco inne odpowiedzi dziki zachowaniom stochastycznym i r贸偶nicom w mo偶liwociach modelu. Na przykad jeden model celuje w audytorium 8 klasy, podczas gdy inny zakada ucznia liceum. Ale wszystkie trzy modele wygeneroway odpowiedzi, kt贸re mogyby przekona niepoinformowanego u偶ytkownika, 偶e wydarzenie byo prawdziwe.

Techniki in偶ynierii prompt贸w, takie jak _metaprompting_ i _konfiguracja temperatury_, mog w pewnym stopniu zmniejszy konfabulacje modelu. Nowe _architektury_ in偶ynierii prompt贸w r贸wnie偶 bezproblemowo wczaj nowe narzdzia i techniki do przepywu prompt贸w, aby zagodzi lub zmniejszy niekt贸re z tych efekt贸w.

## Studium Przypadku: GitHub Copilot

Podsumujmy t sekcj, zyskujc poczucie, jak in偶ynieria prompt贸w jest wykorzystywana w rozwizaniach ze wiata rzeczywistego, patrzc na jedno studium przypadku: [GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-koreyst).

GitHub Copilot to tw贸j "Programista Partnerski AI" - przeksztaca tekstowe prompty w uzupenienia kodu i jest zintegrowany z twoim rodowiskiem programistycznym (np. Visual Studio Code) dla pynnego dowiadczenia u偶ytkownika. Jak udokumentowano w serii blog贸w poni偶ej, najwczeniejsza wersja bya oparta na modelu OpenAI Codex - a in偶ynierowie szybko zdali sobie spraw z potrzeby dostrojenia modelu i opracowania lepszych technik in偶ynierii prompt贸w, aby poprawi jako kodu. W lipcu [zadebiutowali z ulepszonym modelem AI, kt贸ry wykracza poza Codex](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst) dla jeszcze szybszych sugestii.

Przeczytaj posty w kolejnoci, aby ledzi ich podr贸偶 edukacyjn.

- **Maj 2023** | [GitHub Copilot staje si lepszy w rozumieniu twojego kodu](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-koreyst)
- **Maj 2023** | [Wewntrz GitHub: Praca z LLM stojcymi za GitHub Copilot](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Czerwiec 2023** | [Jak pisa lepsze prompty dla GitHub Copilot](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-koreyst).
- **Lipiec 2023** | [.. GitHub Copilot wykracza poza Codex z ulepszonym modelem AI](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-koreyst)
- **Lipiec 2023** | [Przewodnik Developera po In偶ynierii Prompt贸w i LLM](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-koreyst)
- **Wrzesie 2023** | [Jak zbudowa aplikacj LLM dla przedsibiorstw: Lekcje z GitHub Copilot](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-koreyst)

Mo偶esz r贸wnie偶 przeglda ich [blog in偶ynieryjny](https://github.blog/category/engineering/?WT.mc_id=academic-105485-koreyst) w poszukiwaniu post贸w takich jak [ten](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-koreyst), kt贸ry pokazuje, jak te modele i techniki s _stosowane_ do napdzania aplikacji ze wiata rzeczywistego.

---

## Konstrukcja Promptu

Zobaczylimy, dlaczego in偶ynieria prompt贸w jest wa偶na - teraz zrozummy, jak prompty s _konstruowane_, abymy mogli oceni r贸偶ne techniki dla bardziej efektywnego projektowania prompt贸w.

### Podstawowy Prompt

Zacznijmy od podstawowego promptu: wejcia tekstowego wysanego do modelu bez 偶adnego innego kontekstu. Oto przykad - gdy wysyamy pierwsze kilka s贸w amerykaskiego hymnu narodowego do [API Completion](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-koreyst) OpenAI, natychmiast _uzupenia_ ono odpowied藕 kolejnymi kilkoma wersami, ilustrujc podstawowe zachowanie predykcyjne.

| Prompt (Wejcie)   | Uzupenienie (Wyjcie)                                                                                                  |
| :----------------- | :---------------------------------------------------------------------------------------------------------------------- |
| Oh say can you see | Wyglda na to, 偶e zaczynasz tekst "The Star-Spangled Banner", hymnu narodowego Stan贸w Zjednoczonych. Peny tekst to ... |

### Zo偶ony Prompt

Teraz dodajmy kontekst i instrukcje do tego podstawowego promptu. [API Chat Completion](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-koreyst) pozwala nam konstruowa zo偶ony prompt jako zbi贸r _wiadomoci_ z:

- Pary wejcie/wyjcie odzwierciedlajce dane wejciowe _u偶ytkownika_ i odpowied藕 _asystenta_.
- Wiadomo systemowa ustalajca kontekst dla zachowania lub osobowoci asystenta.

Zapytanie jest teraz w formie poni偶ej, gdzie _tokenizacja_ skutecznie przechwytuje istotne informacje z kontekstu i konwersacji. Teraz zmiana kontekstu systemowego mo偶e mie r贸wnie istotny wpyw na jako uzupenie, jak dane wejciowe u偶ytkownika.

```python
response = openai.chat.completions.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "Jeste pomocnym asystentem."},
        {"role": "user", "content": "Kto wygra mistrzostwa wiata w 2020?"},
        {"role": "assistant", "content": "Los Angeles Dodgers wygrali World Series w 2020 roku."},
        {"role": "user", "content": "Gdzie byy rozgrywane?"}
    ]
)
```

### Prompt Instrukcyjny

W powy偶szych przykadach, prompt u偶ytkownika by prostym zapytaniem tekstowym, kt贸re mo偶e by interpretowane jako proba o informacje. Z promptami _instrukcyjnymi_, mo偶emy u偶y tego tekstu do bardziej szczeg贸owego okrelenia zadania, dostarczajc lepsze wskaz贸wki dla AI. Oto przykad:

| Prompt (Wejcie)                                                                                                                                                                                       | Uzupenienie (Wyjcie)                                                                                                                                  | Typ Instrukcji         |
| :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :--------------------- |
| Napisz opis wojny secesyjnej                                                                                                                                                                           | _zwr贸ci prosty akapit_                                                                                                                                 | Proste                 |
| Napisz opis wojny secesyjnej. Podaj kluczowe daty i wydarzenia oraz opisz ich znaczenie                                                                                                                | _zwr贸ci akapit, a nastpnie list kluczowych dat wydarze z opisami_                                                                                   | Zo偶one                |
| Napisz opis wojny secesyjnej w 1 akapicie. Podaj 3 punkty z kluczowymi datami i ich znaczeniem. Podaj 3 kolejne punkty z kluczowymi postaciami historycznymi i ich wkadem. Zwr贸 wynik jako plik JSON | _zwraca bardziej obszerne szczeg贸y w polu tekstowym, sformatowane jako JSON, kt贸re mo偶esz skopiowa i wklei do pliku i zweryfikowa w razie potrzeby_ | Zo偶one. Sformatowane. |

## G贸wna Tre

W powy偶szych przykadach prompt by nadal do otwarty, pozwalajc LLM zdecydowa, kt贸ra cz jego wstpnie wytrenowanego zbioru danych bya istotna. Przy wzorcu projektowym _g贸wnej treci_, tekst wejciowy jest podzielony na dwie czci:

- instrukcja (dziaanie)
- istotna tre (kt贸ra wpywa na dziaanie)

Oto przykad, gdzie instrukcj jest "podsumuj to w 2 zdaniach".

| Prompt (Wejcie)                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     | Uzupenienie (Wyjcie)                                                                                                                                                                                                                                                                                                        |
| :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest to gazowy olbrzym o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 wszystkie inne planety w Ukadzie Sonecznym razem wzite. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom od czas贸w sprzed zapisanej historii. Zosta nazwany na cze rzymskiego boga Jowisza.[19] Widziany z Ziemi, Jowisz mo偶e by na tyle jasny, 偶e jego odbite wiato rzuca widoczne cienie,[20] i rednio jest trzecim najjaniejszym naturalnym obiektem na nocnym niebie po Ksi偶ycu i Wenus. <br/> **Podsumuj to w 2 kr贸tkich zdaniach** | Jowisz, pita planeta od Soca, jest najwiksz w Ukadzie Sonecznym i jest znany z bycia jednym z najjaniejszych obiekt贸w na nocnym niebie. Nazwany na cze rzymskiego boga Jowisza, jest gazowym olbrzymem, kt贸rego masa jest dwa i p贸 razy wiksza ni偶 wszystkich innych planet w Ukadzie Sonecznym razem wzitych. |

Segment g贸wnej treci mo偶e by u偶ywany na r贸偶ne sposoby, aby napdza bardziej efektywne instrukcje:

- **Przykady** - zamiast m贸wi modelowi, co ma robi za pomoc jawnej instrukcji, daj mu przykady tego, co ma robi i pozw贸l mu wywnioskowa wzorzec dla po偶danego wyjcia.
- **Wskaz贸wki** - pod偶aj za instrukcj z "wskaz贸wk", kt贸ra nakierowuje uzupenienie, prowadzc model w kierunku bardziej odpowiednich odpowiedzi.
- **Szablony** - s to powtarzalne 'przepisy' na prompty z elementami zastpczymi (zmiennymi), kt贸re mog by dostosowane za pomoc danych dla konkretnych przypadk贸w u偶ycia.

Przyjrzyjmy si im w dziaaniu.

### U偶ywanie Przykad贸w

Jest to podejcie, w kt贸rym u偶ywasz g贸wnej treci, aby "poda modelowi" kilka przykad贸w po偶danego wyjcia dla danej instrukcji i pozwoli mu wywnioskowa wzorzec dla po偶danego wyjcia. W zale偶noci od liczby podanych przykad贸w mo偶emy mie prompt zero-shot, one-shot, few-shot itp.

Prompt skada si teraz z trzech skadnik贸w:

- Opis zadania
- Kilka przykad贸w po偶danego wyjcia
- Pocztek nowego przykadu (kt贸ry staje si niejawnym opisem zadania)

| Typ Uczenia | Prompt (Wejcie)                                                                                                                                        | Uzupenienie (Wyjcie)      |
| :---------- | :------------------------------------------------------------------------------------------------------------------------------------------------------ | :-------------------------- |
| Zero-shot   | "The Sun is Shining". Przetumacz na hiszpaski                                                                                                         | "El Sol est谩 brillando".    |
| One-shot    | "The Sun is Shining" => ""El Sol est谩 brillando". <br> "It's a Cold and Windy Day" =>                                                                   | "Es un d铆a fr铆o y ventoso". |
| Few-shot    | Zawodnik przebieg bazy => Baseball <br/> Zawodnik zaserwowa asa => Tenis <br/> Zawodnik zdoby sz贸stk => Krykiet <br/> Zawodnik wykona slam-dunk => | Koszyk贸wka                  |
|             |                                                                                                                                                         |                             |

Zauwa偶, jak musielimy poda jawn instrukcj ("Przetumacz na hiszpaski") w promptowaniu zero-shot, ale jest ona wywnioskowana w przykadzie promptowania one-shot. Przykad few-shot pokazuje, jak dodanie wikszej liczby przykad贸w pozwala modelom na bardziej dokadne wnioskowanie bez dodatkowych instrukcji.

### Wskaz贸wki w Promptach

Inn technik wykorzystania g贸wnej treci jest podawanie _wskaz贸wek_ zamiast przykad贸w. W tym przypadku dajemy modelowi wskaz贸wk we waciwym kierunku, _rozpoczynajc_ od fragmentu, kt贸ry odzwierciedla po偶dany format odpowiedzi. Model nastpnie "bierze wskaz贸wk", aby kontynuowa w tym duchu.

| Liczba wskaz贸wek | Prompt (Wejcie)                                                                                                                                                                                                                                                                                                                                                                                                                                                               | Uzupenienie (Wyjcie)                                                                                                                                                                                                                                                             |
| :--------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 0                | Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest to gazowy olbrzym o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 wszystkie inne planety w Ukadzie Sonecznym razem wzite. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom od czas贸w sprzed zapisanej historii. <br/>**Podsumuj To**                                                          | Jowisz to najwiksza planeta w naszym Ukadzie Sonecznym i pita od Soca. Jest gazowym olbrzymem o masie 1/1000 masy Soca, ale jest ci偶szy ni偶 wszystkie inne planety razem wzite. Staro偶ytne cywilizacje znay Jowisza od dawna i jest on atwo widoczny na nocnym niebie. |
| 1                | Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest to gazowy olbrzym o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 wszystkie inne planety w Ukadzie Sonecznym razem wzite. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom od czas贸w sprzed zapisanej historii. <br/>**Podsumuj To** <br/> Czego si dowiedzielimy, to 偶e Jowisz             | jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest gazowym olbrzymem o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 wszystkie inne planety razem wzite. Jest atwo widoczny goym okiem i by znany od czas贸w staro偶ytnych.            |
| 2                | Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. Jest to gazowy olbrzym o masie jednej tysicznej masy Soca, ale dwa i p贸 razy wikszej ni偶 wszystkie inne planety w Ukadzie Sonecznym razem wzite. Jowisz jest jednym z najjaniejszych obiekt贸w widocznych goym okiem na nocnym niebie i by znany staro偶ytnym cywilizacjom od czas贸w sprzed zapisanej historii. <br/>**Podsumuj To** <br/> 3 Najwa偶niejsze Fakty, Kt贸rych Si Dowiedzielimy: | 1. Jowisz jest pit planet od Soca i najwiksz w Ukadzie Sonecznym. <br/> 2. Jest gazowym olbrzymem o masie jednej tysicznej masy Soca...<br/> 3. Jowisz jest widoczny goym okiem od czas贸w staro偶ytnych ...                                                            |
|                  |                                                                                                                                                                                                                                                                                                                                                                                                                                                                                |                                                                                                                                                                                                                                                                                    |

### Szablony Prompt贸w

Szablon promptu to _predefiniowany przepis na prompt_, kt贸ry mo偶e by przechowywany i ponownie u偶ywany w razie potrzeby, aby napdza bardziej sp贸jne dowiadczenia u偶ytkownika na du偶 skal. W najprostszej formie jest to po prostu kolekcja przykad贸w prompt贸w, takich jak [ten od OpenAI](https://platform.openai.com/examples?WT.mc_id=academic-105485-koreyst), kt贸ry zapewnia zar贸wno interaktywne komponenty promptu (wiadomoci u偶ytkownika i systemu), jak i format 偶dania oparty na API - aby wspiera ponowne u偶ycie.

W bardziej zo偶onej formie, takiej jak [ten przykad z LangChain](https://python.langchain.com/docs/concepts/prompt_templates/?WT.mc_id=academic-105485-koreyst), zawiera _elementy zastpcze_, kt贸re mog by zastpione danymi z r贸偶nych 藕r贸de (dane wejciowe u偶ytkownika, kontekst systemu, zewntrzne 藕r贸da danych itp.), aby dynamicznie generowa prompt. Pozwala to nam stworzy bibliotek wielokrotnego u偶ytku prompt贸w, kt贸re mog by u偶ywane do napdzania sp贸jnych dowiadcze u偶ytkownika **programistycznie** na du偶 skal.

Ostatecznie, prawdziwa warto szablon贸w le偶y w mo偶liwoci tworzenia i publikowania _bibliotek prompt贸w_ dla pionowych domen aplikacji - gdzie szablon promptu jest teraz _zoptymalizowany_, aby odzwierciedla kontekst specyficzny dla aplikacji lub przykady, kt贸re czyni odpowiedzi bardziej odpowiednimi i dokadnymi dla docelowej grupy u偶ytkownik贸w. Repozytorium [Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-koreyst) jest wietnym przykadem tego podejcia, kuratorujc bibliotek prompt贸w dla dziedziny edukacji z naciskiem na kluczowe cele, takie jak planowanie lekcji, projektowanie programu nauczania, korepetycje dla student贸w itp.

## Tre Wspierajca

Jeli mylimy o konstrukcji promptu jako majcej instrukcj (zadanie) i cel (g贸wna tre), to _tre drugorzdna_ jest jak dodatkowy kontekst, kt贸ry zapewniamy, aby **wpyn na wynik w jaki spos贸b**. Mog to by parametry dostrajajce, instrukcje formatowania, taksonomie temat贸w itp., kt贸re mog pom贸c modelowi _dostosowa_ jego odpowied藕, aby odpowiadaa po偶danym celom lub oczekiwaniom u偶ytkownika.

Na przykad: Majc katalog kurs贸w z obszernymi metadanymi (nazwa, opis, poziom, tagi metadanych, instruktor itp.) na temat wszystkich dostpnych kurs贸w w programie:

- mo偶emy zdefiniowa instrukcj, aby "podsumowa katalog kurs贸w na jesie 2023"
- mo偶emy u偶y g贸wnej treci, aby poda kilka przykad贸w po偶danego wyjcia
- mo偶emy u偶y treci drugorzdnej, aby zidentyfikowa 5 najwa偶niejszych "tag贸w" zainteresowania.

Teraz model mo偶e dostarczy podsumowanie w formacie pokazanym przez kilka przykad贸w - ale jeli wynik ma wiele tag贸w, mo偶e priorytetowo traktowa 5 tag贸w zidentyfikowanych w treci drugorzdnej.

## Najlepsze Praktyki Promptowania

Teraz, gdy wiemy, jak prompty mog by _konstruowane_, mo偶emy zacz myle o tym, jak je _projektowa_, aby odzwierciedlay najlepsze praktyki. Mo偶emy myle o tym w dw贸ch czciach - majc waciwe _podejcie_ i stosujc waciwe _techniki_.

### Podejcie do In偶ynierii Prompt贸w

In偶ynieria Prompt贸w to proces pr贸b i bd贸w, wic miej na uwadze trzy og贸lne czynniki przewodnie:

1. **Zrozumienie Domeny Ma Znaczenie.** Dokadno i trafno odpowiedzi jest funkcj _domeny_, w kt贸rej dziaa dana aplikacja lub u偶ytkownik. Zastosuj swoj intuicj i wiedz dziedzinow, aby **dostosowa techniki** dalej. Na przykad zdefiniuj _osobowoci specyficzne dla domeny_ w twoich promptach systemowych lub u偶yj _szablon贸w specyficznych dla domeny_ w twoich promptach u偶ytkownika. Dostarcz treci drugorzdne, kt贸re odzwierciedlaj konteksty specyficzne dla domeny, lub u偶yj _wskaz贸wek i przykad贸w specyficznych dla domeny_, aby prowadzi model w kierunku znanych wzorc贸w u偶ycia.

2. **Zrozumienie Modelu Ma Znaczenie.** Wiemy, 偶e modele s z natury stochastyczne. Ale implementacje modeli mog r贸wnie偶 r贸偶ni si pod wzgldem zestawu danych treningowych, kt贸rych u偶ywaj (wstpnie wytrenowana wiedza), mo偶liwoci, kt贸re zapewniaj (np. za porednictwem API lub SDK) oraz rodzaju treci, do kt贸rych s zoptymalizowane (np. kod vs obrazy vs tekst). Zrozum mocne i sabe strony u偶ywanego modelu i wykorzystaj t wiedz do _priorytetyzacji zada_ lub budowania _dostosowanych szablon贸w_, kt贸re s zoptymalizowane pod ktem mo偶liwoci modelu.

3. **Iteracja i Walidacja Maj Znaczenie.** Modele ewoluuj szybko, podobnie jak techniki in偶ynierii prompt贸w. Jako ekspert w danej dziedzinie, mo偶esz mie inny kontekst lub kryteria dla _swojej_ konkretnej aplikacji, kt贸re mog nie dotyczy szerszej spoecznoci. Wykorzystaj narzdzia i techniki in偶ynierii prompt贸w, aby "przyspieszy" konstrukcj prompt贸w, a nastpnie iteruj i waliduj wyniki, u偶ywajc wasnej intuicji i wiedzy dziedzinowej. Zapisuj swoje spostrze偶enia i tw贸rz **baz wiedzy** (np. biblioteki prompt贸w), kt贸ra mo偶e by u偶ywana jako nowy punkt wyjcia przez innych, dla szybszych iteracji w przyszoci.

## Najlepsze Praktyki

Przyjrzyjmy si teraz wsp贸lnym najlepszym praktykom, kt贸re s zalecane przez praktyk贸w [OpenAI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-koreyst) i [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-koreyst).

| Co                                         | Dlaczego                                                                                                                                                                                                                                                            |
| :----------------------------------------- | :------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------ |
| Oceniaj najnowsze modele.                  | Nowe generacje modeli prawdopodobnie bd miay ulepszone funkcje i jako - ale mog r贸wnie偶 wiza si z wy偶szymi kosztami. Oce je pod ktem wpywu, a nastpnie podejmij decyzje o migracji.                                                                    |
| Oddzielaj instrukcje i kontekst            | Sprawd藕, czy tw贸j model/dostawca definiuje _ograniczniki_, aby wyra藕niej odr贸偶ni instrukcje, tre g贸wn i tre drugorzdn. Mo偶e to pom贸c modelom dokadniej przypisywa wagi do token贸w.                                                                       |
| Bd藕 konkretny i jasny                     | Podaj wicej szczeg贸贸w dotyczcych po偶danego kontekstu, wyniku, dugoci, formatu, stylu itp. Poprawi to zar贸wno jako, jak i sp贸jno odpowiedzi. Zapisuj przepisy w szablonach wielokrotnego u偶ytku.                                                           |
| Bd藕 opisowy, u偶ywaj przykad贸w            | Modele mog lepiej reagowa na podejcie "poka偶 i powiedz". Zacznij od podejcia `zero-shot`, gdzie dajesz mu instrukcj (ale bez przykad贸w), a nastpnie spr贸buj `few-shot` jako udoskonalenie, dostarczajc kilka przykad贸w po偶danego wyniku. U偶ywaj analogii. |
| U偶ywaj wskaz贸wek do rozpoczcia uzupenie | Nakieruj go na po偶dany wynik, dajc mu kilka wiodcych s贸w lub fraz, kt贸re mo偶e wykorzysta jako punkt wyjcia dla odpowiedzi.                                                                                                                                    |
| Podw贸jnie wzmacniaj                        | Czasami mo偶e by potrzebne powt贸rzenie si modelowi. Dawaj instrukcje przed i po g贸wnej treci, u偶ywaj instrukcji i wskaz贸wki itp. Iteruj i waliduj, aby zobaczy, co dziaa.                                                                                      |
| Kolejno Ma Znaczenie                     | Kolejno, w jakiej prezentujesz informacje modelowi, mo偶e wpywa na wynik, nawet w przykadach uczenia si, dziki tendencyjnoci do faworyzowania ostatnich informacji. Wypr贸buj r贸偶ne opcje, aby zobaczy, co dziaa najlepiej.                                 |
| Daj modelowi "wyjcie"                     | Daj modelowi _awaryjn_ odpowied藕 uzupeniajc, kt贸r mo偶e dostarczy, jeli z jakiegokolwiek powodu nie mo偶e wykona zadania. Mo偶e to zmniejszy szanse, 偶e modele generuj faszywe lub zmylone odpowiedzi.                                                     |
|                                            |                                                                                                                                                                                                                                                                     |

Jak w przypadku ka偶dej najlepszej praktyki, pamitaj, 偶e _twoje wyniki mog si r贸偶ni_ w zale偶noci od modelu, zadania i domeny. Wykorzystaj je jako punkt wyjcia i iteruj, aby znale藕 to, co dziaa najlepiej dla ciebie. Stale ponownie oceniaj sw贸j proces in偶ynierii prompt贸w w miar, jak nowe modele i narzdzia staj si dostpne, skupiajc si na skalowalnoci procesu i jakoci odpowiedzi.

## Zadanie

Gratulacje! Dotare do koca lekcji! Czas przetestowa niekt贸re z tych koncepcji i technik na prawdziwych przykadach!

W ramach naszego zadania bdziemy u偶ywa Notebooka Jupyter z wiczeniami, kt贸re mo偶esz wykona interaktywnie. Mo偶esz r贸wnie偶 rozszerzy Notebook o wasne kom贸rki Markdown i Code, aby eksplorowa pomysy i techniki na wasn rk.

### Aby rozpocz, sforkuj repozytorium, a nastpnie

- (Zalecane) Uruchom GitHub Codespaces
- (Alternatywnie) Sklonuj repozytorium na swoje lokalne urzdzenie i u偶yj go z Docker Desktop
- (Alternatywnie) Otw贸rz Notebook za pomoc preferowanego rodowiska wykonawczego Notebook.

### Nastpnie skonfiguruj swoje zmienne rodowiskowe

- Skopiuj plik `.env.copy` w g贸wnym katalogu repozytorium do `.env` i wypenij wartoci `AZURE_OPENAI_API_KEY`, `AZURE_OPENAI_ENDPOINT` i `AZURE_OPENAI_DEPLOYMENT`. Wr贸 do sekcji [Learning Sandbox](./04-prompt-engineering-fundamentals#learning-sandbox), aby dowiedzie si jak.

### Nastpnie otw贸rz Notebook Jupyter

- Wybierz kernel rodowiska wykonawczego. Jeli u偶ywasz opcji 1 lub 2, po prostu wybierz domylny kernel Python 3.10.x dostarczony przez kontener dev.

Jeste gotowy do uruchomienia wicze. Zauwa偶, 偶e nie ma tu _waciwych i niewaciwych_ odpowiedzi - chodzi o eksplorowanie opcji metod pr贸b i bd贸w oraz budowanie intuicji, co dziaa dla danego modelu i domeny aplikacji.

_Z tego powodu w tej lekcji nie ma segment贸w Code Solution. Zamiast tego, Notebook bdzie mia kom贸rki Markdown zatytuowane "Moje Rozwizanie:", kt贸re pokazuj jeden przykadowy wynik jako odniesienie._

## Test wiedzy

Kt贸ry z poni偶szych jest dobrym promptem, zgodnym z rozsdnymi najlepszymi praktykami?

1. Poka偶 mi obraz czerwonego samochodu
2. Poka偶 mi obraz czerwonego samochodu marki Volvo model XC90 zaparkowanego przy klifie z zachodzcym socem
3. Poka偶 mi obraz czerwonego samochodu marki Volvo model XC90

Odp: 2, to najlepszy prompt, poniewa偶 zawiera szczeg贸y dotyczce "czego" i wchodzi w szczeg贸y (nie tylko dowolny samoch贸d, ale konkretna marka i model) oraz opisuje og贸lne otoczenie. 3 jest nastpny najlepszy, poniewa偶 r贸wnie偶 zawiera du偶o opisu.

##  Wyzwanie

Spr贸buj wykorzysta technik "wskaz贸wki" z promptem: Dokocz zdanie "Poka偶 mi obraz czerwonego samochodu marki Volvo i ". Co odpowiada i jak by to ulepszy?

## wietna Praca! Kontynuuj Nauk

Chcesz dowiedzie si wicej o r贸偶nych koncepcjach In偶ynierii Prompt贸w? Przejd藕 do [strony kontynuacji nauki](https://aka.ms/genai-collection?WT.mc_id=academic-105485-koreyst), aby znale藕 inne wietne zasoby na ten temat.

Przejd藕 do Lekcji 5, gdzie przyjrzymy si [zaawansowanym technikom promptowania](../../../05-advanced-prompts/translations/pl/README.md?WT.mc_id=academic-105485-koreyst)!
